<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca---1328">NCA - 1328</h2>
<ul>
<li><details>
<summary>
(2024). Correction: Stochastic optimal reactive power dispatch at
varying time of load demand and renewable energy resources using an
efficient modified jellyfish optimizer. <em>NCA</em>, <em>36</em>(36),
23309. (<a href="https://doi.org/10.1007/s00521-024-10367-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Gami, Fatma and Alrowaili, Ziyad A. and Ezzeldien, Mohammed and Ebeed, Mohamed and kamel, Salah and Oda, Eyad S. and Mohamed, Shazly A.},
  doi          = {10.1007/s00521-024-10367-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23309},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Stochastic optimal reactive power dispatch at varying time of load demand and renewable energy resources using an efficient modified jellyfish optimizer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regularization of deep neural network using a multisample
memory model. <em>NCA</em>, <em>36</em>(36), 23295–23307. (<a
href="https://doi.org/10.1007/s00521-024-10474-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (CNNs) are widely used in computer vision and have achieved significant performance for image classification tasks. Overfitting is a general problem in deep learning models that inhibit the generalization capability of deep models due to the presence of noise, the limited size of the training data, the complexity of the classifier, and the larger number of hyperparameters involved during training. Several techniques have been developed for overfitting inhibition, but in this research we focus only on regularization techniques. We propose a memory-based regularization technique to inhibit overfitting problems and generalize the performance of deep neural networks. Our backbone architectures receive input samples in bags rather than directly in batches to generate deep features. The proposed model receives input samples as queries and feeds them to the MAM (memory access module), which searches for the relevant items in memory and computes memory loss using Euclidean similarity measures. Our memory loss function incorporates intra-class compactness and inter-class separability at the feature level. Most surprisingly, the convergence rate of the proposed model is superfast, requiring only a few epochs to train both shallow and deeper models. In this study, we evaluate the performance of the memory model across several state-of-the-art (SOTA) deep learning architectures, including ReseNet18, ResNet50, ResNet101, VGG-16, AlexNet, and MobileNet, using the CIFAR-10 and CIFAR-100 datasets. The results show that the efficient memory model we have developed significantly outperforms almost all existing SOTA benchmarks by a considerable margin.},
  archive      = {J_NCA},
  author       = {Tanveer, Muhammad and Siyal, Mohammad Yakoob and Rashid, Sheikh Faisal},
  doi          = {10.1007/s00521-024-10474-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23295-23307},
  shortjournal = {Neural Comput. Appl.},
  title        = {Regularization of deep neural network using a multisample memory model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing breast cancer histopathological image
classification using attention-based high order covariance pooling.
<em>NCA</em>, <em>36</em>(36), 23275–23293. (<a
href="https://doi.org/10.1007/s00521-024-10464-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer, the most common cancer affecting female patients, presents serious challenges for proper detection. Although computer-aided diagnostic techniques have progressed, their accuracy and efficacy remain limited. To overcome these challenges, we introduce DHA-Net, a new deep learning system that combines an effective attention module (EAM) and a high-order pooling layer with a ResNet-18 backbone. DHA-Net is tested using three well-known breast cancer histopathology image datasets: BreakHis, BACH2018, and a closely related Kaggle-Breast cancer histopathology dataset. Our experiments show that DHA-Net not only improves on existing state-of-the-art approaches, but significantly outperforms them in classifying breast cancer images. This work emphasizes the novel combination of an EAM with high-order pooling, demonstrating DHA-Net’s potential to improve diagnostic accuracy and serve as a more effective tool for medical imaging applications.},
  archive      = {J_NCA},
  author       = {Waqas, Muhammad and Ahmed, Amr and Maul, Tomas and Liao, Iman Yi},
  doi          = {10.1007/s00521-024-10464-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23275-23293},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing breast cancer histopathological image classification using attention-based high order covariance pooling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Potcapsnet: An explainable pyramid dilated capsule network
for visualization of blight diseases. <em>NCA</em>, <em>36</em>(36),
23251–23274. (<a
href="https://doi.org/10.1007/s00521-024-10476-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Potato tuber is crucial as a primary vegetable food crop across the globe. However, its quality and quantity are constantly threatened by fungal blight diseases, particularly late and early blight, posing a significant risk to food security. To identify blight diseases, agrarians visually inspect potato leaf color variations, which is time-consuming and computationally expensive. To address this challenge, various advanced technologies, such as image processing, machine learning, and deep neural networks, have been widely applied in agricultural domains, especially for autonomous disease identification and classification. However, there is an urgent need to develop computational models that can rapidly and objectively detect these diseases, even in their early stages. Therefore, this paper introduces the “PotCapsNet&quot; method that utilizes parallel atrous convolutional layers with varying dilation rates for multi-scale feature extraction, a shuffled convolutional block attention module for effective feature selection, and a capsule network for early disease classification. The effectiveness of the proposed model was validated using the publicly available PlantVillage and PLD datasets for multi-class potato leaf disease identification. The experimental findings show that the proposed method outperforms other methods in terms of accuracy, specificity, F1 score, and sensitivity. The proposed method attained average recognition accuracy of 97.81 $$\%$$ and 97.95 $$\%$$ on the PlantVillage and PLD datasets, respectively, the best among all the considered methods. The code and datasets of the proposed method are available at https://github.com/ersachingupta11/PotCapsNet .},
  archive      = {J_NCA},
  author       = {Gupta, Sachin and Tripathi, Ashish Kumar and Pandey, Avinash Chandra},
  doi          = {10.1007/s00521-024-10476-9},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23251-23274},
  shortjournal = {Neural Comput. Appl.},
  title        = {Potcapsnet: An explainable pyramid dilated capsule network for visualization of blight diseases},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete orca predation algorithm for the traveling salesman
problem. <em>NCA</em>, <em>36</em>(36), 23223–23250. (<a
href="https://doi.org/10.1007/s00521-024-10475-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) is a frequently studied problem by researchers today and belongs to the class of combinatorial optimization problems. It can be used to solve many current world problems such as scheduling, circuit design, layout design of plants in factories, route planning and printed circuit design. Therefore, researchers working in the field of optimization methods use it as a realistic test environment and evaluate the performance of new algorithms on it. In this study, a discrete version of the orca predation algorithm (OPA) was developed, called DOPA. DOPA is a novel discrete and permutation-coded optimization algorithm. As in OPA, it consists of two phases: chasing and attacking. However, these phases in DOPA were arranged to be able to solve a combinatorial optimization problem such as TSP. In the chasing phase, the distances between the orcas were calculated with the Hamming distance, and the speed values were obtained by using these distances. The positions of the orcas were updated using the speed values and 2-opt algorithm. In the attacking phase, the positions of the orcas were calculated by order crossover (OX1) operator. In the position adjustment procedure, swap local search operator was used. Thus, the convergence of the algorithm was accelerated. DOPA has much less parameters than OPA. Therefore, it is a simple and effective algorithm with few parameters. The parameters of DOPA were optimized by the Taguchi statistical method. It was tested on 67 well-known TSP instances. The results of different performance measures and tests showed that DOPA is a highly competitive and alternative method compared to other methods.},
  archive      = {J_NCA},
  author       = {Kilinç, Hamdi and İlhan, İlhan},
  doi          = {10.1007/s00521-024-10475-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23223-23250},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discrete orca predation algorithm for the traveling salesman problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSTMN: A novel meta-attention-based multi-task
spatiotemporal network for traffic flow prediction. <em>NCA</em>,
<em>36</em>(36), 23195–23222. (<a
href="https://doi.org/10.1007/s00521-024-10331-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction in a given area is often influenced by the interactions with complex dependencies among multiple areas. By far, it remains unexplored to obtain interactive information. To address the issue, MSTMN was proposed, a multi-task learning framework that jointly learns interactive information and spatiotemporal dependencies across tasks. MSTMN consists of a node network, an edge network, and a prediction network. The node network and edge network were trained using the proposed meta-fully convolutional blocks to extract interactive features and generalizable features. The prediction network employed the meta-gated fusion and the recalibration block to both integrate these learned features and external factors. This ensures that the features capture optimal interaction information during the training phase. The proposed model was validated on two real-world movement-on-demand traffic datasets collected in Xiamen, China. Experimental results showed that MSTMN improved performance by 38.42% and 31.77% for one-step and multi-step prediction compared to the state-of-the-art baseline.},
  archive      = {J_NCA},
  author       = {Zhou, Qianqian and Chen, Nan},
  doi          = {10.1007/s00521-024-10331-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23195-23222},
  shortjournal = {Neural Comput. Appl.},
  title        = {MSTMN: A novel meta-attention-based multi-task spatiotemporal network for traffic flow prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing abnormality detection in fundus images with
triplet-OS and orchard search optimization model. <em>NCA</em>,
<em>36</em>(36), 23181–23194. (<a
href="https://doi.org/10.1007/s00521-024-10005-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate and early detection of abnormalities in fundus images is crucial for the timely diagnosis and treatment of various eye diseases, such as glaucoma and diabetic retinopathy. The detection of abnormalities in fundus images using traditional methods is often challenging due to high computational demands, scalability issues, and the requirement of large labeled datasets for effective training. To address these limitations, a new method called triplet-based orchard search (Triplet-OS) has been proposed in this paper. In this study, a GoogleNet (Inception) is utilized for feature extraction of fundus images. Also, the residual network is employed to detect abnormalities in fundus images. The Triplet-OS utilizes the medical imaging technique fundus photography dataset to capture detailed images of the interior surface of the eye, known as the fundus and the fundus includes the retina, optic disk, macula, and blood vessels. To enhance the performance of the Triplet-OS method, the orchard optimization algorithm has been implemented with an initial search strategy for hyperparameter optimization. The performance of the Triplet-OS method has been evaluated based on different metrics such as F1-score, specificity, AUC-ROC, recall, precision, and accuracy. Additionally, the performance of the proposed method has been compared with existing methods. Few-shot learning refers to a process where models can learn from just a small number of examples. This method has been applied to reduce the dependency on deep learning [1]. The goal is for machines to become as intelligent as humans. Today, numerous computing devices, extensive datasets, and advanced methods such as CNN and LSTM have been developed. AI has achieved human-like performance and, in many fields, surpasses human abilities. AI has become part of our daily lives, but it generally relies on large-scale data. In contrast, humans can often apply past knowledge to quickly learn new tasks [2]. For example, if given multiple photographs of strangers, a child can easily recognize the same person across different images. This highlights the difference between AI and human learning. To address this gap, a new machine learning approach called few-shot learning was developed, enabling machines to learn from a limited number of examples in a manner similar to human learning [3]. The experimental results demonstrate the effectiveness of the Triplet-OS method for detecting abnormalities in fundus images using a few-shot learning framework.},
  archive      = {J_NCA},
  author       = {Venkatraman, K. and Hemalatha, R. and Radhika, S.},
  doi          = {10.1007/s00521-024-10005-8},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23181-23194},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing abnormality detection in fundus images with triplet-OS and orchard search optimization model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Narrator identification by querying sanad graph and
utilizing the NarratorsKG on AR-sanad 280K-v2 dataset. <em>NCA</em>,
<em>36</em>(36), 23169–23180. (<a
href="https://doi.org/10.1007/s00521-024-10194-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Narrator disambiguation is a field within hadith science that studies unidentified narrators in hadith narration chains, also known as sanads. Sanads can be represented as graphs, with the nodes representing the narrators and the edges representing their relationships in the chain. The current methods for resolving the narrator disambiguation problem do not utilize the graph structure of the sanad, but by leveraging this structure, we can apply graph computational and deep learning techniques to identify narrators. This paper introduces a method that utilizes the sanad graph structure to identify all narrators in a given sanad. Our two-stage approach begins by generating a query embedding and identifying the top k narrator entities closest to the query embedding. We then use AraBERT to re-rank the top k narrators and make the final prediction. Our method achieves 94.6% accuracy on the validation set of AR-Sanad 280K dataset. Additionally, we present AR-Sanad 280K-v2, an updated dataset that represents real hadiths more accurately.},
  archive      = {J_NCA},
  author       = {Mahmoud, Somaia and Nabil, Emad and Saif, Omar and Torki, Marwan},
  doi          = {10.1007/s00521-024-10194-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23169-23180},
  shortjournal = {Neural Comput. Appl.},
  title        = {Narrator identification by querying sanad graph and utilizing the NarratorsKG on AR-sanad 280K-v2 dataset},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VISTA: Vision improvement via split and reconstruct deep
neural network for fundus image quality assessment. <em>NCA</em>,
<em>36</em>(36), 23149–23168. (<a
href="https://doi.org/10.1007/s00521-024-10174-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Widespread eye conditions such as cataracts, diabetic retinopathy, and glaucoma impact people worldwide. Ophthalmology uses fundus photography for diagnosing these retinal disorders, but fundus images are prone to image quality challenges. Accurate diagnosis hinges on high-quality fundus images. Therefore, there is a need for image quality assessment methods to evaluate fundus images before diagnosis. Consequently, this paper introduces a deep learning model tailored for fundus images that supports large images. Our division method centres on preserving the original image’s high-resolution features while maintaining low computing and high accuracy. The proposed approach encompasses two fundamental components: an autoencoder model for input image reconstruction and image classification to classify the image quality based on the latent features extracted by the autoencoder, all performed at the original image size, without alteration, before reassembly for decoding networks. Through post hoc interpretability methods, we verified that our model focuses on key elements of fundus image quality. Additionally, an intrinsic interpretability module has been designed into the network that allows decomposing class scores into underlying concepts quality such as brightness or presence of anatomical structures. Experimental results in our model with EyeQ, a fundus image dataset with three categories (Good, Usable, and Rejected) demonstrate that our approach produces competitive outcomes compared to other deep learning-based methods with an overall accuracy of 0.9066, a precision of 0.8843, a recall of 0.8905, and an impressive F1-score of 0.8868. The code is publicly available at https://github.com/saifalkhaldiurv/VISTA_-Image-Quality-Assessment .},
  archive      = {J_NCA},
  author       = {Khalid, Saif and Abdulwahab, Saddam and Stanchi, Oscar Agustín and Quiroga, Facundo Manuel and Ronchetti, Franco and Puig, Domenec and Rashwan, Hatem A.},
  doi          = {10.1007/s00521-024-10174-6},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23149-23168},
  shortjournal = {Neural Comput. Appl.},
  title        = {VISTA: Vision improvement via split and reconstruct deep neural network for fundus image quality assessment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Group activity recognition using unreliable tracked pose.
<em>NCA</em>, <em>36</em>(36), 23131–23148. (<a
href="https://doi.org/10.1007/s00521-024-10470-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group activity recognition in video is a complex task due to the need for a model to recognise the actions of all individuals in the video and their complex interactions. Recent studies propose that optimal performance is achieved by individually tracking each person and subsequently inputting the sequence of poses or cropped images/optical flow into a model. This helps the model to recognise what actions each person is performing before they are merged to arrive at the group action class. However, all previous models rely highly on high-quality tracking and have only been evaluated using ground truth tracking information. In practice, achieving highly reliable tracking information for all individuals in a group activity video is almost impossible. We introduce an innovative deep learning-based group activity recognition approach called Rendered Pose-based Group Activity Recognition System (RePGARS), designed to tolerate unreliable tracking and pose information. Experimental results confirm that RePGARS outperforms all existing group activity recognition algorithms tested, which do not use ground truth detection and tracking information.},
  archive      = {J_NCA},
  author       = {Thilakarathne, Haritha and Nibali, Aiden and He, Zhen and Morgan, Stuart},
  doi          = {10.1007/s00521-024-10470-1},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23131-23148},
  shortjournal = {Neural Comput. Appl.},
  title        = {Group activity recognition using unreliable tracked pose},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computerized otoscopy image-based artificial intelligence
model utilizing deep features provided by vision transformer, grid
search optimization, and support vector machine for otitis media
diagnosis. <em>NCA</em>, <em>36</em>(36), 23113–23129. (<a
href="https://doi.org/10.1007/s00521-024-10457-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Otitis media (OM) is an inflammation of the middle ear, often associated with fluid accumulation and characterized by symptoms such as ear pain, fever, and impaired hearing. Timely and accurate diagnosis of OM is essential to facilitate prompt treatment and mitigate the risk of complications such as hearing loss or chronic infection, particularly in regions with limited access to healthcare professionals. In this study, we introduce an advanced computational model for automated OM diagnosis, utilizing the vision transformer (ViT) architecture to extract highly discriminative features from otoscope images. The proposed approach employs a grid search optimization algorithm in combination with a support vector machine (SVM) classifier to accurately recognize different types of OM based on deep feature representations. All experiments were conducted using a publicly accessible Ear Imagery dataset containing 880 otoscope images, categorized into four distinct classes. As a result, the proposed model demonstrated remarkable efficacy, achieving an impressive accuracy rate of 99.37%. It successfully classified all OM types. At its core, the emergence of advanced computational models in healthcare represents a transformative leap that promises to close gaps in access to medical expertise and revolutionize diagnostic practices. Harnessing the power of machine learning and leveraging vast datasets, these models offer unprecedented accuracy and efficiency, paving the way for early intervention and improving patient outcomes on a global scale.},
  archive      = {J_NCA},
  author       = {Cömert, Zafer and Sbrollini, Agnese and Demircan, Furkancan and Burattini, Laura},
  doi          = {10.1007/s00521-024-10457-y},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23113-23129},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computerized otoscopy image-based artificial intelligence model utilizing deep features provided by vision transformer, grid search optimization, and support vector machine for otitis media diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RSDiff: Remote sensing image generation from text using
diffusion model. <em>NCA</em>, <em>36</em>(36), 23103–23111. (<a
href="https://doi.org/10.1007/s00521-024-10363-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation and enhancement of satellite imagery are critical in remote sensing, requiring high-quality, detailed images for accurate analysis. This research introduces a two-stage diffusion model methodology for synthesizing high-resolution satellite images from textual prompts. The pipeline comprises a low-resolution diffusion model (LRDM) that generates initial images based on text inputs and a super-resolution diffusion model (SRDM) that refines these images into high-resolution outputs. The LRDM merges text and image embeddings within a shared latent space, capturing essential scene content and structure. The SRDM then enhances these images, focusing on spatial features and visual clarity. Experiments conducted using the Remote Sensing Image Captioning Dataset demonstrate that our method outperforms existing models, producing satellite images with accurate geographical details and improved spatial resolution.},
  archive      = {J_NCA},
  author       = {Sebaq, Ahmad and ElHelw, Mohamed},
  doi          = {10.1007/s00521-024-10363-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23103-23111},
  shortjournal = {Neural Comput. Appl.},
  title        = {RSDiff: Remote sensing image generation from text using diffusion model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-heuristic-based home energy management system for
optimizing smart appliance scheduling and electricity cost reduction in
residential complexes. <em>NCA</em>, <em>36</em>(36), 23077–23102. (<a
href="https://doi.org/10.1007/s00521-024-10275-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the evolution of technology and substantial advancements in smart devices, managing and controlling energy consumption in households has become increasingly crucial. Smart grid technology serves as an enabler, empowering consumers to effectively manage their energy consumption. This necessitates the role of smart appliance scheduling. In this study, an effective home energy management (HEM) system is introduced, utilizing a new proposed approach called the gradient-based Runge–Kutta optimizer (GRUN). The proposed GRUN approach aims to optimize energy consumption by employing the Runge–Kutta optimizer (RUN) which based on the Local Escaping Operator (LEO) from gradient-based optimizer (GBO). It utilizes multiple knapsacks to maintain electricity demand below a predefined threshold during peak hours. Firstly, the validation of the proposed GRUN technique is confirmed by seven benchmark functions and compared its results with those  obtained by other well-known optimization algorithms, including artificial ecosystem-based optimization, hunter prey optimization, GBO, and the original RUN algorithm. Then, the performance of the GRUN technique is checked for the optimization of smart HEM. This study ensures that power remains within specified limits and that power consumption remains constant before and after scheduling, without affecting the operation time of each device. Additionally, it determines the cost of both scheduled and unscheduled loads, providing information about their operating times and the current status of each device. The developed approach yields significant benefits in reducing electricity costs and the peak-to-average ratio. The reduction in electricity bill ranges from 60% for a single home to 20% for 100 homes throughout the day. Moreover, a decrease in electricity consumption per hour leads to a peak reduction of 50% for one house and 25% for 100 houses during the day. Evaluated through MATLAB simulations in a residential complex with multiple smart homes, the GRUN system demonstrates substantial advantages over the RUN system in reducing electricity costs. This study offers an effective perspective on household energy management, achieving a better balance between energy consumption and its associated costs.},
  archive      = {J_NCA},
  author       = {Youssef, Heba and Kamel, Salah and Hassan, Mohamed H.},
  doi          = {10.1007/s00521-024-10275-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23077-23102},
  shortjournal = {Neural Comput. Appl.},
  title        = {Meta-heuristic-based home energy management system for optimizing smart appliance scheduling and electricity cost reduction in residential complexes},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LPL-VIO: Monocular visual-inertial odometry with deep
learning-based point and line features. <em>NCA</em>, <em>36</em>(36),
23061–23075. (<a
href="https://doi.org/10.1007/s00521-024-10294-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual-inertial SLAM (VINS) has garnered substantial interest in the field of mobile robotics due to its robustness and cost-effectiveness. The incorporation of both point and line features in visual SLAM has shown significant performance improvements compared to relying solely on point features. Furthermore, learning-based features consistently outperform traditional hand-crafted features across a diverse range of tasks. Leveraging all these observations, we propose a novel deep learning technique, termed learning-based point and line visual-inertial odometry (LPL-VIO), which is aimed to enhance robustness and performance of traditional systems. LPL-VIO takes a 2-stage approach, including a deep learning front-end and a traditional nonlinear optimization back-end. In the first stage (front-end), we employ proposed networks for points and lines to extract and track deep learning-based point and line features in visual images, while implementing IMU preintegration. In the second stage (back-end), we adopt a sliding window strategy to tightly couple point and line re-projection errors with IMU preintegration residuals. These residuals are optimized using bundle adjustment for precise global pose estimation. Extensive experiments are conducted on both public EuRoC datasets and our own real-world dataset collected in challenging outdoor environments. Qualitative and quantitative results show that our method exhibits strong competitiveness compared with the existing point–line techniques, and outperforms the popular VINS-Mono.},
  archive      = {J_NCA},
  author       = {Liu, Changxiang and Yang, Qinhan and Yu, Hongshan and Fu, Qiang and Akhtar, Naveed},
  doi          = {10.1007/s00521-024-10294-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23061-23075},
  shortjournal = {Neural Comput. Appl.},
  title        = {LPL-VIO: Monocular visual-inertial odometry with deep learning-based point and line features},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved graph convolutional neural network for EEG
emotion recognition. <em>NCA</em>, <em>36</em>(36), 23049–23060. (<a
href="https://doi.org/10.1007/s00521-024-10469-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic uncertainty of the relationship among brain regions is an important limiting factor in electroencephalography (EEG)-based emotion recognition. This uncertainty stems from individual differences and emotional volatility, which needs further in-depth study. In this paper, we propose a new emotion recognition method, which is named graph convolutional neural network with spatio-temporal modeling and long short-term memory (STLGCNN). The proposed method aims to address the instability of emotion intensity and underutilization of EEG biotopological information. The method consists of an attention module, a bi-directional long short-term memory network (BiLSTM), a graph convolutional neural network (GCNN) and a long short-term memory module (LSTM). The attention mechanism is utilized to reveal correlations between different time periods and to reduce emotional temporal volatility. The BiLSTM is employed to learn spatio-temporal features. Then, the GCNN learns the biotopological information of multi-channel EEG signals and extracts effective graph domain features. These features are then fed into the LSTM to integrate the graph-domain information and extract valid temporal information. To verify the effectiveness of the STLGCNN method, we conducted experiments on the DEAP and SEED datasets. The average accuracies on the two datasets are 93.95 and 96.78%, respectively. The results show that the STLGCNN method has better performance than existing methods.},
  archive      = {J_NCA},
  author       = {Xu, Bingyue and Zhang, Xin and Zhang, Xiu and Sun, Baiwei and Wang, Yujie},
  doi          = {10.1007/s00521-024-10469-8},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23049-23060},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved graph convolutional neural network for EEG emotion recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IA-HLD: An improved AlexNet for hairline fracture detection
in orthopedic images. <em>NCA</em>, <em>36</em>(36), 23031–23047. (<a
href="https://doi.org/10.1007/s00521-024-10348-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone fractures are a substantial health concern affecting approximately 2.7 million individuals annually across six European countries: France, Germany, Italy, Spain, Sweden, and the UK. If left untreated, this issue carries significant health risks, including fatality. It is crucial to accurately identify the types of fractures, especially subtle hairline fractures to mitigate long-term consequences. These fractures are characterized by small breaks where the bone fragments are aligned, and there is no visible displacement. Unfortunately, detecting hairline fractures is a significant challenge in the medical field. This is mainly attributed to the intricate nature of these fractures adding complexity, posing difficulties for both human and machine detection. Additionally, there is a lack of easily accessible datasets focused on hairline fractures. This paper introduces the iA-HLD model, a novel and enhanced approach for detecting hairline fractures. Through architectural modifications, this model exhibits superior capabilities in identifying hairline fractures across all types of human bones using deep learning and stands as the pioneering solution of its kind. A comprehensive comparative analysis is conducted, assessing the performance of the proposed model against established models, including ResNet-50, AlexNet, and convolutional neural network. Evaluation metrics, including accuracy, precision, recall, and F1-score, are used to compare the models. iA-HLD achieved an accuracy rate of 97.6%, highlighting its superior capabilities. In addition, it scored 98% in precision, recall, and F1-score, which surpasses all other models. These results show its improved capabilities as well as its potential for use in real-world applications across many fields. The research is a significant stride in advancing hairline fracture detection and addresses a critical gap in current medical diagnostic methods.},
  archive      = {J_NCA},
  author       = {Jain, Bhawna and Malik, Diksha and Jagota, Ganiti and Gyanvi and Chandra, Ishita},
  doi          = {10.1007/s00521-024-10348-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {23031-23047},
  shortjournal = {Neural Comput. Appl.},
  title        = {IA-HLD: An improved AlexNet for hairline fracture detection in orthopedic images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal renewable distributed generation planning in radial
distribution systems: A probabilistic and multi-objective approach with
enhanced young’s double-slit experiment optimizer. <em>NCA</em>,
<em>36</em>(36), 22999–23030. (<a
href="https://doi.org/10.1007/s00521-024-10301-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the stochastic nature of renewable energy sources, demand fluctuations, and the complexity of distribution systems, addressing the Optimal Renewable Distributed Generation Planning (ORDGP) problem in radial distribution systems (RDS) practically requires a combination of probabilistic and multi-objective approaches. Therefore, this study’s primary objective is to meticulously integrate both technical and economic aspects by simultaneously allocating photovoltaic and wind turbine generators within the standard IEEE 69-bus RDS, considering voltage-dependent and time-varying mixed loads. Moving closer to real-world scenarios, the complexity of ORDGP is heightened by considering uncertainties in solar and wind power generation, achieved through a new probabilistic model to evaluate the expected energy output from these sources. Additionally, this study targets six objectives for the first time, including reducing energy losses, enhancing voltage stability, refining load balancing, ensuring reliable supply, and maximizing total savings over a five-year period. To effectively address the ORDGP problem, an enhancement is introduced in the global search capacity of the recent Young’s double-slit experiment (YDSE) optimizer, resulting in the modified YDSE (mYDSE) algorithm. The robustness of the mYDSE optimizer is validated through nonparametric tests, including the Freidman mean rank test and Wilcoxon sum test. Encouragingly, this study reveals promising results, including an 85.66% reduction in total energy losses and notable improvements in technical system metrics. Additionally, the proposed method suggests substantial economic savings, estimated at up to 12.77 million US dollars. Remarkably, the mYDSE optimizer emerges as a leader, surpassing recent methods and demonstrating its ability to maximize economic benefits while enhancing technical system performance. The proposed approach promises to pave the way for balanced and realistic solutions, with profound implications for the sustainable evolution of power systems.},
  archive      = {J_NCA},
  author       = {Tarraq, Ali and Hashim, Fatma A. and Bouaouda, Anas and El Mariami, Faissal and Kamel, Salah},
  doi          = {10.1007/s00521-024-10301-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22999-23030},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal renewable distributed generation planning in radial distribution systems: A probabilistic and multi-objective approach with enhanced young’s double-slit experiment optimizer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial neural networks for predicting the sorption
coefficient of s-metolachlor: A hypothetical alternative to mitigate
environmental risks and enhance herbicide efficiency in weed management.
<em>NCA</em>, <em>36</em>(36), 22983–22997. (<a
href="https://doi.org/10.1007/s00521-024-10472-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sorption coefficients of herbicides are directly linked to soil properties, making predictive mathematical modeling crucial for understanding their behavior in soil environments. This study aims to leverage artificial neural networks (ANNs) to predict the sorption coefficient of S-metolachlor in soils, facilitating the assessment of environmental contamination risk and recommending pre-emergent herbicides. The objectives are: (1) to identify predictive variables for ANNs that can estimate S-metolachlor sorption coefficients; (2) to assess the performance of ANNs in predicting S-metolachlor sorption coefficients; and (3) to determine the key soil attributes for predicting these coefficients using ANNs. The ANNs successfully estimated the sorption capacity of S-metolachlor in the soils under study. By carefully selecting representative variables and employing appropriate structures, the ANNs achieved high precision and accuracy in estimating the S-metolachlor sorption coefficient (Kfs) in soil. The predictive screening process, utilizing the bootstrap forest partitioning method to select ANN inputs, emerged as a crucial step in developing well-trained models with strong generalization capabilities during testing. Furthermore, predictive screening revealed that certain attributes, not typically correlated with herbicide sorption in soils, contribute significantly to predicting Kfs. These findings suggest a theoretical alternative for optimizing the application of S-metolachlor in soil, ensuring efficiency while minimizing environmental risks. Future research in this area should focus on biological assays in controlled environments and field settings to validate the effectiveness of the proposed method for agronomic recommendations regarding S-metolachlor.},
  archive      = {J_NCA},
  author       = {Lins, Hamurábi Anizio and de Freitas Souza, Matheus and Batista, Lucrecia Pacheco and da Silva Rodrigues, Luma Lorena Loureiro and Silva, Francisca Daniele da and Fernandes, Bruno Caio Chaves and das Chagas, Paulo Sérgio Fernandes and de Jesus Passos, Ana Beatriz Rocha and Silva, Daniel Valadão},
  doi          = {10.1007/s00521-024-10472-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22983-22997},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural networks for predicting the sorption coefficient of S-metolachlor: A hypothetical alternative to mitigate environmental risks and enhance herbicide efficiency in weed management},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing plant disease detection: A novel CNN-based
approach with tensor subspace learning and HOWSVD-MDA. <em>NCA</em>,
<em>36</em>(36), 22957–22981. (<a
href="https://doi.org/10.1007/s00521-024-10454-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has revolutionized the field of agricultural science, particularly in the early detection and management of plant diseases, which are crucial for maintaining crop health and productivity. Leveraging advanced algorithms and imaging technologies, researchers are now able to identify and classify plant diseases with unprecedented accuracy and speed. Effective management of tomato diseases is crucial for enhancing agricultural productivity. The development and application of tomato disease classification methods are central to this objective. This paper introduces a cutting-edge technique for the detection and classification of tomato leaf diseases, utilizing insights from the latest pre-trained convolutional neural network (CNN) models. We propose a sophisticated approach within the domain of tensor subspace learning, known as higher-order whitened singular value decomposition (HOWSVD), designed to boost the discriminatory power of the system. Our approach to tensor subspace learning is methodically executed in two phases, beginning with HOWSVD and culminating in multilinear discriminant analysis (MDA). The novelty of this study lies in the integration of HOWSVD and MDA, enhancing the discriminatory capabilities of high-dimensional CNN embeddings. Our HOWSVD method preprocesses and reduces the high dimensionality of features while preserving crucial variance. Subsequently, the application of MDA ensures the maximization of class separability within the transformed tensor subspace. Our results demonstrate that HOWSVD-MDA achieves superior accuracy compared to existing methods. The efficacy of this innovative method was rigorously tested through comprehensive experiments on two distinct datasets, namely, PlantVillage and the Taiwan dataset. Key findings include achieving up to 98.36% accuracy on the PlantVillage dataset and 98.39% on the Taiwan dataset, significantly outperforming current state-of-the-art techniques. The findings reveal that HOWSVD-MDA outperforms existing methods, underscoring its capability to markedly enhance the precision and dependability of diagnosing tomato leaf diseases.},
  archive      = {J_NCA},
  author       = {Ouamane, Abdelmalik and Chouchane, Ammar and Himeur, Yassine and Debilou, Abderrazak and Nadji, Slimane and Boubakeur, Nabil and Amira, Abbes},
  doi          = {10.1007/s00521-024-10454-1},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22957-22981},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing plant disease detection: A novel CNN-based approach with tensor subspace learning and HOWSVD-MDA},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TS-pothole: Automated imputation of missing values in
univariate time series. <em>NCA</em>, <em>36</em>(36), 22923–22955. (<a
href="https://doi.org/10.1007/s00521-024-10391-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data are pivotal in diverse fields such as finance, meteorology, and health data analysis. Accurate analysis of these data is crucial for identifying temporal trends and making informed decisions. However, frequent occurrences of missing values, often due to device failures or data collection errors, pose a significant challenge. In this work, we introduce TS-Pothole, a method for imputing missing values in univariate time series. This method leverages cyclic pattern analysis and a recursive strategy to handle univariate datasets in which missing values are distributed both continuously and randomly. We evaluate TS-Pothole on four real-world datasets representing different configurations of missing values, and assess its performance in terms of accuracy and execution speed. In particular, we compare our approach with state-of-the-art methods, such as GANs and autoencoders. Our experiments show that TS-Pothole outperforms such methods by providing more accurate (up to 1.5 times) and faster (up to 2 times) imputations, even as the proportion of missing data increases, representing the best alternative in handling univariate time series with missing values.},
  archive      = {J_NCA},
  author       = {Sanwouo, Brell and Quinton, Clément and Rouvoy, Romain},
  doi          = {10.1007/s00521-024-10391-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22923-22955},
  shortjournal = {Neural Comput. Appl.},
  title        = {TS-pothole: Automated imputation of missing values in univariate time series},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual learning for brain tumor segmentation: Dual
residual blocks approach. <em>NCA</em>, <em>36</em>(36), 22905–22921.
(<a href="https://doi.org/10.1007/s00521-024-10380-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most common type of malignant brain tumor, gliomas, has a variety of grades that significantly impact a patient’s chance of survival. Accurate segmentation of brain tumor regions from MRI images is crucial for enhancing diagnostic precision and refining surgical strategies. This task is particularly challenging due to the diverse sizes and shapes of tumors, as well as the intricate nature of MRI data. Mastering this segmentation process is essential for improving clinical outcomes and ensuring optimal treatment planning. In this research, we provide a UNet-based model (RR-UNet) designed specifically for brain tumor segmentation, which uses small and diverse datasets containing human-annotated ground truth segmentations. This model uses residual learning to improve segmentation results over the original UNet architecture, as shown by higher dice similarity coefficient (DSC) and Intersection over Union (IoU) scores. Residual blocks enable a deeper network, which can capture complex patterns. Residual blocks reuse features, allowing the network to learn more abstract and informative representations from input images. Through comprehensive evaluation and validation, we illustrate our method’s efficacy and generalization capabilities, emphasizing its potential for real-world clinical applications. This segmentation model predicts DSC of 98.18% and accuracy of 99.78% in tumor segmentation using Figshare LGG (Low-grade glioma) FLAIR segmentation dataset and DSC of 98.54% &amp; accuracy of 99.81% using BraTS 2020 dataset. The ablation study shows the importance of the model’s residual mechanism. Overall, the proposed approach outperforms or compares to existing most recent algorithms in brain tumor segmentation tasks.},
  archive      = {J_NCA},
  author       = {Verma, Akash and Yadav, Arun Kumar},
  doi          = {10.1007/s00521-024-10380-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22905-22921},
  shortjournal = {Neural Comput. Appl.},
  title        = {Residual learning for brain tumor segmentation: Dual residual blocks approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Egocentric activity recognition using two-stage decision
fusion. <em>NCA</em>, <em>36</em>(36), 22889–22903. (<a
href="https://doi.org/10.1007/s00521-024-10463-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of wearable devices equipped with advanced sensor technologies has fueled the rapid growth of egocentric video capture, known as First Person Vision (FPV). Unlike traditional third-person videos, FPV exhibits distinct characteristics such as significant ego-motions and frequent scene changes, rendering conventional vision-based methods ineffective. This paper introduces a novel audio-visual decision fusion framework for egocentric activity recognition (EAR) that addresses these challenges. The proposed framework employs a two-stage decision fusion pipeline with explicit weight learning, integrating both audio and visual cues to enhance overall recognition performance. Additionally, a new publicly available dataset, the Egocentric Outdoor Activity Dataset, comprising 1392 video clips featuring 30 diverse outdoor activities, is also introduced to facilitate comparative evaluations of EAR algorithms and spur further research in the field. Experimental results demonstrate that the integration of audio and visual information significantly improves activity recognition performance, outperforming single modality approaches and equally weighted decisions from multiple modalities.},
  archive      = {J_NCA},
  author       = {Arabacı, Mehmet Ali and Surer, Elif and Temizel, Alptekin},
  doi          = {10.1007/s00521-024-10463-0},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22889-22903},
  shortjournal = {Neural Comput. Appl.},
  title        = {Egocentric activity recognition using two-stage decision fusion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced prediction of agricultural CO2 emission using
ensemble machine learning-based imputation approach. <em>NCA</em>,
<em>36</em>(36), 22867–22887. (<a
href="https://doi.org/10.1007/s00521-024-10444-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agricultural sector contributes significantly to greenhouse gas emissions, which cause global warming and climate change. Numerous mathematical models have been developed to predict the greenhouse gas emissions from agriculture. However, the database utilized for prediction has thousands of missing values and imbalanced data records due to various factors, such as environmental disasters, sensor failure, maintenance issues, and budgetary constraints. Many researchers have either completely discarded records with missing values or have only partially addressed the issue, leading to less precise predictions. This study proposes a machine learning-based ensemble approach that uses multiple imputation by chained equations (MICE), K-nearest neighbors (KNN), and MissForest techniques to impute the missing values by reducing uncertainties and improves robustness in predictions. Furthermore, Synthetic Minority Oversampling Technique (SMOTE R) addresses data imbalance in CO2 emissions prediction by generating synthetic data to balance the target variable&#39;s distribution in the regression problem. Thereby the proposed SMOTE R and ensemble imputation approach aims to improve prediction accuracy and reliability by tackling data completeness and distribution issues simultaneously. The experiments are conducted on the GRACEnet database shows that the proposed approach outperforms the existing work in measure of R2, MAE, and RMSE metrics.},
  archive      = {J_NCA},
  author       = {Thendral, M. Sathya and Abinaya, S. and Devi, M. K. Kavitha},
  doi          = {10.1007/s00521-024-10444-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22867-22887},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced prediction of agricultural CO2 emission using ensemble machine learning-based imputation approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inferring preferences from demonstrations in multi-objective
reinforcement learning. <em>NCA</em>, <em>36</em>(36), 22845–22865. (<a
href="https://doi.org/10.1007/s00521-024-10412-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many decision-making problems feature multiple objectives where it is not always possible to know the preferences of a human or agent decision-maker for different objectives. However, demonstrated behaviors from the decision-maker are often available. This research proposes a dynamic weight-based preference inference (DWPI) algorithm that can infer the preferences of agents acting in multi-objective decision-making problems from demonstrations. The proposed algorithm is evaluated on three multi-objective Markov decision processes: Deep Sea Treasure, Traffic, and Item Gathering, and is compared to two existing preference inference algorithms. Empirical results demonstrate significant improvements compared to the baseline algorithms, in terms of both time efficiency and inference accuracy. The DWPI algorithm maintains its performance when inferring preferences for sub-optimal demonstrations. Moreover, the DWPI algorithm does not necessitate any interactions with the user during inference—only demonstrations are required. We provide a correctness proof and complexity analysis of the algorithm and statistically evaluate the performance under different representation of demonstrations.},
  archive      = {J_NCA},
  author       = {Lu, Junlin and Mannion, Patrick and Mason, Karl},
  doi          = {10.1007/s00521-024-10412-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22845-22865},
  shortjournal = {Neural Comput. Appl.},
  title        = {Inferring preferences from demonstrations in multi-objective reinforcement learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A benchmark for graph-based dynamic recommendation systems.
<em>NCA</em>, <em>36</em>(36), 22829–22844. (<a
href="https://doi.org/10.1007/s00521-024-10425-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge of graph neural networks has catalyzed significant advancements in recommendation systems by enabling more effective modeling of user-item interactions within undirected bipartite graphs. However, the proliferation of graph neural network architectures, coupled with the absence of standardized benchmarking frameworks, presents challenges in systematically evaluating and comparing different dynamic recommendation models. In response, we propose a comprehensive benchmarking study of bipartite graph neural network operators for recommendation systems using the PyTorch geometric library. Our contributions include the development of a flexible benchmarking framework encompassing data preprocessing, model training, and evaluation protocols, facilitating fair comparison across diverse dynamic recommendation scenarios. We rigorously assess the performance of various graph neural network models, ranging from traditional methods to state-of-the-art architectures, on the MovieLens100k dataset. Through insightful analysis of experimental results, we elucidate the strengths and weaknesses of different graph neural network operators and offer practical suggestions for model selection and configuration. Our work aims to foster transparency, reproducibility, and innovation in graph neural network-based dynamic recommendation systems, providing a valuable resource for researchers and practitioners in the field.},
  archive      = {J_NCA},
  author       = {Wallett, Tyler and Jafari, Amir},
  doi          = {10.1007/s00521-024-10425-6},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22829-22844},
  shortjournal = {Neural Comput. Appl.},
  title        = {A benchmark for graph-based dynamic recommendation systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlled time series forecasting for oil reservoir
management. <em>NCA</em>, <em>36</em>(36), 22805–22827. (<a
href="https://doi.org/10.1007/s00521-024-10424-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Management of oil reservoirs requires many high computational cost simulations for decision-making. This work aims to develop fast machine learning-based proxies based on production history data to replace the reservoir simulator. The proxy must accurately forecast reservoir responses by analyzing time series of fluid phase rates or bottom hole pressures, defined as a function of informed controls of the injector and producer wells. It is crucial to note that this is not a regular problem of forecasting the future of time series based on past trends but the prediction of reservoir response time series as a function of informed new controls. The proposed strategy is to use neural networks to learn reservoir dynamics based only on samples of production history data. Multi-head architectures based on recurrent neural networks (RNNs), convolutional neural networks (CNNs) configurations, and hybridization are considered. Parallel architectures involving separate RNNs are tested, using long short-term memory (LSTM) and CNN concatenated sub-networks. Eight different architectures are tested on two reservoir models of different sizes and heterogeneity complexities. Several training samples are generated to assess their impact on accuracy and precision. For the smaller example, the CNN architecture produced the most precise results with fewer trainable parameters. The proposed Parallel CNN-LSTM architecture is generally the most successful for the larger and more complex reservoir. In any case, the proposed techniques have been demonstrated to be very promising, with root mean square error in the order of 2.25%.},
  archive      = {J_NCA},
  author       = {de Souza, Alexandre and Tueros, Juan A. R. and Machado, Mateus G. and Santos, Rafael F. V. C. and Willmersdorf, Ramiro B. and Afonso, Silvana M. B. and Oliveira, Leonardo C. and Horowitz, Bernardo},
  doi          = {10.1007/s00521-024-10424-7},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22805-22827},
  shortjournal = {Neural Comput. Appl.},
  title        = {Controlled time series forecasting for oil reservoir management},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IDS-FRNN: An intrusion detection system with optimized
fuzziness-based sample selection technique. <em>NCA</em>,
<em>36</em>(36), 22789–22803. (<a
href="https://doi.org/10.1007/s00521-024-10333-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high intricacy rate of cyber-threats has led to the emergence of more advanced intrusion detection systems (IDSs) for identifying, detecting, and responding to potential security breaches. Over the past few years, there has been a growing trend toward utilizing machine learning (ML) models to improve the detection rate of IDSs. However, dealing with extensive or large amounts of intrusion detection (ID) data can still pose a significant challenge that may cause an IDS to experience performance degradation and the challenge of increased computational complexities (i.e., storage requirements). To alleviate this issue, this paper introduces a novel technique called IDS-FRNN which can reduce the storage space by selecting optimal and representative samples from ID dataset to enhance the effectiveness of the learning model and improve the detection rate of an IDS. IDS-FRNN initially chooses two sets of samples (i.e., representative and unrepresentative) from the data. Next, a fuzziness-based selector acquires a new group of optimized samples by using the fuzzy membership vectors outputted by a random weights neural network (RNN) from both sets of samples. The new group of samples contributes to improve the effectiveness of the IDS and achieve a trade-off between accuracy and reduction rate. The proposed technique is evaluated on three distinct attacks: Distributed Denial of Service (DDoS), DoS Hulk, and PortScan, using CIC-IDS2017 dataset. The experimental results demonstrate that IDS-FRNN significantly enhances the generalization ability of IDS, with a detection accuracy of up to 99.89% and an error rate of 0.001%. This surpasses the performance of other instance selection (IS) methods, with the ability to optimize resources and maintain high accuracy. A comprehensive comparison with existing approaches confirms IDS-FRNN’s superiority in intrusion detection and reveals valuable insights into its effectiveness.},
  archive      = {J_NCA},
  author       = {Ajmal, Saadia and Ashfaq, Rana Aamir Raza and Raza, Asad and Rauf, Abdul},
  doi          = {10.1007/s00521-024-10333-9},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22789-22803},
  shortjournal = {Neural Comput. Appl.},
  title        = {IDS-FRNN: An intrusion detection system with optimized fuzziness-based sample selection technique},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A physics-informed kernel approach to learning the operator
for parametric PDEs. <em>NCA</em>, <em>36</em>(36), 22773–22787. (<a
href="https://doi.org/10.1007/s00521-024-10460-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operator networks are neural networks designed to learn operators with special emphasis on solution operators for parameterized families of partial differential equations (PDEs). Once trained, operator networks can provide a solution to a PDE more quickly than current numerical PDE solvers by several orders of magnitude. Fourier neural operators (FNOs) and deep operator networks (DeepONets) are the two primary operator networks in existence for learning the solution operator to PDEs and have mostly only been applied to two-dimensional or three-dimensional problems, due to the computational expense of training networks in higher dimensional settings. The sole exception is a model-parallel FNO, which decomposes the function input domain space. We demonstrate a neural operator network with a physics-informed integral kernel that, once trained, is able to predict skin and ocular media’s time-dependent thermal response to incident laser radiation much more rapidly than existing numerical algorithms.},
  archive      = {J_NCA},
  author       = {Kurz, J. and Bowman, B. and Seman, M. and Oian, C. and Khan, T.},
  doi          = {10.1007/s00521-024-10460-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22773-22787},
  shortjournal = {Neural Comput. Appl.},
  title        = {A physics-informed kernel approach to learning the operator for parametric PDEs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter selection for long short-term memory networks with
multi-criteria decision-making tools: An application for g7 countries
stock market forecasting. <em>NCA</em>, <em>36</em>(36), 22731–22771.
(<a href="https://doi.org/10.1007/s00521-024-10433-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study integrates Long Short-Term Memory (LSTM) networks with Multi-Criteria Decision-Making (MCDM) methods to improve the accuracy of stock market forecasts. Drawing on a dataset from G7 stock markets spanning June 2018 to June 2023, the study aggregates fifteen performance metrics to generate a diverse parameter pool with randomly assigned values. These parameters are evaluated using decision matrices applied through the MARCOS (Measurement of Alternatives and Ranking according to Compromise Solution) and TOPSIS (Technique for Order of Preference by Similarity to Ideal Solution) methods. The models are assessed under both equal-weighted criteria and criteria weighted via the CRITIC (Criteria Importance through Intercriteria Correlation) method. Additionally, the study examines Empirical Mode Decomposition-based LSTM (EMD-LSTM) models, revealing that those optimized using the MARCOS method substantially outperform those optimized through TOPSIS, particularly in forecasting accuracy. The integration of MCDM techniques with LSTM models yields a hit rate of up to 75%, demonstrating the effectiveness of this approach in parameter selection and overall model enhancement. This study not only underscores the potential of MCDM methods in refining LSTM models but also provides a robust framework for improving predictive accuracy in financial markets.},
  archive      = {J_NCA},
  author       = {Ozcalici, Mehmet and Bumin, Mete},
  doi          = {10.1007/s00521-024-10433-6},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22731-22771},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parameter selection for long short-term memory networks with multi-criteria decision-making tools: An application for g7 countries stock market forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributed privacy preserving model for the detection of
alzheimer’s disease. <em>NCA</em>, <em>36</em>(36), 22719–22729. (<a
href="https://doi.org/10.1007/s00521-024-10419-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of rapidly advancing medical technologies, the segmentation of medical data has become inevitable, necessitating the development of privacy preserving machine learning algorithms that can train on distributed data. Consolidating sensitive medical data is not always an option particularly due to the stringent privacy regulations imposed by the Health Insurance Portability and Accountability Act. In this paper, I introduce a HIPAA compliant framework that can train from distributed data. I then propose a multimodal vertical federated model for Alzheimer’s disease detection, a serious neurodegenerative condition that can cause dementia, severely impairing brain function and hindering simple tasks, especially without preventative care. This vertical federated learning model offers a distributed architecture that enables collaborative learning across diverse sources of medical data while respecting privacy constraints imposed by HIPAA. The VFL architecture proposed herein offers a novel distributed architecture, enabling collaborative learning across diverse sources of medical data while respecting statutory privacy constraints. By leveraging multiple modalities of data, the robustness and accuracy of AD detection can be enhanced. This model not only contributes to the advancement of federated learning techniques but also holds promise for overcoming the hurdles posed by data segmentation in medical research.},
  archive      = {J_NCA},
  author       = {Mandal, Paul K.},
  doi          = {10.1007/s00521-024-10419-4},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22719-22729},
  shortjournal = {Neural Comput. Appl.},
  title        = {A distributed privacy preserving model for the detection of alzheimer’s disease},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing fairness in breast cancer recurrence prediction
through temporal machine learning models. <em>NCA</em>, <em>36</em>(36),
22697–22718. (<a
href="https://doi.org/10.1007/s00521-024-10407-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer recurrence prediction is a significant challenge in oncology. Advanced methodologies are required to improve prediction accuracy and clinical decision-making. This study presents a novel approach to breast cancer recurrence prediction by integrating machine learning techniques and a hybrid data mining methodology incorporating a temporal dimension into dataset derivation. Our research is based on the Jordan Breast Cancer Dataset (JBRCA), which includes over 44,000 cases spanning 15 years collected from the King Hussein Cancer Center’s registry database in Amman, Jordan. The proposed methodology encompasses data understanding, preparation, and model development stages. We use a thorough data preparation process involving multicollinearity feature selection, feature scaling, and strategic sampling to address dataset challenges. Moreover, we introduce a temporal-derived dataset strategy, dividing the data into four distinct time intervals to capture evolving characteristics and optimize model relevance. We employ diverse base classifiers and ensemble methods to enhance predictive performance in model development. We use evaluation metrics such as accuracy, recall, specificity, G-mean, and ROC-AUC to assess model efficacy across temporal intervals. Our experimental findings reveal significant impacts on classifier performance with temporal dataset derivation, with notable strengths observed in specific classifiers and temporal intervals. For instance, the Naive Bayes model demonstrates efficacy in identifying recurrence cases, while logistic regression exhibits robust performance in ROC-AUC and G-mean metrics. Our study contributes to breast cancer recurrence prediction by introducing a novel methodology that addresses dataset challenges and leverages temporal insights for enhanced predictive accuracy. The findings have a direct impact on clinical practice, providing valuable tools for early detection and improved therapy planning.},
  archive      = {J_NCA},
  author       = {Sundus, Katrina I. and Hammo, Bassam H. and Al-Zoubi, Mohammad B.},
  doi          = {10.1007/s00521-024-10407-8},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22697-22718},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing fairness in breast cancer recurrence prediction through temporal machine learning models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the generalization of PINNs outside the training domain
and the hyperparameters influencing it. <em>NCA</em>, <em>36</em>(36),
22677–22696. (<a
href="https://doi.org/10.1007/s00521-024-10178-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalization is a key property of machine learning models to perform accurately on unseen data. Conversely, in the field of scientific machine learning (SciML), generalization entails not only predictive accuracy but also the capacity of the model to encapsulate underlying physical principles. In this paper, we delve into the concept of generalization for Physics-informed neural networks (PINNs) by investigating the consistency of the predictions of a PINN outside of its training domain. Through the lenses of a novel metric and statistical analysis, we study the scenarios in which a PINN can provide consistent predictions outside the region considered for training and hereinafter assess whether the algorithmic setup of the model can influence its potential for generalizing. Our results highlight why overparametrization is not a crucial component in SciML while encouraging overfitting on the training data. Despite being counterintuitive, the outcome of our analysis serves as a guideline for training PINNs for engineering applications.},
  archive      = {J_NCA},
  author       = {Bonfanti, Andrea and Santana, Roberto and Ellero, Marco and Gholami, Babak},
  doi          = {10.1007/s00521-024-10178-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22677-22696},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the generalization of PINNs outside the training domain and the hyperparameters influencing it},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting tensile strength of steel fiber-reinforced
concrete based on a novel differential evolution-optimized extreme
gradient boosting machine. <em>NCA</em>, <em>36</em>(36), 22653–22676.
(<a href="https://doi.org/10.1007/s00521-024-10458-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Splitting tensile strength (fspt) is a crucial parameter in designing concrete mixes. The addition of steel fibers helps improve the mechanical properties of concrete, including its fspt. Due to the complexity and time-consuming processes required in conducting tensile tests, this study proposes a novel integration of differential evolution (DE) and an extreme gradient boosting machine (XGBoost) for estimating the fspt of concrete mixes based on their constituents, age, and compressive strength. XGBoost is used to learn the nonlinear and multivariate mapping function between the fspt and its influencing factors. In addition, DE, as a metaheuritic algorithm, is employed to automatically optimize the XGBoost performance. A dataset, including eight predictor variables and 173 records, is used to train and verify the hybrid DE-XGBoost approach. Experimental results, supported by statistical tests, show that the newly proposed method can achieve outstanding predictive accuracy with a mean absolute percentage error (MAPE) of 9.5% and a coefficient of determination (R2) of 0.9. Sensitivity analysis shows that the contents of aggregates and water critically affect the fspt. Meanwhile, the volume fraction of steel fiber, aspect ratio of steel fibers, binder quantity, and concrete age moderately influence tensile strength performance. Moreover, an asymmetric squared error loss function is used during the training phase of XGBoost to reduce the percentage of overestimated fspt values from 52 to 35% with a minor loss of predictive accuracy.},
  archive      = {J_NCA},
  author       = {Hoang, Nhat-Duc},
  doi          = {10.1007/s00521-024-10458-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22653-22676},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting tensile strength of steel fiber-reinforced concrete based on a novel differential evolution-optimized extreme gradient boosting machine},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual detection and tracking of lane violations for heavy
vehicles. <em>NCA</em>, <em>36</em>(36), 22633–22652. (<a
href="https://doi.org/10.1007/s00521-024-10429-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid progress in deep learning and high-performance computing, video-based traffic monitoring systems and analysis of CCTV camera images have witnessed significant advancements. In this paper, we present a novel and automated traffic monitoring system that harnesses the power of robust deep learning models, offering a comprehensive framework for efficient traffic surveillance. Our system introduces several innovative contributions, including a novel approach for lane identity (LaneID) determination and an integrated methodology for comprehensive traffic rule violation detection. Leveraging state-of-the-art algorithms such as HybridNets, YOLOv8, and DeepSORT, carefully selected through comprehensive comparisons, our approach focuses on detecting lane violations by heavy vehicles and considers crucial factors such as vehicle type, speed, and lane positioning to ensure accurate and reliable violation recognition. By integrating LaneIDs, vehicle speed, and orientation, our system achieves more reliable and nuanced violation detection, improving overall efficiency. Through meticulous fine-tuning and training on a custom dataset, our YOLOv8-based vehicle detection achieved a mean average precision (mAP) of 95%, while our speed estimation algorithm, leveraging a combination of pixel per metric (PPM) and frame differences, demonstrated strong performance with an mAP of 93.1%. This fine-tuned and efficient system ensures real-time monitoring, immediate feedback, and accurate lane violation detection, thereby promoting responsible driving behavior. Additionally, we employed the proposed system to detect other traffic violations, achieving an overall accuracy of 94.03%, which also benefits from geometrical information as of the orientation angle.},
  archive      = {J_NCA},
  author       = {Mutlukaya, Irem and Can Karakurt, Riza and Cetinkaya, Sevval and Bayraktar, Ertugrul},
  doi          = {10.1007/s00521-024-10429-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {36},
  pages        = {22633-22652},
  shortjournal = {Neural Comput. Appl.},
  title        = {Visual detection and tracking of lane violations for heavy vehicles},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A three-branch deep neural network for diagnosing
respiratory sounds. <em>NCA</em>, <em>36</em>(35), 22611–22631. (<a
href="https://doi.org/10.1007/s00521-024-10421-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding an accurate model is essential for classification of respiratory pathologies through extraction and fusion of respiratory sounds’ features. To handle the unlabeled data, a sequence of autoencoders are used for data augmentation. A deep neural network framework is proposed to extract three types of features: 1-Features based on the human auditory system, using Mel-frequency cepstral coefficients (MFCCs), 2-Temporal features contained in the sequence of sound signal using the long short-term memory (LSTM) network, and 3-The nonlinear and complex relationship among temporal characteristics in neighborhood regions using a two-dimensional (2D) convolutional neural network (CNN) applied to the sound sequence converted to a 2D time array. Three branches are fused through some fully connected layers. The ICBHI 2017 sound database is used in two cases of 6 and 3 pathological classes. In the case of 6-classes database, 98.72% overall accuracy, 98.46% kappa coefficient, 99.66% sensitivity, 98.70% specificity and 99.70% F1-Sscore is provided. In the case of 3-classes database, 97.18% overall accuracy, 95.77% kappa coefficient, 98.31% sensitivity, 99.16% specificity and 98.93% F1-score are achieved. In contrast to the many researchers that are applying CNN on the Mel spectrogram of the audios, CNN is applied to the 2D form of the time series to find the hidden relationship among the time instants in local regions. Moreover, fusion of these hidden features with the LSTM and MFCC features leads to an accurate multiple classification. This work proposes a new deep learning framework for fusion of three types of sound features, which leads to a significant improvement in multiple respiratory infection diagnosing.},
  archive      = {J_NCA},
  author       = {Imani, Maryam and Ghassemian, Hassan},
  doi          = {10.1007/s00521-024-10421-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22611-22631},
  shortjournal = {Neural Comput. Appl.},
  title        = {A three-branch deep neural network for diagnosing respiratory sounds},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nested object detection using mask r-CNN: Application to bee
and varroa detection. <em>NCA</em>, <em>36</em>(35), 22587–22609. (<a
href="https://doi.org/10.1007/s00521-024-10393-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address an essential problem related to object detection and image processing: detecting objects potentially nested in other ones. This problem exists particularly in the beekeeping sector: detecting varroa parasites on bees. Indeed, beekeepers must ensure the level of infestation of their apiaries by the varroa parasite which settles on the backs of bees. As far as we know, there is no yet a published approach to deal with nested object detection using only one neural network trained on two different datasets. We propose an approach that fills this gap. Therefore, we improve the accuracy and the efficiency of bee and varroa detection task. Our work is based on deep learning, more precisely Mask R-CNN neural network. Instead of segmenting detected objects (bees), we segment internal objects (varroas). We add a branch to Faster R-CNN to segment internal objects. We extract relevant features for internal object segmentation and suggest efficient method for training the neural network on two different datasets. Our experiments are based on a set of images of bee frames, containing annotated bees and varroa mites. Due to differences in occurrence rates, two different sets were created. After carrying out experiments, we ended up with a single neural network capable of detecting two nested objects without decreasing accuracy compared to two separate neural networks. Our approach, compared to traditional separate neural networks, improves varroa detection accuracy by 1.9%, reduces infestation level prediction error by 0.22%, and reduces execution time by 28% and model memory by 23%. In our approach, we extract Res4 (a layer of the ResNet neural network) features for varroa segmentation, which improves detection accuracy by 11% compared to standard FPN extraction. Thus, we suggest a new approach that detects nested objects more accurately than two separate network approaches.},
  archive      = {J_NCA},
  author       = {Kriouile, Yassine and Ancourt, Corinne and Wegrzyn-Wolska, Katarzyna and Bougueroua, Lamine},
  doi          = {10.1007/s00521-024-10393-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22587-22609},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nested object detection using mask R-CNN: Application to bee and varroa detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ViT-LSTM synergy: A multi-feature approach for speaker
identification and mask detection. <em>NCA</em>, <em>36</em>(35),
22569–22586. (<a
href="https://doi.org/10.1007/s00521-024-10389-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global health crisis caused by the COVID-19 pandemic has brought new challenges to speaker identification systems, particularly due to the acoustic alterations caused by the widespread use of face masks. Aiming to mitigate these distortions and improve the accuracy of speaker identification, this study introduces a novel two-level classification system, leveraging a unique integration of Vision Transformers (ViT) and Long Short-Term Memory (LSTM). This ViT-LSTM model was trained and tested on an extensive dataset composed of diverse speakers, both masked and unmasked, allowing a comprehensive evaluation of its capabilities. Our experimental results demonstrate remarkable improvements in speaker identification, with an accuracy score of 95.67%, significantly surpassing traditional and other deep learning-based methods. Moreover, our framework also shows considerable strength in detecting the presence of a mask, achieving an accuracy of 91.15% and outperforming existing state-of-the-art models. This study provides the first-ever benchmark for mask detection in the context of speaker identification, opening new pathways for research in this emerging area and presenting a robust solution for speaker identification in the era of face masks.},
  archive      = {J_NCA},
  author       = {Nassif, Ali Bou and Shahin, Ismail and Bader, Mohamed and Ahmed, Abdelfatah and Werghi, Naoufel},
  doi          = {10.1007/s00521-024-10389-7},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22569-22586},
  shortjournal = {Neural Comput. Appl.},
  title        = {ViT-LSTM synergy: A multi-feature approach for speaker identification and mask detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wire and arc-based additive manufacturing of 316L SS:
Predicting and optimizing process variables using BRFFNN, NSGA-GP and
TOPSIS approach. <em>NCA</em>, <em>36</em>(35), 22547–22568. (<a
href="https://doi.org/10.1007/s00521-024-10375-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wire- and arc-based additive manufacturing (WA-AM) technology is a prominent solution to produce components having large-scale dimensions in terms of elevated deposition rates, high material utilization efficiency, and cost effectiveness. Although many research works have explored the WA-AM process of 316L stainless steel, the selection of optimal input parameters for enhancing geometrical characteristics of the WA-AMed 316L stainless steel has not been addressed. In this paper, the variables—voltage (U), current (I), and traveling speed (V), were optimized to obtain the expected attributes of weld beads (WB) in the WA-AM of 316L SS. The empirical models of the width (BW), height (BH), and contact angle (CA) of WBs were developed using a BRFFNN (Bayesian regularized feed forward neural networks) model. To determine the best optimality, the non-dominated-sorting-genetic algorithm based on a grid partition (NSGA-GP) and TOPSIS (technique for order of preference by similarity-to-ideal solution) were adopted. The outcomes indicate that the developed BRFFNN models are adequate to predict the objectives (BW, BH, and CA). The optimized value of I, U, and V is 130 A, 22.0 V, and 0.30 m/min, respectively, which enable BW, BH, and CA to be improved by 22.97%, 11.24%, and 5.61%, respectively. The optimal parameters were used to successfully build a component without major defects, indicating their suitability for producing 316L SS components used in industrial applications. The outcomes have demonstrated the efficiency of the proposed optimization approach, which can also be used to predict optimal parameters of other AM and conventional manufacturing processes.},
  archive      = {J_NCA},
  author       = {Le, Van Thao and Nguyen, Trung-Thanh and Nguyen, Van Canh},
  doi          = {10.1007/s00521-024-10375-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22547-22568},
  shortjournal = {Neural Comput. Appl.},
  title        = {Wire and arc-based additive manufacturing of 316L SS: Predicting and optimizing process variables using BRFFNN, NSGA-GP and TOPSIS approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparison of complex-valued and real-valued neural networks
for protein sequence classification. <em>NCA</em>, <em>36</em>(35),
22533–22546. (<a
href="https://doi.org/10.1007/s00521-024-10368-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, tremendous progress has been made in the field of real-valued deep learning. Despite successful applications using amplitude and phase features, complex-valued deep learning methods remain an actively researched area with significant potential. This study investigates the potential of complex-valued networks in biological sequence analysis. In this context, the sequences encoded by a novel approach proposed for encoding protein sequences into complex numbers are classified by complex networks and compared with a real method available in the literature. This comparative study is carried out separately for three different sequence forms of protein sequences: DNA, codon and amino acid. Both real and complex networks achieved very high test accuracies of 90% and above. In statistical analyses using tenfold cross-validation, the complex-valued method yielded average accuracies of 88% (± 6), 84% (± 8) and 87% (± 8) for DNA, codon and amino acid sequences, respectively. The real-valued method gave mean accuracies of 91% (± 8), 88% (± 6) and 88% (± 7), respectively. According to the comparative t-test, there was no statistically significant difference between the two methods at the p = 0.05 level, but the findings highlight the potential for achieving high success in biological sequence analysis of complex networks despite their current limitations.},
  archive      = {J_NCA},
  author       = {Yakupoğlu, Abdullah and Bilgin, Ömer Cevdet},
  doi          = {10.1007/s00521-024-10368-y},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22533-22546},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparison of complex-valued and real-valued neural networks for protein sequence classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accurate segmentation of COVID-19 infected regions in lung
CT scans with deep learning. <em>NCA</em>, <em>36</em>(35), 22511–22531.
(<a href="https://doi.org/10.1007/s00521-024-10336-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread impact of coronavirus disease 2019 (COVID-19) has led to a severe health crisis and loss of life affecting billions of people. Detecting COVID-19 early on and distinguishing it from other illnesses is a major challenge in the pandemic. Computed tomography scans are vital for diagnosis, but they are difficult and slow for radiologists to interpret. So, deep learning technology is being used to speed up disease diagnosis, especially for COVID-19. This research employs a multi-scale feature extraction module that captures features at different scales to detect small and large structures in infection areas. The channel attention module enhances feature representation by focusing on informative channels. A bidirectional pyramid module is utilized to acquire fine-grained details and reduce spatial dimensions. The global dependencies and long-range contextual relationships among the images are captured through global and edge paths, resulting in clear and accurate images. Finally, the outputs from both modules are merged in the feature fusion Network to provide an accurate segmentation mask for COVID-19-related areas. The testing is conducted using the COVID-19 lung scan image dataset. Extensive trials are performed using standard metrics, and the output is compared with recently proposed approaches. The results demonstrate that this method achieves 98.6% accuracy, 96.54% precision, 97.52% sensitivity, 98.55% specificity, 98.59% kappa score, and an execution time of 3.2 s. These results suggest that this method performs better than other comparative methods and accurately identifies regions in the lungs affected by COVID-19.},
  archive      = {J_NCA},
  author       = {Lenin Marksia, U and Yesubai Rubavathi, C},
  doi          = {10.1007/s00521-024-10336-6},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22511-22531},
  shortjournal = {Neural Comput. Appl.},
  title        = {Accurate segmentation of COVID-19 infected regions in lung CT scans with deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infield disease detection in citrus plants: Integrating
semantic segmentation and dynamic deep learning object detection model
for enhanced agricultural yield. <em>NCA</em>, <em>36</em>(35),
22485–22510. (<a
href="https://doi.org/10.1007/s00521-024-10451-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous and dynamic detection of diseases from infield images of citrus plants is the primary objective of this investigation. Refraining from discarding the disease-related issues would reduce agricultural yield and production, resulting in significant crop loss and economic instability. Computer Vision offers an inexpensive and efficient solution for detecting and predicting multiple diseases from infield images of citrus plants in various stages of plant growth. This study aims to perform simultaneous detection and prediction of cankers, mites, and nutritional deficiencies from infield images of citrus plants. For this purpose, over 4914 samples are annotated that are obtained from 441 image samples collected from orchards of citrus plants. Initially, the input image is subject to preprocessing followed by segmentation of prominent leaf regions and disease prediction. Contributions investigated in this work are two-fold: a deep semantic segmentation model named Dynamic U-Net is employed to extract prominent regions of interest, and a dynamic, lightweight object detection deep learning model for predicting diseases. From experimental outcomes, the segmentation efficiency is found to be 89.07% foreground accuracy, 0.7881 of IoU, and 0.9188 of the Dice coefficient. The object detection performance is quantified using the mapped metric, resulting in 0.85, 0.71, 0.64, and 0.27 efficiency concerning plant diseases, cankers, mites, and nutritional deficiency. As per the findings, the proposed approach is an effective solution to perform automated detection and prediction from infield images of citrus plants.},
  archive      = {J_NCA},
  author       = {Rani, N. Shobha and Krishna, Arun Sri and Sunag, M. and Sangamesha, M. A. and Pushpa, B. R.},
  doi          = {10.1007/s00521-024-10451-4},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22485-22510},
  shortjournal = {Neural Comput. Appl.},
  title        = {Infield disease detection in citrus plants: Integrating semantic segmentation and dynamic deep learning object detection model for enhanced agricultural yield},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving patient’s medical history classification using a
feature construction approach based on situation awareness and granular
computing. <em>NCA</em>, <em>36</em>(35), 22461–22484. (<a
href="https://doi.org/10.1007/s00521-024-10413-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare decision support systems aid physicians in disease classification by analyzing patients’ medical histories to suggest preliminary diagnoses. As physicians largely base their analysis on anamnesis, integrating this process into an automated recommendation system can expedite decision-making and transition to relevant clinical investigations, thus enhancing efficiency in diagnosing potential pathologies. In this research, an innovative method for feature construction is introduced, drawing on the concepts of Situation Awareness and Granular Computing. The aim of this method is to enhance the performance of out-of-the-box classification algorithms used in machine learning. The approach is specifically tailored to mimic physicians’ cognitive processes when analyzing a patient’s medical history, resulting in the generation of new, information-dense features that can be used for classification tasks. By employing this strategy, a deeper comprehension of the data can be achieved, as well as a more precise categorization of anamneses in relation to possible medical conditions. To authenticate the efficacy of the proposed technique, three major disease categories, namely cardiac, gastrointestinal, and thyroid, were considered. The dataset comprised 1213 medical histories. The experimental results indicate that the study’s six classifiers attained a balanced accuracy exceeding 90%. Among these, the SVM classifier demonstrated the highest balanced accuracy at 93%. Overall, the proposed approach resulted in an average increase of 16 percentage points in balanced accuracy, representing an improvement over the traditional methods commonly employed in machine learning. This approach could be integrated into a clinical decision support system, aiding physicians in accurately identifying necessary investigations and expediting diagnosis.},
  archive      = {J_NCA},
  author       = {Lepore, Mario and Plenzich, Elvira and Tufano, Roberto and Cerulli, Raffaele and Maccioni, Raffaele},
  doi          = {10.1007/s00521-024-10413-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22461-22484},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving patient’s medical history classification using a feature construction approach based on situation awareness and granular computing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-powered GUI for prediction of axial compression capacity
in concrete-filled steel tube columns. <em>NCA</em>, <em>36</em>(35),
22429–22459. (<a
href="https://doi.org/10.1007/s00521-024-10405-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel methodology is developed for the characterization of the capacity of rectangular-shaped concrete-filled steel tubes (CFSTs). In the scientific research field, of particular interest is the behavior of long CFST columns under eccentric compressive load. These conditions promote failure mechanisms involving global member buckling. The developed methodologies are based on machine learning techniques found on artificial neural networks (ANNs). Furthermore, optimization methodologies, employing the grey wolf optimization algorithm and the firefly algorithm, have been attempted. For the training and validation of the models, a database consisting of 1,641 experimental tests collected from literature sources has been prepared, containing long and short specimens as well as specimens with or without load eccentricity. As the vast majority of the available experimental tests involve short specimens, the database has been augmented with 216 3D finite element models (FEMs), featuring increased member slenderness values. The calibration of the FEMs has been performed against experimental tests. The performance of the developed models has been measured through a number of performance indices, and compared with available code procedures. They have been found to provide significant improvements, both for short and long CFST columns, with the ANN model optimized with the firefly algorithm outperforming the others. Furthermore, a graphical user interface (GUI) has been developed which can be readily used to estimate the axial load capacity of CFST columns through the optimal ANN model. The developed GUI is made available as a supplementary material.},
  archive      = {J_NCA},
  author       = {Asteris, Panagiotis G. and Tsavdaridis, Konstantinos Daniel and Lemonis, Minas E. and Ferreira, Felipe Piana Vendramell and Le, Tien-Thinh and Gantes, Charis J. and Formisano, Antonio},
  doi          = {10.1007/s00521-024-10405-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22429-22459},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI-powered GUI for prediction of axial compression capacity in concrete-filled steel tube columns},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation of fractional order mathematical model of robots
for detection of coronavirus using levenberg–marquardt backpropagation
neural network. <em>NCA</em>, <em>36</em>(35), 22417–22428. (<a
href="https://doi.org/10.1007/s00521-024-10361-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research motive is to present more realistic results through the fractional order derivatives of the Robots mathematical system (FORMS), which is used to detect the coronavirus-positive cases. This nonlinear FORMS is useful to prevent individuals from the coronavirus and its spread. The classification of mathematical system is categorized into two dynamics, infected and Robots. The designed FORMS has never been solved before through the stochastic Levenberg–Marquardt backpropagation (LBMBP) neural networks (NNs), i.e., LBMBP-NNs. The solution of three cases of the FORMS is presented along with the statistics of 76% training, 12% authorization and 12% testing. To observe the exactness of LBMBP-NNs, a reference dataset is constructed using the Adams scheme. For the validation and capability of LBMBP-NNs, the illustrations are drawn based on the state transition values, regression measures, correlation performances and error histograms.},
  archive      = {J_NCA},
  author       = {Sabir, Zulqurnain and Ali, Mohamed R. and Sadat, R.},
  doi          = {10.1007/s00521-024-10361-5},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22417-22428},
  shortjournal = {Neural Comput. Appl.},
  title        = {Simulation of fractional order mathematical model of robots for detection of coronavirus using Levenberg–Marquardt backpropagation neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel k-nearest neighbor classifier for lung cancer
disease diagnosis. <em>NCA</em>, <em>36</em>(35), 22403–22416. (<a
href="https://doi.org/10.1007/s00521-024-10235-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the world&#39;s deadliest diseases is lung cancer. Based on a few features, machine learning techniques can help in the diagnosis of lung cancer. The performance of several classifiers: support vector machine (SVM), logistic regression (LR), Naïve Bayes (NB), random forest (RF), and K-nearest neighbor (KNN), was evaluated by the authors using the dataset available on Kaggle to create a systematic approach for the diagnosis of lung cancer disease based on readily observable signs and historical medical data without the requirement of CT scan images. The authors have proposed a novel approach for classification called Pearson correlation weighted KNN (PCWKNN), which is a modified version of KNN and uses Pearson correlation coefficient values to determine weights in a weighted KNN. The performance of the classifiers was evaluated using the hold-out validation method. SVM, LR, and RF were 96.77% accurate. NB obtained 95.16% accuracy. KNN achieved 91.93% accuracy. PCWKNN outperformed the employed classifiers and obtained an accuracy of 98.39%. Addressing the imperative for improved model generalization, the researchers utilized PCWKNN on an alternative, more extensive lung cancer dataset and subsequently broadened its application to diverse diseases, including the brain stroke dataset. The encouraging outcomes underscore PCWKNN&#39;s resilience and adaptability, suggesting its viability for real-world implementation.},
  archive      = {J_NCA},
  author       = {Sachdeva, Ravi Kumar and Bathla, Priyanka and Rani, Pooja and Lamba, Rohit and Ghantasala, G. S. Pradeep and Nassar, Ibrahim F.},
  doi          = {10.1007/s00521-024-10235-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22403-22416},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel K-nearest neighbor classifier for lung cancer disease diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). StackGridCov: A robust stacking ensemble learning-based
model integrated with GridSearchCV hyperparameter tuning technique for
mutation prediction of COVID-19 virus. <em>NCA</em>, <em>36</em>(35),
22379–22401. (<a
href="https://doi.org/10.1007/s00521-024-10428-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of the coronavirus disease 2019 (COVID-19) pandemic has caused great fear and panic around the world. In order to fight the COVID-19 virus, countries have had to develop some vaccines and drugs. Unfortunately, the effectiveness of these vaccines and drugs has diminished significantly due to the frequent mutations of the COVID-19 virus. Therefore, if future mutations on the Spike (S) protein of the COVID-19 virus can be predicted, vaccines and drugs can be developed faster and the fight against the COVID-19 virus can be easier. As in every field, artificial intelligence (AI)-based approaches also offer promising results in COVID-19 mutation prediction. However, finding the best hyperparameter value to improve the performance of each AI-based approach is quite difficult. In this study, we propose a robust StackGridCov model to predict future mutations on the COVID-19 virus. We utilize GridSearchCV hyperparameter tuning algorithm to improve the performance of the proposed StackGridCov model. Our main aim is to predict future mutations on the COVID-19 virus using the proposed StackGridCov model. In addition, to evaluate the performance of the proposed StackGridCov model, we carry out mutation prediction on the previously emerged influenza A/H1N1 HA virus dataset. The experimental results show that the proposed StackGridCov model outperforms 0.6623 accuracy, 0.6723 F1-score and 0.3273 MCC both the literature and other models. The results indicate that the proposed StackGridCov model can make a reliable contribution to predict mutations in both COVID-19 virus datasets and influenza A/H1N1 HA virus dataset.},
  archive      = {J_NCA},
  author       = {Burukanli, Mehmet and Yumuşak, Nejat},
  doi          = {10.1007/s00521-024-10428-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22379-22401},
  shortjournal = {Neural Comput. Appl.},
  title        = {StackGridCov: A robust stacking ensemble learning-based model integrated with GridSearchCV hyperparameter tuning technique for mutation prediction of COVID-19 virus},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Edge detective weights initialization on darknet-19 model
for YOLOv2-based facemask detection. <em>NCA</em>, <em>36</em>(35),
22365–22378. (<a
href="https://doi.org/10.1007/s00521-024-10427-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The object detection model based on the transfer learning approach comprises feature extraction and detection layers. YOLOv2 is among the fastest detection algorithms, which can utilize various pretrained classifier networks for feature extraction. However, reducing the number of network layers and increasing the mean average precision (mAP) together have challenges. Darknet-19-based YOLOv2 model achieved an mAP of 76.78% by having a smaller number of layers than other existing models. This work proposes modification by adding layers that help enhance feature extraction for further increasing the mAP of the model. Above that, the initial weights of the new layers can be random or deterministic, fine-tuned during training. In our work, we introduce a block of layers initialized with deterministic weights derived from several edge detection filter weights. Integrating such a block to the darknet-19-based object detection model improves the mAP to 85.94%, outperforming the other existing model in terms of mAP and number of layers.},
  archive      = {J_NCA},
  author       = {Ningthoujam, Richard and Pritamdas, Keisham and Singh, Loitongbam Surajkumar},
  doi          = {10.1007/s00521-024-10427-4},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22365-22378},
  shortjournal = {Neural Comput. Appl.},
  title        = {Edge detective weights initialization on darknet-19 model for YOLOv2-based facemask detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). End-to-end entity extraction from OCRed texts using
summarization models. <em>NCA</em>, <em>36</em>(35), 22347–22363. (<a
href="https://doi.org/10.1007/s00521-024-10422-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel methodology is introduced for extracting entities from noisy scanned documents by using end-to-end data and reformulating the entity extraction task as a text summarization problem. This approach offers two significant advantages over traditional entity extraction methods while maintaining comparable performance. First, it utilizes preexisting data to construct datasets, thereby eliminating the need for labor-intensive annotation procedures. Second, it employs multitask learning, enabling the training of a model via a single dataset. To evaluate our approach against state-of-the-art methods, we adapted three commonly used datasets, namely, Conference on Natural Language Learning (CoNLL++), few-shot named entity recognition (Few-NERD), and WikiNEuRal domain adaptation (WikiNEuRal + DA), to the format required by our methodology. We subsequently fine-tuned four sequence-to-sequence models: text-to-text transfer transformer (T5), fine-tuned language net T5 (FLAN-T5), bidirectional autoregressive transformer (BART), and pretraining with extracted gap sentences for abstractive summarization sequence-to-sequence models (PEGASUS). The results indicate that, in the absence of optical character recognition (OCR) noise, the BART model performs comparably to state-of-the-art methods. Furthermore, the performance degradation was limited to 3.49–5.23% when 39–62% of the sentences contained OCR noise. This performance is significantly superior to that of previous studies, which reported a 10–20% decrease in the F1 score with texts that had a 20% OCR error rate. Our experimental results demonstrate that a single model trained via our methodology can reliably extract entities from noisy OCRed texts, unlike existing state-of-the-art approaches, which require separate models for correcting OCR errors and extracting entities.},
  archive      = {J_NCA},
  author       = {Villa-García, Pedro A. and Alonso-Calvo, Raúl and García-Remesal, Miguel},
  doi          = {10.1007/s00521-024-10422-9},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22347-22363},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end entity extraction from OCRed texts using summarization models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated defect identification in coherent diffraction
imaging with smart continual learning. <em>NCA</em>, <em>36</em>(35),
22335–22346. (<a
href="https://doi.org/10.1007/s00521-024-10415-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray Bragg coherent diffraction imaging is a powerful technique for 3D materials characterization. However, obtaining X-ray diffraction data is difficult and computationally intensive, motivating the need for automated processing of coherent diffraction images, with the goal of minimizing the number of X-ray datasets needed. We automate a machine learning approach to identify crystalline line defects in samples from the raw coherent diffraction data, in a workflow coupling coherent diffraction data generation with training and inference of deep neural network defect classifiers. In particular, we adopt a continual learning approach, where we generate training data as needed based on the accuracy of the defect classifier instead of generating all training data a priori. Moreover, we develop a novel data generation mechanism to improve the efficiency of defect identification beyond the previously published continual learning approach. We call the improved method smart continual learning. The results show that our approach improves the accuracy of defect classifiers and reduces training data requirements by up to 98% compared with prior approaches.},
  archive      = {J_NCA},
  author       = {Yildiz, Orcun and Raghavan, Krishnan and Chan, Henry and Cherukara, Mathew J. and Balaprakash, Prasanna and Sankaranarayanan, Subramanian and Peterka, Tom},
  doi          = {10.1007/s00521-024-10415-8},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22335-22346},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated defect identification in coherent diffraction imaging with smart continual learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recommendation systems with user and item profiles based on
symbolic modal data. <em>NCA</em>, <em>36</em>(35), 22315–22333. (<a
href="https://doi.org/10.1007/s00521-024-10411-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recommendation systems are implemented using numerical or categorical data, that is, traditional data. This type of data can be a limiting factor when used to model complex concepts where there is internal variability or internal structure in the data. To overcome these limitations, symbolic data is used, where data can be represented by different types of values, such as intervals, lists, or histograms. This work introduces a single approach to constructing recommendation systems based on content or based on collaborative filtering using modal variables for users and items. In the content-based system, user profiles and item profiles are created from modal representations of their features, and a list of items is matched against a user profile. For collaborative filtering, user profiles are built, and users are grouped to form a neighborhood, products rated by users of this neighborhood are recommended based on the similarity between the neighbor and the user who will receive the recommendation. Experiments are carried out, using a movie domain dataset, to evaluate the effectiveness of the proposed approach. The outcomes suggest our ability to generate ranked lists of superior quality compared to previous methods utilizing symbolic data. Specifically, the lists created through the proposed method exhibit higher normalized discounted cumulative gain and, in qualitative terms, showcase more diverse content.},
  archive      = {J_NCA},
  author       = {Sampaio-Neto, Delmiro D. and Silva Filho, Telmo M. and Souza, Renata M. C. R.},
  doi          = {10.1007/s00521-024-10411-y},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22315-22333},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recommendation systems with user and item profiles based on symbolic modal data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Potential analysis of radiographic images to determine
infestation of rice seeds. <em>NCA</em>, <em>36</em>(35), 22301–22313.
(<a href="https://doi.org/10.1007/s00521-024-10379-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The X-ray method, together with image analysis tools, has been used to evaluate the internal structures of seeds and correlate them with the physical, physiological and sanitary quality, providing significant and accurate results. The objective of this study was to analyze radiographic images of rice seeds infested by the rice weevil Sitophilus oryzae (Linnaeus, 1763) (Coleoptera: Curculionidae). Rice seed samples from three different cultivars were infested with S. oryzae for 90 days. Next, seed samples collected at random were analyzed by X-ray testing. The radiographic images were analyzed by ImageJ® software to extract color and shape features. Scanning electron microscopy analyses were also performed. The results showed that X-ray testing was effective in detecting infestation. The gray distribution histograms revealed differences between healthy seeds and those infested by adult insects or empty seeds, confirmed by the significant differences obtained for the area and relative and integrated density variables. The study demonstrated that the analysis of radiographic images can provide quantitative information on insect infestation of rice seeds, which is useful in the evaluation of seed quality and for detecting the presence of pests in rice seeds.},
  archive      = {J_NCA},
  author       = {Briceño-Pinzón, Ivan David and de Oliveira Pires, Raquel Maria and Carvalho, Geraldo Andrade and Botelho, Flávia Barbosa Silva and Baute, Júlia Lima and Nery, Marcela Carlota},
  doi          = {10.1007/s00521-024-10379-9},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22301-22313},
  shortjournal = {Neural Comput. Appl.},
  title        = {Potential analysis of radiographic images to determine infestation of rice seeds},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AD-net: Attention-based dilated convolutional residual
network with guided decoder for robust skin lesion segmentation.
<em>NCA</em>, <em>36</em>(35), 22277–22299. (<a
href="https://doi.org/10.1007/s00521-024-10362-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer-aided diagnosis tools employed for skin cancer treatment and early diagnosis, skin lesion segmentation is important. However, achieving precise segmentation is challenging due to inherent variations in appearance, contrast, texture, and blurry lesion boundaries. This research presents a robust approach utilizing a dilated convolutional residual network, which incorporates an attention-based spatial feature enhancement block (ASFEB) and employs a guided decoder strategy. In each dilated convolutional residual block, dilated convolution is employed to broaden the receptive field with varying dilation rates. To improve the spatial feature information of the encoder, we employed an attention-based spatial feature enhancement block in the skip connections. The ASFEB in our proposed method combines feature maps obtained from average and maximum-pooling operations. These combined features are then weighted using the active outcome of global average pooling and convolution operations. Additionally, we have incorporated a guided decoder strategy, where each decoder block is optimized using an individual loss function to enhance the feature learning process in the proposed AD-Net. The proposed AD-Net presents a significant benefit by necessitating fewer model parameters compared to its peer methods. This reduction in parameters directly impacts the number of labeled data required for training, facilitating faster convergence during the training process. The effectiveness of the proposed AD-Net was evaluated using four public benchmark datasets. We conducted a Wilcoxon signed-rank test to verify the efficiency of the AD-Net. The outcomes suggest that our method surpasses other cutting-edge methods in performance, even without the implementation of data augmentation strategies.},
  archive      = {J_NCA},
  author       = {Naveed, Asim and Naqvi, Syed S. and Khan, Tariq M. and Iqbal, Shahzaib and Wani, M. Yaqoob and Khan, Haroon Ahmed},
  doi          = {10.1007/s00521-024-10362-4},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22277-22299},
  shortjournal = {Neural Comput. Appl.},
  title        = {AD-net: Attention-based dilated convolutional residual network with guided decoder for robust skin lesion segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designing dataless neural networks for kidney exchange
variants. <em>NCA</em>, <em>36</em>(35), 22265–22275. (<a
href="https://doi.org/10.1007/s00521-024-10352-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kidney transplantation is vital for treating end-stage renal disease, impacting roughly one in a thousand Europeans. The search for a suitable deceased donor often leads to prolonged and uncertain wait times, making living donor transplants a viable alternative. However, approximately 40% of living donors are incompatible with their intended recipients. Therefore, many countries have established kidney exchange programs, allowing patients with incompatible donors to participate in “swap” arrangements, exchanging donors with other patients in similar situations. Several variants of the vertex-disjoint cycle cover problem model the above problem, which deals with different aspects of kidney exchange as required. This paper discusses several specific vertex-disjoint cycle cover variants and deals with finding the exact solution. We employ the dataless neural networks framework to establish single differentiable functions for each variant. Recent research highlights the framework’s effectiveness in representing several combinatorial optimization problems. Inspired by these findings, we propose customized dataless neural networks for vertex-disjoint cycle cover variants. We derive a differentiable function for each variant and prove that the function will attain its minimum value if an exact solution is found for the corresponding problem variant. We also provide proof of the correctness of our approach.},
  archive      = {J_NCA},
  author       = {Jena, Sangram K. and Subramani, K. and Velasquez, Alvaro},
  doi          = {10.1007/s00521-024-10352-6},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22265-22275},
  shortjournal = {Neural Comput. Appl.},
  title        = {Designing dataless neural networks for kidney exchange variants},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective affective EEG-based indicators in emotion-evoking
VR environments: An evidence from machine learning. <em>NCA</em>,
<em>36</em>(35), 22245–22263. (<a
href="https://doi.org/10.1007/s00521-024-10240-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the use of electroencephalography (EEG) to characterize emotions and provides insights into the consistency between self-reported and machine learning outcomes. Thirty participants engaged in five virtual reality environments designed to elicit specific emotions, while their brain activity was recorded. The participants self-assessed their ground truth emotional state in terms of Arousal and Valence through a Self-Assessment Manikin. Gradient Boosted Decision Tree was adopted as a classification algorithm to test the EEG feasibility in the characterization of emotional states. Distinctive patterns of neural activation corresponding to different levels of Valence and Arousal emerged, and a noteworthy correspondence between the outcomes of the self-assessments and the classifier suggested that EEG-based affective indicators can be successfully applied in emotional characterization, shedding light on the possibility of using them as ground truth measurements. These findings provide compelling evidence for the validity of EEG as a tool for emotion characterization and its contribution to a better understanding of emotional activation.},
  archive      = {J_NCA},
  author       = {Castiblanco Jimenez, Ivonne Angelica and Olivetti, Elena Carlotta and Vezzetti, Enrico and Moos, Sandro and Celeghin, Alessia and Marcolin, Federica},
  doi          = {10.1007/s00521-024-10240-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22245-22263},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective affective EEG-based indicators in emotion-evoking VR environments: An evidence from machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-tuning adaptive stochastic optimizers: Determining the
optimal hyperparameter <span class="math display"><em>ϵ</em></span> via
gradient magnitude histogram analysis. <em>NCA</em>, <em>36</em>(35),
22223–22243. (<a
href="https://doi.org/10.1007/s00521-024-10302-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimizers play a crucial role in the successful training of deep neural network models. To achieve optimal model performance, designers must carefully select both model and optimizer hyperparameters. However, this process is frequently demanding in terms of computational resources and processing time. While it is a well-established practice to tune the entire set of optimizer hyperparameters for peak performance, there is still a lack of clarity regarding the individual influence of hyperparameters mislabeled as “low priority”, including the safeguard factor $$\epsilon$$ and decay rate $$\beta$$ , in leading adaptive stochastic optimizers like the Adam optimizer. In this manuscript, we introduce a new framework based on the empirical probability density function of the loss’ gradient magnitude, termed as the “gradient magnitude histogram”, for a thorough analysis of adaptive stochastic optimizers and the safeguard hyperparameter $$\epsilon$$ . This framework reveals and justifies valuable relationships and dependencies among hyperparameters in connection to optimal performance across diverse tasks, such as classification, language modeling and machine translation. Furthermore, we propose a novel algorithm using gradient magnitude histograms to automatically estimate a refined and accurate search space for the optimal safeguard hyperparameter $$\epsilon$$ , surpassing the conventional trial-and-error methodology by establishing a worst-case search space that is two times narrower.},
  archive      = {J_NCA},
  author       = {Silva, Gustavo and Rodriguez, Paul},
  doi          = {10.1007/s00521-024-10302-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22223-22243},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fine-tuning adaptive stochastic optimizers: Determining the optimal hyperparameter $$\epsilon$$ via gradient magnitude histogram analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Augmented electric eel foraging optimization algorithm for
feature selection with high-dimensional biological and medical
diagnosis. <em>NCA</em>, <em>36</em>(35), 22171–22221. (<a
href="https://doi.org/10.1007/s00521-024-10288-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the importance of the electric eel foraging optimization (EEFO) algorithm in addressing feature selection (FS) problems, with the aim of ameliorating the practical benefit of FS in real-world applications. The use of EEFO to solve FS problems props our goal of providing clean and useful datasets that provide robust effectiveness for use in classification and clustering tasks. High-dimensional feature selection problems (HFSPs) are more common nowadays yet intricate where they contain a large number of features. Hence, the vast number of features in them should be carefully selected in order to determine the optimal subset of features. As the basic EEFO algorithm experiences premature convergence, there is a need to enhance its global and local search capabilities when applied in the field of FS. In order to tackle such issues, a binary augmented EEFO (BAEEFO) algorithm was developed and proposed for HFSPs. The following strategies were integrated into the mathematical model of the original EEFO algorithm to create BAEEFO: (1) resting behavior with nonlinear coefficient; (2) weight coefficient and confidence effect in the hunting process; (3) spiral search strategy; and (4) Gaussian mutation and random perturbations when the algorithm update is stagnant. Experimental findings confirm the effectiveness of the proposed BAEEFO method on 23 HFSPs gathered from the UCI repository, recording up to a 10% accuracy increment over the basic BEEFO algorithm. In most test cases, BAEEFO outperformed its competitors in classification accuracy rates and outperformed BEEFO in 90% of the datasets used. Thereby, BAEEFO has demonstrated strong competitiveness in terms of fitness scores and classification accuracy. When compared to its competitors, BAEEFO produced superior reduction rates with the fewest number of features selected. The findings in this research underscore the critical need for FS to combat the curse of dimensionality concerns and find highly useful features in data mining applications such as classification. The use of a new meta-heuristic algorithm incorporated with efficient search strategies in solving HFSPs represents a step forward in using this algorithm to solve other practical real-world problems in a variety of domains.},
  archive      = {J_NCA},
  author       = {Al-Betar, Mohammed Azmi and Braik, Malik Sh. and Mohamed, Elfadil A. and Awadallah, Mohammed A. and Nasor, Mohamed},
  doi          = {10.1007/s00521-024-10288-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22171-22221},
  shortjournal = {Neural Comput. Appl.},
  title        = {Augmented electric eel foraging optimization algorithm for feature selection with high-dimensional biological and medical diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Amina: An arabic multi-purpose integral news articles
dataset. <em>NCA</em>, <em>36</em>(35), 22149–22169. (<a
href="https://doi.org/10.1007/s00521-024-10277-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic newspapers are one of the most common sources of Modern Standard Arabic. Existing datasets of Arabic news articles typically provide a title, body, and single label. Ignoring important features, like the article author, image, tags, and publication date, can degrade the efficacy of classification models. In this paper, we propose the Arabic multi-purpose integral news articles (AMINA) dataset. AMINA is a large-scale Arabic news corpus with over 1,850,000 articles collected from 9 Arabic newspapers from different countries. It includes all the article features: title, tags, publication date and time, location, author, article image and its caption, and the number of visits. To test the efficacy of the proposed dataset, three tasks were developed and validated: article textual content (classification and generation) and article image classification. For content classification, we experimented the performance of several state-of-the-art Arabic NLP models including AraBERT and CAMeL-BERT, etc. For content generation, the reformer architecture is adopted as a character text generation model. For image classification applied on Al-Sharq and Youm7 news portals, we have compared the performance of 10 pre-trained models including ConvNeXt, MaxViT, ResNet18, etc. The overall study verifies the significance and contribution of our newly introduced Arabic articles dataset. The AMINA dataset has been released at https://huggingface.co/datasets/MohamedZayton/AMINA .},
  archive      = {J_NCA},
  author       = {Zaytoon, Mohamed and Bashar, Muhannad and Khamis, Mohamed A. and Gomaa, Walid},
  doi          = {10.1007/s00521-024-10277-0},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22149-22169},
  shortjournal = {Neural Comput. Appl.},
  title        = {Amina: An arabic multi-purpose integral news articles dataset},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A metaheuristic algorithm based on a radial basis function
neural networks. <em>NCA</em>, <em>36</em>(35), 22119–22147. (<a
href="https://doi.org/10.1007/s00521-024-10372-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic methods are optimization techniques generally based on natural or physical phenomena. Although these processes inspire, the underlying mechanisms of these phenomena still need to be fully understood. Translating these mechanisms into algorithmic solutions may lead to unclear strategies, whose performance can exhibit unpredictable behavior. On the other hand, a radial basis function neural network (RBFNN) is a powerful method for approximating highly complex functions through a training process. Its key advantage lies in its interpretable structure, which allows us to understand the underlying relationships among the input–output data. This paper proposes a new metaheuristic algorithm based on the architecture of an RBFNN. Under this approach, an RBFNN is trained to approximate the objective function based on initial input data distributed from the search space. After training, the radial basis functions and weights associated with the neurons that maintain a strong influence or contribution to obtain the highest values of the cost function are determined. The parameters of these radial basis functions define the promissory regions of the input space that are used to produce the individuals of the new population through the Latin hypercube sampling technique. Therefore, during the optimization process, different regions of the search space represented by radial basis functions are explored and exploited as the accuracy of the cost function approximation increases. The experimental results demonstrated the success of our approach, as it outperformed the established metaheuristic algorithms on various benchmark functions.},
  archive      = {J_NCA},
  author       = {Rivera-Aguilar, Beatriz A. and Cuevas, Erik and Zaldívar, Daniel and Pérez-Cisneros, Marco A.},
  doi          = {10.1007/s00521-024-10372-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22119-22147},
  shortjournal = {Neural Comput. Appl.},
  title        = {A metaheuristic algorithm based on a radial basis function neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A monadic second-order temporal logic framework for
hypergraphs. <em>NCA</em>, <em>36</em>(35), 22081–22118. (<a
href="https://doi.org/10.1007/s00521-024-10365-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel computational framework integrating monadic second-order temporal logic (MSOTL) with hypergraph models to enhance the predictive analysis and prediction of complex systems, with a specific focus on urban agriculture. Traditional graph-based models often fail to capture the intricate, high-order temporal dynamics inherent in such systems. By leveraging the expressive power of MSOTL within a hypergraph context, our approach enables a more nuanced representation of temporal and relational data, leading to improved predictive accuracy and deeper analytical insights. The framework was applied to a comprehensive dataset of urban agricultural practices, incorporating data from diverse farming sites across multiple countries. Our results demonstrate the model’s capability to outperform existing methods in predicting agricultural outcomes by effectively capturing both the spatial and temporal complexities of urban farming data. The study not only advances the theoretical understanding of hypergraph-based temporal logic modeling but also offers an application for urban agricultural planning and management.},
  archive      = {J_NCA},
  author       = {Bhuyan, Bikram Pratim and Singh, T. P. and Tomar, Ravi and Meraihi, Yassine and Ramdane-Cherif, Amar},
  doi          = {10.1007/s00521-024-10365-1},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22081-22118},
  shortjournal = {Neural Comput. Appl.},
  title        = {A monadic second-order temporal logic framework for hypergraphs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The use of multi-task learning in cybersecurity
applications: A systematic literature review. <em>NCA</em>,
<em>36</em>(35), 22053–22079. (<a
href="https://doi.org/10.1007/s00521-024-10436-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybersecurity is crucial in today’s interconnected world, as digital technologies are increasingly used in various sectors. The risk of cyberattacks targeting financial, military, and political systems has increased due to the wide use of technology. Cybersecurity has become vital in information technology, with data protection being a major priority. Despite government and corporate efforts, cybersecurity remains a significant concern. The application of multi-task learning (MTL) in cybersecurity is a promising solution, allowing security systems to simultaneously address various tasks and adapt in real-time to emerging threats. While researchers have applied MTL techniques for different purposes, a systematic overview of the state-of-the-art on the role of MTL in cybersecurity is lacking. Therefore, we carried out a systematic literature review (SLR) on the use of MTL in cybersecurity applications and explored its potential applications and effectiveness in developing security measures. Five critical applications, such as network intrusion detection and malware detection, were identified, and several tasks used in these applications were observed. Most of the studies used supervised learning algorithms, and there were very limited studies that focused on other types of machine learning. This paper outlines various models utilized in the context of multi-task learning within cybersecurity and presents several challenges in this field.},
  archive      = {J_NCA},
  author       = {Ibrahim, Shimaa and Catal, Cagatay and Kacem, Thabet},
  doi          = {10.1007/s00521-024-10436-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22053-22079},
  shortjournal = {Neural Comput. Appl.},
  title        = {The use of multi-task learning in cybersecurity applications: A systematic literature review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the potential of YOLOv8 in hybrid models for
facial mask identification in diverse environments. <em>NCA</em>,
<em>36</em>(35), 22037–22052. (<a
href="https://doi.org/10.1007/s00521-024-10351-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of facial masks has become a global standard in response to the COVID-19 pandemic, necessitating the development of reliable detection systems to monitor adherence to health guidelines. This paper presents an facial mask detection framework that enhances the YOLOv8 algorithm and leverages the ResNet-50 architecture for improved feature extraction. Our proposed framework was rigorously evaluated against widely recognized methods, including the original YOLOv8, faster R-CNN, and SSD, across various metrics such as precision, recall, and mean average precision (mAP). The results of these comparative analyses underscore the superiority of our approach, with our framework showing significant improvements in the detection of properly worn masks. Specifically, our model achieved precision and recall rates above 97% and a mAP0.5% of 99.6%, significantly outperforming the comparison group. These advancements highlight the potential of our framework as a cornerstone for public health initiatives, providing a high-precision tool for real-time mask detection and adherence monitoring in various settings.},
  archive      = {J_NCA},
  author       = {Ferreira, Fernando Rodrigues Trindade and do Couto, Loena Marins and de Melo Baptista Domingues, Guilherme},
  doi          = {10.1007/s00521-024-10351-7},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22037-22052},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring the potential of YOLOv8 in hybrid models for facial mask identification in diverse environments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of a semi-supervised technique for identifying
unstable mine slopes. <em>NCA</em>, <em>36</em>(35), 22023–22035. (<a
href="https://doi.org/10.1007/s00521-024-10438-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to apply a semi-supervised technique to study the stability of mine slopes, aiding in the identification of those with potential failure risks. Semi-supervised techniques are valuable when not all information about the data is known. To achieve this objective, biased random key genetic algorithm was employed to solve the constrained clustering problem. The solution to this problem involves grouping slopes based on similar characteristics while adhering to specified constraints. The obtained results demonstrate the effectiveness of the proposed technique in slope grouping.},
  archive      = {J_NCA},
  author       = {Oliveira, Rudinei Martins de and Santos, Tatiana Barreto dos and Junior, Ladir Antonio da Silva},
  doi          = {10.1007/s00521-024-10438-1},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22023-22035},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of a semi-supervised technique for identifying unstable mine slopes},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Firearm detection using DETR with multiple self-coordinated
neural networks. <em>NCA</em>, <em>36</em>(35), 22013–22022. (<a
href="https://doi.org/10.1007/s00521-024-10373-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new strategy that uses multiple neural networks in conjunction with the DEtection TRansformer (DETR) network to detect firearms in surveillance images. The strategy developed in this work presents a methodology that promotes collaboration and self-coordination of networks in the fully connected layers of DETR through the technique of multiple self-coordinating artificial neural networks (MANN), which does not require a coordinator. This self-coordination consists of training the networks one after the other and integrating their outputs without an extra element called a coordinator. The results indicate that the proposed network is highly effective, achieving high-level outcomes in firearm detection. The network’s high precision of 84% and its ability to perform classifications are noteworthy.},
  archive      = {J_NCA},
  author       = {Soares, Romulo Augusto Aires and Oliveira, Alexandre Cesar Muniz de and Ribeiro, Paulo Rogerio de Almeida and Almeida Neto, Areolino de},
  doi          = {10.1007/s00521-024-10373-1},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {22013-22022},
  shortjournal = {Neural Comput. Appl.},
  title        = {Firearm detection using DETR with multiple self-coordinated neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review of vision transformers and convolutional
neural networks for alzheimer’s disease classification using 3D MRI
images. <em>NCA</em>, <em>36</em>(35), 21985–22012. (<a
href="https://doi.org/10.1007/s00521-024-10420-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a progressive neurodegenerative disorder that mainly affects memory and other cognitive functions, such as thinking, reasoning, and the ability to carry out daily activities. It is considered the most common form of dementia in older adults, but it can appear as early as the age of 25. Although the disease has no cure, treatment can be more effective if diagnosed early. In diagnosing AD, changes in the brain’s morphology are identified macroscopically, which is why deep learning models, such as convolutional neural networks (CNN) or vision transformers (ViT), excel in this task. We followed the Systematic Literature Review process, applying stages of the review protocol from it, which aims to detect the need for a review. Then, search equations were formulated and executed in several literature databases. Relevant publications were scanned and used to extract evidence to answer research questions. Several CNN and ViT approaches have already been tested on problems related to brain image analysis for disease detection. A total of 722 articles were found in the selected databases. Still, a series of filters were performed to decrease the number to 44 articles, focusing specifically on brain image analysis with CNN and ViT methods. Deep learning methods are effective for disease diagnosis, and the surge in research activity underscores its importance. However, the lack of access to repositories may introduce bias into the information. Full access demonstrates transparency and facilitates collaborative work in research.},
  archive      = {J_NCA},
  author       = {Bravo-Ortiz, Mario Alejandro and Holguin-Garcia, Sergio Alejandro and Quiñones-Arredondo, Sebastián and Mora-Rubio, Alejandro and Guevara-Navarro, Ernesto and Arteaga-Arteaga, Harold Brayan and Ruz, Gonzalo A. and Tabares-Soto, Reinel},
  doi          = {10.1007/s00521-024-10420-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {21985-22012},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review of vision transformers and convolutional neural networks for alzheimer’s disease classification using 3D MRI images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of machine learning techniques for diagnosing
alzheimer’s disease using imaging modalities. <em>NCA</em>,
<em>36</em>(35), 21957–21984. (<a
href="https://doi.org/10.1007/s00521-024-10399-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease is a progressive form of dementia. Dementia is a broad term for conditions that impair memory, thinking, and behaviour. Brain traumas or disorders can cause dementia. It is estimated that 60–80% of dementia cases around the world are caused by Alzheimer’s disease, an incurable neurodegenerative disorder. Although Alzheimer&#39;s disease research has increased in recent years, early diagnosis is challenging due to the complicated brain structure and functions associated with this disease. It is difficult for doctors to identify Alzheimer&#39;s disease in its early stages as there are still no biomarkers to be precise in early detection. In the area of medical imaging, deep learning is becoming increasingly popular and successful. There is no single best approach for the detection of Alzheimer&#39;s disease. In comparison with conventional machine learning methods, the deep learning models detect Alzheimer&#39;s disease more precisely and effectively. In this review paper, various machine learning-based techniques utilized for the classification of Alzheimer&#39;s disease through different imaging modalities are discussed. In addition, a comprehensive and detailed analysis of the various image processing procedures along with corresponding classification performance and feature extraction techniques have been meticulously compiled and presented. The investigation of computer-aided image analysis has demonstrated significant potential in the early detection of cognitive changes in individuals experiencing mild cognitive impairment. Machine learning can provide valuable insights into the cognitive status of patients, enabling healthcare professionals to intervene and provide timely treatment. This review may lead to a reliable method for recognizing and predicting Alzheimer&#39;s disease.},
  archive      = {J_NCA},
  author       = {Kishore, Nand and Goel, Neelam},
  doi          = {10.1007/s00521-024-10399-5},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {21957-21984},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of machine learning techniques for diagnosing alzheimer’s disease using imaging modalities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of multimodal-based emotion recognition techniques
for cyberbullying detection in online social media platforms.
<em>NCA</em>, <em>36</em>(35), 21923–21956. (<a
href="https://doi.org/10.1007/s00521-024-10371-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberbullying is a serious issue in online social media platforms (OSMP), which requires effective detection and intervention systems. Multimodal emotion recognition (MER) technology can help prevent cyberbullying by analyzing emotions from textual messages, vision, facial expressions, tone of voice, and physiological signals. However, existing machine learning-based MER models have limitations in accuracy and generalization. Deep learning (DL) methods have achieved remarkable successes in various tasks and have been applied to learn high-level emotional features for MER. This paper provides a systematic review of the recent research on DL-based MER for cyberbullying detection (MERCD). We first introduce the concept of cyberbullying and the general framework of MERCD, as well as the commonly used multimodal emotion datasets. Then, we overview the principles and advancements of representative DL techniques. Next, we focus on the research progress of two key steps in MERCD: emotion feature extraction from speech, vision, and text modalities; and multimodal information fusion strategies. Finally, we discuss the challenges and opportunities in designing a cyberbullying prediction model and suggest possible directions in the MERCD area for future research.},
  archive      = {J_NCA},
  author       = {Wang, Shuai and Shibghatullah, Abdul Samad and Iqbal, Thirupattur Javid and Keoy, Kay Hooi},
  doi          = {10.1007/s00521-024-10371-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {35},
  pages        = {21923-21956},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of multimodal-based emotion recognition techniques for cyberbullying detection in online social media platforms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wind speed super-resolution and validation: From ERA5 to
CERRA via diffusion models. <em>NCA</em>, <em>36</em>(34), 21899–21921.
(<a href="https://doi.org/10.1007/s00521-024-10139-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Copernicus Regional Reanalysis for Europe, CERRA, is a high-resolution regional reanalysis dataset for the European domain. In recent years, it has shown significant utility across various climate-related tasks, ranging from forecasting and climate change research to renewable energy prediction, resource management, air quality risk assessment, and the forecasting of rare events, among others. Unfortunately, the availability of CERRA is lagging 2 years behind the current date, due to constraints in acquiring the requisite external data and the intensive computational demands inherent in its generation. As a solution, this paper introduces a novel method using diffusion models to approximate CERRA downscaling in a data-driven manner, without additional informations. By leveraging the lower resolution ERA5 dataset, which provides boundary conditions for CERRA, we approach this as a super-resolution task. Focusing on wind speed around Italy, our model, trained on existing CERRA data, shows promising results, closely mirroring the original CERRA. Validation with in-situ observations further confirms the model’s accuracy in approximating ground measurements.},
  archive      = {J_NCA},
  author       = {Merizzi, Fabio and Asperti, Andrea and Colamonaco, Stefano},
  doi          = {10.1007/s00521-024-10139-9},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21899-21921},
  shortjournal = {Neural Comput. Appl.},
  title        = {Wind speed super-resolution and validation: From ERA5 to CERRA via diffusion models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PLD-det: Plant leaf disease detection in real time using an
end-to-end neural network approach based on improved YOLOv7.
<em>NCA</em>, <em>36</em>(34), 21885–21898. (<a
href="https://doi.org/10.1007/s00521-024-10409-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to maintain sustainable agriculture, it is vital to monitor plant health. Since all species of plants are prone to characteristic diseases, it necessitates regular surveillance to search for any symptoms, which is utterly challenging and time-consuming. Besides, farmers may struggle to identify the type of plant disease and its potential symptoms. Hence, the interest in research like image-based computer-aided automated plant leaf disease detection by analyzing the early symptoms has increased enormously. However, limitations in the plant leaf image database, for instance, unfitting backgrounds, blurry images, and so on, sometimes cause underprivileged feature extraction, misclassification, and overfitting issues in existing models. As a result, we have proposed a real-time plant leaf disease detection architecture incorporating proposed PLD-Det model, which is based on improved YOLOv7 with the intention of assisting farmers while reducing the issues in existing models. The architecture has been trained on the widely used PlantVillage dataset, which resulted in an accuracy of 98.53%. Furthermore, SHapley Additive exPlanations (SHAP) values have been analyzed as a unified measure of feature significance. According to the experimental findings, the proposed PLD-Det model, which is an improved YOLOv7 architecture, outperformed the original YOLOv7 model in test accuracy by approximately 4%.},
  archive      = {J_NCA},
  author       = {Mehedi, Md Humaion Kabir and Nawer, Nafisa and Ahmed, Shafi and Khan, Md Shakiful Islam and Hasib, Khan Md and Mridha, M. F. and Alam, Md. Golam Rabiul and Nguyen, Thanh Thi},
  doi          = {10.1007/s00521-024-10409-6},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21885-21898},
  shortjournal = {Neural Comput. Appl.},
  title        = {PLD-det: Plant leaf disease detection in real time using an end-to-end neural network approach based on improved YOLOv7},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging graph-based learning for credit card fraud
detection: A comparative study of classical, deep learning and
graph-based approaches. <em>NCA</em>, <em>36</em>(34), 21873–21883. (<a
href="https://doi.org/10.1007/s00521-024-10397-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card fraud results in staggering financial losses amounting to billions of dollars annually, impacting both merchants and consumers. In light of the escalating prevalence of digital crime and online fraud, it is important for organizations to implement robust and advanced technology to efficiently detect fraud and mitigate the issue. Contemporary solutions heavily rely on classical machine learning (ML) and deep learning (DL) methods to handle such tasks. While these methods have been effective in many aspects of fraud detection, they may not always be sufficient for credit card fraud detection as they aren’t adaptable to detect complex relationships when it comes to transactions. Fraudsters, for example, might set up many coordinated accounts to avoid triggering limitations on individual accounts. In the context of fraud detection, the ability of Graph Neural Networks (GNN’s) to aggregate information contained within the local neighbourhood of a transaction enables them to identify larger patterns that may be missed by just looking at a single transaction. In this research, we conduct a thorough analysis to evaluate the effectiveness of GNNs in improving fraud detection over classical ML and DL methods. We first build an heterogeneous graph architecture with the source, transaction, and destination as our nodes. Next, we leverage Relational Graph Convolutional Network (RGCN) to learn the representations of nodes in our graph and perform node classification on the transaction node. Our experimental results demonstrate that GNN’s outperform classical ML and DL methods.},
  archive      = {J_NCA},
  author       = {Harish, Sunisha and Lakhanpal, Chirag and Jafari, Amir Hossein},
  doi          = {10.1007/s00521-024-10397-7},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21873-21883},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging graph-based learning for credit card fraud detection: A comparative study of classical, deep learning and graph-based approaches},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local part attention for image stylization with text prompt.
<em>NCA</em>, <em>36</em>(34), 21859–21871. (<a
href="https://doi.org/10.1007/s00521-024-10394-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt-based portrait image style transfer aims at translating an input content image to a desired style described by text without a style image. In many practical situations, users may not only attend to the entire portrait image but also the local parts (e.g., eyes, lips, and hair). To address such applications, we propose a new framework that enables style transfer on specific regions described by a text description of the desired style. Specifically, we incorporate semantic segmentation to identify the intended area without requiring edit masks from the user while utilizing a pre-trained CLIP-based model for stylizing. Besides, we propose a text-to-patch matching loss by randomly dividing the stylized image into smaller patches to ensure the consistent quality of the result. To comprehensively evaluate the proposed method, we use several metrics, such as FID, SSIM, and PSNR on a dataset consisting of portraits from the CelebAMask-HQ dataset and style descriptions of other related works. Extensive experimental results demonstrate that our framework outperforms other state-of-the-art methods in terms of both stylization quality and inference time.},
  archive      = {J_NCA},
  author       = {Truong, Quoc-Truong and Nguyen, Vinh-Tiep and Nguyen, Lan-Phuong and Cao, Hung-Phu and Luu, Duc-Tuan},
  doi          = {10.1007/s00521-024-10394-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21859-21871},
  shortjournal = {Neural Comput. Appl.},
  title        = {Local part attention for image stylization with text prompt},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep convolutional neural networks for age and gender
estimation using an imbalanced dataset of human face images.
<em>NCA</em>, <em>36</em>(34), 21839–21858. (<a
href="https://doi.org/10.1007/s00521-024-10390-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic age and gender estimation provides an important information to analyze real-world applications such as human–machine interaction, system access, activity recognition, and consumer profile detection. While it is easy to estimate a person’s gender from human facial images, estimating their age is difficult. In such previous challenging studies, traditional convolutional neural network (CNN) methods have been used for age and gender estimation. With the development of deep convolutional neural network (DCNN) architectures, more successful results have been obtained than traditional CNN methods. In this study, two state-of-the-art DCNN models have been developed in the field of artificial intelligence (AI) to make age and gender estimation on an imbalanced dataset of human face images. Firstly, a new model called fast description network (FINet) was developed, which has a parametrically changeable structure. Secondly, the number of parameters has been reduced by using the layer reduction approach in InceptionV3 and NASNetLarge DCNN model structures, and a second model named inception Nasnet fast identify network (INFINet) was developed by concatenating these models and the FINet model as a triple. FINet and INFINet models developed for age and gender estimation were compared with many other state-of-the-art DCNN models in AI. The most successful accuracy results in terms of both age and gender were obtained with the INFINet model (age: 61.22%, gender: 80.95% in the FG-NET dataset, age: 72.00%, gender: 90.50% in the UTKFace dataset). The results obtained in age and gender estimation with the INFINet model are much more effective than other recent state-of-the-art works. In addition, the FINet model, which has a much smaller number of parameters than the compared models, showed a classification performance that can compete with state-of-the-art methods for age and gender estimation.},
  archive      = {J_NCA},
  author       = {Akgül, İsmail},
  doi          = {10.1007/s00521-024-10390-0},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21839-21858},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep convolutional neural networks for age and gender estimation using an imbalanced dataset of human face images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A knowledge-enhanced interest segment division attention
network for click-through rate prediction. <em>NCA</em>,
<em>36</em>(34), 21817–21837. (<a
href="https://doi.org/10.1007/s00521-024-10330-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction aims to estimate the probability of a user clicking on a particular item, making it one of the core tasks in various recommendation platforms. In such systems, user behavior data are crucial for capturing user interests, which has garnered significant attention from both academia and industry, leading to the development of various user behavior modeling methods. However, existing models still face unresolved issues, as they fail to capture the complex diversity of user interests at the semantic level, refine user interests effectively, and uncover users’ potential interests. To address these challenges, we propose a novel model called knowledge-enhanced Interest segment division attention network (KISDAN), which can effectively and comprehensively model user interests. Specifically, to leverage the semantic information within user behavior sequences, we employ the structure of a knowledge graph to divide user behavior sequence into multiple interest segments. To provide a comprehensive representation of user interests, we further categorize user interests into strong and weak interests. By leveraging both the knowledge graph and the item co-occurrence graph, we explore users’ potential interests from two perspectives. This methodology allows KISDAN to better understand the diversity of user interests. Finally, we extensively evaluate KISDAN on three benchmark datasets, and the experimental results consistently demonstrate that the KISDAN model outperforms state-of-the-art models across various evaluation metrics, which validates the effectiveness and superiority of KISDAN.},
  archive      = {J_NCA},
  author       = {Liu, Zhanghui and Chen, Shijie and Chen, Yuzhong and Su, Jieyang and Zhong, Jiayuan and Dong, Chen},
  doi          = {10.1007/s00521-024-10330-y},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21817-21837},
  shortjournal = {Neural Comput. Appl.},
  title        = {A knowledge-enhanced interest segment division attention network for click-through rate prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of cervical cells from the pap smear image
using the RES_DCGAN data augmentation and ResNet50V2 with self-attention
architecture. <em>NCA</em>, <em>36</em>(34), 21801–21815. (<a
href="https://doi.org/10.1007/s00521-024-10404-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is a type of cancer in which abnormal cell growth occurs on the surface lining of the cervix. In this study, we propose a novel residual deep convolutional generative adversarial network (RES_DCGAN) for data augmentation and ResNet50V2 self-attention method to classify cervical cells, to improve the generalizability and performance of the model. The proposed method involves adding residual blocks in the generator of the DCGAN to enhance data flow and generate higher-quality images. Subsequently, a self-attention mechanism is incorporated at the top of the pre-trained models to allow the model to focus more on significant features of the input data. To evaluate our approach, we utilized the Pomeranian and SIPaKMeD cervical cell imaging datasets. The results demonstrate superior performance, achieving an accuracy of 98% with Xception and 96.4% with ResNet50V2 on the Pomeranian dataset. Additionally, DenseNet121 with self-attention achieved accuracies of 92% and 95% in multiclass and binary classification, respectively, using the SIPaKMeD dataset. In conclusion, our RES_DCGAN-based data augmentation and pre-trained with self-attention model yields a promising result in the classification of cervical cancer cells.},
  archive      = {J_NCA},
  author       = {Wubineh, Betelhem Zewdu and Rusiecki, Andrzej and Halawa, Krzysztof},
  doi          = {10.1007/s00521-024-10404-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21801-21815},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of cervical cells from the pap smear image using the RES_DCGAN data augmentation and ResNet50V2 with self-attention architecture},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M2auth: A multimodal behavioral biometric authentication
using feature-level fusion. <em>NCA</em>, <em>36</em>(34), 21781–21799.
(<a href="https://doi.org/10.1007/s00521-024-10403-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional authentication methods, such as passwords and PINs, are vulnerable to multiple threats, from sophisticated hacking attempts to the inherent weaknesses of human memory. This highlights a critical need for a more secure, convenient, and user-friendly approach to authentication. This paper introduces M2auth, a novel multimodal behavioral biometric authentication framework for smartphones. M2auth leverages a combination of multiple authentication modalities, including touch gestures, keystrokes, and accelerometer data, with a focus on capturing high-quality, intervention-free data. To validate the efficacy of M2auth, we conducted a large-scale field study involving 52 participants over two months, collecting data from touch gestures, keystrokes, and smartphone sensors. The resulting dataset, comprising over 5.5 million action points, serves as a valuable resource for behavioral biometric research. Our evaluation involved two fusion scenarios, feature-level fusion and decision-level fusion, that play a pivotal role in elevating authentication performance. These fusion approaches effectively mitigate challenges associated with noise and variability in behavioral data, enhancing the robustness of the system. We found that the decision-level fusion outperforms the feature level, reaching a 99.98% authentication success rate and an EER reduced to 0.84%, highlighting the robustness of M2auth in real-world scenarios.},
  archive      = {J_NCA},
  author       = {Mahfouz, Ahmed and Mostafa, Hebatollah and Mahmoud, Tarek M. and Sharaf Eldin, Ahmed},
  doi          = {10.1007/s00521-024-10403-y},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21781-21799},
  shortjournal = {Neural Comput. Appl.},
  title        = {M2auth: A multimodal behavioral biometric authentication using feature-level fusion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Athletic signature: Predicting the next game lineup in
collegiate basketball. <em>NCA</em>, <em>36</em>(34), 21761–21780. (<a
href="https://doi.org/10.1007/s00521-024-10383-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advances in machine learning (ML) tools and techniques have enabled the non-intrusive collection and rapid analysis of massive amounts of data involving athletes in competitive collegiate sports. It has facilitated the development of services that a coach can employ in analyzing these data into actionable insights in designing training schedules and effective strategies for maximizing an athlete’s performance, while minimizing injury risk. Collegiate sports utilize data to get a competitive advantage. While game statistics are publicly available, relying on more than one form of data can help reveal a pattern. We developed a framework that considers various modalities and creates an athletic signature to predict their future performance. Our research involves the study of 42 distinct features that quantify various internal/external stressors the athletes face to characterize and estimate their athletic readiness (in the form of reactive strength index modified—RSImod) using ML algorithms. Our study, conducted over 26 weeks with 17 collegiate women’s basketball athletes, developed a framework that first performed sensitivity analysis using a hybrid approach combining the strengths of various filter-based, wrapper-based, and embedded feature importance techniques to identify the features most significantly impacting athlete readiness. These features were then categorized into four moderating variables (MVs, i.e. factors): sleep, cardiac rhythm, training strain, and travel schedule. Further, we used factor analysis to enhance interpretability and reduce computational complexity. A hybrid boosted-decision-trees-based model designed based on athlete clusters predicted future athletic readiness based on MVs with a mean squared error (MSE) of 0.0102. Partial dependence plots (PDPs) helped qualitatively learn the relationship between the moderating variables and the RSImod score. Athletic signatures, uniquely defining athlete-specific MV patterns, account for intra-individual variability, offering a better statistical basis for predicting game lineup (green/yellow/red card assignment) in combination with model predictions. SHAP (SHapley Additive exPlanations) values suggest the causative MV in order of significance for each prediction, enabling coaches to make informed decisions about training adjustments and athlete well-being, leading to performance improvement. Using the fingerprint mechanism, we created green (within 1 Standard Deviation (SD)), yellow (&gt; 1SD and &lt; 2SD), and red card (&gt; 2SD) zones for athlete readiness assessment. While, this study was conducted on D-I women’s basketball, the modalities apply to several sports, such as soccer, volleyball, football, and ice hockey. This framework allows coaches to understand their athlete dynamics from a strictly data perspective, which helps them strategize their next moves, combined with their personal experience and interactions with the team.},
  archive      = {J_NCA},
  author       = {Sharma, Srishti and Divakaran, Srikrishnan and Kaya, Tolga and Raval, Mehul},
  doi          = {10.1007/s00521-024-10383-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21761-21780},
  shortjournal = {Neural Comput. Appl.},
  title        = {Athletic signature: Predicting the next game lineup in collegiate basketball},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph network-based human movement prediction for
socially-aware robot navigation in shared workspaces. <em>NCA</em>,
<em>36</em>(34), 21743–21759. (<a
href="https://doi.org/10.1007/s00521-024-10369-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods for socially-aware robot path planning are increasingly needed as robots and humans increasingly coexist in shared industrial spaces. The practice of clearly separated zones for humans and robots in shop floors is transitioning towards spaces where both humans and robot operate, often collaboratively. To allow for safer and more efficient manufacturing operations in shared workspaces, mobile robot fleet path planning needs to predict human movement. Accounting for the spatiotemporal nature of the problem, the present work introduces a spatiotemporal graph neural network approach that uses graph convolution and gated recurrent units, together with an attention mechanism to capture the spatial and temporal dependencies in the data and predict human occupancy based on past observations. The obtained results indicate that the graph network-based approach is suitable for short-term predictions but the rising uncertainty beyond short-term would limit its applicability. Furthermore, the addition of learnable edge weights, a feature exclusive to graph neural networks, enhances the predictive capabilities of the model. Adding workspace context-specific embeddings to graph nodes has additionally been explored, bringing modest performance improvements. Further research is needed to extend the predictive capabilities beyond the range of scenarios captured through the original training, and towards establishing standardised benchmarks for testing human motion prediction in industrial environments.},
  archive      = {J_NCA},
  author       = {Dik, Casper and Emmanouilidis, Christos and Duqueroie, Bertrand},
  doi          = {10.1007/s00521-024-10369-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21743-21759},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph network-based human movement prediction for socially-aware robot navigation in shared workspaces},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Chain-of-thought prompting empowered generative user
modeling for personalized recommendation. <em>NCA</em>, <em>36</em>(34),
21723–21742. (<a
href="https://doi.org/10.1007/s00521-024-10364-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation plays a crucial role in Internet platforms, providing users with tailored content based on their user models and enhancing user satisfaction and experience. To address the challenge of information overload, it is essential to analyze user needs comprehensively, considering historical behavior and interests and the user&#39;s intentions and profiles. Previous user modeling approaches for personalized recommendations have exhibited certain limitations, relying primarily on historical behavior data to infer user preferences, which results in challenges such as the cold-start problem, incomplete modeling, and limited explanation. Motivated by recent advancements in large language models (LLMs), we present a novel approach to user modeling by embracing generative user modeling using LLMs. We propose generative user modeling with chain-of-thought prompting for personalized recommendation, which utilizes LLMs to generate comprehensive and accurate user models expressed in natural language and then employs these user models to empower LLMs for personalized recommendation. Specifically, we adopt the chain-of-thought prompting method to reason about user attributes, subjective preferences, and intentions, integrating them into a holistic user model. Subsequently, we utilize the generated user models as input to LLMs and design a collection of prompts to align the LLMs with various recommendation tasks, encompassing rating prediction, sequential recommendation, direct recommendation, and explanation generation. Extensive experiments conducted on real-world datasets demonstrate the immense potential of large language models in generating natural language user models, and the adoption of generative user modeling significantly enhances the performance of LLMs across the four recommendation tasks. Our code and dataset can be found at https://github.com/kwyyangfan/GUMRec .},
  archive      = {J_NCA},
  author       = {Yang, Fan and Yue, Yong and Li, Gangmin and Payne, Terry R. and Man, Ka Lok},
  doi          = {10.1007/s00521-024-10364-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21723-21742},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chain-of-thought prompting empowered generative user modeling for personalized recommendation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing island sequencing in laser powder bed fusion
using genetic algorithms. <em>NCA</em>, <em>36</em>(34), 21703–21721.
(<a href="https://doi.org/10.1007/s00521-024-10332-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing, particularly laser powder bed fusion (L-PBF), is an emerging method for fabricating complex parts in various industries. However, it faces the persistent challenge of thermal deformation, a significant barrier to its wider application and reliability. Current strategies, while partially effective, do not fully address the intricate thermal dynamics of the process, indicating a clear research gap in optimizing manufacturing techniques for better thermal management. This study focuses on understanding and mitigating thermal deformation in L-PBF using Genetic Algorithms (GAs). The application of GAs as a ‘black-box’ approach is explored to gain insights into the complex physics of L-PBF. A comprehensive investigation into the optimization of island sequencing within L-PBF processes is presented, employing GAs to systematically reduce thermal deformation. Various island sequences in a bilayered block structure are analyzed to assess the effectiveness of GAs in minimizing deformation, including scenarios such as variations in block sizes and interlayer rotation angles. Statistical tools such as silhouette scores and probability density distribution plots are utilized to provide a thorough analysis of deformation patterns and their respective thermal behaviors. The results show GA&#39;s remarkable efficiency in enhancing thermal management, achieving a significant reduction in thermal deformation within a range of 12–15% across the examined scenarios. This achievement highlights GA&#39;s capability in rapid optimization of scan sequences for better thermal deformation control. The findings enhance the understanding of thermal dynamics in L-PBF and consequently open new avenues for improving the quality and reliability of other metal additive manufacturing processes as well.},
  archive      = {J_NCA},
  author       = {Ball, Amit Kumar and Raut, Riddhiman and Basak, Amrita},
  doi          = {10.1007/s00521-024-10332-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21703-21721},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing island sequencing in laser powder bed fusion using genetic algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing connectivity and coverage in wireless sensor
networks: A hybrid comprehensive learning-fick’s algorithm with particle
swarm optimization for router node placement. <em>NCA</em>,
<em>36</em>(34), 21671–21702. (<a
href="https://doi.org/10.1007/s00521-024-10315-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) are essential for collecting and transmitting data in modern applications that rely on data, where effective network connectivity and coverage are crucial. The optimal placement of router nodes within WSNs is a fundamental challenge that significantly impacts network performance and reliability. Researchers have explored various approaches using metaheuristic algorithms to address these challenges and optimize WSN performance. This paper introduces a new hybrid algorithm, CFL-PSO, based on combining an enhanced Fick’s Law algorithm with comprehensive learning and Particle Swarm Optimization (PSO). CFL-PSO exploits the strengths of these techniques to strike a balance between network connectivity and coverage, ultimately enhancing the overall performance of WSNs. We evaluate the performance of CFL-PSO by benchmarking it against nine established algorithms, including the conventional Fick’s law algorithm (FLA), Sine Cosine Algorithm (SCA), Multi-Verse Optimizer (MVO), Salp Swarm Optimization (SSO), War Strategy Optimization (WSO), Harris Hawk Optimization (HHO), African Vultures Optimization Algorithm (AVOA), Capuchin Search Algorithm (CapSA), Tunicate Swarm Algorithm (TSA), and PSO. The algorithm’s performance is extensively evaluated using 23 benchmark functions to assess its effectiveness in handling various optimization scenarios. Additionally, its performance on WSN router node placement is compared against the other methods, demonstrating its competitiveness in achieving optimal solutions. These analyses reveal that CFL-PSO outperforms the other algorithms in terms of network connectivity, client coverage, and convergence speed. To further validate CFL-PSO’s effectiveness, experimental studies were conducted using different numbers of clients, routers, deployment areas, and transmission ranges. The findings affirm the effectiveness of CFL-PSO as it consistently delivers favorable optimization results when compared to existing methods, highlighting its potential for enhancing WMN performance. Specifically, CFL-PSO achieves up to a 66.5% improvement in network connectivity, a 16.56% improvement in coverage, and a 21.4% improvement in the objective function value when compared to the standard FLA.},
  archive      = {J_NCA},
  author       = {Amer, Dina A. and Soliman, Sarah A. and Hassan, Asmaa F. and Zamel, Amr A.},
  doi          = {10.1007/s00521-024-10315-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21671-21702},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing connectivity and coverage in wireless sensor networks: A hybrid comprehensive learning-fick’s algorithm with particle swarm optimization for router node placement},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Some new types induced complex intuitionistic fuzzy einstein
geometric aggregation operators and their application to decision-making
problem. <em>NCA</em>, <em>36</em>(34), 21647–21669. (<a
href="https://doi.org/10.1007/s00521-024-10214-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this research is to develop some novel operational laws based of T-norm and T-conorm and then using these operational laws to develop several Einstein operators for aggregating the different complex intuitionistic fuzzy numbers (CIFNs) by considering the dependency between the pairs of its membership degrees. In the existing studies of fuzzy and its extensions, the uncertainties present in the data are handled with the help of degrees of membership that are the subset of real numbers, which may also loss some valuable data and hence consequently affect the decision results. A modification to these, complex intuitionistic fuzzy set handles the uncertainties with the degree whose ranges are extended from real subset to the complex subset with unit disk and hence handle the two-dimensional information in a single set. Thus, motivated by this and this paper we present some novel methods such as complex intuitionistic fuzzy Einstein weighted geometric aggregation (CIFEWGA) operator, complex intuitionistic fuzzy Einstein ordered weighted geometric aggregation (CIFEOWGA) operator, complex intuitionistic fuzzy Einstein hybrid geometric aggregation (CIFEHGA) operator, induced complex intuitionistic fuzzy Einstein ordered weighted geometric aggregation (I-CIFEOWGA) operator and induced complex intuitionistic fuzzy Einstein hybrid geometric aggregation (I-CIFEHGA) operator. We present some of their desirable properties such as idempotency, boundedness and monotonicity. Furthermore, based on these methods a multi-attribute group decision-making problem developed under complex intuitionistic fuzzy set environment. An illustrative example related to the selection of the best alternative is considered to show the effectiveness, importance and efficiency of the novel approach.},
  archive      = {J_NCA},
  author       = {Rahman, Khaista},
  doi          = {10.1007/s00521-024-10214-1},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21647-21669},
  shortjournal = {Neural Comput. Appl.},
  title        = {Some new types induced complex intuitionistic fuzzy einstein geometric aggregation operators and their application to decision-making problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI for industrial: Automate the network design for 5G URLLC
services. <em>NCA</em>, <em>36</em>(34), 21623–21645. (<a
href="https://doi.org/10.1007/s00521-024-10321-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fifth generation (5G) mobile networks enable ultra-reliable low-latency communication (URLLC) applications, ushering in an era of endless possibilities for 5G. URLLC supports emerging 5G services and applications with stringent requirements for latency and reliability. Factory automation (FA) is a URLLC application that automates and optimizes workflows and processes in factories. To accommodate diversified FA services, 5G networks employ the “network slicing” technique, which divides the network into slices tailored to different service requirements. Designing a sliced network and translating diversified service-level agreements (SLAs) into network attributes necessitates advanced automation techniques to enhance human–machine collaboration, increase efficiency, minimize manual errors, reduce operating costs, and, most importantly, provide adequate service quality economically and reliably. To apply autonomic computing to FA network design, new architectures and software components have been envisioned. These include information extraction, domain knowledge representation, rule-based reasoning, performance model calculation, and querying using simulators and neural networks (NNs), among others. This paper proposes an innovative approach to network slicing design using advanced automation methods. This approach can be easily extended to include new services or to integrate cutting-edge 5G techniques.},
  archive      = {J_NCA},
  author       = {Wang, Jiao and Weitzen, Jay and Bayat, Oguz and Sevindik, Volkan},
  doi          = {10.1007/s00521-024-10321-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21623-21645},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI for industrial: Automate the network design for 5G URLLC services},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable AI model for PDFMal detection based on gradient
boosting model. <em>NCA</em>, <em>36</em>(34), 21607–21622. (<a
href="https://doi.org/10.1007/s00521-024-10314-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Portable document formats (PDFs) are widely used for document exchange due to their widespread usage and versatility. However, PDFs are highly vulnerable to malware attacks, which pose significant security risks. Existing defense mechanisms often struggle to effectively detect and mitigate these threats, highlighting the need for more robust solutions. This paper introduces a robust framework that uses advanced tree-based ensemble models to detect malicious PDFs using the Evasive-PDFMal2022 dataset. The proposed model achieves a recall rate of 100%, an accuracy rate of 99.95%, and a fast inference time of 0.1723 s. Furthermore, the framework exhibits minimal false positive and false negative rates, ensuring a high level of precision in distinguishing between malicious and benign PDFs. Shapley additive explanations are used to improve the interpretability and reliability of the model’s predictions. The results highlight the effectiveness of the proposed model in improving PDF document security and addressing the challenges posed by malware attacks.},
  archive      = {J_NCA},
  author       = {Elattar, Mona and Younes, Ahmed and Gad, Ibrahim and Elkabani, Islam},
  doi          = {10.1007/s00521-024-10314-y},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21607-21622},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable AI model for PDFMal detection based on gradient boosting model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-modal approach for mixed-frequency time series
forecasting. <em>NCA</em>, <em>36</em>(34), 21581–21605. (<a
href="https://doi.org/10.1007/s00521-024-10305-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel multimodal approach for mixed-frequency time series forecasting in the oil industry, enabling the use of high-frequency (HF) data in their original frequency. We specifically address the challenge of integrating HF data streams, such as pressure and temperature measurements, with daily time series without introducing noise. Our approach was compared with existing econometric regression model mixed-data sampling (MIDAS) and with the data-driven models N-HiTS and a GRU-based network, across short-, medium-, and long-term prediction horizons. Additionally, we validated the proposed method on datasets from other domains beyond the oil industry. The experimental results indicate that our multimodal approach significantly improves long-term prediction accuracy.},
  archive      = {J_NCA},
  author       = {Filho, Leopoldo Lusquino and de Oliveira Werneck, Rafael and Castro, Manuel and Ribeiro Mendes Júnior, Pedro and Lustosa, Augusto and Zampieri, Marcelo and Linares, Oscar and Moura, Renato and Morais, Elayne and Amaral, Murilo and Salavati, Soroor and Loomba, Ashish and Esmin, Ahmed and Gonçalves, Maiara and Schiozer, Denis José and Ferreira, Alexandre and Davólio, Alessandra and Rocha, Anderson},
  doi          = {10.1007/s00521-024-10305-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21581-21605},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-modal approach for mixed-frequency time series forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anomaly detection in multifactor data. <em>NCA</em>,
<em>36</em>(34), 21561–21580. (<a
href="https://doi.org/10.1007/s00521-024-10291-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In anomaly detection applications, anomalies might come from multiple sources and there might be many reasons why a sample is considered to be anomalous. However, most novel anomaly detection methods do not consider this. In our work, we describe a novel approach that is demonstrated on the problem of detection of anomalies in image data. We propose the SGVAEGAN model, which decomposes the image into three independent components—the shape of an object and its foreground and background textures—and provides anomaly scores for each of those factors separately. The overall anomaly score of an image is a weighted combination of the individual factor scores. The anomaly scores are learned in an unsupervised manner, and the weights are considered as hyperparameters that can be learned in the validation stage. The approach allows the identification of the source of the anomaly using factor scores, as well as the detection of semantic anomalies where the semantic meaning is encoded in the weights and learned from very few samples of validation anomalies. On classical anomaly detection benchmarks, the proposed model outperforms all baseline models. This is shown in a rigorous experimental study that covers the behavior of the model under a varying range of conditions.},
  archive      = {J_NCA},
  author       = {Škvára, Vít and Šmídl, Václav and Pevný, Tomáš},
  doi          = {10.1007/s00521-024-10291-2},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21561-21580},
  shortjournal = {Neural Comput. Appl.},
  title        = {Anomaly detection in multifactor data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A decision-making model for self-driving vehicles based on
GPT-4V, federated reinforcement learning, and blockchain. <em>NCA</em>,
<em>36</em>(34), 21545–21560. (<a
href="https://doi.org/10.1007/s00521-024-10161-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making is crucial in fully autonomous vehicle operations and is expected to greatly influence future transportation systems. Observing the current driving status of autonomous vehicles is vital for its decision-making process. The autonomous connected vehicles on the road send significant data about their movements to the server to maintain continuous training. With the Proof of Authority (PoA) consensus process, blockchain technology provides a valid, decentralised and secure option to improve transactions throughput and minimise delay. The limited computational capacity of vehicles poses a challenge in achieving high accuracy and low latency while training self-driving algorithms. GPT-4V surpassed challenging autonomous systems in scene interpretation and causal thinking. GPT-4V has ability to navigate circumstances without access to database, interpret intentions, and make sound decisions in real-world driving scenarios. The reward function and different driving conditions are organised to allow an optimal search to find the most efficient driving style while ensuring safety. The consequences of the Blockchain-enabled decision-making model (DMM) for Self-Driving Vehicles (SDV) primarily based on GPT-4V and Federated Reinforcement Learning (FRL) would, likely, upgrades in decision-making accuracy, operational performance, statistics integrity, and potentially enhanced learning skills in SDV. Integrating blockchain technology, superior language modelling GPT-4V and FRL may lead to multiplied safety, reliability, and decision-making ability in SDV. This study utilised the Simulation of Urban MObility (SUMO) simulator to assess the ability of SDV to maintain its desired speed consistently and securely in a highway setting using proposed DMM. This study indicates that the suggested DMM, utilising the driving state evaluation approach for SDV, can help these vehicles operate safely and effectively. The performance of the proposed model, such as CPU utilisation, bandwidth and latency, are evaluated through multiple tests.},
  archive      = {J_NCA},
  author       = {Alam, Tanweer and Gupta, Ruchi and Ahamed, N. Nasurudeen and Ullah, Arif},
  doi          = {10.1007/s00521-024-10161-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21545-21560},
  shortjournal = {Neural Comput. Appl.},
  title        = {A decision-making model for self-driving vehicles based on GPT-4V, federated reinforcement learning, and blockchain},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optihybrid: A modified firebug swarm optimization algorithm
for optimal sizing of hybrid renewable power system. <em>NCA</em>,
<em>36</em>(34), 21517–21543. (<a
href="https://doi.org/10.1007/s00521-024-10196-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In areas where conventional energy sources are unavailable, alternative energy technologies play a crucial role in generating electricity. These technologies offer various benefits, such as reliable energy supply, environmental sustainability, and employment opportunities in rural regions. This study focuses on the development of a novel optimization algorithm called the modified firebug swarm algorithm (mFSO). Its objective is to determine the optimal size of an integrated renewable power system for supplying electricity to a specific remote site in Dehiba town, located in the eastern province of Tataouine, Tunisia. The proposed configuration for the standalone hybrid system involves PV/biomass/battery, and three objective functions are considered: minimizing the total energy cost (COE), reducing the loss of power supply probability (LPSP), and managing excess energy (EXC). The effectiveness of the modified algorithm is evaluated using various tests, including the Wilcoxon test, boxplot analysis, and the ten benchmark functions of the CEC2020 benchmark. Comparative analysis between the mFSO and widely used algorithms like the original Firebug Swarm Optimization (FSO), Slime Mold Algorithm (SMA), and Seagull Optimization Algorithm (SOA) demonstrates that the proposed mFSO technique is efficient and effective in solving the design problem, surpassing other optimization algorithms.},
  archive      = {J_NCA},
  author       = {Abd El-Sattar, Hoda and Kamel, Salah and Hashim, Fatma A. and Sabbeh, Sahar F.},
  doi          = {10.1007/s00521-024-10196-0},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21517-21543},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optihybrid: A modified firebug swarm optimization algorithm for optimal sizing of hybrid renewable power system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient fake account identification in social media
networks: Facebook and instagram using NSGA-II algorithm. <em>NCA</em>,
<em>36</em>(34), 21487–21515. (<a
href="https://doi.org/10.1007/s00521-024-10350-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of online social networks (OSNs) has made them prime targets for cyber attackers, who exploit these platforms for various malicious activities. As a result, a whole industry of black-market services has emerged, selling services based on the sale of fake accounts. Because of the massive rise of OSNs, the number of fraudulent accounts rapidly expands. Hence, this research focuses on detecting fraudulent profiles on Instagram and Facebook and aims to find an optimal subset of features that can effectively differentiate between real and fake accounts. The problem has been formulated as a multiobjective optimization task, aiming to maximize the classification accuracy while minimizing the number of selected features. NSGA-II (non-dominated sorting genetic algorithm II) is employed as the optimization algorithm to explore the trade-offs between these conflicting objectives. In the current study, a novel approach for feature selection using the NSGA-II optimization algorithm to detect fake accounts is proposed. The proposed methodology relies on input data comprising features characterizing the profiles under investigation. The selected features are utilized to train a machine learning model. The model’s performance is evaluated using various metrics, including precision, recall, F1-score, and receiver operating characteristic (ROC) curve. The final prediction model achieved accuracy values ranging from 90 to 99.88%. The results indicated that the model, utilizing features selected by the NSGA-II algorithm, delivered high prediction accuracy while using less than 31% of the total feature space. This efficient feature selection allowed for the precise differentiation between fake and real users, demonstrating the model’s effectiveness with a minimal number of input variables. Furthermore, the results of experiments demonstrate that the proposed approach achieves better performance as compared to other existing approaches. This research paper focuses on explainability, which refers to the ability to understand and interpret the decisions and outcomes of machine learning models.},
  archive      = {J_NCA},
  author       = {Sallah, Amine and Abdellaoui Alaoui, El Arbi and Hessane, Abdelaaziz and Agoujil, Said and Nayyar, Anand},
  doi          = {10.1007/s00521-024-10350-8},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21487-21515},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient fake account identification in social media networks: Facebook and instagram using NSGA-II algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IRAM–NET model: Image residual agnostics meta-learning-based
network for rare de novo glioblastoma diagnosis. <em>NCA</em>,
<em>36</em>(34), 21465–21485. (<a
href="https://doi.org/10.1007/s00521-024-10347-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, neuroimaging and deep learning have received notable scientific attention for the diagnosis of grade IV tumor de novo glioblastoma in the central nervous system. However, the scarce amount of neuroimaging data for training has resulted in significant overfitting issues for numerous deep learning models. To address these challenges, we propose the implementation of a meta-learning-based IRAM–NET model that utilizes the ResNet-50 as a deep learning-based model and incorporates the e-MAML ensemble technique from meta-learning for the early diagnosis of glioblastoma. The methodology developed was trained and validated using brain MRI images taken from numerous national and international cancer initiative data repositories. In the training phase, this study employed detailed procedures, including the handling of exceptions and the application of normalization techniques. These measures were implemented to guarantee precise data representation, mitigate the risk of overfitting, and enhance the proposed model’s capacity for making meaningful generalizations. The proposed IRAM–NET model surpasses the most recent studies in accurately predicting glioblastoma diagnosis, achieving a training, testing and validation accuracy of 97.22%, 96.10%, and 94.74%, respectively. Overall, the research not only enhances the diagnosis of rare disorders like glioblastoma, but also promotes the wider inclusion of meta-learning in healthcare. This underlines the importance of adaptation and efficiency in situations with limited data availability.},
  archive      = {J_NCA},
  author       = {Singh, Kuljeet and Malhotra, Deepti},
  doi          = {10.1007/s00521-024-10347-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21465-21485},
  shortjournal = {Neural Comput. Appl.},
  title        = {IRAM–NET model: Image residual agnostics meta-learning-based network for rare de novo glioblastoma diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dementia diagnosis in young adults: A machine learning and
optimization approach. <em>NCA</em>, <em>36</em>(34), 21451–21464. (<a
href="https://doi.org/10.1007/s00521-024-10317-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals who are younger and have dementia often start experiencing its symptoms before they turn 65, with cases even documented in people as young as their thirties. Researchers strive for accurate dementia diagnosis to slow or halt its progression. This paper presents a novel Enhanced Dementia Detection and Classification Model (EDCM) comprised of four modules: data acquisition, preprocessing, hyperparameter optimization, and feature extraction/classification. Notably, the model uses texture information from segmented brain images for improved feature extraction, leading to significant gains in both binary and multi-class classification. This is achieved by selecting optimal features via a Gray Wolf Optimization (GWO)-driven enhancement model. Results demonstrate substantial accuracy improvements after optimization. For instance, using an Extra Tree Classifier for &quot;normal&quot; cases, the model achieves 85% accuracy before optimization. However, with GWO-optimized features and hyperparameters, the accuracy jumps to 97%.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and Ibraheem, Mai Ramadan},
  doi          = {10.1007/s00521-024-10317-9},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21451-21464},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dementia diagnosis in young adults: A machine learning and optimization approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid two-level protection system for preserving
pre-trained DNN models ownership. <em>NCA</em>, <em>36</em>(34),
21415–21449. (<a
href="https://doi.org/10.1007/s00521-024-10304-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep neural networks (DNNs) have made them indispensable for numerous commercial applications. These include healthcare systems and self-driving cars. Training DNN models typically demands substantial time, vast datasets and high computational costs. However, these valuable models face significant risks. Attackers can steal and sell pre-trained DNN models for profit. Unauthorised sharing of these models poses a serious threat. Once sold, they can be easily copied and redistributed. Therefore, a well-built pre-trained DNN model is a valuable asset that requires protection. This paper introduces a robust hybrid two-level protection system for safeguarding the ownership of pre-trained DNN models. The first-level employs zero-bit watermarking. The second-level incorporates an adversarial attack as a watermark by using a perturbation technique to embed the watermark. The robustness of the proposed system is evaluated against seven types of attacks. These are Fast Gradient Method Attack, Auto Projected Gradient Descent Attack, Auto Conjugate Gradient Attack, Basic Iterative Method Attack, Momentum Iterative Method Attack, Square Attack and Auto Attack. The proposed two-level protection system withstands all seven attack types. It maintains accuracy and surpasses current state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Fkirin, Alaa and Moursi, Ahmed Samy and Attiya, Gamal and El-Sayed, Ayman and Shouman, Marwa A.},
  doi          = {10.1007/s00521-024-10304-0},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21415-21449},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid two-level protection system for preserving pre-trained DNN models ownership},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Skin cancer detection with MobileNet-based transfer learning
and MixNets for enhanced diagnosis. <em>NCA</em>, <em>36</em>(34),
21383–21413. (<a
href="https://doi.org/10.1007/s00521-024-10227-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer poses a significant health hazard, necessitating the utilization of advanced diagnostic methodologies to facilitate timely detection, owing to its escalating prevalence in recent years. This paper proposes a novel approach to tackle the issue by introducing a method for detecting skin cancer that uses MixNets to enhance diagnosis and leverages mobile network-based transfer learning. Skin cancer has diverse forms, each distinguishable by its structural attributes, morphological characteristics, texture, and coloration. The pressing demand for accurate and efficient diagnostic instruments has spurred the investigation of novel techniques. The present study utilizes the ISIC dataset, comprising a validation set of 660 images and a training set of 2637 images. Moreover, the research employs a combination of MixNets and mobile network-based transfer learning as its chosen approach. Transfer learning is a technique that leverages preexisting models to enhance the diagnostic capabilities of the proposed system. Integrating MobileNet and MixNets allows for utilizing their respective functionalities, resulting in a dual-model methodology that enhances the comprehensiveness of skin cancer diagnosis. The results demonstrate impressive performance metrics, with MobileNet and MixNets models, and the proposed approach achieves an outstanding accuracy rate of 99.58%. The above findings underscore the efficacy of the dual-model method in effectively discerning between benign and malignant skin lesions. Moreover, the present study aims to examine the potential integration of emerging technologies to enhance the accuracy and practicality of diagnostics within real-world healthcare settings.},
  archive      = {J_NCA},
  author       = {Zakariah, Mohammed and Al-Razgan, Muna and Alfakih, Taha},
  doi          = {10.1007/s00521-024-10227-w},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21383-21413},
  shortjournal = {Neural Comput. Appl.},
  title        = {Skin cancer detection with MobileNet-based transfer learning and MixNets for enhanced diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aspect-based sentiment analysis in urdu language: Resource
creation and evaluation. <em>NCA</em>, <em>36</em>(34), 21365–21381. (<a
href="https://doi.org/10.1007/s00521-024-10145-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement in web interactions and increased use of Online Social Networks, sentiment analysis has gained popularity. Topics like sports, health, music, and technology are widely debated on in OSN, especially on twitter. People share their activities, views, and feelings toward different events in their native languages that can be analyzed using sentiment analysis to understand the sentiments of the people toward these events. For English language, studies on sentiment analysis are vastly available. However, very little work exists on sentiment analysis for resource-scarce language like Urdu. For this study, we perform aspect-based sentiment analysis on sports tweets in Urdu language by extracting the following information from a sentence, i.e., aspect terms, aspect term polarity, aspect category, and aspect category polarity, using machine learning and deep learning classifiers. This work is the first effort in aspect-based sentiment analysis for Urdu language using classical machine learning and deep learning approach. Additionally, we also identify implicit aspects from a sentence. Our proposed approach shows classical machine learning approach performed better on the tasks of aspect term polarity, aspect category, and aspect category polarity, while deep learning model outperformed classical machine learning classifiers for the task of aspect term/s.},
  archive      = {J_NCA},
  author       = {Altaf, Amna and Anwar, Muhammad Waqas and Jamal, Muhammad Hasan and Bajwa, Usama Ijaz and Rani, Sadaf},
  doi          = {10.1007/s00521-024-10145-x},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21365-21381},
  shortjournal = {Neural Comput. Appl.},
  title        = {Aspect-based sentiment analysis in urdu language: Resource creation and evaluation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel hyper-heuristic algorithm: An application to
automatic voltage regulator. <em>NCA</em>, <em>36</em>(34), 21321–21364.
(<a href="https://doi.org/10.1007/s00521-024-10313-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel optimization algorithm called hyper-heuristic fitness-distance balance success-history-based adaptive differential evolution (HH-FDB-SHADE). The hyper-heuristic algorithms have two main structures: a hyper-selection framework and a low-level heuristic (LLH) pool. In the proposed algorithm, the FDB method is preferred as a high-level selection framework to evaluate the LLH pool algorithms. In addition, a total of 10 different strategies is derived from five mutation operators and two crossover methods for using them as the LLH pool. Balancing the exploration and exploitation capability of FDB is the main reason for being the selection framework of the proposed algorithm. The success of the HH-FDB-SHADE algorithm was tested on CEC-17 and CEC-20 benchmark test suits for different dimensional search spaces, and the obtained solutions from the HH-FDB-SHADE were compared to 10 different LLH pool algorithms. In addition, the HH-FDB-SHADE algorithm has been applied to optimize the control parameters of PID, PIDF, FOPID, and PIDD2 in the optimal automatic voltage regulator (AVR) design problem to reveal the improved algorithm&#39;s performance more clearly and prove its success in solving engineering problems. The results obtained from the AVR system are compared with five other effective meta-heuristic search algorithms such as the fitness-distance balance Lévy Flight distribution, differential evolution, Harris–Hawks optimization, Barnacles mating optimizer, and Moth–Flame optimization algorithms in the literature. The results of the statistical analyses indicate that HH-FDB-SHADE is the best-ranked algorithm for solving CEC-17 and CEC-20 benchmark problems and gives better results compared to the LLH pool algorithms. Besides, the proposed algorithm is more effective and robust than five other meta-heuristic algorithms in solving optimal AVR design problems.},
  archive      = {J_NCA},
  author       = {Hinislioglu, Yunus and Guvenc, Ugur},
  doi          = {10.1007/s00521-024-10313-z},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21321-21364},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel hyper-heuristic algorithm: An application to automatic voltage regulator},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SuspAct: Novel suspicious activity prediction based on deep
learning in the real-time environment. <em>NCA</em>, <em>36</em>(34),
21307–21320. (<a
href="https://doi.org/10.1007/s00521-024-10355-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s evolving landscape of video surveillance, our study introduces SuspAct, an innovative ensemble model designed to detect suspicious activities in real time swiftly. Leveraging advanced Long-term Recurrent Convolutional Networks (LRCN), SuspAct represents a significant advancement in intelligent surveillance technology. By combining insights from various LRCN models through the Majority Voting ensemble technique, SuspAct enhances its overall robustness, outperforming traditional surveillance methods. Through rigorous experimentation on large-scale datasets, we demonstrate SuspAct’s superiority in proactive crime prevention, showcasing its potential to revolutionize security protocols and contribute substantially to public safety. Our work addresses the challenges posed by the escalating volume of video data and lays a strong foundation for future advancements in intelligent video surveillance technology.},
  archive      = {J_NCA},
  author       = {Kansal, Sachin and Jain, Akshat Kumar and Biswas, Moyukh and Bansal, Shaurya and Mahindru, Namay and Kansal, Priya},
  doi          = {10.1007/s00521-024-10355-3},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21307-21320},
  shortjournal = {Neural Comput. Appl.},
  title        = {SuspAct: Novel suspicious activity prediction based on deep learning in the real-time environment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating deep learning for accurate gastrointestinal
cancer classification: A comprehensive analysis of MSI and MSS patterns
using histopathology data. <em>NCA</em>, <em>36</em>(34), 21273–21305.
(<a href="https://doi.org/10.1007/s00521-024-10287-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of microsatellite instability (MSI) and microsatellite stability (MSS) is crucial in the fight against gastrointestinal (GI) cancer. MSI is a sign of genetic instability often associated with DNA repair mechanism deficiencies, which can cause (GI) cancers. On the other hand, MSS signifies genomic stability in microsatellite regions. Differentiating between these two states is pivotal in clinical decision-making as it provides prognostic and predictive information and treatment strategies. Rapid identification of MSI and MSS enables oncologists to tailor therapies more accurately, potentially saving patients from unnecessary treatments and guiding them toward regimens with the highest likelihood of success. Detecting these microsatellite status markers at an initial stage can improve patient outcomes and quality of life in GI cancer management. Our research paper introduces a cutting-edge method for detecting early GI cancer using deep learning (DL). Our goal is to identify the optimal model for GI cancer detection that surpasses previous works. Our proposed model comprises four stages: data acquisition, image processing, feature extraction, and classification. We use histopathology images from the Cancer Genome Atlas (TCGA) and Kaggle website with some modifications for data acquisition. In the image processing stage, we apply various operations such as color transformation, resizing, normalization, and labeling to prepare the input image for enrollment in our DL models. We present five different DL models, including convolutional neural networks (CNNs), a hybrid of CNNs-simple RNN (recurrent neural network), a hybrid of CNNs with long short-term memory (LSTM) (CNNs-LSTM), a hybrid of CNNs with gated recurrent unit (GRU) (CNNs-GRU), and a hybrid of CNNs-SimpleRNN-LSTM-GRU. Our empirical results demonstrate that CNNs-SimpleRNN-LSTM-GRU outperforms other models in accuracy, specificity, recall, precision, AUC, and F1, achieving an accuracy of 99.90%. Our proposed methodology offers significant improvements in GI cancer detection compared to recent techniques, highlighting the potential of DL-based approaches for histopathology data. We expect our findings to inspire future research in DL-based GI cancer detection.},
  archive      = {J_NCA},
  author       = {Wafa, Abeer A. and Essa, Reham M. and Abohany, Amr A. and Abdelkader, Hanan E.},
  doi          = {10.1007/s00521-024-10287-y},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21273-21305},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrating deep learning for accurate gastrointestinal cancer classification: A comprehensive analysis of MSI and MSS patterns using histopathology data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep fusion model for stock market prediction with news
headlines and time series data. <em>NCA</em>, <em>36</em>(34),
21229–21271. (<a
href="https://doi.org/10.1007/s00521-024-10303-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting models are essential decision support tools in real-world domains. Stock market is a remarkably complex domain, due to its quickly evolving temporal nature, as well as the multiple factors having an impact on stock prices. To date, a number of machine learning-based approaches have been proposed in the literature to tackle stock trend prediction. However, they typically tend to analyze a single data source or modality, or consider multiple modalities in isolation and rely on simple combination strategies, with a potential reduction in their modeling power. In this paper, we propose a multimodal deep fusion model to predict stock trends, leveraging daily stock prices, technical indicators, and sentiment in daily news headlines published by media outlets. The proposed architecture leverages a BERT-based model branch fine-tuned on financial news and a long short-term memory (LSTM) branch that captures relevant temporal patterns in multivariate data, including stock prices and technical indicators. Our experiments on 12 different stock datasets with prices and news headlines demonstrate that our proposed model is more effective than popular baseline approaches, both in terms of accuracy and trading performance in a portfolio analysis simulation, highlighting the positive impact of multimodal deep learning for stock trend prediction.},
  archive      = {J_NCA},
  author       = {Chen, Pinyu and Boukouvalas, Zois and Corizzo, Roberto},
  doi          = {10.1007/s00521-024-10303-1},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21229-21271},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep fusion model for stock market prediction with news headlines and time series data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Lyapunov-guided representation of recurrent
neural network performance. <em>NCA</em>, <em>36</em>(34), 21227. (<a
href="https://doi.org/10.1007/s00521-024-10366-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Vogt, Ryan and Zheng, Yang and Shlizerman, Eli},
  doi          = {10.1007/s00521-024-10366-0},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21227},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Lyapunov-guided representation of recurrent neural network performance},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Lyapunov-guided representation of recurrent neural network
performance. <em>NCA</em>, <em>36</em>(34), 21211–21226. (<a
href="https://doi.org/10.1007/s00521-024-09824-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNN) are ubiquitous computing systems for sequences and multivariate time-series data. While several robust RNN architectures are known, it is unclear how to relate RNN initialization, architecture, and other hyperparameters with accuracy for a given task. In this work, we propose treating RNN as dynamical systems and correlating hyperparameters with accuracy through Lyapunov spectral analysis, a methodology designed explicitly for nonlinear dynamical systems. To address the fact that RNN features go beyond the existing Lyapunov spectral analysis, we propose to infer relevant features from the Lyapunov spectrum with an Autoencoder and an embedding of its Latent representation (AeLLE). Our studies of various RNN architectures show that AeLLE successfully correlates RNN Lyapunov spectrum with accuracy. Furthermore, the Latent representation learned by AeLLE is generalizable to novel inputs from the same task and is formed early in the process of RNN training. The latter property allows for predicting the accuracy to which RNN would converge when training is complete. We conclude that the representation of RNN through the Lyapunov spectrum, along with AeLLE, provides a novel method for the organization and interpretation of variants of RNN architectures.},
  archive      = {J_NCA},
  author       = {Vogt, Ryan and Zheng, Yang and Shlizerman, Eli},
  doi          = {10.1007/s00521-024-09824-6},
  journal      = {Neural Computing and Applications},
  month        = {12},
  number       = {34},
  pages        = {21211-21226},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lyapunov-guided representation of recurrent neural network performance},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-adaptive arithmetic optimization algorithm with
hybrid search modes for 0–1 knapsack problem. <em>NCA</em>,
<em>36</em>(33), 21177–21210. (<a
href="https://doi.org/10.1007/s00521-024-10327-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arithmetic optimization algorithm (AOA) is a recently proposed algorithm inspired by mathematical operations. It has been used to solve a variety of optimization problems due to its simplicity of parameters and ease of implementation. However, it has been found that AOA encounters challenges such as poor exploration and premature convergence. To solve these issues, this paper proposes a self-adaptive AOA with hybrid search modes, named AOAHSM. In this algorithm, two hybrid search modes, i.e., the parallel search mode and the serial search mode, are established by combining AOA and differential evolution (DE) in different ways to enhance the exploration and exploitation abilities, respectively. In the parallel search mode, AOA and DE independently implement on their respective subpopulations to maintain a high distribution of the population. In the serial search mode, DE is embedded into AOA to provide more diversified solutions and thereby help the population jump out of local optima. Then, a self-adaptive conversion strategy is employed to dynamically switch between the two modes so as to achieve a better balance between exploration and exploitation. Additionally, a Levy flight strategy is used to perturb and update the best solution obtained in each iteration to further prevent premature convergence. Lastly, a binary version of AOAHSM is proposed to tackle the 0–1 knapsack problem. The proposed algorithms are evaluated on CEC2019, CEC2020 test functions, two typical engineering design problems and 45 instances of the 0–1 knapsack problem and compared with a number of state-of-the-art meta-heuristic algorithms. The obtained results demonstrate that AOAHSM and its binary version not only significantly outperform the original AOA but also achieve superior performance to the comparison algorithms in most cases.},
  archive      = {J_NCA},
  author       = {Lu, Mengdie and Lu, Haiyan and Hou, Xinyu and Hu, Qingyuan},
  doi          = {10.1007/s00521-024-10327-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21177-21210},
  shortjournal = {Neural Comput. Appl.},
  title        = {A self-adaptive arithmetic optimization algorithm with hybrid search modes for 0–1 knapsack problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A siamese neural network-based diagnosis of COVID-19 using
chest x-rays. <em>NCA</em>, <em>36</em>(33), 21163–21175. (<a
href="https://doi.org/10.1007/s00521-024-10326-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiological findings play an essential and complementary role in diagnosing Covid-19, assessing its severity, and managing its patients. Artificial intelligence technology based on medical imaging, which has made exciting developments by being applied in many areas, has become an area of interest for the rapid and accurate detection of the disease in the fight against the Covid-19 pandemic. The main difficulty is the inability to obtain a large dataset size with quality and standard images that neural networks need to perform well. Aiming at this problem, this study proposes a Siamese neural network-based deep learning framework for accurate diagnostics of Covid-19 using chest X-ray (CXR) images. The pre-trained VGG16 architecture, based on the transfer learning approach, forms the backbone of the Siamese neural network. The outputs of the backbones are joined together by a merging layer, and then the output passes through a fully connected layer. Based on this structure, category-aware Siamese-based models are produced for each class. The predictions from the models are combined using a voting mechanism to reduce the possibility of misclassification and to make better decisions. The framework was evaluated using a publicly available dataset for the 4-class classification task for Covid-19 pneumonia, lung opacity, normal, and non-Covid-19 viral pneumonia images. The findings reveal the high discrimination ability of the framework, trained using only 10 images per class in less training time, achieving an average test accuracy of 92%. Our framework, which learns a single Siamese-based pairwise model for each class, effectively captures class-specific features. Additionally, it has the potential to deal with data scarcity and long training time problems in multi-class classification tasks.},
  archive      = {J_NCA},
  author       = {Tas, Engin and Atli, Ayca Hatice},
  doi          = {10.1007/s00521-024-10326-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21163-21175},
  shortjournal = {Neural Comput. Appl.},
  title        = {A siamese neural network-based diagnosis of COVID-19 using chest X-rays},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting blood transfusions for coronary artery bypass
graft patients using deep neural networks and synthetic data.
<em>NCA</em>, <em>36</em>(33), 21153–21162. (<a
href="https://doi.org/10.1007/s00521-024-10309-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary Artery Bypass Graft (CABG) is a common cardiac surgery, but it continues to have many associated risks, including the need for blood transfusions. Previous research has shown that blood transfusion during CABG surgery is associated with an increased risk for infection and mortality. The current study aims to use modern techniques, such as deep neural networks and data synthesis, to develop models that can best predict the need for blood transfusion among CABG patients. Results show that neural networks with synthetic data generated by DataSynthesizer have the best performance. Implications of results and future directions are discussed.},
  archive      = {J_NCA},
  author       = {Tsai, Hsiao-Tien and Wu, Jichong and Gupta, Puneet and Heinz, Eric R. and Jafari, Amir},
  doi          = {10.1007/s00521-024-10309-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21153-21162},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting blood transfusions for coronary artery bypass graft patients using deep neural networks and synthetic data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Radial basis function neural network training using variable
projection and fuzzy means. <em>NCA</em>, <em>36</em>(33), 21137–21151.
(<a href="https://doi.org/10.1007/s00521-024-10274-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis function (RBF) neural network training presents a challenging optimization task, necessitating the utilization of advanced algorithms that can fully train the network so as to produce accurate and computationally efficient models. To achieve this goal, this work introduces a new framework where the original RBF training problem is divided into two simpler subproblems; the linear parameters, namely the network weights, are projected out of the problem using variable projection (VP), thus leaving a reduced functional, which depends only on nonlinear parameters, i.e., the RBF centers. The centers are updated using the Levenberg–Marquardt (LM) algorithm, while the optimal values of the synaptic weights are calculated in each iteration of the LM algorithm using linear regression. The proposed VP-LM scheme is coupled with the fuzzy means (FM) algorithm, which helps to select the number of RBF centers and enhances the overall search procedure, thus resulting to a framework that produces parsimonious models with enhanced accuracy in shorter training times. The proposed training scheme is evaluated on 12 both real-world and synthetic benchmark datasets and tested against various RBF training algorithms, as well as different neural network architectures. The experimental results underscore the effectiveness of the VP-FM algorithm in producing neural network models that outperform those generated by alternative methods in many aspects; to be more specific, the proposed approach achieves very competitive model accuracy, while resulting to smaller network sizes and thus lower complexity, which leads to shorter training times.},
  archive      = {J_NCA},
  author       = {Karamichailidou, Despina and Gerolymatos, Georgios and Patrinos, Panagiotis and Sarimveis, Haralambos and Alexandridis, Alex},
  doi          = {10.1007/s00521-024-10274-3},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21137-21151},
  shortjournal = {Neural Comput. Appl.},
  title        = {Radial basis function neural network training using variable projection and fuzzy means},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a design tool for the horizontal stabilizer
of a helicopter using artificial neural networks. <em>NCA</em>,
<em>36</em>(33), 21123–21135. (<a
href="https://doi.org/10.1007/s00521-024-10204-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of a helicopter is an intricate and challenging process. Decisions made during the preliminary design phase can significantly impact subsequent design stages, making it crucial to base these decisions on a solid foundation. A range of methods, including hand calculations, finite element analyses, and experimental tests, can be employed to establish the conceptual design parameters. However, these methods often come with the drawbacks of being time-intensive and costly, especially when testing various structures during the early design phase. To address this issue, this study introduces an artificial neural network-based design tool to evaluate the static structural characteristics of a helicopter’s horizontal stabilizer. The tool was built in Python using the Keras library. The required database for the training of the artificial neural network model was established using finite element analyses of the horizontal stabilizer subjected to the aerodynamic load for diverse design variables. The model’s performance was evaluated, and the model’s outputs were compared to the results derived from the finite element analyses. Moreover, the Hammersley sampling methodology was employed to reduce the size of the database without compromising on accuracy. The study also assessed the impact of decreasing the amount of data fed into the network model.},
  archive      = {J_NCA},
  author       = {Duzcu, Eren and Yıldırım, Bora},
  doi          = {10.1007/s00521-024-10204-3},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21123-21135},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of a design tool for the horizontal stabilizer of a helicopter using artificial neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gene pointNet for tumor classification. <em>NCA</em>,
<em>36</em>(33), 21107–21121. (<a
href="https://doi.org/10.1007/s00521-024-10307-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising incidence of cancer underscores the imperative for innovative diagnostic and prognostic methodologies. This study delves into the potential of RNA-Seq gene expression data to enhance cancer classification accuracy. Introducing a pioneering approach, we model gene expression data as point clouds, capitalizing on the data&#39;s intrinsic properties to bolster classification performance. Utilizing PointNet, a typical technique for processing point cloud data, as our framework&#39;s cornerstone, we incorporate inductive biases pertinent to gene expression and pathways. This integration markedly elevates model efficacy, culminating in developing an end-to-end deep learning classifier with an accuracy rate surpassing 99%. Our findings not only illuminate the capabilities of AI-driven models in the realm of oncology but also highlight the criticality of acknowledging biological dataset nuances in model design. This research provides insights into application of deep learning in medical science, setting the stage for further innovation in cancer classification through sophisticated biological data analysis. The source code for our study is accessible at: https://github.com/cialab/GPNet .},
  archive      = {J_NCA},
  author       = {Lu, Hao and Rezapour, Mostafa and Baha, Haseebullah and Niazi, Muhammad Khalid Khan and Narayanan, Aarthi and Gurcan, Metin Nafi},
  doi          = {10.1007/s00521-024-10307-x},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21107-21121},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gene pointNet for tumor classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-optimized vision-enhanced prompt learning for
few-shot multi-modal sentiment analysis. <em>NCA</em>, <em>36</em>(33),
21091–21105. (<a
href="https://doi.org/10.1007/s00521-024-10297-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To fulfill the explosion of multi-modal data, multi-modal sentiment analysis (MSA) emerged and attracted widespread attention. Unfortunately, conventional multi-modal research relies on large-scale datasets. On the one hand, collecting and annotating large-scale datasets is challenging and resource-intensive. On the other hand, the training on large-scale datasets also increases the research cost. However, the few-shot MSA (FMSA), which is proposed recently, requires only few samples for training. Therefore, in comparison, it is more practical and realistic. There have been approaches to investigating the prompt-based method in the field of FMSA, but they have not sufficiently considered or leveraged the information specificity of visual modality. Thus, we propose a vision-enhanced prompt-based model based on graph structure to better utilize vision information for fusion and collaboration in encoding and optimizing prompt representations. Specifically, we first design an aggregation-based multi-modal attention module. Then, based on this module and the biaffine attention, we construct a syntax–semantic dual-channel graph convolutional network to optimize the encoding of learnable prompts by understanding the vision-enhanced information in semantic and syntactic knowledge. Finally, we propose a collaboration-based optimization module based on the collaborative attention mechanism, which employs visual information to collaboratively optimize prompt representations. Extensive experiments conducted on both coarse-grained and fine-grained MSA datasets have demonstrated that our model significantly outperforms the baseline models.},
  archive      = {J_NCA},
  author       = {Zhou, Zikai and Qiao, Baiyou and Feng, Haisong and Han, Donghong and Wu, Gang},
  doi          = {10.1007/s00521-024-10297-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21091-21105},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention-optimized vision-enhanced prompt learning for few-shot multi-modal sentiment analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing robustness and control performance of voltage
source inverters using kalman filter adaptive observer and ANN-based
model predictive controller. <em>NCA</em>, <em>36</em>(33), 21073–21090.
(<a href="https://doi.org/10.1007/s00521-024-10243-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power electronic converters play a crucial role in integrating distributed generation, renewable energy sources, microgrids, and HVDC transmission networks into the grid. The control technique used in the voltage source inverters (VSI) is essential for handling load variations, system nonlinearity, stability, and fast transient response. This study focuses on improving the robustness and control performance of VSIs by integrating a Kalman filter adaptive observer into a finite control set model predictive control (FCS-MPC), resulting in an improved FCS-MPC strategy (IMPC). The classical FCS-MPC can be affected by inaccuracies due to measurement noise and uncertainties in system models, leading to less accurate predictions and suboptimal control actions. By employing the Kalman filter adaptive observer, real-time estimates of unmeasured variables are provided, compensating for uncertainties, and enhancing control performance. To further enhance flexibility and adaptivity, an artificial neural network (ANN)-based controller is designed. The ANN controller is trained offline using IMPC as baseline thus eliminating the need for online predictions and optimization. The ANN controller directly generates inverter switching configuration states, resulting in high-quality sinusoidal output voltage with low distortions. Comparative analysis is conducted for the classical FCS-MPC, IMPC, support vector machine (SVM), convolutional neural network (CNN), and ANN-based controllers under diverse operating conditions and system parameters. Although it has reduced interpretability, the ANN controller exhibits superior harmonic reduction, outperforming both MPC-based controllers and SVM. Evaluation against CNN-based controls also validates the ANN’s robustness and effectiveness in handling uncertainties, emphasizing its adaptability, efficiency, and practical applicability in power electronic applications.},
  archive      = {J_NCA},
  author       = {Kinga, Sammy and Megahed, Tamer F. and Kanaya, Haruichi and Mansour, Diaa-Eldin A.},
  doi          = {10.1007/s00521-024-10243-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21073-21090},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing robustness and control performance of voltage source inverters using kalman filter adaptive observer and ANN-based model predictive controller},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-based detection and identification of low-level nuclear
waste: A comparative analysis. <em>NCA</em>, <em>36</em>(33),
21061–21072. (<a
href="https://doi.org/10.1007/s00521-024-10238-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring environmental safety and regulatory compliance at Department of Energy (DOE) sites demands an efficient and reliable detection system for low-level nuclear waste (LLW). Unlike existing methods that rely on human effort, this paper explores the integration of computer vision algorithms to automate the identification of such waste across DOE facilities. We evaluate the effectiveness of multiple algorithms in classifying nuclear waste materials and their adaptability to newly emerging LLW. Our research introduces and implements five state-of-the-art computer vision models, each representing a different approach to the problem. Through rigorous experimentation and validation, we evaluate these algorithms based on performance, speed, and adaptability. The results reveal a noteworthy trade-off between detection performance and adaptability. YOLOv7 shows the best performance and requires the highest effort to detect new LLW. Conversely, OWL-ViT has lower performance than YOLOv7 and requires minimal effort to detect new LLW. The inference speed does not strongly correlate with performance or adaptability. These findings offer valuable insights into the strengths and limitations of current computer vision algorithms for LLW detection. Each developed model provides a specialized solution with distinct advantages and disadvantages, empowering DOE stakeholders to select the algorithm that aligns best with their specific needs.},
  archive      = {J_NCA},
  author       = {Duani Rojas, Aris and Lagos, Leonel and Upadhyay, Himanshu and Soni, Jayesh and Prabakar, Nagarajan},
  doi          = {10.1007/s00521-024-10238-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21061-21072},
  shortjournal = {Neural Comput. Appl.},
  title        = {AI-based detection and identification of low-level nuclear waste: A comparative analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep ensemble learning for osteoporosis diagnosis from knee
x-rays: A preliminary cohort study in kashmir valley. <em>NCA</em>,
<em>36</em>(33), 21041–21059. (<a
href="https://doi.org/10.1007/s00521-024-10158-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporosis (OP) is the most prevalent and common bone disease, especially knee osteoporosis. It significantly disables sufferers all over the world. Although laborious and prone to user variation, manual diagnosis, segmentation, and annotation of knee joints continue to be the preferred way to diagnose OP in clinical procedures. Therefore, many deep learning algorithms, particularly the convolutional neural network (CNN), have been created to increase clinical workflow efficiency to overcome the shortcomings of the widely used method as above. Medical imaging procedures can show hidden structures in a volumetric view, particularly those that generate three-dimensional (3D) pictures like MRI. We created a dataset of 240 pictures from patients who had knee X-rays and skeletal bone mineral density assessments at the same time. Four convolutional neural networks (CNN) models were used to analyse the X-ray images and deep neural networks for clinical covariances to determine the degree of osteoporosis. Additionally, we investigated ensemble models that included each CNN with a clinical covariance. For every network, scores for accuracy and error rate were computed. ResNet and Alexnet displayed the highest levels of accuracy when the CNN models were tested using knee X-rays with normal, low BMD, and osteoporosis. An ensemble of DNN with Alexnet, ResNet, and both ResNet and Alexnet are employed resulting in improved accuracy. The ensemble of best-performing CNN and DNN is proposed to diagnose osteoporosis more accurately. The proposed method has produced a highly accurate osteoporosis diagnosis.},
  archive      = {J_NCA},
  author       = {Wani, Insha Majeed and Arora, Sakshi},
  doi          = {10.1007/s00521-024-10158-6},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21041-21059},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep ensemble learning for osteoporosis diagnosis from knee X-rays: A preliminary cohort study in kashmir valley},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary variational inference for bayesian generalized
nonlinear models. <em>NCA</em>, <em>36</em>(33), 21023–21040. (<a
href="https://doi.org/10.1007/s00521-024-10349-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the exploration of recently developed Bayesian Generalized Nonlinear Models (BGNLM), this paper proposes a pragmatic scalable approximation for computing posterior distributions. Traditional Markov chain Monte Carlo within the populations of the Genetically Modified Mode Jumping Markov Chain Monte Carlo (GMJMCMC) algorithm is an NP-hard search problem. To linearize them, we suggest using instead variational Bayes, employing either mean-field approximation or normalizing flows for simplicity and scalability. This results in an evolutionary variational Bayes algorithm as a more scalable alternative to GMJMCMC. Through practical applications including inference on Bayesian linear models, Bayesian fractional polynomials, and full BGNLM, we demonstrate the effectiveness of our method, delivering accurate predictions, transparency and interpretations, and accessible measures of uncertainty, while improving the scalability of BGNLM inference through on the one hand using a novel variational Bayes method, but, on the other hand, enabling the use of GPUs for computations.},
  archive      = {J_NCA},
  author       = {Sommerfelt, Philip Sebastian Hauglie and Hubin, Aliaksandr},
  doi          = {10.1007/s00521-024-10349-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {21023-21040},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolutionary variational inference for bayesian generalized nonlinear models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polar fox optimization algorithm: A novel meta-heuristic
algorithm. <em>NCA</em>, <em>36</em>(33), 20983–21022. (<a
href="https://doi.org/10.1007/s00521-024-10346-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proposed paper introduces a new optimization algorithm inspired by nature called the polar fox optimization algorithm (PFA). This algorithm addresses the herd life of polar foxes and especially their hunting method. The polar fox jumping strategy for hunting, which is performed through high hearing power, is mathematically formulated and implemented to perform optimization processes in a wide range of search spaces. The performance of the polar fox algorithm is tested with 14 classic benchmark functions. To provide a comprehensive comparison, all 14 test functions are expanded, shifted, rotated and combined for this test. For further testing, the recent CEC 2021 test’s complex functions are studied in the unimodal, basic, hybrid and composition modes. Finally, the rate of convergence and computational time of PFA are also evaluated by several changes with other algorithms. Comparisons show that PFA has numerous benefits over other well-known meta-heuristic algorithms and determines the solutions with fewer control parameters. So it offers competitive and promising results. In addition, this research tests PFA performance with 6 different challenging engineering problems. Compared to the well-known meta-artist methods, the superiority of the PFA is observed from the experimental results of the proposed algorithm in real-world problem-solving. The source codes of the PFA are publicly available at https://github.com/ATR616/PFA .},
  archive      = {J_NCA},
  author       = {Ghiaskar, Ahmad and Amiri, Amir and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-024-10346-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20983-21022},
  shortjournal = {Neural Comput. Appl.},
  title        = {Polar fox optimization algorithm: A novel meta-heuristic algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sampled-data synchronization for heterogeneous delays
inertial neural networks with generally uncertain semi-markovian jumping
and its application. <em>NCA</em>, <em>36</em>(33), 20963–20982. (<a
href="https://doi.org/10.1007/s00521-024-10192-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with sampled-data synchronization problem of heterogeneous delays inertial neural networks (INNs) with generally uncertain semi-Markovian (GUSM) jumping. Different from traditional Markovian inertial neural networks (MINNs), the INNs with GUSM are investigated in this paper by fully considering the sojourn time and the lacking transition rates, which is more general and applicable for practical system. The new extended two-sided looped-functional (ETSLF) approach is adopted in this paper, and some improved less conservative criteria are derived to achieve the synchronization of the drive and response INNs. The controller gain matrices are acquired based on synchronization criteria. Finally, the viability of the method is presented through three examples.},
  archive      = {J_NCA},
  author       = {Wang, Junyi and He, Wenyuan and Xu, Hongli and Cai, Haibin and Chen, Xiangyong},
  doi          = {10.1007/s00521-024-10192-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20963-20982},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sampled-data synchronization for heterogeneous delays inertial neural networks with generally uncertain semi-markovian jumping and its application},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal fusion: Advancing medical visual
question-answering. <em>NCA</em>, <em>36</em>(33), 20949–20962. (<a
href="https://doi.org/10.1007/s00521-024-10318-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the application of Visual Question-Answering (VQA) technology, which combines computer vision and natural language processing (NLP), in the medical domain, specifically for analyzing radiology scans. VQA can facilitate medical decision-making and improve patient outcomes by accurately interpreting medical imaging, which requires specialized expertise and time. The paper proposes developing an advanced VQA system for medical datasets using the Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (BLIP) architecture from Salesforce, leveraging deep learning and transfer learning techniques to handle the unique challenges of medical/radiology images. The paper discusses the underlying concepts, methodologies, and results of applying the BLIP architecture and fine-tuning approaches for VQA in the medical domain, highlighting their effectiveness in addressing the complexities of VQA tasks for radiology scans. Inspired by the BLIP architecture from Salesforce, we propose a novel multi-modal fusion approach for medical VQA and evaluating its promising potential.},
  archive      = {J_NCA},
  author       = {Mudgal, Anjali and Kush, Udbhav and Kumar, Aditya and Jafari, Amir},
  doi          = {10.1007/s00521-024-10318-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20949-20962},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal fusion: Advancing medical visual question-answering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational and artificial neural network study on ternary
nanofluid flow with heat and mass transfer with magnetohydrodynamics and
mass transpiration. <em>NCA</em>, <em>36</em>(33), 20927–20947. (<a
href="https://doi.org/10.1007/s00521-024-10325-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ternary nanofluids have been an interesting field for academics and researchers in the modern technological era because of their advanced thermophysical properties and the desire to increase heat transfer rates. Furthermore, the innovative, sophisticated artificial neural network strategy with the Levenberg–Marquardt backpropagation technique (LMBPT) is proposed for research on heat and mass transport over non-Newtonian ternary Casson fluid on a radially extending surface with magnetic field and convective boundary conditions. The main objective of the current research is to conduct a comparative study of numerical solutions of the ternary nanofluid model of heat/mass transport utilizing the artificial neural network (ANN) together with the (LMBPT). To accurately represent complex patterns, neural networks modify their parameters flexibly, resulting in more accurate predictions and greater generalization with numerical outcomes. The model equations were reduced from partial to ODEs through applying appropriate similarity variables. The shooting technique and the byp-4c algorithm were then used to analyze the numerical data. The current study reveals that a rise in the Casson parameter diminishes the fluid velocity but an opposite nature is seen in thermal distribution for rising behavior of heat source/sink and Biot number, and the concentration profile tends to deteriorate when the mass transfer is elevated. Furthermore, the resulting values of the significant engineering coefficients are numerically analyzed and tabulated.},
  archive      = {J_NCA},
  author       = {Mahabaleshwar, U. S. and Nihaal, K. M. and Zeidan, Dia and Dbouk, T. and Laroze, D.},
  doi          = {10.1007/s00521-024-10325-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20927-20947},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computational and artificial neural network study on ternary nanofluid flow with heat and mass transfer with magnetohydrodynamics and mass transpiration},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reduced-form multigrid approach for ANN equivalent to
classic multigrid expansion. <em>NCA</em>, <em>36</em>(33), 20907–20926.
(<a href="https://doi.org/10.1007/s00521-024-10311-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the method of solving partial differential equations (PDEs) using artificial neural network (ANN) structures, which have been actively applied in artificial intelligence models. The ANN model for solving PDEs offers the advantage of providing explicit and continuous solutions. However, the ANN model for solving PDEs cannot construct a conventionally solvable linear system with known matrix solvers; thus, computational speed could be a significant concern. We study the implementation of the multigrid method, developing a general concept for a coarse-grid correction method to be integrated into the ANN-PDE architecture, with the goal of enhancing computational efficiency. By developing a reduced form of the multigrid method for ANN, we demonstrate that it can be interpreted as an equivalent representation of the classic multigrid expansion. We validated the applicability of the proposed method through rigorous experiments, which included analyzing loss decay and the number of iterations along with improvements in terms of accuracy, speed, and complexity. We accomplished this by employing the gradient descent method and the Broyden–Fletcher–Goldfarb–Shanno (BFGS) method to update the gradients while solving the given ANN systems of PDEs.},
  archive      = {J_NCA},
  author       = {Seo, Jeong-Kweon},
  doi          = {10.1007/s00521-024-10311-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20907-20926},
  shortjournal = {Neural Comput. Appl.},
  title        = {A reduced-form multigrid approach for ANN equivalent to classic multigrid expansion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SEAformer: Frequency domain decomposition transformer with
signal enhanced for long-term wind power forecasting. <em>NCA</em>,
<em>36</em>(33), 20883–20906. (<a
href="https://doi.org/10.1007/s00521-024-10295-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable wind power forecasting is of great importance for stable grid operation and advanced dispatch planning. Due to the complex, non-stationary, and highly volatile nature of wind power data, Transformer-based methods find it difficult to capture long-term trend features and incur high computational costs. To address these challenging problems, we propose a frequency domain decomposition Transformer architecture with signal enhanced attention mechanism (SEAformer). Firstly, we devise a frequency domain-based trend decomposition structure that enables the Transformer to extract more effective long-term trend features, thereby further improving the long-term prediction accuracy of the model. Secondly, in response to the large fluctuations and instability of wind power data, we design an internal signal enhanced substructure combined with an attention mechanism in the Transformer, which filters out high-frequency noise signals and reduces the computational cost of the Transformer. We conduct extensive experiments on the benchmark dataset, the experimental analysis demonstrates that SEAformer outperforms the baseline methods (Transformer-based, MLP-based, and Traditional methods) in both multivariate and univariate prediction tasks, exhibiting the best prediction performance.},
  archive      = {J_NCA},
  author       = {Yan, Leiming and Wu, Siqi and Li, Shaopeng and Chen, Xianyi},
  doi          = {10.1007/s00521-024-10295-y},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20883-20906},
  shortjournal = {Neural Comput. Appl.},
  title        = {SEAformer: Frequency domain decomposition transformer with signal enhanced for long-term wind power forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Predictions of steel price indices through machine learning
for the regional northeast chinese market. <em>NCA</em>,
<em>36</em>(33), 20863–20882. (<a
href="https://doi.org/10.1007/s00521-024-10270-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projections of commodity prices have long been a significant source of dependence for investors and the government. This study investigates the challenging topic of forecasting the daily regional steel price index in the northeast Chinese market from January 1, 2010, to April 15, 2021. The projection of this significant commodity price indication has not received enough attention in the literature. The forecasting model that is used is Gaussian process regressions, which are trained using a mix of cross-validation and Bayesian optimizations. The models that were built precisely predicted the price indices between January 8, 2019, and April 15, 2021, with an out-of-sample relative root mean square error of 0.5432%. Investors and government officials can use the established models to study pricing and make judgments. Forecasting results can help create comparable commodity price indices when reference data on the price trends suggested by these models are used.},
  archive      = {J_NCA},
  author       = {Jin, Bingzi and Xu, Xiaojie},
  doi          = {10.1007/s00521-024-10270-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20863-20882},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictions of steel price indices through machine learning for the regional northeast chinese market},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing human-like multimodal reasoning: A new challenging
dataset and comprehensive framework. <em>NCA</em>, <em>36</em>(33),
20849–20861. (<a
href="https://doi.org/10.1007/s00521-024-10310-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal reasoning is a critical component in the pursuit of artificial intelligence systems that exhibit human-like intelligence, especially when tackling complex tasks. While the chain-of-thought (CoT) technique has gained considerable attention, the existing ScienceQA dataset, primarily focused on multimodal scientific questions and explanations from elementary and high school textbooks, exhibits limitations in providing a comprehensive evaluation across a broader spectrum of open-domain questions. To address this gap, we introduce the COCO Multi-Modal Reasoning (COCO-MMR) dataset, a comprehensive collection of open-ended questions, rationales, and answers derived from the COCO dataset. Unlike previous datasets that rely on multiple-choice questions, our dataset utilizes open-ended questions to more effectively challenge and assess CoT models’ reasoning capabilities. Through comprehensive evaluations and detailed analyses, we demonstrate that our multihop cross-modal attention and sentence-level contrastive learning modules, designed to simulate human thought processes, significantly enhance model comprehension abilities. Experiments confirm the proposed dataset and techniques, showing their potential to advance multimodal reasoning. The data and code are available at https://github.com/weijingxuan/COCO-MMR .},
  archive      = {J_NCA},
  author       = {Wei, Jingxuan and Tan, Cheng and Gao, Zhangyang and Sun, Linzhuang and Li, Siyuan and Yu, Bihui and Guo, Ruifeng and Li, Stan Z.},
  doi          = {10.1007/s00521-024-10310-2},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20849-20861},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing human-like multimodal reasoning: A new challenging dataset and comprehensive framework},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DONN: Leveraging heterogeneous outer products for CTR
prediction. <em>NCA</em>, <em>36</em>(33), 20823–20848. (<a
href="https://doi.org/10.1007/s00521-024-10296-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primary strategy for constructing click-through rate models based on deep learning involves combining a multi-layer perceptron (MLP) with custom networks that can effectively capture the interactions between different features. This is due to the widespread recognition that relying solely on a vanilla MLP network is not effective in acquiring knowledge about multiplicative feature interactions. These custom networks often employ product methods, such as inner, Hadamard, and outer products, to construct dedicated architectures for this purpose. Among these methods, the outer product has shown superiority in capturing feature interactions. However, the resulting quadratic form from the outer product operation limits the conveyance of informative higher-order interactions to the MLP. Efforts to address this limitation have led to models attempting to increase interaction degrees to higher orders. However, utilizing matrix factorization techniques to reduce learning parameters has resulted in information loss and decreased performance. Furthermore, previous studies have constrained the MLP’s potential by providing it with inputs consisting of homogeneous outer products, thus limiting available information diversity. To overcome these challenges, we introduce DONN, a model that leverages a composite-wise bilinear module incorporating factorized bilinear pooling to mitigate information loss and facilitate higher-order interaction development. Additionally, DONN utilizes a feature-wise bilinear module for outer product computations between feature pairs, augmenting the MLP with combined information. By employing heterogeneous outer products, DONN enhances the MLP’s prediction capabilities, enabling the recognition of additional nonlinear interdependencies. Our evaluation on two benchmark datasets demonstrates that DONN surpasses state-of-the-art models in terms of performance.},
  archive      = {J_NCA},
  author       = {Kim, Tae-Suk},
  doi          = {10.1007/s00521-024-10296-x},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20823-20848},
  shortjournal = {Neural Comput. Appl.},
  title        = {DONN: Leveraging heterogeneous outer products for CTR prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Circuit topology aware GNN-based multi-variable model for
DC-DC converters dynamics prediction in CCM and DCM. <em>NCA</em>,
<em>36</em>(33), 20807–20822. (<a
href="https://doi.org/10.1007/s00521-024-10293-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A regression model based on graph neural network, tailored for electric circuit dynamics prediction is introduced, providing converter performance predictions on converter circuit level and internal parameter variations. Regardless of the number of components or connections present in a converter circuit, the proposed model can be readily scaled to incorporate different converter circuit topologies. Moreover, the model can be used to analyse converter circuits with any number of circuit components and any control parameters variation. To enable the use of machine learning methods and applications, all physical and switching circuit properties such as converter circuits operating in continuous conduction mode or discontinuous conduction mode are accurately mapped to graph representation. Three of the most common converters (Buck, Boost, and Buck-boost) are used as example circuits applied to model and the target is to predict the gain and current ripples in inductor. The model achieves 99.51% on the $$R^2$$ measure and a mean square error of 0.0263.},
  archive      = {J_NCA},
  author       = {Khamis, Ahmed K. and Agamy, Mohammed},
  doi          = {10.1007/s00521-024-10293-0},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20807-20822},
  shortjournal = {Neural Comput. Appl.},
  title        = {Circuit topology aware GNN-based multi-variable model for DC-DC converters dynamics prediction in CCM and DCM},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extensive evaluation of image classifiers’ interpretations.
<em>NCA</em>, <em>36</em>(33), 20787–20805. (<a
href="https://doi.org/10.1007/s00521-024-10273-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saliency maps are input-resolution matrices used for visualizing local interpretations of image classifiers. Their pixel values reflect the importance of corresponding image locations for the model’s decision. Despite numerous proposals on how to obtain such maps, their evaluation remains an open question. This paper presents a carefully designed experimental procedure along with a set of quantitative interpretation evaluation metrics that rely solely on the original model behavior. Previously noticed evaluation biases have been attenuated by separating locations with high and low values, considering the full saliency map resolution, and using classifiers with diverse accuracies and all the classes in the dataset. We used the proposed evaluation metrics to compare and analyze seven well-known interpretation methods. Our experiments confirm the importance of object background as well as negative saliency map pixels, and we show that the scale of their impact on the model is comparable to that of positive ones. We also demonstrate that a good class score interpretation does not necessarily imply a good probability interpretation. DeepLIFT and LRP- $$\epsilon$$ methods proved most successful altogether, while Grad-CAM and Ablation-CAM performed very poorly, even in the detection of positive relevance. The retention of positive values alone in the latter two methods was responsible for the inaccurate detection of irrelevant locations as well.},
  archive      = {J_NCA},
  author       = {Poštić, Suraja and Subašić, Marko},
  doi          = {10.1007/s00521-024-10273-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20787-20805},
  shortjournal = {Neural Comput. Appl.},
  title        = {Extensive evaluation of image classifiers’ interpretations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation of the behavior of fine and gross motor skills of
an individual with motor disabilities. <em>NCA</em>, <em>36</em>(33),
20769–20785. (<a
href="https://doi.org/10.1007/s00521-024-10267-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed a neural network model that imitates the central nervous system’s control of motor sensors (Sánchez-Torres and Rodríguez-Romo in Neurocomputing 581:127511, 2024). Our research explored various levels of connectivity in our neural network related to neuroplasticity in the central nervous system. We have conducted a study comparing healthy individuals to those with motor impairments by utilizing reinforcement learning and transfer entropy. In our previous research (Sánchez-Torres and Rodríguez-Romo in Neurocomputing 581:127511, 2024), we have simulated human walking while encountering obstacles as an instance of gross motor activities. Now, we have used the same model to simulate fine motor activities. Our goal is to identify differences in information transmission between gross and fine motor activities among healthy individuals and those with motor impairments by evaluating the effective connectivity of our network. To regulate learning accuracy in our model, we introduced a variable called numClusterToFire. However, we discovered that the value for this variable requires careful calibration. If the value is too small, agent exploration is insufficient, and network learning is inefficient. Conversely, learning times increase exponentially, often unnecessarily if the value is too large. We conducted simulations for gross and fine motor skills using three different numClusterToFire values and found that as we increased numClusterToFire, the time required for the network to memorize the outputs for each of the objects in the test set also increased. Our findings indicate that in gross motor skills, which do not require precision, changes in the numClusterToFire variable do not affect information transfer behavior. Conversely, in fine motor skills, information transfer decreases as numClusterToFire increases. On the other hand, our model revealed that for healthy and disabled individuals, the transfer of information between the input layer and the first hidden layer is higher for fine motor skills; this important biological fact suggests the influence of external cues in performing this activity successfully. Additionally, our neural network model showed that movements that do not require precision do not necessarily require a high level of neuroplasticity. Increasing neuroplasticity may cause some neurons to transmit more information than others. Whereas, increasing neuroplasticity through practice is essential for precise movements like fine motor skills. We also found that information transfer in the network’s hidden layers is similar for fine and gross motor activities, as we observed identical patterns. However, the distribution and proportion of these patterns differ, concluding that more neurons are involved in fine motor activities, and more information is transferred compared to gross motor activities. Finally, a pattern was observed in the transfer of information in the last hidden layer, which is only present in fine motor skills. This pattern is associated with the precision of the movements.},
  archive      = {J_NCA},
  author       = {Sánchez-Torres, Karla K. and Rodríguez-Romo, Suemi},
  doi          = {10.1007/s00521-024-10267-2},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20769-20785},
  shortjournal = {Neural Comput. Appl.},
  title        = {Simulation of the behavior of fine and gross motor skills of an individual with motor disabilities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated evaluation and parameter estimation of brain tumor
using deep learning techniques. <em>NCA</em>, <em>36</em>(33),
20751–20767. (<a
href="https://doi.org/10.1007/s00521-024-10255-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification and region extraction of brain tumors is an essential aspect of clinical image analysis and the diagnosis of brain-related illnesses. The precise and accurate identification of tumors from MRI images is particularly significant in the effective formulating of treatments such as surgery, radiation therapy, and drug therapy. The challenge of segmentation stems from the variability in the size, location, and appearance of tumors, making it a complex task. Various segmentation and classification techniques have been created and designed for brain tumor diagnosis; however, these traditional techniques are time-consuming and subjective and require expertise in image processing. In recent times, deep learning-based approaches have shown promising results in brain tumor segmentation. This research aims to develop a brain tumor segmentation and classification model that enables medical professionals to locate and measure tumors accurately and develop effective treatment and rehabilitation strategies. The process involves segmenting the tumor and further classifying it into its two major types. The parameter estimation from the segmented output provides an insight that is pivotal in the evaluation of MRI brain tumors. With further research and development, deep learning-based segmentation and classification could become an important tool for accurate detection and evaluation of brain tumors. The development of deep learning-based segmentation and classification methods can greatly benefit the medical community, and according to the finding from the experiment, it is shown that the proposed framework excels in brain tumor segmentation and classification with an accuracy of 99.3%.},
  archive      = {J_NCA},
  author       = {Vijayakumari, B. and Kiruthiga, N. and Bushkala, C. P.},
  doi          = {10.1007/s00521-024-10255-6},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20751-20767},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated evaluation and parameter estimation of brain tumor using deep learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A proposed framework for crop yield prediction using hybrid
feature selection approach and optimized machine learning. <em>NCA</em>,
<em>36</em>(33), 20723–20750. (<a
href="https://doi.org/10.1007/s00521-024-10226-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting crop yield is essential for optimizing agricultural practices and ensuring food security. However, existing approaches often struggle to capture the complex interactions between various environmental factors and crop growth, leading to suboptimal predictions. Consequently, identifying the most important feature is vital when leveraging Support Vector Regressor (SVR) for crop yield prediction. In addition, the manual tuning of SVR hyperparameters may not always offer high accuracy. In this paper, we introduce a novel framework for predicting crop yields that address these challenges. Our framework integrates a new hybrid feature selection approach with an optimized SVR model to enhance prediction accuracy efficiently. The proposed framework comprises three phases: preprocessing, hybrid feature selection, and prediction phases. In preprocessing phase, data normalization is conducted, followed by an application of K-means clustering in conjunction with the correlation-based filter (CFS) to generate a reduced dataset. Subsequently, in the hybrid feature selection phase, a novel hybrid FMIG-RFE feature selection approach is proposed. Finally, the prediction phase introduces an improved variant of Crayfish Optimization Algorithm (COA), named ICOA, which is utilized to optimize the hyperparameters of SVR model thereby achieving superior prediction accuracy along with the novel hybrid feature selection approach. Several experiments are conducted to assess and evaluate the performance of the proposed framework. The results demonstrated the superior performance of the proposed framework over state-of-art approaches. Furthermore, experimental findings regarding the ICOA optimization algorithm affirm its efficacy in optimizing the hyperparameters of SVR model, thereby enhancing both prediction accuracy and computational efficiency, surpassing existing algorithms.},
  archive      = {J_NCA},
  author       = {Abdel-salam, Mahmoud and Kumar, Neeraj and Mahajan, Shubham},
  doi          = {10.1007/s00521-024-10226-x},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20723-20750},
  shortjournal = {Neural Comput. Appl.},
  title        = {A proposed framework for crop yield prediction using hybrid feature selection approach and optimized machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully convolutional neural network-based segmentation of
brain metastases: A comprehensive approach for accurate detection and
localization. <em>NCA</em>, <em>36</em>(33), 20711–20722. (<a
href="https://doi.org/10.1007/s00521-024-10334-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain metastases present a formidable challenge in cancer management due to the infiltration of malignant cells from distant sites into the brain. Precise segmentation of brain metastases (BM) in medical imaging is vital for treatment planning and assessment. Leveraging deep learning techniques has shown promise in automating BM identification, facilitating faster and more accurate detection. This paper aims to develop an innovative novel deep learning model tailored for BM segmentation, addressing current approach limitations. Utilizing a comprehensive dataset of annotated magnetic resonance imaging (MRI) from Stanford University, the proposed model will undergo thorough evaluation using standard performance metrics. Comparative analysis with existing segmentation methods will highlight the superior performance and efficacy of our model. The anticipated outcome of this research is a highly accurate and efficient deep learning model for brain metastasis segmentation. Such a model holds potential to enhance treatment planning, monitoring, and ultimately improve patient care and clinical outcomes in managing brain metastases.},
  archive      = {J_NCA},
  author       = {Farghaly, Omar and Deshpande, Priya},
  doi          = {10.1007/s00521-024-10334-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20711-20722},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fully convolutional neural network-based segmentation of brain metastases: A comprehensive approach for accurate detection and localization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intuitionistic fuzzy broad learning system with a new
non-membership function. <em>NCA</em>, <em>36</em>(33), 20699–20710. (<a
href="https://doi.org/10.1007/s00521-024-10328-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data containing noises, outliers, and imbalanced class distributions pose challenges to the traditional classifiers. By incorporating both the membership and non-membership functions, the intuitionistic fuzzy (IF) set has shown potential in designing robust learning algorithms for classifiers. However, the non-membership function used in these IF-based classifiers usually only utilizes the local distribution information of the training samples, and the classifiers are built upon single-hidden layer networks, which degrade the performance of the corresponding classifiers. Broad learning system (BLS) is an emerging neural network model with fast learning speed and flexible network architecture; however, it still fails to distinguish n samples. To this end, in this paper, we propose a new definition of the non-membership function within intuitionistic fuzzy sets and subsequently propose an intuitionistic fuzzy broad learning system (IFBLS) model. The proposed non-membership function incorporates two ratio numbers based on four distances, allowing for the utilization of global information on the distribution of samples and mitigating misclassification of valid samples as noise which is often observed in traditional methods. By using a score function that considers both the membership and non-membership functions to redistribute the importance of the training samples, the proposed IFBLS benefits from both the powerful representation capability of the original BLS and the robust learning of IF-based models. Extensive experiments conducted on 21 imbalanced binary classification problems sourced from the UCI and KEEL repositories illustrate that the proposed IFBLS achieves state-of-the-art performance by attaining the highest testing accuracy in 17 out of the 21 problems.},
  archive      = {J_NCA},
  author       = {Jiang, Mengying and Zhang, Huisheng and Liu, Yuxuan},
  doi          = {10.1007/s00521-024-10328-6},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20699-20710},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intuitionistic fuzzy broad learning system with a new non-membership function},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evidential neural network for tensile stress uncertainty
quantification in thermoplastic elastomers. <em>NCA</em>,
<em>36</em>(33), 20687–20697. (<a
href="https://doi.org/10.1007/s00521-024-10320-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the use of artificial neural networks (ANNs) with deep evidential regression to model the tensile stress response of a thermoplastic elastomer (TPE) considering uncertainty. Three Gaussian noise scenarios were added to a previous dataset of a TPE to simulate noise in the stress response. The trained ANN models were able to address stress–strain data that were not used for their training or validation, even in the presence of noise. The uncertainty in all tested ANN scenarios comprised, within ± $$3\sigma$$ , the noisy data of the TPE stress response. The method was extended to other grades of Hytrel material with ANN architectures that obtained results with a coefficient of determination of about 0.9. These results suggest that shallow neural networks, equipped and trained using evidential output layers and an evidential regression loss, can predict, generalize, and simulate noisy tensile stress responses in TPE materials.},
  archive      = {J_NCA},
  author       = {Rodríguez-Sánchez, Alejandro E.},
  doi          = {10.1007/s00521-024-10320-0},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20687-20697},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evidential neural network for tensile stress uncertainty quantification in thermoplastic elastomers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid-mode tracker with online SA-LSTM updater.
<em>NCA</em>, <em>36</em>(33), 20671–20686. (<a
href="https://doi.org/10.1007/s00521-024-10354-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The backbone network and target template are pivotal factors influencing the performance of Siamese trackers. However, traditional approaches encounter challenges in eliminating local redundancy and establishing global dependencies when learning visual data representations. While convolutional neural networks (CNNs) and vision transformers (ViTs) are commonly employed as backbones in Siamese-based trackers, each primarily addresses only one of these challenges. Furthermore, tracking is a dynamic process. Nonetheless, in many Siamese trackers, solely a fixed initial template is employed to facilitate target state matching. This approach often proves inadequate for effectively handling scenes characterized by target deformation, occlusion, and fast motion. In this paper, we propose a Hybrid-Mode Siamese tracker featuring an online SA-LSTM updater. Distinct learning operators are tailored to exploit characteristics at different depth levels of the backbone, integrating convolution and transformers to form a Hybrid-Mode backbone. This backbone efficiently learns global dependencies among input tokens while minimizing redundant computations in local domains, enhancing feature richness for target tracking. The online SA-LSTM updater comprehensively integrates spatial–temporal context during tracking, producing dynamic template features with enhanced representations of target appearance. Extensive experiments across multiple benchmark datasets, including GOT-10K, LaSOT, TrackingNet, OTB-100, UAV123, and NFS, demonstrate that the proposed method achieves outstanding performance, running at 35 FPS on a single GPU.},
  archive      = {J_NCA},
  author       = {Zheng, Hongsheng and Gao, Yun and Hu, Yaqing and Zhang, Xuejie},
  doi          = {10.1007/s00521-024-10354-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20671-20686},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid-mode tracker with online SA-LSTM updater},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gene expression clock: An unsupervised deep learning
approach for predicting circadian rhythmicity from whole genome
expression. <em>NCA</em>, <em>36</em>(33), 20653–20670. (<a
href="https://doi.org/10.1007/s00521-024-10316-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circadian rhythms are driven by an internal molecular clock which controls physiological and behavioral processes. Disruptions in these rhythms have been associated with health issues. Therefore, studying circadian rhythms is crucial for understanding physiology, behavior, and pathophysiology. However, it is challenging to study circadian rhythms over gene expression data, due to a scarcity of time labels. In this paper, we propose a novel approach to predict the phases of un-timed samples based on a deep neural network (DNN) architecture. This approach addresses two challenges: (1) prediction of sample phases and reliable identification of cyclic genes from high-dimensional expression data without relying on conserved circadian genes and (2) handling small sample-sized datasets. Our algorithm begins with initial gene screening to select candidate cyclic genes using a Minimum Distortion Embedding framework. This stage is then followed by greedy layer-wise pre-training of our DNN. Pre-training accomplishes two critical objectives: First, it initializes the hidden layers of our DNN model, enabling them to effectively capture features from the gene profiles with limited samples. Second, it provides suitable initial values for essential aspects of gene periodic oscillations. Subsequently, we fine-tune the pre-trained network to achieve precise sample phase predictions. Extensive experiments on both animal and human datasets show accurate and robust prediction of both sample phases and cyclic genes. Moreover, based on an Alzheimer’s disease (AD) dataset, we identify a set of hub genes that show significant oscillations in cognitively normal subjects but had disruptions in AD, as well as their potential therapeutic targets.},
  archive      = {J_NCA},
  author       = {Ansary Ogholbake, Aram and Cheng, Qiang},
  doi          = {10.1007/s00521-024-10316-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20653-20670},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gene expression clock: An unsupervised deep learning approach for predicting circadian rhythmicity from whole genome expression},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Traffic sign detection and recognition based on MMS data
using YOLOv4-tiny algorithm. <em>NCA</em>, <em>36</em>(33), 20633–20651.
(<a href="https://doi.org/10.1007/s00521-024-10279-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic signs have great importance in driving safety. For the recently emerging autonomous vehicles, that can automatically detect and recognize all road inventories such as traffic signs. Firstly, in this study, a method based on a mobile mapping system (MMS) is proposed for the detection of traffic signs to establish a Turkish traffic sign dataset. Obtaining images from real traffic scenes using the MMS method enhances the reliability of the model. It is an easy method to be applied to real life in terms of both cost and suitability for mobile and autonomous systems. In this frame, YOLOv4-Tiny, one of the object detection algorithms, that is considered to be more suitable for mobile vehicles, is used to detect and recognize traffic signs. This algorithm is low operation cost and more suitable for embedded devices due to its simple neural network structure compared to other algorithms. It is also a better option for real-time detection than other approaches. For the training of the model in the suggested method, a dataset consisting partly of images taken with MMS based on realistic field measurement and partly of images obtained from open data sets was used. This training resulted in the mean average precision (mAP) value being obtained as 98.1%. The trained model was first tested on existing images and then tested in real time in a laboratory environment using a simple fixed web camera. The test results show that the suggested method can improve driving safety by detecting traffic signs quickly and accurately, especially for autonomous vehicles. Therefore, the proposed method is considered suitable for use in autonomous vehicles.},
  archive      = {J_NCA},
  author       = {Gezgin, Hilal and Alkan, Reha Metin},
  doi          = {10.1007/s00521-024-10279-y},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20633-20651},
  shortjournal = {Neural Comput. Appl.},
  title        = {Traffic sign detection and recognition based on MMS data using YOLOv4-tiny algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage algorithm for heterogeneous face recognition
using deep stacked PCA descriptor (DSPD) and coupled discriminant
neighbourhood embedding (CDNE). <em>NCA</em>, <em>36</em>(33),
20617–20631. (<a
href="https://doi.org/10.1007/s00521-024-10272-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic face recognition has made significant progress in recent decades, particularly in controlled environments. However, recognizing faces across different modalities, known as Heterogeneous Face Recognition, presents challenges due to variations in modality gaps. This paper addresses the problem of HFR by proposing a two-stage algorithm. In the first stage, a deep stacked PCA descriptor (DSPD) is introduced to extract domain-invariant features from face images of different modalities. The DSPD utilizes multiple convolution layers of domain-trained PCA filters, and the features extracted from each layer are concatenated to obtain a final feature representation. Additionally, pre-processing steps are applied to input images to enhance the prominence of facial edges, making the features more distinctive. The obtained DSPD features can be directly used for recognition using nearest neighbour algorithms. To further improve recognition robustness, a coupled subspace called coupled discriminant neighbourhood embedding (CDNE) is proposed in the second stage. CDNE is trained with a limited number of data samples and can project DSPD features from different modalities onto a common subspace. In this subspace, data points representing the same subjects from different modalities are positioned closely, while those of different subjects are positioned apart. This spatial arrangement enhances the recognition of heterogeneous faces using nearest neighbour algorithms. Experimental results demonstrate the effectiveness of the proposed algorithm on various HFR scenarios, including VIS-NIR, VIS-Sketch, and VIS-Thermal face pairs from respective databases. The algorithm shows promising performance in addressing the challenges posed by the modality gap, providing a potential solution for accurate and robust Heterogeneous Face Recognition.},
  archive      = {J_NCA},
  author       = {Bhattacharya, Shubhobrata},
  doi          = {10.1007/s00521-024-10272-5},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20617-20631},
  shortjournal = {Neural Comput. Appl.},
  title        = {A two-stage algorithm for heterogeneous face recognition using deep stacked PCA descriptor (DSPD) and coupled discriminant neighbourhood embedding (CDNE)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PRF: Deep neural network compression by systematic pruning
of redundant filters. <em>NCA</em>, <em>36</em>(33), 20607–20616. (<a
href="https://doi.org/10.1007/s00521-024-10256-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep neural networks, the filters of convolutional layers play an important role in extracting the features from the input. Redundant filters often extract similar features, leading to increased computational overhead and larger model size. To address this issue, a two-step approach is proposed in this paper. First, the clusters of redundant filters are identified based on the cosine distance between them using hierarchical agglomerative clustering (HAC). Next, instead of pruning all the redundant filters from every cluster in single-shot, we propose to prune the filters in a systematic manner. To prune the filters, the cluster importance among all clusters and filter importance within each cluster are identified using the $$\ell _1$$ -norm based criterion. Then, based on the pruning ratio filters from the least important cluster to the most important ones are pruned systematically. The proposed method showed better results compared to other clustering-based works. The benchmark datasets CIFAR-10 and ImageNet are used in the experiments. After pruning 83.92% parameters from VGG-16 architecture, an improvement over the baseline is observed. After pruning 54.59% and 49.33% of the FLOPs from ResNet-56 and ResNet-110, respectively, both showed an improvement in accuracy. After pruning 52.97% of the FLOPs, the top-5 accuracy of ResNet-50 drops by only 0.56 over ImageNet.},
  archive      = {J_NCA},
  author       = {Sarvani, C. H. and Ghorai, Mrinmoy and Basha, S. H. Shabbeer},
  doi          = {10.1007/s00521-024-10256-5},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20607-20616},
  shortjournal = {Neural Comput. Appl.},
  title        = {PRF: Deep neural network compression by systematic pruning of redundant filters},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HMedCaps: A new hybrid capsule network architecture for
complex medical images. <em>NCA</em>, <em>36</em>(33), 20589–20606. (<a
href="https://doi.org/10.1007/s00521-024-10147-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing and analyzing medical images is crucial for disease early detection and treatment planning with appropriate treatment options based on the patient&#39;s individual needs and disease history. Deep learning technologies are widely used in the field of healthcare because they can analyze images rapidly and precisely. However, because each object on the image has the potential to hold illness information in medical images, it is critical to analyze the images with minimal information loss. In this context, Capsule Network (CapsNet) architecture is an important approach that aims to reduce information loss by storing the location and properties of objects in images as capsules. However, because CapsNet maintains information on each object in the image, the existence of several objects in complicated images can impair CapsNet&#39;s performance. This work proposes a new model called HMedCaps to improve the performance of CapsNet. In the proposed model, it is aimed to develop a deeper and hybrid structure by using Residual Block and FractalNet module together in the feature extraction layer. While it is aimed to obtain rich feature maps by increasing the number of features extracted by deepening the network, it is aimed to prevent the vanishing gradient problem that may occur in the network with increasing depth with these modules with skip connections. Furthermore, a new squash function is proposed to make distinctive capsules more prominent by customizing capsule activation. The CIFAR10 dataset of complex images, RFMiD dataset of retinal images, and Blood Cell Count Dataset dataset of blood cell images were used to evaluate the study. When the proposed model was compared with the basic CapsNet and studies in the literature, it was observed that the performance in complex images was improved and more accurate classification results were obtained in the field of medical image analysis. The proposed hybrid HMedCaps architecture has the potential to make more accurate diagnoses in the field of medical image analysis.},
  archive      = {J_NCA},
  author       = {Sengul, Sumeyra Busra and Ozkan, Ilker Ali},
  doi          = {10.1007/s00521-024-10147-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {33},
  pages        = {20589-20606},
  shortjournal = {Neural Comput. Appl.},
  title        = {HMedCaps: A new hybrid capsule network architecture for complex medical images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A predictive and explanatory model for remaining useful life
of crushers using deep learning. <em>NCA</em>, <em>36</em>(32),
20575–20588. (<a
href="https://doi.org/10.1007/s00521-024-10308-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current maintenance models lack the technological capabilities to generate key performance indicators that optimize both critical equipment behavior and the surrounding processes. Artificial intelligence offers powerful tools for predicting and interpreting sensor data collected from such equipment, enabling continuous improvement. This paper proposes a tool that leverages deep learning to predict the remaining useful life (RUL) of a large-scale mining crusher. Additionally, the model incorporates result interpretation algorithms to analyze both training cycles and subsequent production cycles. This analysis not only identifies a process &quot;fingerprint&quot; but also recommends adjustments to the crusher system within the ongoing maintenance plan. By employing a dense neural network and interpretation algorithms, the proposed tool predicts the current crusher cycle’s RUL and compares its interpretation graphs to the process fingerprint. This comparison identifies discrepancies, which in turn inform maintenance recommendations tailored to specific crusher components.},
  archive      = {J_NCA},
  author       = {Kristjanpoller, Fredy and Vásquez, Raymi and Kristjanpoller, Werner and Minutolo, Marcel C. and Jackson, Canek},
  doi          = {10.1007/s00521-024-10308-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20575-20588},
  shortjournal = {Neural Comput. Appl.},
  title        = {A predictive and explanatory model for remaining useful life of crushers using deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing AI methods for forecasting polyester fabric
tensile property. <em>NCA</em>, <em>36</em>(32), 20561–20574. (<a
href="https://doi.org/10.1007/s00521-024-10284-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensile properties of multifilament polyester woven fabrics are of great importance for their end uses such as parachutes, sails, tents, sleeping bags, filters and surgical textiles. The filament fineness, weave type and weave density have a great influence on the tensile properties of these fabrics. In this study, artificial intelligence (AI) models such as artificial neural networks (ANN), fuzzy logic (FL) and genetic algorithms (GA) were developed to forecast breaking strength and breaking elongation values of multifilament polyester woven fabrics. The fabric samples used in the study have three different microfilament finenesses and two different conventional filament finenesses with plain, twill and satin weave types. By applying four different weft density values, totally 60 woven fabric samples were obtained in the experimental design. The regression coefficient values ( $${R}^{2}$$ ) between actual and predicted results were obtained as 0.80, 0.90 and 0.92 with ANN, FL and ANN–GA hybrid methods, respectively. The mean absolute percentage error (MAPE) was lower than 6% for all AI techniques used in this study. As a conclusion, it was proved that the breaking strength and breaking elongation properties of multifilament polyester woven fabrics can be forecasted with high accuracy rates by AI techniques.},
  archive      = {J_NCA},
  author       = {Ayaz, Nurselin Özkan and Çelik, Halil İbrahim and Kaynak, Hatice Kübra},
  doi          = {10.1007/s00521-024-10284-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20561-20574},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparing AI methods for forecasting polyester fabric tensile property},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new approach for automatic classification of non-hodgkin
lymphoma using deep learning and classical learning methods on
histopathological images. <em>NCA</em>, <em>36</em>(32), 20537–20560.
(<a href="https://doi.org/10.1007/s00521-024-10229-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lymph cancer, also known as lymphoma, refers to the uncontrolled proliferation of the body&#39;s defensive cells, resulting in their transformation into cancerous cells. Lymphoma belongs to the group of blood cancers and exhibits a higher incidence compared to other cancers within this category. Early and accurate diagnosis plays a crucial role in managing this disease. In this particular investigation, an expert support system was developed employing histopathological images of lymph cancer. The data set comprised images of various lymphomas, including chronic lymphocytic leukemia (CLL), follicular lymphoma (FL), and mantle cell lymphoma (MCL). The initial approach involved utilizing the GLCM method to extract features from these images, while subsequent approaches adopted transfer learning architectures. Additionally, principal component analysis was employed for feature selection and dimension reduction. For the classification stage, a combination of machine learning algorithms such as random forests, k-nearest neighbors (KNN), naive Bayes, and decision trees, as well as deep learning methods including VGG16, ResNet50, and DenseNet201 architectures were employed. The models were trained separately for double and triple classes, and their performance was evaluated. The highest accuracy values in binary classification are: 94% for CLL and FL, 92% for FL and MCL, and 82% for MCL and CLL. In triple classification, the highest accuracy rate is 82%. The lowest accuracy values in binary classification are: 52% for CLL and FL, 57% for FL and MCL, and 49% for MCL and CLL. The methods by which these accuracy values were obtained are stated in &quot;Results&quot; section. However, due to the difficulty in distinguishing between MCL- and CLL-type lymphomas, the classification accuracy for these lymphomas was lower compared to the other classifications. On the other hand, the classification accuracy for FL was higher, as it exhibits more distinctive features than the other two lymphomas. The lowest success in the study was achieved at 36% as a result of the use of the KNN algorithm in triple classification. Notably, the DenseNet201 method achieved the highest success in the study, accurately classifying FL and CLL with a 94% accuracy rate.},
  archive      = {J_NCA},
  author       = {Özgür, Emine and Saygılı, Ahmet},
  doi          = {10.1007/s00521-024-10229-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20537-20560},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new approach for automatic classification of non-hodgkin lymphoma using deep learning and classical learning methods on histopathological images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introduction to the blockchain, bitcoin, and other
cryptocurrencies for educators. <em>NCA</em>, <em>36</em>(32),
20527–20536. (<a
href="https://doi.org/10.1007/s00521-024-10209-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of blockchain technology and the emergence of cryptocurrencies, most notably Bitcoin, have transformed the landscape of finance and technology. This article fulfills three main roles: The first is to show the rapid rate that these technologies are affecting the global landscape, emphasizing the compelling need to integrate these topics into educational curricula, as enabling students to grasp the intricacies of decentralized systems and digital currencies will soon be necessary for their full economic participation in society. Second, this article introduces the concepts of blockchain and Bitcoin, presenting their foundational principles followed by their relationship. Both are viewed in terms of their historical development while emphasizing their decentralized and immutable nature, cryptographic security, and blockchain’s potential applications beyond cryptocurrencies. Third, this article presents several perspectives from which blockchain, Bitcoin, and other cryptocurrencies might be taught, including historical, technological, legal, social, economic, political, and environmental contexts.},
  archive      = {J_NCA},
  author       = {Tommerdahl, Jodi},
  doi          = {10.1007/s00521-024-10209-y},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20527-20536},
  shortjournal = {Neural Comput. Appl.},
  title        = {Introduction to the blockchain, bitcoin, and other cryptocurrencies for educators},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging time-based acoustic patterns for ecosystem
analysis. <em>NCA</em>, <em>36</em>(32), 20513–20526. (<a
href="https://doi.org/10.1007/s00521-024-10157-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passive acoustic monitoring (PAM) is an effective, non-intrusive method for studying ecosystems, but obtaining meaningful ecological information from its large number of audio files is challenging. In this study, we take advantage of the expected animal behavior at different times of the day (e.g., higher acoustic animal activity at dawn) and develop a novel approach to use these time-based patterns. We organize PAM data into 24-hour temporal blocks formed with sound features from a pretrained VGGish network. These features feed a 1D convolutional neural network with a class activation mapping technique that gives interpretability to its outcomes. As a result, these diel-cycle blocks offer more accurate and robust hour-by-hour information than using traditional ecological acoustic indices as features, effectively recognizing key ecosystem patterns.},
  archive      = {J_NCA},
  author       = {Castro-Ospina, Andrés E. and Rodríguez-Marín, Paula and López, José D. and Martínez-Vargas, Juan D.},
  doi          = {10.1007/s00521-024-10157-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20513-20526},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging time-based acoustic patterns for ecosystem analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Golden lichtenberg algorithm: A fibonacci sequence approach
applied to feature selection. <em>NCA</em>, <em>36</em>(32),
20493–20511. (<a
href="https://doi.org/10.1007/s00521-024-10155-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational and technological advancements have led to an increase in data generation and storage capacity. Many annotated datasets have been used to train machine learning models for predictive tasks. Feature selection (FS) is a combinatorial binary optimization problem that arises from a need to reduce dataset dimensionality by finding the subset of features with maximum predictive accuracy. While different methodologies have been proposed, metaheuristics adapted to binary optimization have proven to be reliable and efficient techniques for FS. This paper applies the first and unique population-trajectory metaheuristic, the Lichtenberg algorithm (LA), and enhances it with a Fibonacci sequence to improve its exploration capabilities in FS. Substituting the random scales that controls the Lichtenberg figures&#39; size and the population distribution in the original version by a sequence based on the golden ratio, a new optimal exploration–exploitation LF&#39;s size decay is presented. The new few hyperparameters golden Lichtenberg algorithm (GLA), LA, and eight other popular metaheuristics are then equipped with the v-shaped transfer function and associated with the K-nearest neighbor classifier in the search of the optimized feature subsets through a double cross-validation experiment method on 15 UCI machine learning repository datasets. The binary GLA selected reduced subsets of features, leading to the best predictive accuracy and fitness values at the lowest computational cost.},
  archive      = {J_NCA},
  author       = {Pereira, João Luiz Junho and Francisco, Matheus Brendon and Ma, Benedict Jun and Gomes, Guilherme Ferreira and Lorena, Ana Carolina},
  doi          = {10.1007/s00521-024-10155-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20493-20511},
  shortjournal = {Neural Comput. Appl.},
  title        = {Golden lichtenberg algorithm: A fibonacci sequence approach applied to feature selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved hybrid feature extractor in lightweight
convolutional neural network for postharvesting technology: Automated
oil palm fruit grading. <em>NCA</em>, <em>36</em>(32), 20473–20491. (<a
href="https://doi.org/10.1007/s00521-024-10300-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grading of oil palm fresh fruit bunches (FFB) plays a vital role in the postharvest operation as it directly influences the extraction rate of oil palm, thereby ensuring quality control in the estate and mill. Currently, manual grading based on visual assessment is employed, but it has limitations mainly due to subjective judgment-influenced factors such as visual resemblance, light intensities, and differences in colors across ripeness categories. Hence, an automated oil palm fruit grading system in postharvest technology is proposed to enhance the grading process and improve productivity while maintaining operational cost efficiency. This work involves developing an improved object detection model based on the You Only Look Once model to accurately identify four grades of oil palm FFB, namely, ripe, unripe, underripe, and overripe. The proposed model incorporated several improvements, including a hybrid feature extractor comprising mobile inverted bottleneck module and densely connected neural network. Additionally, it employs a spatial pyramid pooling structure to expand the receptive field and utilizes the complete intersection over union function for bounding box regression. The results indicate that the proposed model obtains a remarkable mAP of 94.37% and an F1-score of 0.89. Besides, the model performs real-time detection at a faster rate of 4.8 FPS on a limited-capacity embedded device, NVIDIA Jetson Nano. The comprehensive experimental results confirm the superiority of the proposed model over various detection models.},
  archive      = {J_NCA},
  author       = {Junos, Mohamad Haniff and Mohd Khairuddin, Anis Salwa and Abu Talip, Mohamad Sofian and Kairi, Muhammad Izhar and Siran, Yosri Mohd},
  doi          = {10.1007/s00521-024-10300-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20473-20491},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved hybrid feature extractor in lightweight convolutional neural network for postharvesting technology: Automated oil palm fruit grading},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial neural network-based risk assessment for
occupational accidents in the shipbuilding industry in turkey.
<em>NCA</em>, <em>36</em>(32), 20457–20471. (<a
href="https://doi.org/10.1007/s00521-024-10292-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accidents in the workplace are critical issues that necessitate attention from environmental safety and health perspectives to enhance operational safety. The elevated rate of workplace accidents in Turkey underscores deficiencies in reliability analysis studies. Effective planning of preventive measures, considering factors such as location and timing, is pivotal in accident prevention. Sociological and regional disparities, alongside technical factors such as service type, working hours, and age, contribute significantly to accident causation. Reliability analysis studies aim to identify potential causes of accidents, enabling early detection of hazardous situations and combinations. This proactive approach allows responsible personnel to implement measures that mitigate or eliminate specific types of accidents, thereby safeguarding both lives and business assets. This study utilizes Artificial Neural Network (ANN) to forecast potential occupational accidents in the shipbuilding industry before they occur. Analyzing data from 146 occupational accidents involving ship electricians between 2012 and 2016, out of a total of 1165 occupational accidents in the industry, the study estimates potential accidents for 2017. The results demonstrate that ANN achieves high accuracy in predicting occupational accidents.},
  archive      = {J_NCA},
  author       = {Dizdar, Ercüment N. and Koçar, Oğuz},
  doi          = {10.1007/s00521-024-10292-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20457-20471},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural network-based risk assessment for occupational accidents in the shipbuilding industry in turkey},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive dissimilarity: Optimizing performance on
imbalanced and limited data sets. <em>NCA</em>, <em>36</em>(32),
20439–20456. (<a
href="https://doi.org/10.1007/s00521-024-10286-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primary challenge in pattern recognition is imbalanced datasets, resulting in skewed and biased predictions. This problem is exacerbated by limited data availability, increasing the reliance on expensive expert data labeling. The study introduces a novel method called contrastive dissimilarity, which combines dissimilarity-based representation with contrastive learning to improve classification performance in imbalance and data scarcity scenarios. Based on pairwise sample differences, dissimilarity representation excels in situations with numerous overlapping classes and limited samples per class. Unlike traditional methods that use fixed distance functions like Euclidean or cosine, our proposal employs metric learning with contrastive loss to estimate a custom dissimilarity function. We conducted extensive evaluations in 13 databases across multiple training–test splits. The results showed that this approach outperforms traditional models like SVM, random forest, and Naive Bayes, particularly in settings with limited training data.},
  archive      = {J_NCA},
  author       = {Teixeira, Lucas O. and Bertolini, Diego and Oliveira, Luiz S. and Cavalcanti, George D. C. and Costa, Yandre M. G.},
  doi          = {10.1007/s00521-024-10286-z},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20439-20456},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contrastive dissimilarity: Optimizing performance on imbalanced and limited data sets},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving hierarchical federated learning with
biosignals to detect drowsiness while driving. <em>NCA</em>,
<em>36</em>(32), 20425–20437. (<a
href="https://doi.org/10.1007/s00521-024-10282-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the global safety concern of drowsiness during driving, the European Union enforces that new vehicles must integrate detection systems compliant with the general data protection regulation. To identify drowsiness patterns while preserving drivers’ data privacy, recent literature has combined Federated Learning (FL) with different biosignals, such as facial expressions, heart rate, electroencephalography (EEG), or electrooculography (EOG). However, existing solutions are unsuitable for drowsiness detection where heterogeneous stakeholders want to collaborate at different levels while guaranteeing data privacy. There is a lack of works evaluating the benefits of using Hierarchical FL (HFL) with EEG and EOG biosignals, and comparing HFL over traditional FL and Machine Learning (ML) approaches to detect drowsiness at the wheel while ensuring data confidentiality. Thus, this work proposes a flexible framework for drowsiness identification by using HFL, FL, and ML over EEG and EOG data. To validate the framework, this work defines a scenario of three transportation companies aiming to share data from their drivers without compromising their confidentiality, defining a two-level hierarchical structure. This study presents three incremental Use Cases (UCs) to assess detection performance: UC1) intra-company FL, yielding a 77.3% accuracy while ensuring the privacy of individual drivers’ data; UC2) inter-company FL, achieving 71.7% accuracy for known drivers and 67.1% for new subjects, ensuring data confidentiality between companies but not intra-organization; and UC3) HFL inter-company, which ensured comprehensive data privacy both within and between companies, with an accuracy of 71.9% for training subjects and 65.5% for new subjects.},
  archive      = {J_NCA},
  author       = {López Bernal, Sergio and Hidalgo Rogel, José Manuel and Martínez Beltrán, Enrique Tomás and Quiles Pérez, Mario and Martínez Pérez, Gregorio and Huertas Celdrán, Alberto},
  doi          = {10.1007/s00521-024-10282-3},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20425-20437},
  shortjournal = {Neural Comput. Appl.},
  title        = {Privacy-preserving hierarchical federated learning with biosignals to detect drowsiness while driving},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental federated learning for traffic flow
classification in heterogeneous data scenarios. <em>NCA</em>,
<em>36</em>(32), 20401–20424. (<a
href="https://doi.org/10.1007/s00521-024-10281-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the comparative analysis of federated learning (FL) and centralized learning (CL) models in the context of multi-class traffic flow classification for network applications, a timely study in the context of increasing privacy preservation concerns. Unlike existing literature that often omits detailed class-wise performance evaluation, and consistent data handling and feature selection approaches, our study rectifies these gaps by implementing a feed-forward neural network and assessing FL performance under both independent and identically distributed (IID) and non-independent and identically distributed (non-IID) conditions, with a particular focus on incremental training. In our cross-silo experimental setup involving five clients per round, FL models exhibit notable adaptability. Under IID conditions, the accuracy of the FL model peaked at 96.65%, demonstrating its robustness. Moreover, despite the challenges presented by non-IID environments, our FL models demonstrated significant resilience, adapting incrementally over rounds to optimize performance; in most scenarios, our FL models performed comparably to the idealistic CL model regarding multiple well-established metrics. Through a comprehensive traffic flow classification use case, this work (i) contributes to a better understanding of the capabilities and limitations of FL, offering valuable insights for the real-world deployment of FL, and (ii) provides a novel, large, carefully curated traffic flow dataset for the research community.},
  archive      = {J_NCA},
  author       = {Pekar, Adrian and Makara, Laszlo Arpad and Biczok, Gergely},
  doi          = {10.1007/s00521-024-10281-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20401-20424},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incremental federated learning for traffic flow classification in heterogeneous data scenarios},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing entity alignment with dangling cases: A
structure-aware approach through optimal transport learning and
contrastive learning. <em>NCA</em>, <em>36</em>(32), 20387–20400. (<a
href="https://doi.org/10.1007/s00521-024-10276-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) aims to discover the equivalent entities in different knowledge graphs (KGs), which plays an important role in knowledge engineering. Recently, EA with dangling entities has been proposed as a more realistic setting, which assumes that not all entities have corresponding equivalent entities. In this paper, we focus on this setting. Some work has explored this problem by leveraging translation API, pre-trained word embeddings, and other off-the-shelf tools. However, these approaches over-rely on the side information (e.g., entity names) and fail to work when the side information is absent. On the contrary, they still insufficiently exploit the most fundamental graph structure information in KG. To improve the exploitation of the structural information, we propose a novel entity alignment framework called Structure-aware Wasserstein Graph Contrastive Learning (SWGCL), which is refined on three dimensions: (i) Model. We propose a novel Gated Graph Attention Network to capture local and global graph structure attention. (ii) Training. Two learning objectives: contrastive learning and optimal transport learning, are designed to obtain distinguishable entity representations. (iii) Inference. In the inference phase, a PageRank-based method HOSS (Higher-Order Structural Similarity) is proposed to calculate higher-order graph structural similarity. Extensive experiments on two dangling benchmarks demonstrate that our SWGCL outperforms the current state-of-the-art methods with pure structural information in both traditional (relaxed) and dangling (consolidated) settings.},
  archive      = {J_NCA},
  author       = {Xu, Jin and Li, Yangning and Xie, Xiangjin and Hu, Niu and Li, Yinghui and Zheng, Hai-Tao and Jiang, Yong},
  doi          = {10.1007/s00521-024-10276-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20387-20400},
  shortjournal = {Neural Comput. Appl.},
  title        = {Advancing entity alignment with dangling cases: A structure-aware approach through optimal transport learning and contrastive learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel gray wolf optimization-based key frame extraction
method for video classification using ConvLSTM. <em>NCA</em>,
<em>36</em>(32), 20355–20385. (<a
href="https://doi.org/10.1007/s00521-024-10266-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel keyframe extraction extraction method based on the gray wolf optimization (GWO) algorithm, addressing the challenge of information loss in traditional methods due to redundant and similar frames. The proposed method GWOKConvLSTM prioritizes speed, accuracy, and compression efficiency while preserving semantic information. Inspired by wolf behavior, we construct a fitness function that minimizes reconstruction error and achieves optimal compression ratios below 8%. Compared to traditional methods, our GWO method achieves the lowest reconstruction error for a given compression rate, providing a concise and visually coherent summary of keyframes while maintaining consistency across similar motions. Additionally, we propose a template-based method for video classification tasks, achieving the highest accuracy when combined with pre-trained CNNs and ConvLSTM. Our method effectively prevents dynamic background noise from affecting keyframe selection, leading to significantly improve video classification performance using deep neural networks.},
  archive      = {J_NCA},
  author       = {Gawande, Ujwalla and Hajari, Kamal and Golhar, Yogesh and Fulzele, Punit},
  doi          = {10.1007/s00521-024-10266-3},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20355-20385},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel gray wolf optimization-based key frame extraction method for video classification using ConvLSTM},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vpit: Real-time embedded single object 3D tracking using
voxel pseudo images. <em>NCA</em>, <em>36</em>(32), 20341–20354. (<a
href="https://doi.org/10.1007/s00521-024-10259-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel voxel-based 3D single object tracking (3D SOT) method called Voxel Pseudo Image Tracking (VPIT). VPIT is the first method that uses voxel pseudo images for 3D SOT. The input point cloud is structured by pillar-based voxelization, and the resulting pseudo image is used as an input to a 2D-like Siamese SOT method. The pseudo image is created in the Bird’s-eye View (BEV) coordinates; and therefore, the objects in it have constant size. Thus, only the object rotation can change in the new coordinate system and not the object scale. For this reason, we replace multi-scale search with a multi-rotation search, where differently rotated search regions are compared against a single target representation to predict both position and rotation of the object. Experiments on KITTI [1] Tracking dataset show that VPIT is the fastest 3D SOT method and maintains competitive Success and Precision values. Application of a SOT method in a real-world scenario meets with limitations such as lower computational capabilities of embedded devices and a latency-unforgiving environment, where the method is forced to skip certain data frames if the inference speed is not high enough. We implement a real-time evaluation protocol and show that other methods lose most of their performance on embedded devices; while, VPIT maintains its ability to track the object.},
  archive      = {J_NCA},
  author       = {Oleksiienko, Illia and Nousi, Paraskevi and Passalis, Nikolaos and Tefas, Anastasios and Iosifidis, Alexandros},
  doi          = {10.1007/s00521-024-10259-2},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20341-20354},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vpit: Real-time embedded single object 3D tracking using voxel pseudo images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). YOLOv7 for brain tumour detection using morphological
transfer learning model. <em>NCA</em>, <em>36</em>(32), 20321–20340. (<a
href="https://doi.org/10.1007/s00521-024-10246-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate diagnosis of a brain tumour in its early stages is required to improve the possibility of survival for cancer patients. Due to the structural complexity of the brain, it has become very difficult and tedious for neurologists and radiologists to diagnose brain tumours in the initial stages with the help of various common manual approaches to tumour diagnosis. To improve the performance of the diagnosis, some computer-aided diagnosis-based systems are developed with the concepts of artificial intelligence. In this proposed manuscript, we analyse various computer-aided design (CAD)-based approaches and design a modern approach with ideas of transfer learning over deep learning on magnetic resonance imaging (MRI). In this study, we apply a transfer learning approach with the object detection model YOLO (You Only Look Once) and analyse the MRI dataset with the various modified versions of YOLO. After the analysis, we propose an object detection model based on the modified YOLOv7 with a morphological filtering approach to reach an efficient and accurate diagnosis. To enhance the performance accuracy of this suggested model, we also analyse the various versions of YOLOv7 models and find that the proposed model having the YOLOv7-E6E object detection technique gives the optimum value of performance indicators as precision, recall, F1, and mAP@50 as 1, 0.92, 0.958333, and 0.974, respectively. The value of mAP@50 improves to 0.992 by introducing a morphological filtering approach before the object detection technique. During the complete analysis of the suggested model, we use the BraTS 2021 dataset. The BraTS 2021 dataset has brain MR images from the RSNA-MICCAI brain tumour radiogenetic competition, and the complete dataset is labelled using the online tool MakeSense AI.},
  archive      = {J_NCA},
  author       = {Pandey, Sanat Kumar and Bhandari, Ashish Kumar},
  doi          = {10.1007/s00521-024-10246-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20321-20340},
  shortjournal = {Neural Comput. Appl.},
  title        = {YOLOv7 for brain tumour detection using morphological transfer learning model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing dynamic ensemble selection: Combining
self-generating prototypes and meta-classifier for data classification.
<em>NCA</em>, <em>36</em>(32), 20295–20320. (<a
href="https://doi.org/10.1007/s00521-024-10237-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In dynamic ensemble selection (DES) techniques, the competence level of each classifier is estimated from a pool of classifiers, and only the most competent ones are selected to classify a specific test sample and predict its class labels. A significant challenge in DES is efficiently estimating classifier competence for accurate prediction, especially when these techniques employ the K-Nearest Neighbors (KNN) algorithm to define the competence region of a test sample based on a validation set (known as the dynamic selection dataset or DSEL). This challenge is exacerbated when the DSEL does not accurately reflect the original data distribution or contains noisy data. Such conditions can reduce the precision of the system, induce unexpected behaviors, and compromise stability. To address these issues, this paper introduces the self-generating prototype ensemble selection (SGP.DES) framework, which combines meta-learning with prototype selection. The proposed meta-classifier of SGP.DES supports multiple classification algorithms and utilizes meta-features from prototypes derived from the original training set, enhancing the selection of the best classifiers for a test sample. The method improves the efficiency of KNN in defining competence regions by generating a reduced and noise-free DSEL set that preserves the original data distribution. Furthermore, the SGP.DES framework facilitates tailored optimization for specific classification challenges through the use of hyperparameters that control prototype selection and the meta-classifier operation mode to select the most appropriate classification algorithm for dynamic selection. Empirical evaluations of twenty-four classification problems have demonstrated that SGP.DES outperforms state-of-the-art DES methods as well as traditional single-model and ensemble methods in terms of accuracy, confirming its effectiveness across a wide range of classification contexts.},
  archive      = {J_NCA},
  author       = {Manastarla, Alberto and Silva, Leandro A.},
  doi          = {10.1007/s00521-024-10237-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20295-20320},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing dynamic ensemble selection: Combining self-generating prototypes and meta-classifier for data classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). One-shot knowledge graph completion based on disentangled
representation learning. <em>NCA</em>, <em>36</em>(32), 20277–20293. (<a
href="https://doi.org/10.1007/s00521-024-10236-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-shot knowledge graph completion (KGC) aims to infer unseen facts when only one support entity pair is available for a particular relationship. Prior studies learn reference representations from one support pair for matching query pairs. This strategy can be challenging, particularly when dealing with multiple relationships between identical support pairs, resulting in indistinguishable reference representations. To this end, we propose a disentangled representation learning framework for one-shot KGC. Specifically, to learn sufficient representations, we construct an entity encoder with a fine-grained attention mechanism to explicitly model the input and output neighbors. We adopt an orthogonal regularizer to promote the independence of learned factors in entity representation, enabling the matching processor with max pooling to adaptively identify the semantic roles associated with a particular relation. Subsequently, the one-shot KGC is accomplished by seamlessly integrating the aforementioned modules in an end-to-end learning manner. Extensive experiments on real-world datasets demonstrate the outperformance of the proposed framework.},
  archive      = {J_NCA},
  author       = {Zhang, Youmin and Sun, Lei and Wang, Ye and Liu, Qun and Liu, Li},
  doi          = {10.1007/s00521-024-10236-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20277-20293},
  shortjournal = {Neural Comput. Appl.},
  title        = {One-shot knowledge graph completion based on disentangled representation learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing CNN model classification performance through RGB
angle rotation method. <em>NCA</em>, <em>36</em>(32), 20259–20276. (<a
href="https://doi.org/10.1007/s00521-024-10232-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, convolutional neural networks have significantly advanced the field of computer vision by automatically extracting features from image data. CNNs enable the modeling of complex and abstract image features using learnable filters, eliminating the need for manual feature extraction. However, combining feature maps obtained from CNNs with different approaches can lead to more complex and interpretable inferences, thereby enhancing model performance and generalizability. In this study, we propose a new method called RGB angle rotation to effectively obtain feature maps from RGB images. Our method rotates color channels at different angles and uses the angle information between channels to generate new feature maps. We then investigate the effects of integrating models trained with these feature maps into an ensemble architecture. Experimental results on the CIFAR-10 dataset show that using the proposed method in the ensemble model results in performance increases of 9.10 and 8.42% for the B and R channels, respectively, compared to the original model, while the effect of the G channel is very limited. For the CIFAR-100 dataset, the proposed method resulted in a 17.09% improvement in ensemble model performance for the R channel, a 5.06% increase for the B channel, and no significant improvement for the G channel compared to the original model. Additionally, we compared our method with traditional feature extraction methods like scale-invariant feature transform and local binary pattern and observed higher performance. In conclusion, it has been observed that the proposed RGB angle rotation method significantly impacts model performance.},
  archive      = {J_NCA},
  author       = {Dogan, Yahya and Ozdemir, Cuneyt and Kaya, Yılmaz},
  doi          = {10.1007/s00521-024-10232-z},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20259-20276},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing CNN model classification performance through RGB angle rotation method},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking of BERT sentence embedding for text
classification. <em>NCA</em>, <em>36</em>(32), 20245–20258. (<a
href="https://doi.org/10.1007/s00521-024-10212-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification is a fundamental task in NLP that is used in several real-life tasks and applications. Large pre-trained language models such as BERT achieve state-of-the-art performance in several NLP tasks including text classification tasks. Although BERT boosts text classification performance, the common way of using it for classification lacks many aspects of its advantages. This work rethinks the way of using BERT final layer and hidden layers embeddings by proposing different aggregation architectures for text classification tasks such as sentiment analysis and sarcasm detection. This research also proposes different approaches for using BERT as a feature extractor without fine-tuning whose performance surpasses its fine-tuning counterpart. It also proposes promising multi-task learning aggregation architectures to improve the performance of the related classification problems. The experiments of the different architectures show that freezing BERT can outperform fine-tuning it for sentiment analysis. The experiments also show that multi-task learning while freezing BERT boosts the performance of yet hard tasks such as sarcasm detection. The best-performing models achieved new state-of-the-art performance on the ArSarcasm-v2 dataset for Arabic sarcasm detection and sentiment analysis. For multi-task learning and freezing BERT, a new SOTA F1-score of 64.41 was achieved for the sarcasm detection with a 3.47% improvement and near SOTA FPN of 75.78 for the sentiment classification. For single-task learning, a new SOTA FPN of 75.26 was achieved for the sentiment with a 1.81% improvement.},
  archive      = {J_NCA},
  author       = {Galal, Omar and Abdel-Gawad, Ahmed H. and Farouk, Mona},
  doi          = {10.1007/s00521-024-10212-3},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20245-20258},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rethinking of BERT sentence embedding for text classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional image-to-image translation generative
adversarial network (cGAN) for fabric defect data augmentation.
<em>NCA</em>, <em>36</em>(32), 20231–20244. (<a
href="https://doi.org/10.1007/s00521-024-10179-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of comprehensive datasets is a crucial challenge for developing artificial intelligence (AI) models in various applications and fields. The lack of large and diverse public fabric defect datasets forms a major obstacle to properly and accurately developing and training AI models for detecting and classifying fabric defects in real-life applications. Models trained on limited datasets struggle to identify underrepresented defects, reducing their practicality. To address these issues, this study suggests using a conditional generative adversarial network (cGAN) for fabric defect data augmentation. The proposed image-to-image translator GAN features a conditional U-Net generator and a 6-layered PatchGAN discriminator. The conditional U-Network (U-Net) generator can produce highly realistic synthetic defective samples and offers the ability to control various characteristics of the generated samples by taking two input images: a segmented defect mask and a clean fabric image. The segmented defect mask provides information about various aspects of the defects to be added to the clean fabric sample, including their type, shape, size, and location. By augmenting the training dataset with diverse and realistic synthetic samples, the AI models can learn to identify a broader range of defects more accurately. This technique helps overcome the limitations of small or unvaried datasets, leading to improved defect detection accuracy and generalizability. Moreover, this proposed augmentation method can find applications in other challenging fields, such as generating synthetic samples for medical imaging datasets related to brain and lung tumors.},
  archive      = {J_NCA},
  author       = {Mohammed, Swash Sami and Clarke, Hülya Gökalp},
  doi          = {10.1007/s00521-024-10179-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20231-20244},
  shortjournal = {Neural Comput. Appl.},
  title        = {Conditional image-to-image translation generative adversarial network (cGAN) for fabric defect data augmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing precision agriculture: Domain-specific
augmentations and robustness testing for convolutional neural networks
in precision spraying evaluation. <em>NCA</em>, <em>36</em>(32),
20211–20229. (<a
href="https://doi.org/10.1007/s00521-024-10142-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern agriculture relies heavily on the precise application of chemicals such as fertilisers, herbicides, and pesticides, which directly affect both crop yield and environmental footprint. Therefore, it is crucial to assess the accuracy of precision sprayers regarding the spatial location of spray deposits. However, there is currently no fully automated evaluation method for this. In this study, we collected a novel dataset from a precision spot spraying system to enable us to classify and detect spray deposits on target weeds and non-target crops. We employed multiple deep convolutional backbones for this task; subsequently, we have proposed a robustness testing methodology for evaluation purposes. We experimented with two novel data augmentation techniques: subtraction and thresholding which enhanced the classification accuracy and robustness of the developed models. On average, across nine different tests and four distinct convolutional neural networks, subtraction improves robustness by 50.83%, and thresholding increases by 42.26% from a baseline. Additionally, we have presented the results from a novel weakly supervised object detection task using our dataset, establishing a baseline Intersection over Union score of 42.78%. Our proposed pipeline includes an explainable artificial intelligence stage and provides insights not only into the spatial location of the spray deposits but also into the specific filtering methods within that spatial location utilised for classification.},
  archive      = {J_NCA},
  author       = {Rogers, Harry and De La Iglesia, Beatriz and Zebin, Tahmina and Cielniak, Grzegorz and Magri, Ben},
  doi          = {10.1007/s00521-024-10142-0},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20211-20229},
  shortjournal = {Neural Comput. Appl.},
  title        = {Advancing precision agriculture: Domain-specific augmentations and robustness testing for convolutional neural networks in precision spraying evaluation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization of energy consumption of oil refinery reboiler
and condenser using neural network. <em>NCA</em>, <em>36</em>(32),
20193–20209. (<a
href="https://doi.org/10.1007/s00521-024-10049-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distillation tower is a crucial component of the refining process. Its energy efficiency has been a major area of research, especially following the oil crisis. This study focuses on optimizing energy consumption in the Shiraz refinery’s distillation unit. The unit is simulated using ASPEN-HYSYS software. Simulation results are validated against real data to ensure model accuracy. The operational data aligns well with model predictions. Following the creation of a data bank using HYSYS software, the tower’s operating conditions are optimized using neural networks and MATLAB software. In this study, a neural network model is developed for the distillation tower. This modeling approach is cost-effective, does not require complex theories, and does not rely on prior system knowledge. Additionally, real-time modeling is achievable through parallel distributed processing. The findings indicate that the optimal feed tray is 9 and the optimal feed temperature is 283.5°C. Furthermore, the optimized number of trays in the distillation tower is 47. Results show that in optimal conditions, cold and hot energy consumption are reduced by approximately 9.7% and 10.8%, respectively. Moreover, implementing optimal conditions results in a reduction of hot energy consumption in the reboiler by 60,000 MW and a reduction of cold energy consumption in the condenser by 30,000 MW.},
  archive      = {J_NCA},
  author       = {Farahbod, Farshad},
  doi          = {10.1007/s00521-024-10049-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20193-20209},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization of energy consumption of oil refinery reboiler and condenser using neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Short-term load forecasting: Cascade intuitionistic fuzzy
time series—univariate and bivariate models. <em>NCA</em>,
<em>36</em>(32), 20167–20192. (<a
href="https://doi.org/10.1007/s00521-024-10280-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term load forecasting (STLF) is essential for developing reliable and sustainable economic and operational strategies for power systems. This study presents a forecasting model combining cascade forward neural network (CFNN) and intuitionistic fuzzy time series (IFTS) models for STLF. The proposed cascading intuitionistic fuzzy time series forecasting model (C-IFTS-FM) offers the advantage of CFNN using the links of both linear and nonlinear to model fuzzy relations between inputs and outputs. Moreover, it offers a more reliable and realistic approach to uncertainty, taking notice of also the degree of hesitation. C-IFTS-FM works in univariate structure when it uses only hourly load data, and in bivariate structure when it uses hourly load data and hourly temperature time series together. The conversion of time series into IFTS is realized with intuitionistic fuzzy c-means (IFCM). Thus, the membership and non-membership values for each data point are produced. In modelling process, membership and non-membership values, in addition to actual lagged observations, are used as input of the CFNNs. The effectiveness of C-IFTS-FM on test sets for both structures was discussed comparatively via different error criteria, in addition, the convergence time was examined, and also the fit of forecasts and observations was presented with different illustrations. Among different combinations of hyperparameters, in the best case, approximately 86% better accuracy is achieved than the best of the others, while even in the case of the worst of hyperparameters combination, the accuracy was improved by over 20% for the PSJM data sets. For HEXING, CHENGNAN, and EUNITE data sets, these progress rates reached approximately 90% in the best case.},
  archive      = {J_NCA},
  author       = {Cagcag Yolcu, Ozge and Lam, Hak-Keung and Yolcu, Ufuk},
  doi          = {10.1007/s00521-024-10280-5},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20167-20192},
  shortjournal = {Neural Comput. Appl.},
  title        = {Short-term load forecasting: Cascade intuitionistic fuzzy time series—univariate and bivariate models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual feature decomposition and multi-task learning-based
variation-invariant face recognition. <em>NCA</em>, <em>36</em>(32),
20147–20166. (<a
href="https://doi.org/10.1007/s00521-024-10234-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial identity is subject to two primary natural variations: time-dependent (TD) factors such as age, and time-independent (TID) factors including sex and race. This study aims to address a broader problem known as variation-invariant face recognition (VIFR) by exploring the question: “How can identity preservation be maximized in the presence of TD and TID variations?&quot; While existing state-of-the-art (SOTA) methods focus on either age-invariant or race and sex-invariant FR, our approach introduces the first novel deep learning architecture utilizing multi-task learning to tackle VIFR, termed “multi-task learning-based variation-invariant face recognition (MTLVIFR).&quot; We redefine FR by incorporating both TD and TID, decomposing faces into age (TD) and residual features (TID: sex, race, and identity). MTLVIFR outperforms existing methods by 2% in LFW and CALFW benchmarks, 1% in CALFW, and 5% in AgeDB (20 years of protocol) in terms of face verification score. Moreover, it achieves higher face identification scores compared to all SOTA methods. Open source code .},
  archive      = {J_NCA},
  author       = {Haider, Abbas and Wu, Guanfeng and Spence, Ivor and Wang, Hui},
  doi          = {10.1007/s00521-024-10234-x},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20147-20166},
  shortjournal = {Neural Comput. Appl.},
  title        = {Residual feature decomposition and multi-task learning-based variation-invariant face recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining transformer based deep reinforcement learning with
black-litterman model for portfolio optimization. <em>NCA</em>,
<em>36</em>(32), 20111–20146. (<a
href="https://doi.org/10.1007/s00521-024-09805-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a model-free algorithm, deep reinforcement learning (DRL) agent learns and makes decisions by interacting with the environment in an unsupervised way. In recent years, DRL algorithms have been widely applied by scholars for portfolio optimization in consecutive trading periods, since the DRL agent can dynamically adapt to market changes and does not rely on the specification of the joint dynamics across the assets. However, typical DRL agents for portfolio optimization cannot learn a policy that is aware of the dynamic correlation between portfolio asset returns. Since the dynamic correlations among portfolio assets are crucial in optimizing the portfolio, the lack of such knowledge makes it difficult for the DRL agent to maximize the return per unit of risk, especially when the target market permits short selling (i.e., the US stock market). In this research, we propose a hybrid portfolio optimization model combining the DRL agent and the Black-Litterman (BL) model to enable the DRL agent to learn the dynamic correlation between the portfolio asset returns and implement an efficacious long/short strategy based on the correlation. Essentially, the DRL agent is trained to learn the policy to apply the BL model to determine the target portfolio weights. In this model, we formulate a specific objective function based on the environment’s reward function, which considers the return, risk, and transaction scale of the portfolio. Our DRL agent is trained by propagating the objective function’s gradient to the policy function of our DRL agent. To test our DRL agent, we construct the portfolio based on all the Dow Jones Industrial Average constitute stocks. Empirical results of the experiments conducted on real-world United States stock market data demonstrate that our DRL agent significantly outperforms various comparison portfolio choice strategies and alternative DRL frameworks by at least 42% in terms of accumulated return. In terms of the return per unit of risk, our DRL agent significantly outperforms various comparative portfolio choice strategies and alternative strategies based on other machine learning frameworks.},
  archive      = {J_NCA},
  author       = {Sun, Ruoyu and Stefanidis, Angelos and Jiang, Zhengyong and Su, Jionglong},
  doi          = {10.1007/s00521-024-09805-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20111-20146},
  shortjournal = {Neural Comput. Appl.},
  title        = {Combining transformer based deep reinforcement learning with black-litterman model for portfolio optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An innovative approach for parkinson’s disease diagnosis
using CNN, NCA, and SVM. <em>NCA</em>, <em>36</em>(32), 20089–20110. (<a
href="https://doi.org/10.1007/s00521-024-10299-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a prevalent neurodegenerative disorder affecting millions of people globally, with substantial health risks and economic burdens. This study aims to introduce an innovative hybrid approach combining deep learning and machine learning algorithms to improve the diagnosis of PD using handwriting dynamics indicative of Parkinson’s symptoms. The proposed approach integrates hybrid feature extraction using nine fine-tuned transfer learning models, i.e., InceptionV3, DenseNet201, EfficientNetB0, ResNet50, MobileNetV2, VGG16, Xception, NASNetMobile, and InceptionResNetV2. Initially, features from these models are used individually or in binary and ternary combinations. Given the limited sample size in PD datasets, some extracted features through fine-tuning may lack significance, and fully connected layers can lead to overfitting. To address this issue, Neighborhood Component Analysis (NCA) is employed to refine these features, retaining only the most informative ones. Finally, the selected features are classified using Support Vector Machines (SVM) maximizing the margin between classes and reducing the risk of overfitting. The proposed hybrid model achieves a state-of-the-art accuracy of 99.39% on the Parkinson Hand Drawings dataset. The combination of features extracted from DenseNet201, Xception, and NASNetMobile models, processed using NCA and SVM methods, has been identified as the most efficient model, balancing high accuracy with computational efficiency. Qualitative assessments further confirm the accuracy and reliability of the approach.},
  archive      = {J_NCA},
  author       = {Dogan, Yahya},
  doi          = {10.1007/s00521-024-10299-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20089-20110},
  shortjournal = {Neural Comput. Appl.},
  title        = {An innovative approach for parkinson’s disease diagnosis using CNN, NCA, and SVM},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Breast-NET: A lightweight DCNN model for breast cancer
detection and grading using histological samples. <em>NCA</em>,
<em>36</em>(32), 20067–20087. (<a
href="https://doi.org/10.1007/s00521-024-10298-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is a prevalent and highly lethal cancer affecting women globally. While non-invasive techniques like ultrasound and mammogram are used for diagnosis, histological examination after biopsy is considered the gold standard. However, manual examination of tissues for abnormality is labor-intensive, expensive, and requires prior domain knowledge. Early detection, awareness, and access to specialized medical infrastructure in resource-constrained and remote areas are significant challenges but crucial for saving lives. In recent years, deep learning-based approaches have shown promising results in breast cancer detection, facilitated by advancements in GPU memory, computation power, and the availability of digital data. Motivated by these observations, we propose the Breast-NET deep convolutional neural network model for breast cancer detection and grading using histological images. Our model’s performance is evaluated on the BreakHis dataset, and we demonstrate its generalization ability on the Invasive Ductal Carcinoma (IDC) grading and IDC datasets. Extensive experimental and statistical performance analysis, along with an ablation study, validates the efficiency of our proposed model. Furthermore, we demonstrate the effectiveness of transfer learning with seven pre-trained convolutional neural networks for breast cancer detection and grading. Experimental results show that our framework outperforms state-of-the-art approaches in terms of accuracy, space, and computational complexity for the BreakHis, IDC grading, and IDC datasets.},
  archive      = {J_NCA},
  author       = {Saha, Mousumi and Chakraborty, Mainak and Maiti, Suchismita and Das, Deepanwita},
  doi          = {10.1007/s00521-024-10298-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20067-20087},
  shortjournal = {Neural Comput. Appl.},
  title        = {Breast-NET: A lightweight DCNN model for breast cancer detection and grading using histological samples},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An explainable echo state network trained from
photoplethysmography signals for equine life stage prediction.
<em>NCA</em>, <em>36</em>(32), 20055–20066. (<a
href="https://doi.org/10.1007/s00521-024-10285-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the life stage of animals is crucial for assessing their overall health and making informed decisions for their care. However, traditional veterinary practices often rely on subjective methods, resulting in fuzziness or ambiguity. A quantitative metric via measurable vital signs has yet to be developed, which could be due to lack of a sophisticated methodology that can correlate the vital signs with age. To tackle this challenge, we present a method for equine life stage (young to old) classification from photoplethysmography (PPG) waveforms collected from 50 equine subjects with various ages, sex, and breeds. The data were collected using compact, wearable PPG sensors on their tails. The collected waveforms served as the input for the classification by an echo state network (ESN). It was found that the classification accuracy depended on the age split, suggesting a fussiness in classifying the youth and elder. Using the 17th year as the splitting age, the highest training and testing accuracies of 81.3% and 81.1% were achieved, respectively. In addition, input features from the reservoirs of the ESN were extracted and analyzed by a kernel principal component analysis, which afforded a 3D PCA map with clear clusters according to the age groups. This suggests that the ESN can learn hidden information from the PPG waves to classify the life stage. The proposed algorithm exhibits immense potential in veterinary medicine by offering a more objective and reliable approach to animal life stage assessment.},
  archive      = {J_NCA},
  author       = {Byfield, Richard and Miller, Morgan and Xie, Yunchao and Crosby, Marci and Schiltz, Paul and Johnson, Philip and Lin, Jian},
  doi          = {10.1007/s00521-024-10285-0},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20055-20066},
  shortjournal = {Neural Comput. Appl.},
  title        = {An explainable echo state network trained from photoplethysmography signals for equine life stage prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leaf disease detection using convolutional neural networks:
A proposed model using tomato plant leaves. <em>NCA</em>,
<em>36</em>(32), 20043–20053. (<a
href="https://doi.org/10.1007/s00521-024-10283-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A proper system for identifying leaf disease, which is crucial for developing agricultural areas, has been addressed in this research using a neural network approach. This study helps find plant illnesses and their stages whenever they occur. Fungal, bacterial, and viral infections are very harmful to plants. Five major tomato diseases have been classified in this research: bacterial spot, early blight, late blight, leaf mold, tomato mosaic virus, and healthy tomato plant leaves. The study underscores the importance of algorithmic adaptability to attain precision in leaf disease identification and emphasizes the potential for customized strategies in achieving accuracy. The classification is done by extracting color, shape, and texture features from a healthy tomato plant leaf image. The feature extraction method is carried out to proceed with the segmentation phase. Features extracted from segmented pictures are used as inputs to a classification algorithm. These five categories were used to finalize the illness categorization stage. The variety of five kinds of tomato leaf images yielded almost 99% classification accuracy. Furthermore, various research gaps have been identified to achieve a more open approach to detecting tomato diseases.},
  archive      = {J_NCA},
  author       = {Billah, Md Masum and Sultana, Azmery and Sad Aftab, Rakin and Ahmed, Mir Maruf and Shorif Uddin, Mohammad},
  doi          = {10.1007/s00521-024-10283-2},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20043-20053},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leaf disease detection using convolutional neural networks: A proposed model using tomato plant leaves},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using fuzzy transforms for neural networks-based wireless
localization in outdoor environments. <em>NCA</em>, <em>36</em>(32),
20027–20041. (<a
href="https://doi.org/10.1007/s00521-024-10250-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As neural network-based localization algorithms are becoming popular, there is a need to shorten the training time and the localization time for sustainability and efficiency purposes. To address such issues, the fuzzy transform (or F-transform for short) is employed here for the first time in a neural network-based localization algorithm. The F-transform is a dimensionality reduction method, which has found several applications over the last decade, but it has not been well explored in the form of a prepending layer to a neural network. In this respect, some properties (including the computational cost) of the F-transformed neural scheme are formally discussed here. The performance of the neural network-based approach with and without F-transform, and with a state-of-the-art reduction technique, i.e. the principal component analysis, is evaluated first on simulated data and then on publicly available real-world data. Different neural network architectures have been tried jointly with the above-mentioned reduction techniques. The numerical experiments show the excellent performance of the proposed fuzzy transform-based approach, which can ensure considerable savings in training time and query response time, without significant losses in accuracy.},
  archive      = {J_NCA},
  author       = {Solmann, Kristjan and Loffredo, Rocco and Tomasiello, Stefania},
  doi          = {10.1007/s00521-024-10250-x},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20027-20041},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using fuzzy transforms for neural networks-based wireless localization in outdoor environments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Streamlit-based enhancing crop recommendation systems with
advanced explainable artificial intelligence for smart farming.
<em>NCA</em>, <em>36</em>(32), 20011–20025. (<a
href="https://doi.org/10.1007/s00521-024-10208-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this paper is to clarify the importance of explainability in the crop recommendation process and provide insights on how Explainable Artificial Intelligence (XAI) can be incorporated into existing models successfully. The objective is to increase the definition and transparency of the recommendations implemented by AI in smart agriculture, leading to a detailed analysis of the synchronization between crop recommendation systems and XAI that informs decisions as it has sustainable knowledge and practices in modern agriculture. It reviews state-of-the-art XAI techniques such as local interpretable model-agnostic interpretation (LIME), SHapley interpretation additive approach (SHAP), integrated gradients (IG), and level-wise relevance propagation (LRP). It focuses on interpretable models and critical features analysis, and XAI methods are discussed in terms of their applications, critical features, and definitions. The paper found that XAI methods such as LIME and SHAP can make AI-driven crop recommendation systems more transparent and reliable. Graphical techniques such as dependency plots, summary plots, waterfall graphs, and decision plots effectively analyze feature importance. The paper includes counterfactual explanations using dice ml and hearing with advanced techniques combining IG and LRP to provide in-depth narrative model behavior. The novelty of this study lies in a detailed investigation of how XAI can be incorporated into crop recommendation systems to address the “black box” nature of AI models. It uses a unique XAI technique and model approach to make AI-driven recommendations more meaningful and practical for farmers. The proposed systems and techniques are designed to consume agriculture, addressing the specific needs of intelligent systems, making this research a significant contribution to agricultural AI.},
  archive      = {J_NCA},
  author       = {Akkem, Yaganteeswarudu and Biswas, Saroj Kumar and Varanasi, Aruna},
  doi          = {10.1007/s00521-024-10208-z},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {20011-20025},
  shortjournal = {Neural Comput. Appl.},
  title        = {Streamlit-based enhancing crop recommendation systems with advanced explainable artificial intelligence for smart farming},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning-based robust nonlinear
controller for photovoltaic systems. <em>NCA</em>, <em>36</em>(32),
19989–20009. (<a
href="https://doi.org/10.1007/s00521-024-10170-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently renewable energy such as a photovoltaic (PV) system has been utilized more and more since it is pollution-free and permanent. To maintain the PV system functioning at, or near, the peak power point of the PV panel under different conditions such as fluctuating solar irradiation, temperature, and other factors, maximum power point tracking algorithms are required. In this study, a novel hybrid robust intelligent controller for a photovoltaic system is proposed. Three loops are used for creating the proposed controller, ensuring the controller’s robustness. The first loop’s objective is to locate the photovoltaic system’s highest power spots. In the second loop, a novel fractional-order sliding model observer based on deep reinforcement learning optimization approach is proposed as a result of the design of a reliable controller under the lumped uncertainty in the system. Designing a novel back-stepping fast non-singular terminal fractional-order sliding mode controller is achieved at the final step. This method offers a nice transition response, a small tracking error, with a quick response to changes in solar radiation. Numerical analysis shows that the performance of the photovoltaic system by the proposed controller has been able to increase the efficiency of the system significantly.},
  archive      = {J_NCA},
  author       = {Veisi, Amir and Delavari, Hadi},
  doi          = {10.1007/s00521-024-10170-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {19989-20009},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning-based robust nonlinear controller for photovoltaic systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global quantitative robustness of regression feed-forward
neural networks. <em>NCA</em>, <em>36</em>(32), 19967–19988. (<a
href="https://doi.org/10.1007/s00521-024-10289-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are an indispensable model class for many complex learning tasks. Despite the popularity and importance of neural networks and many different established techniques from literature for stabilization and robustification of the training, the classical concepts from robust statistics have rarely been considered so far in the context of neural networks. Therefore, we adapt the notion of the regression breakdown point to regression neural networks and compute the breakdown point for different feed-forward network configurations and contamination settings. In an extensive simulation study, we compare the performance, measured by the out-of-sample loss, by a proxy of the breakdown rate and by the training steps, of non-robust and robust regression feed-forward neural networks in a plethora of different configurations. The results indeed motivate to use robust loss functions for neural network training.},
  archive      = {J_NCA},
  author       = {Werner, Tino},
  doi          = {10.1007/s00521-024-10289-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {19967-19988},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global quantitative robustness of regression feed-forward neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computer vision-based hybrid efficient convolution for
isolated dynamic sign language recognition. <em>NCA</em>,
<em>36</em>(32), 19951–19966. (<a
href="https://doi.org/10.1007/s00521-024-10258-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Isolated dynamic sign language recognition (IDSLR) has the potential to change accessibility and inclusion by enabling speech and/or hearing-impaired people to engage more completely in a variety of spheres of life, including social interactions, work, and more. IDSLR is a challenging task due to considering a sequence of image frame analysis with multiple linguistic features for a single gesture in cluttered backgrounds and an illumination variation environment. We have proposed a Hybrid Efficient Convolution (HEC) model that ensembles EfficientNet-B3 and a few modified layers as an alternative to traditional machine learning techniques with improved performances in cluttered backgrounds with illumination variation environments. The architecture of the HCE integrates pre-trained layers of EfficientNet-B3 loaded with customized weights and a new custom dense layer featuring 256 units, followed by batch normalization, dropout, and the final output layer. To enhance the robustness of the system, we employed the augmentation technique during pre-processing. Then, the system executes channel-wise feature transformation through point-wise convolution that reduces the computational complexity and increases the accuracy. The updated dense layer with 256 units processes the output from the standard EfficientNet-B3, shaping the model into a hybrid form to achieve better performance. We have created our own gesture dataset, called “BdSL_OPA_23_GESTURES,” which consists of 6000 video clips of 100 isolated dynamic Bangla Sign Language words, with 60 videos for each word from 20 different people in the cluttered background with illumination variation environments to train and evaluate the performances of the proposed model. We have considered 80% of the total dataset for training purpose, while the remaining 20% is dedicated to testing and validation. In a small number of epochs, our proposed HEC model achieves a superior accuracy of 93.17% on our created “BdSL_OPA_23_GESTURES” dataset. All the information of the proposed model with the dataset has been shared along with the scientific community to provide access publicly at: https://github.com/Prothoma2001/Bangla-Continuous-Sign-Language-Recognition.git .},
  archive      = {J_NCA},
  author       = {Chowdhury, Prothoma Khan and Oyshe, Kabiratun Ummi and Rahaman, Muhammad Aminur and Debnath, Tanoy and Rahman, Anichur and Kumar, Neeraj},
  doi          = {10.1007/s00521-024-10258-3},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {19951-19966},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computer vision-based hybrid efficient convolution for isolated dynamic sign language recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward an emotion efficient architecture based on the sound
spectrum from the voice of portuguese speakers. <em>NCA</em>,
<em>36</em>(32), 19939–19950. (<a
href="https://doi.org/10.1007/s00521-024-10249-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main challenges in the process of recognizing emotion through the voice are related to the specific characteristics of an individual’s sound spectrum, such as accent and speech rhythm, as well as regionalism and wide variability of spoken phrases. Despite efforts to propose emotion recognition models, providing an increase in accuracy in classifying emotion in a specialized way is an open research question. Faced with these challenges, this work proposes DEEP (DEtection of voice Emotion in Portuguese language), an architecture for detecting voice emotion based on patterns present in the sound spectrum generated by the voice of Brazilian Portuguese speakers. DEEP recognizes each emotion by using a set of specialist Convolutional Neural Networks that receive as input the features extracted from the sound spectrum. With this, DEEP aims to specialize each emotion to increase the rate of correct answers and adapt to different tones and voice conditions that may occur in everyday life. Our results show that DEEP outperforms the emotion recognition measures of other state of art techniques for all evaluated scenarios.},
  archive      = {J_NCA},
  author       = {Filho, Geraldo P. Rocha and Meneguette, Rodolfo I. and Mendonça, Fábio Lúcio Lopes de and Enamoto, Liriam and Pessin, Gustavo and Gonçalves, Vinícius P.},
  doi          = {10.1007/s00521-024-10249-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {32},
  pages        = {19939-19950},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward an emotion efficient architecture based on the sound spectrum from the voice of portuguese speakers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transfer learning for bloom’s taxonomy-based question
classification. <em>NCA</em>, <em>36</em>(31), 19915–19937. (<a
href="https://doi.org/10.1007/s00521-024-10241-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bloom’s taxonomy (BT) is commonly employed to categorize assessment questions posed to students based on different degrees of complexity. The existing datasets based on BT are small in size. Due to the substantial data requirements of deep learning models, the existing datasets are inadequate for adequately training these models and attaining favorable outcomes. This paper presents a new dataset referred to as “NCERT question classification” which is significantly larger than the existing BT-based question classification datasets. Experimental results demonstrate that an ensemble of pre-trained language models achieves state-of-the-art accuracy of 92.77%, 88.50%, and 78.44% on the existing Yahya et al., Jain et al., and CLO datasets, respectively, and an accuracy of 94.10% on our proposed dataset. Furthermore, we show that the results on existing datasets can be improved by up to 3% through fine-tuning a combined dataset that includes training instances from both the proposed and existing datasets.},
  archive      = {J_NCA},
  author       = {Chindukuri, Mallikarjuna and Sivanesan, Sangeetha},
  doi          = {10.1007/s00521-024-10241-y},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19915-19937},
  shortjournal = {Neural Comput. Appl.},
  title        = {Transfer learning for bloom’s taxonomy-based question classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An incremental tree seed algorithm for balancing local and
global search behaviors in continuous optimization problems.
<em>NCA</em>, <em>36</em>(31), 19879–19914. (<a
href="https://doi.org/10.1007/s00521-024-10228-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based tree seed algorithm (TSA), a popular optimization algorithm, was used in this study. The purpose of this study is to develop a TSA via improving its exploitation and exploration capability which is the most important element of the algorithm. Accordingly, the study was aimed at increasing the convergence rate and performance level of the algorithm. The population diversity of the algorithm was studied, and the incremental social learning method in the literature was integrated into a TSA. The new algorithm obtained was called “Incremental tree seed algorithm” (ITSA). Four different ITSA methods were obtained by using four different methods. With the new methods obtained, the TSA method was applied to twelve low-dimensional benchmark functions. The success of the proposed methods on functions was extraordinary, and the results were shown in the tables. At the same time, Wilcoxon p-test analysis, sign test and ROC curve analysis of the obtained results were also performed. According to the results of p-test, sign test and ROC curve analysis, the proposed method was found to be successful. It can be concluded that the proposed method is more robust than its original version.},
  archive      = {J_NCA},
  author       = {Beşkirli, Mehmet},
  doi          = {10.1007/s00521-024-10228-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19879-19914},
  shortjournal = {Neural Comput. Appl.},
  title        = {An incremental tree seed algorithm for balancing local and global search behaviors in continuous optimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Self-supervised modal optimization transformer for image
captioning. <em>NCA</em>, <em>36</em>(31), 19863–19878. (<a
href="https://doi.org/10.1007/s00521-024-10211-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal data processing of image captioning, data from different modalities usually exhibit distinct feature distributions. The gap in unimodal representation makes capturing cross-modal mappings in multimodal learning challenging. Current image captioning models transform images into captions directly. However, this approach results in large data requirements and limited performance on small quantities of multimodal data. In this paper, we introduce a novel self-supervised modal optimization transformer (SMOT) for image captioning. Specifically, we leverage self-supervised learning to propose a cross-modal feature optimizer. This optimizer aims to optimize the distribution of semantic information in images by leveraging raw images and their corresponding paired captions, ultimately approaching the semantic object of the caption. The optimized image features inherit information from both modalities, reducing the disparity in feature distribution between modalities and decreasing reliance on extensive training data. Furthermore, we fuse the features with image grid features and text features, using their complementary information to bridge the differences between features, providing more comprehensive semantic guidance for image captioning. Experimental results demonstrate that our proposed SMOT outperforms state-of-the-art models when trained on limited data, showing efficient learning and good generalization capabilities on small training datasets. Additionally, it also exhibits competitive performance on the MSCOCO dataset, further highlighting its efficacy and potential in the field of image captioning.},
  archive      = {J_NCA},
  author       = {Wang, Ye and Li, Daitianxia and Liu, Qun and Liu, Li and Wang, Guoyin},
  doi          = {10.1007/s00521-024-10211-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19863-19878},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-supervised modal optimization transformer for image captioning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing epigraphy: A deep learning approach to recognize
and analyze tamil ancient inscriptions. <em>NCA</em>, <em>36</em>(31),
19839–19861. (<a
href="https://doi.org/10.1007/s00521-024-10137-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper presents a novel algorithmic approach for character recognition and contextual analysis of temple inscriptions, specifically focusing on Tamil ancient script. The methodology combines advanced preprocessing techniques, deep learning models, and contextual analysis to address the challenges posed by noisy images, script variations, and historical context understanding. We compiled a dataset of 100 high-resolution images of temple inscriptions from various regions and periods. The preprocessing phase involves Noise Reduction, Contrast Enhancement, Orientation Correction, and Adaptive Binarization algorithms to enhance the quality of the inscription images. The character recognition stage employs Convolutional Neural Networks with Transfer Learning, further enhanced by the Multi-head Attention mechanism in Vision Transformers (ViT). The character segmentation algorithm used was the Stroke Width Transform. Transfer Learning was incorporated to adapt the pre-trained ViT model to our specific task. This approach significantly improves the model’s ability to recognize characters from diverse scripts and languages. The results demonstrate the effectiveness of the proposed methodology. The character recognition accuracy metrics include a precision of 97.25%, a recall of 95.05%, and an F1-score of 95.17%. Additionally, the model achieved a recognition rate of 98.92% for key terms related to historical events, deities, and rulers. It also demonstrated a 94% recognition rate for context-specific phrases and a 95% recognition rate for historical dates. Contextual analysis results indicate that the model successfully identifies specific terms, phrases, and historical references, contributing to a deeper understanding of the inscriptions. The model&#39;s ability to recognize characters from multiple scripts underscores its adaptability to diverse inscriptions. In conclusion, this research provides a comprehensive and efficient solution for character recognition and contextual analysis of temple inscriptions in Tamil ancient script. It advances the field of epigraphy and historical research, facilitating the digital preservation and exploration of historical and cultural heritage contained within these inscriptions.},
  archive      = {J_NCA},
  author       = {Bhuvaneswari, S. and Kathiravan, K.},
  doi          = {10.1007/s00521-024-10137-x},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19839-19861},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing epigraphy: A deep learning approach to recognize and analyze tamil ancient inscriptions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Utilizing chaos game representation for enhanced
classification of SARS-CoV-2 variants with stacked sparse autoencoders.
<em>NCA</em>, <em>36</em>(31), 19823–19837. (<a
href="https://doi.org/10.1007/s00521-024-10278-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the beginning of the COVID-19 pandemic, the World Health Organization (WHO) has been tracking SARS-CoV-2 mutations. The SARS-CoV-2 consistently mutated throughout the pandemic, which resulted in many variants. A variant is a viral genome containing one or more genetic code mutations. Deep learning techniques have been successfully used in many viral classification problems associated with viral infection diagnosis, metagenomics, phylogenetics, and analysis. This work proposed an effective viral genome classifier for SARS-CoV-2 variants using the deep neural network based on the stacked sparse autoencoder (SSAE). Aiming to achieve the best performance of the model, we explored the utilization of image representations of the complete genome sequences as the SSAE input. The dataset based on Chaos Game Representation (CGR) images was generated and applied to the experiments of classification of SARS-CoV-2 variants of concern (VOC). The SSAE technique provided great performance results, achieving classification accuracy of 99.9% for the validation set and 99.8% for the test set. Finally, the results indicated the relevance of using this deep learning technique in genome classification problems.},
  archive      = {J_NCA},
  author       = {Coutinho, Maria G. F. and Câmara, Gabriel B. M. and Barbosa, Raquel de M. and Fernandes, Marcelo A. C.},
  doi          = {10.1007/s00521-024-10278-z},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19823-19837},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utilizing chaos game representation for enhanced classification of SARS-CoV-2 variants with stacked sparse autoencoders},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GCN-SA: A hybrid recommendation model based on graph
convolutional network with embedding splicing layer. <em>NCA</em>,
<em>36</em>(31), 19807–19821. (<a
href="https://doi.org/10.1007/s00521-024-10254-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks are capable of handling non-Euclidean data with sparse features, and some research has begun to apply them to the field of recommendation systems. Graph convolutional network’s aggregation and propagation mechanism can learn features well and improve the embedding quality. However, simply applying GCN to the recommendation domain can only show some of its advantages, and the complex structure makes it difficult for the model to handle the massive amount of data in the industrial domain. Some work has been done to integrate GCN with recommendation systems better. However, most related work pursues the model’s simplicity and ignores the large amount of hidden auxiliary information. In this paper, we propose a GCN-SA model, which adds a multi-head self-attention mechanism to the aggregation and propagation process to learn the weights of neighboring nodes and analyze the importance of the relationships between nodes; we also design a new embedding splicing layer for the graph convolutional network, which dynamically adjusts the embedding of different layers to achieve adaptive layer smoothing and mitigate the over-smoothing phenomenon. After experimental results on five benchmark datasets, we show that the GCN-SA model outperforms previous related work, captures a large amount of auxiliary information, and enhances the expressive ability of the model.},
  archive      = {J_NCA},
  author       = {Sun, Yifei and Zhang, Ao and Cheng, Shi and Cao, Yifei and Yang, Jie and Shi, Wenya and Ju, Jiale and Yin, Jihui and Yan, Qiaosen and Yang, Xinqi and Wang, Ziang},
  doi          = {10.1007/s00521-024-10254-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19807-19821},
  shortjournal = {Neural Comput. Appl.},
  title        = {GCN-SA: A hybrid recommendation model based on graph convolutional network with embedding splicing layer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight deep learning architecture for malaria
parasite-type classification and life cycle stage detection.
<em>NCA</em>, <em>36</em>(31), 19795–19805. (<a
href="https://doi.org/10.1007/s00521-024-10219-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malaria is an endemic in various tropical countries. The gold standard for disease detection is to examine the blood smears of patients by an expert medical professional to detect malaria parasite called Plasmodium. In the rural areas of underdeveloped countries, with limited infrastructure, a scarcity of healthcare professionals, an absence of sufficient computing devices, and a lack of widespread internet access, this task becomes more challenging. A severe case of malaria can be fatal within one week, so the correct detection of the malaria parasite and its life cycle stage is crucial in treating the disease correctly. Though computer vision-based malaria detection has been adequately explored lately, the malaria life cycle stage classification is still a relatively unexplored field. In this paper, we introduce a fast and robust deep learning methodology to not only classify the malaria parasite-type detection but also the life cycle stage identification of the infected cell. The proposed deep learning architecture is more than twenty times lighter than the widely used DenseNet and has less than 0.4 million parameters, making it a good candidate to be used in the mobile applications of such economically challenged states for malaria detection. We have used four different publicly available malaria datasets to test the proposed architecture and gained significantly better results than the current state of the art on malaria parasite-type and malaria life cycle classification.},
  archive      = {J_NCA},
  author       = {Chaudhry, Hafiza Ayesha Hoor and Farid, Muhammad Shahid and Fiandrotti, Attilio and Grangetto, Marco},
  doi          = {10.1007/s00521-024-10219-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19795-19805},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight deep learning architecture for malaria parasite-type classification and life cycle stage detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MV-DUO: Multi-variate discrete unified optimization for
psychological vital assessments. <em>NCA</em>, <em>36</em>(31),
19777–19793. (<a
href="https://doi.org/10.1007/s00521-024-10183-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychological vital assessments are required for monitoring health conditions and observing body reactions toward diseases and medications. Wearable sensors play a vital role in sensing body vitals and presenting them as signals for computer-based analysis. The problem relies on the signal decoding due to its input stream that turns out to be discrete/ continuous. Therefore for addressing the above specific issue, this article introduces MV-DUO (Multi-Variate Discrete Unified Optimization) method. This method addresses the above problem from a multi-variate perspective by sensing differential signals across healthy and unhealthy conditions. The healthy and unhealthy conditions are trained using neural learning by augmenting/ ceasing external vital data. The unification is performed using single-point artificial ecosystem-based optimization for identifying discrete sequences collaborated with continuous signals. The single-point reference is grouped based on the maximum continuity fitness observed under various sensing intervals. In this process, the non-grouped sequences are identified as unhealthy or discrete for which additional detection training and classification are required. Considerably the changes between successive sensing intervals are used for variations detection from unified high-fitness groups. Those grouped instances are used for training new vital changes observed at distinct intervals. This improves detection accuracy under controlled errors. For the varying sensing intervals, the proposed method achieves 14.13% high accuracy, 8.29% high grouping rate, 10.77% less error, and 10.07% less detection time.},
  archive      = {J_NCA},
  author       = {Pethuraj, Mohamed Shakeel and Burhanuddin, M. A. and Dzakiyullah, Nur Rachman},
  doi          = {10.1007/s00521-024-10183-5},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19777-19793},
  shortjournal = {Neural Comput. Appl.},
  title        = {MV-DUO: Multi-variate discrete unified optimization for psychological vital assessments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deepfake detection using convolutional vision transformers
and convolutional neural networks. <em>NCA</em>, <em>36</em>(31),
19759–19775. (<a
href="https://doi.org/10.1007/s00521-024-10181-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake technology has rapidly advanced in recent years, creating highly realistic fake videos that can be difficult to distinguish from real ones. The rise of social media platforms and online forums has exacerbated the challenges of detecting misinformation and malicious content. This study leverages many papers on artificial intelligence techniques to address deepfake detection. This research proposes a deep learning (DL)-based method for detecting deepfakes. The system comprises three components: preprocessing, detection, and prediction. Preprocessing includes frame extraction, face detection, alignment, and feature cropping. Convolutional neural networks (CNNs) are employed in the eye and nose feature detection phase. A CNN combined with a vision transformer is also used for face detection. The prediction component employs a majority voting approach, merging results from the three models applied to different features, leading to three individual predictions. The model is trained on various face images using FaceForensics++ and DFDC datasets. Multiple performance metrics, including accuracy, precision, F1, and recall, are used to assess the proposed model’s performance. The experimental results indicate the potential and strengths of the proposed CNN that achieved enhanced performance with an accuracy of 97%, while the CViT-based model achieved 85% using the FaceForences++ dataset and demonstrated significant improvements in deepfake detection compared to recent studies, affirming the potential of the suggested framework for detecting deepfakes on social media. This study contributes to a broader understanding of CNN-based DL methods for deepfake detection.},
  archive      = {J_NCA},
  author       = {Soudy, Ahmed Hatem and Sayed, Omnia and Tag-Elser, Hala and Ragab, Rewaa and Mohsen, Sohaila and Mostafa, Tarek and Abohany, Amr A. and Slim, Salwa O.},
  doi          = {10.1007/s00521-024-10181-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19759-19775},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deepfake detection using convolutional vision transformers and convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel type-2 decision mechanism for dynamic parameter
adaptation: Theory and application in mathematical and structural
problems. <em>NCA</em>, <em>36</em>(31), 19729–19757. (<a
href="https://doi.org/10.1007/s00521-024-10176-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms are stochastic-based search techniques widely used for solving different types of optimization problems. These methods mostly adjust their search behavior using pre-defined search pattern(s) regardless of the current problem specifications. Therefore, integrating them with logical auxiliary modules can significantly enhance their search efficiency by enabling them to dynamically adapt their search behavior. The present study introduces a novel decision-making approach that employs interval type-2 fuzzy logic to balance the search behavior during optimization process. The proposed approach, designed as a stand-alone module with the flexibility to be integrated into various algorithms, is incorporated into the Interactive Search Algorithm. The developed reinforced technique is named Type-2 Fuzzy Interactive Search Algorithm. Performance of the proposed method is tested on different unconstrained mathematical functions and constrained structural and mechanical optimization problems. The attained results are compared with standard ISA method and seven other metaheuristic techniques through a suite of numerical and statistical evaluations. Drawing from the obtained results, the integration of the type-2 fuzzy decision module significantly enhances the algorithm&#39;s search capability. This improvement is evident in terms of stability, accuracy, and computational cost. It is worth noting that the employed comparative performance index for the proposed method indicates improvements of 3.38, 13.09, 16.61, and 27.23 percent compared to the best solution found by the selected methods for engineering problems.},
  archive      = {J_NCA},
  author       = {Mortazavi, Ali},
  doi          = {10.1007/s00521-024-10176-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19729-19757},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel type-2 decision mechanism for dynamic parameter adaptation: Theory and application in mathematical and structural problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resnet50 and logistic gaussian map-based zero-watermarking
algorithm for medical color images. <em>NCA</em>, <em>36</em>(31),
19707–19727. (<a
href="https://doi.org/10.1007/s00521-024-10121-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image copyright protection is becoming increasingly relevant as medical images are used more frequently in medical networks and institutions. The traditional embedded watermarking system is inappropriate for medical images since it degrades the original images’ quality. Furthermore, medical-colored image watermarking options are constrained since most medical watermarking systems are built for gray-scale images. This paper proposes a zero-watermarking scheme for medical color image copyright protection based on a chaotic system and Resnet50, which is a convolutional neural network method. The network Resnet50 is used to extract features from the color medical image, and then a logistic Gaussian map is used to scramble these features and scramble the binary image. Finally, an exclusive OR operation is performed (scrambled binary image, scrambled features for the medical color image) to form a zero watermarking. The experimental result proves that our scheme is effective and robust to geometric and common image processing attacks. The BER values of the extracted watermarks are below 0.0039, and the NCC values are above 0.9942, while the average PSNR values of the attacked images are 29.0056 dB. Also, it is superior to other zero-watermark schemes for medical images in terms of robustness to conventional image processing and geometric attacks. Furthermore, the experimental results show that the Resnet50 model outperforms other models in terms of reducing the mean squared errors of the features between the attacked and original image.},
  archive      = {J_NCA},
  author       = {Farhat, Amal A. and Darwish, Mohamed M. and El-Gindy, T. M.},
  doi          = {10.1007/s00521-024-10121-5},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19707-19727},
  shortjournal = {Neural Comput. Appl.},
  title        = {Resnet50 and logistic gaussian map-based zero-watermarking algorithm for medical color images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using machine learning techniques for the classification of
ultra-low concentrations of cannabis in biological fluids. <em>NCA</em>,
<em>36</em>(31), 19691–19705. (<a
href="https://doi.org/10.1007/s00521-024-10263-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the application of three different Machine Learning algorithms, random forest (RF), support vector machine (SVM), and artificial neural network (ANN), to accurately classify ultra-low concentrations of Δ9-tetrahydrocannabinol in biological fluids such as saliva was successfully demonstrated. In doing so, experimental data consisting of the voltammetry signals of 0, 2, and 5 ng/mL of Δ9-tetrahydrocannabinol (THC) in synthetic and human saliva was employed. The dataset consists of person-to-person saliva variation and experimental variabilities in the procedure and artifacts. The results showed that RF was the most robust ML technique to classify different concentration levels of THC in the presence of a variety of variabilities in the experimental data, with an average training accuracy of 96% and an average testing accuracy of 87%. On the other hand, SVM and ANN models were susceptible to incoherencies in the experimental data.},
  archive      = {J_NCA},
  author       = {Mozaffari, Hoda and Ortega, Greter and Viltres, Herlys and Ahmed, Syed Rahin and Rajabzadeh, Amin Reza and Srinivasan, Seshasai},
  doi          = {10.1007/s00521-024-10263-6},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19691-19705},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using machine learning techniques for the classification of ultra-low concentrations of cannabis in biological fluids},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mean policy-based proximal policy optimization for
maneuvering decision in multi-UAV air combat. <em>NCA</em>,
<em>36</em>(31), 19667–19690. (<a
href="https://doi.org/10.1007/s00521-024-10261-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous maneuvering decision-making is a crucial technology for Unmanned Aerial Vehicles (UAVs) to take the air domination in modern unmanned warfare. With the advantage of balancing exploration and exploitation, as well as the immediacy of end-to-end output by combining with deep neural network, multi-agent reinforcement learning (MARL) has made remarkable achievements in multi-UAV autonomous air combat maneuvering decision-making (MUAAMD). However, the implementation of effective cooperative policy learning remains a challenging issue for MARL methods with centralized training decentralized execution (CTDE) paradigm. This paper proposes a MARL-based method to improve the performance of cooperation in MUAAMD. Firstly, considering the constraints of dynamic and limited perception for UAVs in the realistic air combat scenario, the MUAAMD problem is formulated based on partially observable Markov game (POMG) model. Secondly, a novel efficient MARL algorithm named the mean policy-based proximal policy optimization (MP3O) is introduced. Specifically, a joint policy optimization mechanism is constructed by estimating the policies of neighboring agents in group as a mean-field approximation while training, which enables both centralized evaluation and improvement of cooperative policy under the CTDE paradigm. Thirdly, by combining with three improvement techniques, a cooperative decision-making framework for MUAAMD based on MP3O is proposed. Empirically, results of simulations and comparative experiments validate the effectiveness of proposed method in promoting cooperative policy learning in resolving MUAAMD problem.},
  archive      = {J_NCA},
  author       = {Zheng, Yifan and Xin, Bin and He, Bin and Ding, Yulong},
  doi          = {10.1007/s00521-024-10261-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19667-19690},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mean policy-based proximal policy optimization for maneuvering decision in multi-UAV air combat},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization and comparison of machine learning algorithms
for the prediction of the performance of football players. <em>NCA</em>,
<em>36</em>(31), 19653–19666. (<a
href="https://doi.org/10.1007/s00521-024-10260-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Athletes’ performance evaluation is a critical step for the assessment of the skills and the quality of training of the athletes. This is even more important in team sports such as football, in which different roles, and hence different skills, are required. In light of this, the presented work aims at forecasting above team-average performance of football players by using supervised machine learning algorithms. Such algorithms were trained and tested on four biometric parameters as input and seven performance indicators as labels. The algorithms have been optimized using three optimization techniques: the gridsearch, and two versions of the whale-optimization algorithm, the standard one and another, proposed by us, in which Euclidean distance is used. The analyses were conducted by dividing the players by their role: the strikers, the midfielders and the defenders, to take into account the different skills required for each task. The obtained results show that the Random Forest, trained with specific combinations of biometric parameters is capable of predicting the selected performance indicators with an accuracy higher than 90%, for all the considered players’ roles and that the proposed optimization technique outperforms the existing ones. In light of these results, the proposed method could be used profitably by football teams’ staff to monitor their players, offering the possibility to take tactical decisions, design customized training sessions and orient market choices.},
  archive      = {J_NCA},
  author       = {Morciano, Gianluca and Zingoni, Andrea and Calabrò, Giuseppe},
  doi          = {10.1007/s00521-024-10260-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19653-19666},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimization and comparison of machine learning algorithms for the prediction of the performance of football players},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised learning for on-street parking violation
prediction using graph convolutional networks. <em>NCA</em>,
<em>36</em>(31), 19643–19652. (<a
href="https://doi.org/10.1007/s00521-024-10248-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlled parking systems in cities provide designated parking zones and allow citizens to easily find parking spaces increasing comfort and potentially reducing traffic and pollution. However, illegally occupied parking spaces can negatively affect the accuracy of these systems, diminishing their benefits. This work presents a semi-supervised deep learning approach for fine-grained parking violation rate prediction using graph neural networks, which can capture both the spatial and temporal dynamics of parking systems and driver behavior, providing a valuable tool for controlled parking systems. The proposed method addresses several challenges faced in this task, including the need to appropriately construct temporal graph-based training datasets and design a model that can handle missing values. Additionally, the method includes a novel semi-supervised data augmentation and smoothing technique to mitigate the effect of the small amount of annotated data and/or missing data in the training dataset. The proposed method was evaluated using a large-scale dataset from Thessaloniki’s on-street public parking system and found to significantly improve the accuracy of parking violation prediction compared to state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Karantaglis, Nikolaos and Passalis, Nikolaos and Tefas, Anastasios},
  doi          = {10.1007/s00521-024-10248-5},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19643-19652},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semi-supervised learning for on-street parking violation prediction using graph convolutional networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of a non-destructive fruit quality assessment
utilizing odour sensing, expert vision and deep learning algorithm.
<em>NCA</em>, <em>36</em>(31), 19613–19641. (<a
href="https://doi.org/10.1007/s00521-024-10245-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The food and agriculture sector is one of the world&#39;s most critical and essential industries, as it provides the necessities of life for a growing global population. Food assessment, especially fruit, is an essential mechanism for producers and industries that can affect fruit quality assessment and export markets. However, the food industry still practices manual fruit classification and quality assessment during post-harvest handling and is prone to human error. This research aims to implement a computer-assisted and non-destructive method to classify and determine fruit quality based on colour, odour, and shape characteristics to improve the efficiency of the post-harvest handling process. Six thousand samples of mango, honeydew, chilli and tomato went through the system with data processing techniques (image and odour) and the predictive model using multimodal deep learning algorithms such as convolutional neural network (CNN), CNN-LSTM, and CNN-SVM. The predictive model extracted and concatenated odour and image features using the feature fusion level method. As a result, multimodal CNN-LSTM achieved the highest accuracy rate, such as 93.50% in fruit classification and 96.08% in fruit quality assessment. The experiments demonstrate the feasibility of the proposed multimodal deep learning method in fruit classification and quality assessment. Finally, this fruit assessment intends to provide good food quality to the customers and maintain the food quality consistently.},
  archive      = {J_NCA},
  author       = {Tan, Wei Keong and Husin, Zulkifli and Yasruddin, Muhammad Luqman and Ismail, Muhammad Amir Hakim},
  doi          = {10.1007/s00521-024-10245-8},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19613-19641},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of a non-destructive fruit quality assessment utilizing odour sensing, expert vision and deep learning algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A learning-based nearly optimal control framework for
trajectory tracking of a flexible-link manipulator system with actuator
fault. <em>NCA</em>, <em>36</em>(31), 19597–19612. (<a
href="https://doi.org/10.1007/s00521-024-10224-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a learning-based nearly optimal control framework with fault-tolerant capability is designed to tackle the tracking control problem of a flexible-link manipulator in the presence of actuator fault and model uncertainties. Initially, the optimal control law is obtained by adopting the dynamic programming and a critic structure as the solution of Hamilton–Jacobi–Bellman equation for the nominal model. Then, by implementing an integral sliding mode control, the robustness against actuator fault and model uncertainty is guaranteed. The adaptive laws are constructed based on radial basis functions neural networks to estimate the upper bound of uncertainty and the actuator bias fault, satisfying both optimal performance and chattering reduction of the sliding surface. Furthermore, the actuator effectiveness loss is handled. The stability of the closed-loop system is analytically proven, and the performance of the proposed framework is investigated against several practical operating conditions. This incorporates the fidelity assessment of tracking precision and trackability of control signal using performance indices such as the integral absolute error and root-mean-square error. The results of extensive simulation studies confirm the effectiveness and robustness of the proposed control framework.},
  archive      = {J_NCA},
  author       = {Raoufi, Mona and Habibi, Hamed and Yazdani, Amirmehdi and Wang, Hai},
  doi          = {10.1007/s00521-024-10224-z},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19597-19612},
  shortjournal = {Neural Comput. Appl.},
  title        = {A learning-based nearly optimal control framework for trajectory tracking of a flexible-link manipulator system with actuator fault},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid convolutional neural network approach for optimizing
automatic identification of natural isotopes in gamma ray environmental
sample spectra. <em>NCA</em>, <em>36</em>(31), 19585–19595. (<a
href="https://doi.org/10.1007/s00521-024-10221-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radioisotope identification presents challenges that can be effectively addressed through pattern recognition and machine learning (ML) techniques. However, further investigation is necessary to assess the accuracy of these algorithms in quantifying mixtures of radioisotopes. The novelty of the study focuses on a hybrid convolutional neural network (CNN) architecture, called Arch, which utilizes numerical values to predict the presence of radioisotopes based on their signals. The feature extraction methods are employed to analyze small-isotope libraries using area-of-interest techniques and low-resolution spectrometers, with fully calibrated detectors ensuring accurate identification complexity. Additionally, this study explores the use of two sets of machine learning approaches for the automated identification of radioisotopes, focusing specifically on the feature extraction method. The Hybrid CNN Arc model, as proposed, achieved a test data accuracy of 95%. Additionally, a recurrent neural network model achieved an accuracy of 92%, while a GBDT model achieved an accuracy of 86%. The precision, recall, and f1-score metrics have been computed for the Hybrid CNN Arch approach, yielding values of 95%, 95%, and 95%, respectively. Similarly, the RNN model achieved precision, recall, and f1-score scores of 89%, 82%, and 81.5%, respectively. Lastly, the GBDT model attained precision, recall, and f1-score values of 84%, 81%, and 74.6%, respectively.},
  archive      = {J_NCA},
  author       = {Paleti, Bharathi and Sastry, G Hanumat},
  doi          = {10.1007/s00521-024-10221-2},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19585-19595},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid convolutional neural network approach for optimizing automatic identification of natural isotopes in gamma ray environmental sample spectra},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving dynamic optimization problems using parent–child
multi-swarm clustered memory (PCSCM) algorithm. <em>NCA</em>,
<em>36</em>(31), 19549–19583. (<a
href="https://doi.org/10.1007/s00521-024-10205-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Particle Swarm Optimization (PSO) algorithm faces several inherent challenges when applied to dynamic and large-scale optimization problems. These challenges encompass the issues of outdated particle memory, inadequate scalability in high-dimensional search spaces, the incapability to detect environmental changes, a continual trade-off between exploration and exploitation, and the potential loss of population diversity within the problem space. To address these challenges, we propose a novel hybrid PSO algorithm, denoted as Parent–Child Multi-Swarm Clustered Memory (PCSCM). PCSCM is explicitly designed to leverage an enhanced memory system, capable of mitigating the issue of outdated particle memory after convergence, and efficiently adapting to changing environmental conditions. This innovative memory system retains and retrieves promising solutions from the past when environmental alterations occur. Additionally, PCSCM introduces clustering mechanisms for particles within each swarm, aimed at augmenting diversity within the problem space. This clustering strategy substantially bolsters the algorithm’s performance in tracking evolving optimal solutions and positively contributes to its scalability. Crucially, the clustering approach is implemented not only for the main population but also for stored solutions in memory, which collectively strike a balance between exploration and exploitation. In the proposed method, particle swarms are divided into parent and child swarms, with parent swarms dedicated to preserving diversity; while, child swarms focus on identifying local solutions. These clustering and memory strategies are consistently applied within each sub-swarm to effectively address the challenges posed by high-dimensional search spaces. In addition to addressing challenges related to dynamic optimization, our proposed Parent–Child Multi-Swarm Clustered Memory (PCSCM) algorithm introduces an innovative mechanism for detecting environmental changes. This novel approach enhances the algorithm’s adaptability by efficiently identifying moments when the optimization environment undergoes significant shifts. The detection of such changes is a crucial aspect of the PCSCM algorithm, contributing to its robust performance in dynamic scenarios. The effectiveness and robustness of the PCSCM algorithm are substantiated through extensive simulation experiments. These experiments provide insights into PCSCM’s behavior in dynamic environments and showcase its ability to scale proficiently in high-dimensional settings. Particularly noteworthy are the results obtained when benchmarked against the Moving Peaks Benchmark and Generalized Moving Peaks Benchmark. These results not only underscore the algorithm’s efficiency but also demonstrate its superiority when compared to several existing state-of-the-art optimization methods, including Multi-Swarm PSO, AmQSO, CPSO, Cellular PSO, FMSO, mQSO10 (5 + 5q), and DPSABC.},
  archive      = {J_NCA},
  author       = {Mohammadpour, Majid and Mostafavi, Seyedakbar and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-024-10205-2},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19549-19583},
  shortjournal = {Neural Comput. Appl.},
  title        = {Solving dynamic optimization problems using parent–child multi-swarm clustered memory (PCSCM) algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning LSTM-based approach for AMD classification
using OCT images. <em>NCA</em>, <em>36</em>(31), 19531–19547. (<a
href="https://doi.org/10.1007/s00521-024-10149-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age-related macular degeneration (AMD) is an age-related, persistent, painless eye disease that impairs central vision. The central area (macula) of the retina, located at the back of the eye, sustains damage that is the cause of loss of vision. The early detection of AMD can increase the probability of treatment and prevent vision loss. The AMD can be classified into dry and wet AMD based on the absence of neovascularization. This study introduces a new methodology for the classification of AMD using optical coherence tomography (OCT) retinal images. The proposed methodology is based on three stages. The first stage is the data preparation stage for resizing and normalizing the used images. The second stage is the image processing stage for enhancing the image quality as contrast and resolution these enhancements have been checked by the weighted peak signal-to-noise ratio (WPSNR) methodology. The third stage is the deep feature extraction and classification stage, which consists of two sub-models. The first model is MobileNet V1 which has been used as a deep feature extractor. The second model is LSTM (long short-term memory), fed with deep features to classify the AMD stages. A multi-classification with six separate trials has been employed with the proposed methodology, and compared with other models like DenseNet201 and InceptionV3. The proposed model has been tested on a sample of benchmark data with 4005 grayscale images labeled into three classes. The proposed methodology has achieved an accuracy of 98.85%, a sensitivity of 99.09%, and a specificity of 99.1%. To ensure the effectiveness of the proposed methodology, a comparative analysis has been established with previous approaches in the related field, and the results demonstrated the superiority of the proposed system in AMD multi-classification.},
  archive      = {J_NCA},
  author       = {Hamid, Laila and Elnokrashy, Amgad and Abdelhay, Ehab H. and Abdelsalam, Mohamed M.},
  doi          = {10.1007/s00521-024-10149-7},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19531-19547},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning LSTM-based approach for AMD classification using OCT images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Forecasting intraday power output by a set of PV systems
using recurrent neural networks and physical covariates. <em>NCA</em>,
<em>36</em>(31), 19515–19529. (<a
href="https://doi.org/10.1007/s00521-024-10257-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate intraday forecasts of the power output by photovoltaic (PV) systems are critical to improve the operation of energy distribution grids. We describe a neural autoregressive model that aims to perform such intraday forecasts. We build upon a physical, deterministic PV performance model, the output of which is used as covariates in the context of the neural model. In addition, our application data relate to a geographically distributed set of PV systems. We address all PV sites with a single neural model, which embeds the information about the PV site in specific covariates. We use a scale-free approach which relies on the explicit modeling of seasonal effects. Our proposal repurposes a model initially used in the retail sector and discloses a novel truncated Gaussian output distribution. An ablation study and a comparison to alternative architectures from the literature show that the components in the best performing proposed model variant work synergistically to reach a skill score of 15.72% with respect to the physical model, used as a baseline.},
  archive      = {J_NCA},
  author       = {Bruneau, Pierrick and Fiorelli, David and Braun, Christian and Koster, Daniel},
  doi          = {10.1007/s00521-024-10257-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19515-19529},
  shortjournal = {Neural Comput. Appl.},
  title        = {Forecasting intraday power output by a set of PV systems using recurrent neural networks and physical covariates},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smoke detection in foggy surveillance environment using
parallel vision transformer network. <em>NCA</em>, <em>36</em>(31),
19499–19514. (<a
href="https://doi.org/10.1007/s00521-024-10230-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen an unprecedented increase in fire incidents, resulting in severe damage to forest regions, loss of human and animal lives, and unwarranted displacement of people. Owing to these issues, artificial intelligence-based fire detection systems have been developed. These systems mostly work with camera-based inputs for fire detection and alarm generation. As fire-smoke can be seen from a distance, methods for smoke detection have also been deployed for identifying fire incidents. But detecting smoke in an outdoor environment can be challenging due to weather conditions such as haze, fog, or clouds. These challenges have led to advancements in the field, and various deep learning architectures have been suggested over the years for fire-smoke detection in normal and foggy or cloudy weather conditions. Many existing methods are either computationally expensive and demand high memory, or if they are lightweight, they suffer from lower smoke detection accuracy and high false alarms. In the present paper, a dual-channel vision transformer model ‘SmokeViT’ is proposed for detecting fire-smoke in an outdoor environment. These channels are interlaced with a convolutional neural network to improve the feature learning capability of the model. ‘SmokeViT’ shows a remarkable accuracy of more than 99% and false alarm rate below 0.20% on two publicly available smoke datasets, outperforming six state-of-the-art methods. The model architecture has only 0.4 million parameters and 0.17 giga floating-point operations, making it suitable for deployment on resource-constrained surveillance devices.},
  archive      = {J_NCA},
  author       = {Chaturvedi, Shubhangi and Thakur, Poornima Singh and Khanna, Pritee and Ojha, Aparajita},
  doi          = {10.1007/s00521-024-10230-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19499-19514},
  shortjournal = {Neural Comput. Appl.},
  title        = {Smoke detection in foggy surveillance environment using parallel vision transformer network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new iterative fuzzy approach to the multi-objective
fractional solid transportation problem with mixed constraints using a
bisection algorithm. <em>NCA</em>, <em>36</em>(31), 19489–19497. (<a
href="https://doi.org/10.1007/s00521-024-10223-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-objective solid transportation problem that includes source, destination, and mode of transport parameters may have fractional objective functions in real-life applications to maximize the profitability ratio, which could be the profit/cost or profit/time. We refer to such transportation problems as multi-objective fractional solid transportation problems. In addition, although most of the studies in the literature deal with the standard equality-constrained form of the multi-objective fractional solid transportation problem, the mixed-constrained type is addressed in this paper. With these mixed constraints, the multi-objective fractional solid transportation problem offers more flexible modeling of real-world problems that exist in many application areas, but mixed constraints also make the optimization process more challenging. This article presents an iterative fuzzy approach that combines the use of linear programming and the bisection algorithm using linear membership functions to obtain a strongly efficient solution. The algorithm’s ability to convert a nonlinear problem into a set of linear problems is one of its main advantages, and it also decreases the amount of time needed to solve large-scale problems. A numerical example from the literature is adopted to illustrate the solution procedure. Moreover, large-scale instances are generated to further test the presented algorithm, and a comparison between the traditional fuzzy approach and the proposed method is presented.},
  archive      = {J_NCA},
  author       = {Kara, Nurdan},
  doi          = {10.1007/s00521-024-10223-0},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19489-19497},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new iterative fuzzy approach to the multi-objective fractional solid transportation problem with mixed constraints using a bisection algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blood supply chain location-inventory problem considering
incentive programs: Comparison and analysis of NSGA-II, NRGA and
electromagnetic algorithms. <em>NCA</em>, <em>36</em>(31), 19469–19487.
(<a href="https://doi.org/10.1007/s00521-024-10216-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem Blood is a rare perishable substance with limited life in the real world and blood supply chain management is a vital subject. Hence, it is trying to design an efficient supply chain network to create a balance between blood supply and demand, particularly in deficient conditions. One effective solution for blood deficiency compensation is the use of incentive programs at the right times to encourage people for blood donation. The novel aspect of this study considers a new mathematical model to design a blood supply chain network with the location of temporary centers for collecting donated blood, in addition to incentive programs in the right periods to actualize the goal of creating blood supply-demand equilibrium and minimizing the cost of the network. Method In this paper, four methods have been used in different dimensions to solve the proposed model. In this case, augmented epsilon constraint (AEC/EC) was used for small dimensions, while electromagnetic algorithm (EM), Non-dominated ranked genetic algorithm (NRGA), and non-dominated sorting genetic algorithm (NSGA-II) were used for large dimensions due to the inherent complexity of the problem. Results The performance of algorithms was analyzed based on the four standard indicators. Then, their outputs were evaluated using statistical assumption tests at the significance level of 0.05. In three considered indicators (SNS, MID, and TIME indicators), the NSGA-II algorithm outperformed the NRGA and EM algorithms. This case indicated the superiority of the NSGA-II algorithm over the NRGA and EM algorithms especially for problem solution time, which is one of the most significant indicators used in metaheuristic algorithms.},
  archive      = {J_NCA},
  author       = {Alikhani, Tayebeh and Dezfoulian, Hamidreza and Samouei, Parvaneh},
  doi          = {10.1007/s00521-024-10216-z},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19469-19487},
  shortjournal = {Neural Comput. Appl.},
  title        = {Blood supply chain location-inventory problem considering incentive programs: Comparison and analysis of NSGA-II, NRGA and electromagnetic algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recognizing salat activity using deep learning models via
smartwatch sensors. <em>NCA</em>, <em>36</em>(31), 19449–19467. (<a
href="https://doi.org/10.1007/s00521-024-10195-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we focus on human activity recognition, particularly aiming to distinguish the activity of praying (salat) from other daily activities. To achieve this goal, we have created a new dataset named HAR-P (Human activity recognition for Praying), which includes eight different activities: walking, running, sitting, standing, walking upstairs, walking downstairs, typing with a keyboard, and praying (salat). The HAR-P dataset was collected from 50 male individuals, who wore smartwatches on their dominant wrists. We compare the activity classification performance using three state-of-the-art algorithms from the literature: Long Short-Term Memory, Convolutional Long Short-Term Memory, and Convolutional Neural Network—Long Short-Term Memory. To assess the influence of sensors, data from accelerometer, gyroscope, linear acceleration sensor, and magnetic field sensor were utilized. The impact of individual sensor data as well as combinations thereof was investigated. The highest classification accuracy within single sensor groups, reaching 95.7%, was achieved using the accelerometer data with the Convolutional Long Short-Term Memory method. Combining two sensor groups resulted in an increase in accuracy of up to 9%. The highest accuracy of 96.4% was obtained by utilizing three sensor groups together with the Convolutional Neural Network—Long Short-Term Memory method. Furthermore, the evaluation of sensor and model performance was conducted using the stratified k-fold cross-validation method with 5-folds. These findings contribute significantly to evaluating the performance of sensor combinations and different algorithms in activity classification. This study may provide an effective foundation for the automatic recognition and tracking of human activities and offer an applicable model, particularly for the recognition of religious practices such as praying.},
  archive      = {J_NCA},
  author       = {Vurgun, Yasin and Kiran, Mustafa Servet},
  doi          = {10.1007/s00521-024-10195-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19449-19467},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recognizing salat activity using deep learning models via smartwatch sensors},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An empirical study on prediction of seismic activity using
stochastic configuration networks. <em>NCA</em>, <em>36</em>(31),
19435–19448. (<a
href="https://doi.org/10.1007/s00521-024-10244-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting seismic events has long been a huge challenge due to intricate nature of the underlying occurrence mechanisms. The traditional approach to estimating recurrence intervals is highly reliant on prior knowledge and expert experience, which often leads to considerable error margins. Recent advances in high-performance monitoring systems and artificial intelligence (AI) achieving great successes in various areas have renewed interest in identifying failure precursors and predicting seismic events. In this paper, we propose a genetic algorithm wrapped stochastic configuration networks (GAWSCN) approach to explore seismic physics for time-to-failure prediction. Specifically, stochastic configuration networks (SCN), a novel randomized learning paradigm, is utilized to learn essential seismic information from acoustic emission signals. To further enhance the generalization capability and alleviate overfitting, a regularization technique is imposed during the SCN training to establish a robust seismic prediction model. In particular, a genetic algorithm is integrated with SCN to optimize the selection of pertinent seismic features and further improve prediction performance. The experimental results demonstrate that our GAWSCN method outperforms other machine learning methods across evaluation metrics. This study offers promising insights for geophysical hazards assessment.},
  archive      = {J_NCA},
  author       = {Qiu, Yuanhang and Wang, Dianhui},
  doi          = {10.1007/s00521-024-10244-9},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19435-19448},
  shortjournal = {Neural Comput. Appl.},
  title        = {An empirical study on prediction of seismic activity using stochastic configuration networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of neurodegenerative diseases using hybrid MODWT
and adaptive local binary pattern. <em>NCA</em>, <em>36</em>(31),
19417–19433. (<a
href="https://doi.org/10.1007/s00521-024-10222-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative diseases cause significant irregularities in walking patterns, impacting gait dynamics and rhythms analyzed through gait time series. Human gait analysis is a promising avenue for identifying unique walking patterns. Automated computer-aided techniques show potential in tracking pathological progression, particularly through non-invasive methods using football contact sensors. In this study, wavelet coefficients extracted via the maximal overlapped discrete wavelet transform from gait time series provide valuable insights into neurological deficiencies and deviations in gait. We employed various local binary patterns (LBPs), including inverse LBP, adaptive right-shifted LBP, and adaptive left-shifted LBP (ALS-LBP) on wavelet coefficients for classifying neurodegenerative diseases such as amyotrophic lateral sclerosis (ALS), Huntington’s disease (HD), Parkinson’s disease (PD), and healthy control (HC). Histogram-oriented features were extracted using different binary pattern techniques on gait time series. The feature subset was classified using the long short-term memory classifier. The study achieved maximum accuracy across all experimental cases, analyzing signals from left, right, and both feet during stride, swing, and stance. This approach demonstrated 100% classification accuracy for tasks involving HC versus PD, ALS versus HD, and ALS versus PD. The proposed method could open avenues for early-stage diagnosis of neurodegenerative diseases.},
  archive      = {J_NCA},
  author       = {Prasanna, J. and George, S. Thomas and Subathra, M. S. P.},
  doi          = {10.1007/s00521-024-10222-1},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19417-19433},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of neurodegenerative diseases using hybrid MODWT and adaptive local binary pattern},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implementation of artificial neural network using levenberg
marquardt algorithm for casson–carreau nanofluid flow over exponentially
stretching curved surface. <em>NCA</em>, <em>36</em>(31), 19393–19415.
(<a href="https://doi.org/10.1007/s00521-024-10193-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A theoretical framework is constructed for the Casson–Carreau nanofluid flow over a curved surface that is stretched exponentially. Artificial intelligence and machine learning are in vogue as the technologies that involve them, have expanded exponentially. In the current analysis, the Levenberg–Marquardt algorithm is used to train a machine learning language made of artificial neural networks to train the mathematical model constructed by including chemical reaction, and an exponential heat source component. The activation energy effect is taken into account while analyzing the impact of fluid concentration. Double stratification and Stefan blowing boundary conditions are used. Runge–Kutta Fehlberg 4–5th order is a numerical method applied to form the solution. An artificial neural network is used to train, test, and validate numerical computations. The linear regression models, histograms, and mean squared errors are used to verify the model&#39;s accuracy. The accuracy of the training is predicted by the least error in the range of 10−3–10−4 as per the absolute error analysis carried out individually for the six parameters under consideration. Results reveal that the velocity is augmented by Weissenberg number and the mixed convection parameter. The temperature enhances for increasing unsteadiness parameter and depletes for increasing thermal stratification parameter. The concentration increases with increasing activation energy parameter and decreasing Schmidt number. Consequently, this study reveals that artificial neural network can be used as an alternative for the prediction of prolonged calculations. Nevertheless, the flow structure designed for the fluid considered in the model can be a pathway to fabricate an optimized industrial design.},
  archive      = {J_NCA},
  author       = {Almeida, F. and Kumar, Pradeep and Ajaykumar, A. R. and Nagaraja, B.},
  doi          = {10.1007/s00521-024-10193-3},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19393-19415},
  shortjournal = {Neural Comput. Appl.},
  title        = {Implementation of artificial neural network using levenberg marquardt algorithm for Casson–Carreau nanofluid flow over exponentially stretching curved surface},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for prediction of cardiomegaly using chest
x-rays. <em>NCA</em>, <em>36</em>(31), 19383–19391. (<a
href="https://doi.org/10.1007/s00521-024-10190-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, deep learning in biomedical imaging has exponentially increased the accuracy of disease detection and improved the health standards. This research paper introduces a novel approach for the early detection and diagnosis of cardiomegaly using the cardiothoracic ratio (CT ratio) measurement in chest X-ray scans. Cardiomegaly is a serious cardiac condition that can lead to life-threatening complications if left undiagnosed. The proposed method involves segmenting the heart from a chest CT scan using a convolutional neural network model, ResNet-18, and calculating the CT ratio, which is the ratio of the maximum width of the heart to the maximum width of the thoracic cage. Studies have shown that increasing CT ratio leads to an increasing risk of heart diseases. Hence, a need to monitor the CT ratio for every individual arises, for if the ratio changes, an alert to take precautions can be rang. The method is evaluated using a dataset of 490 chest X-ray scans, and it achieves an accuracy of 80% and a precision of 84%. The integration of CT ratio measurement in chest X-ray scan reports has the potential to aid in the early detection and diagnosis of cardiomegaly, allowing for prompt medical intervention and improving patient outcomes.},
  archive      = {J_NCA},
  author       = {Gupta, Mrigakshi and Singh, Akash and Kumar, Yatender},
  doi          = {10.1007/s00521-024-10190-6},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19383-19391},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning for prediction of cardiomegaly using chest X-rays},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based few-shot person re-identification from
top-view RGB and depth images. <em>NCA</em>, <em>36</em>(31),
19365–19382. (<a
href="https://doi.org/10.1007/s00521-024-10239-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-id) attempts to match a person from the images of different time steps. Existing deep learning approaches either use appearance or geometry features for re-id which does not provide the required robustness because of higher intra-class similarity. Existing supervised re-id approaches utilize Convolutional Neural Networks (CNNs) and identity-labeled images to train, where the person images are taken by the sensors from a horizontal view. The horizontal view exposes the privacy of the people because of their facial appearance in the image. Moreover, person re-id includes new unseen people; however, CNN does not have the ability to identify the new unseen people because of a lack of continual learning. Privacy-preserved computer vision-assisted person re-id systems can benefit from visual appearance and geometry features extracted from top-view RGB and depth input. This paper presents the privacy-preserved person top-view re-id few-shot network which uses the appearance and geometry features. The EfficientNet is used for appearance-based features from RGB input, while PointNet is used to extract the geometry features from the point cloud which is made from the RGB-D image registration. Concatenated features from EfficientNet and PointNet are fed to the two-layer Bi-LSTM network for person identification. Finally, the whole network is converted into a few-shot network to achieve continual learning by removing the output layer and joining the similarity measurement unit. This approach is based on CNN and fine-tunes a TVPR/2 dataset acquired by using a top-view arrangement that is publicly available. The experimental results on TVPR/2 and GODPR datasets show that the proposed re-id network outperforms other state-of-the-art networks.},
  archive      = {J_NCA},
  author       = {Abed, Almustafa and Akrout, Belhassen and Amous, Ikram},
  doi          = {10.1007/s00521-024-10239-6},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19365-19382},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based few-shot person re-identification from top-view RGB and depth images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approaches based on language models for aspect extraction
for sentiment analysis in the portuguese language. <em>NCA</em>,
<em>36</em>(31), 19353–19363. (<a
href="https://doi.org/10.1007/s00521-024-10265-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the gap in aspect extraction techniques for Portuguese by adapting methods originally designed for English. It focuses on TV devices and literary reviews in the TV and ReLi datasets. For this, models based on the BERT architecture were employed, including pre-trained general domain (BERTimbau) and specific domain models (BERTtv and BERTreli). Also, this paper contributes with a novel double embedding technique that merges these models. We further explored the potential of large language models (LLMs) with a Portuguese-trained LLaMa variant, Cabrita. Efficient fine-tuning techniques such as LoRA (low-rank adaptation) for BERTimbau and QLoRA (quantized low-rank adaptation) for Cabrita were applied to optimize resource demands. The BERTimbau model, adjusted with LoRA, achieved the highest F1 scores (0.846 for TV and 0.615 for ReLi), while Cabrita showed lower performance (0.68 for TV and 0.46 for ReLi). This study underscores the potential of adapting and optimizing existing techniques for aspect extraction in Portuguese, marking a significant advancement in the field},
  archive      = {J_NCA},
  author       = {Neto, José Carlos Ferreira and Pereira, Denilson Alves and Barbosa, Bruno Henrique Groenner and Ferreira, Danton Diego},
  doi          = {10.1007/s00521-024-10265-4},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19353-19363},
  shortjournal = {Neural Comput. Appl.},
  title        = {Approaches based on language models for aspect extraction for sentiment analysis in the portuguese language},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal prediction model with context-aware data
augmentation for robust visual reinforcement learning. <em>NCA</em>,
<em>36</em>(31), 19337–19352. (<a
href="https://doi.org/10.1007/s00521-024-10251-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While reinforcement learning has shown promising abilities to solve continuous control tasks from visual inputs, it remains a challenge to learn robust representations from high-dimensional observations and generalize to unseen environments with distracting elements. Recently, strong data augmentation has been applied to increase the diversity of the training data, but it may damage the task-relevant pixels and thus hinder the optimization of reinforcement learning. To this end, this paper proposes temporal prediction model with context-aware data augmentation (TPMC), a framework which incorporates context-aware strong augmentation into the dynamic model for learning robust policies. Specifically, TPMC utilizes the gradient-based saliency map to identify and preserve task-relevant pixels during strong augmentation, generating reliable augmented images for stable training. Moreover, the temporal prediction consistency between strong and weak augmented views is enforced to construct a contrastive objective for learning shared task-relevant representations. Extensive experiments are conducted to evaluate the performance on DMControl-GB benchmarks and several robotic manipulation tasks. Experimental results demonstrate that TPMC achieves superior data-efficiency and generalization to other state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Yue, Xinkai and Ge, Hongwei and He, Xin and Hou, Yaqing},
  doi          = {10.1007/s00521-024-10251-w},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19337-19352},
  shortjournal = {Neural Comput. Appl.},
  title        = {Temporal prediction model with context-aware data augmentation for robust visual reinforcement learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implementation of four machine learning algorithms for
forecasting stock’s low and high prices. <em>NCA</em>, <em>36</em>(31),
19323–19336. (<a
href="https://doi.org/10.1007/s00521-024-10247-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, several tools and statistical techniques can be used to find profitable trading opportunities, particularly when it comes to predicting stock closing prices. Yet, a few studies have been done on daily low- and high-price predictions which are useful for estimating support and resistance prices and improving the timing of stock purchases and sales. In this paper, we suggest combining machine learning algorithms with seven statistical features to enhance the forecasts of the low and high prices for the upcoming 5 days. In the experiment, the performances of linear regression, k-nearest neighbor, support vector machine (SVM), and the enhanced bidirectional LSTM (Bi-LSTM) were compared. Our findings showed that the Bi-LSTM surpassed the competition with a low RMSE of 0.018, a decrease in the error of over 58% compared to SVM, and a reduction of 51% compared to the unimproved LSTM. The four implemented algorithms are accessible online through a web application that displays the trend for the upcoming 5 days together with projected lines for the best-selling price (the high price) and the best-purchasing price (the low price).},
  archive      = {J_NCA},
  author       = {Heednacram, Apichat and Kliangsuwan, Thitinan and Werapun, Warodom},
  doi          = {10.1007/s00521-024-10247-6},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19323-19336},
  shortjournal = {Neural Comput. Appl.},
  title        = {Implementation of four machine learning algorithms for forecasting stock’s low and high prices},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective cell configuration considering part quality
and machine compatibility. <em>NCA</em>, <em>36</em>(31), 19307–19322.
(<a href="https://doi.org/10.1007/s00521-024-10215-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formulate the generalized group technology concept in cellular manufacturing under two new assumptions. Each process routing is indexed by a level of quality and each pair of machines is indexed by a level of compatibility. The quality of parts depends on their processing. The compatibility between machines corresponds to their ability to work together. Three objective functions are designed. They are minimizing exceptional elements, maximizing total quality of parts, and maximizing total compatibility between machines. A genetic algorithm (GA) embedded simple augmented ε-constraint (SAEC) is proposed. Computational experiments are performed on the GA-embedded SAEC, the SAEC, and a nondominated sorting GA. We compare the trade-off solutions produced by the three techniques. Due to the similarity in structure, we also make a direct comparison between the GA-embedded SAEC and the SAEC in terms of the quality of the most preferred solutions obtained. The results indicate that the hybrid approach performs satisfactorily within reasonable computation time.},
  archive      = {J_NCA},
  author       = {Heydari, Habib and Paydar, Mohammad Mahdi and Mahdavi, Iraj and Khatayi, Alireza},
  doi          = {10.1007/s00521-024-10215-0},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19307-19322},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective cell configuration considering part quality and machine compatibility},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Understanding the complexities of the fine structure of
interest rates: A wasserstein barycenter learning approach.
<em>NCA</em>, <em>36</em>(31), 19291–19305. (<a
href="https://doi.org/10.1007/s00521-024-10202-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel methodology to investigate the fine structure of interest rates based on Machine Learning techniques is discussed. The aim is to capture in an unsupervised way the common stochastic structure that drives the dynamics of interest rates of different maturities. The proposed approach is based on the Wasserstein barycenter, a powerful tool of analysis that allows us to construct, from a set of assigned probability distributions, a single probability distribution that captures the essential features of the whole set. To identify common stochastic factors, a Gaussian Mixture Model is fitted to the Wasserstein barycenter by maximum likelihood using the Expectation-Maximization algorithm with an initialization strategy based on Graph Machine Learning techniques. A fine-tuning of single-maturity interest rates is discussed in an attempt to capture maturity-specific stochastic factors. The proposed analysis also gives us the opportunity to test the hypothesis of a market segmentation into a short-term segment, the money market, and a long-term segment, the capital market, each with its own segment-specific stochastic factors. The methodology is tested on the US zero-coupon Treasury yield curve. The results obtained seem to show that most of the stochastic nature of the dynamics of the US zero-coupon yield curve can be captured by a three-component Gaussian Mixture Model describing the Wasserstein barycenter of the short-term segment of the yield curve.},
  archive      = {J_NCA},
  author       = {Mari, Carlo and Baldassari, Cristiano},
  doi          = {10.1007/s00521-024-10202-5},
  journal      = {Neural Computing and Applications},
  month        = {11},
  number       = {31},
  pages        = {19291-19305},
  shortjournal = {Neural Comput. Appl.},
  title        = {Understanding the complexities of the fine structure of interest rates: A wasserstein barycenter learning approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved slime mould algorithm for optimal hybrid power
system scheduling. <em>NCA</em>, <em>36</em>(30), 19267–19289. (<a
href="https://doi.org/10.1007/s00521-024-10200-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an improved slime mould algorithm (ISMA) to minimize the total electricity generation cost of thermal power plants (TPs) in newly developed hybrid power systems with pumped storage hydropower plants (PSHPs), cascaded hydropower plants (CHPs), photovoltaic power plants (PVPs), conventional hydropower plants, and TPs. ISMA is a better version of the original slime mould algorithm (OSMA) by cancelling OSMA’s shortcomings and applying new methods to update new control variables. ISMA replaces two equations of OSMA to update new solutions. In the first equation, ISMA search around each old solution by adding one more increased interval, while OSMA multiplies each old solution by a vector with terms having smaller values than one. In the second equation, OSMA searches around the best solution by adding one more increased interval, but ISMA has a more flexible search by expanding search zones with two additional increased intervals or keeping narrow search zones with one additional increased interval. In addition to OSMA, ISMA is also compared to equilibrium optimizer (EO), jellyfish algorithm (JS), and northern goshawk optimization algorithm (NGO). After solving a test system, ISMA reaches a smaller cost than NGO, JS, EO, and OSMA by 2.43%, 0.68%, 2.83%, and 1.52%, respectively. Then, ISMA is applied for two cases: considering and neglecting the water storage function of PSHPs. Thanks to the water storage function of PSHPs, the total cost of the system is smaller than another case without the water storage function of PSHPs by $196,578.6, corresponding to 8.4%. Clearly, the contribution of the PSHPs to the economic effectiveness of hybrid power systems is huge, and the proposed ISMA is a very suitable optimization tool for finding operation solutions for newly developed hybrid power systems. Hence, the proposed ISMA should be tried for other hybrid power systems with the PSHPs and other power sources, as well as more practical conditions.},
  archive      = {J_NCA},
  author       = {Ha, Phu Trieu and Tran, Dao Trong and Nguyen, Thuan Thanh and Nguyen, Thang Trung},
  doi          = {10.1007/s00521-024-10200-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19267-19289},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved slime mould algorithm for optimal hybrid power system scheduling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Orthrus: Multi-scale land cover mapping from satellite image
time series via 2D encoding and convolutional neural network.
<em>NCA</em>, <em>36</em>(30), 19247–19265. (<a
href="https://doi.org/10.1007/s00521-024-10186-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of modern Earth observation (EO) systems, the opportunity of collecting satellite image time series (SITS) provides valuable insights to monitor spatiotemporal dynamics. Within this context, accurate land use/land cover (LULC) mapping plays a pivotal role in supporting territorial management and facilitating informed decision-making processes. However, traditional pixel-based and object-based classification methods often face challenges to effectively exploit spectral and spatial information. In this study, we propose Orthrus, a novel approach that fuses multi-scale information for enhanced LULC mapping. The proposed approach exploits several 2D encoding techniques to encode times series information into imagery. The resulting image is leveraged as input to a standard convolutional neural network (CNN) image classifier to cope with the downstream classification task. The evaluations on two real-world benchmarks, namely Dordogne and Reunion-Island, demonstrated the quality of Orthrus over state-of-the-art techniques from the field of land cover mapping based on SITS data. More precisely, Orthrus exhibits an enhancement of more than 3.5 accuracy points compared to the best competing approach on the Dordogne benchmark, and surpasses the best competing approach on the Reunion-Island dataset by over 3 accuracy points.},
  archive      = {J_NCA},
  author       = {Abidi, Azza and Ienco, Dino and Ben Abbes, Ali and Farah, Imed Riadh},
  doi          = {10.1007/s00521-024-10186-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19247-19265},
  shortjournal = {Neural Comput. Appl.},
  title        = {Orthrus: Multi-scale land cover mapping from satellite image time series via 2D encoding and convolutional neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable multi-layer COSFIRE filters robust to
corruptions and boundary attack with application to retina and palmprint
biometrics. <em>NCA</em>, <em>36</em>(30), 19231–19245. (<a
href="https://doi.org/10.1007/s00521-024-10164-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel and versatile computational approach, based on hierarchical COSFIRE filters, that addresses the challenge of explainable retina and palmprint recognition for automatic person identification. Unlike traditional systems that treat these biometrics separately, our method offers a unified solution, leveraging COSFIRE filters’ trainable nature for enhanced selectivity and robustness, while exhibiting explainability and resilience to decision-based black-box adversarial attack and partial matching. COSFIRE filters are trainable, in that their selectivity can be determined with a one-shot learning step. In practice, we configure a COSFIRE filter that is selective for the mutual spatial arrangement of a set of automatically selected keypoints of each retina or palmprint reference image. A query image is then processed by all COSFIRE filters and it is classified with the reference image that was used to configure the COSFIRE filter that gives the strongest similarity score. Our approach, tested on the VARIA and RIDB retina datasets and the IITD palmprint dataset, achieved state-of-the-art results, including perfect classification for retina datasets and a 97.54% accuracy for the palmprint dataset. It proved robust in partial matching tests, achieving over 94% accuracy with 80% image visibility and over 97% with 90% visibility, demonstrating effectiveness with incomplete biometric data. Furthermore, while effectively resisting a decision-based black-box adversarial attack and impervious to imperceptible adversarial images, it is only susceptible to highly perceptible adversarial images with severe noise, which pose minimal concern as they can be easily detected through histogram analysis in preprocessing. In principle, the proposed learning-free hierarchical COSFIRE filters are applicable to any application that requires the identification of certain spatial arrangements of moderately complex features, such as bifurcations and crossovers. Moreover, the selectivity of COSFIRE filters is highly intuitive; and therefore, they provide an explainable solution.},
  archive      = {J_NCA},
  author       = {Apap, Adrian and Bhole, Amey and Fernández-Robles, Laura and Castejón-Limas, Manuel and Azzopardi, George},
  doi          = {10.1007/s00521-024-10164-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19231-19245},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable multi-layer COSFIRE filters robust to corruptions and boundary attack with application to retina and palmprint biometrics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable AI approach for early detection of parkinson’s
disease using PPMI online data. <em>NCA</em>, <em>36</em>(30),
19209–19230. (<a
href="https://doi.org/10.1007/s00521-024-10127-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and early disease prediction enables patients to plan and improve their quality of life in the future. Early detection of neurodegenerative diseases, such as Parkinson’s disease, is a high priority and a significant challenge in which physicians must act quickly to diagnose and predict the risk of disease severity. Machine learning (ML) models combined with feature selection (FS) techniques can assist physicians in quickly diagnosing a disease. FS technique optimally subsets features to improve model performance and reduce the number of tests required for a patient, thereby speeding up diagnosis. This paper proposes an e-diagnosis approach based on ML-FS algorithms to detect Parkinson’s disease using data obtained from Parkinson’s Progression Markers Initiative (PPMI) Online study. Also, it can be considered patient-oriented research as it uses self-reported online collected data. The results of six FS techniques pre-applied to classification algorithms named logistic regression, random forest, support vector machine, CatBoost, extreme learning machine, and XGBoost are shown in this study. Chi-square, mutual information, and analysis of variance (ANOVA) filter-based FS methods, while sequential feature selection, Boruta, and recursive feature elimination are considered wrapper methods. The outcomes show that random forest when trained on features selected by the recursive feature elimination technique help to build an efficient and effective approach for detecting Parkinson’s disease.},
  archive      = {J_NCA},
  author       = {Aggarwal, Nitisha and Saxena, Geetika Jain and Singh, Sanjeev and Pundir, Amit},
  doi          = {10.1007/s00521-024-10127-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19209-19230},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable AI approach for early detection of parkinson’s disease using PPMI online data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intelligent skin cancer detection system using two-level
multi-column convolutional neural network architecture. <em>NCA</em>,
<em>36</em>(30), 19191–19207. (<a
href="https://doi.org/10.1007/s00521-024-10252-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, the medical field is witnessing a greater need and the subsequent involvement of technology and automation. Skin cancer detection is one particular area in the medical field that is in dire need of such automation because day by day, the complexity of skin cancer is increasing and it is becoming more difficult to depend on specialized doctors at all instances. The aim of this work is to create a skin cancer detection system using DICOM images and multi-column convolutional neural networks (CNNs). DICOM dataset was chosen because it contains additional information about a patient which is not available in raw images, like age, gender, special medical conditions, time period, etc. This work uses the ISIC 2020 dataset which contains DICOM formatted data of cancerous and non-cancerous images of the outer skin. The images are trained in a separate multi-column CNN architecture, and simultaneously the additional information, or tag information, is trained in a separate dense network, then the parameters from these two sub-models are concatenated to give a single prediction. For comparison purpose, three other models were developed, one based on raw images alone, one based on preprocessed images and one based on preprocessed images alone with a multi-column CNN network. The following evaluation metrics are recorded and compared for all models: accuracy (training, validation and testing), F1-score, specificity and root-mean-square error (RMSE). Additionally, a comparative analysis is carried out with a previous work on the same field published in 2019 that utilized a MobileNet architecture. The proposed model achieved high accuracy when it is compared with other models. Moreover, the model also provide the results for a tenfold cross-validation carried out and to highlight the specific data split that yields the best results for training, validation and testing accuracies.},
  archive      = {J_NCA},
  author       = {Sivakumar, Akash and Vedhapriyavadhana, R. and Ganapathy, Sannasi},
  doi          = {10.1007/s00521-024-10252-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19191-19207},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent skin cancer detection system using two-level multi-column convolutional neural network architecture},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Evaluation of aircraft engine performance during takeoff
phase with machine learning methods. <em>NCA</em>, <em>36</em>(30),
19173–19190. (<a
href="https://doi.org/10.1007/s00521-024-10220-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the takeoff phase, aircraft engines reach maximum speed and temperature to achieve the required thrust. Due to these harsh operating conditions, the performance of aircraft engines may decrease. This decrease in performance increases both fuel consumption and environmental damage. Reducing or eliminating the damages caused by aircraft is among the objectives of ICAO. In order to achieve this goal, aircraft engines are compulsorily tested, evaluated by experts and certified. The data obtained during the test process is recorded and stored in the engine emission databank (EEDB). During the takeoff phase, there is no system that can evaluate aircraft engines without dismantling and without expert knowledge. In this study, EEDB 2019 and 2021 takeoff phase data sets were used. Fuel flow T/O parameter is an important parameter used both in the calculation of aircraft emissions and in the evaluation of engine performance. Gaussian process regression (GPR), support vector machine (SVM) and multilayer perceptron (MLP) models were used to estimate the fuel flow T/O parameter. The results obtained were compared according to error performance criteria and the best model was selected. In MATLAB® environment, confidence intervals were plotted with the estimated fuel flow T/O value at 99% confidence level. This study demonstrates that the performance evaluation of aircraft engines during the takeoff phase can be performed without the need for expert knowledge.},
  archive      = {J_NCA},
  author       = {Kurt, Bulent},
  doi          = {10.1007/s00521-024-10220-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19173-19190},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation of aircraft engine performance during takeoff phase with machine learning methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balancing accuracy and efficiency: A homogeneous ensemble
approach for lithium-ion battery state of charge estimation in electric
vehicles. <em>NCA</em>, <em>36</em>(30), 19157–19171. (<a
href="https://doi.org/10.1007/s00521-024-10210-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, lithium-ion batteries (LIB) have become the de facto energy storage means for electric vehicles (EVs) due to their high energy density. However, LIBs require state of charge (SOC) monitoring to ensure safe operating conditions and for an enhanced lifespan. Since SOC cannot be directly measured, various estimation methods have been proposed in recent literature, most notably the recent rise in popularity of long short-term memory-recurrent neural networks (LSTM-RNN). Current research in the use of LSTM-RNNs typically applies a single strong data-driven model that can produce accurate predictions at the expense of lengthy model training times. As LSTM-RNNs must be retrained as LIBs age to maintain reasonable estimation accuracies, this poses a problem for EV battery management system processors. To address this research gap, this work proposes a homogeneous ensemble learning model based on several LSTM-RNN base models, as a solution to reduce the training time. The LSTM base models are fused by a meta-learner, to overcome the shortcomings of traditional ensemble fusion methods. Data diversification methods for homogeneous ensembles are also reviewed and benchmarked in this paper. The proposed method achieves a low model training time by 2.6–3.5 times while maintaining a similar mean absolute error (MAE) of 1.4% when compared to conventional shallow and deep LSTM-RNN models. The proposed model was also successfully validated with battery discharge data collected from a custom build battery tester. It is anticipated that the proposed LIB SOC estimation approach can contribute to increased feasibility of using artificial intelligence in EVs in general and improve EV battery management.},
  archive      = {J_NCA},
  author       = {Wong, Rae Hann and Sooriamoorthy, Denesh and Manoharan, Aaruththiran and Binti Sariff, Nohaidda and Hilmi Ismail, Zool},
  doi          = {10.1007/s00521-024-10210-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19157-19171},
  shortjournal = {Neural Comput. Appl.},
  title        = {Balancing accuracy and efficiency: A homogeneous ensemble approach for lithium-ion battery state of charge estimation in electric vehicles},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel methodology for offline english handwritten
character recognition using ELBP-based sequential (CNN). <em>NCA</em>,
<em>36</em>(30), 19139–19156. (<a
href="https://doi.org/10.1007/s00521-024-10206-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten character recognition falls under the domain of image classification, which has been under research for years. But still, specific gaps need to be highlighted as offline handwritten character recognition (OHCR) with the limitation of the unstructured hierarchy of character classification. However, the idea is to make the machine recognize handwritten human characters. The language focused on in this research paper is English, using offline handwritten character recognition for identifying English characters. There are many publicly available datasets, of which EMNIST is the most challenging. The key idea of this research paper is to recommend a deep learning-based ELBP-CNN method to help recognize English characters. This research paper proposes a deep learning CovNet with feature extraction and novel local binary pattern-based approaches, LBP (AND, OR), that is tested and compared with renowned pre-trained models using transfer learning. These parametric settings address multiple issues and are finalized after experimentation. The same hyperparametric settings were used for all the models under test and E-Character, with the same data augmentation settings. The proposed model, named the E-Character recognizer, produced 87.31% accuracy. It was better than most of the tested pre-trained models and other proposed methods by other researchers. This research paper further highlighted some problems, like misclassification due to the similar structure of characters.},
  archive      = {J_NCA},
  author       = {Humayun, Muniba and Siddiqi, Raheel and Uddin, Mueen and Kandhro, Irfan Ali and Abdelhaq, Maha and Alsaqour, Raed},
  doi          = {10.1007/s00521-024-10206-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19139-19156},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel methodology for offline english handwritten character recognition using ELBP-based sequential (CNN)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuroQuMan: Quantum neural network-based consumer reaction
time demand response predictive management. <em>NCA</em>,
<em>36</em>(30), 19121–19138. (<a
href="https://doi.org/10.1007/s00521-024-10201-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand response, and artificial intelligence integration with it, have a considerable effect in optimizing energy consumption, grid stability, and promoting sustainable energy practices. Consequently, this paper presents NeuroQuMan, a comprehensive methodology for simulating demand response using a three-Qubit quantum neural network (QNN) model. NeuroQuMan integrates quantum computing and machine learning techniques to accurately predict demand based on user reaction time. The methodology encompasses an advanced structure that includes data preprocessing, three-Qubit quantum device initialization, quantum circuit definition, user decision-making, QNN predictions, loss calculations, and visualization. During the tests, NeuroQuMan achieved considerable performance values of metrics, with RMSPE of 5.41%, MAPE of 4.43%, as well as MAE of 0.37, RMSE of 0.45, and MSE of 0.21, respectively. These metrics manifest the accuracy and effectiveness of NeuroQuMan in predicting demand response. By the side of future perspectives of the work, it explores the application of advanced quantum techniques to further enhance prediction accuracy. NeuroQuMan represents the potential of quantum computing in addressing demand response challenges and provides a pathway toward more resilient and intelligent energy management systems. The findings and framework presented in this paper are utilized to advance the field of demand response and quantum-based energy management techniques using a three-Qubit structure.},
  archive      = {J_NCA},
  author       = {Safari, Ashkan and Badamchizadeh, Mohammad Ali},
  doi          = {10.1007/s00521-024-10201-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19121-19138},
  shortjournal = {Neural Comput. Appl.},
  title        = {NeuroQuMan: Quantum neural network-based consumer reaction time demand response predictive management},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel fractional physics-informed neural networks method
for solving the time-fractional huxley equation. <em>NCA</em>,
<em>36</em>(30), 19097–19119. (<a
href="https://doi.org/10.1007/s00521-024-10177-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neural network methods in solving differential equations have significant research importance and promising application prospects. Aimed at the time-fractional Huxley (TFH) equation, we propose a novel fractional physics-informed neural networks (fPINNs) method. By integrating the physical information of the TFH equation into neural networks, the fPINNs are trained as a precise approximation model for solving the TFH equation. The fPINNs method involves calculating the Caputo fractional derivative using the L1 formula and estimating the integer-order derivative through the chain rule. The Adam algorithm is employed to optimize two kinds of loss functions constructed by hard and soft constraints, respectively. Through an analysis of the impact of fPINNs parameters on training results, we identify the optimal parameter configuration for solving both one-dimensional and two-dimensional (2D) TFH equations. Numerical examples validate the efficiency and robustness of the fPINNs method in solving TFH equations. Furthermore, numerical simulation of the 2D TFH problem demonstrates the method’s practical applicability to engineering problem.},
  archive      = {J_NCA},
  author       = {Shi, Jieyu and Yang, Xiaozhong and Liu, Xinlong},
  doi          = {10.1007/s00521-024-10177-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19097-19119},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel fractional physics-informed neural networks method for solving the time-fractional huxley equation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal knowledge embedding via circular
correlation: Insights into functional urban area travel pattern mining.
<em>NCA</em>, <em>36</em>(30), 19075–19095. (<a
href="https://doi.org/10.1007/s00521-024-10167-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent urban studies, understanding the flow patterns of urban residents has become crucial for effective transportation planning and business district design. Traditional data-driven approaches have provided insights but often lead to random and uninterpretable results due to their sole reliance on data features, lacking a deeper contextual and semantic analysis of the underlying patterns. To overcome these limitations, our work introduces a novel framework that fuses holographic knowledge embedding with graph deep learning to predict urban population travel patterns. This dual-driven approach of data and knowledge uniquely integrates traffic geographic information, vehicle trajectory data, and Points of Interest (POI) into a comprehensive urban traffic knowledge graph. Our method not only captures the spatial-temporal dependencies of big data traffic but also models the relationships between geographic, semantic POI information, and urban travel behaviors. The knowledge graph is then processed through a graph deep learning model, enhancing the embedding features and enabling sophisticated link prediction. Compared with conventional data-driven methods, our approach demonstrates significant advancements in harnessing semantic information, leading to more accurate and interpretable predictions of travel patterns. Experimental validation on real-world datasets confirms the effectiveness of our method in capturing complex urban dynamics.},
  archive      = {J_NCA},
  author       = {Pan, Qihong and Chen, Yao and Shen, Guojiang and Yang, Yao and Kong, Xiangjie},
  doi          = {10.1007/s00521-024-10167-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19075-19095},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatio-temporal knowledge embedding via circular correlation: Insights into functional urban area travel pattern mining},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Utilization of genetic algorithm in tuning the
hyper-parameters of hybrid NN-based side-slip angle estimators.
<em>NCA</em>, <em>36</em>(30), 19055–19074. (<a
href="https://doi.org/10.1007/s00521-024-10115-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a solution to enhance and compare different neural network (NN)-based side-slip angle estimators. The feed-forward neural networks (FFNNs), recurrent neural networks, long short-term memory units (LSTMs), and gated recurrent units are investigated. However, there is a lack in the selection criteria of the architectures’ hyper-parameters. Therefore, the genetic algorithm is integrated with the NN-based estimators to find the optimal hyper-parameters for the studied architectures. The tuned hyper-parameters in this work include the number of neurons, number of layers, activation function, optimizer type, and learning rate. The objective function of the optimization problem is minimizing the root-mean-square error (RMSE) on multiple testing data. The optimal models are further included in the design of a hybrid NN estimator with Kalman filter. In the hybrid estimators, the optimal NN estimators are used as virtual sensors to correct the prediction of the side-slip angle resulting from the mathematical lateral vehicle model. Eventually, the performance of the best selected model is evaluated in terms of different metrics; mean RMSE, mean error variance, mean training time, and mean estimation time. LSTMs are found to achieve the lowest mean RMSE while being tested on highly generalized data yielding the highest training and estimation time. However, FFNNs achieve the lowest RMSE while being tested on low generalized data and the lowest training and estimation time. Meanwhile, it is observed that the hybrid estimators achieved lower RMSE with great enhancement compared to the non-hybridized ones proving the effectiveness of the proposed approach and increasing the side-slip estimation generalization ability in unknown environments with high uncertainties, which are not covered by the training dataset for the NNs estimators.},
  archive      = {J_NCA},
  author       = {Essa, Mohamed G. and Elias, Catherine M. and Shehata, Omar M.},
  doi          = {10.1007/s00521-024-10115-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19055-19074},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utilization of genetic algorithm in tuning the hyper-parameters of hybrid NN-based side-slip angle estimators},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pipeline and dataset generation for automated fact-checking
in almost any language. <em>NCA</em>, <em>36</em>(30), 19023–19054. (<a
href="https://doi.org/10.1007/s00521-024-10113-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a pipeline for automated fact-checking leveraging publicly available language models and data. The objective is to assess the accuracy of textual claims using evidence from a ground-truth evidence corpus. The pipeline consists of two main modules—the evidence retrieval and the claim veracity evaluation. Our primary focus is on the ease of deployment in various languages that remain unexplored in the field of automated fact-checking. Unlike most similar pipelines, which work with evidence sentences, our pipeline processes data on a paragraph level, simplifying the overall architecture and data requirements. Given the high cost of annotating language-specific fact-checking training data, our solution builds on the question answering for claim generation method, which we adapt and use to generate the data for all models of the pipeline. Our strategy enables the introduction of new languages through machine translation of only two fixed datasets of moderate size. Subsequently, any number of training samples can be generated based on an evidence corpus in the target language. We provide open access to all data and fine-tuned models for Czech, English, Polish, and Slovak pipelines, as well as to our codebase that may be used to reproduce the results.  We comprehensively evaluate the pipelines for all four languages, including human annotations and per-sample difficulty assessment using Pointwise $${\mathcal {V}}$$ -information. The presented experiments are based on full Wikipedia snapshots to promote reproducibility. To facilitate implementation and user interaction, we develop the FactSearch application featuring the proposed pipeline and the preliminary feedback on its performance.},
  archive      = {J_NCA},
  author       = {Drchal, Jan and Ullrich, Herbert and Mlynář, Tomáš and Moravec, Václav},
  doi          = {10.1007/s00521-024-10113-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {19023-19054},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pipeline and dataset generation for automated fact-checking in almost any language},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Coupled conditional neural movement primitives.
<em>NCA</em>, <em>36</em>(30), 18999–19021. (<a
href="https://doi.org/10.1007/s00521-024-10077-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning sensorimotor trajectories through flexible neural representations is fundamental for robots as it facilitates the building of motor skills as well as equipping them with the ability to represent the world as predictable temporal events. Recent advances in deep learning led to the development of powerful learning from demonstration (LfD) systems such as Conditional Neural Movement Primitives (CNMPs). CNMPs can robustly represent skills as movement distributions and allow them to be ‘recalled’ by conditioning the movement on a few observation points. In this study, we focus on improving CNMPs to achieve a higher resource economy by adopting a divide-and-conquer approach. We propose a novel neural architecture called Coupled CNMP (C-CNMP), that couples the latent spaces of a pair of CNMPs that splits a given sensorimotor trajectory into segments whose learning is undertaken by smaller sub-networks. Therefore, each sub-network needs to deal with a less complex trajectory making the learning less resource-hungry. With systematic simulations on a controlled trajectory data set, we show that the overhead brought by the coupling introduced in our model is well offset by the resource and performance gain obtained. To be specific, with CNMP model as the baseline, it is shown that the proposed model is able to learn to generate trajectories in the data set with a lower trajectory error measured as the mean absolute difference between the generated trajectory and the ground truth. Importantly, our model can perform well with relatively limited resources, i.e., with less number of neural network parameters compared to the baseline. To show that the findings from the controlled data set well-transfer to robot data, we use robot joint data in an LfD setting and compare the learning performance of the proposed model with the baseline model at equal complexity levels. The simulation experiments show that with also the robot joint data, the proposed model, C-CNMP, learns to generate the joint trajectories with significantly less error than the baseline model. Overall, our study improves the state of the art in sensorimotor trajectory learning and exemplifies how divide-and-conquer approaches can benefit deep learning architectures for resource economy.},
  archive      = {J_NCA},
  author       = {Pekmezci, Mehmet and Ugur, Emre and Oztop, Erhan},
  doi          = {10.1007/s00521-024-10077-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18999-19021},
  shortjournal = {Neural Comput. Appl.},
  title        = {Coupled conditional neural movement primitives},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method for the detection and classification of
multiple diseases using transfer learning-based deep learning techniques
with improved performance. <em>NCA</em>, <em>36</em>(30), 18979–18997.
(<a href="https://doi.org/10.1007/s00521-024-09900-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A disease is a distinct abnormal state that significantly affects the functioning of all or part of an individual and is not caused by external harm. Diseases are frequently understood as medical conditions connected with distinct indications and symptoms. According to a fairly wide categorization, diseases can also be categorized as mental disorders, deficient diseases, genetic diseases, degenerative diseases, self-inflicted diseases, infectious diseases, non-infectious diseases, social diseases, and physical diseases. Prevention of the diseases is of multiple instances. Primary prevention seeks to prevent illness or harm before it ever happens. Secondary prevention tries to lessen the effect of an illness or damage that has already happened. This is done through diagnosing and treating illness or injury as soon as feasible to stop or delay its course, supporting personal ways to avoid recurrence or reinjury, and implementing programs to restore individuals to their previous health and function to prevent long-term difficulties. Tertiary prevention tries to lessen the impact of a continuing sickness or injury that has enduring repercussions. Diagnosis of the disease at an earlier stage is important for the treatment of the disease. Hence, in this study, deep learning algorithms, such as VGG16, EfficientNetB4, and ResNet, are utilized to diagnose various diseases, such as Alzheimer&#39;s, brain tumors, skin diseases, and lung diseases. Chest X-rays, MRI scans, CT scans, and skin lesions are used to diagnose the mentioned diseases. Transfer learning algorithms, such as VGG16, VGG19, ResNet, InceptionV3, and EfficientNetB4, are utilized to categorize various diseases. EfficientNetB4 with the learning rate annealing, having obtained an accuracy of 94.04% on the test dataset, is observed. As a consequence, we observed that every network has unique particular skills on the multi-disease dataset, which includes chest X-rays, MRI scans, etc.,},
  archive      = {J_NCA},
  author       = {Natarajan, Krishnamoorthy and Muthusamy, Suresh and Sha, Mizaj Shabil and Sadasivuni, Kishor Kumar and Sekaran, Sreejith and Charles Gnanakkan, Christober Asir Rajan and A.Elngar, Ahmed},
  doi          = {10.1007/s00521-024-09900-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18979-18997},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel method for the detection and classification of multiple diseases using transfer learning-based deep learning techniques with improved performance},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weed detection and classification in sesame crops using
region-based convolution neural networks. <em>NCA</em>, <em>36</em>(30),
18961–18977. (<a
href="https://doi.org/10.1007/s00521-024-10231-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Farming has many moving parts, including planting, watering, harvesting, and more. One of their most complex and time-consuming is keeping an eye out for and controlling weeds that might ruin a harvest. Unwanted weeds cause decreased crop productivity by competing with desired agricultural plants for water, sunshine, and soil nutrients. This research aims to use Region-Based Convolutional Neural Networks (RCNNs) to detect weeds in photographs of sesame crops and then classify them into their respective weed families. Object detection is a promising use of deep learning, and the suggested method takes advantage of RCNNs, a prominent method. By applying RCNNs to sesame crop images, we could accurately identify the presence of weeds, achieving an impressive detection accuracy of 96.84%. This high accuracy can significantly aid farmers in pinpointing areas of their fields that require immediate attention and weed management strategies. Furthermore, after successfully detecting weeds, we classified them into different types. This classification step is crucial as different weed species require specific control measures. Our proposed methodology achieved an outstanding weed classification accuracy of 97.79%. By correctly categorizing weeds, farmers better understand the weed composition in their fields, making it easier to use targeted control methods and lessen the use of possibly dangerous chemicals with a wide range of effects.},
  archive      = {J_NCA},
  author       = {Naik, Nenavath Srinivas and Chaubey, Harshit Kumar},
  doi          = {10.1007/s00521-024-10231-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18961-18977},
  shortjournal = {Neural Comput. Appl.},
  title        = {Weed detection and classification in sesame crops using region-based convolution neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SkinNet-14: A deep learning framework for accurate skin
cancer classification using low-resolution dermoscopy images with
optimized training time. <em>NCA</em>, <em>36</em>(30), 18935–18959. (<a
href="https://doi.org/10.1007/s00521-024-10225-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing incidence of skin cancer necessitates advancements in early detection methods, where deep learning can be beneficial. This study introduces SkinNet-14, a novel deep learning model designed to classify skin cancer types using low-resolution dermoscopy images. Unlike existing models that require high-resolution images and extensive training times, SkinNet-14 leverages a modified compact convolutional transformer (CCT) architecture to effectively process 32 × 32 pixel images, significantly reducing the computational load and training duration. The framework employs several image preprocessing and augmentation strategies to enhance input image quality and balance the dataset to address class imbalances in medical datasets. The model was tested on three distinct datasets—HAM10000, ISIC and PAD—demonstrating high performance with accuracies of 97.85%, 96.00% and 98.14%, respectively, while significantly reducing the training time to 2–8 s per epoch. Compared to traditional transfer learning models, SkinNet-14 not only improves accuracy but also ensures stability even with smaller training sets. This research addresses a critical gap in automated skin cancer detection, specifically in contexts with limited resources, and highlights the capabilities of transformer-based models that are efficient in medical image analysis.},
  archive      = {J_NCA},
  author       = {Al Mahmud, Abdullah and Azam, Sami and Khan, Inam Ullah and Montaha, Sidratul and Karim, Asif and Haque, Aminul and Zahid Hasan, Md. and Brady, Mark and Biswas, Ritu and Jonkman, Mirjam},
  doi          = {10.1007/s00521-024-10225-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18935-18959},
  shortjournal = {Neural Comput. Appl.},
  title        = {SkinNet-14: A deep learning framework for accurate skin cancer classification using low-resolution dermoscopy images with optimized training time},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KDTL: Knowledge-distilled transfer learning framework for
diagnosing mental disorders using EEG spectrograms. <em>NCA</em>,
<em>36</em>(30), 18919–18934. (<a
href="https://doi.org/10.1007/s00521-024-10207-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a well-known modality in neuroscience and is widely used in identifying and classifying neurological disorders. This paper investigates how EEG data can be used along with knowledge distillation-based deep learning models to detect mental disorders like epilepsy and sleep disorders. The EEG signals are converted into time–frequency plots using short-time Fourier transforms. Further, we propose a novel methodology for using knowledge distillation-based transfer learning (KDTL). Knowledge distillation is becoming quite prevalent in the machine learning field and is associated with various applications in our work; we propose its use in the detection of mental disorders from EEG spectrograms. We convert the EEGs using short-term Fourier transform to obtain time–frequency representation and apply teacher-student by first training a large teacher model and use knowledge distillation to train a student model. In our experiments, we found that ConvNext teacher and MobileNet student combination obtained better results. Our proposed KDTL approach is tested on two datasets with multiple cases, namely the Bonn and ISRUC datasets and obtain 98% and 95% accuracies, respectively. Further experimental results show that the overall KDTL methodology can obtain high classification accuracy across both datasets in binary and multiclass classifications and proves to be better than multiple prior works. Further, our KDTL approach provides a way to train lightweight models which have a smaller number of trainable parameters and thereby constitute lower training time overall. Our proposed KDTL-based approach obtained accurate results in diagnosing mental disorders from EEG spectrograms. Compared to other related methods, KDTL outperformed across tasks with obtained good results in both binary and multiclass classifications.},
  archive      = {J_NCA},
  author       = {Singh, Shreyash and Jadli, Harshit and Padma Priya, R. and Surya Prasath, V. B.},
  doi          = {10.1007/s00521-024-10207-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18919-18934},
  shortjournal = {Neural Comput. Appl.},
  title        = {KDTL: Knowledge-distilled transfer learning framework for diagnosing mental disorders using EEG spectrograms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy efficient and low-latency spiking neural networks on
embedded microcontrollers through spiking activity tuning. <em>NCA</em>,
<em>36</em>(30), 18897–18917. (<a
href="https://doi.org/10.1007/s00521-024-10191-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we target the efficient implementation of spiking neural networks (SNNs) for low-power and low-latency applications. In particular, we propose a methodology for tuning SNN spiking activity with the objective of reducing computation cycles and energy consumption. We performed an analysis to devise key hyper-parameters, and then we show the results of tuning such parameters to obtain a low-latency and low-energy embedded LSNN (eLSNN) implementation. We demonstrate that it is possible to adapt the firing rate so that the samples belonging to the most frequent class are processed with less spikes. We implemented the eLSNN on a microcontroller-based sensor node and we evaluated its performance and energy consumption using a structural health monitoring application processing a stream of vibrations for damage detection (i.e. binary classification). We obtained a cycle count reduction of 25% and an energy reduction of 22% with respect to a baseline implementation. We also demonstrate that our methodology is applicable to a multi-class scenario, showing that we can reduce spiking activity between 68 and 85% at iso-accuracy.},
  archive      = {J_NCA},
  author       = {Barchi, Francesco and Parisi, Emanuele and Zanatta, Luca and Bartolini, Andrea and Acquaviva, Andrea},
  doi          = {10.1007/s00521-024-10191-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18897-18917},
  shortjournal = {Neural Comput. Appl.},
  title        = {Energy efficient and low-latency spiking neural networks on embedded microcontrollers through spiking activity tuning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ground-truth generation through crowdsourcing with
probabilistic indexes. <em>NCA</em>, <em>36</em>(30), 18879–18895. (<a
href="https://doi.org/10.1007/s00521-024-10188-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic transcription of large series of historical handwritten documents generally aims at allowing to search for textual information in these documents. However, automatic transcripts often lack the level of accuracy needed for reliable text indexing and search purposes. Probabilistic Indexing (PrIx) offers a unique alternative to raw transcripts. Since it needs training data to achieve good search performance, PrIx-based crowdsourcing techniques are introduced in this paper to gather the required data. In the proposed approach, PrIx confidence measures are used to drive a correction process in which users can amend errors and possibly add missing text. In a further step, corrected data are used to retrain the PrIx models. Results on five large series are reported which show consistent improvements after retraining. However, it can be argued whether the overall costs of the crowdsourcing operation pay off for the improvements, or perhaps it would have been more cost-effective to just start with a larger and cleaner amount of professionally produced training transcripts.},
  archive      = {J_NCA},
  author       = {Sánchez, Joan Andreu and Vidal, Enrique and Bosch, Vicente and Quirós, Lorenzo},
  doi          = {10.1007/s00521-024-10188-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18879-18895},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ground-truth generation through crowdsourcing with probabilistic indexes},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From data to clean water: XGBoost and bayesian optimization
for advanced wastewater treatment with ultrafiltration. <em>NCA</em>,
<em>36</em>(30), 18863–18877. (<a
href="https://doi.org/10.1007/s00521-024-10187-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water pollution remains a pressing global challenge, threatening human health and ecosystem stability. Ultrafiltration emerges as a vital technology in this contest, offering a powerful tool for contaminant removal and safeguarding clean water resources. Thus, the optimization of ultrafiltration processes holds paramount significance for efficient contaminant removal. This study revolutionizes wastewater treatment by introducing a hybrid machine learning approach that optimizes ultrafiltration processes for superior contaminant removal. Utilizing the powerful synergy between eXtreme Gradient Boosting (XGBoost) and Bayesian optimization, we developed predictive models with remarkable accuracy (R2 values exceeding 99%) for post-treatment concentrations of metal ions, organic pollutants, and salts. This translates to precise control over the ultrafiltration process, driven by 4 key input variables: metal ion concentration, organic pollutants, salts, and applied pressure. The findings not only demonstrate the effectiveness of this hybrid approach but also pave the way for significant advancements in wastewater treatment strategies, ultimately contributing to cleaner water. This research marks a significant leap in machine learning applications for environmental challenges, paving the way for further advancements in wastewater treatment technology.},
  archive      = {J_NCA},
  author       = {Al-Jamimi, Hamdi A. and BinMakhashen, Galal M. and Saleh, Tawfik A.},
  doi          = {10.1007/s00521-024-10187-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18863-18877},
  shortjournal = {Neural Comput. Appl.},
  title        = {From data to clean water: XGBoost and bayesian optimization for advanced wastewater treatment with ultrafiltration},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep multi-metric training: The need of multi-metric curve
evaluation to avoid weak learning. <em>NCA</em>, <em>36</em>(30),
18841–18862. (<a
href="https://doi.org/10.1007/s00521-024-10182-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development and application of artificial intelligence-based computer vision systems in medicine, environment, and industry are playing an increasingly prominent role. Hence, the need for optimal and efficient hyperparameter tuning strategies is more than crucial to deliver the highest performance of the deep learning networks in large and demanding datasets. In our study, we have developed and evaluated a new training methodology named deep multi-metric training (DMMT) for enhanced training performance. The DMMT delivers a state of robust learning for deep networks using a new important criterion of multi-metric performance evaluation. We have tested the DMMT methodology in multi-class (three, four, and ten), multi-vendors (different X-ray imaging devices), and multi-size (large, medium, and small) datasets. The validity of the DMMT methodology has been tested in three different classification problems: (i) medical disease classification, (ii) environmental classification, and (iii) ecological classification. For disease classification, we have used two large COVID-19 chest X-rays datasets, namely the BIMCV COVID-19+ and Sheffield hospital datasets. The environmental application is related to the classification of weather images in cloudy, rainy, shine or sunrise conditions. The ecological classification task involves a classification of three animal species (cat, dog, wild) and a classification of ten animals and transportation vehicles categories (CIFAR-10). We have used state-of-the-art networks of DenseNet-121, ResNet-50, VGG-16, VGG-19, and DenResCov-19 (DenRes-131) to verify that our novel methodology is applicable in a variety of different deep learning networks. To the best of our knowledge, this is the first work that proposes a training methodology to deliver robust learning, over a variety of deep learning networks and multi-field classification problems.},
  archive      = {J_NCA},
  author       = {Mamalakis, Michail and Banerjee, Abhirup and Ray, Surajit and Wilkie, Craig and Clayton, Richard H. and Swift, Andrew J. and Panoutsos, George and Vorselaars, Bart},
  doi          = {10.1007/s00521-024-10182-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18841-18862},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep multi-metric training: The need of multi-metric curve evaluation to avoid weak learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Suspicious transaction alert and blocking system for
cryptocurrency exchanges in metaverse’s social media universes:
RG-guard. <em>NCA</em>, <em>36</em>(30), 18825–18840. (<a
href="https://doi.org/10.1007/s00521-024-10122-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose an effective system called RG-Guard that detects potential risks and threats in the use of cryptocurrencies in the metaverse ecosystem. In order for the RG-Guard engine to detect suspicious transactions, Ethereum network transaction information and phishing wallet addresses were collected, and a unique dataset was created after the data preprocessing process. During the data preprocessing process, we manually distinguished the features within the original dataset that contained potential risk indicators. The learning process of the RG-Guard engine in risk classification was achieved by developing a deep learning model based on LSTM + Softmax. In the training process of the model, RG-Guard was optimised for maximum accuracy, and optimum hyperparameters were obtained. The reliability and dataset performance of the preferred LSTM + Softmax model were verified by comparing it with algorithms used in risk classification and detection applications in the literature (Decision tree, XG boost, Random forest and light gradient boosting machine). Accordingly, among the trained models, LSTM + Softmax has the highest accuracy with an F1-score of 0.9950. When a cryptocurrency transaction occurs, RG-Guard extracts the feature vectors of the transaction and assigns a risk level between 1 and 5 to the parameter named βrisk. Since transactions with βrisk &gt;  = 3 are labelled as suspicious transactions, RG-Guard blocks this transaction. Thus, thanks to the use of the RG-Guard engine in metaverse applications, it is aimed to easily distinguish potential suspicious transactions from instant transactions. As a result, it is aimed to detect and prevent instant potential suspicious transactions with the RG-Guard engine in money transfers, which have the greatest risk in cryptocurrency transactions and are the target of fraud. The original dataset prepared in the proposed study and the hybrid LSTM + Softmax model developed specifically for the model are expected to contribute to the development of such studies.},
  archive      = {J_NCA},
  author       = {Gürfidan, Remzi},
  doi          = {10.1007/s00521-024-10122-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18825-18840},
  shortjournal = {Neural Comput. Appl.},
  title        = {Suspicious transaction alert and blocking system for cryptocurrency exchanges in metaverse’s social media universes: RG-guard},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrasting bean analysis system based on YOLOv5 and a
neural network model using the interval type-2 fuzzy set approach.
<em>NCA</em>, <em>36</em>(30), 18807–18824. (<a
href="https://doi.org/10.1007/s00521-024-10217-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beans are a legume that has historically been a cheap source of protein, in the daily human diet. Therefore, it is challenging that the quality of this legume be guaranteed. In this work, we propose a novelty system for evaluating the contrasting bean quality, combining an algorithm for detecting black variety bean kernels and a neural network model based on an interval type-2 fuzzy set approach for weight estimation. To perform the detection task, YOLOv5 was used, which achieved favorable results, with an accuracy of 0.998, recall of 0.997, mAP_0.5 of 0.995 and mAP_0.5:0.95 of 0.733. Meanwhile, a model based on artificial neural networks was developed to estimate the weight. However, since the current quality assessment system includes vagueness and uncertainty, to deal with this problem, the interval type-2 fuzzy set approach was used by converting the collected data to fuzzy numbers with trapezoidal membership to use them in the training and validation process. The model for weight estimation showed favorable results, with a variance explained by the model (R2) of 0.99, a mean squared error (MSE) of 0.02, mean absolute percentage error of 0.05, and a mean absolute error (MAE) of 0.12 g. Meanwhile, an MSE of 0.02 and MAE of 0.11 g were the results for data not included in the training and validation process. Finally, both models were incorporated into a graphical user interface to facilitate their use in a real quality assessment process. The experiments with the proposed system demonstrated its effectiveness in detecting and estimating weight dynamically and with acceptable accuracy.},
  archive      = {J_NCA},
  author       = {Rodríguez-Álvarez, José L. and García-Alcaraz, Jorge L. and Puig i Vidal, Rita and Soto-Cabral, Alondra},
  doi          = {10.1007/s00521-024-10217-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18807-18824},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contrasting bean analysis system based on YOLOv5 and a neural network model using the interval type-2 fuzzy set approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Early-stage stroke prediction based on parkinson and
wrinkles using deep learning. <em>NCA</em>, <em>36</em>(30),
18781–18805. (<a
href="https://doi.org/10.1007/s00521-024-10189-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of noninvasive methods to enhance healthcare systems has been facilitated by the development of new technology. Among the four major cardiovascular diseases, stroke is one of the deadliest and potentially fatal, but, if detected early enough, a patient&#39;s life may be spared. Most stroke research has centered on MRI and CT scans for uncomplicated categorization. This medical approach (imaging) is costly, time-consuming and needs the utilization of complex technology. To make up for these shortcomings, however, there has been a lot of interest in adopting noninvasive, measurable EEGs. Nevertheless, the raw data should be classified before the proper characteristics can be formed, both the forecasting algorithms and the analytical techniques demand time. As a result, this work proposes a deep learning-based model that aims to predict the chance of stroke at an early stage utilizing Parkinson&#39;s disease and wrinkles as markers. A patient may have a stroke disease if they are diagnosed with both Parkinson&#39;s disease and wrinkles. To the best of our knowledge, this research is the first to use these biomarkers to predict the risk of having a stroke. The proposed model achieves a higher accuracy of 94.7% on the considered dataset. Additionally, the recommended model was evaluated and tested in terms of loss, training time, accuracy, recall, and F1-score versus the other existing models. With less price and pain than present testing approaches, these discoveries are predicted to result in major enhancements in the early detection of strokes.},
  archive      = {J_NCA},
  author       = {Haritha, T. and Babu, A. V. Santhosh},
  doi          = {10.1007/s00521-024-10189-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18781-18805},
  shortjournal = {Neural Comput. Appl.},
  title        = {Early-stage stroke prediction based on parkinson and wrinkles using deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In-depth analysis of automated baggage inspection using
simulated x-ray images of 3D models. <em>NCA</em>, <em>36</em>(30),
18761–18780. (<a
href="https://doi.org/10.1007/s00521-024-10159-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray baggage inspection ensures transport and border security, as it prevents hazardous objects from entering secure areas. Currently, deep learning is the state-of-the-art approach for automated threat object detection and classification. These networks require extensive training data; however, the number of publicly available datasets of X-ray images is limited. To overcome this, we propose an image generation pipeline that generates new data by superimposing simulated X-ray images of 3D models onto real baggage X-rays. This approach allows researchers to train deep neural networks without requiring additional imaging or manual labeling. The effectiveness and reliability of our image simulation pipeline are demonstrated, integrating advanced techniques such as distortion with diffusion models. We conducted hundreds of YOLOv5 trainings with a combination of real images from the SIXray dataset and simulated X-rays containing wrenches and handguns. Testing was performed exclusively on unaltered real images. Training exclusively with 16,000 simulated images of grayscale wrenches resulted in an $$AP_{0.5}$$ of 72.7%. For the handguns, using only 50 real images yielded an $$AP_{0.5}$$ of 78.8%; however, by adding 16,000 simulated X-rays to these real images, the $$AP_{0.5}$$ increased to 91.6%. Our results prove that using simulated images of threat objects can improve the performance of object detection models. As modern object detectors process images in real-time, they establish themselves as a feasible approach for aiding inspectors and even fully automating baggage inspection. Our novel superimposition and colorization techniques are not only relevant to security but can also be employed in other areas of X-ray imaging.},
  archive      = {J_NCA},
  author       = {Kaminetzky, Alejandro and Mery, Domingo},
  doi          = {10.1007/s00521-024-10159-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18761-18780},
  shortjournal = {Neural Comput. Appl.},
  title        = {In-depth analysis of automated baggage inspection using simulated X-ray images of 3D models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing beyond boundaries: Empowering the salp swarm
algorithm for global optimization and defective software module
classification. <em>NCA</em>, <em>36</em>(30), 18727–18759. (<a
href="https://doi.org/10.1007/s00521-024-10131-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a new version of the salp swarm optimizer (SSA), called ”mSSA,” that uses complex mathematical expressions to dynamically manipulate the crucial control parameter ( $$c_1$$ ) during optimization. These expressions are carefully designed to modulate the shift in search strategy from exploratory to exploitative, improving the flexibility and speed of convergence of the algorithm. To evaluate the performance of the developed mSSA variants, a thorough examination is carried out on twenty-three benchmark test functions alongside their application to the complex task of software module classification. The process of classifying defective software modules involves developing a multilayer perceptron (MLP) classifier that is suited to the particular complexity and heterogeneity of the task. Selecting the best optimizer is made easier by systematically evaluating the different mSSA versions as MLP classifier trainers. Based on metrics like classification accuracy, convergence speed, and avoidance of local minima, a comparative analysis in opposition to six previously published metaheuristic optimizers shows that mSSA3, when combined with the developed MLP classifier, outperforms both other mSSA variations and state-of-the-art metaheuristic optimizers in terms of overall performance. The excellent classification accuracy, swift convergence, and ability to avoid local minima of mSSA3 highlight its superiority and establish it as a cutting-edge method in the application of metaheuristic algorithms.},
  archive      = {J_NCA},
  author       = {Kassaymeh, Sofian and Al-Betar, Mohammed Azmi and Rjoubd, Gaith and Fraihat, Salam and Abdullah, Salwani and Almasri, Ammar},
  doi          = {10.1007/s00521-024-10131-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18727-18759},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing beyond boundaries: Empowering the salp swarm algorithm for global optimization and defective software module classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stacked ensemble learning based on deep transfer learning
models for food ingredient classification and food quality
determination. <em>NCA</em>, <em>36</em>(30), 18705–18725. (<a
href="https://doi.org/10.1007/s00521-024-10233-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food safety is critical in protecting consumers from foodborne diseases. The public currently classifies and determines food ingredients and their quality based on appearance, aroma, and other characteristics. Existing food inspection machines often focus on single characteristics, resulting in incomplete and inaccurate information. Hence, developing methods that analyse multiple characteristics is necessary for high-accuracy classification. This research proposed an effective stacked ensemble deep transfer learning algorithm using eight popular transfer learning algorithms as a base classifier and combining them with the Adaptive Neuro-Fuzzy Inference System as a meta-classifier to analyse imaging, odour, and capacitive sensing approaches. Twenty-four food samples classified according to freshness, maturity, ripeness, and disease levels were analysed using the proposed stacked ensemble EfficientNet algorithm, achieving the highest accuracy rate of 0.916 and 0.933 in food ingredient classification and quality determination, respectively. This research demonstrated the system’s reliability for deployment in classifying food ingredients in dishes.},
  archive      = {J_NCA},
  author       = {Keong, T. W. and Husin, Z. and Ismail, M. A. H. and Yasruddin, M. L.},
  doi          = {10.1007/s00521-024-10233-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18705-18725},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stacked ensemble learning based on deep transfer learning models for food ingredient classification and food quality determination},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mango varietal discrimination using hyperspectral imaging
and machine learning. <em>NCA</em>, <em>36</em>(30), 18693–18703. (<a
href="https://doi.org/10.1007/s00521-024-10218-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mango is a highly diverse tropical fruit with numerous varieties that differ in flavor, texture, and chemical composition. Consequently, identifying fraudulent substitutions of mango varieties poses a significant challenge using traditional techniques. Therefore, there is an increasing need for new methods to discriminate between mango varieties. Hyperspectral imaging coupled with machine learning techniques presents a promising approach for varietal discrimination. In this study, mango samples of eleven varieties were collected from a germplasm bank, with four slices obtained from each sample. Hyperspectral images were acquired in the Vis–NIR and NIR ranges for each slice, and spectral profiles were extracted and pretreated. Three discrimination models, linear discriminant analysis, K-nearest neighbor, and artificial neural networks, were implemented and validated using relevant wavelengths selected through a covering array feature selection algorithm. The performance of these models was evaluated using precision, accuracy, and F-score metrics. The average spectral profiles of the studied varieties exhibited a similar behavior with slight differences, which could be used for classification within the evaluated ranges. The optimal number of variables selected to refine the models was 17 for the UV–Vis–NIR range and 21 for the NIR range, with an accuracy ranging between 0.752 and 0.972. This study concludes that hyperspectral imaging combined with machine learning techniques can effectively discriminate between different varieties of mango.},
  archive      = {J_NCA},
  author       = {Castro, Wilson and Tene, Baldemar and Castro, Jorge and Guivin, Alex and Ruesta, Nelson and Avila-George, Himer},
  doi          = {10.1007/s00521-024-10218-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18693-18703},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mango varietal discrimination using hyperspectral imaging and machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised few-shot medical image segmentation with
spatial transformations. <em>NCA</em>, <em>36</em>(30), 18675–18691. (<a
href="https://doi.org/10.1007/s00521-024-10184-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based segmentation models often struggle to achieve optimal performance when encountering new, unseen semantic classes. Their effectiveness hinges on vast amounts of annotated data and high computational resources for training. However, a promising solution to mitigate these challenges is the adoption of few-shot segmentation (FSS) networks, which can train models with reduced annotated data. The inherent complexity of medical images limits the applicability of FSS in medical imaging, despite its potential. Recent advancements in self-supervised label-efficient FSS models have demonstrated remarkable efficacy in medical image segmentation tasks. This paper presents a novel FSS architecture that enhances segmentation accuracy by utilising fewer features than existing methodologies. Additionally, this paper proposes a novel self-supervised learning approach that utilises supervoxel and augmented superpixel images to further enhance segmentation accuracy. This paper assesses the efficacy of the proposed model on two different datasets: abdominal magnetic resonance imaging (MRI) and cardiac MRI. The proposed model achieves a mean dice score and mean intersection over union of 81.62% and 70.38% for abdominal images, and 79.38% and 65.23% for cardiac images.},
  archive      = {J_NCA},
  author       = {Titoriya, Ankit Kumar and Singh, Maheshwari Prasad and Singh, Amit Kumar},
  doi          = {10.1007/s00521-024-10184-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18675-18691},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-supervised few-shot medical image segmentation with spatial transformations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A rotation-invariant horizontal vertical pooled module for
remote sensing image representation. <em>NCA</em>, <em>36</em>(30),
18661–18673. (<a
href="https://doi.org/10.1007/s00521-024-10180-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate information retrieval from multi-source and multi-resolution image data constitutes a foundation for knowledge discovery. Scene image classification in the remote sensing (RS) community using aerial very high resolution (VHR) images is one of the well-researched areas, which mostly utilise deep learning (DL)—based methods thanks to their remarkable classification performance. Nevertheless, existing DL-based methods still have a limited ability to capture precise spatial semantic information scattered toward the horizontal and vertical directions across such images at multiple scales and rotations. As such, we herein propose a novel approach, employing an innovative rotation invariant horizontal vertical pooled module (RIHVPM), to well-represent aerial VHR RS images for stable and improved classification performance. Notably, the proposed RIHVPM benefits from the multiple tensor rotations coupled with attention-enabled multiscale horizontal and vertical pooling operations for image representation. An experimental study on three benchmark datasets demonstrates competent and/or higher classification performance (AID: 96.44%, NWPU: 94.32% and UCM: 99.04%) and robustness/stability (minimum standard deviation of 0.001) of the proposed approach.},
  archive      = {J_NCA},
  author       = {Sitaula, Chiranjibi and Aryal, Jagannath},
  doi          = {10.1007/s00521-024-10180-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18661-18673},
  shortjournal = {Neural Comput. Appl.},
  title        = {A rotation-invariant horizontal vertical pooled module for remote sensing image representation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video anomaly detection using diverse motion-conditioned
adversarial predictive network. <em>NCA</em>, <em>36</em>(30),
18645–18659. (<a
href="https://doi.org/10.1007/s00521-024-10173-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is always formulated as frame prediction task which only learned on normal data and detects deviations as anomalies. However, previous methods lack sufficient spatiotemporal constraints on moving objects, making it difficult to learn compact normal distributions and anomalies near the boundary will be misclassified as normal. Besides, the inadequate exploration of diverse normal patterns results in mode missing and unlearned normal patterns will be misclassified as anomalies. To address these problems, we propose an object-level Diverse Motion-conditioned Adversarial Predictive Network for video anomaly detection which combines conditional variational generation with adversarial learning to mitigate false detection. We design a motion-guided generator that controls the generation process conditioned on optical flows to accurately memorize spatiotemporal correlations of normal data. We employ the diversity regularization strategy which explicitly preserves the recurrent structure of normal data in continuous latent space to ensure full utilization of diverse patterns. Additionally, we combine an input clip with the object it generates to synthesize an anomaly near the boundary, then employ a video discriminator to perceive subtle differences between normal and abnormal data, making them more distinguishable. Extensive experiments conducted on public datasets illustrate the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Wang, Jiaqi and Ji, Genlin and Zhao, Bin},
  doi          = {10.1007/s00521-024-10173-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18645-18659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Video anomaly detection using diverse motion-conditioned adversarial predictive network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PODBoost: An explainable AI model for polycystic ovarian
syndrome detection using grey wolf-based feature selection approach.
<em>NCA</em>, <em>36</em>(30), 18627–18644. (<a
href="https://doi.org/10.1007/s00521-024-10171-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polycystic Ovary Syndrome (PCOS) is a recurring endocrine disorder that primarily affects women of reproductive age. It is difficult to diagnose due to its heterogeneous characteristics and overlapping symptoms with other illnesses. As a result, accurate and trustworthy prediction models are required to detect PCOS early. This research work aims to develop ML methods that predict the risk of PCOS among women based on demographic and clinical features. The entire framework is divided into four phases: in Phase I of the study, the SMOTE-Tomek Links (SMTL) technique balances the data set by combining oversampling and undersampling approaches. A novel meta-heuristic-based feature selection approach, the Grey Wolf Optimization (GWO) method, has been employed to select the most crucial features from the dataset, explained in Phase II. Subsequently, in Phase III, a hybridized classifier PODBoost algorithm (Polycystic Ovarian Disorder Boosting algorithm) is devised for faithful early prediction of PCOS using the concepts of different classical supervised learning algorithms. Finally, Explainable AI (XAI) such as the Local Interpretable Model-Agnostic Explanations (LIME) tool has been implemented to interpret relevant predictions made by the proposed classifier. The proposed algorithm is examined utilizing numerous metrics such as Accuracy, Error-Rate, ROC-AUC Score, Recall, Precision, and F1-Score. Among all the evaluated models, the proposed hybridized model has shown an impressive performance with an exceptional accuracy of $${97.42\%}$$ , indicating its superiority by delivering outstanding results. Based on the findings, the novel meta-heuristic-based feature selection method significantly impacts the outcomes of the proposed hybridized PODBoost algorithm. This algorithm may be recommended to predict PCOS or other relevant diseases having datasets which are multimodal in nature.},
  archive      = {J_NCA},
  author       = {Moral, Poonam and Mustafi, Debjani and Sahana, Sudip Kumar},
  doi          = {10.1007/s00521-024-10171-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18627-18644},
  shortjournal = {Neural Comput. Appl.},
  title        = {PODBoost: An explainable AI model for polycystic ovarian syndrome detection using grey wolf-based feature selection approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ensemble framework for risk prediction of left atrial
thrombus based on undersampling with replacement. <em>NCA</em>,
<em>36</em>(30), 18613–18625. (<a
href="https://doi.org/10.1007/s00521-024-10166-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Left atrial thrombus (LAT) impacts humans greatly and can result in ischemia and necrosis in severe cases. Therefore, health workers appeal to the social community to emphasize the importance of preventive treatment for LAT. This paper proposes an ensemble framework for risk prediction of LAT based on undersampling with replacement (EFRP-UR), addressing the problem of data imbalance. Firstly, in the feature selection process, we adopt the method of separately counting the essential features of data subsets. In view of the characteristics of class imbalance in medical data, we apply our improved undersamling method, “undersampling with replacement&quot;, to obtain a number of training subsets, train multiple base-classifiers, and use an iterative method to select the classifiers with better performance for subsequent integration, improving the prediction accuracy of the proposed EFRP-UR. To aim for disease risk prediction, we synthesize the results of different ensemble algorithms in the end to increase the recall rate. Applied to the LAT dataset obtained from the Regional Medical Center, our experimental results prove that the proposed EFRP-UR has improved in accuracy, recall rate and F1 value, compared with any single base-classifier. In addition, if comprehensive data on other diseases exist, EFRP-UR can also be transferred to predict other diseases.},
  archive      = {J_NCA},
  author       = {Li, Li and Fang, Dongshen and Ye, Qiyao and Hu, Tan and Shi, Shaobo},
  doi          = {10.1007/s00521-024-10166-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18613-18625},
  shortjournal = {Neural Comput. Appl.},
  title        = {An ensemble framework for risk prediction of left atrial thrombus based on undersampling with replacement},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring accuracy and interpretability trade-off in tabular
learning with novel attention-based models. <em>NCA</em>,
<em>36</em>(30), 18583–18611. (<a
href="https://doi.org/10.1007/s00521-024-10163-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Apart from high accuracy, what interests many researchers and practitioners in real-life tabular learning problems (e.g., fraud detection and credit scoring) is uncovering hidden patterns in the data and/or providing meaningful justification of decisions made by machine learning models. In this concern, an important question arises: should one use inherently interpretable models or explain full-complexity models such as XGBoost, Random Forest with post hoc tools? Opting for the second choice is typically supported by the accuracy metric, but it is not always evident that the performance gap is sufficiently significant, especially considering the current trend of accurate and inherently interpretable models, as well as accounting for other real-life evaluation metrics such as faithfulness, stability, and computational cost of explanations. In this work, we show through benchmarking on 45 datasets that the relative accuracy loss is less than 4% in average when using intelligible models such as explainable boosting machine. Furthermore, we propose a simple use of model ensembling to improve the expressiveness of TabSRALinear, a novel attention-based inherently interpretable solution, and demonstrate both theoretically and empirically that it is a viable option for (1) generating stable or robust explanations and (2) incorporating human knowledge during the training phase. Source code is available at https://github.com/anselmeamekoe/TabSRA .},
  archive      = {J_NCA},
  author       = {Amekoe, Kodjo Mawuena and Azzag, Hanane and Dagdia, Zaineb Chelly and Lebbah, Mustapha and Jaffre, Gregoire},
  doi          = {10.1007/s00521-024-10163-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18583-18611},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring accuracy and interpretability trade-off in tabular learning with novel attention-based models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emotional speaker identification using PCAFCM-deepforest
with fuzzy logic. <em>NCA</em>, <em>36</em>(30), 18567–18581. (<a
href="https://doi.org/10.1007/s00521-024-10154-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voice is perceived as a form of biometrics which communicates valuable and rich information pertinent to an individual, such as his or her identity, gender, accent, age and emotion. Speaker identification denotes the task of identifying speakers based on their intrinsic voice characteristics. This study proposes a text-independent speaker identification system based on principal component analysis (PCA), fuzzy C-means (FCM) along with deepForest called PCAFCM-deepForest. The proposed approach is evaluated under neutral and adverse talking environments. Given this approach, we assessed our proposed model architecture on five benchmark corpora, namely private Arabic Emirati-accented speech dataset, public English dataset; Crowd-sourced emotional multimodal actors dataset (CREMA), public German database; Berlin database of emotional speech (EmoDB), public Chinese and English; emotional speech database (ESD), and public French dataset; public Canadian French emotional (CaFE) speech dataset. Our analysis shows that the performance of speaker identification has been immensely increased (greatly improved) when fuzzy logic and PCA are both applied to the extracted mel-frequency cepstral coefficients (MFCC). Speaker identification performance achieved by the proposed PCAFCM-deepForest is superior to that obtained by deepForest alone, FCM-deepForest as well as convolutional neural network (CNN). Besides, it surpasses the following conventional models: Random forest and support vector machine (SVM). Our findings demonstrate that the attained average speaker identification accuracy is equivalent to 98.20% using the Emirati database; an average performance which outperforms the existing frameworks. Moreover, PCAFCM-deepForest is fine-tuned using the grid search algorithm, and the achieved complexity is much less than that of CNN.},
  archive      = {J_NCA},
  author       = {Nassif, Ali Bou and Shahin, Ismail and Nemmour, Nawel},
  doi          = {10.1007/s00521-024-10154-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18567-18581},
  shortjournal = {Neural Comput. Appl.},
  title        = {Emotional speaker identification using PCAFCM-deepforest with fuzzy logic},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STCPU-net: Advanced u-shaped deep learning architecture
based on swin transformers and capsule neural network for brain tumor
segmentation. <em>NCA</em>, <em>36</em>(30), 18549–18565. (<a
href="https://doi.org/10.1007/s00521-024-10144-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning has known a remarkable mutation in computer vision, which has been optimally exploited to solve various complex tasks and improve their results in the medical image analysis field, especially medical image segmentation (MIS). In this regard, convolution neural networks, particularly U-Net-based architectures, have been widely proposed to create several automatic systems for MIS. However, they are still constrained by certain limitations in terms of long-range context information because of the limited kernel size of the convolution layer, sensitivity to rotation and affine transformation, and the discard of the positional information due to the pooling operation. To address these limitations, transformers and capsule neural network have been utilized to model long-range contextual information based on the self-attention mechanism on the one hand and better representation learning based on dynamic routing algorithm on the other hand. To this end, we proposed a deep learning architecture for brain tumor segmentation called Swin transformer capsule pyramid U-Net. Indeed, the encoder consists of four hierarchical features extracted based on shifted window multi-head self-attention used in Swin transformers (ST) blocks. Next, the features are introduced to the proposed residual inception capsule pyramid network (RICapsPN) to encode each spatial relation of features in each encoder depth. Depending on the top-down connection between layers, this network builds a high-level semantic feature at all scales. Furthermore, RICapsPN used inception capsule blocks to test several capsule kernels and optimize the number of parameters. Additionally, the residual connection employed aims to consider the features extracted at each ST depth to enhance feature representation from the encoder part. Finally, the output of RICapsPN has been introduced to the ST decoder to get the final segmentation of different sub-regions of the brain tumor. The experiment results of our method showed a compelling performance on the BraTS 2020 dataset compared with the state-of-the-art methods by achieving 92.80 $$\%$$ , 85.63 $$\%$$ , and 80.14 $$\%$$ of dice similarity coefficient for the whole tumor, core tumor, and enhancing tumor sub-regions, respectively. Ablation experiments also indicate the effectiveness of the designed modules.},
  archive      = {J_NCA},
  author       = {Aboussaleh, Ilyasse and Riffi, Jamal and Fazazy, Khalid El and Mahraz, Adnane Mohamed and Tairi, Hamid},
  doi          = {10.1007/s00521-024-10144-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {30},
  pages        = {18549-18565},
  shortjournal = {Neural Comput. Appl.},
  title        = {STCPU-net: Advanced U-shaped deep learning architecture based on swin transformers and capsule neural network for brain tumor segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Photovoltaic system fault detection
techniques: A review. <em>NCA</em>, <em>36</em>(29), 18547–18548. (<a
href="https://doi.org/10.1007/s00521-024-10056-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {El-Banby, Ghada M. and Moawad, Nada M. and Abouzalm, Belal A. and Abouzaid, Wessam F. and Ramadan, E. A.},
  doi          = {10.1007/s00521-024-10056-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18547-18548},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: photovoltaic system fault detection techniques: a review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TypeFormer: Transformers for mobile keystroke biometrics.
<em>NCA</em>, <em>36</em>(29), 18531–18545. (<a
href="https://doi.org/10.1007/s00521-024-10140-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The broad usage of mobile devices nowadays, the sensitiveness of the information contained in them, and the shortcomings of current mobile user authentication methods are calling for novel, secure, and unobtrusive solutions to verify the users’ identity. In this article, we propose TypeFormer, a novel transformer architecture to model free-text keystroke dynamics performed on mobile devices for the purpose of user authentication. The proposed model consists in temporal and channel modules enclosing two long short-term memory recurrent layers, Gaussian range encoding, a multi-head self-attention mechanism, and a block-recurrent transformer layer. Experimenting on one of the largest public databases to date, the Aalto mobile keystroke database, TypeFormer outperforms current state-of-the-art systems achieving equal error rate values of 3.25% using only five enrolment sessions of 50 keystrokes each. In such way, we contribute to reducing the traditional performance gap of the challenging mobile free-text scenario with respect to its desktop and fixed-text counterparts. To highlight the design rationale, an analysis of the experimental results of the different modules implemented in the development of TypeFormer is carried out. Additionally, we analyse the behaviour of the model with different experimental configurations such as the length of the keystroke sequences and the amount of enrolment sessions, showing margin for improvement.},
  archive      = {J_NCA},
  author       = {Stragapede, Giuseppe and Delgado-Santos, Paula and Tolosana, Ruben and Vera-Rodriguez, Ruben and Guest, Richard and Morales, Aythami},
  doi          = {10.1007/s00521-024-10140-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18531-18545},
  shortjournal = {Neural Comput. Appl.},
  title        = {TypeFormer: Transformers for mobile keystroke biometrics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing the efficiency of recurrent neural networks to
EMG-based continuous estimation of the elbow angle. <em>NCA</em>,
<em>36</em>(29), 18515–18530. (<a
href="https://doi.org/10.1007/s00521-024-10175-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study comprehensively assesses various recurrent neural networks (RNNs) for decoding the elbow angle from electromyogram (EMG) signals, a crucial aspect in myoelectric interfaces. EMG signals from the shoulder girdle and arm were recorded during goal-directed reaching movements, and linear envelopes were continuously mapped to the elbow angle by three RNN architectures: nonlinear autoregressive exogenous (NARX), Elman, and long-term short memory (LSTM). All three approaches effectively captured the complex dynamics of the multi-input to a single-output regression problem. Regarding within-subject variability, the NARX, Elman, and LSTM demonstrated superior accuracy and robustness compared to dynamic feedforward neural networks like time-delay neural networks. Notably, there was no statistically significant distinction among NARX, Elman, and LSTM estimation performances. Elman and LSTM exhibited an advantage in decoding latent information dependencies through their context layers, leading to improved estimation performance in inter-subject variability analysis, particularly with increased training data volume and variability. Furthermore, the LSTM, with its complex architecture capable of learning long-term temporal dependencies, exhibited the highest performance among the considered RNNs. Consequently, selecting the optimal RNN structure is recommended based on the complexity of the data at hand. The RNN-based decoding model holds potential applications in prosthetics, robotic assistants, and exoskeletons, enabling intention detection and real-time assessment of active rehabilitation progress.},
  archive      = {J_NCA},
  author       = {Davarinia, Fatemeh and Maleki, Ali},
  doi          = {10.1007/s00521-024-10175-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18515-18530},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparing the efficiency of recurrent neural networks to EMG-based continuous estimation of the elbow angle},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised anomaly detection and localization via
bidirectional knowledge distillation. <em>NCA</em>, <em>36</em>(29),
18499–18514. (<a
href="https://doi.org/10.1007/s00521-024-10172-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation has demonstrated significant potential in addressing the challenge of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher–student (T-S) model provides evidence for anomaly detection and localization. However, the teacher model is pretrained for classification, while the anomaly scores in the distillation-based anomaly detection method are indirectly derived from the classification scores. The mismatch between the two tasks can hinder the optimization of the model. To tackle this issue, we propose an innovative bidirectional knowledge distillation model. In this approach, forward knowledge distillation is pivotal in bolstering the model’s capacity for generalization. Simultaneously, backward knowledge distillation promotes diversity in representing anomalies. This reciprocal knowledge exchange effectively wards off potential performance declines due to target inconsistency. Through bidirectional knowledge distillation, we establish a more encompassing and resilient framework for knowledge transfer. Additionally, we introduce a novel data augmentation strategy to simulate anomalies and effectively eliminate unnecessary noise. In experiments on the MVTec AD, the proposed model achieves competitive results compared to state-of-the-art methods, 97.47% on image-level AUC, 98.23% on pixel-level AUC, and 94.77% on instance-level PRO. These results demonstrate the practicality of our approach in anomaly detection and localization.},
  archive      = {J_NCA},
  author       = {Wang, Xiaoming and Wang, Yongxiong and Pan, Zhiqun and Wang, Guangpeng},
  doi          = {10.1007/s00521-024-10172-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18499-18514},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised anomaly detection and localization via bidirectional knowledge distillation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CSMEC-based deep learning model for detection and
classification of brain tumours in MR images. <em>NCA</em>,
<em>36</em>(29), 18479–18498. (<a
href="https://doi.org/10.1007/s00521-024-10168-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumours are anomalous growths or clusters of cells in or encircling the brain. These tumours are perhaps detected and classified using magnetic resonance imaging (MRI), which plays an influential role in the identification of tumours. Brain tumours are suspiciously difficult to classify because of their heterogeneity. The manual detection of tumours is a time-wasting and complex process that can lead to a misdiagnosis. To overcome these drawbacks, the progression of deep learning (DL)-based convolutional neural network models is used to diagnose brain tumours using MRI. This research proposes a compound scaling with maximum entropy classifier-based deep learning model to classify brain tumours as pituitary, meningioma, glioma, and no tumour. To enhance the quality of the images, various pre-processing techniques are used. Data augmentation techniques are used to add up the number of images to enrich the training of our proposed model. With and without augmentation results are compared and showed that the proposed model with augmentation gives excellent results for classification. Experimental results show that the proposed model achieves 99.86% accuracy during training, 99.65% accuracy during validation, and a great classification accuracy of 99.24% during testing. In addition to the F1 score, recall, precision, micro-average, macro-average, and weighted average were used in this study. The existing state-of-the-art DL algorithms such as VGG16, VGG19, ResNet50, InceptionV3, and DenseNet121 are used for comparative analysis.},
  archive      = {J_NCA},
  author       = {Beaulah Princiba, D. and Ezhilarasi, P. and Rajeshkannan, S.},
  doi          = {10.1007/s00521-024-10168-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18479-18498},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSMEC-based deep learning model for detection and classification of brain tumours in MR images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Streamlining plant disease diagnosis with convolutional
neural networks and edge devices. <em>NCA</em>, <em>36</em>(29),
18445–18477. (<a
href="https://doi.org/10.1007/s00521-024-10152-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing labor-intensive process of manual plant disease detection, this article introduces an innovative solution—the lightweight parallel depthwise separable convolutional neural network (PDSCNN) coupled with a hybrid ridge regression extreme learning machine classifier. This combined approach automates plant disease classification, significantly expediting the learning process and reducing computational complexity. The PDSCNN model excels in feature capture, boasting a mere 9 layers and 0.053 million parameters, resulting in exceptional computational efficiency. On top of that, the classification performances of traditional ELM increased by introducing a hybrid ridge ELM model. Its accelerated operations, reduced memory usage, and optimized parallel processing render it lightweight and ideal for edge devices. The proposed framework exhibits remarkable efficacy, showcasing a precision of 95.76%, a recall of 89.29%, an F1-score of 91.25%, an accuracy of 94.22%, and an AUC of 99.72%. Moreover, training and testing times clock in at just 0.2314 and 0.0259 s, respectively. A comparative analysis against state-of-the-art transfer learning methods underscores its real-time analytical prowess. To demonstrate real-world applicability, we successfully validated our model on the Jetson Nano hardware, making it suitable for resource-constrained settings.},
  archive      = {J_NCA},
  author       = {Ahamed, Md. Faysal and Salam, Abdus and Nahiduzzaman, Md. and Abdullah-Al-Wadud, M. and Islam, S. M. Riazul},
  doi          = {10.1007/s00521-024-10152-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18445-18477},
  shortjournal = {Neural Comput. Appl.},
  title        = {Streamlining plant disease diagnosis with convolutional neural networks and edge devices},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing pneumonia detection with masked neural networks: A
deep learning approach. <em>NCA</em>, <em>36</em>(29), 18433–18444. (<a
href="https://doi.org/10.1007/s00521-024-10185-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumonia, a prevalent respiratory disease, affects millions globally. Accurate diagnosis and early detection are essential for managing and treating pneumonia. In recent years, machine learning and visual analysis technologies have shown promise for detecting pneumonia from therapeutic imageries such as chest X-rays. The dataset is collected from a Kaggle and contains X-ray scans of lungs from people of all ages. This dataset includes 5,856 labelled images, of which 4,273 are positive for pneumonia and 1,583 are negative. The data set is preprocessed using data augmentation techniques such as rotation, shifting, shearing, flipping and fill mode. The preprocessed data is trained using a masked neural network (MNN). The essential features are extracted from the last layer of MNN, and then the K-nearest neighbor (KNN) classify the chest X-rays to detect Pneumonia. This study developed a mask generation technique, dropout regularisation, and classifiers to train a model with 98.07% accuracy and minimal losses. This approach could lead to faster and more accurate pneumonia diagnoses, ultimately improving patient outcomes. Our research shows that transfer learning of KNN with MNN can effectively analyse chest X-rays to detect pneumonia.},
  archive      = {J_NCA},
  author       = {Gowri, L. and Pradeepa, S. and Panchada, Vamsi and Amirtharajan, Rengarajan},
  doi          = {10.1007/s00521-024-10185-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18433-18444},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing pneumonia detection with masked neural networks: A deep learning approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DriSm_YNet: A breakthrough in real-time recognition of
driver smoking behavior using YOLO-NAS. <em>NCA</em>, <em>36</em>(29),
18413–18432. (<a
href="https://doi.org/10.1007/s00521-024-10162-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver smoking rates are rising day after day. This becomes more crucial when operating a vehicle because of the number of deadly traffic accidents caused by this careless behavior. Therefore, to overcome this problem, there is a need for a reliable system that can work in less time and with reasonable accuracy. Here, the motive of this study is to satisfy this demand. In this study, a vast video dataset named HMDB51 has been utilized. Further, this dataset is pre-processed with image enhancement techniques, i.e., histogram utilization and gamma correction. After that, computer vision techniques, i.e., Haar Cascade and YOLO-NAS, have been employed to capture the face, mouth, and eye regions of interest, respectively. Further, an occlusion condition is formulated based on eye parameters to discard the occluded frames at the initial processing stage. Afterward, the TransGAN-augmented technique was employed to avoid the possibility of underfitting that might occur due to the removal of occluded frames. Thereafter, spatio-temporal features were extracted from mouth ROI by the InceptionV3 and fed into LSTM to classify the smoking and non-smoking states of the driver. Thus, the proposed model has categorized the smoking and non-smoking conditions of the driver with a remarkable accuracy of 96.5% based on the AUC-ROC score and confusion metrics compared to existing models.},
  archive      = {J_NCA},
  author       = {Pandey, Nageshwar Nath and Pati, Avadh and Maurya, Ritesh},
  doi          = {10.1007/s00521-024-10162-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18413-18432},
  shortjournal = {Neural Comput. Appl.},
  title        = {DriSm_YNet: A breakthrough in real-time recognition of driver smoking behavior using YOLO-NAS},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting grout’s uniaxial compressive strength (UCS) for
fully grouted rock bolting system by applying ensemble machine learning
techniques. <em>NCA</em>, <em>36</em>(29), 18387–18412. (<a
href="https://doi.org/10.1007/s00521-024-10128-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel system for accurately predicting grout’s uniaxial compressive strength (UCS) in fully grouted rock bolting systems. To achieve this, a database comprising 73 UCS values with varying water-to-grout (W/G) ratios ranging from 22 to 42%, curing times from 1 to 28 days, the admixture of fly ash contents ranging from 0 to 30%, and two Australian commercial grouts, Stratabinder HS, and BU-100, was built after conducting comprehensive series of experimental tests. After building the dataset, a metaheuristic technique, the jellyfish search (JS) algorithm was employed to determine the weight of base models in the ensemble system. This system combined various data and modelling techniques to enhance the accuracy of the UCS predictions. What sets this technique apart is the comprehensive database and the innovative use of the JS algorithm to create a weighted averaging ensemble model, going beyond traditional methods for predicting grout strength. The proposed ensemble model was called the weighted averaging ensemble model (WAE-JS), in which the obtained results of several soft computing models such as multi-layer perceptron (MLP), Bayesian regularized (BR) neural networks, generalized feed-forward (GFF) neural networks, classification and regression tree (CART), and random forest (RF) were weighted based on JS and the new results were then generated. Eventually, the result of WAE-JS was compared to other models, including MLP, BR, GFF, CART, and RF, based on some statistical parameters, such as R-squared coefficients, RMSE, and VAF as indices for evaluating the performance and capability of the proposed model. The results suggested the superiority of the ensemble WAE-JS system over the base models. In addition, the proposed WAE-JS model effectively improved the predicting accuracy achieved from the MLP, BR, GFF, CART, and RF. Furthermore, the sensitivity analysis revealed that the W/G had the most significant impact on the grout’s UCS values.},
  archive      = {J_NCA},
  author       = {Hosseini, Shahab and Entezam, Shima and Jodeiri Shokri, Behshad and Mirzaghorbanali, Ali and Nourizadeh, Hadi and Motallebiyan, Amin and Entezam, Alireza and McDougall, Kevin and Karunasena, Warna and Aziz, Naj},
  doi          = {10.1007/s00521-024-10128-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18387-18412},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting grout’s uniaxial compressive strength (UCS) for fully grouted rock bolting system by applying ensemble machine learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical modeling of neuron model through
fractal-fractional differentiation based on maxwell electromagnetic
induction: Application to neurodynamics. <em>NCA</em>, <em>36</em>(29),
18377–18385. (<a
href="https://doi.org/10.1007/s00521-024-10047-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electrical activities of the reliable neuron models have different responses within intrinsic biophysical effects and can functionalize for asymmetric coexisting electrical activities under anti-monotonicity phenomenon. This manuscript presents mathematical analysis of neuron model based on Maxwell electromagnetic induction through newly proposed fractal-fractional differential and integral operators. The neuron model based on Maxwell electromagnetic induction changes with time along a fractal dimension that describes the cumulative chaotic phenomenon. The cumulative chaotic phenomenon of neuron model is mathematically modeled via exponential and Mittag–Leffler kernels with variable and fixed fractal and fractional orders. In order to exhibit fractal properties and memory effects, the neuron model is discretized by means of Adams–Bashforth-Moulton method that allows explicitly to compute the approximate solution of neuron model. The comparison of neuron model based on memory effect and fractal dimension have distinguished the evolution of neuron model at (i) variability of fractal order with fixed fractional order, (ii) variability of fractional order with fixed fractal order, and (iii) variability of fractal order as well fractional order.},
  archive      = {J_NCA},
  author       = {Abro, Kashif Ali and Atangana, Abdon},
  doi          = {10.1007/s00521-024-10047-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18377-18385},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mathematical modeling of neuron model through fractal-fractional differentiation based on maxwell electromagnetic induction: Application to neurodynamics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DNACoder: A CNN-LSTM attention-based network for genomic
sequence data compression. <em>NCA</em>, <em>36</em>(29), 18363–18376.
(<a href="https://doi.org/10.1007/s00521-024-10130-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genomic sequencing has become increasingly prevalent, generating massive amounts of data and facing a significant challenge in long-term storage and transmission. A solution that reduces the storage and transfer requirements without compromising data integrity is needed. The effectiveness of neural networks has already been endorsed in tasks like image and speech compression. Adapting them to recognize the intricate patterns in genomic sequences could help to find more redundancies and reduce storage requirements. The proposed method, called DNACoder, leverages deep learning techniques to achieve significant compression ratios while preserving the essential information in genomic data and offers a high-performance compression for genomic sequences in any data format. The results of the experiments clearly demonstrate the effectiveness of the method and its potential applications in genomic data storage. Our proposed method improves compression by 21.1% on bits per base compared to existing compressors on the benchmarked dataset. By using a deep learning prediction model that is structured as a convolutional layer followed by an attention-based long short-term memory network, we propose a novel lossless and reference-free compression approach (DNACoder), which can also be utilized as a reference-based compressor. The experimental outcome on the tested data illustrates that the advocated compression algorithm’s CNN-LSTM model makes generalizations effectively for genomic sequence data and outperforms the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Sheena, K. S. and Nair, Madhu S.},
  doi          = {10.1007/s00521-024-10130-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18363-18376},
  shortjournal = {Neural Comput. Appl.},
  title        = {DNACoder: A CNN-LSTM attention-based network for genomic sequence data compression},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AFINITI: Attention-aware feature integration for nuclei
instance segmentation and type identification. <em>NCA</em>,
<em>36</em>(29), 18343–18361. (<a
href="https://doi.org/10.1007/s00521-024-10114-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately identifying and analyzing nuclei is pivotal for both the diagnosis and examination of cancer. However, the complexity of this task arises due to the presence of overlapping and cluttered nuclei with blurred boundaries, variations in nuclei sizes and shapes, and an imbalance in the available datasets. Although current methods utilize region proposal techniques and feature encoding frameworks, but they often fail to precisely identify occluded nuclei instances. We propose a model named AFINITI, which is both simple, efficient, achieves high accuracy, recognizes instance boundaries cluttered and overlapping nuclei, and addresses class imbalance issues. Our approach utilizes nuclei pixel positional information and a novel loss function to yield accurate class information for each nuclei. Our network features a lightweight, attention-aware feature fusion architecture with separate instance probability, shape radial estimator, and classification heads. We use a compound classification loss function to assign a weighted loss to each class according to its occurrence frequency, thereby addressing the class imbalance issues. The AFINITI model outperforms current leading networks across eight major publicly available nuclei segmentation datasets achieving up to an 8% increase in Dice Similarity Coefficient (DSc) and a 17% increase in Panoptic Quality (PQ) compared to existing techniques demonstrating its effectiveness and potential for clinical applications. The source code and the weights of the trained model have been released to the public and can be accessed at: https://github.com/Vision-At-SEECS/AF-Net .},
  archive      = {J_NCA},
  author       = {Nasir, Esha Sadia and Rasool, Shahzad and Nawaz, Raheel and Fraz, Muhammad Moazam},
  doi          = {10.1007/s00521-024-10114-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18343-18361},
  shortjournal = {Neural Comput. Appl.},
  title        = {AFINITI: Attention-aware feature integration for nuclei instance segmentation and type identification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting diabetes in an ensemble model using a unique
PSO-GWO hybrid approach to hyperparameter optimization. <em>NCA</em>,
<em>36</em>(29), 18313–18341. (<a
href="https://doi.org/10.1007/s00521-024-10160-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes is a chronic medical condition that disrupts the body&#39;s normal blood sugar levels. It is essential to detect this disease at an early stage in order to prevent organ and tissue injury. This study focuses on diagnosing diabetes by leveraging ensemble learning methods, which involve combining various machine learning techniques. The goal is to create an ensemble learning model that achieves the best classification performance by employing different classifiers and combining techniques. The study explores boosting, bagging, voting, and stacking ensemble learning methods, while also introducing an approach called PSO-GWO (Particle Swarm Optimization and Grey Wolf Optimization) hybrid method for optimizing the model&#39;s hyperparameters. The model consisting of combining various classifiers in the stacking ensemble learning method provided the highest classification performance in diagnosing diabetes. The 5-fold cross-validation method is used in the study. Within the scope of the study, the highest accuracy with (98.10%) is obtained with the random forest classifier. The results of the study are presented in comparison with other studies in the literature. These findings contribute to the field of diabetes diagnosis and highlight the potential for developing more accurate and reliable diagnostic systems in the future.},
  archive      = {J_NCA},
  author       = {Ulutas, Hasan and Günay, Recep Batuhan and Sahin, Muhammet Emin},
  doi          = {10.1007/s00521-024-10160-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18313-18341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detecting diabetes in an ensemble model using a unique PSO-GWO hybrid approach to hyperparameter optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive activation functions for predictive modeling with
sparse experimental data. <em>NCA</em>, <em>36</em>(29), 18297–18311.
(<a href="https://doi.org/10.1007/s00521-024-10156-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A pivotal aspect in the design of neural networks lies in selecting activation functions, crucial for introducing nonlinear structures that capture intricate input–output patterns. While the effectiveness of adaptive or trainable activation functions has been studied in domains with ample data, like image classification problems, significant gaps persist in understanding their influence on classification accuracy and predictive uncertainty in settings characterized by limited data availability. This research aims to address these gaps by investigating the use of two types of adaptive activation functions. These functions incorporate shared and individual trainable parameters per hidden layer and are examined in three testbeds derived from additive manufacturing problems containing fewer than 100 training instances. Our investigation reveals that adaptive activation functions, such as Exponential Linear Unit (ELU) and Softplus, with individual trainable parameters, result in accurate and confident prediction models that outperform fixed-shape activation functions and the less flexible method of using identical trainable activation functions in a hidden layer. Therefore, this work presents an elegant way of facilitating the design of adaptive neural networks in scientific and engineering problems.},
  archive      = {J_NCA},
  author       = {Pourkamali-Anaraki, Farhad and Nasrin, Tahamina and Jensen, Robert E. and Peterson, Amy M. and Hansen, Christopher J.},
  doi          = {10.1007/s00521-024-10156-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18297-18311},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive activation functions for predictive modeling with sparse experimental data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). ETSVF-COVID19: Efficient two-stage voting framework for
COVID-19 detection. <em>NCA</em>, <em>36</em>(29), 18277–18295. (<a
href="https://doi.org/10.1007/s00521-024-10150-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 disease, an outbreak in the spring of 2020, reached very alarming dimensions for humankind due to many infected patients during the pandemic and the heavy workload of healthcare workers. Even though we have been saved from the darkness of COVID-19 after about three years, the importance of computer-aided automated systems that support field experts in the fight against with global threat has emerged once again. This study proposes a two-stage voting framework called ETSVF-COVID19 that includes transformer-based deep features and a machine learning approach for detecting COVID-19 disease. ETSVF-COVID19, which offers 99.2% and 98.56% accuracies on computed tomography scan and X-radiation images, respectively, could compete with the related works in the literature. The findings demonstrate that this framework could assist field experts in making informed decisions while diagnosing COVID-19 with its fast and accurate classification role. Moreover, ETSVF-COVID19 could screen for chest infections and help physicians, particularly in areas where test kits and specialist doctors are inadequate.},
  archive      = {J_NCA},
  author       = {Akyol, Kemal},
  doi          = {10.1007/s00521-024-10150-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18277-18295},
  shortjournal = {Neural Comput. Appl.},
  title        = {ETSVF-COVID19: Efficient two-stage voting framework for COVID-19 detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging AutoEncoders and chaos theory to improve
adversarial example detection. <em>NCA</em>, <em>36</em>(29),
18265–18275. (<a
href="https://doi.org/10.1007/s00521-024-10141-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phenomenon of adversarial examples is one of the most attractive topics in machine learning research these days. These are particular cases that are able to mislead neural networks, with critical consequences. For this reason, different approaches are considered to tackle the problem. On the one side, defense mechanisms, such as AutoEncoder-based methods, are able to learn from the distribution of adversarial perturbations to detect them. On the other side, chaos theory and Lyapunov exponents (LEs) have also been shown to be useful to characterize them. This work proposes the combination of both domains. The proposed method employs these exponents to add more information to the loss function that is used during an AutoEncoder training process. As a result, this method achieves a general improvement in adversarial examples detection performance for a wide variety of attack methods.},
  archive      = {J_NCA},
  author       = {Pedraza, Anibal and Deniz, Oscar and Singh, Harbinder and Bueno, Gloria},
  doi          = {10.1007/s00521-024-10141-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18265-18275},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging AutoEncoders and chaos theory to improve adversarial example detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EGANet: Elevation-guided attention network for scene
classification in panchromatic remote sensing images. <em>NCA</em>,
<em>36</em>(29), 18251–18264. (<a
href="https://doi.org/10.1007/s00521-024-10134-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene classification in panchromatic (PAN) remote sensing images is a challenging task due to arbitrary spatial arrangement of a variety of objects with complex background in the absence of RGB-channel information. In this paper, we propose an elevation-guided attention network (EGANet) for multimodal scene classification in panchromatic images by leveraging elevation information from digital elevation model (DEM). The proposed network helps to identify the potential regions containing prominent class-specific features in the panchromatic image scene with the attention of elevation features extracted from a convolution neural network (CNN). Then, elevation-guided features in panchromatic image scene are obtained by the correlation of these two modalities for effective scene classification. The efficacy of the proposed method is demonstrated on Cartosat-1 panchromatic remote sensing image datasets with a lot of variations in view-angle, occlusion, background, and illumination conditions. The experimental results show that our proposed EGANet achieves scene classification accuracy with an improvement of 5% in comparison with the state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Datla, Rajeshreddy and Swetha, G. and Gayathri, C.},
  doi          = {10.1007/s00521-024-10134-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18251-18264},
  shortjournal = {Neural Comput. Appl.},
  title        = {EGANet: Elevation-guided attention network for scene classification in panchromatic remote sensing images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). An improving integration-enhanced ZNN for solving
time-varying polytope distance problems with inequality constraint.
<em>NCA</em>, <em>36</em>(29), 18237–18250. (<a
href="https://doi.org/10.1007/s00521-024-10100-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying polytope distance (TVPD) problems are prevalent in scientific and engineering applications and can be transformed into time-varying quadratic programming (TVQP) problems with both equality and inequality constraints. Concurrently, the noise interferences during the solution process are non-negligible and challenging to eliminate. Although zeroing neural networks (ZNNs) perform well in solving various types of time-varying problems, they still fall short in the suppression of unbounded noises, such as linear noise. To address this limitation, this paper proposes an improving integration-enhanced ZNN (IIEZNN) model for accurately solving TVPD problems under noise environments. Compared with the existing ZNN models, the IIEZNN model has stronger inherent robustness. The stability and robustness of the IIEZNN model are guaranteed by rigorous theoretical analysis. Firstly, the effectiveness of the IIEZNN model is verified via two TVQP examples. Then, the IIEZNN model is generalized to TVPD problem solving and has excellent performance. Specifically, in solving the TVPD under linear noises, the residual error of the IIEZNN model converges to the order of $$10^{-5}$$ , which is much lower than that of the existing noise-tolerant ZNN model with an order of $$10^{-1}$$ .},
  archive      = {J_NCA},
  author       = {Li, Hao and Zhang, Zhen and Liao, Bolin and Hua, Cheng},
  doi          = {10.1007/s00521-024-10100-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18237-18250},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improving integration-enhanced ZNN for solving time-varying polytope distance problems with inequality constraint},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated multiple-choice question generation in spanish
using neural language models. <em>NCA</em>, <em>36</em>(29),
18223–18235. (<a
href="https://doi.org/10.1007/s00521-024-10076-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents an approach to automatic multiple-choice question (MCQ) generation in the Spanish language, using mT5-based models. The process encompasses three crucial tasks: candidate answer extraction, answer-aware question generation, and distractor generation. A methodical pipeline is structured to seamlessly integrate these tasks, converting an input text into a systematic questionnaire. For model fine-tuning, the Stanford Question Answering Dataset is employed for the first two tasks, while a combination of three different multiple-choice question datasets, translated automatically into Spanish, is used for the distractor generation task. The efficiency of the models is then evaluated by using a triad of metrics, namely BLEU, ROUGE-L, and cosine similarity. The outcomes indicate a marginal deviation from the baseline model in the question generation task but demonstrate superior performance in the distractor generation task. Importantly, this research emphasizes the potential and effectiveness of language models for automating MCQ generation, providing a valuable contribution to the field and enhancing the understanding and application of such models in the context of the Spanish language.},
  archive      = {J_NCA},
  author       = {de-Fitero-Dominguez, David and Garcia-Cabot, Antonio and Garcia-Lopez, Eva},
  doi          = {10.1007/s00521-024-10076-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18223-18235},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated multiple-choice question generation in spanish using neural language models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating ARAS with PyFWZIC to evaluate and benchmark
patient-facing genetic services digital tools. <em>NCA</em>,
<em>36</em>(29), 18201–18222. (<a
href="https://doi.org/10.1007/s00521-024-10153-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital tools are revolutionizing patient care by enhancing the quality of care and facilitating the development of patient-oriented solutions that improve patients’ well-being. Evaluating and comparing these digital tools requires the consideration of several essential key criteria, which turns it into a multicriteria decision-making (MCDM) problem. This study introduces a decision-making framework that integrates the additive ratio assessment (ARAS) method with an extension of the fuzzy weighted zero inconsistency based on the Pythagorean fuzzy environment (PyFWZIC). The framework is used to evaluate and benchmark genetic services tools used by patients based on a decision matrix formed of eight key attributes and 69 existing digital tools as alternatives grouped in five main categories. PyFWZIC is used to compute the weights of the criteria based on the opinion of three domain experts. The ARAS method is used to benchmark the digital tools and rank them for effectiveness. The findings of the study reveal that PyFWZIC effectively weighs the key criteria required for the development and benchmarking of genetic services digital tools while considering the vagueness and ambiguities of subjective opinions and eliminating inconsistencies that arise thereof. The robustness and reliability of the result is evaluated using sensitivity analysis and comparative analysis.},
  archive      = {J_NCA},
  author       = {Bilquise, Ghazala and Ibrahim, Samar},
  doi          = {10.1007/s00521-024-10153-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18201-18222},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrating ARAS with PyFWZIC to evaluate and benchmark patient-facing genetic services digital tools},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation and benchmarking of hybrid machine learning
models for autism spectrum disorder diagnosis using a 2-tuple linguistic
neutrosophic fuzzy sets-based decision-making model. <em>NCA</em>,
<em>36</em>(29), 18161–18200. (<a
href="https://doi.org/10.1007/s00521-024-09905-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) presents challenges for accurate diagnosis, prompting researchers to search for an optimal diagnostic process. Feature selection (FS) approaches and classification methods considering medical tests and socio-demographic characteristics are crucial for diagnosing autism. However, evaluating and benchmarking hybrid diagnosis machine learning (ML) models in the presence of multiple evaluation performance metrics, criteria trade-offs, and varying criteria importance present complex multi-criteria decision-making (MCDM) problems. This study proposes a three-phase methodology integrating FS, ML, and fuzzy MCDM to develop and evaluate diagnosis models. Firstly, an ASD dataset combining medical tests and socio-demographic characteristics is identified and preprocessed. Secondly, 72 hybrid diagnosis models are developed by combining eight FS techniques and nine ML algorithms using an intersection process. Thirdly, the following steps are performed: (i) A decision matrix is formulated based on nine evaluation metrics, including classification accuracy (CA), specificity, precision, F1 score, recall, test time, train time, log loss, and area under the curve (AUC); (ii) a new extension of fuzzy-weighted zero inconsistency is developed using 2-tuple linguistic neutrosophic fuzzy sets (2TLNFSs) to assign weights to the evaluation metrics criteria and address related issues; (iii) a new extension of the fuzzy decision-by-opinion score method is developed using 2TLNFSs as well to benchmark the 72 models. Results indicate that the selected FS techniques vary in the number of features chosen, with the sets ranging from 19 to 46 out of the 48 available features. Socio-demographic features were predominantly selected over medical tests. Regarding the evaluation and benchmarking results, the weights constructed by three experts suggest that CA holds high importance, precision and recall are assigned equal weights, and AUC and test time carry moderate weights. At the same time, F1 and log loss are considered less crucial in the decision-making process. Specificity and train time are assigned relatively lower weights, indicating their lower importance. The best-performing hybrid model identified was sequential feature selection/logistic regression (SFS/LR)-decision tree, with a score value of 4.3964. Decision trees and gradient boosting consistently achieved high rankings, demonstrating their effectiveness in diagnosing ASD, while SVM, random forest, and logistic regression showed mixed results across different hybrid models. The sensitivity analysis assessments were conducted to verify the efficiency of the proposed evaluation and benchmarking methodology. We benchmarked the proposed framework against three other benchmark studies and achieved a score of 100% across five key areas. The developed methodology can potentially advance and accelerate the selection of diagnostic tools for ASD therapy, benefiting individuals with ASD.},
  archive      = {J_NCA},
  author       = {Alqaysi, M. E. and Albahri, A. S. and Hamid, Rula A.},
  doi          = {10.1007/s00521-024-09905-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18161-18200},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluation and benchmarking of hybrid machine learning models for autism spectrum disorder diagnosis using a 2-tuple linguistic neutrosophic fuzzy sets-based decision-making model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Chimera states and information transfer in interacting
populations of map-based neurons. <em>NCA</em>, <em>36</em>(29),
18151–18159. (<a
href="https://doi.org/10.1007/s00521-024-10050-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the synchronization behavior and the emergence of chimera states in a system of two interacting populations of maps possessing chaotic neural-like dynamics. We characterize four collective states on the space of coupling parameters of the system: complete synchronization, generalized synchronization, chimera states, and incoherence. We quantify the information exchange between the two neuron populations in chimera states. We have found a well-defined direction of the flow of information in chimera states, from the desynchronized population to the synchronized one. The incoherent population functions as a driver of the coherent neuron population in a chimera state. This feature is independent of the population sizes or population partitions. Our results yield insight into the communication mechanisms arising in brain processes such as unihemispheric sleep and epileptic seizures that have been associated to chimera states.},
  archive      = {J_NCA},
  author       = {Márquez-Rodríguez, V. J. and Tucci, K. and Cosenza, M. G.},
  doi          = {10.1007/s00521-024-10050-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18151-18159},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chimera states and information transfer in interacting populations of map-based neurons},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic real-word error correction in persian text.
<em>NCA</em>, <em>36</em>(29), 18125–18149. (<a
href="https://doi.org/10.1007/s00521-024-10045-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic spelling correction stands as a pivotal challenge within the ambit of natural language processing (NLP), demanding nuanced solutions. Traditional spelling correction techniques are typically only capable of detecting and correcting non-word errors, such as typos and misspellings. However, context-sensitive errors, also known as real-word errors, are more challenging to detect because they are valid words that are used incorrectly in a given context. The Persian language, characterized by its rich morphology and complex syntax, presents formidable challenges to automatic spelling correction systems. Furthermore, the limited availability of Persian language resources makes it difficult to train effective spelling correction models. This paper introduces a cutting-edge approach for precise and efficient real-word error correction in Persian text. Our methodology adopts a structured, multi-tiered approach, employing semantic analysis, feature selection, and advanced classifiers to enhance error detection and correction efficacy. The innovative architecture discovers and stores semantic similarities between words and phrases in Persian text. The classifiers accurately identify real-word errors, while the semantic ranking algorithm determines the most probable corrections for real-word errors, taking into account specific spelling correction and context properties such as context, semantic similarity, and edit-distance measures. Evaluations have demonstrated that our proposed method surpasses previous Persian real-word error correction models. Our method achieves an impressive F-measure of 96.6% in the detection phase and an accuracy of 99.1% in the correction phase. These results clearly indicate that our approach is a highly promising solution for automatic real-word error correction in Persian text.},
  archive      = {J_NCA},
  author       = {Dashti, Seyed Mohammad Sadegh and Bardsiri, Amid Khatibi and Shahbazzadeh, Mehdi Jafari},
  doi          = {10.1007/s00521-024-10045-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18125-18149},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic real-word error correction in persian text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial neural network-assisted theoretical model to
predict the viscoelastic–plastic tensile behavior of polyamide-6
multi-ply yarns. <em>NCA</em>, <em>36</em>(29), 18107–18123. (<a
href="https://doi.org/10.1007/s00521-024-10048-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-ply yarns have been used as the main structure to form strands, braids, and fabrics. Thus, various strategies including experimental, numerical, and analytical models have been utilized to predict their tensile behavior. In analytical models, all are limited to a specific number of fibers in an elastic region. The time-consuming experimental-based studies suffer from the accuracy of subjective results, associated errors of the experiment, ignoring the physical aspect of the problem, and practical issues during the controlling of variables. Concerning the numerical approaches, no insight into generalization is provided and they are bug-prone methods. In this study, a generalized method is developed to predict the whole tensile behavior of polyamide-6 (PA-6) multi-ply yarns with an open-packing structure. This approach is a combination of two geometrical models and an artificial neural network that enable the calculation of the deformation of fibers in different layers, the number of fibers in each layer by taking the gap into account, and an artificial neural network to map from parameters including strain and rate of strain to the reacting force on monofilament. The model has been verified by numerical analysis and examination of several factors including the number of layers, twist level, and rate of strain. After having trained ANN modeling with $${R}^{2}\approx 1$$ , the proof-of-concept results demonstrated that this established model is capable of predicting the tensile behavior of PA-6 multi-ply yarns with high precision and accuracy (average value of $${R}^{2}=0.97$$ and $$\text{MAPE}=4.65 \%$$ ). It is envisioned that the presented model can be extensively applied to all yarns.},
  archive      = {J_NCA},
  author       = {Razbin, Milad and Gharehaghaji, Ali Akbar and Salehian, Mortaza and Zhu, Yangzhi and Kish, Mohammad Haghighat and Kouchehbaghi, Negar Hosseinzadeh},
  doi          = {10.1007/s00521-024-10048-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18107-18123},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural network-assisted theoretical model to predict the viscoelastic–plastic tensile behavior of polyamide-6 multi-ply yarns},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing OCT patch-based segmentation with improved GAN
data augmentation and semi-supervised learning. <em>NCA</em>,
<em>36</em>(29), 18087–18105. (<a
href="https://doi.org/10.1007/s00521-024-10044-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For optimum performance, deep learning methods, such as those applied for retinal and choroidal layer segmentation in optical coherence tomography (OCT) images, require sufficiently large and diverse labelled datasets for training. However, the acquisition and labelling of such data can be difficult or infeasible due to privacy reasons (particularly in the medical domain), accessing patient images such as those with specific pathologies, and the cost and time investment to annotate large volumes of data by clinical experts. Data augmentation is one solution to address this issue, either using simple variations and transformations of the images (e.g. flips, brightness) or using synthetic data from sophisticated generative methods such as generative adversarial networks (GANs). Semi-supervised learning (SSL) is another technique which aims to utilise unlabelled data to enhance the performance of deep learning methods and is beneficial where significant amounts of data may be available but are not labelled. In this study, we aim to enhance patch-based OCT retinal and choroidal layer segmentation with both GAN-based data augmentation and SSL. In particular, we employ a conditional StyleGAN2 to generate synthetic patches for data augmentation and a similar unconditional GAN for pre-training the patch classifier to perform SSL. In doing so, we propose a new patch classifier architecture based on the discriminator architecture to improve performance, in addition to the SSL benefit. Compared to previous methods, the proposed data augmentation approach provides an improved data augmentation performance for patch classification with its effectiveness widespread, particularly in the case of low data, across three different OCT datasets encompassing a range of scanning parameters, noise levels, pathology and participant variability. The method provides some subsequent improvements in boundary delineation which is of high importance from a clinical perspective. Additionally, the proposed SSL approach boosts classification performance and boundary delineation performance in some cases which provides further usefulness in the case of low data. The proposed methods can be utilised to enhance OCT segmentation methods, which may be of considerable benefit for both clinicians and researchers.},
  archive      = {J_NCA},
  author       = {Kugelman, Jason and Alonso-Caneiro, David and Read, Scott A. and Vincent, Stephen J. and Collins, Michael J.},
  doi          = {10.1007/s00521-024-10044-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18087-18105},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing OCT patch-based segmentation with improved GAN data augmentation and semi-supervised learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KHACDD: A knowledge-based hybrid method for multilabel
sentiment analysis on complex sentences using attentive capsule and dual
structured recurrent network. <em>NCA</em>, <em>36</em>(29),
18065–18086. (<a
href="https://doi.org/10.1007/s00521-024-09934-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using a machine to mine public opinion saves money and time. Traditional sentiment analysis approaches are typically unable to handle multi-meaning phrases, syntactically complex structured statements, and a large number of characteristics. We proposed a new knowledge-based hybrid deep learning method (KHACDD) for sentiment classification that integrates a hierarchical attention-based capsule infrastructure with both the dual along with bidirectional recurrent neural network (RNN), Dilated convolutional neural network (CNN), and domain-based knowledge to fix these problems. Our innovative hybrid approach enhances the structure of feature representation as well as feature extraction as well as sentiment classification by dynamically routing capsules its hierarchy structure toward an attention capsule. The suggested hybrid neural network model is based on modified capsules and therefore can learn implicit semantics effectively. The BiGRU-BiLSTM is used all through this system to achieve proper long-distance and interdependent contextual information functioning. In addition, the capsule network may be capable of extracting rich textual information in order to improve express ability. GloVe embedding is used before the RNN layer to incorporate local context into global statistics. To improve performance, the proposed technique leveraged domain-specific information to handle misclassification. Adding adaptive domain-specific knowledge produces a margin of roughly 1% for multilabel ER(Emotion Recognition) social media data as well as 4% for multifeatured and multilabel MHER(Mental Health Emotion Recognition) clinical data, according to the experimental results. In the future, we will improve our model to handle more classes of sentiment with less complexity.},
  archive      = {J_NCA},
  author       = {Islam, Md Shofiqul and Ghani, Ngahzaifa Ab and Zamli, Kamal Zuhairi and Hasan, Md Munirul and Lokman, Abbas Saliimi},
  doi          = {10.1007/s00521-024-09934-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18065-18086},
  shortjournal = {Neural Comput. Appl.},
  title        = {KHACDD: A knowledge-based hybrid method for multilabel sentiment analysis on complex sentences using attentive capsule and dual structured recurrent network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heart rate variability analysis in controls and epilepsy
patients with or without receiving treatment: A clinical review and
meta-analysis. <em>NCA</em>, <em>36</em>(29), 18043–18063. (<a
href="https://doi.org/10.1007/s00521-024-10135-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The malfunctioning of cardiac autonomic control in epileptic patients develops ventricular tachyarrhythmia and causes sudden unexpected death in epilepsy patients (SUDEP). Various clinical studies investigated the effect of epilepsy on cardiac autonomic control by performing heart rate variability (HRV) analysis; however, results are unclear regarding whether sympathetic, parasympathetic, or both branches of the autonomic nervous system (ANS) are affected in epilepsy and also the impact of anticonvulsant treatment on the ANS. This study follows the systematic protocols to investigate epilepsy and its anticonvulsant treatment on cardiac autonomic control by using linear and nonlinear HRV analysis measures. The electronic databases of PubMed, Embase, and Cochrane Library were used for the collection of studies. Initially, 1475 articles were identified whereas after 2-staged exclusion criteria, 33 studies were selected for execution of the review process and meta-analysis. For meta-analysis, four comparisons were performed (epilepsy patients): (1) controls (healthy subject with no history of epilepsy) versus untreated patients; (2) treated (patients under treatment that have a seizure) versus untreated patients; (3) controls versus treated patients; and (4) refractory versus well-controlled (epilepsy patients that were seizure-free for last 1 year). For treated and untreated patients, there was no significant difference whereas well-controlled patients presented higher values as compared to refractory patients. Meta-analysis was performed for the time-domain, frequency-domain, and nonlinear parameters. Untreated patients in comparison with controls presented significantly lower HF (high-frequency) and LF (low-frequency) values. These LF (g = − 0.9; 95% CI − 1.48 to − 0.37) and HF (g = − 0.69; 95% confidence interval (CI) − 1.24 to  − 0.16) values were affirming suppressed both, vagal and sympathetic activity, respectively. Additionally, LF and HF value was increased in most of the studies indicating suppressed vagal tone, while for some studies, their value decreased to indicate suppressed sympathetic activity. No significant difference was observed for the remaining comparisons. Results affirmed the hypothesis that suppressed sympathetic activity affects sympathovagal balance and leads to SUDEP, as the LF value was significantly lower for patients as compared to healthy subjects. The overall effect size and statistical results for LF and HF were significant, showing the research and clinical significance of our study.},
  archive      = {J_NCA},
  author       = {Shahnawaz, Muhammad Bilal and Dawooda, Hassan and Iqbal, Uzair},
  doi          = {10.1007/s00521-024-10135-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18043-18063},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heart rate variability analysis in controls and epilepsy patients with or without receiving treatment: A clinical review and meta-analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning approaches to intrusion detection in
unmanned aerial vehicles (UAVs). <em>NCA</em>, <em>36</em>(29),
18009–18041. (<a
href="https://doi.org/10.1007/s00521-024-10306-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) have been gaining popularity in various commercial, civilian, and military applications due to their efficiency and cost-effectiveness. However, the increasing demand for UAVs makes them vulnerable to various cyberattacks/intrusions that could have devastating consequences at an individual, organizational, and national level. To mitigate this, prompt detection of such threats is crucial in order to prevent potential damage and ensure safe and secure operations. In this work, we provide an overview of UAV systems’ architecture, security, and privacy requirements. We then analyze potential threats to UAVs, providing an evaluation of countermeasures for UAV-based attacks. We also present a comprehensive and timely exploration of state-of-the-art UAV Intrusion Detection Systems (IDSs), specifically focusing on Machine Learning (ML)-based approaches. We look at the increasing importance of using ML for detecting intrusions in UAVs, which have gained significant attention from both academia and industry. This study also takes a step forward by pointing out and classifying contemporary IDSs based on their detection methods, feature selection techniques, evaluation datasets, and performance metrics. By evaluating existing research, we aim to provide more insight into the issues and limitations of current UAV IDSs. Additionally, we identify research gaps and challenges while suggesting potential future research directions in this domain.},
  archive      = {J_NCA},
  author       = {AL-Syouf, Raghad A. and Bani-Hani, Raed M. and AL-Jarrah, Omar Y.},
  doi          = {10.1007/s00521-024-10306-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {18009-18041},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning approaches to intrusion detection in unmanned aerial vehicles (UAVs)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision transformers in domain adaptation and domain
generalization: A study of robustness. <em>NCA</em>, <em>36</em>(29),
17979–18007. (<a
href="https://doi.org/10.1007/s00521-024-10353-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are often evaluated in scenarios where the data distribution is different from those used in the training and validation phases. The discrepancy presents a challenge for accurately predicting the performance of models once deployed on the target distribution. Domain adaptation and generalization are widely recognized as effective strategies for addressing such shifts, thereby ensuring reliable performance. The recent promising results in applying vision transformers in computer vision tasks, coupled with advancements in self-attention mechanisms, have demonstrated their significant potential for robustness and generalization in handling distribution shifts. Motivated by the increased interest from the research community, our paper investigates the deployment of vision transformers in domain adaptation and domain generalization scenarios. For domain adaptation methods, we categorize research into feature-level, instance-level, model-level adaptations, and hybrid approaches, along with other categorizations with respect to diverse strategies for enhancing domain adaptation. Similarly, for domain generalization, we categorize research into multi-domain learning, meta-learning, regularization techniques, and data augmentation strategies. We further classify diverse strategies in research, underscoring the various approaches researchers have taken to address distribution shifts by integrating vision transformers. The inclusion of comprehensive tables summarizing these categories is a distinct feature of our work, offering valuable insights for researchers. These findings highlight the versatility of vision transformers in managing distribution shifts, crucial for real-world applications, especially in critical safety and decision-making scenarios.},
  archive      = {J_NCA},
  author       = {Alijani, Shadi and Fayyad, Jamil and Najjaran, Homayoun},
  doi          = {10.1007/s00521-024-10353-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17979-18007},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vision transformers in domain adaptation and domain generalization: A study of robustness},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review of hybrid AC/DC networks: Insights
into system planning, energy management, control, and protection.
<em>NCA</em>, <em>36</em>(29), 17961–17977. (<a
href="https://doi.org/10.1007/s00521-024-10264-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of hybrid alternating current (AC)/direct current (DC) distribution networks led to several developments in smart grid and decentralized power system technology. The paper concentrates on several topics related to the operation of hybrid AC/DC networks. Such as optimization methods, control strategies, energy management, protection issues, and proposed solutions. The implementation of neural network optimization methods has great importance for the successful integration of multiple energy sources, dynamic energy management, establishment of system stability and reliability, power distribution optimization, management of energy storage, and online fault detection and diagnosis in hybrid networks like the hybrid AC–DC microgrids (MG). Taking advantage of renewable energy generation and cost-cutting through the neural network optimization technique holds the key to these progressions. Besides identifying the challenges in the operation of a hybrid system, the paper also compares this system to conventional MGs and shows the benefits of this type of system over different MG structures. This review compares the different topologies, particularly looking at the AC–DC coupled hybrid MGs, and shows the important role of the interlinking of converters that are used for efficient transmission between AC and DC MGs and generally used to implement the different control and optimization techniques. Overall, this review paper can be regarded as a reference, pointing out the pros and cons of integrating hybrid AC/DC distribution networks for future study and improvement paths in this developing area.},
  archive      = {J_NCA},
  author       = {Abdelwanis, Mohamed I. and Elmezain, Mohammed I.},
  doi          = {10.1007/s00521-024-10264-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17961-17977},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive review of hybrid AC/DC networks: Insights into system planning, energy management, control, and protection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Metaheuristic-based ensemble learning: An extensive review
of methods and applications. <em>NCA</em>, <em>36</em>(29), 17931–17959.
(<a href="https://doi.org/10.1007/s00521-024-10203-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning has become a cornerstone in various classification and regression tasks, leveraging its robust learning capacity across disciplines. However, the computational time and memory constraints associated with almost all-learners-based ensembles necessitate efficient approaches. Ensemble pruning, a crucial step, involves selecting a subset of base learners to address these limitations. This study underscores the significance of optimization-based methods in ensemble pruning, with a specific focus on metaheuristics as high-level problem-solving techniques. It reviews the intersection of ensemble learning and metaheuristics, specifically in the context of selective ensembles, marking a unique contribution in this direction of research. Through categorizing metaheuristic-based selective ensembles, identifying their frequently used algorithms and software programs, and highlighting their uses across diverse application domains, this research serves as a comprehensive resource for researchers and offers insights into recent developments and applications. Also, by addressing pivotal research gaps, the study identifies exploring selective ensemble techniques for cluster analysis, investigating cutting-edge metaheuristics and hybrid multi-class models, and optimizing ensemble size as well as hyper-parameters within metaheuristic iterations as prospective research directions. These directions offer a robust roadmap for advancing the understanding and application of metaheuristic-based selective ensembles.},
  archive      = {J_NCA},
  author       = {Rezk, Sahar Saeed and Selim, Kamal Samy},
  doi          = {10.1007/s00521-024-10203-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17931-17959},
  shortjournal = {Neural Comput. Appl.},
  title        = {Metaheuristic-based ensemble learning: An extensive review of methods and applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An in-depth examination of artificial intelligence-based
methods for optimal power flow solutions. <em>NCA</em>, <em>36</em>(29),
17881–17929. (<a
href="https://doi.org/10.1007/s00521-024-10312-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fundamental objective of a modern power system lies in ensuring reliable and effective energy access for its customers. The assessment and determination of optimal operating conditions for power systems involve the utilization of the optimal power flow (OPF) tool. By considering critical factors such as generator power, bus voltages, and line power flow limits while satisfying the power balance equations, the OPF tool enables the identification of the most favorable configuration for efficient power system operation. Traditional optimization methods have limitations in addressing complex power system problems due to poor convergence and long computational times. As a result, computational intelligence tools have gained popularity in recent years. These tools are versatile and enable efficient solution of power system problems by effectively handling qualitative constraints. This paper presents a well-organized and comprehensive review of the algorithms used in power system optimization in the existing literature, encompassing the most recent developments in the field. Specifically, it examines the application of various population-based artificial intelligence techniques that have gained widespread adoption over the past decade (2012–2022). The aim of these techniques is to resolve an OPF problem. This paper organizes the reviewed papers into various types of population-based metaheuristic algorithms, each one implemented sequentially to deal with the OPF problem in the same chronological order in which they appeared in the literature.},
  archive      = {J_NCA},
  author       = {Mittal, Udit and Nangia, Uma and Jain, Narender Kumar},
  doi          = {10.1007/s00521-024-10312-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17881-17929},
  shortjournal = {Neural Comput. Appl.},
  title        = {An in-depth examination of artificial intelligence-based methods for optimal power flow solutions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extraction of emerging trends in quantum algorithm archives.
<em>NCA</em>, <em>36</em>(29), 17851–17880. (<a
href="https://doi.org/10.1007/s00521-024-10198-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing (QC) has been viewed as a groundbreaking development in the modern technological landscape. The field of QC technology has made significant strides in various applications in recent years, making it one of the most researched topics today. QC technology outperforms classical computers by running quantum algorithms (QA), which have demonstrated superiority in real-time decision-making over traditional computing solutions. QA has wide-ranging applications in areas such as cryptography, search, optimization, measurements, quantum system simulation, and solving large-scale linear equations. This current study presents a scientometric analysis of over 2800 QA publications from the Scopus database spanning the last decade (2014–2023). The findings of this study shed light on key research areas in QA, providing insights into geographical analysis, linkages, keyword co-occurrences, prominent institutions, journal co-citations, document co-citations, and future research directions for QA. Furthermore, document co-citation analysis and linkages are conducted for each QA domain. A review of the academic literature reveals significant issues in the QA knowledge domain. The information gathered from this study can help identify relevant applications, research challenges, and major issues, offering a comprehensive overview of QA research. This scientometric study examines the growth and categorization of QA and its domains over time, while also identifying trends in collaboration among leading nations and institutions, prestigious journals, and active research fields. Through collaboration analysis, the top 10 nations and universities supporting QA research were identified, showcasing their global leadership in the discipline. Additionally, the study determined the most highly esteemed journals in the field.},
  archive      = {J_NCA},
  author       = {Sood, Sandeep Kumar and Singh, Manmohan and Bhatia, Munish},
  doi          = {10.1007/s00521-024-10198-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17851-17880},
  shortjournal = {Neural Comput. Appl.},
  title        = {Extraction of emerging trends in quantum algorithm archives},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Employing of machine learning and wearable devices in
healthcare system: Tasks and challenges. <em>NCA</em>, <em>36</em>(29),
17829–17849. (<a
href="https://doi.org/10.1007/s00521-024-10197-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disease outbreaks are nowadays a critical issue despite the development and rapid growth of technology. One of the major challenges facing healthcare professionals and healthcare industries is disease prevention and control by technology. Due to busy work schedules, maintaining a healthy lifestyle has become impossible, so the solution to these previous challenges is the intelligent health monitoring system. Over the past few years, a lot of research has been done on the use of Machine learning (ML) techniques in healthcare applications. With wearable devices, ML greatly helps in tracking human activities and vital signs as well as helping to monitor and diagnose patients’ health so it plays a huge role in elderly care. Research and development of more applications for wearable devices has been underway in the past five years, due to significant technological advances in medical sensors. Despite the widespread use of wearable devices, there is little research on machine learning applications of these devices. This paper presents a review of the different areas of recent ML research for healthcare wearable devices. It also discusses the different challenges facing ML applications on wearable devices.},
  archive      = {J_NCA},
  author       = {Saad, Hend S. and Zaki, John F. W. and Abdelsalam, Mohamed M.},
  doi          = {10.1007/s00521-024-10197-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17829-17849},
  shortjournal = {Neural Comput. Appl.},
  title        = {Employing of machine learning and wearable devices in healthcare system: Tasks and challenges},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of research on micro-expression recognition
algorithms based on deep learning. <em>NCA</em>, <em>36</em>(29),
17787–17828. (<a
href="https://doi.org/10.1007/s00521-024-10262-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expression is a special kind of human emotion. Due to its characteristics of short time, low intensity, and local region, micro-expression recognition is a difficult task. At the same time, it is a natural, spontaneous, and unconcealable emotion that can well convey a person&#39;s actual psychological state and, therefore, has certain research value and practical significance. This paper focuses on micro-expression recognition in the field of deep learning through the survey and understanding of existing micro-expression recognition research, as well as grasping the research trend, for the previous literature on micro-expression review ignored the handcrafted features as an important part of the micro-expression recognition framework, and at the same time lacked the analysis of the various enhancement processing, a new micro-expression recognition framework based on deep learning is proposed. The model is designed from the perspective of modularity and streaming data. On the other hand, unlike the previous process of feeding the data directly into the network for training and recognition, the handcrafted features are used as the initial encoding of the micro-expression recognition data, followed by the training and learning of the deep model and at the same time the modular embedding approach is used to incorporate the feature enhancement module, and finally the classification and recognition. The article provides a detailed summary and analysis of each part of the whole framework and a comprehensive introduction to the current problems, experimental protocols, evaluation metrics, and application areas. Finally, it summarizes and gives possible future research directions. Therefore, this paper provides a comprehensive summary and analysis of micro-expression recognition in deep learning so that the related personnel can have a new understanding of the development of this field. On the other hand, it proposes a new recognition framework that also provides a reference for the researchers&#39; later research.},
  archive      = {J_NCA},
  author       = {Zhang, Fan and Chai, Lin},
  doi          = {10.1007/s00521-024-10262-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17787-17828},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of research on micro-expression recognition algorithms based on deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning applications for vascular stenosis
detection in computed tomography angiography: A systematic review and
meta-analysis. <em>NCA</em>, <em>36</em>(29), 17767–17786. (<a
href="https://doi.org/10.1007/s00521-024-10199-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era in which cardiovascular disease has become the main cause of death all over the world, diagnostic accuracy in identifying blood vessels has become particularly important. Vascular stenosis causes serious health risks by affecting blood flow, leading to conditions like heart attacks and strokes. Traditional diagnostic methods face challenges in terms of timeliness and accuracy. Our systematic review aims to critically assess the role of machine learning (ML) techniques in enhancing computed tomography angiography’s (CTA) diagnostic capabilities for vasoconstriction. This review followed the predetermined inclusion and exclusion criteria and focused on research articles published between January 2013 and October 2023 collected from databases such as PubMed, IEEE, Web of Science, and Scopus. Studies focus on multiphase CTA or dynamic CTA; papers do not use the ML; and papers not in English are removed. The risk of bias of included studies was evaluated using the QUADAS2 tool. The results were analyzed in tabular form using metrics such as accuracy, sensitivity, and specificity and examine variations in stenosis detection by anatomical regions. In our review, a total of 63 studies were identified as relevant. These studies included a variety of ML applications for identifying anatomical stenosis of the arteries in different anatomical areas. The findings highlighted a trend of high sensitivity and specificity in broader anatomical assessments, with nuanced variations observed in detailed segmental analysis. The review acknowledges limitations within the existing studies, including the retrospective nature of most studies and their limited scope in terms of patient diversity and center variation. Nonetheless, the implications of integrating ML in vascular stenosis detection via CTA are profound, suggesting a pivotal shift toward more accurate, efficient, and patient-centric diagnostic practices in cardiovascular care. Registration: The protocol for this systematic review and meta-analysis was registered on PROSPERO, with the registration number CRD420234603.},
  archive      = {J_NCA},
  author       = {Anwer, Ali M. O. A. and Karacan, Hacer and Enver, Levent and Cabuk, Gonca},
  doi          = {10.1007/s00521-024-10199-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {29},
  pages        = {17767-17786},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning applications for vascular stenosis detection in computed tomography angiography: A systematic review and meta-analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A color image watermarking scheme based on
affine transformation and s4 permutation. <em>NCA</em>, <em>36</em>(28),
17765. (<a href="https://doi.org/10.1007/s00521-024-10339-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Batool, Syeda Iram and Shah, Tariq and Khan, Majid},
  doi          = {10.1007/s00521-024-10339-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17765},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A color image watermarking scheme based on affine transformation and s4 permutation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: CMDP-based intelligent transmission for
wireless body area network in remote health monitoring. <em>NCA</em>,
<em>36</em>(28), 17763. (<a
href="https://doi.org/10.1007/s00521-024-10359-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zang, Weilin and Miao, Fen and Gravina, Raffaele and Sun, Fangmin and Fortino, Giancarlo and Li, Ye},
  doi          = {10.1007/s00521-024-10359-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17763},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: CMDP-based intelligent transmission for wireless body area network in remote health monitoring},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A proposal for internet of smart home
things based on BCI system to aid patients with amyotrophic lateral
sclerosis. <em>NCA</em>, <em>36</em>(28), 17761. (<a
href="https://doi.org/10.1007/s00521-024-10358-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {de Oliveira Júnior, Wilson G. and de Oliveira, Juliana M. and Munoz, Roberto and de Albuquerque, Victor Hugo C.},
  doi          = {10.1007/s00521-024-10358-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17761},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A proposal for internet of smart home things based on BCI system to aid patients with amyotrophic lateral sclerosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A new EEG software that supports emotion
recognition by using an autonomous approach. <em>NCA</em>,
<em>36</em>(28), 17759. (<a
href="https://doi.org/10.1007/s00521-024-10357-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Munoz, Roberto and Olivares, Rodrigo and Taramasco, Carla and Villarroel, Rodolfo and Soto, Ricardo and Alonso-Sánchez, María Francisca and Merino, Erick and de Albuquerque, Victor Hugo C.},
  doi          = {10.1007/s00521-024-10357-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17759},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A new EEG software that supports emotion recognition by using an autonomous approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: REHAB FUN: An assistive technology in
neurological motor disorders rehabilitation of children with cerebral
palsy. <em>NCA</em>, <em>36</em>(28), 17757. (<a
href="https://doi.org/10.1007/s00521-024-10356-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {de Oliveira, Juliana M. and Munoz, Roberto and Ribeiro, Sidarta and Wu, Wanqing and de Albuquerque, Victor Hugo C.},
  doi          = {10.1007/s00521-024-10356-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17757},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: REHAB FUN: an assistive technology in neurological motor disorders rehabilitation of children with cerebral palsy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Evaluation of artificial intelligence
techniques for the classification of different activities of daily
living and falls. <em>NCA</em>, <em>36</em>(28), 17755. (<a
href="https://doi.org/10.1007/s00521-024-10360-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {De Falco, Ivanoe and De Pietro, Giuseppe and Sannino, Giovanna},
  doi          = {10.1007/s00521-024-10360-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17755},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Evaluation of artificial intelligence techniques for the classification of different activities of daily living and falls},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Learning visual representations with
optimum-path forest and its applications to barrett’s esophagus and
adenocarcinoma diagnosis. <em>NCA</em>, <em>36</em>(28), 17753. (<a
href="https://doi.org/10.1007/s00521-024-10343-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {de Souza, Luis A. and Afonso, Luis C. S. and Ebigbo, Alanna and Probst, Andreas and Messmann, Helmut and Mendel, Robert and Hook, Christian and Palm, Christoph and Papa, João P.},
  doi          = {10.1007/s00521-024-10343-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17753},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Learning visual representations with optimum-path forest and its applications to barrett’s esophagus and adenocarcinoma diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Retraction note: A novel image encryption technique based
on hénon chaotic map and s8 symmetric group. <em>NCA</em>,
<em>36</em>(28), 17751. (<a
href="https://doi.org/10.1007/s00521-024-10342-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Khan, Majid and Shah, Tariq},
  doi          = {10.1007/s00521-024-10342-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17751},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel image encryption technique based on hénon chaotic map and s8 symmetric group},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Retraction note: A copyright protection using watermarking
scheme based on nonlinear permutation and its quality metrics.
<em>NCA</em>, <em>36</em>(28), 17749. (<a
href="https://doi.org/10.1007/s00521-024-10338-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Khan, Majid and Shah, Tariq},
  doi          = {10.1007/s00521-024-10338-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17749},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A copyright protection using watermarking scheme based on nonlinear permutation and its quality metrics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Deep learning model for home automation and
energy reduction in a smart home environment platform. <em>NCA</em>,
<em>36</em>(28), 17747. (<a
href="https://doi.org/10.1007/s00521-024-10345-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Popa, Dan and Pop, Florin and Serbanescu, Cristina and Castiglione, Aniello},
  doi          = {10.1007/s00521-024-10345-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17747},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Deep learning model for home automation and energy reduction in a smart home environment platform},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Deployment of smart home management system
at the edge: Mechanisms and protocols. <em>NCA</em>, <em>36</em>(28),
17745. (<a href="https://doi.org/10.1007/s00521-024-10344-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Batalla, Jordi Mongay and Gonciarz, Franciszek},
  doi          = {10.1007/s00521-024-10344-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17745},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: deployment of smart home management system at the edge: mechanisms and protocols},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Construction of s-box based on chaotic
boolean functions and its application in image encryption. <em>NCA</em>,
<em>36</em>(28), 17743. (<a
href="https://doi.org/10.1007/s00521-024-10341-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Khan, Majid and Shah, Tariq and Batool, Syeda Iram},
  doi          = {10.1007/s00521-024-10341-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17743},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Construction of S-box based on chaotic boolean functions and its application in image encryption},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Tabu search-based classification for
eye-movement behavioral decisions. <em>NCA</em>, <em>36</em>(28), 17741.
(<a href="https://doi.org/10.1007/s00521-024-10340-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yin, Peng-Yeng and Day, Rong-Fuh and Wang, Yu-Chi},
  doi          = {10.1007/s00521-024-10340-w},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17741},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Tabu search-based classification for eye-movement behavioral decisions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Retraction note: An efficient chaotic image encryption
scheme. <em>NCA</em>, <em>36</em>(28), 17739. (<a
href="https://doi.org/10.1007/s00521-024-10337-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Khan, Majid and Shah, Tariq},
  doi          = {10.1007/s00521-024-10337-5},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17739},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An efficient chaotic image encryption scheme},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Diagnosis of the hypopnea syndrome in the
early stage. <em>NCA</em>, <em>36</em>(28), 17737. (<a
href="https://doi.org/10.1007/s00521-024-10335-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yang, Xiaodong and Fan, Dou and Ren, Aifeng and Zhao, Nan and Shah, Syed Aziz and Alomainy, Akram and Ur-Rehman, Masood and Abbasi, Qammer H.},
  doi          = {10.1007/s00521-024-10335-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17737},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Diagnosis of the hypopnea syndrome in the early stage},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CNN-based automatic detection of photovoltaic solar module
anomalies in infrared images: A comparative study. <em>NCA</em>,
<em>36</em>(28), 17715–17736. (<a
href="https://doi.org/10.1007/s00521-024-10322-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar energy is emerging as an environmentally friendly and sustainable energy source. However, with the widespread use of solar panels, how to manage these panels after their end-of-life becomes an important problem. It is known that heavy metals in solar modules can harm the environment and if not managed properly, it can cause great difficulties in waste management. Therefore, regular inspection, maintenance and waste management of solar modules are of great importance. The main objective of the study is to develop a Convolutional Neural Network (CNN) model to detect and classify failures in solar panels. By utilizing a large-scale IR image dataset obtained from real solar fields, the proposed CNN model is designed to effectively detect and classify various faults in photovoltaic (PV) modules. The dataset consists of 20,000 IR images including 12 different situations that occur under different conditions such as partial shading, short circuit, dust accumulation. The study addresses the issues of low-resolution and low-contrast images, class imbalance, and difficulty in tuning model parameters. The impact of resolving these issues on model performance is examined, with a focus on the effects of image preprocessing techniques like histogram equalization, data augmentation, and oversampling, as well as hyperparameter optimization methods such as Hyperband, Optuna, Successive Halving, and Bayesian Optimization. The results of the study show that the proposed model can predict an anomaly module with an average accuracy of 92% and correctly classify 12 anomaly types with an average accuracy of 82%.},
  archive      = {J_NCA},
  author       = {Sinap, Vahid and Kumtepe, Alihan},
  doi          = {10.1007/s00521-024-10322-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17715-17736},
  shortjournal = {Neural Comput. Appl.},
  title        = {CNN-based automatic detection of photovoltaic solar module anomalies in infrared images: A comparative study},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ISSL-AL: A deep active learning framework based on
self-supervised learning for image classification. <em>NCA</em>,
<em>36</em>(28), 17699–17713. (<a
href="https://doi.org/10.1007/s00521-024-10271-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have demonstrated exceptional performance across numerous applications. However, DNNs require large amounts of labeled data to avoid overfitting. Unfortunately, the labeled data may not be available; annotating large amounts of data is time-consuming, laborious, and requires human expertise, making it unfeasible to rely on manpower for annotation. One of the solutions to address this limitation is active learning (AL), a technique that utilizes unlabeled data while maintaining high performance. AL reduces the annotation cost of large datasets and enhances the training of models with fewer annotations. Uncertainty sampling has been proven to be one of the most effective strategies in AL; however, it lacks diversity. This research proposes iSSL-AL, a novel active learning framework that utilizes self-supervised learning (SSL) to ensure informative yet diverse samples. Three main aspects categorize the novelty of our work. The first is extending the margin uncertainty sampling by incorporating SSL to select informative and diverse points. The second is employing incremental learning for efficient training of the AL base classifier, where the model is trained incrementally in each AL cycle. The third is addressing the cold start problem, as our framework achieved high results in the early stages of training. Experiments show that iSSL-AL outperforms other state-of-the-art algorithms on the MNIST, FashionMNIST, and CIFAR-10 datasets, with accuracy scores of 99%, 98.9%, and 93.5%, respectively, effectively selecting diverse and informative samples.},
  archive      = {J_NCA},
  author       = {Agha, Rand and Mustafa, Ahmad M. and Abuein, Qusai},
  doi          = {10.1007/s00521-024-10271-6},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17699-17713},
  shortjournal = {Neural Comput. Appl.},
  title        = {ISSL-AL: A deep active learning framework based on self-supervised learning for image classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered adaptive control for
state-constrained strict-feedback nonlinear systems with guaranteed
feasibility conditions. <em>NCA</em>, <em>36</em>(28), 17689–17697. (<a
href="https://doi.org/10.1007/s00521-024-09925-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new dynamic event-triggered control solution is presented for state-constrained strict-feedback nonlinear systems. The current barrier Lyapunov function is required to assume or remove the feasibility conditions for virtual control signals. In this paper, a new scheme is proposed to guarantee the designed virtual control signals satisfy feasibility conditions. By introducing a dynamic variable into the event-triggered schedule, the dynamic event-triggered control scheme is established by using backstepping iterative design procedure. Moreover, the theoretical analysis illustrates that the proposed control solution can ensure the boundedness of all signals in SNS. Finally, simulation example is given to showcase the availability of the developed method.},
  archive      = {J_NCA},
  author       = {Liu, Yongchao and Zeng, Bowen and Wang, Haiyu},
  doi          = {10.1007/s00521-024-09925-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17689-17697},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic event-triggered adaptive control for state-constrained strict-feedback nonlinear systems with guaranteed feasibility conditions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced techniques for automated emotion recognition in
dogs from video data through deep learning. <em>NCA</em>,
<em>36</em>(28), 17669–17688. (<a
href="https://doi.org/10.1007/s00521-024-10042-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inter-species emotional relationships, particularly the symbiotic interaction between humans and dogs, are complex and intriguing. Humans and dogs share fundamental mammalian neural mechanisms including mirror neurons, crucial to empathy and social behavior. Mirror neurons are activated during the execution and observation of actions, indicating inherent connections in social dynamics across species despite variations in emotional expression. This study explores the feasibility of using deep-learning Artificial Intelligence systems to accurately recognize canine emotions in general environments, to assist individuals without specialized knowledge or skills in discerning dog behavior, particularly related to aggression or friendliness. Starting with identifying key challenges in classifying pleasant and unpleasant emotions in dogs, we tested advanced deep-learning techniques and aggregated results to distinguish potentially dangerous human--dog interactions. Knowledge transfer is used to fine-tune different networks, and results are compared on original and transformed sets of frames from the Dog Clips dataset to investigate whether DogFACS action codes detailing relevant dog movements can aid the emotion recognition task. Elaborating on challenges and biases, we emphasize the need for bias mitigation to optimize performance, including different image preprocessing strategies for noise mitigation in dog recognition (i.e., face bounding boxes, segmentation of the face or body, isolating the dog on a white background, blurring the original background). Systematic experimental results demonstrate the system’s capability to accurately detect emotions and effectively identify dangerous situations or signs of discomfort in the presence of humans.},
  archive      = {J_NCA},
  author       = {Franzoni, Valentina and Biondi, Giulio and Milani, Alfredo},
  doi          = {10.1007/s00521-024-10042-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17669-17688},
  shortjournal = {Neural Comput. Appl.},
  title        = {Advanced techniques for automated emotion recognition in dogs from video data through deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal wind speed forecasting with approximate
bayesian uncertainty quantification. <em>NCA</em>, <em>36</em>(28),
17645–17667. (<a
href="https://doi.org/10.1007/s00521-024-10054-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of short- and long-term wind speed has great utility for the industry, especially for wind energy generation. Deep neural networks can be used to tackle this task by modeling the spatio-temporal behavior of the wind. In this work, Bayesian spatio-temporal wind speed forecasts are performed based on measurements collected from wind turbine data acquisition systems and predictions from widely used global climate forecasting models. Moreover, the resulting predictions are complemented by the quantification of the corresponding uncertainty, extracted via approximate Bayesian inference techniques. Such uncertainty is a valuable information in practical scenarios, such as turbine maintenance. The proposed solution is evaluated using real data collected from a wind farm in the South of Brazil. Different combinations of models and approximations are compared based on the achieved metrics and graphs of uncertainty calibration. The conducted experiments indicate that the use of recurrent convolutional neural networks (ConvLSTM) with the Deep Ensembles strategy provides the best results in terms of predictive distribution, which has the potential of assisting maintenance and operation in wind farms. The final results can be viewed as a novel way for wind farm performance teams to extract Bayesian wind speed forecasts with spatial information.},
  archive      = {J_NCA},
  author       = {Neto, Airton F. Souza and Mattos, César L. C. and Gomes, João P. P.},
  doi          = {10.1007/s00521-024-10054-z},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17645-17667},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatio-temporal wind speed forecasting with approximate bayesian uncertainty quantification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Res-MGCA-SE: A lightweight convolutional neural network
based on vision transformer for medical image classification.
<em>NCA</em>, <em>36</em>(28), 17631–17644. (<a
href="https://doi.org/10.1007/s00521-024-10053-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a lightweight and accurate convolution neural network (CNN) based on encoder in vision transformer structure, which uses multigroup convolution rather than multilayer perceptron and multiheaded self-attention. We propose a group convolution block called multigroup convolution attention (MGCA) and squeeze and excitation (SE). The MGCA includes two parts: three 1 $$\times$$ 1 convolutions concatenated along the channel dimension and depth-wise separable convolution. SE is used as a skip connection to provide long-range dependencies. MGCA-SE is introduced to reduce the number of parameters in state-of-the-art network in order to use fewer datasets for training CNN. Furthermore, we provide a lightweight network based on MGCA-SE in Resnet architecture called Resnet-multigroup convolution attention-squeeze and excitation (Res-MGCA-SE) in order to have early detection and treatment of medical images. Finally, Res-MGCA-SE is evaluated on lung cancer and Covid-19 chest X-ray and CT and images. According to our research findings, MGCA-SE can change convolutional layers in state-of-the-art networks and switch them to lightweight networks with properties comparable to heavy-weight networks.},
  archive      = {J_NCA},
  author       = {Soleimani-Fard, Sina and Ko, Seok-bum},
  doi          = {10.1007/s00521-024-10053-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17631-17644},
  shortjournal = {Neural Comput. Appl.},
  title        = {Res-MGCA-SE: A lightweight convolutional neural network based on vision transformer for medical image classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ant colony optimization for solving directed chinese postman
problem. <em>NCA</em>, <em>36</em>(28), 17615–17630. (<a
href="https://doi.org/10.1007/s00521-024-10052-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Chinese Postman Problem (CPP) is a well-known optimization problem involving determining the shortest route, modeling the system as an undirected graph, for delivering mail, ensuring all roads are traversed while returning to the post office. The Directed Chinese Postman Problem (DCPP) extends the Chinese Postman Problem (CPP), where the underlying graph representing the system incorporates exclusively directed edges. Similarly to CPP, this problem has plenty of applications in route optimization, interactive system analysis, and circuit design problems. However, due to the added constraint (directionality of edges), DCPP results are more challenging to solve. Although methods to solve it in literature are proposed, typically by using minimum-cost-flow algorithms, the meta-heuristics approaches proposed to deal with it are very limited. In this paper, we propose an innovative meta-heuristic approach to solve DCPP by using an ant colony optimization (ACO) algorithm, i.e., an algorithm that simulates in a simplified way the behavior of some species of ants to solve optimization problems. The efficiency of our ant colony optimization for solving the Directed Chinese Postman Problem (ACO-DCPP) is measured by comparing the ACO outcomes with the results obtained by a recursive algorithm that explores all the possible solutions. Results show that ACO-DCPP is stable and gets the global optimum frequently by using an extremely limited number of solutions explored.},
  archive      = {J_NCA},
  author       = {Sgarro, Giacinto Angelo and Santoro, Domenico and Grilli, Luca},
  doi          = {10.1007/s00521-024-10052-1},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17615-17630},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ant colony optimization for solving directed chinese postman problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new feature selection algorithm based on fuzzy-pathfinder
optimization. <em>NCA</em>, <em>36</em>(28), 17585–17614. (<a
href="https://doi.org/10.1007/s00521-024-10043-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining and machine learning require feature selection because features can dramatically improve model performance. In contrast, there are no polynomial solutions for selecting a subset feature. It is possible to achieve this by using meta-heuristic algorithms, specifically population-based algorithms that are able to provide a subset of features that is optimal and not exact. Meta-heuristic algorithms face challenges such as staying in local minima, easily falling into local optimum, weakly global searchability, premature convergence, and slow convergence speeds. However, recent research has limitations such as high complexity and weak initialization. In order to overcome these limitations, a three-stage model is proposed. In the first stage, the correlation of features and the correlation of features with class are considered during feature selection and used to create the initial population in the pathfinder optimization algorithm (PFA). PFA is a population-based algorithm and has some drawbacks, in the last iterations, the fluctuation rate (A) and vibration vector (ε) parameters converge to 0, and finding a new solution is impossible. As a second stage, a fuzzy inference system is designed to adjust these parameters adaptively and is called fuzzy-pathfinder optimization (FPO). In the third stage, FPO is used to select relevant features based on classification error, proportion of selected features, and redundancy. Finally, different algorithms such as simulated annealing (SA), differential evolutionary (DE), genetic algorithm (GA), particle swarm optimization (PSO), PFA, estimation of distribution algorithm (EDA), and symmetrical uncertainty criterion (SUC-PSO) are used for comparison. Based on the results, the proposed model is able to reach an average accuracy of 96% on average. Based on a comparison of the proposed algorithm with SA, DE, GA, PSO, PFA, EDA, and SUC-PSO, the objective function is improved by 17.3%, 5.6%, 3.0%, 4.5%, 5.0%, 0.5%, and 1.2%, respectively. The use of comprehensive objective functions, the adaptive adjustment of parameters, and the creation of a targeted initial population are key strengths of FPO.},
  archive      = {J_NCA},
  author       = {Zandvakili, Aboozar and Mansouri, Najme and Javidi, Mohammad Masoud},
  doi          = {10.1007/s00521-024-10043-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17585-17614},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new feature selection algorithm based on fuzzy-pathfinder optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for ultrasound medical images: Artificial life
variant. <em>NCA</em>, <em>36</em>(28), 17559–17584. (<a
href="https://doi.org/10.1007/s00521-024-09910-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of tumors in the ultrasound (US) images of the breast is a critical problem in medical imaging. Due to the poor quality of the US images and varying specifications of the US machines, the segmentation and classification of the abnormalities present difficulties even for trained radiologists. Nevertheless, the US remains one of the most reliable and inexpensive tests. Recently, an artificial life (ALife) model based on tracing agents and fusion of the US and the elasticity images (F-ALife) has been proposed and analyzed. Under certain conditions, F-ALife outperforms state-of-the-art including the selected deep learning (DL) models, deformable models, machine learning, contour grouping and superpixels. Apart from the improved accuracy, F-ALife requires smaller training sets. The strongest competitors of the F-ALife are hybrids of the DL with conventional models. However, the current DL methods require a large amount of data (thousands of annotated images), which often is not available. Moreover, the hybrids require that the conventional model is properly integrated into the DL. Therefore, we offer a new DL-based hybrid with ALife. It is characterized by a high accuracy, requires a relatively small dataset, and is capable of handling previously unseen data. The new ideas include (1) a special image mask to guide ALife. The mask is generated using DL and the distance transform, (2) modification of ALife for segmentation of the US images providing a high accuracy. (These ideas are motivated by the “vehicles” of Braitenberg (Vehicles, experiments in synthetic psychology, MIT Press, Cambridge, 1984) and ALife proposed in Karunanayake et al. (Pattern Recognit 108838, 2022), (3) a two-level genetic algorithm which includes training by an individual image and by the entire set of images. The training employs an original categorization of the images based on the properties of the edge maps. The efficiency of the algorithm is demonstrated on complex tumors. The method combines the strengths of the DL neural networks with the speed and interpretability of ALife. The tests based on the characteristics of the edge map and complexity of the tumor shape show the advantages of the proposed DL-ALife. The model outperforms 14 state-of-the-art algorithms applied to the US images characterized by a complex geometry. Finally, the novel classification allows us to test and analyze the limitations of the DL for the processing of the unseen data. The code is applicable to breast cancer diagnostics (Automated Breast Ultra Sound), US-guided biopsies as well as to  projects related to automatic breast scanners. A video demo is at https://tinyurl.com/3xthedff .},
  archive      = {J_NCA},
  author       = {Karunanayake, Nalan and Makhanov, Stanislav S.},
  doi          = {10.1007/s00521-024-09910-9},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17559-17584},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning for ultrasound medical images: Artificial life variant},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving incentive policies to salespeople cross-sells: A
cost-sensitive uplift modeling approach. <em>NCA</em>, <em>36</em>(28),
17541–17558. (<a
href="https://doi.org/10.1007/s00521-024-10051-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a novel cost-sensitive approach for uplift modeling in the context of cross-selling and workforce analytics. We leverage referrals from sales agents across business units to estimate the individual treatment effects of incentives on the cross-selling outcomes within a company. Uplift modeling is employed to predict relationships between salespeople that should be encouraged based on the probability of successful cross-selling - defined when a customer accepts the product suggested by sales agents. We conducted experiments on data from a Chilean financial group, evaluating both statistical and profit metrics. Exploring various machine learning classifiers for predictive purposes, we observed a significant improvement over the current approach, which exhibits an uplift below 0.01. Finally, we show that selecting the best classifier with profit metrics results in a 31.6% improvement in terms of average customer profit. This emphasizes the importance of defining an adequate compensation scheme and integrating it into the modeling process.},
  archive      = {J_NCA},
  author       = {Vairetti, Carla and Vargas, Raimundo and Sánchez, Catalina and García, Andrés and Armelini, Guillermo and Maldonado, Sebastián},
  doi          = {10.1007/s00521-024-10051-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17541-17558},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving incentive policies to salespeople cross-sells: A cost-sensitive uplift modeling approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid physics-infused 1D-CNN based deep learning framework
for diesel engine fault diagnostics. <em>NCA</em>, <em>36</em>(28),
17511–17539. (<a
href="https://doi.org/10.1007/s00521-024-10055-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is required to ensure the safe operation of various equipment and enables real-time monitoring of associated components. As a result, the demand for new cognitive fault diagnosis algorithms is the need of the hour. Existing deep learning algorithms can detect faults but do not incorporate the system’s underlying physics into the prediction and model training processes. Therefore, the results generated by this class of fault-detecting algorithms sometimes do not make sense and fail to deliver when put to the test in actual operating conditions. We propose an end-to-end, autonomous hybrid physics-infused deep learning framework that consists of a low-fidelity physics model combined with a 1 Dimensional Convolutional Neural Network (1D CNN) to address the aforementioned issues. The application system under consideration is a 6-cylinder, 4-stroke, 7.6 L Navistar diesel engine. The physics model in the hybrid framework ensures that the predictions made by the framework are in coherence with the actual dynamics of the engine. In contrast, the deep learning component of the hybrid framework makes up for the simplifications involved during the development of the physics model of the engine, where the 1D CNN module enables robust Spatiotemporal feature extraction. Using empirical results, we demonstrate that our proposed hybrid fault diagnostics framework is autonomous and efficient for fault detection and isolation. The robustness of this framework is put to the test against the data obtained by the engine when subjected to different operating conditions, such as varying speed, changing injection pressure, and injection duration.},
  archive      = {J_NCA},
  author       = {Singh, Shubhendu Kumar and Khawale, Raj Pradip and Hazarika, Subhashis and Bhatt, Ankur and Gainey, Brian and Lawler, Benjamin and Rai, Rahul},
  doi          = {10.1007/s00521-024-10055-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17511-17539},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid physics-infused 1D-CNN based deep learning framework for diesel engine fault diagnostics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UAV remote sensing detection and target recognition based on
SCP-YOLO. <em>NCA</em>, <em>36</em>(28), 17495–17510. (<a
href="https://doi.org/10.1007/s00521-024-09938-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying small, overlapping wheat ears in UAV images continues to be a difficult task. This paper proposes SCP-YOLO, a novel detection model that addresses this limitation. Initially, the dataset comprises remote sensing images of wheat kernels captured at two periods and three altitudes. Using the YOLOv8n network as a baseline, SCP-YOLO processes the network’s low-resolution feature layer using the space-to-depth (SPD) approach. At the stage of feature fusion, the Context-Aggregation structure is executed to facilitate the aggregation and interaction of data on the feature map on a global scale. The PConv method ingeniously implements the lightweight detection head structure. On top of that, a new detection scale that integrates more superficial information with location data is positioned. The experimental outcomes demonstrate that the proposed method outperformed several established state-of-the-art detection models by achieving a detection speed of 90 frames per second and an AP@50 value of 96.3%. Compared with the baseline network, the AP@0.5, and AP@0.5:95 exhibited respective increases of 2.5% and 6.3%, respectively. Experimental results indicate that the methodology demonstrates exceptional robustness for six scenario datasets. About counting, it is exact and capable of quantifying wheat ears in images acquired through remote sensing.},
  archive      = {J_NCA},
  author       = {Wang, Lihui and Miao, Zhan and Liu, Endong},
  doi          = {10.1007/s00521-024-09938-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17495-17510},
  shortjournal = {Neural Comput. Appl.},
  title        = {UAV remote sensing detection and target recognition based on SCP-YOLO},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning framework for automatic detection and
classification of sleep apnea severity from polysomnography signals.
<em>NCA</em>, <em>36</em>(28), 17483–17493. (<a
href="https://doi.org/10.1007/s00521-024-09889-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep apnea (SA) is a sleep-related breathing disorder characterized by breathing pauses during sleep. A person’s sleep schedule is significantly influenced by that person’s hectic lifestyle, which may include unhealthy eating habits and their line of work. Polysomnographic (PSG) sleep studies examine sleep-related disorders by recording various biosignals from the human body. However, SA classification methods could be more robust in terms of performance because they rely on feature-engineering strategies or employ a particular signal from PSG recording for diagnosis. This study aims to classify the severity of SA according to the apnea–hypopnea index (AHI) into normal, mild, and moderate-to-severe groups using oxygen saturation (SpO2), electroencephalogram (EEG), and electrocardiogram (ECG) signals. The proposed deep neural network (DNN)-bidirectional long short-term memory (DNN-BiLSTM) framework addresses the issue of low detection accuracy in analysis. The DNN-BiLSTM approach employs features extracted from a multiscale dilation attention 1D convolutional neural network (MSDA-1DCNN) as input for detection and classification purposes. The MSDA-1DCNN network extracts deep features from processed SpO2, EEG, and ECG signals. The developed firefly combined electric fish optimization (FCEFO) algorithm improves performance by optimizing the hidden neuron count of the DNN and the learning rate of the BiLSTM framework. The performance measures proved the effectiveness of the model over conventional machine and deep learning approaches. With the integration of deep features, the proposed DNN-BiLSTM model provides enhanced performance in terms of accuracy and precision. Thus, the proposed approach is progressive and can be used for medical diagnosis.},
  archive      = {J_NCA},
  author       = {Raja Brundha, A. and Lakshmi Sangeetha, A. and Balajiganesh, A.},
  doi          = {10.1007/s00521-024-09889-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17483-17493},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning framework for automatic detection and classification of sleep apnea severity from polysomnography signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural network-based secure healthcare framework.
<em>NCA</em>, <em>36</em>(28), 17467–17482. (<a
href="https://doi.org/10.1007/s00521-024-10039-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare stands out as a critical domain profoundly impacted by Internet of Things (IoT) technology, generating vast data from sensing devices as IoT applications expand. Addressing security challenges is paramount for a successful IoT healthcare framework, with blockchain technology offering a decentralized structure for robust data protection and secure data exchange within multi-node IoT networks. The research introduces a secure IoT healthcare diagnostic model empowered by deep neural networks, emphasizing encryption, safe transactions, and healthcare diagnostics as key components. Notably, the model incorporates innovative techniques like the orthogonal particle swarm optimization algorithm for sharing medical images and a neighborhood indexing sequence method for hash value encryption. The development of an optimized deep neural network-based classification model for illnesses, validated through extensive trials, demonstrates superior performance metrics compared to existing decision-making techniques, with significant improvements in f-Measure (96.25%), sensitivity (93.26%), specificity (94.26%), and accuracy (93.26%). This study’s scientific contribution lies in its innovative approach to securing IoT-healthcare diagnosis models, validated performance enhancements using real-world datasets, and insightful recommendations for future research directions, fostering advancements in healthcare technology for enhanced patient care and system efficiency.},
  archive      = {J_NCA},
  author       = {Aldaej, Abdulaziz and Ahanger, Tariq Ahamed and Ullah, Imdad},
  doi          = {10.1007/s00521-024-10039-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17467-17482},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep neural network-based secure healthcare framework},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Kids learning optimizer: Social evolution and cognitive
learning-based optimization algorithm. <em>NCA</em>, <em>36</em>(28),
17417–17465. (<a
href="https://doi.org/10.1007/s00521-024-10009-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel social cognitive learning-based metaheuristic called kids Learning Optimizer (KLO), inspired by the early social learning behavior of kids organized as families in societal setup. In a society, people are organized as family groups (parents and children) where they interact with each other within and outside their family. This interaction plays a vital role in early brain development, mannerisms, and behavioral learning. Early childhood learning is affected by various stimuli in their surroundings at different stages of life (newborn, infant, toddler, pre-school). This idea motivated us to map the decentralized learning concept of families and their interactions into a new algorithm where search agents (individuals) are arranged/organized in families, and they interact with each other at different stages of life to find the optimal solution. The algorithm is tested against 116 challenging benchmark functions including 31 unimodal, 63 multimodal, 14 CEC&#39;2017 functions, and eight constrained functions. The algorithm is compared with 10 state-of-the-art algorithms. Friedman’s Mean Rank (FMR) and Wilcoxon rank-sum test (WRS) are used to measure the performance of competing algorithms. In the first two experiments, unimodal and multimodal benchmark functions are used to measure the explorative and exploitative ability of the algorithm. FMR and WRS show KLO outperformed all other algorithms. In the third experiment, the proposed method is tested against 14 CEC&#39;2017 functions and eight constrained functions along with three real life mechanical engineering optimization problems. KLO proved to be better or equivalent to other competing algorithms.},
  archive      = {J_NCA},
  author       = {Javed, Sobia Tariq and Zafar, Kashif and Younas, Irfan},
  doi          = {10.1007/s00521-024-10009-4},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17417-17465},
  shortjournal = {Neural Comput. Appl.},
  title        = {Kids learning optimizer: Social evolution and cognitive learning-based optimization algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive neuro-fuzzy sliding mode control of the human upper
limb during manual wheelchair propulsion: Estimation of continuous joint
movements using synergy-based extended kalman filter. <em>NCA</em>,
<em>36</em>(28), 17375–17416. (<a
href="https://doi.org/10.1007/s00521-024-10001-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheelchair upper limb exoskeletons can present a revolutionary approach to aid individuals with neuromuscular disorders in their daily tasks, which require two primary factors, i.e., estimating the human intention to decrease human–robot interactions and generating the adaptive optimal control signals. Therefore, firstly, this study aimed to propose an adaptive neuro-fuzzy sliding mode controller to generate the optimal control signals, in which and an adaptive optimal multi-critic-based neuro-fuzzy system was designed to tune the control gains of the sliding mode controller according to the changes in the joint torques and tracking errors. Secondly, a neural network model was designed as a measurement function in the structure of an extended Kalman filter to infer the human’s continuous movement intention, which was trained to establish a comprehensive relationship between inputs, i.e., joints’ kinematics and pushrim force, and outputs, i.e., electromyography features. Data acquisition relied on Biometrics Ltd.’s DataLink software and hardware, including surface electromyography and electrogoniometer sensors, while a force sensor system was designed for pushrim force acquisition. The features were extracted using the nonnegative matrix factorization method. The results of the proposed controller were compared with two of the newest control strategies for position-tracking in the wheelchair upper limb exoskeleton robotic system, i.e., proportional derivative-based fuzzy sliding mode control and a fuzzy-based nonsingular terminal sliding mode control structures, which both used the sliding mode control approach with different proposed sliding surfaces to generate the required control signals and also used the neuro-fuzzy system to improve the performance. For the proposed measurement model, the results were compared with the linear regression model and the adaptive neuro-fuzzy inference system, which are two of the most used classification methods. The results affirmed the efficacy of the proposed controller as a robust and accurate control structure for trajectory tracking, both in the absence and presence of disturbance, thereby underscoring its potential for practical applications in manual wheelchair propulsion. Furthermore, the findings underscored the proposed measurement model’s robustness and adaptability, making it a promising tool for estimating continuous joint movements in rehabilitation and assistive applications.},
  archive      = {J_NCA},
  author       = {Rusta, Mohammad Mahdi and Haghpanah, Seyyed Arash and Taghvaei, Sajjad and Vatankhah, Ramin},
  doi          = {10.1007/s00521-024-10001-y},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17375-17416},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive neuro-fuzzy sliding mode control of the human upper limb during manual wheelchair propulsion: Estimation of continuous joint movements using synergy-based extended kalman filter},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MOAAA/d: A decomposition-based novel algorithm and a
structural design application. <em>NCA</em>, <em>36</em>(28),
17345–17374. (<a
href="https://doi.org/10.1007/s00521-024-09746-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When real-world engineering challenges are examined adequately, it becomes clear that multi-objective need to be optimized. Many engineering problems have been handled utilizing the decomposition-based optimization approach according to the literature. The performance of multi-objective evolutionary algorithms is highly dependent on the balance of convergence and diversity. Diversity and convergence are not appropriately balanced in the decomposition technique, as they are in many approaches, for real-world problems. A novel Multi-Objective Artificial Algae Algorithm based on Decomposition (MOAAA/D) is proposed in the paper to solve multi-objective structural problems. MOAAA/D is the first multi-objective algorithm that uses the decomposition-based method with the artificial algae algorithm. MOAAA/D, which successfully draws a graph on 24 benchmark functions within the area of two common metrics, also produced promising results in the structural design problem to which it was applied. To facilitate the design of the &quot;rectangular reinforced concrete column&quot; using MOAAA/D, a solution space was derived by optimizing the rebar ratio and the concrete quantity to be employed.},
  archive      = {J_NCA},
  author       = {Altiok, Mustafa and Gündüz, Mesut},
  doi          = {10.1007/s00521-024-09746-3},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17345-17374},
  shortjournal = {Neural Comput. Appl.},
  title        = {MOAAA/D: A decomposition-based novel algorithm and a structural design application},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gene selection based on recursive spider wasp optimizer
guided by marine predators algorithm. <em>NCA</em>, <em>36</em>(28),
17327–17344. (<a
href="https://doi.org/10.1007/s00521-024-09965-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting tumors using gene analysis in microarray data is a critical area of research in artificial intelligence and bioinformatics. However, due to the large number of genes compared to observations, feature selection is a central process in microarray analysis. While various gene selection methods have been developed to select the most relevant genes, these methods’ efficiency and reliability can be improved. This paper proposes a new two-phase gene selection method that combines the ReliefF filter method with a novel version of the spider wasp optimizer (SWO) called RSWO-MPA. In the first phase, the ReliefF filter method is utilized to reduce the number of genes to a reasonable number. In the second phase, RSWO-MPA applies a recursive spider wasp optimizer guided by the marine predators algorithm (MPA) to select the most informative genes from the previously selected ones. The MPA is used in the initialization step of recursive SWO to narrow down the search space to the most relevant and accurate genes. The proposed RSWO-MPA has been implemented and validated through extensive experimentation using eight microarray gene expression datasets. The enhanced RSWO-MPA is compared with seven widely used and recently developed meta-heuristic algorithms, including Kepler optimization algorithm (KOA), marine predators algorithm (MPA), social ski-driver optimization (SSD), whale optimization algorithm (WOA), Harris hawks optimization (HHO), artificial bee colony (ABC) algorithm, and original SWO. The experimental results demonstrate that the developed method yields the highest accuracy, selects fewer features, and exhibits more stability than other compared algorithms and cutting-edge methods for all the datasets used. Specifically, it achieved an accuracy of 100.00%, 94.51%, 98.13%, 95.63%, 100.00%, 100.00%, 92.97%, and 100.00% for Yeoh, West, Chiaretti, Burcyznski, leukemia, ovarian cancer, central nervous system, and SRBCT datasets, respectively.},
  archive      = {J_NCA},
  author       = {Osama, Sarah and Ali, Abdelmgeid A. and Shaban, Hassan},
  doi          = {10.1007/s00521-024-09965-8},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17327-17344},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gene selection based on recursive spider wasp optimizer guided by marine predators algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DATE: A video dataset and benchmark for dynamic hand gesture
recognition. <em>NCA</em>, <em>36</em>(28), 17311–17325. (<a
href="https://doi.org/10.1007/s00521-024-09990-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new Dynamic hAnd gesTurE (DATE) dataset for dynamic hand gestures. The DATE dataset contains 13,500 videos of 22 different subjects. The subjects wear different clothes, have different backgrounds, and are filmed from various camera angles. Two different benchmarks for our self-built DATE dataset are also proposed. The first one is the high accuracy approach, while the second benchmark is the lightweight approach. The operation of our benchmarks has two phases. In the first phase, videos are preprocessed with detection or segmentation tasks. Then, the processed data are classified by customized cutting-edge deep learning models in the second phase. Experimental results showed that our benchmarks obtained high accuracies in both the self-build dataset and a publicly recognized dataset.},
  archive      = {J_NCA},
  author       = {Dang, Tuan Linh and Pham, Trung Hieu and Dao, Duc Manh and Nguyen, Hoang Vu and Dang, Quang Minh and Nguyen, Ba Tuan and Monet, Nicolas},
  doi          = {10.1007/s00521-024-09990-7},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17311-17325},
  shortjournal = {Neural Comput. Appl.},
  title        = {DATE: A video dataset and benchmark for dynamic hand gesture recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EnParaNet: A novel deep learning architecture for faster
prediction using low-computational resource devices. <em>NCA</em>,
<em>36</em>(28), 17285–17309. (<a
href="https://doi.org/10.1007/s00521-024-09933-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of deep learning architectures on low-computational resource devices is challenging due to their high number of parameters and computational complexity. These heavy and complex architectures result in increased latency in real-time applications. However, splitting the deep architecture in a way that parallelizes the forward propagation into different subnets deploying into multiple low-computational resource devices, and then, aggregating the predictions may reduce the latency while preserving the performance. In this paper, we propose a novel deep learning architecture called Ensembled Parallel Networks (EnParaNets) that leverage network dissection, knowledge distillation, and ensemble learning strategies to reduce inference time while maintaining, even in some cases, outperforming the baseline accuracy in real-time applications. The methodology involves splitting the original network into N equal-sized blocks, forming N Sub-ParaNets for each block, and enhancing their representations using (A) contrastive knowledge distillation along with reducing Kullback–Leibler divergence between logits distributions of the teacher and student networks, and (B) L2 loss between intermediate representations of the original network and corresponding Sub-ParaNets. Predictive distributions from each Sub-ParaNet are assembled to form the final EnParaNet. The proposed EnParaNet outperforms the baseline models of seven diverse architectures: ResNet56, VGG_13, WRN_40_2, DenseNet, ResNeXt50, MobileNetv2, and ShuffleNetv2 in terms of accuracy while reducing inference time significantly using training methods A and B, respectively. Our proposed EnParaNet enhances ResNet56, VGG_13, WRN_40_2, MobileNetv2, DenseNet, ResNeXt50, and ShuffleNetv2 by 2.69%, 0.24%, 1.95%, 7.69%, 0.33%, 2.13%, and 3.12%, respectively, using training method A, where the inference time is reduced by 45%, 24%, 47%, 31%, 33%, 32%, and 44%, respectively. With training method B, EnParaNet achieves improvements of 1.75%, 2.90%, 1.09%, 3.91%, and 1.66%, with inference time reductions of 50%, 42%, 49%, 48%, and 49%, respectively. Moreover, a comprehensive ablation study analyzes the performance of the proposed technique and highlights its effectiveness and challenges. Furthermore, we also evaluate the performance of EnParaNet in transferability and adversarial robustness tasks.},
  archive      = {J_NCA},
  author       = {Akhter, Sharmen and Hossain, Md. Imtiaz and Hossain, Md. Delowar and Hong, Choong Seon and Huh, Eui-Nam},
  doi          = {10.1007/s00521-024-09933-2},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17285-17309},
  shortjournal = {Neural Comput. Appl.},
  title        = {EnParaNet: A novel deep learning architecture for faster prediction using low-computational resource devices},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BIDGCN: Boundary-informed dynamic graph convolutional
network for adaptive spline fitting of scattered data. <em>NCA</em>,
<em>36</em>(28), 17261–17284. (<a
href="https://doi.org/10.1007/s00521-024-09997-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface reconstruction from scattered point clouds is the process of generating surfaces from unstructured data configurations retrieved using an acquisition device such as a laser scanner. Smooth surfaces are possible with the use of spline representations, an established mathematical tool in computer-aided design and related application areas. One key step in the surface reconstruction process is the parameterization of the points, that is, the construction of a proper mapping of the 3D point cloud to a planar domain that preserves surface boundary and interior points. Despite achieving a remarkable progress, existing heuristics for generating a suitable parameterization face challenges related to the accuracy, the robustness with respect to noise, and the computational efficiency of the results. In this work, we propose a boundary-informed dynamic graph convolutional network (BIDGCN) characterized by a novel boundary-informed input layer, with special focus on applications related to adaptive spline approximation of scattered data. The newly introduced layer propagates given boundary information to the interior of the point cloud, in order to let the input data be suitably processed by successive graph convolutional network layers. We apply our BIDGCN model to the problem of parameterizing three-dimensional unstructured data sets over a planar domain. A selection of numerical examples shows the effectiveness of the proposed approach for adaptive spline fitting with (truncated) hierarchical B-spline constructions. In our experiments, improved accuracy is obtained, e.g., from 60% up to 80% for noisy data, while speedups ranging from 4 up to 180 times are observed with respect to classical algorithms. Moreover, our method automatically predicts the local neighborhood graph, leading to much more robust results without the need for delicate free parameter selection.},
  archive      = {J_NCA},
  author       = {Giannelli, Carlotta and Imperatore, Sofia and Mantzaflaris, Angelos and Scholz, Felix},
  doi          = {10.1007/s00521-024-09997-0},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17261-17284},
  shortjournal = {Neural Comput. Appl.},
  title        = {BIDGCN: Boundary-informed dynamic graph convolutional network for adaptive spline fitting of scattered data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Swinv2-imagen: Hierarchical vision transformer diffusion
models for text-to-image generation. <em>NCA</em>, <em>36</em>(28),
17245–17260. (<a
href="https://doi.org/10.1007/s00521-023-09021-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, diffusion models have been proven to perform remarkably well in text-to-image synthesis tasks in a number of studies, immediately presenting new study opportunities for image generation. Google’s Imagen follows this research trend and outperforms DALLE2 as the best model for text-to-image generation. However, Imagen merely uses a T5 language model for text processing, which cannot ensure learning the semantic information of the text. Furthermore, the Efficient UNet leveraged by Imagen is not the best choice in image processing. To address these issues, we propose the Swinv2-Imagen, a novel text-to-image diffusion model based on a Hierarchical Visual Transformer and a Scene Graph incorporating a semantic layout. In the proposed model, the feature vectors of entities and relationships are extracted and involved in the diffusion model, effectively improving the quality of generated images. On top of that, we also introduce a Swin-Transformer-based UNet architecture, called Swinv2-Unet, which can address the problems stemming from the CNN convolution operations. Extensive experiments are conducted to evaluate the performance of the proposed model by using three real-world datasets, i.e. MSCOCO, CUB and MM-CelebA-HQ. The experimental results show that the proposed Swinv2-Imagen model outperforms several popular state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Li, Ruijun and Li, Weihua and Yang, Yi and Wei, Hanyu and Jiang, Jianhua and Bai, Quan},
  doi          = {10.1007/s00521-023-09021-x},
  journal      = {Neural Computing and Applications},
  month        = {10},
  number       = {28},
  pages        = {17245-17260},
  shortjournal = {Neural Comput. Appl.},
  title        = {Swinv2-imagen: Hierarchical vision transformer diffusion models for text-to-image generation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise reduction deep CNN-based retinal fundus image
enhancement using recursive histogram. <em>NCA</em>, <em>36</em>(27),
17221–17243. (<a
href="https://doi.org/10.1007/s00521-024-09996-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal imaging often falls short in image quality due to limitations in imaging conditions. Issues such as low contrast and inadequate brightness are frequently encountered. However, fundus pictures play a crucial role in diagnosing various retinal diseases within the field of ophthalmology. Nonetheless, specific ocular abnormalities and capturing environments result in low-grade fundus images, hampering the diagnostic abilities of both human experts and machines. Analyzing color fundus images to detect retinal abnormalities necessitates enhanced representation of image properties, including contrast, illumination, and precise edge points. The proposed method introduces a new technique for improving color fundus photos. The algorithm comprises three stages. Firstly, a feed-forward denoising convolutional neural network (DnCNN) removes noise. Subsequently, a contrast enhancement method, recursive separated weighted histogram equalization (RSWHE), addresses low contrast issues. Finally, adaptive Gamma correction (AGC) improves uneven luminosity. Experiments were conducted using the STARE benchmark datasets to evaluate the algorithm. The suggested algorithm’s output is equated against state-of-the-art enhancement methods. Objective validation was performed using performance parameters such as NIQE, PCQI, CEIQ, MEME, and PSNR. It suggests that the algorithm has the potential to serve as an efficient method for enhancing retinal images, thereby improving diagnostic capabilities in the field of ophthalmology.},
  archive      = {J_NCA},
  author       = {Kumar, Ravi and Bhandari, Ashish Kumar},
  doi          = {10.1007/s00521-024-09996-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17221-17243},
  shortjournal = {Neural Comput. Appl.},
  title        = {Noise reduction deep CNN-based retinal fundus image enhancement using recursive histogram},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AutYOLO-ATT: An attention-based YOLOv8 algorithm for early
autism diagnosis through facial expression recognition. <em>NCA</em>,
<em>36</em>(27), 17199–17219. (<a
href="https://doi.org/10.1007/s00521-024-09966-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is a developmental condition resulting from abnormalities in brain structure and function, which can manifest as communication and social interaction difficulties. Conventional methods for diagnosing ASD may not be effective in the early stages of the disorder. Hence, early diagnosis is crucial to improving the patient&#39;s overall health and well-being. One alternative and effective method for early autism diagnosis is facial expression recognition since autistic children typically exhibit distinct facial expressions that can aid in distinguishing them from other children. This paper provides a deep convolutional neural network (DCNN)-based real-time emotion recognition system for autistic kids. The proposed system is designed to identify six facial emotions, including surprise, delight, sadness, fear, joy, and natural, and to assist medical professionals and families in recognizing facial expressions in autistic children for early diagnosis and intervention. In this study, an attention-based YOLOv8 (AutYOLO-ATT) algorithm for facial expression recognition is proposed, which enhances the YOLOv8 model&#39;s performance by integrating an attention mechanism. The proposed method (AutYOLO-ATT) outperforms all other classifiers in all metrics, achieving a precision of 93.97%, recall of 97.5%, F1-score of 92.99%, and accuracy of 97.2%. These results highlight the potential of the proposed method for real-world applications, particularly in fields where high accuracy is essential.},
  archive      = {J_NCA},
  author       = {Hosney, Reham and Talaat, Fatma M. and El-Gendy, Eman M. and Saafan, Mahmoud M.},
  doi          = {10.1007/s00521-024-09966-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17199-17219},
  shortjournal = {Neural Comput. Appl.},
  title        = {AutYOLO-ATT: An attention-based YOLOv8 algorithm for early autism diagnosis through facial expression recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A learning artificial visual system for motion direction
detection. <em>NCA</em>, <em>36</em>(27), 17181–17197. (<a
href="https://doi.org/10.1007/s00521-024-09921-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on the visual system and its development is not only crucial for understanding how we see and interpret the environment from basic visual processing to complex perception but also aids in the development of technologies like virtual reality, augmented reality, and computer vision. In our previous paper, we have proposed a novel biological motion direction detection mechanism. Based on this mechanism, the authors of this paper proposed a learning artificial visual system (AVS) and use it to achieve motion direction detection. The learning AVS consists of two layers: the local visual feature detective neuron layer and the global feature detective neuron layer. For local motion direction detection, we use dendritic neurons to implement local motion direction-detective neurons and use them to extract local motion direction information. Global feature detective neurons are simply implemented by summing the local motion direction-detective neurons in each direction of possible motion. We trained the learning AVS by eliminating unnecessary branches or synapses and keeping only those that are strongly connected to the function of motion direction detection. Computer simulations demonstrate that AVS can learn the correct motion direction of objects with different shapes, size and positions. We compare the performance of AVS with support vector machine (SVM) and traditional convolutional neural networks (CNNs)—LeNet-5 and EfficientNet-B0 (EfN)—in motion direction detection and find that our learning AVS has better recognition accuracy, noise immunity and less demands on size of dataset and learning costs.},
  archive      = {J_NCA},
  author       = {Chen, Tianqi and Kobayashi, Yuki and Todo, Yuki and Tang, Zheng},
  doi          = {10.1007/s00521-024-09921-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17181-17197},
  shortjournal = {Neural Comput. Appl.},
  title        = {A learning artificial visual system for motion direction detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-attention-based deep architecture for online
handwriting recognition. <em>NCA</em>, <em>36</em>(27), 17165–17179. (<a
href="https://doi.org/10.1007/s00521-024-10015-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-attention mechanism has been the most frequent and efficient way for processing and learning sequences in numerous domains of artificial intelligence, including natural language processing, automatic speech recognition, and computer vision in recent years. It has a strong ability to learn the dependencies between the points of the input sequence, particularly those that are separated by a distance, and it also allows for parallel processing of the sequence. As a result, when used in processing sequences, this mechanism has a stronger ability to extract an appropriate representation from the input sequence at a faster rate than other approaches such as recurrent neural networks. Despite the benefits of the self-attention mechanism, recurrent neural networks along with feature engineering have been the most commonly employed approaches to online handwriting recognition. This study introduces an end-to-end online handwriting recognition system that utilizes the self-attention mechanism into three different modeling methods: CTC-based, RNN-T, and encoder–decoder. The proposed system demonstrates the capacity to recognize handwritten scripts without the need for feature engineering. The system’s performance was evaluated using the Arabic Online-KHATT dataset and the English IAM-OnDB dataset. On the former, it achieved character error rate (CER) of 4.78% and word error rate (WER) of 20.63%, and on the latter, the CER of 4.10% and the WER of 14.31%, both of which were noticeably better than the results previously reported. Additionally, the Persian Online Handwriting Database was utilized for experimental validation, resulting in a CER 8.03% and a WER of 28.39%.},
  archive      = {J_NCA},
  author       = {Molavi, Seyed Alireza and BabaAli, Bagher},
  doi          = {10.1007/s00521-024-10015-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17165-17179},
  shortjournal = {Neural Comput. Appl.},
  title        = {A self-attention-based deep architecture for online handwriting recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interpretable bayesian deep learning-based approach for
sustainable clean energy. <em>NCA</em>, <em>36</em>(27), 17145–17163.
(<a href="https://doi.org/10.1007/s00521-024-10008-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable Development Goal 7 is dedicated to ensuring access to clean and affordable energy that can be utilized in various applications. Solar panels (SP) are utilized to convert sunlight into electricity, acting as a renewable energy source. It is important to keep SP clean to obtain the required performance, as the accumulation of snow and dust on SP greatly affects the amount of electricity generated. On the other hand, excessive cleaning has some detrimental effects on the SP, therefore cleaning should only be done when necessary and not on a regular basis. Consequently, it is critical to determine whether the cleaning procedure is necessary by automatically detecting the presence of dust or snow on the panels while avoiding inaccurate predictions. Research efforts have been made to detect the presence of dust and snow on SP, but most of the proposed methods do not guarantee accurate detection results. This paper proposes an accurate, reliable, and interpretable approach called Solar-OBNet. The proposed Solar-OBNet can detect dusty SP and snow-covered SP very efficiently and be used in conjunction with the methods used to clean SP. The proposed Solar-OBNet is based on a Bayesian convolutional neural network, which enables it to express the amount of confidence in its predictions. Two measurements are used to estimate the uncertainty in the outcomes of the proposed Solar-OBNet, namely predictive entropy and standard deviation. The proposed Solar-OBNet can express confidence in the correct predictions by showing low values for predictive entropy and standard deviation. The proposed Solar-OBNet can also give an uncertainty warning in the case of erroneous predictions by showing high values of predictive entropy and standard deviation. The proposed Solar-OBNet’s efficacy was verified by interpreting its results using a method called Weighted Gradient-Directed Class Activation Mapping (Grad-CAM). The proposed Solar-OBNet has achieved a balanced accuracy of 94.07% and an average specificity 95.83%, outperforming other comparable methods.},
  archive      = {J_NCA},
  author       = {Ezzat, Dalia and Ahmed, Eman and Soliman, Mona and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-024-10008-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17145-17163},
  shortjournal = {Neural Comput. Appl.},
  title        = {An interpretable bayesian deep learning-based approach for sustainable clean energy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Late sensor fusion approach with a designed
multi-segmentation network. <em>NCA</em>, <em>36</em>(27), 17125–17143.
(<a href="https://doi.org/10.1007/s00521-024-10004-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensors have different perceptive abilities against environment. Sensor fusion plays a crucial role at achieving better perception by accumulating the information acquired at different times. But, the decision of the observation may conflict with each other due to usage of different algorithms, thresholds on processing algorithms, and different perceptive character of sensors. This study presents the late fusion method applied to outputs provided by deep learning models fed by camera and lidar sensor’s measurement data. For camera sensor, a deep learning model as a multi-task network is proposed to multi-classify cars, motorcycles, bicycles, buses, trucks, and pedestrians under the category of dynamic traffic objects. In addition, color classified traffic lights and traffic signs with a capability of segmenting drivable area and detecting lane lines are classified under the category of static traffic objects. The proposed multi-network is trained and tested with the BDD100K dataset and benchmarked with publicly available multi-networks. The presented method is the second fastest multi-network reaching at 52 FPS runtime, ranked second based on the drivable area segmentation and lane line detection performance. For segmentation of dynamic objects, the network performance is increased by 22.45%, and considering mIoU overall performance increase is 3.96%. For a lidar sensor, a different modality is presented to detect objects. Two sensors’ data are fused by proposed fusion algorithm, and results are tested and evaluated with the KITTI dataset. The proposed fusion methodology outperforms the stand-alone lidar methods about 3.58% and 3.63% on BEV and 3D detection MAP, respectively. Overall, benchmarking with two distinct fusion approaches illustrates the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Çaldıran, Bekir Eren and Acarman, Tankut},
  doi          = {10.1007/s00521-024-10004-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17125-17143},
  shortjournal = {Neural Comput. Appl.},
  title        = {Late sensor fusion approach with a designed multi-segmentation network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). STOD: Toward semi-supervised tiny object detection.
<em>NCA</em>, <em>36</em>(27), 17107–17123. (<a
href="https://doi.org/10.1007/s00521-024-09936-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection aims to enhance object detectors by utilizing a large number of unlabeled images, which has gained increasing attention in natural scenes. However, when these methods are directly applied to scenes with tiny objects, they face the challenge of selecting pseudo-labels with high localization quality due to the minuscule and blurred characteristics of these objects. To address this issue, we propose a novel method called semi-supervised tiny object detection (STOD). Firstly, to enhance the localization accuracy of pseudo-labels, we design a dense IoU-aware head that evaluates the quality of bounding box localization by incorporating additional predicted overlap values. Secondly, to mine more potential pseudo-labels, we propose a GMM-based multi-threshold pseudo-labels mining module that dynamically generates multiple thresholds using classification scores and overlap values to classify bounding boxes into strong positive and weak positive pseudo-labels. Lastly, we design the localization-aware weighting loss to incorporate the localization quality of both positive and negative samples in order to enhance the accuracy of pseudo-label localization. The experimental results show that STOD achieves comparable performance when compared to both fully and semi-supervised methods. Notably, on the VisDrone-Partial benchmark, STOD achieves outstanding results by outperforming our baseline model with improvements of 3.1 mAP, 5.7 $$AP_{50}$$ , and 3.0 $$AP_{75}$$ .},
  archive      = {J_NCA},
  author       = {Guo, Yanan and Feng, Yuxin and Du, Kangning and Cao, Lin},
  doi          = {10.1007/s00521-024-09936-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17107-17123},
  shortjournal = {Neural Comput. Appl.},
  title        = {STOD: Toward semi-supervised tiny object detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pose-aware video action segmentation. <em>NCA</em>,
<em>36</em>(27), 17095–17106. (<a
href="https://doi.org/10.1007/s00521-024-09920-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action segmentation is an emerging task in video understanding, particularly for untrimmed videos containing multiple actions. However, existing video-based methods may struggle due to their sensitivity to visual factors, while skeleton-based methods may not capture sufficient information from human poses to accurately segment actions. To overcome this limitation, we propose a novel approach that leverages the complementary information of video and human poses synergistically for action segmentation. To the best of our knowledge, this is the first attempt to exploit the complementarity of video and poses for this task. Specifically, we introduce a cross-modal salient sampling module that attentively integrates human pose information with temporal visual features for action segmentation across modalities. Our approach achieves state-of-the-art performance on two benchmarks, demonstrating the efficacy of our method in leveraging both visual and pose information for action segmentation.},
  archive      = {J_NCA},
  author       = {Zhang, Meijing and Liao, Chenyang and Li, Qi and Zhang, Hua and Liu, Wenxi},
  doi          = {10.1007/s00521-024-09920-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17095-17106},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pose-aware video action segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial neural network evaluation of concrete performance
exposed to elevated temperature with destructive–non-destructive tests.
<em>NCA</em>, <em>36</em>(27), 17079–17093. (<a
href="https://doi.org/10.1007/s00521-024-09999-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, it is aimed to predict the performance of concretes obtained by using supplementary cementitious materials (SCM) before and after high temperature using artificial neural network. Thus, in addition to contributing to sustainable development and circular economy by using waste materials in concrete production, predicting concrete strength using artificial neural network without the need for experimental studies will provide a great advantage in practice. In addition, it will also contribute to the literature in terms of determining the optimum amount of metakaolin to be used with fly ash in concrete production. Metakaolin, silica fume and fly ash were used as SCM in different proportions in concrete mixes. Accordingly, a total of 22 concrete series were prepared, one of which was the control series. Porosity, ultrasonic pulse velocity, pressure and tensile strength tests were applied to the series at the end of 7th, 28th and 90th curing periods before high temperature. In order to determine the strength losses after elevated temperature, porosity and compressive strength tests were applied at temperatures of 400, 600 and 800 °C. Mineral additive series showed positive mechanical properties up to 20%. However, it has been observed that the use of fly ash after a certain rate causes a decrease in strength. After elevated temperature, strength loss was observed in all series due to the increase in temperature, while it was observed that the rate of being affected by elevated temperature decreased as the percentage of metakaolin increased. Optimum mineral additive usage percentages were determined as 10% fly ash and 15% metakaolin. On the other hand, the use of mineral additives above the optimum level caused the performance of the concrete to decrease. Then, the concrete compression strengths obtained at 7th, 28th, and 90th days and at 400, 600 and 800 °C temperatures are taken as the outputs of the ANN. The artificial neural network provided the closest results to experimental data. Moreover, to prove the predictive performance of ANN, a comparative analysis was made with GPR, SVM and LR and the smallest value of the RMSE value is obtained with the ANN model. Finally, a fivefold cross-validation criteria was used to objectively present the performance of the model.},
  archive      = {J_NCA},
  author       = {Demir, Tuba and Duranay, Zeynep Bala and Demirel, Bahar and Yildirim, Busra},
  doi          = {10.1007/s00521-024-09999-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17079-17093},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial neural network evaluation of concrete performance exposed to elevated temperature with destructive–non-destructive tests},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating fuzzy metrics and negation operator in FCM
algorithm via genetic algorithm for MRI image segmentation.
<em>NCA</em>, <em>36</em>(27), 17057–17077. (<a
href="https://doi.org/10.1007/s00521-024-09994-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we redefine FCM algorithm by integrating fuzzy set theory, fuzzy metrics, and Sugeno negation principles. This innovative approach overcomes the limitations inherent in conventional machine learning models, especially in situations characterized by uncertainty, noise, and ambiguity. Our model utilizes the membership degrees from fuzzy set theory, and transforms the concept of proximity defined by fuzzy metrics into a minimization problem. This transformation is achieved using a linguistic negation operator, which is crucial for optimizing FCM algorithm&#39;s objective function. A significant innovation in our research is the use of GA for optimizing parameters within the contexts of fuzzy metrics and Sugeno negation. The precise optimization capabilities of GA greatly enhance the sensitivity and adaptability of FCM algorithm, thereby improving overall performance. By leveraging the meticulous parameter adjustments provided by GA, our approach has shown superior results in practical applications, such as brain MRI image segmentation, surpassing traditional methods. Experimental results highlight the considerable enhancements our proposed FCM algorithms bring over existing methods across various performance metrics. In conclusion, this study makes a valuable addition to the field of fuzzy-based machine learning methodologies. It combines the optimization strength of GA with the flexible classification capabilities of fuzzy logic. The integration of Sugeno negation and fuzzy metrics not only improves the accuracy and precision of FCM algorithm but also provides significant benefits in handling complex and ambiguous datasets. This research signifies a major advance in machine learning and fuzzy logic, setting the stage for future applications and studies.},
  archive      = {J_NCA},
  author       = {Kutlu, Fatih and Ayaz, İbrahim and Garg, Harish},
  doi          = {10.1007/s00521-024-09994-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17057-17077},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrating fuzzy metrics and negation operator in FCM algorithm via genetic algorithm for MRI image segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing omics analyses of bacterial protein secretion via
non-classical pathways. <em>NCA</em>, <em>36</em>(27), 17045–17055. (<a
href="https://doi.org/10.1007/s00521-024-09993-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the intricate pathways of protein secretion in bacteria is crucial for advancing research on bacterial diseases and their potential treatments, particularly in the case of non-classical protein secretion pathways. These pathways pose unique challenges due to the complex signaling mechanisms involved. To address this, we employed advanced machine learning techniques and gathered physical–chemical characteristics of amino acids from the AA index site. Through a meticulous six-step methodology, we curated a comprehensive dataset by filtering raw genome data and juxtaposing it with a positive dataset comprising 141 proteins from authoritative literature sources. Leveraging a conventional Random Forest machine learning algorithm, we achieved an impressive accuracy rate of approximately 91% in classifying non-classical secreted proteins. This validation was conducted on a dataset of 14 positive and 92 negative proteins, resulting in a sensitivity of 91% and a specificity of 86%. Notably, our study distinguishes itself by its rapid execution of non-classical secretion pathway analyses, rendering it particularly suitable for large datasets. This speed does not compromise accuracy, allowing for comprehensive Omics analyses. Consequently, our research underscores the significance of carefully selecting appropriate descriptors and constructing a robust training dataset to enhance Omics analyses of bacterial protein secretion via non-classical pathways. For further details, please refer to the complete study available at https://github.com/santosardr/non-CSPs.},
  archive      = {J_NCA},
  author       = {Oliveira, Luiz and Lanes, Gabriel and Santos, Anderson},
  doi          = {10.1007/s00521-024-09993-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17045-17055},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing omics analyses of bacterial protein secretion via non-classical pathways},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subspace-guided GAN for realistic single-image dehazing
scenarios. <em>NCA</em>, <em>36</em>(27), 17023–17044. (<a
href="https://doi.org/10.1007/s00521-024-09969-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-image haze removal is an essential preprocessing phase in many object detection and segmentation approaches. Recently, end-to-end deep learning-based approaches have dominated the field of single-image dehazing because of their superiority in recovering clear images corrupted by different types of degradation. However, training an effective dehazing network remains challenging, particularly in the absence of high-quality realistic training datasets. In this paper, a novel approach called a subspace-based dehazing generative adversarial network (SuDGAN) is proposed. Traditional training methods attempt to apply changes to pixel intensities, whereas SuDGAN adopts a novel training approach using existing synthetic datasets to learn the adjustment of subspace components related to haze. This approach enables the network to learn more discriminative haze-aware features and focus on adjusting the components that are more affected by haze (luminance) while preserving those that are less influenced by haze (structure). The proposed SuDGAN, along with several state-of-the-art approaches, is evaluated on various challenging synthetic and realistic datasets using haze-related and traditional evaluation metrics. The experimental results demonstrate the efficiency of SuDGAN in removing haze and producing visually pleasing results. Furthermore, the results show that SuDGAN has clear quantitative and qualitative improvements over most state-of-the-art dehazing approaches.},
  archive      = {J_NCA},
  author       = {Kajo, Ibrahim and Kas, Mohamed and Chahi, Abderrazak and Ruichek, Yassine},
  doi          = {10.1007/s00521-024-09969-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17023-17044},
  shortjournal = {Neural Comput. Appl.},
  title        = {Subspace-guided GAN for realistic single-image dehazing scenarios},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring how a generative AI interprets music.
<em>NCA</em>, <em>36</em>(27), 17007–17022. (<a
href="https://doi.org/10.1007/s00521-024-09956-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We aim to investigate how closely neural networks (NNs) mimic human thinking. As a step in this direction, we study the behavior of artificial neuron(s) that fire most when the input data score high on some specific emergent concepts. In this paper, we focus on music, where the emergent concepts are those of rhythm, pitch and melody as commonly used by humans. As a black box to pry open, we focus on Google’s MusicVAE, a pre-trained NN that handles music tracks by encoding them in terms of 512 latent variables. We show that several hundreds of these latent variables are “irrelevant” in the sense that can be set to zero with minimal impact on the reconstruction accuracy. The remaining few dozens of latent variables can be sorted by order of relevance by comparing their variance. We show that the first few most relevant variables, and only those, correlate highly with dozens of human-defined measures that describe rhythm and pitch in music pieces, thereby efficiently encapsulating many of these human-understandable concepts in a few nonlinear variables.},
  archive      = {J_NCA},
  author       = {Barenboim, Gabriela and Debbio, Luigi Del and Hirn, Johannes and Sanz, Verónica},
  doi          = {10.1007/s00521-024-09956-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {17007-17022},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring how a generative AI interprets music},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated approach for prediction of magnitude using
deep learning techniques. <em>NCA</em>, <em>36</em>(27), 16991–17006.
(<a href="https://doi.org/10.1007/s00521-024-09891-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely estimation of earthquake magnitude plays a crucial role in the early warning systems for earthquakes. Despite the inherent danger associated with earthquake energy, earthquake research necessitates extensive parameter estimation and predictive techniques to account for uncertain trends in earthquake waveforms when determining earthquake magnitudes using a single station. This study introduces an effective solution to tackle the issue through the automatic magnitude deep network (AMagDN) model. The proposed model includes long short-term memory (LSTM), a bidirectional LSTM, an autocorrelation attention mechanism, and a machine learning block that can capture detailed information from the seismic waveform recorded during an earthquake. The unique feature of this model is the use of multivariate time series waveforms derived from recorded accelerograms specifically tailored to their energy significance with magnitude and seven fusion tabular parameters involving source and geospatial features. The proposed model’s training, validation and testing are done using independent 15014, 1287 and 3448 records maintained by the Kyoshin network, Japan, for moderate to great impact earthquakes between 5.5 and 8.0 ( $$M_\textrm{JMA}$$ ). A comparative study shows that the proposed model outperforms recent state-of-the-art models and common linear relations, reducing mean absolute prediction error by 40% from the second-best model. The multi-stations data are also used for successfully forecasting the magnitudes of two significant earthquakes of 7.7 and 7.3 magnitude ( $$M_\textrm{JMA}$$ ) using the proposed model. The reliable prediction capabilities of the proposed model for both single and multi-station data clearly demonstrate its utility in reducing earthquake hazards.},
  archive      = {J_NCA},
  author       = {Joshi, Anushka and Raman, Balasubramanian and Mohan, C. Krishna},
  doi          = {10.1007/s00521-024-09891-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16991-17006},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated approach for prediction of magnitude using deep learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning segmentation models for estimating the health
status of induction motor bearing. <em>NCA</em>, <em>36</em>(27),
16977–16989. (<a
href="https://doi.org/10.1007/s00521-024-10035-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for accurate health status assessment of bearings in rotating electrical machines is rising. However, traditional fault diagnosis methods based on deep learning are not effective in efficiently and intelligently determining the health condition of the bearings and also requires large memory, hence constraining their use in low-cost microcontrollers. In this work, combination of short time Fourier transform (STFT) with Ostu’s threshold method and MobileNet-V2 with U-Net (MV2UNet) is proposed for rolling bearing fault health status. The proposed method obtains the STFT images of the raw vibration signals from the laboratory experimental setup. Then the Ostu’s threshold method is used to make the labels for STFT images. Finally, the proposed method is trained with these labelled images to detect the health status of each bearing fault. The proposed model achieved the Dice coefficient is 0.9834 and the intersection over union is 0.9479. The main advantage of the proposed model has low memory requirements, which makes it well-suited for implementation in affordable hardware devices like microcontrollers. Finally, the proposed method result is compared with U-Net, DeepLabV3+ with MobileNet-V2 and DeepLabV3+ with ResNet-50.},
  archive      = {J_NCA},
  author       = {Karan Kumar, K. and Mandava, Srihari},
  doi          = {10.1007/s00521-024-10035-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16977-16989},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning segmentation models for estimating the health status of induction motor bearing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DSANet: Dilated spatial attention network for the detection
of text, non-text and touching components in unconstrained handwritten
documents. <em>NCA</em>, <em>36</em>(27), 16959–16976. (<a
href="https://doi.org/10.1007/s00521-024-10013-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten documents generated in our day-to-day office work, class room and other sectors of society carry vital information. Automatic processing of these documents is a pipeline of many challenging steps. The very first and crucial step is to identify text separately from the non-text as any OCR (optical character recognition) engine can only process the textual content. Separating text from non-text in unconstrained handwritten documents is a very complex task. In addition to other challenges, touching component is one of the major issues for text non-text separation in unconstrained handwritten documents. Detection of text, non-text along with touching component in such documents is an unexplored area of research. To address this issue, in this work, we develop a dilated spatial attention-based network for text, non-text and touching component detection. Additionally, in this work, we also prepare a realistic dataset for the said task. In the proposed dataset, the present model obtains overall accuracy of 87.85%. The performance of the present model is compared with seven feature-engineering-based methods and six deep learning-based methods. In most of the cases, the proposed model outperforms the comparing methods in the proposed dataset. The codes of our method are available here https://github.com/Showmik-Bhowmik/DSANet-Dilated-Spatial-Attention-.git .},
  archive      = {J_NCA},
  author       = {Bhowmik, Showmik and Risat, Shaikh and Sarkar, Bhaskar},
  doi          = {10.1007/s00521-024-10013-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16959-16976},
  shortjournal = {Neural Comput. Appl.},
  title        = {DSANet: Dilated spatial attention network for the detection of text, non-text and touching components in unconstrained handwritten documents},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design cost minimization of a reinforced concrete column
section using overnew swarm-based optimization algorithms. <em>NCA</em>,
<em>36</em>(27), 16941–16958. (<a
href="https://doi.org/10.1007/s00521-024-09998-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is very tiresome for a practiser to detect the best feasible sizing design of structural members including reinforced concrete columns that is a highly nonlinear and complicated structural engineering optimization problem. This is due to such a design is practically conducted via conventional trial-and-error computing methods in which resistance to external loads, cost efficiency, and aesthetic factors, etc. have to be considered. This study focuses on minimizing the design cost of primarily proposed reinforced concrete column design problem via three overnew swarm-based optimizers such as Coati Optimization Algorithm, Fox Optimizer and Pelican Optimization Algorithm (POA) that are firstly utilized for this purpose. In this regard, the type of steel rebar distribution, the characteristic strength of the concrete, the height and width of the column section, and the number and diameter of the rebars are treated as discrete design variables of the newly proposed complex reinforced concrete column design cost optimization problem. In solution, the design requirements specified in practice code provisions should also be met. Here, Turkish Building Earthquake Code 2018 specifications are considered as practice structural design constraints. Consequently, the algorithmic performances of three overnew swarm-based metaheuristic optimization algorithms are compared and evaluated in detail. Amongst them, the POA shows most fruitful algorithmic design solution performance.},
  archive      = {J_NCA},
  author       = {Tunca, Osman and Carbas, Serdar},
  doi          = {10.1007/s00521-024-09998-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16941-16958},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design cost minimization of a reinforced concrete column section using overnew swarm-based optimization algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameter-efficient fine-tuning of pre-trained code models
for just-in-time defect prediction. <em>NCA</em>, <em>36</em>(27),
16911–16940. (<a
href="https://doi.org/10.1007/s00521-024-09930-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software engineering workflows use version control systems to track changes and handle merge cases from multiple contributors. This has introduced challenges to testing because it is impractical to test whole codebases to ensure each change is defect-free, and it is not enough to test changed files alone. Just-in-time software defect prediction (JIT-SDP) systems have been proposed to solve this by predicting the likelihood that a code change is defective. Numerous techniques have been studied to build such JIT software defect prediction models, but the power of pre-trained code transformer language models in this task has been underexplored. These models have achieved human-level performance in code understanding and software engineering tasks. Inspired by that, we modeled the problem of change defect prediction as a text classification task utilizing these pre-trained models. We have investigated this idea on a recently published dataset, ApacheJIT, consisting of 44k commits. We concatenated the changed lines in each commit as one string and augmented it with the commit message and static code metrics. Parameter-efficient fine-tuning was performed for 4 chosen pre-trained models, JavaBERT, CodeBERT, CodeT5, and CodeReviewer, with either partially frozen layers or low-rank adaptation (LoRA). Additionally, experiments with the Local, Sparse, and Global (LSG) attention variants were conducted to handle long commits efficiently, which reduces memory consumption. As far as the authors are aware, this is the first investigation into the abilities of pre-trained code models to detect defective changes in the ApacheJIT dataset. Our results show that proper fine-tuning improves the defect prediction performance of the chosen models in the F1 scores. CodeBERT and CodeReviewer achieved a 10% and 12% increase in the F1 score over the best baseline models, JITGNN and JITLine, when commit messages and code metrics are included. Our approach sheds more light on the abilities of language models in software engineering tasks, promoting their use in production environments and ensuring that deployed software is defect-free efficiently.},
  archive      = {J_NCA},
  author       = {Abu Talib, Manar and Bou Nassif, Ali and Azzeh, Mohammad and Alesh, Yaser and Afadar, Yaman},
  doi          = {10.1007/s00521-024-09930-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16911-16940},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parameter-efficient fine-tuning of pre-trained code models for just-in-time defect prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance enhancement of deep neural network using
fusional data assimilation and divide-and-conquer approach; case study:
Earthquake magnitude calculation. <em>NCA</em>, <em>36</em>(27),
16899–16910. (<a
href="https://doi.org/10.1007/s00521-024-10002-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of &quot;ill-posed samples&quot; specifically in low-volume datasets leads to accuracy decrement in the learning procedure and the generalization of neural networks. Such samples can be caused by various reasons such as noise contamination, corrupted sensors, or even, the complex distribution of physical properties governing the problem. The peak ground acceleration (PGA) datasets are definitely among the last mentioned. Focusing on speed and accuracy, a method for calculating earthquake magnitude based on the PGA data recorded at a single station along with hypocentral information has been presented in this research. Here, after training a deep neural network, the regression errors of the training data samples are clustered into two groups, namely well and ill posed using the grey wolf optimization algorithm. Instead of being removed, the data samples with low learning rates are then modified using samples selected from the other cluster in a fusional form. Then, two separate models are used and trained independently for the clusters. Next, in addition to the routine procedure of network generalization, every new sample is first checked whether is more likely to belong to which group of the clustered data, and after processing, the corresponding trained model is used. The results of the experiments show that using the proposed method results in magnitude calculation with an error order of less than 0.212 units of moment magnitude with a probability of more than 99.7%, which is superior to the conventional methods some of which were reviewed in this research.},
  archive      = {J_NCA},
  author       = {Esmaeili, Rezvan and Kimiaefar, Roohollah and Hajian, Alireza and Soleimani-Chamkhorami, Khosro and Hodhodi, Maryam},
  doi          = {10.1007/s00521-024-10002-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16899-16910},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance enhancement of deep neural network using fusional data assimilation and divide-and-conquer approach; case study: Earthquake magnitude calculation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel artificial hummingbird algorithm improved by natural
survivor method. <em>NCA</em>, <em>36</em>(27), 16873–16897. (<a
href="https://doi.org/10.1007/s00521-024-09928-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial hummingbird algorithm (AHA) has been applied in various fields of science and provided promising solutions. Although the algorithm has demonstrated merits in the optimization area, it suffers from local optimum stagnation and poor exploration of the search space. To overcome these drawbacks, this study redesigns the update mechanism of the original AHA algorithm with the natural survivor method (NSM) and proposes a novel metaheuristic called NSM-AHA. The strength of the developed algorithm is that it performs population management not only according to the fitness function value but also according to the NSM score value. The adopted strategy contributes to NSM-AHA exhibiting powerful local optimum avoidance and unique exploration ability. The optimization ability of the proposed NSM-AHA algorithm was compared with 21 state-of-the-art algorithms over CEC 2017 and CEC 2020 benchmark functions with dimensions of 30, 50, and 100, respectively. Based on the Friedman test results, it was observed that NSM-AHA ranked 1st out of 22 competitive algorithms, while the original AHA ranked 8th. This result highlights that the NSM update mechanism provides a remarkable evolution in the convergence performance of the original AHA algorithm. Furthermore, two constrained engineering problems including the optimization of single-diode solar cell model (SDSCM) parameters and the design of a power system stabilizer (PSS) are solved with the proposed algorithm. The NSM-AHA algorithm provided better results compared to other algorithms with a value of 9.86E − 04 root mean square error for SDSCM and 1.43E − 03 integral time square error for PSS. The experimental results showed that the proposed NSM-AHA is a competitive optimizer for solving global and engineering problems.},
  archive      = {J_NCA},
  author       = {Bakır, Hüseyin},
  doi          = {10.1007/s00521-024-09928-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16873-16897},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel artificial hummingbird algorithm improved by natural survivor method},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated asthma detection in a 1326-subject cohort using a
one-dimensional attractive-and-repulsive center-symmetric local binary
pattern technique with cough sounds. <em>NCA</em>, <em>36</em>(27),
16857–16871. (<a
href="https://doi.org/10.1007/s00521-024-09895-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asthma is a common disease. The clinical diagnosis is usually confirmed on a pulmonary function test, which is not always readily accessible. We aimed to develop a computationally lightweight handcrafted machine learning model for asthma detection based on cough sounds recorded using mobile phones. Toward this aim, we proposed a novel feature extractor based on a one-dimensional version of the published attractive-and-repulsive center-symmetric local binary pattern (1D-ARCSLBP), which we tested on a new cough sound dataset. We prospectively recorded cough sounds from 511 asthmatics and 815 non-asthmatic subjects (comprising mostly healthy volunteers), which yielded 1875 one-second cough sound segments for analysis. Our model comprised four steps: (i) preprocessing, in which speech signals and stop times (silent zones between coughs) were removed, leaving behind analyzable cough sound segments; (ii) feature extraction, in which tunable q-factor wavelet transformation was used to perform multilevel signal decomposition into wavelet subbands, allowing 1D-ARCSLBP to extract local low- and high-level features; (iii) feature selection, in which neighborhood component analysis was used to select the most discriminative features; and (iv) classification, in which a standard shallow cubic support vector machine was deployed to calculate binary classification results (asthma versus non-asthma) using tenfold and leave-one-subject-out cross-validations. Our model attained 98.24% and 96.91% accuracy rates with tenfold and leave-one-subject-out cross-validation strategies, respectively, and obtained a low-time complexity. The excellent results confirmed the feature extraction capability of 1D-ARCSLBP and the feasibility of the model being developed into a real-world application for asthma screening.},
  archive      = {J_NCA},
  author       = {Barua, Prabal Datta and Keles, Tugce and Kuluozturk, Mutlu and Kobat, Mehmet Ali and Dogan, Sengul and Baygin, Mehmet and Tuncer, Turker and Tan, Ru-San and Acharya, U. Rajendra},
  doi          = {10.1007/s00521-024-09895-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16857-16871},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated asthma detection in a 1326-subject cohort using a one-dimensional attractive-and-repulsive center-symmetric local binary pattern technique with cough sounds},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid convolutional neural network and support vector
machine classifier for amharic character recognition. <em>NCA</em>,
<em>36</em>(27), 16839–16856. (<a
href="https://doi.org/10.1007/s00521-024-09657-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical character recognition is a way of converting scanned images of printed or handwritten documents into machine-encoded text, making it easier to store, browse, retrieve, and process electronic data. In this research, a Printed Amharic Characters Recognition dataset is prepared to train and test a model. Images in the dataset only contain 231 basic Amharic characters that are normalized to 32 × 32 pixels. In this work, a hybrid model of the two super classifiers is developed: the convolutional neural network (CNN) and the support vector machine (SVM). In this novel hybrid CNN-SVM model, CNN works as an automatic feature extractor from the raw images, and then, the extracted feature vectors are given as input to SVM for classification and recognition. A 99.84% accuracy was achieved on the own-prepared dataset and 95.59% accuracy on the benchmark Amharic Optical Character Recognition Database in classifying the testing dataset images. The proposed hybrid CNN-SVM model gave better results than the CNN with a fully connected layer. Moreover, the proposed model outperforms previously existing works attempted by others to recognize printed Amharic characters on the same and different datasets.},
  archive      = {J_NCA},
  author       = {Tsegaye, Muluken Zemed and Shashi, Mogalla},
  doi          = {10.1007/s00521-024-09657-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16839-16856},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid convolutional neural network and support vector machine classifier for amharic character recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of multi-objective equilibrium optimizer:
Application to cancer chemotherapy. <em>NCA</em>, <em>36</em>(27),
16817–16837. (<a
href="https://doi.org/10.1007/s00521-024-10014-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any multi-objective optimization algorithms are usually introduced by developing a single-objective algorithm. In the current study, a recently developed physics-based algorithm, equilibrium optimizer (EO), is regarded and is extended into a multi-objective algorithm called MOEO. The optimal control problem for cancer treatment is solved using this novel algorithm to confirm its performance. Considering the cancer treatment as an optimal control problem to reduce both the concentration of cancer cells and the concentration of the drugs during treatment is the multi-objective optimization problem of this research. Due to this, this problem’s solution leads to the optimal drug administration protocol to minimize cancer cell concentration and drug concentration. This multi-objective problem is solved using the novel MOEO algorithm, and the results are compared with the previous works. The Pareto front curve obtained from the algorithm offers a set of the most optimal solutions. According to the treatment selection criteria, one of these points is selected as the drug-prescribing protocol. The problem is solved based on three different case studies, where the result comparison shows that the MOEO’s performance is great. Considering different cost functions, it shows that using integral of the time-weighted absolute (ITA) objective function gets the fastest response with a higher drug dose while using integral of the absolute (IS) objective function gets lesser drugs.},
  archive      = {J_NCA},
  author       = {Nozad, K. and Varedi-Koulaei, S. M. and Nazari, M.},
  doi          = {10.1007/s00521-024-10014-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16817-16837},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of multi-objective equilibrium optimizer: Application to cancer chemotherapy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Measuring the efficiency of banks using high-performance
ensemble technique. <em>NCA</em>, <em>36</em>(27), 16797–16815. (<a
href="https://doi.org/10.1007/s00521-024-09929-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of technology and managerial risk management in banks has increased due to the financial crisis. Banks are the most affected since there are so many of them with poor financial standing. Due to this problem, an unstable and inefficient financial system causes economic stagnation in both the banking sector and overall economy. Data envelopment analysis (DEA) has been used to examine decision-making units (DMUs) performance to enhance efficiency. Currently, with the rapid growth of big data, adding more DMUs will likely require a large amount of memory and CPU time on the computer system, which will be the biggest challenge. As a result, machine learning (ML) approaches have been used to analyze financial institution performance, but many of them have variances in predictions or model stability, making measuring bank efficiency extremely difficult. For this, ensemble learning is commonly used to evaluate the performance of financial institutions in this context. This paper presents a robust super learner ensemble technique for assessing bank efficiency, with four machine learning models serving as base learners. These models are the support vector machine (SVM), K-nearest neighbors (KNN), random forest (RF), and AdaBoost classifier (ADA) which represent the base learners and their results utilized to train the meta-learner. The super learner (SL) approach is an extension of the stacking technique, which generates an ensemble based on cross-validation. One important benefit of this cross-validation theory-based technique is that it can overcome the overfitting issue that plagues most other ensemble approaches. When SL and base learners were compared for their forecasting abilities using different statistical standards, the results showed that the SL is superior to the base learners, where different variable combinations were used. The SL had accuracy (ACC) of 0.8636–0.9545 and F1-score (F1) of 0.9143–0.9714, while the basic learners had ACC of 0.5909–0.8182 and F1 of 0.6897–0.9143. So, SL is highly recommended for improving the accuracy of financial data forecasts, even with limited financial data.},
  archive      = {J_NCA},
  author       = {Thabet, Huda H. and Darwish, Saad M. and Ali, Gihan M.},
  doi          = {10.1007/s00521-024-09929-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16797-16815},
  shortjournal = {Neural Comput. Appl.},
  title        = {Measuring the efficiency of banks using high-performance ensemble technique},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection and classification of photovoltaic module defects
based on artificial intelligence. <em>NCA</em>, <em>36</em>(27),
16769–16796. (<a
href="https://doi.org/10.1007/s00521-024-10000-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) system performance and reliability can be improved through the detection of defects in PV modules and the evaluation of their effects on system operation. In this paper, a novel system is proposed to detect and classify defects based on electroluminescence (EL) images. This system is called Fault Detection and Classification (FDC) and splits into four modules, which are (1) Image Preprocessing Module (IPM), (2) Feature Extraction Module (FEM), (3) Feature Selection Module (FSM), and (4) Classification Module (CM). In the first module (i.e., IPM), the EL images are preprocessed to enhance the quality of the images. Next, the two types of features in these images are extracted and fused together through FEM. Then, during FSM, the most important and informative features are extracted from these features using a new feature selection methodology, namely, Feature Selection-based Chaotic Map (FS-CM). FS-CM consists of two stages: filter stage using chi-square to initially select the most effective features and a modified selection stage using an enhanced version of Butterfly Optimization Algorithm (BOA). In fact, BOA is a popular swarm-based metaheuristic optimization algorithm that has only recently found success. While BOA has many benefits, it also has some drawbacks, including a smaller population and an increased likelihood of getting stuck in a local optimum. In this paper, a new methodology is proposed to improve the performance of BOA, called chaotic-based butterfly optimization algorithm. Finally, these selected features are used to feed the proposed classification model through CM. During CM, Hybrid Classification Model (HCM) is proposed. HCM consists of two stages, which are binary classification stage using Naïve Bayes (NB) and multi-class classification stage using enhanced multi-layer perceptron. According to the experimental results, the proposed system FDC outperforms the most recent methods. FDC introduced 98.2%, 89.23%, 87.2%, 87.9%, 87.55%, and 88.20% in terms of accuracy, precision, sensitivity, specificity, g-mean, and f-measure in the same order.},
  archive      = {J_NCA},
  author       = {Shaban, Warda M.},
  doi          = {10.1007/s00521-024-10000-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16769-16796},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection and classification of photovoltaic module defects based on artificial intelligence},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing horizons in remote sensing: A comprehensive survey
of deep learning models and applications in image classification and
beyond. <em>NCA</em>, <em>36</em>(27), 16727–16767. (<a
href="https://doi.org/10.1007/s00521-024-10165-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has significantly reshaped numerous fields and applications, fundamentally altering how we tackle a variety of challenges. Areas such as natural language processing (NLP), computer vision, healthcare, network security, wide-area surveillance, and precision agriculture have leveraged the merits of the deep learning era. Particularly, deep learning has significantly improved the analysis of remote sensing images, with a continuous increase in the number of researchers and contributions to the field. The high impact of deep learning development is complemented by rapid advancements and the availability of data from a variety of sensors, including high-resolution RGB, thermal, LiDAR, and multi-/hyperspectral cameras, as well as emerging sensing platforms such as satellites and aerial vehicles that can be captured by multi-temporal, multi-sensor, and sensing devices with a wider view. This study aims to present an extensive survey that encapsulates widely used deep learning strategies for tackling image classification challenges in remote sensing. It encompasses an exploration of remote sensing imaging platforms, sensor varieties, practical applications, and prospective developments in the field.},
  archive      = {J_NCA},
  author       = {Paheding, Sidike and Saleem, Ashraf and Siddiqui, Mohammad Faridul Haque and Rawashdeh, Nathir and Essa, Almabrok and Reyes, Abel A.},
  doi          = {10.1007/s00521-024-10165-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16727-16767},
  shortjournal = {Neural Comput. Appl.},
  title        = {Advancing horizons in remote sensing: A comprehensive survey of deep learning models and applications in image classification and beyond},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series data mining for railway wheel and track
monitoring: A survey. <em>NCA</em>, <em>36</em>(27), 16707–16725. (<a
href="https://doi.org/10.1007/s00521-024-10138-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The railway sector has witnessed a significant surge in condition-based maintenance, thanks to the proliferation of sensing technologies and data-driven methodologies, such as machine learning. However, despite the plethora of algorithms designed to detect and classify track irregularities and wheel out-of-roundness, they often fall short when put to the test in real-world scenarios. These shortcomings typically stem from their inability to meet all four critical requirements for constructing an effective maintenance plan: (R1) suitability of the condition-based maintenance strategy, (R2) availability of relevant data, (R3) proper problem formulation, and (R4) accurate evaluation of data mining methods. In response to the absence of a unified framework and standardized guidelines, this survey delves into the realm of time series sensor data and wheel-track interface components for railway structural health monitoring. This survey aims to bridge this gap by offering an extensive categorization, pinpointing existing challenges, and outlining potential directions for future research. Through these efforts, this survey provides a more thorough and targeted exploration of the subject matter, contributing to the advancement of this field.},
  archive      = {J_NCA},
  author       = {Lourenço, Afonso and Ribeiro, Diogo and Fernandes, Marta and Marreiros, Goreti},
  doi          = {10.1007/s00521-024-10138-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16707-16725},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time series data mining for railway wheel and track monitoring: A survey},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review of deep learning power in
steady-state visual evoked potentials. <em>NCA</em>, <em>36</em>(27),
16683–16706. (<a
href="https://doi.org/10.1007/s00521-024-10143-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–computer interfacing (BCI) research, fueled by deep learning, integrates insights from diverse domains. A notable focus is on steady-state visual evoked potential (SSVEP) in BCI applications, requiring in-depth assessment through deep learning. EEG research frequently employs SSVEPs, which are regarded as normal brain responses to visual stimuli, particularly in investigations of visual perception and attention. This paper tries to give an in-depth analysis of the implications of deep learning for SSVEP-adapted BCI. A systematic search across four stable databases (Web of Science, PubMed, ScienceDirect, and IEEE) was developed to assemble a vast reservoir of relevant theoretical and scientific knowledge. A comprehensive search yielded 177 papers that appeared between 2010 and 2023. Thence a strict screening method from predetermined inclusion criteria finally generated 39 records. These selected works were the basis of the study, presenting alternate views, obstacles, limitations and interesting ideas. By providing a systematic presentation of the material, it has made a key scholarly contribution. It focuses on the technical aspects of SSVEP-based BCI, EEG technologies and complex applications of deep learning technology in these areas. The study delivers more penetrating reporting on the latest deep learning pattern recognition techniques than its predecessors, together with progress in data acquisition and recording means suitable for SSVEP-based BCI devices. Especially in the realms of deep learning technology orchestration, pattern recognition techniques, and EEG data collection, it has effectively closed four important research gaps. To increase the accessibility of this critical material, the results of the study take the form of easy-to-read tables just generated. Applying deep learning techniques in SSVEP-based BCI applications, as the research shows, also has its downsides. The study concludes that a radical framework will be presented which, includes intelligent decision-making tools for evaluation and benchmarking. Rather than just finding a comparable or similar analogy, this framework is intended to help guide future research and pragmatic applications, and to determine which SSVEP-based BCI applications have succeeded at responsibility for what they set out with.},
  archive      = {J_NCA},
  author       = {Al-Qaysi, Z. T. and Albahri, A. S. and Ahmed, M. A. and Hamid, Rula A. and Alsalem, M. A. and Albahri, O. S. and Alamoodi, A. H. and Homod, Raad Z. and Shayea, Ghadeer Ghazi and Duhaim, Ali M.},
  doi          = {10.1007/s00521-024-10143-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16683-16706},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive review of deep learning power in steady-state visual evoked potentials},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparison of neural FEM and neural operator methods for
applications in solid mechanics. <em>NCA</em>, <em>36</em>(27),
16657–16682. (<a
href="https://doi.org/10.1007/s00521-024-10132-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods are progressively investigated for a large amount of applications. Recently, the solution of partial differential equations (PDE) describing problems in elastostatics came into focus. The current work investigates two neural network-based classes of methods for their solution, namely the neural finite element method (FEM) and neural operator methods. The analysis of these approaches is carried out by means of numerical experiments with linear and nonlinear material behavior where the conventional FEM serves as a benchmark. The formulation of neural FEM allows for elegant integration of finite deformation hyperelasticity at medium training effort. Here, training data are replaced by the evaluation of the equilibrium PDE at sample points. In contrast, most neural operator methods require expensive training with large data sets, but then allow for solving multiple boundary value problems with the same machine learning model. For the comparative analysis, the maximal relative error values over the whole domain and over all components of the strain tensor are evaluated as accuracy measure. The current state of research shows that none of the methods investigated reaches the accuracy and computational performance of the conventional FEM. In many standard applications, the FEM achieves an accuracy of $$10^{-6}$$ , whereas the numerical tests in the present work report a relative error of order of magnitude of $$10^{-4}$$ for the neural FEM and $$10^{-2}$$ to $$10^{-3}$$ for neural operator methods.},
  archive      = {J_NCA},
  author       = {Hildebrand, Stefan and Klinge, Sandra},
  doi          = {10.1007/s00521-024-10132-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16657-16682},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparison of neural FEM and neural operator methods for applications in solid mechanics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed intelligence for IoT-based smart cities: A
survey. <em>NCA</em>, <em>36</em>(27), 16621–16656. (<a
href="https://doi.org/10.1007/s00521-024-10136-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable miniaturization of Internet of Things (IoT)-based systems and the rise of distributed intelligence are promising research paradigms in the design of smart cities. IoT and distributed intelligence are conjoined. On the one hand, IoT provides a digital connection to everyday physical devices, and on the other hand, distributed intelligence allows these connected devices to work together in a distributed environment to solve complex problems through learning and reasoning. In this article, we investigate and report the recent premier advances in distributed intelligence for IoT-based smart cities. We use bibliometric techniques which provide essential insights into many studies to evaluate the literature including publication year, type, and citation status on distributed intelligence and its variations published between 2013 and 2023. We categorize and classify literature by devising a taxonomy based on essential parameters, technologies, approaches, applications, and implications with respect to distributed intelligence. Moreover, we provide recent ongoing advancements in distributed intelligence and IoT such as sustainability, blockchain, 5G technologies, AI, edge computing expansion and IoT expansion. We also highlight some of the use cases which include traffic management, energy management, waste management, public safety, and healthcare. We provide core layers and services for implementing distributed intelligence in IoT-based smart cities and present several research challenges and issues.},
  archive      = {J_NCA},
  author       = {Hashem, Ibrahim Abaker and Siddiqa, Aisha and Alaba, Fadele Ayotunde and Bilal, Muhammad and Alhashmi, Saadat Mehmood},
  doi          = {10.1007/s00521-024-10136-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {27},
  pages        = {16621-16656},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributed intelligence for IoT-based smart cities: A survey},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing retinal fundus image classification through active
gradient deep convolutional neural network and red spider optimization.
<em>NCA</em>, <em>36</em>(26), 16607–16619. (<a
href="https://doi.org/10.1007/s00521-024-09989-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal fundus image classification is pivotal for the early detection of various eye disorders. Leveraging advancements in deep learning, this research introduces a robust framework for retinal fundus image classification. In this research paper, we introduce a novel methodology that integrates the Active Gradient Deep Convolutional Neural Network (AG-DCNN) architecture with the Red Spider Optimization (RSO) algorithm. Extensive evaluations conducted on well-established retinal image datasets such as DRIVE, STARE, CHASE DB1, HRF, DRISHTI-GS, and RFMiD illustrate substantial enhancements in classification accuracy, sensitivity, and specificity when compared to conventional approaches. The AG-DCNN with RSO exhibits superior performance and remarkable generalization abilities across diverse datasets. This novel approach not only enhances the latest advances in retinal image classification but also holds promise for early disease diagnosis and improved patient care. Through extensive examinations, our proposed method consistently outperforms established techniques, establishing itself as the benchmark in retinal fundus image classification. The integration of AG-DCNN and RSO showcases its efficacy and potential impact in advancing the field of medical image analysis.},
  archive      = {J_NCA},
  author       = {Subramaniam, Krishnakumar and Naganathan, Archana},
  doi          = {10.1007/s00521-024-09989-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16607-16619},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing retinal fundus image classification through active gradient deep convolutional neural network and red spider optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of machine learning to model the pressure
poisson equation for fluid flow on generic geometries. <em>NCA</em>,
<em>36</em>(26), 16581–16606. (<a
href="https://doi.org/10.1007/s00521-024-09935-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the importance of enhancing traditional fluid-flow solvers by introducing a Machine Learning procedure to model pressure fields computed by standard fluid-flow solvers. The conventional approach involves enforcing pressure–velocity coupling through a Poisson equation, combining the Navier–Stokes and continuity equations. The solution to this Poisson equation constitutes a substantial percentage of the overall computational cost in fluid flow simulations, therefore improving its efficiency can yield significant gains in computational speed. The study aims to create a versatile method applicable to any geometry, ultimately providing a more efficient alternative to the conventional pressure solver. Machine Learning models were trained with flow fields generated by a Computational Fluid Dynamics solver applied to the confined flow over multiple geometries, namely wall-bounded cylinders with circular, rectangular, triangular, and plate cross-sections. To achieve applicability to any geometry, a method was developed to estimate pressure fields in fixed-shape blocks sampled from the flow domain and subsequently assemble them to reconstruct the entire physical domain. The model relies on multilayer perceptron neural networks combined with Principal Component Analysis transformations. The developed Machine Learning models achieved acceptable accuracy with errors of around 3%. Furthermore, the model demonstrated enhanced computational efficiency, outperforming the classical PISO algorithm by up to 30 times.},
  archive      = {J_NCA},
  author       = {Sousa, Paulo and Afonso, Alexandre and Veiga Rodrigues, Carlos},
  doi          = {10.1007/s00521-024-09935-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16581-16606},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of machine learning to model the pressure poisson equation for fluid flow on generic geometries},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CVApool: Using null-space of CNN weights for the tooth
disease classification. <em>NCA</em>, <em>36</em>(26), 16567–16579. (<a
href="https://doi.org/10.1007/s00521-024-09995-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of current developments in dental care, dental professionals have increasingly used deep learning methods to get precise diagnoses of oral problems. Using intraoral X-rays in dental radiography is imperative in many dental interventions. Integrating deep learning techniques with a unique collection of intraoral X-ray images has been undertaken to enhance the accuracy of dental disease detection. In this study, we propose an alternative pooling layer, namely the Common Vector Approach Pooling technique, to address the constraints associated with average pooling in deep learning methods. The experiments are conducted on a large dataset, involving twenty different dental conditions, divided into seven categories. Our proposed approach achieved a high accuracy rate of 86.4% in identifying dental problems across the seven oral categories.},
  archive      = {J_NCA},
  author       = {Can, Zuhal and Isik, Sahin and Anagun, Yildiray},
  doi          = {10.1007/s00521-024-09995-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16567-16579},
  shortjournal = {Neural Comput. Appl.},
  title        = {CVApool: Using null-space of CNN weights for the tooth disease classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning algorithms for predicting the risk of
chronic kidney disease in type 1 diabetes patients: A retrospective
longitudinal study. <em>NCA</em>, <em>36</em>(26), 16545–16565. (<a
href="https://doi.org/10.1007/s00521-024-09959-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic kidney disease (CKD) is a significant concern for individuals with type 1 diabetes (T1D), impacting their quality of life and healthcare costs. Identifying T1D patients at greater risk of developing CKD is crucial for preventive measures. However, it is challenging due to the asymptomatic progression of CKD and limited nephrologist availability in many countries. This study explores machine learning algorithms to predict CKD risk in T1D patients using ten years of retrospective data from the Epidemiology of Diabetes Interventions and Complications clinical trial. Eleven machine learning algorithms were applied to twenty-two readily available features from T1D patients’ routine check-ups and self-assessments to develop 10-year CKD risk prediction models. In addition, we also proposed a heterogeneous ensemble model (STK) using a stacking generalization approach. The models’ performance was evaluated using different evaluation metrics and repeated stratified k-fold cross-validation. Several predictive models showed reliable performance in CKD risk prediction, with the proposed ensemble model being the best performing with an average accuracy of 0.97, specificity of 0.98, sensitivity/recall of 0.96, precision of 0.98, F1 score of 0.97, Kappa and MCC score of 0.94, AUROC of 0.99, and Precision-Recall curve of 0.99. The proposed machine learning approach could be applicable for CKD risk prediction in T1D patients to ensure the necessary precautions to overcome the risk.},
  archive      = {J_NCA},
  author       = {Chowdhury, Md Nakib Hayat and Reaz, Mamun Bin Ibne and Ali, Sawal Hamid Md and Crespo, María Liz and Cicuttin, Andrés and Ahmad, Shamim and Haque, Fahmida and Bakar, Ahmad Ashrif A. and Razak, Mohd Ibrahim Bin Shapiai Abd and Bhuiyan, Mohammad Arif Sobhan},
  doi          = {10.1007/s00521-024-09959-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16545-16565},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning algorithms for predicting the risk of chronic kidney disease in type 1 diabetes patients: A retrospective longitudinal study},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time and fixed-time function projective
synchronization of competitive neural networks with noise perturbation.
<em>NCA</em>, <em>36</em>(26), 16527–16543. (<a
href="https://doi.org/10.1007/s00521-024-09885-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, finite-time and fixed-time function projective synchronization of competitive neural networks with time-varying delays and noise perturbation is studied. Firstly, different from the existing papers, a more flexible Lyapunov function is constructed based on p-norm and two hybrid controllers are designed in this paper. Secondly, based on the finite-time and fixed-time stability theory and stochastic analysis theory, some new and useful finite-time and fixed-time function projective synchronization criteria are obtained. Furthermore, the settling time is derived with the help of some lemmas and mathematical inequalities under the appropriate control scheme. Finally, illustrative examples are given to show the feasibility of the proposed method.},
  archive      = {J_NCA},
  author       = {Hao, Caiqing and Wang, Baoxian and Tang, Dandan},
  doi          = {10.1007/s00521-024-09885-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16527-16543},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time and fixed-time function projective synchronization of competitive neural networks with noise perturbation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Soil volumetric water content prediction using unique hybrid
deep learning algorithm. <em>NCA</em>, <em>36</em>(26), 16503–16525. (<a
href="https://doi.org/10.1007/s00521-024-09991-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soil volumetric water content (VWC) is one of the key factors in hydrological cycles and responsible for inducing droughts and floods. Therefore, the precise prediction of VWC is crucial for the effective management of water resources. However, the complexity in structural characteristics and interaction with several other external meteorological factors cause difficulty in establishing a mathematical model which can predict soil VWC accurately. This study demonstrates the applicability of Convolution Neural Network-Long short-term memory (CNN-LSTM) hybrid model to predict soil VWC (%), concentrating specifically on optimizing the predictors combination using recursive feature elimination (RFE) which results in a more interpretable model with less complexity. The model was developed using the data collected from Benton County of Washington, USA, and generalization capacity of the model was tested in other counties of Washington. To verify the improved prediction ability of the proposed model, the results were compared with the established CNN, LSTM and MLR models. The results reflected that the proposed CNN-LSTM model predicted better than the individual CNN, LSTM and MLR models for the training site as well as for the five testing sites, proving its good generalization capacity.},
  archive      = {J_NCA},
  author       = {Nath, Koustav and Nayak, P. C. and Kasiviswanathan, K. S.},
  doi          = {10.1007/s00521-024-09991-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16503-16525},
  shortjournal = {Neural Comput. Appl.},
  title        = {Soil volumetric water content prediction using unique hybrid deep learning algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recent advances in applications of machine learning in
reward crowdfunding success forecasting. <em>NCA</em>, <em>36</em>(26),
16485–16501. (<a
href="https://doi.org/10.1007/s00521-024-09886-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entrepreneurs and small businesses have increasingly used reward-based crowdfunding to raise capital for their creative projects, whose success is central to this industry. Thus, predicting the success of crowdfunding campaigns is a topic of great importance for entrepreneurs and platform managers. The literature that employs monolithic classifiers and static ensemble learning for crowdfunding success prediction are scarce. In contrast, the dynamic selection (DS) algorithm, which belongs to the ensemble learning category, deserves a particular remark since it has overcome traditional monolithic classifiers and static ensembles in many applications. This paper proposes a dynamic selection framework for reward crowdfunding prediction. DS algorithms select a competent subset of the classifier per query instance. This procedure is performed during the generalization, and the subset is composed of local experts, favoring an increase in accuracy. Fifteen machine learning models are evaluated using three metrics (accuracy, area under the ROC curve and F-score), and ensemble learning obtained better results than traditional classifiers. In particular, Meta-DES, which performs dynamic selection, obtains the best overall results among the evaluated models. Furthermore, since usually interpreting the output of ML models is considered to be very difficult due to their complex “black box” architecture, we also use Shapley additive explanations to interpret the perdition’s outputs. Among variables evaluated in our models, the textual sentiment of the mass media, the number of pledges, and the target amount of the campaign deserve a highlight when predicting the campaign’s success. The source-code and further details about the experimental analysis are available at https://github.com/las33/Crowdfunding .},
  archive      = {J_NCA},
  author       = {Cavalcanti, George D. C. and Mendes-Da-Silva, Wesley and dos Santos Felipe, Israel José and Santos, Leonardo A.},
  doi          = {10.1007/s00521-024-09886-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16485-16501},
  shortjournal = {Neural Comput. Appl.},
  title        = {Recent advances in applications of machine learning in reward crowdfunding success forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MAUNet: A max-average neural network architecture for
precipitation downscaling. <em>NCA</em>, <em>36</em>(26), 16465–16484.
(<a href="https://doi.org/10.1007/s00521-024-10012-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most operational weather and climate models carry out forecasts or simulations of atmospheric variables at low spatial resolutions, but we often need high-resolution projections of such variables. The process of mapping low-resolution projections to high-resolution projections is called spatial downscaling. This is analogous to the computer vision task of single-image super-resolution (SISR). In recent studies, convolution-based architectures including UNet and its variants have emerged as a good choice for SISR. Since the gridded spatial map of any climate variable is analogous to an image, we can use the SISR-based models for spatial downscaling. In this paper, we present a novel UNet-based architecture called max-average UNet (MAUNet) to downscale the precipitation. We have proposed Max-Average Units (MAUs) that include a max-pooling, an average-pooling, and an averaging unit for the encoding part of the UNet. For the decoding part, we develop UpSampler Unit (USU), which too utilizes averaging. We demonstrate the importance of max-averaging units through toy experiments on the MNIST and CelebA dataset. We also examine the role of dropouts for this task and experimentally demonstrate their skill to improve the model’s performance on different datasets. The task examined here is to obtain fourfold resolution enhancement of monsoon precipitation over the Indian landmass and also over Southeast Continental USA (CONUS) region. The models are evaluated using RMSE, PSNR, MSSIM, and correlation coefficient as evaluation matrices. We have made detailed comparisons to show that MAUNet can produce superior downscaling than standard interpolation techniques as well as previously used deep learning models like UNet, EDSR, and SRDRN.},
  archive      = {J_NCA},
  author       = {Mishra Sharma, Sumanta Chandra and Mitra, Adway},
  doi          = {10.1007/s00521-024-10012-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16465-16484},
  shortjournal = {Neural Comput. Appl.},
  title        = {MAUNet: A max-average neural network architecture for precipitation downscaling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional adversarial segmentation and deep learning
approach for skin lesion sub-typing from dermoscopic images.
<em>NCA</em>, <em>36</em>(26), 16445–16463. (<a
href="https://doi.org/10.1007/s00521-024-09964-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic skin lesion subtyping is a crucial step for diagnosing and treating skin cancer and acts as a first level diagnostic aid for medical experts. Although, in general, deep learning is very effective in image processing tasks, there are notable areas of the processing pipeline in the dermoscopic image regime that can benefit from refinement. Our work identifies two such areas for improvement. First, most benchmark dermoscopic datasets for skin cancers and lesions are highly imbalanced due to the relative rarity and commonality in the occurrence of specific lesion types. Deep learning methods tend to exhibit biased performance in favor of the majority classes with such datasets, leading to poor generalization. Second, dermoscopic images can be associated with irrelevant information in the form of skin color, hair, veins, etc.; hence, limiting the information available to a neural network by retaining only relevant portions of an input image has been successful in prompting the network towards learning task-relevant features and thereby improving its performance. Hence, this research work augments the skin lesion characterization pipeline in the following ways. First, it balances the dataset to overcome sample size biases. Two balancing methods, synthetic minority oversampling TEchnique (SMOTE) and Reweighting, are applied, compared, and analyzed. Second, a lesion segmentation stage is introduced before classification, in addition to a preprocessing stage, to retain only the region of interest. A baseline segmentation approach based on Bi-Directional ConvLSTM U-Net is improved using conditional adversarial training for enhanced segmentation performance. Finally, the classification stage is implemented using EfficientNets, where the B2 variant is used to benchmark and choose between the balancing and segmentation techniques, and the architecture is then scaled through to B7 to analyze the performance boost in lesion classification. From these experiments, we find that the pipeline that balances using SMOTE and uses the adversarially trained segmentation network achieves the best baseline performance of 91% classification accuracy with EfficientNet B2. Based on the scaling experiments, we find that optimal performance is reached with the B6 architecture that classifies with a 97% accuracy. Furthermore, the proposed pipeline for lesion characterization outperforms the state of the art performance on the ISIC dataset.},
  archive      = {J_NCA},
  author       = {Mirunalini, P. and Desingu, Karthik and Aswatha, S. and Deepika, R. and Deepika, V. and Jaisakthi, S. M.},
  doi          = {10.1007/s00521-024-09964-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16445-16463},
  shortjournal = {Neural Comput. Appl.},
  title        = {Conditional adversarial segmentation and deep learning approach for skin lesion sub-typing from dermoscopic images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-stream CoAtNet models for accurate breast ultrasound
image segmentation. <em>NCA</em>, <em>36</em>(26), 16427–16443. (<a
href="https://doi.org/10.1007/s00521-024-09963-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The CoAtNet deep neural model has been shown to achieve state-of-the-art performance by stacking convolutional and self-attention layers. In particular, the initial layers of CoAtNet apply efficient convolutions for extracting local features out of the input image and the initial fine-resolution feature maps. In turn, the final layers apply more cumbersome Transformers in order to extract global features from the coarse-resolution feature maps. The model’s outcome directly depends on those final global features. This paper proposes an extension of the original CoAtNet model based on the introduction of a dual stream of convolution and self-attention blocks applied at the final layers of CoAtNet. In this way, those final layers automatically aggregate both local and global features extracted from the initial feature maps. Two dual-stream topologies have been proposed and evaluated. This Dual-Stream CoAtNet model exhibits a significant improvement on the segmentation accuracy of breast ultrasound images, thus contributing to the development of more robust tumor detection methods.},
  archive      = {J_NCA},
  author       = {Zaidkilani, Nadeem and Garcia, Miguel Angel and Puig, Domenec},
  doi          = {10.1007/s00521-024-09963-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16427-16443},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual-stream CoAtNet models for accurate breast ultrasound image segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revolutionizing alzheimer’s detection: An advanced
telemedicine system integrating internet-of-things and convolutional
neural networks. <em>NCA</em>, <em>36</em>(26), 16411–16426. (<a
href="https://doi.org/10.1007/s00521-024-09859-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of Internet-of-Things (IoT)-based telemedicine systems has ushered in a new era of technology facilitating early diagnosis and prevention for distant patients. This is particularly crucial for severe illnesses such as Alzheimer&#39;s disease, encompassing memory loss and cognitive dysfunction that significantly impairs daily life, necessitating immediate medical attention. The surge in data from intelligent systems, sourced from diverse locations, has heightened complexity and diminished diagnostic accuracy. In response, this study proposes an innovative distributed learning-based classification model, leveraging a deep convolutional neural network (CNN) classifier. This model proficiently manages clinical data images from disparate sources, ensuring disease classification with high accuracy. The research introduces a novel system designed for automated Alzheimer&#39;s disease detection and healthcare delivery. Comprising two subsystems, one dedicated to Alzheimer&#39;s diagnosis with an impressive 94.91% accuracy using CNN, and another for healthcare treatment, delivering excellent results. Notably, the system is adaptable to various diseases post-training. The study emphasizes the model&#39;s robust performance, achieving an outstanding 94.91% accuracy after 200 training epochs, with a loss of 0.1158, and a validation accuracy of 96.60% with a loss of 0.0922 at training without noise and loss: 0.2938 - Accuracy: 0.8713 - val_loss: 0.2387 - val_accuracy: 0.9069 at CNN with noise. Precision, recall, and F1 scores are comprehensively presented in a classification report, underscoring the system&#39;s effectiveness in categorizing Mild Demented and Non-Demented cases. While acknowledging room for further enhancements, this study introduces a promising avenue for telemedicine systems. It significantly impacts the early diagnosis and treatment of Alzheimer&#39;s disease and related medical conditions, thereby advancing the healthcare sector and improving patients&#39; quality of life. The inclusion of these quantitative results enhances the abstract&#39;s appeal to readers, providing a clearer understanding of the study&#39;s outcomes.},
  archive      = {J_NCA},
  author       = {Massoud, Mohamed A. and El-Bouridy, Mohamed E. and Ahmed, Wael A.},
  doi          = {10.1007/s00521-024-09859-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16411-16426},
  shortjournal = {Neural Comput. Appl.},
  title        = {Revolutionizing alzheimer’s detection: An advanced telemedicine system integrating internet-of-things and convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A zeroing feedback gradient-based neural dynamics model for
solving dynamic quadratic programming problems with linear equation
constraints in finite time. <em>NCA</em>, <em>36</em>(26), 16395–16409.
(<a href="https://doi.org/10.1007/s00521-024-09762-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-based neural dynamics (GND) models are a classical algorithm for solving optimization problems, but it has non-negligible flaws in solving dynamic problems. In this study, a novel GND model, namely the zeroing feedback gradient-based neural dynamics (ZF-GND) models, is proposed based on the original GND model for tracking down the exact solution of dynamic quadratic programming problem (DQP). Further, a nonlinear projection function is designed to accelerate the convergence of the model. An upper bound on the convergence time of the ZF-GND model is rigorously defined through theoretical analysis. The superior effect of the ZF-GND model in terms of convergence is verified through comparison experiments. Finally, an application of robot motion planning is introduced to verify the practicality of the ZF-GND model.},
  archive      = {J_NCA},
  author       = {Du, Shangfeng and Fu, Dongyang and Jin, Long and Si, Yang and Li, Yongze},
  doi          = {10.1007/s00521-024-09762-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16395-16409},
  shortjournal = {Neural Comput. Appl.},
  title        = {A zeroing feedback gradient-based neural dynamics model for solving dynamic quadratic programming problems with linear equation constraints in finite time},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training neuro-fuzzy using flower pollination algorithm to
predict number of COVID-19 cases: Situation analysis for twenty
countries. <em>NCA</em>, <em>36</em>(26), 16365–16393. (<a
href="https://doi.org/10.1007/s00521-024-09697-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the number of COVID-19 cases offers a reflection of the future, and it is important for the implementation of preventive measures. The numbers of COVID-19 cases are constantly changing on a daily. Adaptive methods are needed for an effective estimation instead of traditional methods. In this study, a novel method based on neuro-fuzzy and FPA is proposed to estimate the number of COVID-19 cases. The antecedent and conclusion parameters of the neuro-fuzzy model are determined by using FPA. In other words, neuro-fuzzy training is carried out with FPA. The number of COVID-19 cases belonging to twenty countries including USA, India, Brazil, Russian, France, UK, Italy, Spain, Argentina, Germany, Colombia, Mexico, Poland, Turkey, Iran, Peru, Ukraine, South Africa, the Netherlands and Indonesia is estimated. Time series is created using the number of COVID-19 cases. Daily, weekly and monthly estimates are realized by utilizing these time series. MSE is used as the error metric. Although it varies according to the example and problem type, the best training error values between 0.000398027 and 0.0286562 are obtained. These best test error values are between 0.0005607 and 0.409867. The best training and test error values are 0.000398027 and 0.0005607, respectively. In addition to FPA, the number of cases is also predicted with the algorithms such as particle swarm optimization, harmony search, bee algorithm, differential evolution and their performances are compared. Success score and ranking are created for all algorithms. The scores of FPA for the daily, weekly and monthly forecast are 71, 77 and 62, respectively. These scores have shown that neuro-fuzzy training based on FPA is successful than other meta-heuristic algorithms for all three prediction types in the short- and medium-term estimation of COVID-19 case numbers.},
  archive      = {J_NCA},
  author       = {Baştemur Kaya, Ceren and Kaya, Ebubekir},
  doi          = {10.1007/s00521-024-09697-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16365-16393},
  shortjournal = {Neural Comput. Appl.},
  title        = {Training neuro-fuzzy using flower pollination algorithm to predict number of COVID-19 cases: Situation analysis for twenty countries},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of precipitation using wavelet-based hybrid
models considering the periodicity. <em>NCA</em>, <em>36</em>(26),
16345–16364. (<a
href="https://doi.org/10.1007/s00521-024-10006-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the application of machine learning methods in the prediction of hydrological processes such as precipitation has been widely considered. These methods can analyze large volumes of data and detect the existing trends and patterns. Therefore, in the present study, machine learning methods, including random forests (RF), Kstar algorithm and Gaussian process regression (GPR), were used to predict the precipitation of Sindh River basin in India during period of 1901 to 2020. In the next step, three distinct input scenarios include (i) using monthly precipitation data and considering the memory of time series up to 5 months delay, (ii) adding periodic term to the first scenario inputs and (iii) decomposing the data using the Daubechies 4 wavelet function and creating hybrid wavelet-learning machine (W-ML) models, were prepared and introduced to the models. The performance of each method was evaluated using the root mean square error (RMSE), mean absolute error (MAE), Kling–Gupta efficiency score (KGE) and Willmott index (WI). The results showed that single models with the first scenario inputs (without taking into account the periodicity of the data) did not have good accuracy, but by adding the periodicity, the performance of these models was significantly improved, and the average value of KGE index for all studied stations increased from 0.466 to 0.672. It was also found that the GPR model for all stations could not have good performance and RF and Kstar models are the most appropriate methods for predicting precipitation in the Sindh River basin, respectively. With the application of the third scenario and the development of W-ML hybrid models, the accuracy of precipitation forecasting was significantly improved, especially the maximum precipitation values were estimated with higher accuracy than standalone models.},
  archive      = {J_NCA},
  author       = {Ahmadi, Farshad and Mirabbasi, Rasoul and Kumar, Rohitashw and Gajbhiye, Sarita},
  doi          = {10.1007/s00521-024-10006-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16345-16364},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of precipitation using wavelet-based hybrid models considering the periodicity},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging intent–entity relationships to enhance semantic
accuracy in NLU models. <em>NCA</em>, <em>36</em>(26), 16331–16344. (<a
href="https://doi.org/10.1007/s00521-024-09927-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural Language Understanding (NLU) components are used in Dialog Systems (DS) to perform intent detection and entity extraction. In this work, we introduce a technique that exploits the inherent relationships between intents and entities to enhance the performance of NLU systems. The proposed method involves the utilization of a carefully crafted set of rules that formally express these relationships. By utilizing these rules, we effectively address inconsistencies within the NLU output, leading to improved accuracy and reliability. We implemented the proposed method using the Rasa framework as an NLU component and used our own conversational dataset AWPS to evaluate the improvement. Then, we validated the results in other three commonly used datasets: ATIS, SNIPS, and NLU-Benchmark. The experimental results show that the proposed method has a positive impact on the semantic accuracy metric, reaching an improvement of 12.6% in AWPS when training with a small amount of data. Furthermore, the practical application of the proposed method can easily be extended to other Task-Oriented Dialog Systems (T-ODS) to boost their performance and enhance user satisfaction.},
  archive      = {J_NCA},
  author       = {Albornoz-De Luise, Romina Soledad and Arevalillo-Herráez, Miguel and Wu, Yuyan},
  doi          = {10.1007/s00521-024-09927-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16331-16344},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging intent–entity relationships to enhance semantic accuracy in NLU models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive machine learning approaches for perovskites
properties using their chemical formula: Towards the discovery of stable
solar cells materials. <em>NCA</em>, <em>36</em>(26), 16319–16329. (<a
href="https://doi.org/10.1007/s00521-024-09992-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, notable progress in computational density functional theory (DFT) has facilitated the collection of extensive datasets in the field of materials science. Machine learning is a crucial technique for effectively processing and analyzing these large datasets and accelerating the creation of new compounds. In this work, we employ the Extreme Gradient Boosting (XGBoost) classification algorithm to predict the crystal structure of 381 halides and oxide perovskites using 78 features. We achieved a classification accuracy of 76.62% for these materials. Subsequently, we utilized the Random Forest and XGBoost algorithms to investigate a dataset comprising 761 perovskite materials from the material project database to predict the band gap energy (best accuracy = 84.78%, mean absolute error(MAE) = 0.410 eV, root mean square error (RMSE) = 0.594 eV) and formation energy (best accuracy = 94.81%, MAE = 0.083 eV/atom, RMSE = 0.157 eV/atom), all of these prediction results based on the chemical formulas. Notably, the feature importance analysis shows the significant influence of the number of d electrons in the d orbit of the B atom on both band gap (Eg) and formation energy (EF) properties. Finally, we applied our prediction model to identify stable perovskite solar cells, achieving an accuracy of 85.18%. These findings provide valuable guidelines for the discovery of stable perovskite solar cells and help researchers tailor the composition of perovskite materials to optimize their light-harvesting capabilities, leading to higher-power conversion efficiencies.},
  archive      = {J_NCA},
  author       = {Touati, Soundous and Benghia, Ali and Hebboul, Zoulikha and Lefkaier, Ibn Khaldoun and Kanoun, Mohammed Benali and Goumri-Said, Souraya},
  doi          = {10.1007/s00521-024-09992-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16319-16329},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive machine learning approaches for perovskites properties using their chemical formula: Towards the discovery of stable solar cells materials},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated heart disease prediction using improved
explainable learning-based technique. <em>NCA</em>, <em>36</em>(26),
16289–16318. (<a
href="https://doi.org/10.1007/s00521-024-09967-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease (HD) stands as a major global health challenge, being a predominant cause of death and demanding intricate and costly detection methods. The widespread impact of heart failure, contributing to increased rates of morbidity and mortality, underscores the urgency for accurate and timely prediction and diagnosis. This is crucial for effective prevention, early detection, and treatment, thereby reducing the threat to individual health. However, the early and precise prediction of HD remains a significant challenge. The complexity of medical data poses a considerable challenge for healthcare professionals, who are required to interpret and utilize this information swiftly for effective intervention. Addressing this gap, our study introduces a novel Improved Explainable Learning-Based Technique (IELBT) for HD prediction. This technique harnesses a strategic combination of feature selection, Venn diagrams, data normalization methods, optimized parameters, and machine learning algorithms, specifically tailored for predicting HD. We evaluated the performance of our model using the Alizadeh Sani HD dataset, aiming to accurately detect the presence or absence of the condition. Our results demonstrate that the IELBT, employing a support vector machine with a robust scaling approach, optimal parameterization, and a data split ratio of 70:30, achieves an impressive accuracy rate of 96.00%. Beyond achieving high accuracy, the IELBT outperforms similar models in existing literature and provides significant interpretability and explanation, essential elements in the field of medical diagnosis.},
  archive      = {J_NCA},
  author       = {Bizimana, Pierre Claver and Zhang, Zuping and Hounye, Alphonse Houssou and Asim, Muhammad and Hammad, Mohamed and El-Latif, Ahmed A. Abd},
  doi          = {10.1007/s00521-024-09967-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16289-16318},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated heart disease prediction using improved explainable learning-based technique},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FEDAF: Frequency enhanced decomposed attention free
transformer for long time series forecasting. <em>NCA</em>,
<em>36</em>(26), 16271–16288. (<a
href="https://doi.org/10.1007/s00521-024-09937-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long time series forecasting (LTSF), which involves modeling relationships within long time series to predict future values, has extensive applications in domains such as weather forecasting, financial analysis, and traffic prediction. Recently, numerous transformer-based models have been developed to address the challenges in LTSF. These models employ methods such as sparse attention to alleviate the inefficiencies associated with the attention mechanism and utilize decomposition architecture to enhance the predictability of the series. However, these complexity reduction methods necessitate additional calculations, and the series decomposition architecture overlooks the random components. To overcome these limitations, this paper proposes the Frequency Enhanced Decomposed Attention Free Transformer (FEDAF). FEDAF introduces two variants of the Frequency Enhanced Attention Free Mechanism (FEAFM), namely FEAFM-s and FEAFM-c, which seamlessly replace self-attention and cross-attention. Both variants perform calculations in the frequency domain without incurring additional costs, with the time and space complexity of FEAFM-s being $$\mathcal {O}(L{\text {log}}L)$$ . Additionally, FEDAF incorporates a time series decomposition architecture that considers random components. Unlike other models that solely decompose the series into trend and seasonal components, FEDAF also eliminates random terms by applying Fourier denoising. Our study quantifies data drift and validates that the proposed decomposition structure can mitigate the adverse effects caused by data shift. Overall, FEDAF demonstrates superior forecasting performance compared to state-of-the-art models across various domains, achieving a remarkable improvement of 19.49% for Traffic in particular. Furthermore, an efficiency analysis reveals that FEAFM enhances space efficiency by 12.8% compared to the vanilla attention mechanism and improves time efficiency by 43.63% compared to other attention mechanism variants.},
  archive      = {J_NCA},
  author       = {Yang, Xuekang and Li, Hui and Huang, Xiang and Feng, Xingyu},
  doi          = {10.1007/s00521-024-09937-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16271-16288},
  shortjournal = {Neural Comput. Appl.},
  title        = {FEDAF: Frequency enhanced decomposed attention free transformer for long time series forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal sizing of a proposed stand-alone hybrid energy
system in a remote region of southwest egypt applying different
meta-heuristic algorithms. <em>NCA</em>, <em>36</em>(26), 16251–16269.
(<a href="https://doi.org/10.1007/s00521-024-09902-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid energy system (HES) is considered a solution to the energy supply issue, particularly in rural areas to achieve their sustainable development goals. The rise in energy consumption has increased the appeal of renewable resources, because of their potential to supply consumers with competitive, carbon-free electricity. This paper suggests strategies for managing energy and the most recently published optimizers for designing a stand-alone HES positioned in a remote region of southwest Egypt. This HES includes two green energy sources (wind and solar) and a storage system for energy (battery) as the first backup in addition to a second backup (diesel). The most recent sizing techniques employing the Chernobyl disaster optimizer, dynamic control cuckoo search (DCCS), and gold rush optimizer have been suggested to obtain the optimal design of the utilized HES. Furthermore, an in-depth evaluation of the applied optimization approaches has been achieved based on a comparative study. A detailed analysis of the studied algorithms aims to identify the optimum algorithm that provides the lowest possible cost at the highest level of reliability for the proposed HES. The simulation results verified that, the DCCS algorithm outperformed other algorithms, indicating its potential for achieving promising solutions.},
  archive      = {J_NCA},
  author       = {Abdelsattar, Montaser and Mesalam, Abdelgayed and Diab, Ahmed A. Zaki and Fawzi, Abdelrahman and Hamdan, I.},
  doi          = {10.1007/s00521-024-09902-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16251-16269},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal sizing of a proposed stand-alone hybrid energy system in a remote region of southwest egypt applying different meta-heuristic algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computationally efficient LC-SCS deep learning model for
breast cancer classification using thermal imaging. <em>NCA</em>,
<em>36</em>(26), 16233–16250. (<a
href="https://doi.org/10.1007/s00521-024-09968-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning applications have witnessed significant advancements across diverse domains, revolutionizing tasks such as image recognition, disease classification, cancer detection, natural language processing, and autonomous decision-making. However, striking a balance between performance and cost remains a fundamental challenge. Performance, which encompasses accuracy, efficiency, and effectiveness, is crucial for the real-world applicability of deep learning models. Attaining high performance often involves using resource-intensive models with intricate architectures, extensive datasets, and hyperparameter tuning. While these factors lead to improved performance, they also result in increased costs, including computational resources, time, and energy consumption. This research addresses this challenge by proposing a novel low-cost deep learning model based on Sharpened Cosine Similarity (LC-SCS) for breast cancer classification using thermal images. In our study on a DMR-IR dataset, we also utilized pre-trained models: ResNet-101, VGG-16, Inception-V3, ResNet-50, VGG-19, and Xception. The proposed LC-SCS model achieved an impressive accuracy of 94%, trailing just 4% behind the leading VGG-19 model, while maintaining a low computational cost. It achieved recall and precision scores of 0.95 each, with an F1-score of 0.94. The LC-SCS model excels in computational efficiency, demanding only 1.85 GFLOPs and 1.2 million parameters. The memory requirement is minimal at 865.35 MB, and it exhibits a latency of just 0.003 s. Additionally, the CPU execution time for prediction is 3.59 s. Comparatively, the best-performing pre-trained VGG-19 model achieved 98% accuracy but incurred significantly higher costs. The proposed LC-SCS model showcases a remarkable 298.63 times reduction in GFLOPs, a 116.31 times reduction in total parameters, a 4.57 times reduction in memory requirements for model weights, a 5 times reduction in latency, and a 3.33 times reduction in CPU execution time for prediction, thus making it as an exceptionally resource-efficient model, particularly in scenarios with limited computational resources.},
  archive      = {J_NCA},
  author       = {Nissar, Iqra and Alam, Shahzad and Masood, Sarfaraz},
  doi          = {10.1007/s00521-024-09968-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16233-16250},
  shortjournal = {Neural Comput. Appl.},
  title        = {Computationally efficient LC-SCS deep learning model for breast cancer classification using thermal imaging},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrector LSTM: Built-in training data correction for
improved time-series forecasting. <em>NCA</em>, <em>36</em>(26),
16213–16231. (<a
href="https://doi.org/10.1007/s00521-024-09962-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional recurrent neural networks (RNNs) are essential for processing time-series data. However, they function as read-only models, lacking the ability to directly modify the data they learn from. In this study, we introduce the corrector long short-term memory (cLSTM), a Read &amp; Write LSTM architecture that not only learns from the data but also dynamically adjusts it when necessary. The cLSTM model leverages two key components: (a) predicting LSTM’s cell states using Seasonal Autoregressive Integrated Moving Average (SARIMA) and (b) refining the training data based on discrepancies between actual and forecasted cell states. Our empirical validation demonstrates that cLSTM surpasses read-only LSTM models in forecasting accuracy across the Numenta Anomaly Benchmark (NAB) and M4 Competition datasets. Additionally, cLSTM exhibits superior performance in anomaly detection compared to hierarchical temporal memory (HTM) models.},
  archive      = {J_NCA},
  author       = {Baghoussi, Yassine and Soares, Carlos and Mendes-Moreira, João},
  doi          = {10.1007/s00521-024-09962-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16213-16231},
  shortjournal = {Neural Comput. Appl.},
  title        = {Corrector LSTM: Built-in training data correction for improved time-series forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time invasive sea lamprey detection using machine
learning classifier models on embedded systems. <em>NCA</em>,
<em>36</em>(26), 16195–16212. (<a
href="https://doi.org/10.1007/s00521-024-09897-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invasive sea lamprey (Petromyzon marinus) has historically inflicted considerable economic and ecological damage in the Great Lakes and continues to be a major threat. Accurately monitoring sea lampreys are critical to enabling the deployment of more targeted and effective control measures to minimize the impact associated with this species. This paper presents the first stand-alone system for real-time detection of sea lamprey attachment on underwater surfaces through the use of classifier models deployed on a microcontroller system. A range of low-complexity models was explored: single-layer artificial neural networks, logistic regression, Gaussian Naive-Bayes, decision trees, random forest, and Scalable, Efficient, and Fast classifieR (SEFR). Threshold models tuned using a multi-objective optimization formulation were also considered. Classifier models were trained with a dataset generated through live animal testing and presented accuracies between 80 and 86%. The models were deployed on an Arduino microcontroller platform and compared in classification accuracy, detection performance, time complexity, and memory size using real-time detection testing. Classification accuracies between 65 and 75% were observed during validation. Models demonstrated good capture rates for lamprey attachments (63–85%), and average detection delays ranging from 9 to 36 s. A video demonstrating the operation of the system during a real-time validation test is also included in this work. While there is room for improving the accuracy of the system, this research presents the first step toward an electronic sea lamprey monitoring system that can provide a detailed view of sea lamprey activity enhancing control and conservation efforts across its entire range.},
  archive      = {J_NCA},
  author       = {González-Afanador, Ian and Chen, Claudia and Morales-Torres, Gerardo and Meihls, Scott and Shi, Hongyang and Tan, Xiaobo and Sepúlveda, Nelson},
  doi          = {10.1007/s00521-024-09897-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16195-16212},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time invasive sea lamprey detection using machine learning classifier models on embedded systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ABES: Attention bi-directional ensemble SVM for early
detection of brain tumors. <em>NCA</em>, <em>36</em>(26), 16179–16193.
(<a href="https://doi.org/10.1007/s00521-024-09688-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor is the most serious and deadly disease, and it is formed due to abnormal cell production. There are two different sorts of tumors including benign (non-cancerous) and malignant (cancerous), and the third level of a brain tumor is cancerous, which is a highly deadly form of cancer. Detecting brain tumors early is crucial for accurate diagnosis and efficient treatment planning. Although numerous techniques are established, the prediction techniques are time-consuming, have higher computational complexity, prone to overfitting, and have limited accuracy. Thus we proposed an Attention Bi-directional Gated Recurrent Unit Ensemble Support Vector Machine (ABES model) for detecting brain tumors. Here, the Bi-GRU layer learns the most important context information for every image. The attention layer also uses the attention mechanism to assign weights to each Bi-GRU layer output. The ensemble SVM classifier performs the categorization of brain tumors. Then, the training set is used to train the Attention BiGRU model and Ensemble SVM classifiers. The ABES classifier weights are optimized by utilizing the improved whale optimization algorithm. To demonstrate the efficiency of our proposed method, we compare it to four existing methods including Fully Automatic Heterogeneous Segmentation-based Support Vector Machine, Whale Harris Hawks Optimization-based Deep Learning, Machine learning-based back propagation neural networks, and Deep Convolutional Neural Network. Also, the ABES model is validated using the MRI dataset and the Figshare brain tumor dataset. Accuracy, precision, specificity, and sensitivity are the performance metrics used to evaluate classification performance, which achieves 97.2% accuracy, 98.61% Precision, 96.48% Specificity, and 97.34% Sensitivity, respectively.},
  archive      = {J_NCA},
  author       = {Subramaniam, Erana Veerappa Dinesh and Krishnasamy, Valarmathi},
  doi          = {10.1007/s00521-024-09688-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16179-16193},
  shortjournal = {Neural Comput. Appl.},
  title        = {ABES: Attention bi-directional ensemble SVM for early detection of brain tumors},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Alternate inference-decision reinforcement learning with
generative adversarial inferring for bridge bidding. <em>NCA</em>,
<em>36</em>(26), 16163–16177. (<a
href="https://doi.org/10.1007/s00521-024-09860-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contract bridge is a competitive-cooperative multiplayer game. In the bidding phase, the decision-making process is complex, given the extensive range of inaccessible information from the partner and opponents. Inferring partner private information seems to be a viable way to promote cooperation. However, extant research has neglected the reliability and effective utilization of inferred information, consequently limiting adaptability in the face of unpredictable policies and hidden hands of opponents. This paper introduces a novel bidding decision algorithm for contract bridge, utilizing generative adversarial inferring (GAI) and alternate inference-decision reinforcement learning (AID-RL). Specifically, GAI advances the reliability and rationality of partner information inference, factoring in stochastic noises and utilizing adversarial training. Concurrently, AID-RL strengthens the effective and explicit exploitation of inference by integrating a reinforcement objective that increases decision-making payoff into the inference model training alongside the original generative objective. Moreover, a novel self-play approach, augmented by the counterfactual difference reward (CDR) mechanism is proposed to expedite policy updates and ensure robust decision-making against inference biases and unknown opponents. Empirical results demonstrate the superior performance of our algorithm, attaining a noteworthy victory of + 0.359 IMPs against Wbridge5, outperforming EPNN and SiB + 0.596 and + 0.062 IMPs.},
  archive      = {J_NCA},
  author       = {Wang, Jiao and Wang, Shijia and Xu, Tao},
  doi          = {10.1007/s00521-024-09860-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16163-16177},
  shortjournal = {Neural Comput. Appl.},
  title        = {Alternate inference-decision reinforcement learning with generative adversarial inferring for bridge bidding},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EAMultiRes-DSPP: An efficient attention-based multi-residual
network with dilated spatial pyramid pooling for identifying plant
disease. <em>NCA</em>, <em>36</em>(26), 16141–16161. (<a
href="https://doi.org/10.1007/s00521-024-09835-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have made substantial contributions to the domain of plant disease diagnosis, attaining noteworthy levels of accuracy. The primary objective of this study is to enhance the capabilities of CNNs within this particular field. In this article, we suggest a unique strategy utilizing MultiRes blocks and attention mechanisms to enhance the classification performance of CNNs for plant diseases. Our solution involves stacking four MultiRes blocks, each of which gradually increases the number of filters to prevent excessive propagation of memory requirements to deeper network nodes. In order to collect more spatial information, we also implement a residual link and a 1 $$\times $$ 1 convolutional layer. After each MultiRes block, we employ a Convolutional Block Attention Module to emphasize vital information and decrease redundant noise by inferring attention mappings along the channel and spatial dimensions. Finally, our method includes the use of a Dilated Spatial Pyramid Pooling module which is designed to extract information from the input image at various scales. Our evaluation leveraged a comprehensive dataset compiled from multiple sources, including the New Plant Diseases Dataset, Corn Dataset, and Coffee Dataset, encompassing a wide range of plant leaves both healthy and diseased, across various classes. This diverse collection of images, augmented by several techniques to enhance data variance and model robustness, provided a solid foundation for assessing the performance of our proposed model. Experiments demonstrate that this method outperforms conventional machine learning techniques and delivers high classification accuracy for plant diseases, with a precision of 99.34%, recall of 99.25%, f1-score of 99.29%, and accuracy of 99.35%. Our proposed model has the potential to considerably enhance the effectiveness and efficiency of diagnosing plant diseases in the agricultural industry.},
  archive      = {J_NCA},
  author       = {Al-Gaashani, Mehdhar S. A. M. and Muthanna, Ammar and Chelloug, Samia Allaoua and Kumar, Neeraj},
  doi          = {10.1007/s00521-024-09835-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16141-16161},
  shortjournal = {Neural Comput. Appl.},
  title        = {EAMultiRes-DSPP: An efficient attention-based multi-residual network with dilated spatial pyramid pooling for identifying plant disease},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transfer-learning-based robust technique for multi-type
fault detection and classification using hilbert–huang transform in
low-voltage power distribution grids. <em>NCA</em>, <em>36</em>(26),
16125–16139. (<a
href="https://doi.org/10.1007/s00521-024-10007-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the authors present a new transfer-learning-based robust technique for detection and classification of multi-type faults in low-voltage power distribution grids. Three-phase current and voltage signals were initially measured and sampled at a medium-voltage/low-voltage substation upon occurrence of a certain type of fault. Subsequently, a Hilbert–Huang transform was applied to the corresponding sampled fault signals to construct a time–frequency energy matrix as a $$35 \times 35$$ pixel matrix of the digital image after passing through a band-pass filter. Additionally, and for the sake of comprehensiveness, a residual network (ResNet) was designed as a fault detector and classifier to accurately identify the location and type of faults, while guaranteeing the robustness of the proposed technique against both white and connection noises. For the sake of evaluation, a three-phase 10 kV test system was implemented in the MATLAB/Simulink environment under different faulty operating conditions designs. The performance of the introduced technique was also examined in the Python environment. Based on simulation results, several conclusions can be drawn: (i) The ResNet outshines the neural architecture search network, Inception, and Xception by elevating the average accuracy by 2.23%; (ii) the ResNet-101 model is robust against white Gaussian noise and electromagnetic interference with values of 20, 30, and 40 dB; (iii) the proposed technique enhances functional coverage up to a radius of 30 km for fault detection along 14 points in the test system; and (iv) in the presence of distributed energy resources, the proposed technique is superior to other network architectures with an average of 5.44%.},
  archive      = {J_NCA},
  author       = {Rasouli-Eshghabad, Jalal and Shivaie, Mojtaba and Weinsier, Philip D.},
  doi          = {10.1007/s00521-024-10007-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16125-16139},
  shortjournal = {Neural Comput. Appl.},
  title        = {A transfer-learning-based robust technique for multi-type fault detection and classification using Hilbert–Huang transform in low-voltage power distribution grids},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive models for treated clayey soils using waste
powdered glass and expanded polystyrene beads using regression analysis
and artificial neural network. <em>NCA</em>, <em>36</em>(26),
16097–16123. (<a
href="https://doi.org/10.1007/s00521-024-09919-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waste materials contribute to a wide range of environmental and economic problems. To minimize their effects, a safe strategy for reducing such negative impact is required. Recycling and reusing waste materials have proved to be effective measures in this respect. In this study, an eco-friendly treatment is investigated based on using waste powdered glass (WGP) and EPS beads (EPSb) as mechanical and chemical admixers in soils. For this purpose, Atterberg limit, standard proctor, free swell, and unconfined compression tests are performed on soil samples with different ratios of waste materials at their optimum moisture contents. The obtained test results indicate that adding WGP to cohesive soils increases the unconfined compressive strength (UCS) and reduces free swell (FS). In contrast, using EPSb reduces both FS and UCS of the treated soil samples. An optimum combination of both waste materials is determined for the improvement of the properties of high plasticity clay used in this study. Furthermore, multiple linear regression (MLR) and artificial neural network (ANN) methods are used to predict the FS and UCS of the clayey soils based on the data obtained here and the experimental test results reported in the literature. Once the FS and UCS values of untreated soil and additive percentages are defined as independent variables, both methods are shown to predict the FS and UCS values of the treated soil samples on a satisfactory level with the coefficient of correlation ( $${R}^{2}$$ ) values greater than 0.926. Additionally, when only the index properties (liquid limit, plastic limit, and plasticity index) of the soil samples with waste materials are used as dependent variables, the $${R}^{2}$$ values obtained by the ANN method are 0.968 and 0.974 for FS and UCS, respectively. The results of the untreated soil samples&#39; FS and UCS tests are known, and the linear regression and ANN techniques yield similar results. Lastly, the ANN method is used to predict the FS and UCS of the treated samples in accordance to the limited predictors (e.g., only the Atterberg limits of the soil sample).},
  archive      = {J_NCA},
  author       = {Akis, E. and Cigdem, O. Y.},
  doi          = {10.1007/s00521-024-09919-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16097-16123},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive models for treated clayey soils using waste powdered glass and expanded polystyrene beads using regression analysis and artificial neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive change point detection for heterogeneous data.
<em>NCA</em>, <em>36</em>(26), 16071–16096. (<a
href="https://doi.org/10.1007/s00521-024-09846-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An unsupervised change point detection (CPD) framework assisted by a predictive machine learning model called “Predict and Compare” is introduced which is able to detect change points online under the presence of non-trivial trend patterns which must be prevented from triggering false positives. Different predictive models for the required time series forecasting (Predict) step together with different statistical tests for deciding about the proximity of predicted and actual data (Compare step) are allowed. Its performance is shown for the Predict step being carried out by either an LSTM recursive neural network or an ARIMA linear time series model together with the CUSUM rule as Compare step method. It shows to perform best in comparison to several other online CPD methods for detect times in the regime of low numbers of false positive detections. The method’s good performance is based on its ability to detect structural changes in the presence complex underlying trend patterns. The use case concerns tribological wear for which change points separating the run-in, steady-state, and divergent wear phases are detected.},
  archive      = {J_NCA},
  author       = {Glock, Anna-Christina and Sobieczky, Florian and Fürnkranz, Johannes and Filzmoser, Peter and Jech, Martin},
  doi          = {10.1007/s00521-024-09846-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16071-16096},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive change point detection for heterogeneous data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed performance adaptive fuzzy output feedback
control for steer-by-wire vehicle system with intermittent actuator
faults. <em>NCA</em>, <em>36</em>(26), 16057–16070. (<a
href="https://doi.org/10.1007/s00521-024-09797-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a finite-time adaptive fuzzy prescribed performance fault-tolerant control (FTC) issue for the steer-by-wire vehicle (SBWV) systems with intermittent actuator faults. Different from the steer-by-wire (SBW) system studied by the previous literatures, the SBWV system involved in this study consists of a vehicle dynamics model and an SBW system, including unmeasurable states and unknown nonlinear dynamics. Fuzzy logic systems (FLSs) are first used to identify the unknown model dynamics, and a fuzzy state observer is constructed to estimate the unmeasured states. Then, to compensate for the influence of intermittent actuator faults, a novel finite-time output-feedback prescribed performance adaptive FTC scheme is developed by using the adaptive backstepping control methodology and co-designing the last virtual controller. The presented control scheme not only guarantees that all signals of the closed-loop system are bounded in the presence of actuator faults, but also ensures that the tracking error converges to a small neighborhood of the zero within the prescribed performance bounded. The computer simulation and comparison results demonstrate the effectiveness of the proposed fuzzy control algorithm.},
  archive      = {J_NCA},
  author       = {Zhou, Shifeng and Li, Yongming and Tong, Shaocheng},
  doi          = {10.1007/s00521-024-09797-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16057-16070},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prescribed performance adaptive fuzzy output feedback control for steer-by-wire vehicle system with intermittent actuator faults},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training task planning-based adaptive assist-as-needed
control for upper limb exoskeleton using neural network state observer.
<em>NCA</em>, <em>36</em>(26), 16037–16055. (<a
href="https://doi.org/10.1007/s00521-024-09922-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the motivation and enthusiasm of subjects during active rehabilitation training, this paper proposes a novel training task planning-based adaptive assist-as-needed (TTP-AAAN) control algorithm for an upper limb exoskeleton. The overall controller contains an outer control loop to determine the required assistive force, and an inner control loop to drive the exoskeleton to track subject motion and to provide desired assistive force obtained from the outer control loop. In the outer control loop, a motion intention and task performance evaluation (MITPE) strategy is established to learn the motor capability of the subject. Based on the obtained evaluation result, the radius and frequency of multi-periodic trajectory tracking task, and the gain of the assistive force are adaptively adjusted by using the adaptive central pattern generator (ACPG) algorithm. Then, in the inner control loop, an asymmetric barrier Lyapunov function-based adaptive output feedback (ABLF-AOF) controller, in combination with a neural network (NN) state observer, is developed. The exoskeleton tracking errors are constrained by the asymmetric barrier Lyapunov function, and the state variables and uncertainty terms of the exoskeleton are simultaneously estimated by the NN state observer. Experiments are carried out with an upper limb exoskeleton to demonstrate the effectiveness of the proposed control strategy. The experimental results show that the developed control scheme can provide assistance and achieve task parameter adaption for the subjects with different motion patterns. In addition, the proposed controller has better training performance than task performance-based adaptive velocity assist-as-needed (AAN) controller and minimal AAN controller.},
  archive      = {J_NCA},
  author       = {Tian, Yang and Guo, Yida and Wang, Haoping and Caldwell, Darwin G.},
  doi          = {10.1007/s00521-024-09922-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16037-16055},
  shortjournal = {Neural Comput. Appl.},
  title        = {Training task planning-based adaptive assist-as-needed control for upper limb exoskeleton using neural network state observer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Position information encoding FPN for small object detection
in aerial images. <em>NCA</em>, <em>36</em>(26), 16023–16035. (<a
href="https://doi.org/10.1007/s00521-024-09917-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection in aerial images is a challenge in remote sensing. Recently, convolutional neural networks (CNNs) have succeeded by learning localized filters that embed relative spatial information but fail to detect the small objects in the aerial images for the uneven padding. Even though the padding mechanism in CNNs allows for the capture of absolute position information and ensures consistent input–output resolution, it leads to a diminishing extraction of absolute position context from the edges to the center. This results in asymmetry bias, which negatively impacts position-dependent visual tasks like small object detection, causing blind spots and misdetection. In this study, we uncover that complex-valued CNNs, capable of explicitly encoding absolute position information, can significantly enhance conventional object detection techniques. To accomplish this, we introduce the position information encoding feature pyramid network (PieFPN), which consists of a complex-valued encoder and a real-valued decoder for explicit position information encoding. Additionally, we present the general Gaussian normalization and Gaussian error linear unit for multi-variables, incorporating them into end-to-end training schemes. To utilize the ImageNet pre-trained weights, we merge PieF with traditional feature pyramid networks, allowing for seamless integration into existing object detection pipelines. Our complex-valued designs outperform their real-valued counterparts, achieving state-of-the-art results on the DOTA-v2.0 oriented object detection in aerial images dataset.},
  archive      = {J_NCA},
  author       = {Feng, Dapeng and Zhuang, Xuebin and Chen, Zhiqiang and Zhong, Shipeng and Qi, Yuhua and Chen, Hongbo and Ma, Hongjun},
  doi          = {10.1007/s00521-024-09917-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16023-16035},
  shortjournal = {Neural Comput. Appl.},
  title        = {Position information encoding FPN for small object detection in aerial images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Object search by a concept-conditioned object detector.
<em>NCA</em>, <em>36</em>(26), 16001–16021. (<a
href="https://doi.org/10.1007/s00521-024-09914-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detectors are used for searching all objects belonging to a pre-defined set of categories contained in a given picture. However, users are often not interested in finding all objects, but only those that pertain to a small set of categories or concepts. Nowadays, the standard approach to solve this task involves initially employing an object detector to identify all objects within the image, followed by refining the outcomes to retain only the ones of interest. Nevertheless, the object detector does not take advantage of the user’s prior intent that, when used, can potentially improve the detection performance of the model. This work presents a method to condition an existing object detector with the user’s intent, encoded as one or more concepts from the WordNet graph, to find just those objects of interest. The proposed approach takes advantage of existing datasets for object detection without the need for new annotations, and it allows to adapt the already existing object detector models with minor changes. The evaluation, performed on the COCO and the Visual Genome datasets considering several object detector architectures, shows that conditioning the search on concepts is actually beneficial. The code and the pre-trained model weights are released at: https://github.com/drigoni/Concept-Conditioned-Object-Detector .},
  archive      = {J_NCA},
  author       = {Rigoni, Davide and Serafini, Luciano and Sperduti, Alessandro},
  doi          = {10.1007/s00521-024-09914-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {16001-16021},
  shortjournal = {Neural Comput. Appl.},
  title        = {Object search by a concept-conditioned object detector},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A real-time multiple tunneling parameter prediction method
of TBM steady phase based on dual recurrent neural networks.
<em>NCA</em>, <em>36</em>(26), 15981–16000. (<a
href="https://doi.org/10.1007/s00521-024-09912-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the uncertainty of geological conditions during the tunneling process, advanced prediction of TBM tunneling parameters is significant for evaluating operational safety and efficiency, especially for real-time prediction of key tunneling parameters during the steady phase of TBM operation. At present, although there are studies on constructing predictive models based on machine learning algorithms, multiparameter prediction consistent with the actual tunneling process remains challenging due to the complexity of the TBM tunneling process and the numerous tunneling parameters. Therefore, this paper proposes a real-time multiple tunneling parameters prediction method of TBM steady phase based on dual recurrent neural networks. Firstly, the irregular multidimensional time series of tunneling parameters are analyzed and processed, which are divided into an idle-push phase, a rising phase, and a steady phase; secondly, the parameters of rising phase are analyzed using a recurrent neural network, and the parameters relevant for constructing a real-time prediction model are screened; then, based on the screened parameters, the Bayesian-optimized gated recurrent unit (GRU, a kind of recursive neural network) is proposed to construct a real-time prediction model for the four key tunneling parameters during the steady phase. Finally, the effectiveness and practicality of the proposed method are demonstrated by verification on real TBM tunnel datasets and comparing it with the models constructed by six commonly used machine learning algorithms. The results of this paper show that the designed prediction method is able to achieve a good combination of performance in terms of accuracy and computational time-consumption, with an average prediction accuracy of 91.1% for the four parameters for different rock grades of geology, the multiparameter prediction time for 100 samples is only 11 ms. In addition, three current similar studies using deep learning methods were compared to demonstrate the superiority of this proposal. As a method more closer to practical application, this work provides guidance for the forward-looking prediction of TBM tunneling parameters.},
  archive      = {J_NCA},
  author       = {Yu, Shuangfei and Xu, Jinchang and Hu, Jiacheng and Li, Jian and Liu, Jiabin and Chen, Haowen and Guan, Yisheng and Xu, Kun and Zhang, Tao},
  doi          = {10.1007/s00521-024-09912-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {15981-16000},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real-time multiple tunneling parameter prediction method of TBM steady phase based on dual recurrent neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flood subsidence susceptibility mapping using persistent
scatterer SAR interferometry technique coupled with novel metaheuristic
approaches from jeddah, saudi arabia. <em>NCA</em>, <em>36</em>(26),
15961–15980. (<a
href="https://doi.org/10.1007/s00521-024-09909-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient flood risk management hinges on the precise mapping and assessment of areas vulnerable to flooding. This research endeavors to advance the flood susceptibility mapping in Jeddah, Saudi Arabia by harnessing the long short-term memory (LSTM) algorithm enriched with two sophisticated metaheuristic optimizers: invasive weed optimization (IWO) and harmony search (HS). The process commenced with the utilization of synthetic aperture radar (SAR) imagery to construct a detailed flood inventory map. A comprehensive geodatabase encompassing various flood conditioning factors—encompassing lithology, land use, proximity to water bodies, hydrologic soil group (HSG), topographical features (such as slope, plan curvature, and aspect), and hydrological indices [including profile curvature, Topographic Wetness Index (TWI), flow accumulation, Topographic Position Index (TPI), altitude, Terrain Ruggedness Index (TRI), and Stream Power Index (SPI)] was meticulously curated. To develop the model, 70% of this dataset was employed, while the remaining 30% served to validate the predictive efficacy of the resultant flood susceptibility maps. These maps&#39; accuracy was quantitatively gauged through the receiver operating characteristic curve and the area under the curve (AUC) statistics. Findings reveal that the integration of LSTM with IWO and HS metaheuristic algorithms significantly enhances accuracy (LSTM-IWO: AUC = 0.900; LSTM-HS: AUC = 0.876) in comparison to the standalone LSTM approach (AUC = 0.863). The implementation of these hybrid algorithms manifests as a potent and economically viable approach for detailed geospatial modeling of flood susceptibility, providing invaluable insights to bolster flood mitigation, preparedness, and emergency response strategies.},
  archive      = {J_NCA},
  author       = {Abba, Sani I. and Al-Areeq, Ahmed M. and Ghaleb, Mustafa and Kawara, Atef Q. and Razavi-Termeh, Seyed Vahid},
  doi          = {10.1007/s00521-024-09909-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {15961-15980},
  shortjournal = {Neural Comput. Appl.},
  title        = {Flood subsidence susceptibility mapping using persistent scatterer SAR interferometry technique coupled with novel metaheuristic approaches from jeddah, saudi arabia},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time synchronization of fractional-order
complex-valued delayed neural networks with discontinuous activation
functions. <em>NCA</em>, <em>36</em>(26), 15947–15959. (<a
href="https://doi.org/10.1007/s00521-024-09904-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article concentrates on the fixed-time synchronization (FXTS) of fractional-order complex-valued delayed neural networks with discontinuous activation functions. On the basis of the nonsmooth analysis, differential inclusion theory, Lyapunov stability theorem and complex function theory, some sufficient conditions are developed to guarantee the FXTS of such system by designing a novel fractional-order complex-valued controller. The fixed-time synchronization can make up the limitation of the previous finite-time synchronization results, that is, fixed-time synchronization time relies on the parameters of controller, which is independent of initial values. Additionally, the upper limit of synchronization time is estimated accurately. Furthermore, our results improve some finite-time synchronization and fixed-time synchronization ones. Finally, the effectiveness of theoretical results is demonstrated by some numerical simulations.},
  archive      = {J_NCA},
  author       = {Ding, Zhixia and Wang, Jianhao and Li, Sai and Yang, Le and Wang, Liheng},
  doi          = {10.1007/s00521-024-09904-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {26},
  pages        = {15947-15959},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fixed-time synchronization of fractional-order complex-valued delayed neural networks with discontinuous activation functions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Retraction note: Automatic detection of respiratory arrests
in OSA patients using PPG and machine learning techniques. <em>NCA</em>,
<em>36</em>(25), 15945. (<a
href="https://doi.org/10.1007/s00521-024-10068-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Uçar, Muhammed Kürşad and Bozkurt, Mehmet Recep and Bilgin, Cahit and Polat, Kemal},
  doi          = {10.1007/s00521-024-10068-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15945},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Automatic detection of respiratory arrests in OSA patients using PPG and machine learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Linguistic hesitant intuitionistic fuzzy
decision-making method based on VIKOR. <em>NCA</em>, <em>36</em>(25),
15943. (<a href="https://doi.org/10.1007/s00521-024-10126-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yang, Wei and Pang, Yongfeng and Shi, Jiarong and Wang, Chengjun},
  doi          = {10.1007/s00521-024-10126-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15943},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Linguistic hesitant intuitionistic fuzzy decision-making method based on VIKOR},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Simplified neural network for generalized
least absolute deviation. <em>NCA</em>, <em>36</em>(25), 15941. (<a
href="https://doi.org/10.1007/s00521-024-10124-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Li, Yawei and Gao, Xingbao},
  doi          = {10.1007/s00521-024-10124-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15941},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Simplified neural network for generalized least absolute deviation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A novel construction of substitution box
for image encryption applications with gingerbreadman chaotic map and s8
permutation. <em>NCA</em>, <em>36</em>(25), 15939. (<a
href="https://doi.org/10.1007/s00521-024-10125-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Khan, Majid and Asghar, Zeeshan},
  doi          = {10.1007/s00521-024-10125-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15939},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel construction of substitution box for image encryption applications with gingerbreadman chaotic map and s8 permutation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Solutions of bagley–torvik and painlevé
equations of fractional order using iterative reproducing kernel
algorithm with error estimates. <em>NCA</em>, <em>36</em>(25), 15937.
(<a href="https://doi.org/10.1007/s00521-024-10123-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Abu Arqub, Omar and Maayah, Banan},
  doi          = {10.1007/s00521-024-10123-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15937},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Solutions of Bagley–Torvik and painlevé equations of fractional order using iterative reproducing kernel algorithm with error estimates},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Group search optimizer: A nature-inspired
meta-heuristic optimization algorithm with its results, variants, and
applications. <em>NCA</em>, <em>36</em>(25), 15935. (<a
href="https://doi.org/10.1007/s00521-024-10103-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Abualigah, Laith},
  doi          = {10.1007/s00521-024-10103-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15935},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: group search optimizer: a nature-inspired meta-heuristic optimization algorithm with its results, variants, and applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Usability feature extraction using modified
crow search algorithm: A novel approach. <em>NCA</em>, <em>36</em>(25),
15933. (<a href="https://doi.org/10.1007/s00521-024-10088-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Gupta, Deepak and Rodrigues, Joel J. P. C. and Sundaram, Shirsh and Khanna, Ashish and Korotaev, Valery and de Albuquerque, Victor Hugo C.},
  doi          = {10.1007/s00521-024-10088-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15933},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: usability feature extraction using modified crow search algorithm: a novel approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A new approach to eliminating EOG artifacts
from the sleep EEG signals for the automatic sleep stage classification.
<em>NCA</em>, <em>36</em>(25), 15931. (<a
href="https://doi.org/10.1007/s00521-024-10069-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Dursun, Mehmet and Özşen, Seral and Yücelbaş, Cüneyt and Yücelbaş, Şule and Tezel, Gülay and Küççüktürk, Serkan and Yosunkaya, Şebnem},
  doi          = {10.1007/s00521-024-10069-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15931},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A new approach to eliminating EOG artifacts from the sleep EEG signals for the automatic sleep stage classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A study on car flow organization in the
loading end of heavy haul railway based on immune clonal selection
algorithm. <em>NCA</em>, <em>36</em>(25), 15929. (<a
href="https://doi.org/10.1007/s00521-024-10086-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Jing, Yun and Zhang, Zhenhua},
  doi          = {10.1007/s00521-024-10086-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15929},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A study on car flow organization in the loading end of heavy haul railway based on immune clonal selection algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A deep learning approach on short-term
spatiotemporal distribution forecasting of dockless bike-sharing system.
<em>NCA</em>, <em>36</em>(25), 15927. (<a
href="https://doi.org/10.1007/s00521-024-10079-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ai, Yi and Li, Zongping and Gan, Mi and Zhang, Yunpeng and Yu, Daben and Chen, Wei and Ju, Yanni},
  doi          = {10.1007/s00521-024-10079-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15927},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A deep learning approach on short-term spatiotemporal distribution forecasting of dockless bike-sharing system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Research on hot-rolling steel products
quality control based on BP neural network inverse model. <em>NCA</em>,
<em>36</em>(25), 15925. (<a
href="https://doi.org/10.1007/s00521-024-10071-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Xing, Shiyi and Ju, Jianguo and Xing, Jinsheng},
  doi          = {10.1007/s00521-024-10071-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15925},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Research on hot-rolling steel products quality control based on BP neural network inverse model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural algorithm for optimization of multidimensional object
controller parameters. <em>NCA</em>, <em>36</em>(25), 15907–15924. (<a
href="https://doi.org/10.1007/s00521-024-10213-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal control of multivariable systems is a complex dynamic process that minimizes the cost function to obtain the optimal control strategy. Unfortunately, for nonlinear systems, it is not possible to use the traditional linear quadratic regulator (LQR), which would be optimal over the entire range of parameter variation. The problem of nonlinear multivariable systems and their optimal control is very momentous. The solution presented in this paper is based on the application of Reinforcement Learning (RL) networks in controlling a five-degree-of-freedom overhead crane system. Additionally, unlike the classical approach, the algorithm is adapted to directly analyze tabular data of inputs and outputs of the controlled model instead of analyzing its state as feedback (model-free). Implementing the new control structure for the multivariable system improved control quality compared to the classical LQR controller with linearization at the operating point. In addition to quality, the resource indicators, which in the LQR controller are represented by the matrix R, have been significantly improved. The architecture of the neural control system is presented, ensuring that over the entire range of nonlinearity, the quality of control is preserved while reducing the cost of its resource intensity. Obtaining optimal control with reduced resources for its implementation induces a wide range of applications of such neural control in engineering systems. The effectiveness of the proposed control system has been demonstrated in simulation studies. The simulation results present the system’s excellent control performance and adaptability over the entire range of object nonlinearity. The neural algorithm resulted in significantly shorter adjustment time and better control quality with significantly less system resource consumption and increased system dynamics.},
  archive      = {J_NCA},
  author       = {Bałazy, Patryk and Lalik, Krzysztof and Knap, Paweł},
  doi          = {10.1007/s00521-024-10213-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15907-15924},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural algorithm for optimization of multidimensional object controller parameters},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Securing IIoT operations with recurrent federated
network-based enhanced local search grasshopper. <em>NCA</em>,
<em>36</em>(25), 15893–15906. (<a
href="https://doi.org/10.1007/s00521-024-10129-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of the Industrial Internet of Things (IIoT) brings about a significant improvement in the efficiency and productivity of industrial processes. The speed and accuracy of various tasks have been greatly enhanced with the utilization of IIoT which allows smoother operations and cost-effective solutions, to protect uninterrupted intrusions and avoid potential threats. This article proposes a novel recurrent federated network-based enhanced local search grasshopper (RFN-ELG) algorithm. Datasets like UNSW-NB15 and MQTT-IoT-IDS2020 datasets are employed to determine the performances of IIoT via two diverse phases, namely the data preprocessing phase as well as attack detection phase. The recurrent neural networks (RNNs) are integrated with federated learning (FL) to overcome the gradient issues during the training process. In addition to this, the hyperparameters of RNN-FL are tuned via a grasshopper optimization algorithm with a local search strategy. Accuracy, precision, recall, F1-score, and false alarm rate (FAR) are the performance metrics taken for attack detection, where accuracy attains the value of 98.1%, precision attains the value of 97.4%, recall attains the value of 96.1%, F1-score attains the value of 97.2%, and FAR attains the value of 96.1%, respectively. Therefore, the proposed RFN-ELG algorithm attains high performance in detecting the attacks in IIoT.},
  archive      = {J_NCA},
  author       = {Alassafi, Madini O.},
  doi          = {10.1007/s00521-024-10129-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15893-15906},
  shortjournal = {Neural Comput. Appl.},
  title        = {Securing IIoT operations with recurrent federated network-based enhanced local search grasshopper},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-class vulnerability prediction using value flow and
graph neural networks. <em>NCA</em>, <em>36</em>(25), 15869–15891. (<a
href="https://doi.org/10.1007/s00521-024-09819-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, machine learning models have been increasingly used to detect security vulnerabilities in software, due to their ability to achieve high performance and lower false positive rates compared to traditional program analysis tools. However, these models often lack the capability to provide a clear explanation for why a program has been flagged as vulnerable, leaving developers with little reasoning to work with. We present a new method which not only identifies the presence of vulnerabilities in a program, but also the specific type of error, considering the whole program rather than just individual functions. Our approach utilizes graph neural networks that employ inter-procedural value flow graphs, and instruction embedding from the LLVM Intermediate Representation, to predict a class. By mapping these classes to the Common Weakness Enumeration list, we provide a clear indication of the security issue found, saving developers valuable time which would otherwise be spent analyzing a binary vulnerable/non-vulnerable label. To evaluate our method’s effectiveness, we used two datasets: one containing memory-related errors (out of bound array accesses), and the other a range of vulnerabilities from the Juliet Test Suite, including buffer and integer overflows, format strings, and invalid frees. Our model, implemented using PyTorch and the Gated Graph Sequence Neural Network from Torch-Geometric, achieved a precision of 96.35 and 91.59% on the two datasets, respectively. Compared to common static analysis tools, our method produced roughly half the number of false positives, while identifying approximately three times the number of vulnerable samples. Compared to recent machine learning systems, we achieve similar performance while offering the added benefit of differentiating between classes. Overall, our approach represents a meaningful improvement in software vulnerability detection, providing developers with valuable insights to better secure their code.},
  archive      = {J_NCA},
  author       = {McLaughlin, Connor and Lu, Yi},
  doi          = {10.1007/s00521-024-09819-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15869-15891},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-class vulnerability prediction using value flow and graph neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TD-LSTM: A time distributed and deep-learning-based
architecture for classification of motor imagery and execution in EEG
signals. <em>NCA</em>, <em>36</em>(25), 15843–15868. (<a
href="https://doi.org/10.1007/s00521-024-09731-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the critical challenges in brain-computer interfaces is the classification of brain activities through the analysis of EEG signals. This paper seeks to improve the efficacy of deep learning-based rehabilitation systems, aiming to deliver superior services for individuals with physical disabilities. The research introduces the time distributed long short-term memory (TD-LSTM) framework, which incorporates an LSTM and a time distributed approach to classify brain activities. Learning in TD-LSTM is achieved by uncovering time-dependent semantic dependencies within EEG signals over time. By extracting all discriminative and relevant spatiotemporal dependencies via TD-LSTM, valuable information on different time steps in each sequence has been obtained. Time distributed approach shortens the input time series, making learning from long time series sequences easier, and the learning process of complex temporal and spatial dependencies in time series multi-channel EEG signals becomes more efficient. The main contributions in this paper can be outlined as follows: (1) implementation of brain activity binary classification of motor imagery/execution tasks using time distributed approach via RNN network for the first time, (2) evaluation of the performance and generalizability of the proposed method on four benchmark datasets, (3) dual-purpose classification which providing an efficient ways for classifying both types of motor imagery/execution brain activity. The experimental results show that the proposed method performs well compared to several baseline research works.},
  archive      = {J_NCA},
  author       = {Karimian-Kelishadrokhi, Morteza and Safi-Esfahani, Faramarz},
  doi          = {10.1007/s00521-024-09731-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15843-15868},
  shortjournal = {Neural Comput. Appl.},
  title        = {TD-LSTM: A time distributed and deep-learning-based architecture for classification of motor imagery and execution in EEG signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning cooperative strategies in multi-agent encirclement
games with faster prey using prior knowledge. <em>NCA</em>,
<em>36</em>(25), 15829–15842. (<a
href="https://doi.org/10.1007/s00521-024-09727-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent encirclement with collision avoidance constitutes a common challenge in the multi-agent confrontation domain, wherein the focus lies in the development of cooperative strategies among agents. Previous studies encountered difficulties in addressing the dynamic encirclement of faster prey in obstacles environment. This paper introduces a novel multi-agent deep reinforcement learning approach based on prior knowledge. It is dedicated to exploring the multi-agent encirclement with collision avoidance task involving slower multiple pursuers collaboratively encircling faster prey in an obstacles environment. Firstly, the utilization of the classic Apollonius circle theory as prior knowledge guides agent action selection, narrows the exploratory action space, and accelerates the learning of strategies. Subsequently, the variance descriptor restricts the motion direction of pursuers, thus ensuring that pursuers continuously narrow the encirclement until the prey is successfully encircled. Finally, experiments in an obstacles environment were conducted to validate the proposed method. The results indicate that our method can acquire an effective encirclement strategy, with an encirclement success rate exceeding that of previous methods by more than 10%, and simulation experiment results demonstrate the effectiveness and practicability of our method.},
  archive      = {J_NCA},
  author       = {Li, Tongyue and Shi, Dianxi and Wang, Zhen and Yang, Huanhuan and Chen, Yang and Shi, YanYan},
  doi          = {10.1007/s00521-024-09727-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15829-15842},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning cooperative strategies in multi-agent encirclement games with faster prey using prior knowledge},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fault-tolerant visual servo control for a robotic arm with
actuator faults. <em>NCA</em>, <em>36</em>(25), 15815–15828. (<a
href="https://doi.org/10.1007/s00521-024-09714-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study targets uncertain coupling faults in robotic arm actuators and proposes a new fault-tolerant visual servo control strategy. Specifically, it considers both multiplicative and additive actuator faults within the dynamic of the robotic arm, treating the coupling faults and time-varying disturbances as an aggregate of concentrated uncertainties. A radial basis function neural network-based state observer is introduced to online approximate these concentrated uncertainties, which include fault information, eliminating the need for prior knowledge of faults. Furthermore, a fault-tolerant controller based on a non-singular fast terminal sliding mode is proposed, which separately decouples the nominal quantities and concentrated uncertainties and develops individual adaptive control laws for each. This effectively reduces the detrimental impact of coupled faults and disturbances on the system’s performance, facilitating image feature trajectory tracking control with minimal jitter, high precision, and strong transient response capabilities. The stability of the state observer and the fault-tolerant controller has been substantiated through Lyapunov’s theory. Lastly, numerical simulations validate the efficacy and robustness of the proposed fault-tolerant visual servo control approach.},
  archive      = {J_NCA},
  author       = {Li, Jiashuai and Peng, Xiuyan and Li, Bing and Sreeram, Victor and Wu, Jiawei},
  doi          = {10.1007/s00521-024-09714-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15815-15828},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fault-tolerant visual servo control for a robotic arm with actuator faults},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time anomaly detection for “remote” bus stop
surveillance using unsupervised conditional generative adversarial
networks. <em>NCA</em>, <em>36</em>(25), 15799–15813. (<a
href="https://doi.org/10.1007/s00521-024-09911-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the imbalance between normal and abnormal samples in existing anomaly detection datasets, as well as the complexity in defining anomalies, we introduce a new dataset named Remote Stop to provide data support for existing algorithms. Concurrently, we propose an unsupervised video anomaly detection method based on conditional generative adversarial networks. Our approach trains the model to learn the distribution of normal video data, enabling it to identify anomalous events. The incorporation of a spatial attention mechanism enhances the model’s performance in detecting abnormal behaviors in video frames while maintaining high processing efficiency. Moreover, unlike other methods that assess the entire image, our approach uses overlapping image blocks to determine anomalies, enhancing the accuracy and robustness of the model in image segmentation. These innovations not only address the issues of scarce samples and high-cost labeling but also provide new perspectives and tools for video anomaly detection in the field of public safety. The effectiveness of the model was validated on the Avenue and Ped2 datasets and applied to our newly created dataset (Remote Stop), achieving an AUC of 84.3% and processing 61 video frames per second. This enables efficient sequential processing of large-scale video data, offering positive contributions to enhancing public road safety by providing early warnings and enabling timely preventive measures.},
  archive      = {J_NCA},
  author       = {Xi, Beihao and Chen, Qingkui},
  doi          = {10.1007/s00521-024-09911-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15799-15813},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time anomaly detection for ‘Remote’ bus stop surveillance using unsupervised conditional generative adversarial networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stock market index prediction using transformer neural
network models and frequency decomposition. <em>NCA</em>,
<em>36</em>(25), 15777–15797. (<a
href="https://doi.org/10.1007/s00521-024-09931-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an increasingly complex and volatile environment, government officials, researchers, and investors alike would like to possess models that accurately forecast markets in order to make appropriate decisions. This research investigates the efficacy of Transformer-based deep neural networks in predicting financial market returns compared to traditional models, focusing on ten different market indexes. The study employs a comprehensive methodology that involves iterative dropout tests and batch size optimization to enhance model performance. By leveraging the power of deep learning, the research aims to improve prediction accuracy and capture complex patterns in stock market data. Twelve neural network architectures are compared across ten indexes to measure their performance, finding that the proposed Transformer variants produce significantly better results compared to benchmark models in all cases. The results of ablative experiments reveal the superiority of Transformer models in capturing long-term dependencies and extracting meaningful features from time series data. The findings suggest that Transformer neural networks outperform LSTM networks and other traditional models in forecasting financial market trends. This research contributes to the growing body of literature on deep learning applications in finance and provides valuable insights for government officials, researchers, and investors seeking to make informed decisions in the stock market. The implications of this study extend beyond academia, offering practical implications for enhancing prediction accuracy and optimizing investment strategies in the dynamic and volatile financial market landscape.},
  archive      = {J_NCA},
  author       = {Yañez, Camilo and Kristjanpoller, Werner and Minutolo, Marcel C.},
  doi          = {10.1007/s00521-024-09931-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15777-15797},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stock market index prediction using transformer neural network models and frequency decomposition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-supervised method for digital twin-enabled predictive
maintenance in the building industry. <em>NCA</em>, <em>36</em>(25),
15759–15775. (<a
href="https://doi.org/10.1007/s00521-024-09926-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid booming of information and communication technologies (ICT) and artificial intelligence has promoted the development of maintenance practices in the building industry towards a data-driven paradigm, of which the digital twin (DT) serves as the fundamental framework to strengthen data transit ability and interoperability. Among the state-of-the-art approaches in the maintenance industry, predictive maintenance (PdM) is a prominent approach by anticipating unexpected failures and unscheduled maintenance tasks. However, most current PdM frameworks are facility-specific, lacking generality and scalability. Besides, existing solutions mainly concentrate on condition monitoring and fault identification rather than failure prediction. Moreover, good prediction results rely heavily on sufficient labelled data sets, which are costly and labour-intensive to collect. To address these issues, the author developed a unified PdM framework for the building industry from the DT perspective. Next, a novel failure prediction method utilising the Semi-supervised Generative Adversarial Network (GAN) has been proposed in this article, which makes effective utilisation of both labelled and unlabelled data. Finally, an online platform has been developed to present the monitoring and prediction information. Experimental findings show the effectiveness and superiority of the proposed method for failure prediction through public data sets of building facilities.},
  archive      = {J_NCA},
  author       = {Hu, Wei and Cai, Yiyu},
  doi          = {10.1007/s00521-024-09926-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15759-15775},
  shortjournal = {Neural Comput. Appl.},
  title        = {A semi-supervised method for digital twin-enabled predictive maintenance in the building industry},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MADMM: Microservice system anomaly detection via multi-modal
data and multi-feature extraction. <em>NCA</em>, <em>36</em>(25),
15739–15757. (<a
href="https://doi.org/10.1007/s00521-024-09918-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately detecting anomalies in microservice systems is crucial to avoid system failures and economic losses for users. Existing approaches detect anomalies by extracting sequential information from single-modal data, such as metrics or logs. However, they do not clearly analyze the temporal and spatial dependencies of each data type and ignore the correlation between different types of data, which can lead to a significant number of false positives. In this paper, we propose a novel Microservice system Anomaly Detection method via Multi-modal data and Multi-feature extraction (MADMM), which performs a joint analysis of metrics and logs from a spatial and temporal perspective. Specifically, we firstly construct separate feature graphs for metrics and logs in each time window. A graph convolution network is then utilized to capture the spatial correlation among different metrics, while a graph attention network is employed to analyze the contextual relationships among different log events. Then, we design a Cross-Modal Attention-based Gate Recurrent Unit (CMA-GRU) to capture the intricate temporal dependencies of each modal data and facilitate fulfilling cross-modal interactions. Finally, we introduce multi-grained contrastive learning methods to learn robust cross-modal features from both inter- and intra-modality aspects. Experimental results on real-world datasets demonstrate that MADMM outperforms existing baseline methods and exhibits better robustness.},
  archive      = {J_NCA},
  author       = {Wang, Peipeng and Zhang, Xiuguo and Cao, Zhiying and Chen, Zihan},
  doi          = {10.1007/s00521-024-09918-1},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15739-15757},
  shortjournal = {Neural Comput. Appl.},
  title        = {MADMM: Microservice system anomaly detection via multi-modal data and multi-feature extraction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balanced prioritized experience replay in off-policy
reinforcement learning. <em>NCA</em>, <em>36</em>(25), 15721–15737. (<a
href="https://doi.org/10.1007/s00521-024-09913-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Off-Policy reinforcement learning (RL), the experience imbalance problem can affect learning performance. The experience imbalance problem refers to the phenomenon that the experiences obtained by the agent during the learning process are unevenly distributed in the state space, resulting in the agent’s inability to accurately estimate the value of each potential state. This problem is typically caused by environments with high-dimensional state and action spaces, as well as the exploration–exploitation mechanism inherent in RL. This article proposes a balanced prioritized experience replay (BPER) algorithm based on experience rarity. First, an evaluation metric to quantify experience rarity is defined. Then, the sampling priority of each experience is calculated according to this metric. Finally, prioritized experience replay is performed according to the sampling priority. BPER increases the sampling frequency of high-rarity experiences and decreases the sampling frequency of low-rarity experiences, enabling the agent to learn more comprehensive knowledge. We evaluate BPER on a series of MuJoCo continuous control tasks. Experimental results show that BPER can effectively improve the learning performance while mitigating the impact of the experience imbalance problem.},
  archive      = {J_NCA},
  author       = {Lou, Zhouwei and Wang, Yiye and Shan, Shuo and Zhang, Kanjian and Wei, Haikun},
  doi          = {10.1007/s00521-024-09913-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15721-15737},
  shortjournal = {Neural Comput. Appl.},
  title        = {Balanced prioritized experience replay in off-policy reinforcement learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid shunted transformer embedding UNet for remote sensing
image semantic segmentation. <em>NCA</em>, <em>36</em>(25), 15705–15720.
(<a href="https://doi.org/10.1007/s00521-024-09888-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of deep learning, Remote Sensing Image (RSI) semantic segmentation has produced significant advances. However, due to the sparse distribution of the objects and the high similarity between classes, the task of semantic segmentation in RSI is still extremely challenging. In this paper, we propose a novel semantic segmentation framework for RSI called HST-UNet that can overcome the shortcomings of the existing models and extract and recover the global and local features of RSI, which is a hybrid semantic segmentation model with Shunted Transformer as encoder and Multi-Scale Convolutional Attention Network (MSCAN) as decoder. Then, to better fuse the information from the Encoder and the Decoder and alleviate the ambiguity, we design a Learnable Weighted Fusion (LWF) module to effectively connect to the decoder features. Extensive experiments demonstrate that the proposed HST-UNet outperforms the state-of-the-art methods, achieving F1 score/MIoU accuracy of 71.44%/83.00% on the ISPRS Vaihingen dataset and 77.36%/87.09% on ISPRS Potsdam dataset. The code will be available at https://github.com/HC-Zhou/HST-UNet .},
  archive      = {J_NCA},
  author       = {Zhou, Huacong and Xiao, Xiangling and Li, Huihui and Liu, Xiaoyong and Liang, Peng},
  doi          = {10.1007/s00521-024-09888-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15705-15720},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid shunted transformer embedding UNet for remote sensing image semantic segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sustainable and smart electric bus charging station
deployment via hybrid spherical fuzzy BWM and MULTIMOORA framework.
<em>NCA</em>, <em>36</em>(25), 15685–15703. (<a
href="https://doi.org/10.1007/s00521-024-09788-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to assist public bus operators in locating electric bus charging station (EBCS) facilities from a smart and sustainable view. The selection of the most suitable EBCSs from various possible candidates involves a sophisticated decision-making procedure in terms of several contradictory criteria with imprecise information. The novelty of the study resides in exploring the EBCS site selection problem with spherical fuzzy sets (SFSs), which have shown remarkable effectiveness in limiting information loss by seizing ambiguous, and uncertain data. In this regard, a novel best–worst method (BWM) incorporating Multi-objective optimization via full multiplicative form ratio analysis (MULTIMOORA) methodology in the spherical fuzzy context is proposed to choose the optimal locations for EBCSs. The integrated framework combines the adaptability of the spherical fuzzy BWM (SF-BWM) for determining the criteria weights with the convenience of spherical fuzzy MULTIMOORA (SF-MULTIMOORA) approach for ranking the alternatives. A case study for Istanbul is provided to substantiate the propounded technique and to confirm its viability and efficiency. In the course of making a decision, a four-level hierarchical structure consisting of five main and 22 sub-criteria is built and the comparison matrices are reviewed by a panel of seven experts. A sensitivity analysis is executed, and the results demonstrate that the propositioned approach produces outcomes that are quite robust and consistent. Hence, the findings of this research can benefit public bus operators in choosing the ideal sites for electric charging stations. Finally, the formulated generic methodology is also easily applicable to diverse and complex multiple-criteria problems in the spherical fuzzy domain.},
  archive      = {J_NCA},
  author       = {Deniz, Ruchan and Aydin, Nezir},
  doi          = {10.1007/s00521-024-09788-7},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15685-15703},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sustainable and smart electric bus charging station deployment via hybrid spherical fuzzy BWM and MULTIMOORA framework},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging deep learning-assisted attacks against image
obfuscation via federated learning. <em>NCA</em>, <em>36</em>(25),
15667–15684. (<a
href="https://doi.org/10.1007/s00521-024-09703-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obfuscation techniques (e.g., blurring) are employed to protect sensitive information (SI) in images such as individuals’ faces. Recent works demonstrated that adversaries can perform deep learning-assisted (DL) attacks to re-identify obfuscated face images. Adversaries are modeled by their goals, knowledge (e.g., background knowledge), and capabilities (e.g., DL-assisted attacks). Nevertheless, enhancing the evaluation methodology of obfuscation techniques and improving the defense strategies against adversaries requires considering more &quot;pessimistic” attacking scenario, i.e., stronger adversaries. According to a 2019 article published by the European Union Agency for Cybersecurity (ENISA), adversaries tend to perform more sophisticated and dangerous attacks when collaborating together. To address these concerns, our paper investigates a novel privacy challenge in the context of image obfuscation. Specifically, we examine whether adversaries, when collaborating together, can amplify their DL-assisted attacks and cause additional privacy breaches against a target dataset of obfuscated images. We empirically demonstrate that federated learning (FL) can be used as a collaborative attack/adversarial strategy to (i) leverage the attacking capabilities of an adversary, (ii) increase the privacy breaches, and (iii) remedy the lack of background knowledge and data shortage without the need to share/disclose the local training datasets in a centralized location. To the best of our knowledge, we are the first to consider collaborative and more specifically FL-based attacks in the context of face obfuscation.},
  archive      = {J_NCA},
  author       = {Tekli, Jimmy and Al Bouna, Bechara and Tekli, Gilbert and Couturier, Raphaël and Charbel, Antoine},
  doi          = {10.1007/s00521-024-09703-0},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15667-15684},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging deep learning-assisted attacks against image obfuscation via federated learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Align vision-language semantics by multi-task learning for
multi-modal summarization. <em>NCA</em>, <em>36</em>(25), 15653–15666.
(<a href="https://doi.org/10.1007/s00521-024-09908-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current multi-modal summarization methods follow a cascaded manner, where an off-the-shelf object detector is first used to extract visual features. After that, these visual features are fused with language representations for the decoder to generate the text summary. However, the cascaded way employs separate encoders for different modalities, which makes it hard to learn the joint vision and language representation. In addition, they also ignore the semantics alignment between paragraphs and images for multi-modal summarization tasks, which are crucial to a precise summary. To tackle these issues, in this paper, we propose ViL-Sum to jointly model paragraph-level Vision-Language Semantic Alignment and Multi-Modal Summarization. Our ViL-Sum contains two components for better learning multi-modal semantics and aims to align them. The first one is a joint multi-modal encoder. The other one is two well-designed tasks for multi-task learning, including image reordering and image selection. Specifically, the joint multi-modal encoder converts images into visual embeddings and attaches them with text embedding as the input of the encoder. The reordering task guides the model to learn paragraph-level semantic alignment, and the selection task guides the model to select summary-related images in the final summary. Experimental results show that our proposed ViL-Sum outperforms current state-of-the-art methods on most automatic and manual evaluation metrics. In further analysis, we find that two well-designed tasks and a joint multi-modal encoder can effectively guide the model to learn reasonable paragraph-image and summary-image relations.},
  archive      = {J_NCA},
  author       = {Cui, Chenhao and Liang, Xinnian and Wu, Shuangzhi and Li, Zhoujun},
  doi          = {10.1007/s00521-024-09908-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15653-15666},
  shortjournal = {Neural Comput. Appl.},
  title        = {Align vision-language semantics by multi-task learning for multi-modal summarization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An AI pipeline for garment price projection using computer
vision. <em>NCA</em>, <em>36</em>(25), 15631–15651. (<a
href="https://doi.org/10.1007/s00521-024-09901-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fashion industry’s traditional price-setting methods, based on historical sales and Fashion Week trends, are inadequate in the digital era. Rapid changes in collections and consumer preferences necessitate advanced Artificial Intelligence (AI) techniques. These AI methods should analyze data from various sources, including social media and e-commerce, to predict future fashion trends and prices. In this paper, we propose, apply, and assess a data analytics approach, i.e., FashionXpert, employing several image processing and machine learning techniques in an AI pipeline for garment price prediction. It integrates various heterogeneous data sources (e.g., textual and image data from e-stores, brand websites, and social media) to obtain more consistent, accurate, and beneficial information. We evaluated its effectiveness with an industrial data set obtained by a fashion search tool from the electronic commerce sites of clothing brands. FashionXpert predicted garment prices with an average Mean Absolute Error (MAE) of 15.31 EUR on a data set that has a standard deviation of 72.99 EUR.},
  archive      = {J_NCA},
  author       = {Rico Gómez, Rodrigo and Lorentz, Joe and Hartmann, Thomas and Goknil, Arda and Pal Singh, Inder and Halaç, Tayfun Gökmen and Boruzanlı Ekinci, Gülnaz},
  doi          = {10.1007/s00521-024-09901-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15631-15651},
  shortjournal = {Neural Comput. Appl.},
  title        = {An AI pipeline for garment price projection using computer vision},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification of nonlinear dynamical system based on
adaptive radial basis function neural networks. <em>NCA</em>,
<em>36</em>(25), 15617–15629. (<a
href="https://doi.org/10.1007/s00521-024-09794-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive radial basis function neural network (RBFNN) is investigated and presented for identifying the nonlinear dynamical system. In traditional RBFNN structure, the selections of the activated radius are decided by the designer’s experience to satisfy the best approximation of nonlinear dynamical function. In order to reduce the experience error, an adaptive RBFNN mechanism that can realize auto-regulation of activated radius is proposed in this paper. Taking the lattice points as the center of activated function, we use Taylor expansion to separate the factor of activated radius in local space. In order to ensure that the identification error has the property of fast convergence, the error conversion function is used for shrinking the gain in the error differential equation. Constructing a Lyapunov function to determine the differential equation of the weights and the activated radius, it is shown that the weights and the activated radius will converge to the neighborhood of its true value and the identification error will converge to neighborhood of zero in a periodic or period-like nonlinear dynamical system. To illustrate the effectiveness of the proposed adaptive RBFNN, Vanderpol and Duffing dynamical system are used as test examples, in comparison with traditional RBFNN and wavelet neural networks (WNN). The results show that the proposed method has best accurate identification and approximating effect in all of test algorithms.},
  archive      = {J_NCA},
  author       = {Luo, Guo and Min, Hu and Yang, Zhi},
  doi          = {10.1007/s00521-024-09794-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15617-15629},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identification of nonlinear dynamical system based on adaptive radial basis function neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting mortality of cancer patients using artificial
intelligence, patient data and blood tests. <em>NCA</em>,
<em>36</em>(25), 15599–15616. (<a
href="https://doi.org/10.1007/s00521-024-09915-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several authors have shown that hematological parameters can be used to detect poor prognosis in patients with cancer. Thus, such features could be used in artificial intelligence (AI-based) models to predict mortality among these patients. This work aimed to develop and compare several AI-based models to predict the prognosis (death vs. survival) of cancer in patients using blood tests and patient data as inputs. At total, 908 cancer patients were assisted in a prospective study. Four artificial intelligence models were compared: artificial neural networks (ANN), supporting vector machines (SVM), decision trees and neuro-fuzzy networks. Also, four different input strategies were tested, considering the use of 49, 45, 22 and 14 inputs. The results of this study showed that the ANN and the SVM presented the best results, using 45 inputs. The ANN was the best model since it presented better statistical values for the positive (death) and negative (survival) classes. The use of blood parameters as inputs for AI-based models could be used to predict death in patients with cancer, and this methodology can be expanded to other diseases.},
  archive      = {J_NCA},
  author       = {Martins, Tiago D. and Maciel-Filho, Rubens and Montalvão, Silmara A. L. and Gois, Gabriele S. S. and Al Bannoud, Mohamad and Ottaiano, Gabriel Y. and Anhaia, Thaizy R. A. and Almeida, Millene E. A. and Ferreira, Monique R. M. and Martinelli, Beatriz M. and Fernandes, Maria C. G. L. and Huber, Stephany C. and Ribeiro, Daniel and Teixeira, Júlio C. and Carvalheira, José B. C. and Lima, Carmen S. P. and Andreollo, Nelson A. and Etchebehere, Maurício and Zambon, Lair and Ferreira, Ubirajara and Tincani, Alfio J. and Martins, Antônio S. and Coy, Cláudio S. R. and Seabra, José C. T. and Mussi, Ricardo K. and Tedeschi, Helder and Anninchino-Bizzacchi, Joyce M.},
  doi          = {10.1007/s00521-024-09915-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15599-15616},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting mortality of cancer patients using artificial intelligence, patient data and blood tests},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DLEE: A dataset for chinese document-level legal event
extraction. <em>NCA</em>, <em>36</em>(25), 15581–15597. (<a
href="https://doi.org/10.1007/s00521-024-09907-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction (EE) is capable of providing essential information to facilitate comprehension of legal cases by identifying event types and extracting corresponding arguments from legal case documents. In the legal field, events are often presented in the form of document, with arguments scattered across multiple sentences, which means that legal EE at the document level is needed to better capture the complete event. However, the existing legal EE datasets mainly focused on event extraction at the sentence level, with little attention given to the document level. Obviously, it put the development of document-level event extraction (DEE) in the legal field at a disadvantage. To address this challenge, we proposed DLEE, the first DEE dataset in the legal field with two distinctive features: (1) Document-level Semi-automated Annotation, ensuring effective annotation with high quality. (2) Large-scale and Fine-grained coverage, comprising 10,014 events and 99,423 arguments. Finally, we assessed the performance of commonly used DEE baseline models on DLEE. It revealed that the DLEE is an open question, and further attention is needed for the improvement of the models’ performance.},
  archive      = {J_NCA},
  author       = {Xian, Guochuan and Du, Siyuan and Tang, Xi and Shi, Yuan and Jia, Bofang and Tang, Banghao and Leng, Zhefu and Li, Li},
  doi          = {10.1007/s00521-024-09907-4},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15581-15597},
  shortjournal = {Neural Comput. Appl.},
  title        = {DLEE: A dataset for chinese document-level legal event extraction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel generative corrective network structure for traffic
forecasting. <em>NCA</em>, <em>36</em>(25), 15567–15579. (<a
href="https://doi.org/10.1007/s00521-024-09906-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting plays a critical role in intelligent transportation systems aiming to accurately estimate future short-term or long-term traffic conditions. The utilization of neural network-based methods for traffic forecasting has demonstrated significant success. Those models aggregate spatial and temporal information from historical traffic records. The final output module of these models typically utilizes either a fully connected network to directly produce the results or a recurrent neural network to generate results step by step. However, these approaches fail to consider the spatial-temporal dependencies between predicted future traffic conditions, which hinders their forecasting performance. To address this limitation as well as improve forecasting accuracy, we propose a novel traffic prediction framework called the Generative Corrective Network. This framework consists of two procedures: a generative model that captures the spatial temporal relationships inherent in historical traffic condition and generates initial predictions, and a corrective model that amends and updates previous results by considering the relationships among future traffic data to be predicted. To implement this generative corrective network, we design an instantiation utilizing adaptive and dynamic graph convolutional networks with gated recurrent units networks (ADGCN-GRU) based on encoder–decoder structure for the generator, and a local asynchronous attention model conducted on the the representation learning of space and time information and the preliminary results for the corrector. Experiments conducted on two real-world traffic datasets demonstrate that our model can effectively improve forecasting performance compared to existing neural network-based methods.},
  archive      = {J_NCA},
  author       = {Xu, Chenyang and Xu, Changqing},
  doi          = {10.1007/s00521-024-09906-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15567-15579},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel generative corrective network structure for traffic forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing surrogate-assisted evolutionary optimization for
medium-scale expensive problems: A two-stage approach with unsupervised
feature learning and q-learning. <em>NCA</em>, <em>36</em>(25),
15545–15565. (<a
href="https://doi.org/10.1007/s00521-024-09903-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel two-stage progressive search approach with unsupervised feature learning and Q-learning (TSLL) to enhance surrogate-assisted evolutionary optimization for medium-scale expensive problems. The method attempts to address the challenges posed by multi-polar and multi-variable coupling properties in such problems. During the iteration, TSLL splits the optimization process into two distinct stages. First, two unsupervised feature learning techniques: principal component analysis (PCA) and Autoencoder, are utilized to improve the representation of potential optimal samples in the solution space. PCA is used for feature reduction, extracting the most important features. On the other hand, Autoencoder focuses on reconstructing features within the medium-scale solution space. To ensure comprehensive exploration of the entire solution space, TSLL employs two distinct surrogate modeling approaches along with Q-learning in the second stage to dynamically select the mutation strategy for the differential evolution operator. Numerous experiments demonstrate the superiority of TSLL over five state-of-the-art surrogate-assisted approaches and two sophisticated evolutionary algorithms including the winner of CEC 2017 on medium-scale benchmark problems and a wind farm layout problem.},
  archive      = {J_NCA},
  author       = {Gong, Yiyun and Yu, Haibo and Kang, Li and Sun, Chaoli and Zeng, Jianchao},
  doi          = {10.1007/s00521-024-09903-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15545-15565},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing surrogate-assisted evolutionary optimization for medium-scale expensive problems: A two-stage approach with unsupervised feature learning and Q-learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proposal and evaluation of new models for predicting the FRP
contribution to shear strength in reinforced concrete beams using gene
expression programming. <em>NCA</em>, <em>36</em>(25), 15515–15544. (<a
href="https://doi.org/10.1007/s00521-024-09892-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fiber-reinforced polymers (FRP) have been widely used in shear strengthening applications of reinforced concrete (RC) beams. The accurate prediction of the FRP contribution to the shear strength of beams is essential for reliable design. Gene expression programming (GEP) has been widely utilized because it reliably expresses complex relationships between experimental variables. In this study, three new GEP models are proposed for three different strengthening configurations of FRP such as fully-wrapping, U wrapping, and side-bonding to predict the FRP contribution to shear strength. These models are developed using the most comprehensive database containing a total of 811 strengthened beams (350 fully-wrapped, 328 U-wrapped, and 133 side-bonded. Many variables have been considered in the proposed GEP models, including those that have been experimentally effective but are often neglected in existing literature equations, such as the shear span-to-effective depth ratio $$(a/d)$$ and the stirrup ratio ( $${\rho }_{w}$$ ). Additionally, the reliability of existing equations in the literature and the proposed GEP models for predicting the FRP contribution to shear strength was statistically evaluated. As a result of this evaluation, the proposed GEP models for each strengthening configuration of FRP yielded the most accurate statistical results, with the lowest coefficient of variation (COV), and the highest coefficient of correlation (R).},
  archive      = {J_NCA},
  author       = {Alacali, Sema and Akkaya, Hasan Cem and Sengun, Kadir and Arslan, Guray},
  doi          = {10.1007/s00521-024-09892-8},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15515-15544},
  shortjournal = {Neural Comput. Appl.},
  title        = {Proposal and evaluation of new models for predicting the FRP contribution to shear strength in reinforced concrete beams using gene expression programming},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pied kingfisher optimizer: A new bio-inspired algorithm for
solving numerical optimization and industrial engineering problems.
<em>NCA</em>, <em>36</em>(25), 15455–15513. (<a
href="https://doi.org/10.1007/s00521-024-09879-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we introduce the pied kingfisher optimizer (PKO), a novel swarm-based meta-heuristic algorithm that draws inspiration from the distinctive hunting behavior and symbiotic relationships observed in pied kingfishers in the natural world. The PKO algorithm is structured around three distinct phases: perching/hovering for prey (exploration/diversification), diving for prey (exploitation/intensification), and fostering symbiotic relations. These behavioral aspects are translated into mathematical models capable of effectively addressing a wide array of optimization challenges across diverse search spaces. The algorithm’s performance is rigorously evaluated across thirty-nine test functions, which encompass various unimodal, multimodal, composite, and hybrid ones. Additionally, eight real-world engineering optimization problems, including both constrained and unconstrained scenarios, are considered in the assessment. To gauge PKO’s efficacy, it is subjected to a comparative analysis against 3 categories of rival optimizers. The 1st category comprises well-established and widely-cited optimizers such as particle swarm optimization and genetic algorithm. The 2nd category encompasses recently published algorithms, including Harris Hawks optimization, Whale optimization algorithm, sine cosine algorithm, Grey Wolf optimizer, gravitational search algorithm, and moth-flame optimization. The 3rd category includes advanced algorithms, such as covariance matrix adaptation evolution strategy and Ensemble Sinusoidal Differential Covariance Matrix Adaptation with Euclidean Neighborhood (LSHADE-cnEpSin). The comparative analysis employs various performance metrics, including the Friedman mean rank and the Wilcoxon rank-sum test, to reveal PKO’s effectiveness and efficiency. The overall results highlight PKO’s exceptional ability to tackle intricate optimization problems characterized by challenging search spaces. PKO demonstrates superior exploration and exploitation tendencies while effectively avoiding local optima. The source code for the PKO algorithm is publicly accessible at https://www.mathworks.com/matlabcentral/fileexchange/160043-pied-kingfisher-optimizer-pko .},
  archive      = {J_NCA},
  author       = {Bouaouda, Anas and Hashim, Fatma A. and Sayouti, Yassine and Hussien, Abdelazim G.},
  doi          = {10.1007/s00521-024-09879-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15455-15513},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pied kingfisher optimizer: A new bio-inspired algorithm for solving numerical optimization and industrial engineering problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy BERT-LSTM: A novel NLP algorithm for sensitive
information detection in textual documents. <em>NCA</em>,
<em>36</em>(25), 15439–15454. (<a
href="https://doi.org/10.1007/s00521-024-09707-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this modern digital era, the increasing volume of textual data and the widespread adoption of natural language processing (NLP) techniques have presented a critical challenge in safeguarding sensitive privacy information. As a result, there is a pressing demand to design robust and accurate NLP-based techniques to perform efficient sensitive information detection in textual data. This research paper focuses on the detection and classification of sensitive privacy information in textual documents using NLP by proposing a novel algorithm named Privacy BERT-LSTM. The proposed Privacy BERT-LSTM algorithm employs BERT for obtaining contextual embeddings and LSTM for sequential information processing, facilitating efficient sensitive information detection in textual documents. The BERT with its bidirectional characteristics captures the nuances and meaning of the textual documents, while the LSTM derives the long-range dependencies in the textual data. Moreover, the proposed Privacy BERT-LSTM algorithm with its attention mechanism highlights the important regions of the textual documents, contributing to efficient sensitive information detection. The comprehensive performance evaluation is conducted by employing the SMS Spam Collection dataset in terms of standard performance metrics and comparing it with different state-of-the-art techniques, namely, CASSED, PRIVAFRAME, CNN-LSTM, Conv-FFD, GCSA, TSIIP, and, C-PIIM. The experimental outcomes clearly illustrate that the Privacy BERT-LSTM algorithm demonstrates superior performance in identifying various types of sensitive information by achieving an accuracy of 92.50%, F1-score of 85.02%, and Precision of 89.36%. The proposed algorithm outperforms existing baseline models, providing valuable advancements in sensitive information detection using NLP. Therefore, this research contributes to the advancement of privacy protection in NLP applications and opens avenues for future investigations in the domain of sensitive information detection. Additionally, the proposed algorithm provides valuable insights for researchers and practitioners working on privacy-sensitive NLP tasks.},
  archive      = {J_NCA},
  author       = {Muralitharan, Janani and Arumugam, Chandrasekar},
  doi          = {10.1007/s00521-024-09707-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15439-15454},
  shortjournal = {Neural Comput. Appl.},
  title        = {Privacy BERT-LSTM: A novel NLP algorithm for sensitive information detection in textual documents},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ADE: Advanced differential evolution. <em>NCA</em>,
<em>36</em>(25), 15407–15438. (<a
href="https://doi.org/10.1007/s00521-024-09669-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a metaheuristic algorithm, called advanced differential evolution (ADE), by improving the DE algorithm. The ADE algorithm was developed with the goal of creating an optimization framework that addresses the challenges of exploration and exploitation balance, avoiding local minima, utilizing chaos theory for diverse initialization, and improving solution quality and convergence speed. By incorporating these features, ADE aims to enhance the effectiveness of optimization processes. The proposed algorithm utilizes chaos theory to generate the initial population, which is subsequently divided into two sub-populations with adaptive sizes. The size of each sub-population is determined using a formula based on the number of iterations during the algorithm’s execution. The first sub-population has a larger size in the beginning and the second one has a smaller size, but the total size of these two populations is always constant. The main contribution of this paper is the proposal of two novel improved differential evolution algorithms, namely MDE1 and MDE2, which are utilized for exploration within these sub-populations. The proposed ADE is tested on 29 well-known benchmarks and six engineering problems, and the results are compared with seven other algorithms. Various statistical experiments are carried out showing that the proposed algorithm provides significant superiority over other well-known algorithms.},
  archive      = {J_NCA},
  author       = {Abbasi, Behzad and Majidnezhad, Vahid and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-024-09669-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15407-15438},
  shortjournal = {Neural Comput. Appl.},
  title        = {ADE: Advanced differential evolution},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). DeepAR-attention probabilistic prediction for stock price
series. <em>NCA</em>, <em>36</em>(25), 15389–15406. (<a
href="https://doi.org/10.1007/s00521-024-09916-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price prediction is a significant research domain, intersecting statistics, finance, and economics. Accurately forecasting stock price trends has always been a focal point for many researchers. However, traditional statistical methods for time series prediction still lack accuracy. The existing deep learning-based methods for stock price prediction have significantly enhanced the accuracy of predicting individual stock prices. However, they are not effective in forecasting the probability range of future stock price trends. In this paper, to address these limitations, we propose a novel DeepAR model based on the attention mechanism (DeepARA) for both single-point and probabilistic predictions of stock prices. This enhances the accuracy and flexibility of stock price forecasting. Although the attention mechanism was initially developed for natural language processing, it has now found applications in time series forecasting, including the dynamics of the stock market. Attention allocates different weights to time points of varying importance, thereby enhancing the model’s ability to capture fundamental market dynamics. We conducted multiple experiments in the Chinese stock market, involving 30 stocks across the top six sectors. Compared with baseline models, the DeepARA model demonstrates superior predictive capabilities.},
  archive      = {J_NCA},
  author       = {Li, Jiacheng and Chen, Wei and Zhou, Zhiheng and Yang, Junmei and Zeng, Delu},
  doi          = {10.1007/s00521-024-09916-3},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15389-15406},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepAR-attention probabilistic prediction for stock price series},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the kidney exchange problem via graph neural
networks with no supervision. <em>NCA</em>, <em>36</em>(25),
15373–15388. (<a
href="https://doi.org/10.1007/s00521-024-09887-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new learning-based approach for approximately solving the Kidney-Exchange Problem (KEP), an NP-hard problem on graphs. The KEP consists of, given a pool of kidney donors and patients waiting for kidney donations, optimally selecting a set of donations to optimize the quantity and quality of transplants performed while respecting a set of constraints about the arrangement of these donations. The proposed technique consists of two major steps: the first is a Graph Neural Network (GNN) trained without supervision; the second is a deterministic non-learned search heuristic that uses the output of the GNN to find a valid solution. To allow for comparisons, we also implemented and tested an exact solution method using integer programming, two greedy search heuristics without the machine learning module, and the GNN alone without a heuristic. We analyze and compare the methods and conclude that the learning-based two-stage approach is the best solution quality, outputting approximate solutions on average 1.1 times more valuable than the ones from the deterministic heuristic alone.},
  archive      = {J_NCA},
  author       = {Pimenta, Pedro F. and Avelar, Pedro H. C. and Lamb, Luís C.},
  doi          = {10.1007/s00521-024-09887-5},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15373-15388},
  shortjournal = {Neural Comput. Appl.},
  title        = {Solving the kidney exchange problem via graph neural networks with no supervision},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-assisted training of a physics-informed neural network
to predict the separated reynolds-averaged turbulent flow field around
an airfoil under variable angles of attack. <em>NCA</em>,
<em>36</em>(25), 15353–15371. (<a
href="https://doi.org/10.1007/s00521-024-09883-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks are a promising method to yield surrogate models of flow fields. We present a metamodeling technique for variable geometries based on physics-informed neural networks. The method was applied to the DU99W350 airfoil at a Reynolds number of $$1\times 10^{5}$$ . Using our technique, the angle of attack was introduced as an additional input parameter of the network and the model was trained to predict the Reynolds-averaged velocity and pressure fields around the airfoil for arbitrary angles of attack between 10.0 and 17.5 $$^{\circ }$$ . Furthermore, we present an effective method to generate the training points for the parameterized geometry. The model was trained with data from simulations for a limited set of angles of attack. Additionally, satisfaction of the a priori known boundary conditions as well as the Reynolds-averaged Navier–Stokes equations was attained. A sensitivity analysis concerning the Reynolds number, the amount and distribution of training data, and the turbulence model was conducted showing the superiority of the pseudo-Reynolds stress method and the demand for labeled training data in the domain. The trained network was capable of predicting the flow separation progressing with angle of attack on the suction surface and exhibited excellent agreement with numerically simulated results, even in the proximity of the wall for interpolations as well as extrapolations from the labeled data set. Our study demonstrates that physics-informed neural networks can be used to obtain accurate flow field surrogate models of variable geometries.},
  archive      = {J_NCA},
  author       = {Harmening, Jan Hauke and Pioch, Fabian and Fuhrig, Lennart and Peitzmann, Franz-Josef and Schramm, Dieter and el Moctar, Ould},
  doi          = {10.1007/s00521-024-09883-9},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15353-15371},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data-assisted training of a physics-informed neural network to predict the separated reynolds-averaged turbulent flow field around an airfoil under variable angles of attack},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing abstractive summarization of implicit datasets
with contrastive attention. <em>NCA</em>, <em>36</em>(25), 15337–15351.
(<a href="https://doi.org/10.1007/s00521-024-09864-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is important for abstractive summarization models to understand the important parts of the original document and create a natural summary accordingly. Recently, studies have been conducted to incorporate important parts of the original document during learning and have shown good performance. However, these studies are effective for explicit datasets but not implicit datasets which are relatively more abstract. This study addresses the challenge of summarizing implicit datasets, which have a lower deviation in the significance of important sentences compared to explicit datasets. A multi-task learning approach that reflects information about salient and incidental objects during the learning process was proposed. This was achieved by adding a contrastive objective to the fine-tuning process of the encoder-decoder language model. The salient and incidental parts were selected based on the ROUGE-L F1 score and their relationships were learned through triplet loss. The proposed method was evaluated using five benchmark summarization datasets, including two explicit and three implicit. The experimental results showed a greater improvement in implicit datasets, particularly for the highly abstractive XSum dataset, compared to the vanilla fine-tuning method in both the BART-base and T5-small models.},
  archive      = {J_NCA},
  author       = {Kwon, Soonki and Lee, Younghoon},
  doi          = {10.1007/s00521-024-09864-y},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15337-15351},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing abstractive summarization of implicit datasets with contrastive attention},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image retrieval using underlying importance feature
histogram. <em>NCA</em>, <em>36</em>(25), 15323–15335. (<a
href="https://doi.org/10.1007/s00521-024-09735-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep features can exhibit superior retrieval performance than low-level features. However, low-level features (e.g. colour and orientation) can be extracted by generally imitating the human visual perceptual system. Combining human-like low-level and deep features can harmoniously yield more discriminative representations. However, it remains challenging. To address this problem, a new representation method for image retrieval, namely the underlying importance feature histogram (UIFH), is presented in this study. Its main highlights are: (1) This new method extracts low-level features by simulating the human visual perception mechanism, such as opponent colour and orientation selectivity mechanisms. (2) Inspired by the salience evaluation mechanism, the new method can harmoniously evaluate the underlying importance information between deep and low-level features. (3) Assisting the various important information can facilitate the UIFH. It can substantially improve the discriminative power of representation. Comprehensive experiments on seven benchmark datasets demonstrated that the proposed UIFH method outperforms some recent state-of-the-art methods based on pre-trained models. The proposed UIFH method is suitable for the retrieval scenes where images have various colours and prominent orientations.},
  archive      = {J_NCA},
  author       = {He, Qiao-Ping and Liu, Guang-Hai},
  doi          = {10.1007/s00521-024-09735-6},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15323-15335},
  shortjournal = {Neural Comput. Appl.},
  title        = {Image retrieval using underlying importance feature histogram},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic extraction of lightweight and efficient neural
network architecture of heavy convolutional architectures to predict
microsatellite instability from hematoxylin and eosin histology in
gastric cancer. <em>NCA</em>, <em>36</em>(25), 15295–15321. (<a
href="https://doi.org/10.1007/s00521-024-09882-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancers have emerged as a significant concern due to their impact on public health and society. The examination and interpretation of tissue sections stained with Hematoxylin and Eosin (H&amp;E) play a crucial role in disease assessment, particularly in cases like gastric cancer. Microsatellite instability (MSI) is suggested to contribute to the carcinogenesis of specific gastrointestinal tumors. However, due to the nonspecific morphology observed in H&amp;E-stained tissue sections, MSI determination often requires costly evaluations through various molecular studies and immunohistochemistry methods in specialized molecular pathology laboratories. Despite the high cost, international guidelines recommend MSI testing for gastrointestinal cancers. Thus, there is a pressing need for a new diagnostic modality with lower costs and widespread applicability for MSI detection. This study aims to detect MSI directly from H&amp;E histology slides in gastric cancer, providing a cost-effective alternative. The performance of well-known deep convolutional neural networks (DCNNs) and a proposed architecture are compared. Medical image datasets are typically smaller than benchmark datasets like ImageNet, necessitating the use of off-the-shelf DCNN architectures developed for large datasets through techniques such as transfer learning. Designing an architecture proportional to a custom dataset can be tedious and may not yield desirable results. In this work, we propose an automatic method to extract a lightweight and efficient architecture from a given heavy architecture (e.g., well-known off-the-shelf DCNNs) proportional to a specific dataset. To predict MSI instability, we extracted the MicroNet architecture from the Xception network using the proposed method and compared its performance with other well-known architectures. The models were trained using tiles extracted from whole-slide images, and two evaluation strategies, tile-based and whole-slide image (WSI)-based, were employed and compared. Additionally, a visual explanation of the best convolutional neural network model is presented to validate numerical results. The MicroNet architecture achieved the best accuracy (0.85) and area under the curve-receiver operating characteristic curve (0.93), outperforming previous works for the study dataset. The proposed method can be utilized by developers to design lightweight and efficient problem-based neural network architectures, such as MicroNet, for MSI prediction.},
  archive      = {J_NCA},
  author       = {Rostami, Habib and Ashkpour, Maryam and Behzadi-Khormouji, Hamed and Mokhtari, Maral and Khayati, Armin and Keshavarz, Ahmad and Talatian Azad, Saeed and Tabesh, Yahya},
  doi          = {10.1007/s00521-024-09882-w},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15295-15321},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic extraction of lightweight and efficient neural network architecture of heavy convolutional architectures to predict microsatellite instability from hematoxylin and eosin histology in gastric cancer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of sliding mode control based on diagonal
recurrent neural network for coupled tank system. <em>NCA</em>,
<em>36</em>(25), 15279–15293. (<a
href="https://doi.org/10.1007/s00521-024-09849-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the development of sliding mode control (SMC) using the diagonal recurrent neural network (DRNN) for nonlinear systems. Firstly, the SMC for linear systems is developed for nonlinear coupled tank system. Second, the DRNN is used to design the equivalent part of the SMC law, which is performed to approximate the dynamics of a controlled process. Third, the sliding surface for the switching control is developed using the DRNN. The DRNN parameters are tuned using Lyapunov function to achieve the controlled process stability. For the developed scheme, discontinuous signum function is used to compensate the chattering phenomenon. The developed scheme is applied for controlling the uncertain nonlinear coupled tank system. The simulation results indicate that the developed scheme can respond to the effects of system uncertainties compared to other existing schemes.},
  archive      = {J_NCA},
  author       = {El-Nagar, Ahmad M. and Abdo, Mohamed I.},
  doi          = {10.1007/s00521-024-09849-x},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15279-15293},
  shortjournal = {Neural Comput. Appl.},
  title        = {Development of sliding mode control based on diagonal recurrent neural network for coupled tank system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Judgmentally adjusted q-values based on q-ensemble for
offline reinforcement learning. <em>NCA</em>, <em>36</em>(25),
15255–15277. (<a
href="https://doi.org/10.1007/s00521-024-09839-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in offline reinforcement learning (offline RL) have leveraged the Q-ensemble approach to derive optimal policies from static datasets collected in the past. By increasing the batch size, a portion of Q-ensemble instances penalizing out-of-distribution (OOD) data can be replaced, significantly reducing the Q-ensemble size while maintaining comparable performance and expediting the algorithm’s training. To further enhance the Q-ensembles’ ability to penalize OOD data, a technique involving large batch punishment and a binary classification network was employed. This method differentiates in-distribution (ID) data from OOD data. For ID data, positive adjustments to Q values were made (reward-based adjustment), whereas negative adjustments (penalty-based adjustment) were applied for OOD data, which replaced some OOD data punishment within large Q-ensembles, reducing their size without compromising performance. For different tasks on the D4RL benchmark datasets, we selectively use one of its methods. Experimental results demonstrated that employing reward-based adjustment improved algorithm performance. Simultaneously, utilizing penalty-based adjustment reduced Q-ensemble size without compromising performance. In comparison to LB-SAC, this approach reduced average convergence time by 38% for datasets utilizing penalty-based adjustment, thanks to the introduction of a simpler binary classification network and a reduced number of Q networks.},
  archive      = {J_NCA},
  author       = {Liu, Wenzhuo and Xiang, Shuying and Zhang, Tao and Han, Yanan and Guo, Xingxing and Zhang, Yahui and Hao, Yue},
  doi          = {10.1007/s00521-024-09839-z},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15255-15277},
  shortjournal = {Neural Comput. Appl.},
  title        = {Judgmentally adjusted Q-values based on Q-ensemble for offline reinforcement learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving unsupervised domain adaptation through
class-conditional compact representations. <em>NCA</em>,
<em>36</em>(25), 15237–15254. (<a
href="https://doi.org/10.1007/s00521-024-09898-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major technique for tackling unsupervised domain adaptation involves mapping data points from both the source and target domains into a shared embedding space. The mapping encoder to the embedding space is trained such that the embedding space becomes domain agnostic, allowing a classifier trained on the source domain to generalize well on the target domain. To further enhance the performance of unsupervised domain adaptation (UDA), we developed an additional technique which makes the internal distribution of the source domain more compact, thereby improving the model’s ability to generalize in the target domain. We demonstrate that by increasing the margins between data representations for different classes in the embedding space, we can improve the model performance for UDA. To make the internal representation more compact, we estimate the internally learned multimodal distribution of the source domain as Gaussian mixture model (GMM). Utilizing the estimated GMM, we enhance the separation between different classes in the source domain, thereby mitigating the effects of domain shift. We offer theoretical analysis to support outperformance of our method. To evaluate the effectiveness of our approach, we conduct experiments on widely used UDA benchmark UDA datasets. The results indicate that our method enhances model generalizability and outperforms existing techniques.},
  archive      = {J_NCA},
  author       = {Rostami, Mohammad},
  doi          = {10.1007/s00521-024-09898-2},
  journal      = {Neural Computing and Applications},
  month        = {9},
  number       = {25},
  pages        = {15237-15254},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving unsupervised domain adaptation through class-conditional compact representations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: EoT-driven hybrid ambient assisted living
framework with naïve bayes–firefly algorithm. <em>NCA</em>,
<em>36</em>(24), 15215. (<a
href="https://doi.org/10.1007/s00521-024-10093-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Hassan, Mohammed K. and Desouky, Ali I. El and Badawy, Mahmoud M. and Sarhan, Amany M. and Elhoseny, Mohamed and Gunasekaran, M.},
  doi          = {10.1007/s00521-024-10093-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15215},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: EoT-driven hybrid ambient assisted living framework with naïve bayes–firefly algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A new binary salp swarm algorithm:
Development and application for optimization tasks. <em>NCA</em>,
<em>36</em>(24), 15213. (<a
href="https://doi.org/10.1007/s00521-024-10090-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Rizk-Allah, Rizk M. and Hassanien, Aboul Ella and Elhoseny, Mohamed and Gunasekaran, M.},
  doi          = {10.1007/s00521-024-10090-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15213},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: a new binary salp swarm algorithm: development and application for optimization tasks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A novel method for solving the fully
neutrosophic linear programming problems. <em>NCA</em>, <em>36</em>(24),
15211. (<a href="https://doi.org/10.1007/s00521-024-10089-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Abdel-Basset, Mohamed and Gunasekaran, M. and Mohamed, Mai and Smarandache, Florentin},
  doi          = {10.1007/s00521-024-10089-2},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15211},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel method for solving the fully neutrosophic linear programming problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Optimal body mass index cutoff point for
cardiovascular disease and high blood pressure. <em>NCA</em>,
<em>36</em>(24), 15209. (<a
href="https://doi.org/10.1007/s00521-024-10080-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Babu, Gokulnath Chandra and Shantharajah, S. P.},
  doi          = {10.1007/s00521-024-10080-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15209},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Optimal body mass index cutoff point for cardiovascular disease and high blood pressure},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Adaptive computing-based biometric security
for intelligent medical applications. <em>NCA</em>, <em>36</em>(24),
15207. (<a href="https://doi.org/10.1007/s00521-024-10099-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Wu, Wanqing and Pirbhulal, Sandeep and Li, Guanglin},
  doi          = {10.1007/s00521-024-10099-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15207},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Adaptive computing-based biometric security for intelligent medical applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A novel deep learning-based multi-model
ensemble method for the prediction of neuromuscular disorders.
<em>NCA</em>, <em>36</em>(24), 15205. (<a
href="https://doi.org/10.1007/s00521-024-10097-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Khamparia, Aditya and Singh, Aman and Anand, Divya and Gupta, Deepak and Khanna, Ashish and Kumar, N. Arun and Tan, Joseph},
  doi          = {10.1007/s00521-024-10097-2},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15205},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel deep learning-based multi-model ensemble method for the prediction of neuromuscular disorders},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Lung nodule malignancy classification in
chest computed tomography images using transfer learning and
convolutional neural networks. <em>NCA</em>, <em>36</em>(24), 15203. (<a
href="https://doi.org/10.1007/s00521-024-10096-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {da Nóbrega, Raul Victor M. and Filho, Pedro P. Rebouças and Rodrigues, Murillo B. and da Silva, Suane P. P. and Júnior, Carlos M. J. M. Dourado and de Albuquerque, Victor Hugo C.},
  doi          = {10.1007/s00521-024-10096-3},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15203},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Lung nodule malignancy classification in chest computed tomography images using transfer learning and convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Revisiting computer networking protocols by
wireless sniffing on brain signal/image portals. <em>NCA</em>,
<em>36</em>(24), 15201. (<a
href="https://doi.org/10.1007/s00521-024-10092-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sathishkumar, B. R. and Sundaravadivazhagan, B. and Martin, Betty and Sasi, G. and Chandrasekar, M. and Rakesh Kumar, S. and Elamaran, V. and Balaji, V. S. and Arunkumar, N.},
  doi          = {10.1007/s00521-024-10092-7},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15201},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Revisiting computer networking protocols by wireless sniffing on brain signal/image portals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Energy demand classification by
probabilistic neural network for medical diagnosis applications.
<em>NCA</em>, <em>36</em>(24), 15199. (<a
href="https://doi.org/10.1007/s00521-024-10091-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Shilaja, C. and Arunprasath, T.},
  doi          = {10.1007/s00521-024-10091-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15199},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Energy demand classification by probabilistic neural network for medical diagnosis applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A new and efficient firefly algorithm for
numerical optimization problems. <em>NCA</em>, <em>36</em>(24), 15197.
(<a href="https://doi.org/10.1007/s00521-024-10087-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Pan, Xiuqin and Xue, Limiao and Li, Ruixiang},
  doi          = {10.1007/s00521-024-10087-4},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15197},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A new and efficient firefly algorithm for numerical optimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Classifying streaming of twitter data based
on sentiment analysis using hybridization. <em>NCA</em>,
<em>36</em>(24), 15195. (<a
href="https://doi.org/10.1007/s00521-024-10085-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Nagarajan, Senthil Murugan and Gandhi, Usha Devi},
  doi          = {10.1007/s00521-024-10085-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15195},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Classifying streaming of twitter data based on sentiment analysis using hybridization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Abnormal event detection with
semi-supervised sparse topic model. <em>NCA</em>, <em>36</em>(24),
15193. (<a href="https://doi.org/10.1007/s00521-024-10082-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Wang, Jun and Xia, Limin and Hu, Xiangjie and Xiao, Yongliang},
  doi          = {10.1007/s00521-024-10082-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15193},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Abnormal event detection with semi-supervised sparse topic model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Retraction note: Automatic sleep staging in obstructive
sleep apnea patients using photoplethysmography, heart rate variability
signal and machine learning techniques. <em>NCA</em>, <em>36</em>(24),
15191. (<a href="https://doi.org/10.1007/s00521-024-10067-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Uçar, Muhammed Kürşad and Bozkurt, Mehmet Recep and Bilgin, Cahit and Polat, Kemal},
  doi          = {10.1007/s00521-024-10067-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15191},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Automatic sleep staging in obstructive sleep apnea patients using photoplethysmography, heart rate variability signal and machine learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Prediction model for optimized
self-compacting concrete with fly ash using response surface method
based on fuzzy classification. <em>NCA</em>, <em>36</em>(24), 15189. (<a
href="https://doi.org/10.1007/s00521-024-10065-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Selvaraj, Sundari and Sivaraman, Sukumar},
  doi          = {10.1007/s00521-024-10065-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15189},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Prediction model for optimized self-compacting concrete with fly ash using response surface method based on fuzzy classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: LION IDS: A meta-heuristics approach to
detect DDoS attacks against software-defined networks. <em>NCA</em>,
<em>36</em>(24), 15187. (<a
href="https://doi.org/10.1007/s00521-024-10084-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Arivudainambi, D. and Varun Kumar, K. A. and Sibi Chakkaravarthy, S.},
  doi          = {10.1007/s00521-024-10084-7},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15187},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: LION IDS: a meta-heuristics approach to detect DDoS attacks against software-defined networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: An improved dynamic self-adaption cuckoo
search algorithm based on collaboration between subpopulations.
<em>NCA</em>, <em>36</em>(24), 15185. (<a
href="https://doi.org/10.1007/s00521-024-10078-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ma, Hui-sheng and Li, Shu-xia and Li, Shu-fang and Lv, Zheng-nan and Wang, Jie-sheng},
  doi          = {10.1007/s00521-024-10078-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15185},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An improved dynamic self-adaption cuckoo search algorithm based on collaboration between subpopulations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Module overlapping structure detection in
PPI using an improved link similarity-based markov clustering algorithm.
<em>NCA</em>, <em>36</em>(24), 15183. (<a
href="https://doi.org/10.1007/s00521-024-10073-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Gu, L. and Han, Y. and Wang, C. and Chen, Wei and Jiao, Jun and Yuan, X.},
  doi          = {10.1007/s00521-024-10073-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15183},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Module overlapping structure detection in PPI using an improved link similarity-based markov clustering algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Automatic detection of sleep spindles with
the use of STFT, EMD and DWT methods. <em>NCA</em>, <em>36</em>(24),
15181. (<a href="https://doi.org/10.1007/s00521-024-10066-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yücelbaş, Cüneyt and Yücelbaş, Şule and Özşen, Seral and Tezel, Gülay and Küççüktürk, Serkan and Yosunkaya, Şebnem},
  doi          = {10.1007/s00521-024-10066-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15181},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Automatic detection of sleep spindles with the use of STFT, EMD and DWT methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Crime activities prediction using
hybridization of firefly optimization technique and fuzzy cognitive map
neural networks. <em>NCA</em>, <em>36</em>(24), 15179. (<a
href="https://doi.org/10.1007/s00521-024-10063-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Altameem, Torki and Amoon, Mohammed},
  doi          = {10.1007/s00521-024-10063-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15179},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Crime activities prediction using hybridization of firefly optimization technique and fuzzy cognitive map neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Certificateless remote data integrity
checking using lattices in cloud storage. <em>NCA</em>, <em>36</em>(24),
15177. (<a href="https://doi.org/10.1007/s00521-024-10061-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sasikala, C. and Bindu, C. Shoba},
  doi          = {10.1007/s00521-024-10061-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15177},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Certificateless remote data integrity checking using lattices in cloud storage},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Is checkworthiness generalizable? Evaluating task and domain
generalization of datasets for claim detection. <em>NCA</em>,
<em>36</em>(24), 15165–15176. (<a
href="https://doi.org/10.1007/s00521-024-09896-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of misinformation has reached a level at which neither research nor fact-checkers can monitor it only manually anymore. Accordingly, there has been much research on models and datasets for detecting checkworthy claims. However, the research in NLP is mostly detached from findings in communication science on misinformation and fact-checking. Checkworthiness is a notoriously vague concept whose meaning is contested among different stakeholders. Against the background of news value theory, i.e., the study of factors that make an event relevant for journalistic reporting, this is not surprising. It is argued that this vagueness leads to inconsistencies and poor generalization across different datasets and domains. For the experiments, models are trained on one dataset, tested on the remaining, and evaluated against the results on the original performance, against a random baseline, and against the scores when the models are not trained at all. The study finds that there is a drastic reduction in comparison with the performance on the original dataset. Moreover, often the models are outperformed by the random baseline and training on one dataset has no or even a negative impact on the performance on the other datasets. This paper proposes that future research should abandon this task design and instead take inspiration from research in communication science. In the style of news values, Claim Detection should focus on factors that are relevant for fact-checkers and misinformation.},
  archive      = {J_NCA},
  author       = {Nenno, Sami},
  doi          = {10.1007/s00521-024-09896-4},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15165-15176},
  shortjournal = {Neural Comput. Appl.},
  title        = {Is checkworthiness generalizable? evaluating task and domain generalization of datasets for claim detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ELCD-NSC2: A novel early lung cancer detection and non-small
cell classification framework. <em>NCA</em>, <em>36</em>(24),
15149–15164. (<a
href="https://doi.org/10.1007/s00521-024-09856-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The survival rate of lung cancer relies significantly on how far the disease has spread when it is detected, how it reacts to the treatment, the patient’s overall health, and other factors. Therefore, the earlier the lung cancer diagnosis, the higher the survival rate. For radiologists, recognizing malignant lung nodules from computed tomography (CT) scans is a challenging and time-consuming process. As a result, computer-aided diagnosis (CAD) systems have been suggested to alleviate these burdens. Deep-learning approaches have demonstrated remarkable results in recent years, surpassing traditional methods in different fields. Researchers are currently experimenting with several deep-learning strategies to increase the effectiveness of CAD systems in lung cancer detection with CT. This work proposes a deep-learning framework for detecting and diagnosing lung cancer. The proposed framework used recent deep-learning techniques in all its layers. The autoencoder technique structure is tuned and used in the preprocessing stage to denoise and reconstruct the medical lung cancer dataset. Besides, it depends on the transfer learning pre-trained models to make multi-classification among different lung cancer cases such as benign, adenocarcinoma, and squamous cell carcinoma. The proposed model provides high performance while recognizing and differentiating between two types of datasets, including biopsy and CT scans. The Cancer Imaging Archive and Kaggle datasets are utilized to train and test the proposed model. The empirical results show that the proposed framework performs well according to various performance metrics. According to accuracy, precision, recall, F1-score, and AUC metrics, it achieves 99.60, 99.61, 99.62, 99.70, and 99.75%, respectively. Also, it depicts 0.0028, 0.0026, and 0.0507 in mean absolute error, mean squared error, and root mean square error metrics. Furthermore, it helps physicians effectively diagnose lung cancer in its early stages and allows specialists to improve the accuracy and consistency of workflow.},
  archive      = {J_NCA},
  author       = {Helaly, Hadeer A. and Badawy, Mahmoud and El-Gendy, Eman M. and Haikal, Amira Y.},
  doi          = {10.1007/s00521-024-09856-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15149-15164},
  shortjournal = {Neural Comput. Appl.},
  title        = {ELCD-NSC2: A novel early lung cancer detection and non-small cell classification framework},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel metric learning method based on constructing a
uniform data hypersphere via simulated forging approach. <em>NCA</em>,
<em>36</em>(24), 15137–15148. (<a
href="https://doi.org/10.1007/s00521-024-09854-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-uniformly distributed data in unbalanced datasets have the phenomenon of data stacking and data scattering. However, most traditional metric learning algorithms often overemphasize the intra-class compactness and inter-class dispersion of data. When dealing with the typical non-uniformly distributed data, these traditional methods may distort a few classes of data in the embedding space and finally reduce the classification accuracy. To solve these problems, we propose a novel metric learning method based on constructing a uniform data hypersphere via simulated forging approach (CUDH-SF). CUDH-SF aims to achieve a uniformly distributed embedding space through conducting local forging and global forging on the original data, so that the problem of data stacking and data scattering can be more effectively alleviated. Although the uniform data hypersphere changes the absolute position of the original data, it does not change its relative relationship, that is, the geometric structure of the data can be maintained. Such data transformation is helpful to strengthen the representation ability of the input data, so that the subsequent distance-based classifiers can better construct the decision boundary. Moreover, CUDH-SF does not have the parameters needed for tuning in the validation set, which makes it easier to use. Extensive experiments on eight datasets demonstrate the better performance of the proposed method.},
  archive      = {J_NCA},
  author       = {Liang, Lu and Su, Linxin and Fei, Lunke},
  doi          = {10.1007/s00521-024-09854-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15137-15148},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel metric learning method based on constructing a uniform data hypersphere via simulated forging approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep-CNWO: A deep-chaotic nature whale optimization
algorithm for early prediction of blood pressure disorder in smart
healthcare settings. <em>NCA</em>, <em>36</em>(24), 15117–15136. (<a
href="https://doi.org/10.1007/s00521-024-09852-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of cloud and edge computing, along with machine learning, plays a vital role in the development of efficient healthcare systems in smart cities. However, machine and deep learning (DL) models are prone to delayed convergence and Type-I and Type-II errors due to data vastness and high degree imbalance. To overcome the shortcomings of previous frameworks, this work aims to propose an optimization method with DL, ‘Deep-Chaotic Nature Whale Optimization’ (Deep-CNWO) for early prediction of Blood Pressure disorders among patients under at-home supervision. A simplex search algorithm is integrated to improve the update mechanism of whale optimization algorithm (WOA), thereby creating a CNWO algorithm. The purpose of this hybrid optimization is to increase the accuracy and efficiency of DL models. Leveraging the power of DL and CNWO, this method (Deep-CNWO) provides an effective solution for early detection and proactive management of a chronic disease in at-home healthcare settings. We collected relevant data from clinical studies, including vital signs and patient contextual information, to train and evaluate the deep-CNWO model. The CNWO optimization approach has been used to improve the predictive performance and convergence of DL models. Experiments performed on imbalanced datasets using deep-CNWO have given 99.90% accuracy. The average F-score for emergency cases has improved by 22%, while the average accuracy has increased by 5.72% across all three classes, compared to the results reported in previous related work. Deep-CNWO improves the convergence of DL and reduces Type-I and Type-II errors. The experimental results demonstrate the efficacy of our proposed method for remote patient monitoring and highlight its potential for quick intervention during emergencies.},
  archive      = {J_NCA},
  author       = {Motwani, Anand and Shukla, Piyush Kumar and Pawar, Mahesh and Arya, Monika and Jain, Paras},
  doi          = {10.1007/s00521-024-09852-2},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15117-15136},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep-CNWO: A deep-chaotic nature whale optimization algorithm for early prediction of blood pressure disorder in smart healthcare settings},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing indian sign language recognition through data
augmentation and visual transformer. <em>NCA</em>, <em>36</em>(24),
15103–15116. (<a
href="https://doi.org/10.1007/s00521-024-09845-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel approach to Indian Sign Language Recognition (ISLR) by integrating Keras, Visual Transformers (ViT), and sophisticated data augmentation techniques. Our methodology emphasizes the development of a Vision Transformer model trained on a comprehensive dataset, enhanced with both image data and keypoint information, leveraging the capabilities of the Mediapipe library. To improve the model’s ability to generalize, we applied advanced augmentation strategies, including ImageDataGenerator, among others. Through extensive experimentation, involving rigorous hyperparameter optimization across numerous epochs, we sought to determine the most effective model configuration. The results of our validation process revealed a promising evaluation loss of 0.2941 and an impressive accuracy rate of 97.52%. This integration of data augmentation techniques with ViT transformers establishes a groundbreaking framework in the field of ISLR, underscoring its significant potential for practical implementation and marking a substantial progression in the technology for sign language recognition.},
  archive      = {J_NCA},
  author       = {Singla, Venus and Bawa, Seema and Singh, Jasmeet},
  doi          = {10.1007/s00521-024-09845-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15103-15116},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing indian sign language recognition through data augmentation and visual transformer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing isomorphism between word embedding spaces for
distant languages bilingual lexicon induction. <em>NCA</em>,
<em>36</em>(24), 15091–15102. (<a
href="https://doi.org/10.1007/s00521-024-09837-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the bilingual lexicon induction (BLI) models learn a mapping function that can transfer word embedding (WE) spaces from one language to another. This usually relies on the isomorphism hypothesis, which posits that words in different languages share the same structures and relationships (i.e. similar in geometric structure). However, WE’s isomorphism weakens substantially in distant language pairs, resulting in low accuracy of BLI. To address this problem, we propose a novel BLI method incorporating synonymous knowledge. The main idea is to stabilize the distance between words to optimize the monolingual WE space, yielding higher isomorphism. Specifically, we first induce monolingual synonym pairs from Wordnet and construct monolingual synonym lexicons. We then generate pseudo-sentences by substituting words in the training corpus with synonyms. Finally, the original sentences and pseudo-sentences are jointly used to generate monolingual WEs, enabling the word vectors of synonyms to be closer naturally. Comprehensive experiments on standard BLI datasets in diverse distant languages demonstrate that our method significantly outperforms the strong BLI systems in word translation.},
  archive      = {J_NCA},
  author       = {Ding, Qiuyu and Cao, Hailong and Feng, Zihao and Zhao, Tiejun},
  doi          = {10.1007/s00521-024-09837-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15091-15102},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing isomorphism between word embedding spaces for distant languages bilingual lexicon induction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What if we intervene?: Higher-order cross-lagged causal
model with interventional approach under observational design.
<em>NCA</em>, <em>36</em>(24), 15075–15090. (<a
href="https://doi.org/10.1007/s00521-024-09833-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental design allows us to more accurately determine the causal relationship between variables correlated over time as compared to observational design based on conditional probability. Observational design allows us to establish merely a dependency relationships that helps predict the objective variable. However, under certain observational design conditions, it is possible to determine the causal effects of the experimental design without carrying out an intervention. In this work, we present a causal model of higher-order crossed lags capable of inferring causal relationships with hypothetical interventions under an observational design. Additionally, a visualization form is offered that allows us to analyze multiple interventions simultaneously. The methodology is applied to three financial series: the Euro–United States Dollar exchange rate; the Dow Jones Industrial Index; and Gold futures. An analysis of causality concerning their volatilities and differences between the approaches is presented as well as a classic approach of conditioning. Researchers must be cautious in defining the research objective and design for other studies since the approaches lead to very different causal conclusions. The framework presented is expected to be useful in any discipline where one wants to learn  What would happen if we intervene? without actually making an intervention.},
  archive      = {J_NCA},
  author       = {Castro, Christopher and Michell, Kevin and Kristjanpoller, Werner and Minutolo, Marcel C.},
  doi          = {10.1007/s00521-024-09833-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15075-15090},
  shortjournal = {Neural Comput. Appl.},
  title        = {What if we intervene?: Higher-order cross-lagged causal model with interventional approach under observational design},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved multi-scale convolutional neural network with
gated recurrent neural network model for protein secondary structure
prediction. <em>NCA</em>, <em>36</em>(24), 15063–15074. (<a
href="https://doi.org/10.1007/s00521-024-09822-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein structure prediction is one of the main research areas in the field of Bio-informatics. The importance of proteins in drug design attracts researchers for finding the accurate tertiary structure of the protein which is dependent on its secondary structure. In this paper, we focus on improving the accuracy of protein secondary structure prediction. To do so, a Multi-scale convolutional neural network with a Gated recurrent neural network (MCNN-GRNN) is proposed. The novel amino acid encoding method along with layered convolutional neural network and Gated recurrent neural network blocks helps to retrieve local and global relationships between features, which in turn effectively classify the input protein sequence into 3 and 8 states. We have evaluated our algorithm on CullPDB, CB513, PDB25, CASP10, CASP11, CASP12, CASP13, and CASP14 datasets. We have compared our algorithm with different state-of-the-art algorithms like DCNN-SS, DCRNN, MUFOLD-SS, DLBLS_SS, and CGAN-PSSP. The Q3 accuracy of the proposed algorithm is 82–87% and Q8 accuracy is 69–77% on different datasets.},
  archive      = {J_NCA},
  author       = {Bongirwar, Vrushali and Mokhade, A. S.},
  doi          = {10.1007/s00521-024-09822-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15063-15074},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved multi-scale convolutional neural network with gated recurrent neural network model for protein secondary structure prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convolutional neural networks for pattern classifying based
on parameterized predefined sequence of image filters. <em>NCA</em>,
<em>36</em>(24), 15045–15061. (<a
href="https://doi.org/10.1007/s00521-024-09804-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are used to solve pattern classification problems. As this algorithm is based on establishing a relationship between an image-shaped input and its related output through the CNN structure, the training stage is a significant process in their working basis. This study develops a new-fangled and explainable algorithm to train CNNs. The input filters in the convolution layers are parameterized to keep the filter structure, implementing traditional and explainable image processing filters within the network topology. A back-propagation scheme updates the parameters in the filters and the fully connected section of the CNN. Several traditional image filters (Sobel, averaging, Gaussian, and directional, among others) are used in CNN with a learning strategy that keeps their kernel structures. The method implies that the training of these networks is applied to a single parameter instead of all coefficients in the filters, reducing the uncertainty about how each filter performs the image analysis in CNN. This approach was compared with traditional CNNs considering the analysis of the computational cost (measured in terms of time and floops required for training) and their accuracy results. Three image databases were used to evaluate the proposed algorithm. Using a cross-validation methodology, the new training algorithm based on the filter parameterization achieved higher accuracy (93.7% vs. 91.3% in average). The new algorithm got similar results regarding the computational cost compared to traditional methods. This characteristic makes the proposed training methodology an appropriate option to classify images with more explainable processing at the convolution layers.},
  archive      = {J_NCA},
  author       = {Llorente-Vidrio, Dusthon and Fuentes-Aguilar, Rita Q. and Chairez, Isaac},
  doi          = {10.1007/s00521-024-09804-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15045-15061},
  shortjournal = {Neural Comput. Appl.},
  title        = {Convolutional neural networks for pattern classifying based on parameterized predefined sequence of image filters},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IMPRL-net: Interpretable multi-view proximity representation
learning network. <em>NCA</em>, <em>36</em>(24), 15027–15044. (<a
href="https://doi.org/10.1007/s00521-024-09865-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the heterogeneity gap in multi-view data, researchers have been attempting to apply these data to learn a co-latent representation to bridge this gap. However, multi-view representation learning still confronts two challenges: (1) it is hard to simultaneously consider the performance of downstream tasks and the interpretability and transparency of the network; (2) it fails to learn representations that accurately describe the class boundaries of downstream tasks. To overcome these limitations, we propose an interpretable representation learning framework, named interpretable multi-view proximity representation learning network. On the one hand, the proposed network is customized by an explicitly designed optimization objective that enables it to learn semantic co-latent representations while maintaining the interpretability and transparency of the network from the design level. On the other hand, the designed multi-view proximity representation learning objective function encourages its learned co-latent representations to form intuitive class boundaries by increasing the inter-class distance and decreasing the intra-class distance. Driven by a flexible downstream task loss, the learned co-latent representation can adapt to various multi-view scenarios and has been shown to be effective in experiments. As a result, this work provides a feasible solution to a generalized multi-view representation learning framework and is expected to accelerate the research and exploration in this field.},
  archive      = {J_NCA},
  author       = {Lan, Shiyang and Fang, Zihan and Du, Shide and Cai, Zhiling and Wang, Shiping},
  doi          = {10.1007/s00521-024-09865-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {15027-15044},
  shortjournal = {Neural Comput. Appl.},
  title        = {IMPRL-net: Interpretable multi-view proximity representation learning network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Economically optimized heat exchanger design: A synergistic
approach using differential evolution and equilibrium optimizer within
an evolutionary algorithm framework. <em>NCA</em>, <em>36</em>(24),
14999–15026. (<a
href="https://doi.org/10.1007/s00521-024-09829-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the CP-EODE algorithm, a novel hybrid of the Equilibrium Optimizer (EO), and the Differential Evolution (DE) algorithm. It addresses EO’s tendency toward premature convergence by enhancing its exploration capabilities. The motivation for this research stems from the need for more efficient and economically viable designs in engineering, particularly in the optimization of shell-and-tube heat exchangers (STHEs) and photovoltaic module parameters. The CP-EODE algorithm leverages DE&#39;s exploration strengths to enhance EO’s performance adopting a cooperative parallel approach that divides the population into EO and DE sub-populations for a more effective search space exploration. The validation of CP-EODE’s effectiveness commenced with its application to 29 benchmark functions, where a Friedman test yielded an $${F}_{r}$$ value of 22.19, significantly surpassing the critical value of 7.81, and a Wilcoxon signed rank test confirmed statistical improvements with a z-score beyond − 1.96. Four quality metrics were discussed to provide a detailed assessment of CP-EODE’s performance highlighting its robust exploration and exploitation capabilities. In practical applications, CP-EODE demonstrated significant advancements in STHE design achieving up to 19.706% reduction in heat exchanger surface area compared to traditional and other algorithmic designs, showcasing its potential to enhance engineering design efficiency and cost-effectiveness. A critical examination of the algorithm&#39;s convergence rate revealed its swift optimization capability, with rapid attainment of optimal solutions in various test cases, further establishing CP-EODE’s advantage in handling complex optimization challenges. Through rigorous statistical analysis and performance metrics, CP-EODE emerges as a superior solution for complex optimization challenges, underscoring the value of hybrid algorithmic strategies in engineering optimizations.},
  archive      = {J_NCA},
  author       = {Moharam, Amal and Haikal, Amira Y. and Elhosseini, Mostafa},
  doi          = {10.1007/s00521-024-09829-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14999-15026},
  shortjournal = {Neural Comput. Appl.},
  title        = {Economically optimized heat exchanger design: A synergistic approach using differential evolution and equilibrium optimizer within an evolutionary algorithm framework},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using particle size distributions to identify indoor
emissions: A machine learning method for source recognition.
<em>NCA</em>, <em>36</em>(24), 14989–14997. (<a
href="https://doi.org/10.1007/s00521-024-09899-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variation in emitted particle sizes between sources offers potential for source identification. Seven thousand two hundred particle size distributions collected in a single-family home were categorized into four classes: (1) smoking, (2) cooking, (3) household cleaning, and (4) background (no source). We created a multi-class classifier (neural network) to predict the presence of these three source types and background air. Number, surface, and volume concentration profiles (each with 16 particle size bins from 0.3 to 10 µm) were used as input features. Surface or volume concentration profiles were better predictors than number concentration profiles; accuracy was highest when concatenating the number, surface, and volume profiles (48 features). The model achieved ~ 98% accuracy in predicting the four classes when using a 10-unit hidden layer for the 48 input features (compared to ~ 66% for multinomial logistic regression). Smoking has the highest F-score among the four classes (0.999). We applied the model to time series of size-resolved concentrations for three successive indoor particle emissions (pan frying food, sweeping the floor, and smoldering marijuana). Time-varying probabilities of the four classes were visualized. We examined the effects of source, space, ventilation, and temperature/relative humidity on source identification. Using training examples from the single-family home, the model reasonably predicted smoking in another residence under different indoor settings (accuracies &gt; 96%). This study applied, for the first time, the neural network method to identify patterns across different particle size distribution types (number, surface, and volume). It demonstrates the potential of using machine learning for source recognition of transient indoor aerosol emissions (e.g., identifying smoking in a rental property).},
  archive      = {J_NCA},
  author       = {Cheng, Kai-Chung and Huang, Gan and Hildemann, Lynn M.},
  doi          = {10.1007/s00521-024-09899-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14989-14997},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using particle size distributions to identify indoor emissions: A machine learning method for source recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved 3D human face reconstruction from 2D images using
blended hard edges. <em>NCA</em>, <em>36</em>(24), 14967–14987. (<a
href="https://doi.org/10.1007/s00521-024-09868-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study reports an effective and robust edge-based scheme for the reconstruction of 3D human faces from input of single images, addressing drawbacks of existing methods in case of large face pose angles or noisy input images. Accurate 3D face reconstruction from 2D images is important, as it can enable a wide range of applications, such as face recognition, animations, games and AR/VR systems. Edge features extracted from 2D images contain wealthy and robust 3D geometric information, which were used together with landmarks for face reconstruction purpose. However, the accurate reconstruction of 3D faces from contour features is a challenging task, since traditional edge or contour detection algorithms introduce a great deal of noise, which would adversely affect the reconstruction. This paper reports on the use of a hard-blended face contour feature from a neural network and a Canny edge extractor for face reconstruction. The quantitative results indicate that our method achieves a notable improvement in face reconstruction with a Euclidean distance error of 1.64 mm and a normal vector distance error of 1.27 mm when compared to the ground truth, outperforming both traditional and other deep learning-based methods. These metrics show particularly significant advancements, especially in face shape reconstruction under large pose angles. The method also achieved higher accuracy and robustness on in-the-wild images under conditions of blurring, makeup, occlusion and poor illumination.},
  archive      = {J_NCA},
  author       = {Ding, Yueming and Mok, P. Y.},
  doi          = {10.1007/s00521-024-09868-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14967-14987},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved 3D human face reconstruction from 2D images using blended hard edges},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking confidence scores for source-free unsupervised
domain adaptation. <em>NCA</em>, <em>36</em>(24), 14951–14966. (<a
href="https://doi.org/10.1007/s00521-024-09867-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source-free unsupervised domain adaptation (SFUDA) aims to achieve target domain predictions through a source model instead of source data. One of the representative ideas for the SFUDA problem is to apply a self-supervised pseudo-labeling strategy (SSPL) to achieve target domain adaptation, but it is prone to being plagued by noisy labels, which can lead to negative transfer. Therefore, many methods attempt to improve the SSPL and leverage confidence scores to weaken the impact of low-confidence samples on the model, which are potentially noisy samples. However, they are unable to completely overcome the problem of noisy labels because the pseudo-labels of high-confidence samples may also be incorrect. Besides, they rarely allow low-confidence samples to be added to training, which can lead to sample selection bias and thus limit the model generalization ability. In this work, we propose information re-exploitation based on confidence scores (RECS) for the SFUDA problem, in which we rethink the information brought by confidence scores and take advantage of them to solve the shortcomings of the improved SSPL. Specifically, we realize cross-domain target adaptation by the symmetric SSPL with dual denoising, and reduce the intra-domain distribution discrepancy by the discriminative class-balanced feature alignment. In this way, the model robustness and generalization are enhanced. Extensive experiments conducted on three standard datasets have demonstrated the effectiveness and superiority of our proposed method. The code is available at https://github.com/lingyuxuan1234/RECS .},
  archive      = {J_NCA},
  author       = {Tian, Qing and Sun, Canyu},
  doi          = {10.1007/s00521-024-09867-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14951-14966},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rethinking confidence scores for source-free unsupervised domain adaptation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Network security AIOps for online stream data monitoring.
<em>NCA</em>, <em>36</em>(24), 14925–14949. (<a
href="https://doi.org/10.1007/s00521-024-09863-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cybersecurity, live production data for predictive analysis pose a significant challenge due to the inherently secure nature of the domain. Although there are publicly available, synthesized, and artificially generated datasets, authentic scenarios are rarely encountered. For anomaly-based detection, the dynamic definition of thresholds has gained importance and attention in detecting abnormalities and preventing malicious activities. Unlike conventional threshold-based methods, deep learning data modeling provides a more nuanced perspective on network monitoring. This enables security systems to continually refine and adapt to the evolving situation in streaming data online, which is also our goal. Furthermore, our work in this paper contributes significantly to AIOps research, particularly through the deployment of our intelligent module that cooperates within a monitoring system in production. Our work addresses a crucial gap in the security research landscape toward more practical and effective secure strategies.},
  archive      = {J_NCA},
  author       = {Nguyen, Giang and Dlugolinsky, Stefan and Tran, Viet and López García, Álvaro},
  doi          = {10.1007/s00521-024-09863-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14925-14949},
  shortjournal = {Neural Comput. Appl.},
  title        = {Network security AIOps for online stream data monitoring},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iron ore pellets measurement using deep learning based on
YOLACT. <em>NCA</em>, <em>36</em>(24), 14909–14924. (<a
href="https://doi.org/10.1007/s00521-024-09832-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The thermal efficiency for the pelletizing process is intrinsically linked to the diameter and humidity of the iron ore pellets, so that the sensing of the granulometric range in the formation of the pellets becomes essential to the flow of the pelletizing process in the steel industry; this paper presents the assembly of a computer vision system for the detection and segmentation of pellets aiming at the automation of the granulometric measurement, following its formation in the pelletizing disk, using the instance segmentation method to verify whether the particle granulometric distribution (PSD) is adequate for “real-time” applications. The system calculates the normal distribution of the diameter in millimeters, evaluating the normal curve and the standard deviation of the segmented pellets, using a deep neural network based on the You Only Look At CoefficienTs (YOLACT) network, adding speed and precision in the granulometric analysis. In the sample sets, the need for adjustment factors inherent to the pelletizing process became evident. This led to the establishment of the computer vision system, termed the Volumetric Correction Factor (VCF) and Visual Overlay Factor (VOF). The VCF is utilized to estimate the volume of pellets within the pelletizing disk during operation, while the VOF adjusts the millimeter-per-pixel (mpp) ratio. The results of the measurement system proved to be efficient in real-time granulometric measurement.},
  archive      = {J_NCA},
  author       = {Santos, Caio Mario Carletti Vilela and de Almeida, Ricardo and Valadao, Carlos Torturella and Cuadros, Marco Antonio de Souza Leite and Almeida, Gustavo Maia de},
  doi          = {10.1007/s00521-024-09832-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14909-14924},
  shortjournal = {Neural Comput. Appl.},
  title        = {Iron ore pellets measurement using deep learning based on YOLACT},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale deep learning ensemble for segmentation of
endometriotic lesions. <em>NCA</em>, <em>36</em>(24), 14895–14908. (<a
href="https://doi.org/10.1007/s00521-024-09828-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasound is a readily available, non-invasive and low-cost screening for the identification of endometriosis lesions, but its diagnostic specificity strongly depends on the experience of the operator. For this reason, computer-aided diagnosis tools based on Artificial Intelligence techniques can provide significant help to the clinical staff, both in terms of workload reduction and in increasing the overall accuracy of this type of examination and its outcome. However, although these techniques are spreading rapidly in a variety of domains, their application to endometriosis is still very limited. To fill this gap, we propose and evaluate a novel multi-scale ensemble approach for the automatic segmentation of endometriosis lesions from transvaginal ultrasounds. The peculiarity of the method lies in its high discrimination capability, obtained by combining, in a fusion fashion, multiple Convolutional Neural Networks trained on data at different granularity. The experimental validation carried out shows that: (i) the proposed method allows to significantly improve the performance of the individual neural networks, even in the presence of a limited training set; (ii) with a Dice coefficient of 82%, it represents a valid solution to increase the diagnostic efficacy of the ultrasound examination against such a pathology.},
  archive      = {J_NCA},
  author       = {Podda, Alessandro Sebastian and Balia, Riccardo and Barra, Silvio and Carta, Salvatore and Neri, Manuela and Guerriero, Stefano and Piano, Leonardo},
  doi          = {10.1007/s00521-024-09828-2},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14895-14908},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale deep learning ensemble for segmentation of endometriotic lesions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully embedded time series generative adversarial networks.
<em>NCA</em>, <em>36</em>(24), 14885–14894. (<a
href="https://doi.org/10.1007/s00521-024-09825-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks should produce synthetic data that fits the underlying distribution of the data being modeled. For real-valued time series data, this implies the need to simultaneously capture the static distribution of the data, but also the full temporal distribution of the data for any potential time horizon. This temporal element produces a more complex problem that can potentially leave current solutions under-constrained, unstable during training, or prone to varying degrees of mode collapse. In FETSGAN, entire sequences are translated directly to the generator’s sampling space using a seq2seq style adversarial autoencoder, where adversarial training is used to match the training distribution in both the feature space and the lower-dimensional sampling space. This additional constraint provides a loose assurance that the temporal distribution of the synthetic samples will not collapse. In addition, the First Above Threshold operator is introduced to supplement the reconstruction of encoded sequences, which improves training stability and the overall quality of the synthetic data being generated. These novel contributions demonstrate a significant improvement to the current state of the art for adversarial learners in qualitative measures of temporal similarity and quantitative predictive ability of data generated through FETSGAN.},
  archive      = {J_NCA},
  author       = {Beck, Joe and Chakraborty, Subhadeep},
  doi          = {10.1007/s00521-024-09825-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14885-14894},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fully embedded time series generative adversarial networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring facial cues: Automated deception detection using
artificial intelligence. <em>NCA</em>, <em>36</em>(24), 14857–14883. (<a
href="https://doi.org/10.1007/s00521-024-09811-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deception detection is an interdisciplinary field attracting researchers from psychology, criminology, computer science, and economics. Automated deception detection presents unique challenges compared to traditional polygraph tests, but also offers novel economic applications. In this spirit, we propose an approach combining deep learning with discriminative models for deception detection. Therefore, we train CNNs for the facial modalities of gaze, head pose, and facial expressions, allowing us to compute facial cues. Due to the very limited availability of training data for deception, we utilize early fusion on the CNN outputs to perform deception classification. We evaluate our approach on five datasets, including four well-known publicly available datasets and a new economically motivated rolling dice experiment. Results reveal performance differences among modalities, with facial expressions outperforming gaze and head pose overall. Combining multiple modalities and feature selection consistently enhances detection performance. The observed variations in expressed features across datasets with different contexts affirm the importance of scenario-specific training data for effective deception detection, further indicating the influence of context on deceptive behavior. Cross-dataset experiments reinforce these findings. Notably, low-stake datasets, including the rolling dice Experiment, present more challenges for deception detection compared to the high-stake Real-Life trials dataset. Nevertheless, various evaluation measures show deception detection performance surpassing chance levels. Our proposed approach and comprehensive evaluation highlight the challenges and potential of automating deception detection from facial cues, offering promise for future research.},
  archive      = {J_NCA},
  author       = {Dinges, Laslo and Fiedler, Marc-André and Al-Hamadi, Ayoub and Hempel, Thorsten and Abdelrahman, Ahmed and Weimann, Joachim and Bershadskyy, Dmitri and Steiner, Johann},
  doi          = {10.1007/s00521-024-09811-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14857-14883},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring facial cues: Automated deception detection using artificial intelligence},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised kernel fisher discriminant analysis based on
exponential-adjusted geometric distance. <em>NCA</em>, <em>36</em>(24),
14825–14855. (<a
href="https://doi.org/10.1007/s00521-024-09768-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisher discriminant analysis (FDA) is a widely used dimensionality reduction tool in pattern recognition. However, FDA cannot obtain an optimal subspace for classification without sufficient labeled samples. Thus, semi-supervised discriminant analysis has attracted great attention in recent years. In this paper, the proposed method employs the exponential-adjusted geometric distance as the measure of similarity, which modifies the exponential function and the scaling factor. The distance not only satisfies the global and local consistency requirements, but also the similarity matrix obtained is more consistent with the real data distribution, thus improves the dimensionality reduction performance. First, in order to deal with the nonlinear separated data, the kernel function is used to map the original data into the high-dimensional feature space. Then, both labeled and unlabeled data in feature space are used to capture the consistence assumption of geometrical structure based on exponential-adjusted geometric distance, which are incorporated into the objection function of local Fisher discriminant analysis as a regularization term. Eventually, the optimal projection matrix is obtained by maximizing the objective function. Experiments on artificial datasets, UCI benchmark datasets, and high-dimensional recognition problems indicate that the presented technique has a significantly improvement in discriminant performance compared with the-state-of-art dimensionality reduction techniques.},
  archive      = {J_NCA},
  author       = {Chen, Zhiyu and Sun, Yuqi and Hu, Dongliang and Bian, Yangguang and Wang, Shensen and Zhang, Xiyuan and Tao, Xinmin},
  doi          = {10.1007/s00521-024-09768-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14825-14855},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semi-supervised kernel fisher discriminant analysis based on exponential-adjusted geometric distance},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning (RL)-based semantic segmentation and
attention based backpropagation convolutional neural network (ABB-CNN)
for breast cancer identification and classification using mammogram
images. <em>NCA</em>, <em>36</em>(24), 14797–14823. (<a
href="https://doi.org/10.1007/s00521-024-09721-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer poses a threat to women’s health and contributes to an increase in mortality rates. Mammography has proven to be an effective tool for the early detection of breast cancer. However, it faces many challenges in early breast cancer detection due to poor image quality, traditional segmentation, and feature extraction. Therefore, this work addresses these issues and proposes an attention-based backpropagation convolutional neural network (ABB-CNN) to detect breast cancer from mammogram images more accurately. The proposed work includes image enhancement, reinforcement learning-based semantic segmentation (RLSS), and multiview feature extraction and classification. The image enhancement is performed by removing noise and artefacts through a hybrid filter (HF), image scaling through a pixel-based bilinear interpolation (PBI), and contrast enhancement through an election-based optimization (EO) algorithm. In addition, the RLSS introduces intelligent segmentation by utilizing a deep Q network (DQN) to segment the region of interest (ROI) strategically. Moreover, the proposed ABB-CNN facilitates multiview feature extraction from the segmented region to classify the mammograms into normal, malignant, and benign classes. The proposed framework is evaluated on the collected and the digital database for screening mammography (DDSM) datasets. The proposed framework provides better outcomes in terms of accuracy, sensitivity, specificity, precision, f-measure, false-negative rate (FNR) and area under the curve (AUC). This work achieved (99.20%, 99.35%), (99.56%, 99.66%), (98.96%, 98.99%), (99.05%, 99.12%), (0.44%, 0.34%), (99.31%, 99.39%) and (99.27%, 99.32%) of accuracy, sensitivity, specificity, precision, FNR, f-measure and AUC on (collected, DDSM datasets), respectively. This research addresses the prevalent challenges in breast cancer identification and offers a robust and highly accurate solution by integrating advanced deep-learning techniques. The evaluated results reveal the proposed framework’s potential in early breast cancer detection.},
  archive      = {J_NCA},
  author       = {Thakur, Neha and Kumar, Pardeep and Kumar, Amit},
  doi          = {10.1007/s00521-024-09721-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14797-14823},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning (RL)-based semantic segmentation and attention based backpropagation convolutional neural network (ABB-CNN) for breast cancer identification and classification using mammogram images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient deep neural network model for tuberculosis
detection using chest x-ray images. <em>NCA</em>, <em>36</em>(24),
14775–14796. (<a
href="https://doi.org/10.1007/s00521-024-09884-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tuberculosis caused by the infection of Mycobacterium. It is the fifth major source of death and one of the greatest threats to humans in the modern world. Thus, it needs to be detected at an earlier stage using the chest X-rays (CXR) image for precise identification and treatment. The suggested scheme&#39;s main goal is to identify this deadly disease using CXR with improved classification accuracy. This detection process comprises pre-processing, noise removal, balancing of image level, application of the Double Attention Res-U-Net-based Deep Neural Network (DARUNDNN) model, and optimization of deep learning features using the Dingo Optimization Algorithm for achieving better accuracy. The experimental validation of the proposed DARUNDNN model is conducted using benchmark datasets, namely Montgomery, Shenzhen, and National Institutes of Health CXR images. The results obtained using the Shenzhen dataset confirm that the proposed DARUNDNN model is efficient in achieving better accuracy of 98.92%, specificity of 97.24%, and sensitivity of 98.86% with a least error of 1.6 compared to the benchmarked models used for investigation. Moreover, the experimental validation conducted using the Montgomery County dataset also confirmed an excellent accuracy of 98.982%, a specificity of 97.56%, and a sensitivity of 98.52%, with a least error of 1.32 compared to the baseline approaches used for investigation.},
  archive      = {J_NCA},
  author       = {Balamurugan, M. and Balamurugan, R.},
  doi          = {10.1007/s00521-024-09884-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14775-14796},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient deep neural network model for tuberculosis detection using chest X-ray images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Radical-attended and pinyin-attended malicious long-tail
keywords detection. <em>NCA</em>, <em>36</em>(24), 14757–14773. (<a
href="https://doi.org/10.1007/s00521-024-09871-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Netizens all over the world can search malicious websites by malicious long-tail keywords on search engines, but malicious websites are strictly prohibited by law in most countries, so the construction of short text classification models for detecting malicious long-tail keywords has become a key research topic of Natural Language Processing (NLP). Most of the short text classification models are for English, with the widespread use of Chinese, there is an urgent need to develop Chinese short text classification models to help Chinese search engines detect malicious long-tail keywords. Considering that malicious long-tail keywords often evade detection by using homophones that have the same pinyin, pinyin is added to solve the homophonic typos problem of Chinese short text. Considering the data sparsity problem of malicious long-tail keywords, pinyin and radicals are added to obtain more abundant features. Since there is no publicly available pre-trained pinyin and radical embedding models, the embedding vectors of Chinese words, radical and pinyin are trained through Word2Vec, and 492,345 individual word embedding vectors, 207,995 individual radical embedding vectors and 402,071 individual pinyin embedding vectors are obtained. In addition, the positional encoding and part-of-speech coefficient are added to them, and the TF-IDF and MI values are added to reflect the word frequency weight and the different importance of the same word in different documents. Then, two parallel co-attention networks are used to fuse features of words, pinyin, and radicals, BIGRU is used to extract temporal features, and CNN is used to extract local features. Multi-group comparative experiment results on two short text benchmark datasets and pornographic and gambling long-tail keywords show that the proposed model outperforms the state-of-the-art text classification model.},
  archive      = {J_NCA},
  author       = {Sun, Guoying and Zhang, Zhaoxin},
  doi          = {10.1007/s00521-024-09871-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14757-14773},
  shortjournal = {Neural Comput. Appl.},
  title        = {Radical-attended and pinyin-attended malicious long-tail keywords detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating the performance of metaheuristic-tuned weight
agnostic neural networks for crop yield prediction. <em>NCA</em>,
<em>36</em>(24), 14727–14756. (<a
href="https://doi.org/10.1007/s00521-024-09850-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores crop yield forecasting through weight agnostic neural networks (WANN) optimized by a modified metaheuristic. WANNs offer the potential for lighter networks with shared weights, utilizing a two-layer cooperative framework to optimize network architecture and shared weights. The proposed metaheuristic is tested on real-world crop datasets and benchmarked against state-of-the-art algorithms using standard regression metrics. While not claiming WANN as the definitive solution, the model demonstrates significant potential in crop forecasting with lightweight architectures. The optimized WANN models achieve a mean absolute error (MAE) of 0.017698 and an R-squared ( $$R^2$$ ) score of 0.886555, indicating promising forecasting performance. Statistical analysis and Simulator for Autonomy and Generality Evaluation (SAGE) validate the improvement significance and feature importance of the proposed approach.},
  archive      = {J_NCA},
  author       = {Jovanovic, Luka and Zivkovic, Miodrag and Bacanin, Nebojsa and Dobrojevic, Milos and Simic, Vladimir and Sadasivuni, Kishor Kumar and Tirkolaee, Erfan Babaee},
  doi          = {10.1007/s00521-024-09850-4},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14727-14756},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating the performance of metaheuristic-tuned weight agnostic neural networks for crop yield prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection and classification of human respiration under
building debris model using VHF/UHF waves. <em>NCA</em>,
<em>36</em>(24), 14709–14725. (<a
href="https://doi.org/10.1007/s00521-024-09848-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting live humans in buildings that have collapsed due to disasters and identifying their condition of health is of great importance for search and rescue operations. Although various methods have been used for this purpose, there are still critical challenges to ensure accurate and rapid life-saving operations. Immediate detection of the presence of living humans under debris combined with the assessment of their vital signs is a crucial factor. This research endeavors to introduce a previously unexplored method: the use of artificial neural network-based techniques to detect human respiration under building debris by generating novel simulation-derived electromagnetic data. To achieve this, a realistic three-dimensional debris model was integrated into an electromagnetic simulation program and complemented by a phantom simulating anterior–posterior body movements indicative of respiration. Measurements of magnitude and phase between 150 and 650 MHz were performed under different conditions. Using surrogate models based on artificial neural networks, noise with different signal-to-noise ratios within the selected frequencies was introduced. These models were used to perform two different steps. Firstly, the presence of respiration of living humans trapped under debris was successfully detected with a success rate of 99.97%. Secondly, the difficult task of classifying the respiration patterns of the human was accomplished with an impressive accuracy of 99.69%, providing a solid basis for proof of concept.},
  archive      = {J_NCA},
  author       = {Niyaz, Özden and Tüylü, Tolgahan and Mahouti, Peyman and Erkmen, Burcu and Türker Tokan, Nurhan},
  doi          = {10.1007/s00521-024-09848-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14709-14725},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection and classification of human respiration under building debris model using VHF/UHF waves},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal attention-driven visual question answering for
malayalam. <em>NCA</em>, <em>36</em>(24), 14691–14708. (<a
href="https://doi.org/10.1007/s00521-024-09818-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering is a challenging task that necessitates for sophisticated reasoning over the visual elements to provide an accurate answer to a question. Majority of the state-of-the-art VQA models are only applicable to English questions. However, applications such as visual assistance and tourism necessitate the incorporation of multilingual VQA systems. This paper presents an effective deep learning framework for Malayalam visual question answering (MVQA), which can answer a specific natural language question about an image in Malayalam. As there is no available dataset in English–Malayalam VQA, a MVQA dataset was created by translating English question–answer pairs from the visual genome dataset. The paper proposes an attention-driven MVQA model on the developed dataset. The proposed MVQA model uses a deep learning-based co-attention mechanism to jointly learn the attention for images and Malayalam questions. A second-order multimodal factorized high-order pooling is used for multi modal feature fusion. Different VQA models using combinations of classical CNNs and RNNs were experimented on the developed MVQA dataset, and the performance was compared against the proposed attention-driven model. Experimental results show that the proposed attention-driven MVQA model achieves state-of-the-art results as compared to other models for MVQA on the custom Malayalam VQA dataset.},
  archive      = {J_NCA},
  author       = {Kovath, Abhishek Gopinath and Nayyar, Anand and Sikha, O. K.},
  doi          = {10.1007/s00521-024-09818-4},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14691-14708},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal attention-driven visual question answering for malayalam},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Observer-based practical prescribed time control for
fractional-order nonlinear systems with asymmetric state constraints.
<em>NCA</em>, <em>36</em>(24), 14673–14689. (<a
href="https://doi.org/10.1007/s00521-024-09801-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary emphasis of this work is on investigating the practical prescribed time tracking issue for a type of fractional-order state constrained system with immeasurable states. These unknown system states are estimated by developing a neural state observer. Then, to further address the issue of asymmetric state constraints in fractional-order systems, the improved barrier Lyapunov function is utilized throughout dynamic surface control. On this basis, the practical prescribed time control approach is presented, which not only assures that the state signals do not cross the predetermined bounds, but also that the tracking error converges to the predefined set within a prescribed time. Finally, the effectiveness and practicability of the suggested control mechanism are shown by means of two example simulations.},
  archive      = {J_NCA},
  author       = {Chen, Lu and Chen, Fa and Fang, Jian-an},
  doi          = {10.1007/s00521-024-09801-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14673-14689},
  shortjournal = {Neural Comput. Appl.},
  title        = {Observer-based practical prescribed time control for fractional-order nonlinear systems with asymmetric state constraints},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Batch data recovery from gradients based on generative
adversarial networks. <em>NCA</em>, <em>36</em>(24), 14661–14672. (<a
href="https://doi.org/10.1007/s00521-024-09870-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the federated learning scenario, the private data are kept local, and gradients are shared to train the global model. Because gradients are updated according to the private training data, the features of the data are encoded into gradients. Prior work proved the possibility of reconstructing the private training data based on gradients. However, only a small batch of images can be recovered, and the reconstruction quality, especially against the large batch size of images, is unsatisfactory. To improve the quality of reconstruction of a large batch of images, a generative gradient inversion attack based on a regulation term is designed, which is called fDLG. First, a regulation term that can avoid drastic variations within image regions is proposed, which is based on the cognition that changes between image pixels are gradual. The proposed regulation term encourages the synthesized dummy image to be piece-wise smooth. Second, generative adversarial networks are trained to improve the quality of the attack with the global model used as a discriminator. Simulation shows that large batches of images (128 images on CIFAR100, 256 images on MNIST) can be faithfully reconstructed at high resolution, and even large images from ImageNet can be reconstructed.},
  archive      = {J_NCA},
  author       = {Huang, Yunbo and Chen, Yuwen and Martí­nez-Ortega, José-Fernán and Yu, Haiyang and Yang, Zhen},
  doi          = {10.1007/s00521-024-09870-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14661-14672},
  shortjournal = {Neural Comput. Appl.},
  title        = {Batch data recovery from gradients based on generative adversarial networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Enhancing intrusion detection in IIoT: Optimized CNN model
with multi-class SMOTE balancing. <em>NCA</em>, <em>36</em>(24),
14643–14659. (<a
href="https://doi.org/10.1007/s00521-024-09857-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces an intrusion detection system (IDS) tailored for industrial internet of things (IIoT) environments based on an optimized convolutional neural network (CNN) model. The model is trained on a dataset that was balanced using a novel multi-class implementation of synthetic minority over-sampling technique (SMOTE) that ensures equal representation of all classes. Additionally, systematic optimization will be used to fine tune the hyperparameters of the CNN model and mitigate the effects of the increased size of the training dataset. Evaluation results will demonstrate substantial improvement in performance when the optimized CNN model is trained on the balanced dataset. The proposed IDS will be evaluated using the IIoT-specific WUSTL-IIOT-2021 dataset, and then its generalization capability will be verified using the non-domain specific UNSW_NB15 dataset. The model’s performance will be evaluated using accuracy, precision, recall, and F1-score metrics. The results will demonstrate that the proposed IDS is highly effective with performance exceeding 99.9% on all performance metrics. The IDS is also highly effective in detecting intrusion for generic IT networks achieving improvements in excess of 30% compared to the default baseline model. The results emphasize the versatility and effectiveness of the proposed IDS model, making it a reliable and adaptable solution for enhancing network security across diverse network environments.},
  archive      = {J_NCA},
  author       = {Eid, Abdulrahman Mahmoud and Soudan, Bassel and Nassif, Ali Bou and Injadat, MohammadNoor},
  doi          = {10.1007/s00521-024-09857-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14643-14659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing intrusion detection in IIoT: Optimized CNN model with multi-class SMOTE balancing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient multi-foci networks for 3D skeleton-based human
motion prediction. <em>NCA</em>, <em>36</em>(24), 14627–14642. (<a
href="https://doi.org/10.1007/s00521-024-09817-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve 3D skeleton-based human motion prediction, attention-based methods have encouraged performance due to the observation that attention parts in the past state influence future actions. The model can identify the most relevant information for motion prediction by introducing an attention mechanism. However, existing methods tend to address the general allocation of attention without further exploiting the precision to pinpoint the exact location of the most relevant information. This oversight subsequently curtails the potential of prediction performance. To solve this problem, we propose a novel Gradient Multi-Foci Network (GMFnet), which leverages two-stage foci: spectral focus and spatial focus, to find the most pertinent information in a manner that emulates natural cognitive processes. The core idea of the proposed GMFnet is based on two aspects: spectral focus to model the repeatability of the observation action sequence by deploying an attention-based Related Sequences Directing Block (RSDB), spatial focus to capture the most valuable parts between motion joints by using Attention Feature Computational Unit (AFCU). Extensive experiments are conducted to reveal that GMFnet can capture the precision to pinpoint the exact attention location, thus enhancing the prediction performance. The proposed GMFnet outperforms state-of-the-art methods by 10.7 and 7.4% of MPJPEs for short-term and long-term prediction in Human 3.6M and by 14.3 and 4.8% of MPJPEs for short-term and long-term forecast in CMU-Mocap. Moreover, GMFnet outperforms even more in short term by 24.9% in AMASS. The code is available at https://github.com/JunyuShi02/GMFNet .},
  archive      = {J_NCA},
  author       = {Shi, Junyu and Zhong, Jianqi and He, Zhiquan and Cao, Wenming},
  doi          = {10.1007/s00521-024-09817-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {24},
  pages        = {14627-14642},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gradient multi-foci networks for 3D skeleton-based human motion prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Novel deep genetic ensemble of classifiers
for arrhythmia detection using ECG signals. <em>NCA</em>,
<em>36</em>(23), 14625. (<a
href="https://doi.org/10.1007/s00521-024-10083-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Pławiak, Paweł and Acharya, U. Rajendra},
  doi          = {10.1007/s00521-024-10083-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14625},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Novel deep genetic ensemble of classifiers for arrhythmia detection using ECG signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A self-adaptive genetic algorithm with
improved mutation mode based on measurement of population diversity.
<em>NCA</em>, <em>36</em>(23), 14623. (<a
href="https://doi.org/10.1007/s00521-024-10081-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sun, Na and Lu, Yong},
  doi          = {10.1007/s00521-024-10081-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14623},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A self-adaptive genetic algorithm with improved mutation mode based on measurement of population diversity},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: IoT-based 3D convolution for video salient
object detection. <em>NCA</em>, <em>36</em>(23), 14621. (<a
href="https://doi.org/10.1007/s00521-024-10072-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Dong, Shizhou and Gao, Zhifan and Pirbhulal, Sandeep and Bian, Gui-Bin and Zhang, Heye and Wu, Wanqing and Li, Shuo},
  doi          = {10.1007/s00521-024-10072-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14621},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: IoT-based 3D convolution for video salient object detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Study on the spatial–temporal change
characteristics and influence factors of fog and haze pollution based on
GAM. <em>NCA</em>, <em>36</em>(23), 14619. (<a
href="https://doi.org/10.1007/s00521-024-10070-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Wu, Zhuang and Zhang, Shuo},
  doi          = {10.1007/s00521-024-10070-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14619},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Study on the spatial–temporal change characteristics and influence factors of fog and haze pollution based on GAM},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Optimized feature selection algorithm based
on fireflies with gravitational ant colony algorithm for big data
predictive analytics. <em>NCA</em>, <em>36</em>(23), 14617. (<a
href="https://doi.org/10.1007/s00521-024-10075-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {AlFarraj, Osama and AlZubi, Ahmad and Tolba, Amr},
  doi          = {10.1007/s00521-024-10075-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14617},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Optimized feature selection algorithm based on fireflies with gravitational ant colony algorithm for big data predictive analytics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Using hardware counter-based performance
model to diagnose scaling issues of HPC applications. <em>NCA</em>,
<em>36</em>(23), 14615. (<a
href="https://doi.org/10.1007/s00521-024-10074-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ding, Nan and Xu, Shiming and Song, Zhenya and Zhang, Baoquan and Li, Jingmei and Zheng, Zhigao},
  doi          = {10.1007/s00521-024-10074-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14615},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Using hardware counter-based performance model to diagnose scaling issues of HPC applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual contextual bandit for recommendation under
delayed feedback. <em>NCA</em>, <em>36</em>(23), 14599–14613. (<a
href="https://doi.org/10.1007/s00521-024-09800-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommendation system has far-reaching significance and great practical value, which alleviates people’s troubles about choosing from a huge amount of information. The existing recommendation system usually faces the selection bias problem due to the ignorance of samples with delayed feedback. To alleviate this problem, by modeling the recommendation as a batch contextual bandit problem, we propose a counterfactual reward estimation approach in this work. First, we formalize the counterfactual problem as “would the user be interested in the recommended item if the delayed time is before the collection time point?&quot;. The above counterfactual reward is estimated in a survival analysis framework, by fully exploring the causal generation process of user feedback on batch data. Second, based on the above estimated counterfactual rewards, the policy of batch contextual bandit is updated for online recommendation in the next episode. Third, new batch data are generated in the online recommendation for further counterfactual reward estimation. The above three steps are iteratively conducted until the optimal policy is learned. We also prove the sub-linear regret bound of the learned bandit policy theoretically. Our method achieved a $$4\%$$ improvement in average reward compared to the baseline methods in experiments conducted on synthetic and Criteo datasets, demonstrating the efficacy of our approach.},
  archive      = {J_NCA},
  author       = {Cai, Ruichu and Lu, Ruming and Chen, Wei and Hao, Zhifeng},
  doi          = {10.1007/s00521-024-09800-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14599-14613},
  shortjournal = {Neural Comput. Appl.},
  title        = {Counterfactual contextual bandit for recommendation under delayed feedback},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A feature selection method based on shapley values robust
for concept shift in regression. <em>NCA</em>, <em>36</em>(23),
14575–14597. (<a
href="https://doi.org/10.1007/s00521-024-09745-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is one of the most relevant processes in any methodology for creating a statistical learning model. Usually, existing algorithms establish some criterion to select the most influential variables, discarding those that do not contribute to the model with any relevant information. This methodology makes sense in a static situation where the joint distribution of the data does not vary over time. However, when dealing with real data, it is common to encounter the problem of the dataset shift and, specifically, changes in the relationships between variables (concept shift). In this case, the influence of a variable cannot be the only indicator of its quality as a regressor of the model, since the relationship learned in the training phase may not correspond to the current situation. In tackling this problem, our approach establishes a direct relationship between the Shapley values and prediction errors, operating at a more local level to effectively detect the individual biases introduced by each variable. The proposed methodology is evaluated through various examples, including synthetic scenarios mimicking sudden and incremental shift situations, as well as two real-world cases characterized by concept shifts. Additionally, we perform three analyses of standard situations to assess the algorithm’s robustness in the absence of shifts. The results demonstrate that our proposed algorithm significantly outperforms state-of-the-art feature selection methods in concept shift scenarios, while matching the performance of existing methodologies in static situations.},
  archive      = {J_NCA},
  author       = {Sebastián, Carlos and González-Guillén, Carlos E.},
  doi          = {10.1007/s00521-024-09745-4},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14575-14597},
  shortjournal = {Neural Comput. Appl.},
  title        = {A feature selection method based on shapley values robust for concept shift in regression},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ALP-net: A segmentation-free approach for license plate
recognition in unconstrained scenarios. <em>NCA</em>, <em>36</em>(23),
14559–14574. (<a
href="https://doi.org/10.1007/s00521-024-09840-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {License plate recognition technology is of paramount importance in intelligent transportation. While ideal scenario license plate recognition technology has gradually matured, traditional methods still exhibit limitations in performance under unconstrained scenarios. Although network models based on the recurrent neural network structure address some shortcomings of traditional methods to a certain extent, they constraints in recognition speed. To address these issues, we introduce and implements ALP-Net, a novel structural model, aimed at enhancing the robustness and efficiency of license plate recognition in diverse and challenging scenarios. The model utilizes a fully convolutional structure and custom attention mechanism modules (GFE-Block, ALP-Attention) to ensure speed while significantly improving recognition for low-quality license plates. Introducing synthetic data and a dynamic random perturbation mechanism further enhances the model’s generalization ability. We believe this model can elevate performance while maintaining a low computational complexity. Extensive experiments indicate that our approach outperforms state-of-the-art methods on the CCPD dataset and demonstrates robust generalization capabilities on the CLPD and CRPD datasets. The code and datasets can be available from https://github.com/HeYaoting666/ALP-Net .},
  archive      = {J_NCA},
  author       = {He, Yaoting and Zhou, Xin and Zhou, Tao and Chen, Yuanyuan},
  doi          = {10.1007/s00521-024-09840-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14559-14574},
  shortjournal = {Neural Comput. Appl.},
  title        = {ALP-net: A segmentation-free approach for license plate recognition in unconstrained scenarios},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCAD: Multi-classification anomaly detection with relational
knowledge distillation. <em>NCA</em>, <em>36</em>(23), 14543–14557. (<a
href="https://doi.org/10.1007/s00521-024-09838-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of deep learning in anomaly detection (AD), industrial vision AD has achieved remarkable success. However, current AD usually focuses on anomaly localization and rarely investigates anomaly classification. Furthermore, anomaly classification is currently requested for quality management and anomaly reason analysis. Therefore, it is essential to classify anomalies while improving the accuracy of AD. This paper designs a novel multi-classification AD (MCAD) framework to achieve high-accuracy AD with an anomaly classification function. In detail, the proposal model based on relational knowledge distillation consists of two components. The first one employs a teacher–student AD model, utilizing a relational knowledge distillation approach to transfer the interrelationships of images. The teacher–student critical layer feature activation values are used in the knowledge transfer process to achieve anomaly detection. The second component realizes anomaly multi-classification using the lightweight convolutional neural network. Our proposal has achieved 98.95, 96.04, and 92.94% AUROC AD results on MNIST, FashionMNIST, and CIFAR10 datasets. Meanwhile, we earn 97.58 and 98.10% AUROC for AD and localization in the MVTecAD dataset. The average classification accuracy of anomaly classification has reached 76.37% in fifteen categories of the MVTec-AD dataset. In particular, the classification accuracy of the leather category has gained 95.24%. The results on the MVTec-AD dataset show that MCAD achieves excellent detection, localization, and classification results.},
  archive      = {J_NCA},
  author       = {Li, Zhuo and Ge, Yifei and Yue, Xuebin and Meng, Lin},
  doi          = {10.1007/s00521-024-09838-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14543-14557},
  shortjournal = {Neural Comput. Appl.},
  title        = {MCAD: Multi-classification anomaly detection with relational knowledge distillation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot learning and modeling of 3D reservoir properties
for predicting oil reservoir production. <em>NCA</em>, <em>36</em>(23),
14527–14541. (<a
href="https://doi.org/10.1007/s00521-024-09834-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The oil and gas industry employs numerical simulation tools extensively in reservoir analysis and strategic planning. This study presents a machine-learning proxy model, employing a Few-shot Learning approach with a Deep Convolutional Generative Adversarial Network (DC-GAN) to reduce computational costs using fewer training samples. The DC-GAN generates new training samples by synthesizing spatial attributes, reservoir parameters, and time series data, thus enhancing the sample variability and diversity needed for accurate production prediction. Also, the study proposes a straightforward and efficient method for data augmentation that primarily involves replicating the initial training dataset. The accumulated production forecast generated from geostatistical realizations enables intelligent reservoir management through risk analysis. The technique can reduce the processing footprint by 70%. Unlike most reservoir studies that employ synthetic datasets, this investigation adopts a real, high-dimensional, and complex reservoir model.},
  archive      = {J_NCA},
  author       = {Cirac, Gabriel and Avansi, Guilherme Daniel and Farfan, Jeanfranco and Schiozer, Denis José and Rocha, Anderson},
  doi          = {10.1007/s00521-024-09834-4},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14527-14541},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot learning and modeling of 3D reservoir properties for predicting oil reservoir production},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel robust elman neural network-based predictive models
for bubble point oil formation volume factor and solution gas–oil ratio
using experimental data. <em>NCA</em>, <em>36</em>(23), 14503–14526. (<a
href="https://doi.org/10.1007/s00521-024-09821-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bubble point oil formation volume factor (Bob) and solution gas–oil ratio (Rs) are two crucial PVT parameters used for modeling and volumetric calculations in petroleum industry. They are usually determined in laboratory or estimated using empirical correlations. Experimental methods are time-consuming and expensive where empirical correlations have limitations. Artificial intelligence can be sued overcome these limitations to develop more accurate, robust, and quick predictive tools. In this paper, we used three artificial neural network algorithms to develop intelligent models to predict Bob and Rest using 465 experimental data. Application of the Elman neural network (ENN) for this purpose is being reported for the first time. A variety of input parameters were selected based on a sensitivity analysis which include reservoir temperature (T), oil API gravity (°API), bubble point pressure (Pb), gas-specific gravity (γg), and Rs was used to predict the Bob. T, °API, Pb, γg, and Bob was used to predict the Rs. The ENN model was found superior to the other developed smart models and the empirical correlations with coefficient of determination (R2) of 0.993, root mean square error (RMSE) of 0.0093, and average absolute percent relative error (AAPRE) of 0.93% for the Bob and 0.999, 0.016, and 6.72% for the Rs, respectively. The ENN network has fewer adjustable parameters and provides faster training capabilities using fewer neurons and hidden layers compared to other ANN algorithms. The developed smart predictive tools can be safely used instead of laboratory methods and empirical correlations for a much wider ranges of input parameters and with higher accuracy and confidence.},
  archive      = {J_NCA},
  author       = {Kohzadvand, Kamyab and Mahmoudi Kouhi, Maryam and Ghasemi, Mehdi and Shafiei, Ali},
  doi          = {10.1007/s00521-024-09821-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14503-14526},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel robust elman neural network-based predictive models for bubble point oil formation volume factor and solution gas–oil ratio using experimental data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-channel graph contrastive learning for multi-label
classification with label-specific features and label correlations.
<em>NCA</em>, <em>36</em>(23), 14483–14502. (<a
href="https://doi.org/10.1007/s00521-024-09810-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label classification scenarios, the labels have both interactive correlations and their own respective characteristics. It is a meaningful but challenging task that learning the discriminative features specific to each label while simultaneously utilizing the correlations among multiple labels. Recently, the graph-based methods that can collaboratively learn label-specific features and correlated label semantics have shown tremendous potential for multi-label classification tasks. However, these approaches only calculate the co-occurrence probabilities between pairwise labels; they ignore high-order label correlations. Moreover, the topological structure of the label relational graph employed in this type of method is completely fixed, making the label correlations heavily dataset-dependent and limiting the generalization ability of the method. To address these issues, we propose a dual-channel graph contrastive learning method named DGCL to generate label-specific features using both second-order and high-order label correlations. Specifically, a hypergraph neural network is first employed to explore high-order label correlations. Second, an adaptive graph convolutional neural network is designed to model second-order label correlations. Finally, we construct a contrastive learning objective to collaboratively update these two label correlation semantics, which are subsequently used to guide the process of generating label-specific features. Experimental results on ten benchmark datasets demonstrate that the proposed method outperforms the state-of-the-art multi-label classification methods.},
  archive      = {J_NCA},
  author       = {Zhu, Xiaoyan and Zhu, Tong and Li, Jiaxuan and Wang, Jiayin},
  doi          = {10.1007/s00521-024-09810-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14483-14502},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual-channel graph contrastive learning for multi-label classification with label-specific features and label correlations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based automatic analysis of legal contracts: A
named entity recognition benchmark. <em>NCA</em>, <em>36</em>(23),
14465–14481. (<a
href="https://doi.org/10.1007/s00521-024-09869-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity recognition and extraction from contracts play a crucial role in automating contract analysis and extracting valuable information. Named Entity Recognition (NER) techniques are used for identifying and classifying specific entities such as parties, dates, amounts, and clauses within contracts. In this study, we create a high-quality NER dataset from various types of English language contracts by considering their structure, and the legal terminology used within these documents. We present a systematic approach to manually annotate contracts with appropriate entity labels, ensuring accuracy and consistency. The resulting NER dataset serves as a valuable resource for training and evaluating NER models for contract analysis tasks. We evaluate the performance of NER on this dataset using a range of methods. These methods include Conditional Random Fields, various Bidirectional LSTM configurations, and BERT models. Each of these models brings different strengths and capabilities to the task of entity recognition, allowing for a comprehensive evaluation and the selection of the best models over the dataset. Among these, the NER model based on Contracts–BERT–base from the Legal–BERT family, which is pre-trained specifically on English contracts, outperformed all others, achieving an impressive overall F1 score of 0.94.},
  archive      = {J_NCA},
  author       = {Aejas, Bajeela and Belhi, Abdelhak and Zhang, Haiqing and Bouras, Abdelaziz},
  doi          = {10.1007/s00521-024-09869-7},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14465-14481},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based automatic analysis of legal contracts: A named entity recognition benchmark},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Software effort estimation using convolutional neural
network and fuzzy clustering. <em>NCA</em>, <em>36</em>(23),
14449–14464. (<a
href="https://doi.org/10.1007/s00521-024-09855-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adopting an efficient software process model is critical for building high-quality software applications. An important factor impacting the software development process is an accurate estimate of human effort required to complete the software project. While machine learning methods were historically used to develop estimation models, there has been little investigation into the potential of deep convolutional neural networks (DCNNs) for improving software effort estimation. One of the biggest obstacles in using DCNN for this purpose is the common nature of software datasets, which often consist of vectorized samples rather than matrices. To defeat this obstacle and reduce vagueness in software attribute measurement, this study uses Fuzzy theory to generate an appropriate two-dimensional datapoint representation. The fuzzy clustering is commonly used to split dataset samples into separate clusters, which can help to generate Fuzzy membership functions. This approach makes it easier to generate a two-dimensional array representation for each data sample based on the membership values, allowing it to be used as input to the DCNN model. The efficiency of the proposed model was thoroughly evaluated using PROMISE benchmark datasets. The findings based on mean absolute errors and standardized accuracy show that our proposed model produced very good performance with low error rates and outperformed several current state-of-the-art effort estimation models. Nonetheless, further research is needed to determine the impact of different cluster numbers and features on the performance of our model. In conclusion, this study emphasizes the possibility for incorporating DCNN into software effort estimates and highlights the viability of utilizing fuzzy modeling and clustering techniques to enhance the data representation of software datasets.},
  archive      = {J_NCA},
  author       = {Azzeh, Mohammad and Alkhateeb, Abedalrhman and Bou Nassif, Ali},
  doi          = {10.1007/s00521-024-09855-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14449-14464},
  shortjournal = {Neural Comput. Appl.},
  title        = {Software effort estimation using convolutional neural network and fuzzy clustering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-based prediction of length of stay (LoS) in
the neonatal intensive care unit using ensemble methods. <em>NCA</em>,
<em>36</em>(23), 14433–14448. (<a
href="https://doi.org/10.1007/s00521-024-09831-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neonatal medical data holds critical information within the healthcare industry, and it is important to analyze this data effectively. Machine learning algorithms offer powerful tools for extracting meaningful insights from the medical data of neonates and improving treatment processes. Knowing the length of hospital stay in advance is very important for managing hospital resources, healthcare personnel, and costs. Thus, this study aims to estimate the length of stay for infants treated in the Neonatal Intensive Care Unit (NICU) using machine learning algorithms. Our study conducted a two-class prediction for long and short-term lengths of stay utilizing a unique dataset. Adopting a hybrid approach called Classifier Fusion-LoS, the study involved two stages. In the initial stage, various classifiers were employed including classical models such as Logistic Regression, ExtraTrees, Random Forest, KNN, Support Vector Classifier, as well as ensemble models like AdaBoost, GradientBoosting, XGBoost, and CatBoost. Random Forest yielded the highest validation accuracy at 0.94. In the subsequent stage, the Voting Classifier—an ensemble method—was applied, resulting in accuracy increasing to 0.96. Our method outperformed existing studies in terms of accuracy, including both neonatal-specific length of stay prediction studies and other general length of stay prediction research. While the length of stay estimation offers insights into the potential suitability of the incubators in the NICUs, which are not universally available in every city, for patient admission, it plays a pivotal role in delineating the treatment protocols of patients. Additionally, the research provides crucial information to the hospital management for planning such as beds, equipment, personnel, and costs.},
  archive      = {J_NCA},
  author       = {Erdogan Yildirim, Ayse and Canayaz, Murat},
  doi          = {10.1007/s00521-024-09831-7},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14433-14448},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-based prediction of length of stay (LoS) in the neonatal intensive care unit using ensemble methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive fractional controller design for automatic
voltage regulator system: Sigmoid-based fractional-order PID controller.
<em>NCA</em>, <em>36</em>(23), 14409–14431. (<a
href="https://doi.org/10.1007/s00521-024-09816-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of a power system is to provide safe and reliable electrical energy to consumers. This objective is achieved by maintaining the stability of the power system, a multifaceted concept that can be divided into three distinct classes. The focus of this study is on one of these classes, voltage stability. A critical component in maintaining voltage stability is the automatic voltage regulator (AVR) system of synchronous generators. In this paper, a novel control method, the sigmoid-based fractional-order PID (SFOPID), is introduced with the aim of improving the dynamic response and the robustness of the AVR system. The dandelion optimizer (DO), a successful optimization algorithm, is used to optimize the parameters of the proposed SFOPID control strategy. The optimization process for the DO-SFOPID control strategy includes a variety of objective functions, including error-based metrics such as integral of absolute error, integral of squared error, integral of time absolute error, and integral of time squared error, in addition to the user-defined Zwee Lee Gaing’s metric. The effectiveness of the DO-SFOPID control technique on the AVR system has been rigorously investigated through a series of tests and analyses, including aspects such as time domain, robustness, frequency domain, and evaluation of nonlinearity effects. The simulation results are compared between the proposed DO-SFOPID control technique and the fractional-order PID (FOPID) and sigmoid-based PID (SPID) control techniques, both of which have been tuned using different metaheuristic algorithms that have gained significant recognition in recent years. As a result of these comparative analyses, the superiority of the DO-SFOPID control technique is confirmed as it shows an improved performance with respect to the other control techniques. Furthermore, the performance of the proposed DO-SFOPID control technique is validated within an experimental setup for the AVR system. The simulation results show that the proposed DO-SFOPID control technique is highly successful in terms of stability and robustness. In summary, this study provides comprehensive evidence supporting the effectiveness and superiority of the DO-SFOPID control technique on the AVR system through both simulation and experimental results.},
  archive      = {J_NCA},
  author       = {Sahin, Ali Kivanc and Cavdar, Bora and Ayas, Mustafa Sinasi},
  doi          = {10.1007/s00521-024-09816-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14409-14431},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive fractional controller design for automatic voltage regulator system: Sigmoid-based fractional-order PID controller},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid CGAN-based plant leaf disease classification using
OTSU and surf feature extraction. <em>NCA</em>, <em>36</em>(23),
14395–14407. (<a
href="https://doi.org/10.1007/s00521-024-09812-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture encompasses a way of life and a profession for the general population. Most global traditions and cultures revolve around agriculture. With the help of advanced farming, agriculture may become more profitable, dependable, and able to use resources and time more effectively. The proposed hybrid CGAN using OTSU and SURF (CGAN-OF) model provides a novel framework for plant leaf disease classification. In proposed CGAN-OF model, contrast-limited adaptive histogram equalization is used for image preprocessing and enhancement. The proposed model utilizes OTSU algorithm to speed up the image segmentation without prior knowledge of the images and SURF algorithm to extract the local features using scale-invariant feature transformation. CGAN increases the input plant village dataset using image generation method and identifies the various plant leaf diseases and classifies them. There are three classifications of leaf diseases: fungi, viruses, and bacteria. Furthermore, these classifications contain approximately 300 diseases. The proposed work identified a minimum of 200 diseases in 18,161 major and minor crop species. The investigational investigations are carried out using the Python Jupyter app with the Kaggle Plant Village Dataset and also leaf samples collected from farmers. The proposed framework achieves 99.2% accuracy.},
  archive      = {J_NCA},
  author       = {Saraswathi, E. and Banu, J. Faritha},
  doi          = {10.1007/s00521-024-09812-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14395-14407},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid CGAN-based plant leaf disease classification using OTSU and surf feature extraction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring adversarial examples and adversarial robustness of
convolutional neural networks by mutual information. <em>NCA</em>,
<em>36</em>(23), 14379–14394. (<a
href="https://doi.org/10.1007/s00521-024-09774-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are susceptible to adversarial examples, which are similar to original examples but contain malicious perturbations. Adversarial training is a simple and effective defense method to improve the robustness of CNNs to adversarial examples. Many works explore the mechanism behind adversarial examples and adversarial training. However, mutual information is rarely present in the interpretation of these counter-intuitive phenomena. This work investigates similarities and differences between normally trained CNNs (NT-CNNs) and adversarially trained CNNs (AT-CNNs) from the mutual information perspective. We show that although mutual information trends of NT-CNNs and AT-CNNs are similar throughout training for original and adversarial examples, there exists an obvious difference. Compared with NT-CNNs, AT-CNNs achieve a lower clean accuracy and extract less information from the input. CNNs trained with different methods have different preferences for certain types of information; NT-CNNs tend to extract texture-based information from the input, while AT-CNNs prefer shape-based information. The reason why adversarial examples mislead CNNs may be that they contain more texture-based information about other classes. Furthermore, we also analyze the mutual information estimators used in this work and find that they outline the geometric properties of the middle layer’s output.},
  archive      = {J_NCA},
  author       = {Zhang, Jiebao and Qian, Wenhua and Cao, Jinde and Xu, Dan},
  doi          = {10.1007/s00521-024-09774-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14379-14394},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring adversarial examples and adversarial robustness of convolutional neural networks by mutual information},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMDCF: An effective cross-modal dense cooperative fusion
network for RGB-d SOD. <em>NCA</em>, <em>36</em>(23), 14361–14378. (<a
href="https://doi.org/10.1007/s00521-024-09692-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of vision transformer demonstrates that the transformer structure is also suitable for various vision tasks, including high-level classification tasks and low-level dense prediction tasks. Salient object detection (SOD) is a pixel-level dense prediction task that simulates the most salient objects in human visual recognition scenarios. In recent years, depth images have been widely used for salient object detection. Compared with RGB SOD, the key point of RGB-D SOD is the effective fusion of depth information. As RGB-D SOD requires extracting depth features and fusing cross-modal information, additional computation is involved. However, except for lightweight models, most RGB-D SOD methods tend to obtain better prediction maps by consuming more computational resources. We propose a cross-modal dense cooperative fusion net, which provides state-of-the-art performance with less computation and parameters. We take advantage of the ability of the transformer structure to model long sequence dependencies to extract saliency features from RGB images. Since there is less information in the depth image than in the RGB image, it is not necessary to use the same structure in the depth stream. For the sake of reducing parameters and computation, we consider the asymmetric architecture. It is enough to meet our needs that deep features extracted by lightweight MobileV2Net. Our decoder can perform dense cooperative fusion of cross-modal information while decoding features. It can both effectively fuse cross-modal information and save computation. Comprehensive experiments on multiple benchmark datasets for RGB-D SOD show that compared with SOTA methods, our method performs much better with less computation and parameters.},
  archive      = {J_NCA},
  author       = {Jia, XingZhao and Zhao, WenXiu and Wang, YuMei and DongYe, ChangLei and Peng, YanJun},
  doi          = {10.1007/s00521-024-09692-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14361-14378},
  shortjournal = {Neural Comput. Appl.},
  title        = {CMDCF: An effective cross-modal dense cooperative fusion network for RGB-D SOD},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning-based autonomous attacker to uncover
computer network vulnerabilities. <em>NCA</em>, <em>36</em>(23),
14341–14360. (<a
href="https://doi.org/10.1007/s00521-024-09668-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s intricate information technology landscape, the escalating complexity of computer networks is accompanied by a myriad of malicious threats seeking to compromise network components. To address these security challenges, we propose an approach that synergizes reinforcement learning and deep neural networks. Our method involves training autonomous cyber-agents to strategically attack network nodes, aiming to expose vulnerabilities and extract confidential information. We employ various off-policy deep reinforcement learning algorithms, including deep Q-network (DQN), double DQN, and dueling DQN, to train and evaluate these agents within two enterprise simulation networks provided by Microsoft. The simulations, modeled as Markov games between attack and defense, exclude human intervention. Results demonstrate that agents trained by double DQN and dueling DQN surpass baseline agents trained using traditional reinforcement learning and DQN methods. This approach not only enhances our understanding of network vulnerabilities but also lays the groundwork for future efforts to fortify computer network defense and security.},
  archive      = {J_NCA},
  author       = {Mohamed Ahmed, Ahmed and Nguyen, Thanh Thi and Abdelrazek, Mohamed and Aryal, Sunil},
  doi          = {10.1007/s00521-024-09668-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14341-14360},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning-based autonomous attacker to uncover computer network vulnerabilities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Few-shot classification with intra-class co-salient
learning and holistic metric. <em>NCA</em>, <em>36</em>(23),
14327–14339. (<a
href="https://doi.org/10.1007/s00521-024-09866-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning is to learn to discriminate novel classes from a minimal amount of support images. The core of the matter lies in obtaining effective feature representations from limited samples and measuring the similarity between query and support images. In this paper, we approach this problem from two perspectives: effective feature learning and similarity measurement. We observe that the objects being classified are typically the common salient targets within the support class in few-shot classification. Based on this observation, we design a Co-Salient Feature Extraction module which can learn the correlations among the intra-class samples in the support images, thereby making the learned features more representative of the class. Regarding similarity measurement, we comprehensively consider both the global features and local details of the images and propose a Multi-Scale Metric module to implement holistic metric and improve the reliability of image-to-class measurement. We conduct experiments on four benchmark datasets for few-shot image classification, including general object recognition, fine-grained categorization, and cross-domain classification. The experimental results in various few-shot learning scenarios demonstrate that the proposed Intra-class Co-Salient (ICoS) network achieves competitive performance, particularly excelling in fine-grained classification, ICoS outperforms the similarity techniques DN4 by 20.61% in 1-shot and 11.23% in 5-shot on the CUB dataset, demonstrating the validity of co-salient learning.},
  archive      = {J_NCA},
  author       = {Chen, Baifan and Zhu, Ruyi and Yu, Lingli and Zhao, Yuqian},
  doi          = {10.1007/s00521-024-09866-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14327-14339},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot classification with intra-class co-salient learning and holistic metric},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pathologic myopia diagnosis and localization from retinal
fundus images using custom CNN. <em>NCA</em>, <em>36</em>(23),
14309–14325. (<a
href="https://doi.org/10.1007/s00521-024-09851-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathologic myopia (PM) is the critical factor of irreversible visual artifacts and puts patients at risk of other severe retinal diseases such as glaucoma. Early intervention can help control the disease&#39;s progression and prevent vision loss. Due to its prevalence worldwide, automated detection of PM and its severity is essential. Deep learning-aided diagnosis has proven itself in the field of ophthalmology. The proposed study automatically classifies pathologic and non-pathologic myopia from the fundus images using a guided mini U-Net (GM-U-Net) for feature extraction integrated with a customized convolutional neural network (PMNet) explicitly designed for fundus images. The proposed GM-U-Net allows a deeper network with significantly reduced parameters than conventional U-Net for feature extraction. The proposed PMNet utilizes the features extracted by GM-U-Net to discriminate between PM and a normal retina image. The PMNet classification performance is compared with the other transfer learning models based on the features provided by the GM-U-Net. The combination of GM-U-Net and PMNet outperforms the different models for PM classification. In-depth ablation tests are conducted to realize the current form of PMNet and test its effectiveness. PMNet achieves an accuracy of 90%, average sensitivity of 93%, and specificity of 97% for binary class on the test set, demonstrating it as a valuable tool for early PM detection. Further, to localize the prominent regions in the images, colored heatmap techniques are applied to visualize the affected areas with a hotter color.},
  archive      = {J_NCA},
  author       = {Kumari, Pammi and Saxena, Priyank},
  doi          = {10.1007/s00521-024-09851-3},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14309-14325},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pathologic myopia diagnosis and localization from retinal fundus images using custom CNN},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic sensor fault detection approach using data-driven
techniques. <em>NCA</em>, <em>36</em>(23), 14291–14307. (<a
href="https://doi.org/10.1007/s00521-024-09847-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor fault detection is an important phase for process surveillance. Indeed, successful execution of process tasks depends on the state of the available data. In industrial applications, systems have an uncertain behavior, so methods based on interval principles are useful in this context, such as interval kernel principal component analysis (IKPCA) and Interval-Kernel-Partial-Least Square (IKPLS). These techniques do not always achieve efficiency since they are based on an invariant time. To overcome this restriction, we used a sliding windows principle to develop these methods in dynamic uncertain systems. In addition, a small size of the sliding window can improve the computation time and adapt to the rapidly changing process dynamics. It is for this reason that we propose a second method; the reduced rank moving window IKPCA method (MW-RRIKPCA), In order to improve the performance of the suggested methods based on sliding windows, compared to classical ones, we carried out a comparative study using Tennessee Eastman process (TEP) data and the air quality monitoring network (AIRLOR).},
  archive      = {J_NCA},
  author       = {Hamrouni, Imen and Abdellafou, Khaoula Ben and Aborokbah, Majed and Taouali, Okba},
  doi          = {10.1007/s00521-024-09847-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14291-14307},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic sensor fault detection approach using data-driven techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A sketch recognition method based on bi-modal model using
cooperative learning paradigm. <em>NCA</em>, <em>36</em>(23),
14275–14290. (<a
href="https://doi.org/10.1007/s00521-024-09836-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Static image is an important form of displaying a sketch, representing the appearance information of the sketch. And a stroke sequence composed of several points can also express the shape and contour information of the sketch. Therefore, it is very reasonable to treat a sketch as point-modal data and image-modal data simultaneously. In this paper, a method based on bi-modal model using cooperative learning paradigm is proposed for the sketch recognition task. Specifically, in the point-modal branch, a structural point convolution block is developed by properly dividing local regions to preserve the structural information. In the image-modal branch, the hierarchical residual structure is used to fully extract image-modal features. To reduce the negative impact of noisy samples on the recognition performance, a cooperative learning paradigm is designed based on different perceptual abilities of two modal branches on noisy samples, that is, when training the two branches, the noisy samples can be filtered out through information exchanges and mutual learning. Extensive experiments on the sketch datasets TU-Berlin and QuickDraw show that the proposed method outperforms most baseline methods and has many advantages such as no dependence on additional data and stroke information.},
  archive      = {J_NCA},
  author       = {Zhang, Shihui and Wang, Lei and Cui, Zhiguo and Wang, Shi},
  doi          = {10.1007/s00521-024-09836-2},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14275-14290},
  shortjournal = {Neural Comput. Appl.},
  title        = {A sketch recognition method based on bi-modal model using cooperative learning paradigm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adulterant estimation in paprika powder using deep learning
and chemometrics through near-infrared spectroscopy. <em>NCA</em>,
<em>36</em>(23), 14263–14273. (<a
href="https://doi.org/10.1007/s00521-024-09830-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spices and other food products have been permanently susceptible to adulteration, affecting safety and acceptability when commercialized. A relevant alternative to detect contaminants in food products is to couple near-infrared spectroscopy (NIR) with chemometrics. Among the most accurate chemometric techniques employed to analyze food products, partial least squares regression (PLSR) combines features from and generalizes principal component analysis (PCA) to create compact and accurate models. Other techniques inspired in the human brain, such as multilayer perceptron, the long short-term memory (LSTM) models, and other approaches based on deep learning, take advantage of the high complexity of weights and neurons to train models based on large amounts of data. In this paper, a methodology is proposed to evaluate chemometric tools to estimate the percentage of adulterants in paprika powder using NIR spectroscopy, and three approaches are proposed and compared showing different performances. According to the methodology, the paprika samples were dried and separated into pericarp, peduncle, and seed cake. The resulting elements were finely milled, sieved, and mixed into 21 different combinations with a different percentage of each. Spectral profiles were used to train PLSR, multilayer perceptron, and regression models based on LSTM networks. The models were compared following a k-fold cross-validation strategy. Results showed that PLSR presented the highest $$R^2=0.978$$ for peduncle adulterant estimation, and the lowest $$RMSE=6.24$$ . In particular, when seed cake powder was used as an adulterant, the PLSR approach showed the highest $$R^2=0.981$$ , and the lowest $$RMSE=5.806$$ . The RPD values were higher than 2.000 for all models that use the peduncle as an adulterant and only for models bound to the PLSR in the adulterated samples with pressed seed cake. In summary, the best predictions were obtained using PLSR models, providing evidence of the feasibility of using NIR spectra to estimate the percentage of adulterants in paprika powder.},
  archive      = {J_NCA},
  author       = {Castro, Wilson and Oblitas, Jimy and Nuñez, Luis and Yoplac, Ives and Avila-George, Himer and De-la-Torre, Miguel},
  doi          = {10.1007/s00521-024-09830-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14263-14273},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adulterant estimation in paprika powder using deep learning and chemometrics through near-infrared spectroscopy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining EfficientNet with ML-decoder classification head
for multi-label retinal disease classification. <em>NCA</em>,
<em>36</em>(23), 14251–14261. (<a
href="https://doi.org/10.1007/s00521-024-09820-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal diseases that are not treated in time can cause irreversible, permanent damage, including blindness. Although a patient may suffer from more than one retinal disease at the same time, most of the studies focus on the diagnosis of a single disease only. Therefore, to detect multi-label retinal diseases from color fundus images, we developed an end-to-end deep learning architecture that combines the EfficientNet backbone with the ML-Decoder classification head in this study. While EfficientNet provides powerful feature extraction with fewer parameters via compound scaling, ML-Decoder further improves efficiency and flexibility by reducing quadratic dependency to a linear one and using a group decoding scheme. Also, with the use of sharpness-aware minimization (SAM) optimizer, which minimizes loss value and loss sharpness simultaneously, higher accuracy rates have been reached. In addition, a significant increase in EfficientNet performance is achieved by using image transformations and concatenation together. During the training phase, the random application of the image transformations allows for increasing the image diversity and makes the model more robust. Besides, fusing fundus images of left and right eyes at the pixel level extracts useful information about their relationship. The performance of the final model was evaluated on the publicly available Ocular Disease Intelligent Recognition (ODIR) dataset consisting of 10,000 fundus images, and superior results were obtained in all test set scenarios and performance metrics than state-of-the-art methods. The best results we obtained in the threefold cross-validation scenario for the kappa, F1, and AUC scores are 68.96%, 92.48%, and 94.80%, respectively. Moreover, it can be considered attractive in terms of floating point operations per second (FLOP) and a number of parameters.},
  archive      = {J_NCA},
  author       = {Sivaz, Orhan and Aykut, Murat},
  doi          = {10.1007/s00521-024-09820-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14251-14261},
  shortjournal = {Neural Comput. Appl.},
  title        = {Combining EfficientNet with ML-decoder classification head for multi-label retinal disease classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed personalized imputation based on gaussian
mixture model for missing data. <em>NCA</em>, <em>36</em>(23),
14237–14250. (<a
href="https://doi.org/10.1007/s00521-024-09803-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed machine learning has received much attention for more than two decades. Yet, it is still a challenge to achieve acceptable performance in practical scenarios when some features of data samples are missing. Although some imputation methods have been proposed for handling missing data, their performance deteriorates significantly when data are heterogeneously distributed over different nodes in the network. Considering this, in this article, we first propose a general Gaussian mixture model (GMM) consisting of both public and personalized components for modeling the homogeneous and the heterogeneous parts of data distribution, respectively. Then, we develop a distributed personalized expectation–maximization method based on knowledge transfer (KT-dpEM) to estimate the parameters of the proposed general GMM. After that, based on the estimated general GMM, missing data are imputed using the posterior conditional mean. Experimental results show that the proposed KT-dpEM algorithm has better imputation accuracy, higher robustness against different missing probabilities and better classification performance in the downstream classification tasks, compared with state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Chen, Sicong and Liu, Ying},
  doi          = {10.1007/s00521-024-09803-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14237-14250},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributed personalized imputation based on gaussian mixture model for missing data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-stage multiform optimization for constrained
multi-objective optimization. <em>NCA</em>, <em>36</em>(23),
14173–14235. (<a
href="https://doi.org/10.1007/s00521-024-09787-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of evolutionary algorithms to solve constrained multi-objective optimization problems (CMOPs) with various characteristics and difficulties obtains considerable attention. Most of existing methods tend to introduce an alternate formulation to simplify the original problem and facilitate the solving, which corresponds to the methodology of multiform optimization. Inspired by multiform optimization, this paper proposes a multi-stage multiform optimization framework to solve CMOPs. To prevent the population from falling into local optima in the early stages of evolution, we construct an alternate formulation that ignores all constraints. Meanwhile, in order to utilize high-quality infeasible solutions to explore more feasible regions, we construct another alternate formulation by using a constraint relaxation technique that analyzes the relationships between constraints, evaluating important constraints, and ignoring unimportant constraints. The two formulations provide exclusive and complementary searches in the objective space with the help of knowledge transfer. As both alternate formulations are designed to find the unconstrained Pareto front in the early stages and the final goal must be finding the constrained Pareto front, a multi-stage strategy is devised. Different numbers of alternate formulations are used at different stages to allocate computational resources more effectively. In addition, we propose a hybrid operator strategy to improve the performance of the algorithm by combining the advantages of different operators. Then, 33 instances and 18 real-world CMOPs are selected to evaluate the performance of the algorithm. Experimental results demonstrate the superiority or competitiveness of the proposed approaches.},
  archive      = {J_NCA},
  author       = {Feng, Pengyun and Ming, Fei and Gong, Wenyin},
  doi          = {10.1007/s00521-024-09787-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14173-14235},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-stage multiform optimization for constrained multi-objective optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). GCAT: Graph calibration attention transformer for robust
object tracking. <em>NCA</em>, <em>36</em>(23), 14151–14172. (<a
href="https://doi.org/10.1007/s00521-024-09756-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent Siamese trackers have taken advantage of transformers to achieve impressive advancements. However, existing transformer trackers ignore considering the positional and structural information between tokens, and traditional template update strategies easily introduce noises to the dynamic templates during tracking. In order to alleviate this issue, this paper develops a novel end-to-end graph calibration attention transformer network (GCAT) to enhance tracking robustness and accuracy. A graph calibration attention mechanism is first designed to calibrate and aggregate template information, for effectively updating dynamic templates during the tracking process. Specifically, each token is considered as a node in the graph, and then, we calculate the weight relationships between each node and their adjacent nodes. Thus, this mechanism can aggregate the global context information of the template and search nodes and activate feature channels based on weights and biases to obtain more discriminative feature information. Moreover, we leverage a multi-level dropout mechanism to perform the data dropout, the layer dropout, and the feature dropout on the data, network, and attention levels, respectively, to avoid overfitting of local-specific information and improve the generalization ability. Extensive experiments show the proposed method achieves superior performance on seven challenging benchmark datasets, i.e., OTB100, OTB2013, UAV123, LaSOT, GOT10K, VOT2020, and TrackingNet.},
  archive      = {J_NCA},
  author       = {Chen, Si and Hu, Xinxin and Wang, Da-Han and Yan, Yan and Zhu, Shunzhi},
  doi          = {10.1007/s00521-024-09756-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14151-14172},
  shortjournal = {Neural Comput. Appl.},
  title        = {GCAT: Graph calibration attention transformer for robust object tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wind speed prediction and insight for generalized predictive
modeling framework: A comparative study for different artificial
intelligence models. <em>NCA</em>, <em>36</em>(23), 14119–14150. (<a
href="https://doi.org/10.1007/s00521-024-09677-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind speed (WS) has played a vital role in local urban and sub-urban weather, agriculture, and ecosystem. Several meteorological parameters are influencing WS such as relative humidity (at 2 m, %), surface pressure (kPa), maximum temperature (at 2 m, °C), minimum temperature (at 2 m, °C), average temperature (at 2 m, °C), and all sky insolation incident on a horizontal surface (kW-h/m2/day). The current research was conducted to predict WS at different locations at Vietnam using the feasibility of computer aid models (i.e., multivariate adaptive regression splines (MARS), extreme gradient boosting (XGBoost) and random forest generator (Ranger)). Pearson correlation (PC) was investigated to select the high significant predictors to predict the WS at 10 m high. All inputs (maximum number, 6) are chosen by the PC approach for PhuongNinh, DaNang, and HaNoi; and for minimum number of inputs i.e four, are selected for  PhuongHung, CanTho, and SaPa city; that exhibit the relationship with WS, citywise. The sequence selection of input parameters differed in each station as per the PC analysis. Based on the statistical evaluation and graphical presentation, MARS model attained the best prediction results, followed by XGBoost and Ranger. MARS predictive model remains at the top performance among others based on 95% confidence interval.},
  archive      = {J_NCA},
  author       = {Bhagat, Suraj Kumar and Tiyasha, Tiyasha and Shather, A. H. and Jamei, Mehdi and Kumar, Adarsh and Al-Khafaji, Zainab and Goliatt, Leonardo and Shafik, Shafik S. and Alawi, Omer A. and Yaseen, Zaher Mundher},
  doi          = {10.1007/s00521-024-09677-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14119-14150},
  shortjournal = {Neural Comput. Appl.},
  title        = {Wind speed prediction and insight for generalized predictive modeling framework: A comparative study for different artificial intelligence models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blending shapley values for feature ranking in machine
learning: An analysis on educational data. <em>NCA</em>,
<em>36</em>(23), 14093–14117. (<a
href="https://doi.org/10.1007/s00521-024-09861-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In educational institutions, it is now more important than ever to deliver high-quality academic instruction, and educational data mining is essential for resolving problems that arise from challenging unstructured data in this field. Using machine learning (ML) approaches, the performance of students and traits related to academia, a crucial indicator of higher education, is examined. In the proposed study, the educational dataset is subjected to feature ranking algorithms, including MRMR, ReliefF, Chi-Square, ANOVA, and Kruskal–Wallis, followed by important feature selection using Shapley. The dataset has 16 attributes of integer, categorical type, and after feature ranking approaches, the features with the most important information are chosen and ML techniques are applied to them. It takes two phases to complete the work. The results are obtained after the first phase, in which all features are taken into account for ML training. The second phase of ML training takes into account selective features that are derived using ranking approaches. ML models with only selective attributes are compared to models with all features in order to determine which is more precise. In comparison, the results of the ML models with selective attributes outperformed the models with all attributes. Overall, the ensemblers, i.e., bagged tree and AdaBoost, outperformed other ML techniques such as decision trees, neural networks, naive Bayes, K-nearest neighbor, and support vector machines presented in the proposed study. Bagged trees achieved an accuracy of 81.0 percent, while AdaBoost achieved an accuracy of 74.2 percent.},
  archive      = {J_NCA},
  author       = {Guleria, Pratiyush},
  doi          = {10.1007/s00521-024-09861-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14093-14117},
  shortjournal = {Neural Comput. Appl.},
  title        = {Blending shapley values for feature ranking in machine learning: An analysis on educational data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting autoencoder’s weakness to generate pseudo
anomalies. <em>NCA</em>, <em>36</em>(23), 14075–14091. (<a
href="https://doi.org/10.1007/s00521-024-09790-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rare occurrence of anomalous events, a typical approach to anomaly detection is to train an autoencoder (AE) with normal data only so that it learns the patterns or representations of the normal training data. At test time, the trained AE is expected to well reconstruct normal but to poorly reconstruct anomalous data. However, contrary to the expectation, anomalous data are often well reconstructed as well. In order to further separate the reconstruction quality between normal and anomalous data, we propose creating pseudo anomalies from learned adaptive noise by exploiting the aforementioned weakness of AE, i.e., reconstructing anomalies too well. The generated noise is added to the normal data to create pseudo anomalies. Extensive experiments on Ped2, Avenue, ShanghaiTech, CIFAR-10, and KDDCUP datasets demonstrate the effectiveness and generic applicability of our approach in improving the discriminative capability of AEs for anomaly detection.},
  archive      = {J_NCA},
  author       = {Astrid, Marcella and Zaheer, Muhammad Zaigham and Aouada, Djamila and Lee, Seung-Ik},
  doi          = {10.1007/s00521-024-09790-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14075-14091},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploiting autoencoder’s weakness to generate pseudo anomalies},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Numerical reasoning reading comprehension on vietnamese
COVID-19 news: Task, corpus, and challenges. <em>NCA</em>,
<em>36</em>(23), 14053–14073. (<a
href="https://doi.org/10.1007/s00521-024-09744-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical reasoning-based machine reading comprehension is a challenging task that involves language understanding with arithmetic operations such as addition, subtraction, comparison, and counting. Various studies on numeric-based reading comprehension have been conducted in English, but low-resource languages such as Vietnamese need to be considered more positively. The online COVID-19 news contains much numerical data and is the appropriate data source for this task. To overcome this problem, we propose COVIDROP, the first challenging Vietnamese machine reading comprehension corpus with numerical reasoning for online COVID-19 news articles. The corpus comprises 6594 human-generated question–answer pairs in 841 Vietnamese COVID-19 online news articles. Furthermore, we evaluated the performance of two numerical reasoning-based machine reading comprehension models, NAQANet and NumNet on COVIDROP. NAQANet performed best on the test set with 22.37% exact match (EM) and 26.58% F1. However, human performance (85.47%) is much higher, indicating that the corpus presents a good challenge for future research. Our corpus is available for evaluating numerical reasoning based on machine reading comprehension and question answering.},
  archive      = {J_NCA},
  author       = {Van Nguyen, Kiet and Le, Thang Viet and Do, Tinh Pham-Phuc},
  doi          = {10.1007/s00521-024-09744-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14053-14073},
  shortjournal = {Neural Comput. Appl.},
  title        = {Numerical reasoning reading comprehension on vietnamese COVID-19 news: Task, corpus, and challenges},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameters extraction of photovoltaic models using enhanced
generalized normal distribution optimization with neighborhood search.
<em>NCA</em>, <em>36</em>(23), 14035–14052. (<a
href="https://doi.org/10.1007/s00521-024-09609-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The photovoltaic system has been widely integrated into electrical power grids to produce clean and sustainable energy sources. Precisely modeling of PV systems is crucial to simulate and asset the performance of such power system. Modeling of PV system is a challenge because the characteristic curve of current and voltage is nonlinear and has unknown parameters due to insufficient data points in manufacture’s data sheet. This work proposes generalized normal distribution optimization based on neighborhood search strategies (NSGNDO) to extract the parameter of single diode model (SDM), double diode model (DDM), and PV module model (PVM). The root means square error (RMSE) is used as a performance indicator. Two commercial PV models like RTC France solar cell and PWP201 are used to validate the ability of NSGNDO to precisely estimated the PV system’s parameters. The results show the superiority of NSGNDO over competitive optimization methods and can reduce the RMSE to 2.05296E-03 for PWP201 and to 9.8248E-04 for RTC France solar cell which prove that NSGNDO can be used as competitor method to identify the parameters of PV solar system. The statistical analysis shows the robustness of NSGNDO through statistical measurements and Wilcoxon rank test.’},
  archive      = {J_NCA},
  author       = {Ghetas, Mohamed and Elshourbagy, Motasem},
  doi          = {10.1007/s00521-024-09609-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14035-14052},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parameters extraction of photovoltaic models using enhanced generalized normal distribution optimization with neighborhood search},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High impedance fault classification in microgrids using a
transformer-based model with time series harmonic synchrophasors under
data quality issues. <em>NCA</em>, <em>36</em>(23), 14017–14034. (<a
href="https://doi.org/10.1007/s00521-024-09802-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in distribution networks, driven by the integration of renewable energy sources, have spurred the emergence of microgrids, elevating concerns regarded reliability and stability. In this context, precise monitoring of events, particularly those elusive to detection like high-impedance faults (HIFs), becomes imperative. The development of phasor measurement units (PMUs) with their harmonic synchronized measurements has enhanced the monitoring task and fostering the application of synchrophasors even on microgrids. This work introduces a novel method for event classification in microgrids, utilizing combined low-rate PMU data and harmonic synchrophasor time series. Central to our approach is the usage of a state-of-the-art transformer neural network, based on the attention mechanism, to effectively discern HIFs from other faulty and non-fault events. Notably, this methodology accounts for prevalent PMU data quality issues, including noise, missing data, and synchronism errors. Results from real-world HIF data demonstrate a robust performance, with an accuracy rate of approximately 98% in event classification. This harmonic synchrophasor-based strategy showcases promise as an original approach for handling commercial PMU data, offering sufficient robustness for deployment in real-world applications.},
  archive      = {J_NCA},
  author       = {Cieslak, Dionatan A. G. and Moreto, Miguel and Lazzaretti, André E. and Macedo-Júnior, José R.},
  doi          = {10.1007/s00521-024-09802-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {23},
  pages        = {14017-14034},
  shortjournal = {Neural Comput. Appl.},
  title        = {High impedance fault classification in microgrids using a transformer-based model with time series harmonic synchrophasors under data quality issues},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Tuberculosis (TB) detection system using
deep neural networks. <em>NCA</em>, <em>36</em>(22), 14015. (<a
href="https://doi.org/10.1007/s00521-024-10064-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Dinesh Jackson Samuel, R. and Rajesh Kanna, B.},
  doi          = {10.1007/s00521-024-10064-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {14015},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Tuberculosis (TB) detection system using deep neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Fuzzy curvilinear path optimization using
fuzzy regression analysis for mid vehicle collision detection and
avoidance system analyzed on NGSIM i-80 dataset (real-road scenarios).
<em>NCA</em>, <em>36</em>(22), 14013. (<a
href="https://doi.org/10.1007/s00521-024-10062-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Prabhakaran, N. and Sudhakar, M. S.},
  doi          = {10.1007/s00521-024-10062-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {14013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Fuzzy curvilinear path optimization using fuzzy regression analysis for mid vehicle collision detection and avoidance system analyzed on NGSIM I-80 dataset (real-road scenarios)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: An efficient cost-based algorithm for
scheduling workflow tasks in cloud computing systems. <em>NCA</em>,
<em>36</em>(22), 14011. (<a
href="https://doi.org/10.1007/s00521-024-10060-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Amoon, Mohammed and El-Bahnasawy, Nirmeen and ElKazaz, Mai},
  doi          = {10.1007/s00521-024-10060-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {14011},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An efficient cost-based algorithm for scheduling workflow tasks in cloud computing systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Computer-based cobb angle measurement using
deflection points in adolescence idiopathic scoliosis from radiographic
images. <em>NCA</em>, <em>36</em>(22), 14009. (<a
href="https://doi.org/10.1007/s00521-024-10059-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Al-Bashir, Areen K. and Al-Abed, Mohammad A. and Amari, Hala K. and Al-Rousan, Fadi M. and Bashmaf, Omar M. K. and Abdulhay, Enas W. and Al Abdi, Rabah M. and Arunkumar, N. and Bapu, B. R. Tapas and Al-Basheer, Ahmad K.},
  doi          = {10.1007/s00521-024-10059-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {14009},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Computer-based cobb angle measurement using deflection points in adolescence idiopathic scoliosis from radiographic images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Gray relational clustering model for
intelligent guided monitoring horizontal wells. <em>NCA</em>,
<em>36</em>(22), 14007. (<a
href="https://doi.org/10.1007/s00521-024-10058-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Liang, Haibo and Sun, Yuqi and Li, Guoliang and Li, ZhengLin},
  doi          = {10.1007/s00521-024-10058-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {14007},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Gray relational clustering model for intelligent guided monitoring horizontal wells},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Fault classification and detection in wind
turbine using cuckoo-optimized support vector machine. <em>NCA</em>,
<em>36</em>(22), 14005. (<a
href="https://doi.org/10.1007/s00521-024-10057-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Agasthian, A. and Pamula, Rajendra and Kumaraswamidhas, L. A.},
  doi          = {10.1007/s00521-024-10057-w},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {14005},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Fault classification and detection in wind turbine using cuckoo-optimized support vector machine},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual graph convolution collaborative filtering with
asymmetric neighborhood aggregation. <em>NCA</em>, <em>36</em>(22),
13989–14003. (<a
href="https://doi.org/10.1007/s00521-024-09795-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the superior performance of graph convolutional networks (GCNs) in feature extraction and representation, researchers have introduced GCNs to collaborative filtering (CF) to improve the accuracy of recommendations. However, existing GCN-based CF models still have three shortcomings: degrading the model performance due to symmetric normalization in neighborhood aggregation, underutilizing the node (user or item) representations at lower layers, and failing to alleviate the over-smoothing effect in graph convolution operations. We present a Residual Graph Convolution Collaborative Filtering model with Asymmetric neighborhood aggregation (ARGCCF) to tackle the above shortcomings. Firstly, ARGCCF utilizes asymmetric normalization in neighborhood aggregation, enabling better preservation of high-degree node information for more precisely learning node representations. Secondly, the propagation of ARGCCF embeddings proceeds in two steps. During the initial propagation, a residual connection is established between the node representation of the current layer and the previous layer to utilize the low-level layer’s node representation fully. The embeddings generated after the initial propagation are propagated again in the same graph convolutional layer, which obtains more refined embedding representations to alleviate the over-smoothing problem. Finally, experimentations on five truthful datasets exhibit that ARGCCF has better-improved performance over several mainstream methods.},
  archive      = {J_NCA},
  author       = {Wang, Tao and Qin, Jiwei and Ma, Chao},
  doi          = {10.1007/s00521-024-09795-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13989-14003},
  shortjournal = {Neural Comput. Appl.},
  title        = {Residual graph convolution collaborative filtering with asymmetric neighborhood aggregation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute subspace-guided multi-scale community detection.
<em>NCA</em>, <em>36</em>(22), 13975–13988. (<a
href="https://doi.org/10.1007/s00521-024-09751-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is designed to divide a network into multiple subnetworks (communities) with high cohesiveness, which has attracted wide attention in graph analysis. Attributes are typically served as auxiliary side information to improve the quality of community detection. In spite of their effectiveness, they suffer from two limitations: (1) existing methods usually return a single partition of the network by default, which is a critical requirement and not allowing much flexibility; (2) existing approach just globally assigns the same attribute weights to each community. We believe that community detection should be approached from the perspective of attribute subspace with different dimensional correlations. Toward this end, a novel attribute subspace-guided multi-scale community detection method (ASMS) is proposed, which can identify multi-scale communities with personalized subspaces. Specifically, ASMS can output multiple network divisions of different scales, and each subdivision has a distinctive attribute subspace that is used to reveal the inner meaning of that community formation. In particular, we devise three operators to infer the attribute subspaces. Abundant experimental results indicate that ASMS outperforms the existing methods.},
  archive      = {J_NCA},
  author       = {Yan, Cairui and Ma, Huifang and Tang, Yuechen and Li, Zhixin},
  doi          = {10.1007/s00521-024-09751-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13975-13988},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attribute subspace-guided multi-scale community detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating syntax information into attention mechanism
vector for improved aspect-based opinion mining. <em>NCA</em>,
<em>36</em>(22), 13957–13974. (<a
href="https://doi.org/10.1007/s00521-024-09747-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Aspect-based Sentiment Analysis (ABSA), accurately determining the sentiment polarity of specific aspects within text requires a nuanced understanding of linguistic elements, including syntax. Traditional ABSA approaches, particularly those leveraging attention mechanisms, have shown effectiveness but often fall short in integrating crucial syntax information. Moreover, while some methods employ Graph Neural Networks (GNNs) to extract syntax information, they face significant limitations, such as information loss due to pooling operations. Addressing these challenges, our study proposes a novel ABSA framework that bypasses the constraints of GNNs by directly incorporating syntax-aware insights into the analysis process. Our approach, the Syntax-Informed Attention Mechanism Vector (SIAMV), integrates syntactic distances obtained from dependency trees and part-of-speech (POS) tags into the attention vectors, ensuring a deeper focus on linguistically relevant elements. This not only substantially enhances ABSA accuracy by enriching the attention mechanism but also maintains the integrity of sequential information, a task managed by adopting Long Short-Term Memory (LSTM) networks. The LSTM’s inputs, consisting of syntactic distance, POS tags, and the sentence itself, are processed to generate a syntax vector. This vector is then combined with the attention vector, offering a robust model that adeptly captures the nuances of language. Moreover, the sequential processing capability of LSTM ensures minimal information loss across the text by preserving the context and dependencies inherent in the sentence structure, unlike traditional pooling methods. Our experimental findings demonstrate that this innovative combination of SIAMV and LSTM significantly outperforms existing GNN-based ABSA models in accuracy, thereby setting a new standard for sentiment analysis research. By overcoming the traditional reliance on GNNs and their pooling-induced information loss, our method presents a comprehensive model that adeptly captures and analyzes sentiment at the aspect level, marking a significant advancement in the field of ABSA. The syntax distance programming code for required to replicate the experiment is accessible: https://github.com/Makera86/Syntax-Distance.git .},
  archive      = {J_NCA},
  author       = {Aziz, Makera Moayad and Yaakub, Mohd Ridzwan and Bakar, Azuraliza Abu},
  doi          = {10.1007/s00521-024-09747-2},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13957-13974},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incorporating syntax information into attention mechanism vector for improved aspect-based opinion mining},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Isolation and distillation network for generalized zero-shot
learning. <em>NCA</em>, <em>36</em>(22), 13935–13955. (<a
href="https://doi.org/10.1007/s00521-024-09724-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning (GZSL) aims to identify the samples that belong to a different label space than training samples, while the samples of these unseen classes have the same semantic space as the samples of seen classes. Therefore, most GZSL models use the samples to train the fundamental part, then use semantic information to match or generate the features of the unseen classes as the generalized part. However, the importance of features and their consistency with semantics are different. This difference causes jeopardizing between each other, becoming one of the main reasons that the classification results of seen and unseen classes in the GZSL are lower than the traditional classification and the CZSL. To maintain the training effect from two parts without jeopardizing each other, IDN-GZSL is presented in this paper. We provide rearrangement modules in different isolated scenarios to distinguish the positive and negative parts of the feature and extract the positive features. Three rearrangement modules have been trained using existing training data and generated data in corresponding scenarios. Although the three scenarios are isolated, the decoupling and relation modules are used to support the rearrangement and acquire positive features for semantic information, and the distillation module is used to establish indirect connections. The results demonstrate that our methods take effect with three significant improvements in ablation experiments: successfully trained rearrangement modules for obtaining positive features in multiple scenarios for classification, eliminated jeopardizing among different scenarios by establishing three isolation scenarios, and established necessary connections among them by distillation module. Our method performs the best classification ability of unseen classes on four datasets and achieves the best performance on AWA2, CUB, and FLO when evaluating the method through harmonic means.},
  archive      = {J_NCA},
  author       = {Liang, Yuchuan and Cao, Wenming},
  doi          = {10.1007/s00521-024-09724-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13935-13955},
  shortjournal = {Neural Comput. Appl.},
  title        = {Isolation and distillation network for generalized zero-shot learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A roulette wheel-based pruning method to simplify cumbersome
deep neural networks. <em>NCA</em>, <em>36</em>(22), 13915–13933. (<a
href="https://doi.org/10.1007/s00521-024-09719-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have been applied in many pattern recognition or object detection applications. DNNs generally consist of millions or even billions of parameters. These demanding computational storage and requirements impede deployments of DNNs in resource-limited devices, such as mobile devices, micro-controllers. Simplification techniques such as pruning have commonly been used to slim DNN sizes. Pruning approaches generally quantify the importance of each component such as network weight. Weight values or weight gradients in training are commonly used as the importance metric. Small weights are pruned and large weights are kept. However, small weights are possible to be connected with significant weights which have impact to DNN outputs. DNN accuracy can be degraded significantly after the pruning process. This paper proposes a roulette wheel-like pruning algorithm, in order to simplify a trained DNN while keeping the DNN accuracy. The proposed algorithm generates a branch of pruned DNNs which are generated by a roulette wheel operator. Similar to the roulette wheel selection in genetic algorithms, small weights are more likely to be pruned but they can be kept; large weights are more likely to be kept but they can be pruned. The slimmest DNN with the best accuracy is selected from the branch. The performance of the proposed pruning algorithm is evaluated by two deterministic datasets and four non-deterministic datasets. Experimental results show that the proposed pruning algorithm generates simpler DNNs while DNN accuracy can be kept, compared to several existing pruning approaches.},
  archive      = {J_NCA},
  author       = {Chan, Kit Yan and Yiu, Ka Fai Cedric and Guo, Shan and Jiang, Huimin},
  doi          = {10.1007/s00521-024-09719-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13915-13933},
  shortjournal = {Neural Comput. Appl.},
  title        = {A roulette wheel-based pruning method to simplify cumbersome deep neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cervical cancer classification using sparse stacked
autoencoder and fuzzy ARTMAP. <em>NCA</em>, <em>36</em>(22),
13895–13913. (<a
href="https://doi.org/10.1007/s00521-024-09706-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer (CC) is affecting women predominantly, and early diagnosis could cure this cancer. This study aims to design and develop an effective deep learning-based classification model to detect early CC stages using clinical data. The proposed method is a combination of an unsupervised deep learning and a supervised neural network, i.e. sparse stacked autoencoder (SSAE) and fuzzy adaptive resonance theory MAP (FAM), respectively, and is denoted as SSAE-FAM. Specifically, SSAE is applied to tackle the data sparsity problem. It extracts the representative features from a data set through feature transformation. The transformed features are then classified by FAM. In this study, a CC data set obtained from the University of California Irvine (UCI) machine learning repository is utilised for evaluation. Owing to missing data in the original CC data set, two data sets are generated from the original CC data samples using two data preprocessing techniques. Both generated CC data sets with four target classes (i.e. Schiller, Cytology, Biopsy, and Hinselmann) are evaluated as four independent binary-class problems. We improve the classification performance of FAM by mitigating the data sparsity problem. Based on a series of experimental studies, SSAE-FAM outperforms other state-of-art methods by achieving 99.47%, 99.34%, 99.48%, and 99.81% mean accuracy rates, respectively, with the first CC data set, and 99.74%, 99.86%, 99.77%, and 99.80% mean accuracy rates, respectively, with the second CC data set. The results positively indicate the usefulness of SSAE-FAM for early CC diagnosis.},
  archive      = {J_NCA},
  author       = {Liaw, Lawrence Chuin Ming and Tan, Shing Chiang and Goh, Pey Yun and Lim, Chee Peng},
  doi          = {10.1007/s00521-024-09706-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13895-13913},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cervical cancer classification using sparse stacked autoencoder and fuzzy ARTMAP},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UCTT: Universal and low-cost adversarial example generation
for tendency classification. <em>NCA</em>, <em>36</em>(22), 13865–13894.
(<a href="https://doi.org/10.1007/s00521-024-09760-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adversary makes malicious samples capable of triggering erroneous judgments in deep learning models by introducing imperceptible perturbations to the original benign texts. These malicious samples are referred to as adversarial texts. The exploration of adversarial text generation methods not only facilitates our understanding of the robustness of mainstream deep neural networks against such adversarial attacks but also aids in developing appropriate defensive strategies. Nevertheless, the mainstream research on textual adversarial attacks has mainly focused on attack effectiveness, overlooking the associated attack cost. For real-world attacks, considerations such as the time cost, material cost, manpower cost, and various constraints are also crucial. In this paper, we propose a low-cost adversarial text generation method based on the universal strategy in the black-box attack scenario, Universal Chinese Text Tricker (UCTT), for tendency classification on Chinese texts. UCTT is both text-independent and model-independent, which markedly reduces its attack cost. Instead of crafting adversarial texts for a specific text, UCTT generates universal perturbations based on a universal word substitution list, which is applicable to any data in tendency classification datasets. Given a perturbation rate, we can use the word list to craft adversarial texts by simple substitutions without accessing the target model. In the framework of adversarial text generation based on word importance, UCTT utilizes count, arithmetic progression, linear normalization, and nonlinear normalization to calculate the scores of the important words in the dataset and then computes the candidate word frequencies, which in turn constructs the universal word substitution list. Compared with other black-box methods, the experimental results on real-world tendency classification datasets show that UCTT exhibits an effective attack capability while significantly reducing the attack cost. Compared to the powerful baseline we designed that exceeds the SOTA, UCTT improves the efficiency of adversarial text generation by up to a factor of 7 without accessing the target model. In addition to demonstrating excellent attack performance on mainstream models, UCTT is also capable of attacking the powerful ChatGPT in the physical world, which cannot be directly attacked by traditional adversarial text generation methods due to the hard labels produced by the target model.},
  archive      = {J_NCA},
  author       = {Zhang, Yunting and Ye, Lin and Tian, Zeshu and Chen, Zhe and Zhang, Hongli and Li, Baisong and Fang, Binxing},
  doi          = {10.1007/s00521-024-09760-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13865-13894},
  shortjournal = {Neural Comput. Appl.},
  title        = {UCTT: Universal and low-cost adversarial example generation for tendency classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dose multimodal machine translation can improve translation
performance? <em>NCA</em>, <em>36</em>(22), 13853–13864. (<a
href="https://doi.org/10.1007/s00521-024-09705-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal machine translation (MMT) is a method that uses visual information to guide text translation. However, recent studies have engendered controversy regarding the extent to which MMT can contribute to the improvement of text-enhanced translation. To explore whether the MMT model can improve translation performance, we use the current Neural Machine Translation (NMT) system for evaluation at Multi30K dataset. Specifically, we judge the performance of the MMT model by comparing the difference between the NMT model and the MMT model. At the same time, we conduct text and multimodal degradation experiments to verify whether vision can play a role. We explored the performance of the NMT model and the MMT model for sentences of different lengths to clarify the pros and cons of the MMT model. We found that the performance of the current NMT model surpasses that of the MMT model, suggesting that the impact of visual features might be less significant. Visual features seem to exert influence primarily when a substantial number of words in the source text are masked.},
  archive      = {J_NCA},
  author       = {Cui, ShaoDong and Duan, Kaibo and Ma, Wen and Shinnou, Hiroyuki},
  doi          = {10.1007/s00521-024-09705-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13853-13864},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dose multimodal machine translation can improve translation performance?},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A frequency and two-hop configuration checking-driven local
search algorithm for the minimum weakly connected dominating set
problem. <em>NCA</em>, <em>36</em>(22), 13833–13852. (<a
href="https://doi.org/10.1007/s00521-024-09665-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum weakly connected dominating set problem is a typical NP-hard problem with a wide range of applications. To solve this problem, we propose a frequency property and two-hop configuration checking strategy-driven local search algorithm (FCC2LS). In this algorithm, we first propose a lock-vertex-based initial solution construction procedure. This procedure guarantees that certain vertices, which must be included in the optimal solution, are added to the solution. Second, we propose a two-hop configuration checking strategy and a frequency property. The two-hop configuration checking strategy is a new variant of the original configuration checking strategy, which prohibits vertices with unchanged configuration from being added to the candidate solution. The frequency property is used to record the number of times for each vertex is added to the solution, which can increase the diversity of selected vertices. Third, we combine two scoring functions, Dscore and Nscore, with the above strategies and propose effective vertex selection methods to help the algorithm select suitable vertices to add into or remove from the candidate solutions. Finally, we evaluate the proposed algorithm FCC2LS with four state-of-the-art algorithms on four groups of benchmark instances. Experimental results show that our algorithm performs better on four classical benchmark instances.},
  archive      = {J_NCA},
  author       = {Li, Ruizhi and He, Jintao and Lin, Cuisong and Liu, Ying and Hu, Shuli and Yin, Minghao},
  doi          = {10.1007/s00521-024-09665-3},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13833-13852},
  shortjournal = {Neural Comput. Appl.},
  title        = {A frequency and two-hop configuration checking-driven local search algorithm for the minimum weakly connected dominating set problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling source code in bimodal for program comprehension.
<em>NCA</em>, <em>36</em>(22), 13815–13832. (<a
href="https://doi.org/10.1007/s00521-024-09498-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source code is an intermediary through which humans communicate with computer systems. It contains a large amount of domain knowledge which can be learned by statistical models. Furthermore, this knowledge can be used to build software engineering tools. We find that the functionality of the source code depends on the programming language-specific token which build the base structure, while identifiers provide natural language information. On this basis, we found that the knowledge in the source code can be sufficiently learned more when modeling the source code in bimodal. This paper presents the bimodal composition language model (BCLM) for source code modeling and representation. We analyze the effectiveness of bimodal modeling, and the results show that the bimodal approach has great potential for source code modeling and program comprehension.},
  archive      = {J_NCA},
  author       = {Wen, Dongzhen and Zhang, Xiaokun and Diao, Yufeng and Zhao, Ziyun and Jiang, He and Lin, Hongfei},
  doi          = {10.1007/s00521-024-09498-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13815-13832},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modeling source code in bimodal for program comprehension},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple object tracking based on appearance and motion
graph convolutional neural networks with an explainer. <em>NCA</em>,
<em>36</em>(22), 13799–13814. (<a
href="https://doi.org/10.1007/s00521-024-09773-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tracking performance of Multi-Object Tracking (MOT) has recently been improved by using discriminative appearance and motion features. However, dense crowds and occlusions significantly reduce the reliability of these features, resulting in unsatisfied tracking performance. Thus, we design an end-to-end MOT model based on Graph Convolutional Neural Networks (GCNNs) which fuses four classes of features that characterize objects from their appearances, motions, appearance interactions, and motion interactions. Specifically, a Re-Identification (Re-ID) module is used to extract more discriminative appearance features. The appearance features from object tracklets are then averaged to simplify the proposed tracker. Then, we design two GCNNs to better distinguish objects. One is for extracting interactive appearance features, and the other is for interactive motion features. A fusion module then fuses those features, getting the global feature similarity based on which an association component calculates the MOT matching results. Finally, we semantically visualize relevant structures with the GNNExplainer for insight into the proposed tracker. The evaluation results on MOT16 and MOT17 benchmarks show that our model outperforms the state-of-the-art online tracking methods in terms of Multi-Object Tracking Accuracy and Identification F1 score which is consistent with the results from the GNNExplainer.},
  archive      = {J_NCA},
  author       = {Zhang, Yubo and Huang, Qingming and Zheng, Liying},
  doi          = {10.1007/s00521-024-09773-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13799-13814},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multiple object tracking based on appearance and motion graph convolutional neural networks with an explainer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parsing and encoding interactive phrase structure for
implicit discourse relation recognition. <em>NCA</em>, <em>36</em>(22),
13783–13797. (<a
href="https://doi.org/10.1007/s00521-024-09709-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit discourse relation recognition (IDRR) is to detect and classify relation sense between two text segments without an explicit connective. Existing neural network models learn a semantic representation for each argument from its compositional words and classify discourse relation by the interactive semantic representation of an argument pair. As the basic English unit, a word only carries a simple and limited meaning that may be incorrectly interpreted in an argument without considering its syntactic context. This motivates us to explore whether we can learn an argument’s semantic representation from another language unit phrase which usually contains full contextual meaning. We also argue that some semantic connection in between phrase pairs can be further exploited to infer the discourse relation between arguments. In this paper, we propose an Attentive Phrase Interaction Learning (APIL) model to parse and encode the interactive phrase structure for the IDRR task. In APIL, we propose a minimum subtree algorithm to obtain the phrase sequence of input arguments from its constituency syntax tree. We also design an Attentive Matching Network to learn the representation for each phrase from both arguments’ semantic context and words’ linguistic evidence. Furthermore, we propose a Phrase Inference Network to encode the linguistic relations of phrase pairs as semantic connections for relation inference. Experiments on the PDTB corpus show that our APIL model outperforms the state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Xiang, Wei and Liu, Songtao and Wang, Bang},
  doi          = {10.1007/s00521-024-09709-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13783-13797},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parsing and encoding interactive phrase structure for implicit discourse relation recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Traffic signal optimization framework using interpretable
machine learning technique under heterogeneous-autonomy traffic
environment. <em>NCA</em>, <em>36</em>(22), 13761–13781. (<a
href="https://doi.org/10.1007/s00521-024-09694-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in the industrial revolution and artificial intelligence have aided in the development of novel approaches that have considerable potential for increasing the efficiency of traffic networks. Emerging concepts of autonomous driving and machine learning can be incorporated intelligently for improving traffic operations and control. In the coming years, traffic composition can vary in terms of autonomous vehicle (AV) penetration rate, which can lead to a heterogeneous traffic environment. Traffic control methods for such complex networks need to be designed effectively for accommodating the positive effects of AV implementation without compromising the safety and level of service in the presence of regular vehicles (RVs). An intelligent-based optimization framework for traffic signal control under heterogeneous AV-based traffic is proposed in this paper. This framework utilizes state-of-the-art machine-learning approaches to represent and design different components of the optimization process of cycle length. Further, SHapley Additive exPlanations (SHAP) is used to enhance model interpretability. The proposed optimization framework improves performance under congested traffic conditions compared with that of the conventional optimization methods. Compared to pure RV-based traffic, the penetration rates of 25%, 50%, and 100% can decrease optimized cycle lengths by 26%, 39%, and 53%, respectively, which can result in delay reductions of approximately 18%, 31%, and 56%, respectively. The proposed framework when applied in an adaptive-based manner can help in the generalization of controlling existing signalized intersections with the gradual penetration of AVs without the extra infrastructure or specific operational and connectivity capabilities of the involved vehicles.},
  archive      = {J_NCA},
  author       = {Al-Turki, Mohammed and Kashifi, Mohammad Tamim and Ratrout, Nedal T. and Rahman, Syed Masiur},
  doi          = {10.1007/s00521-024-09694-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13761-13781},
  shortjournal = {Neural Comput. Appl.},
  title        = {Traffic signal optimization framework using interpretable machine learning technique under heterogeneous-autonomy traffic environment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatiotemporal synchronous dynamic graph attention network
for traffic flow forecasting. <em>NCA</em>, <em>36</em>(22),
13745–13759. (<a
href="https://doi.org/10.1007/s00521-024-09675-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow forecasting (TFF) is crucial for effective urban planning and traffic management. Most modeling approaches in TFF ignore the dynamic characteristics of the transportation network topology, which results in an inability to accurately capture the hidden spatiotemporal correlations. To this end, we investigate a Spatiotemporal Synchronous Dynamic Graph Attention Network (STS-DGAT) for TFF. STS-DGAT is composed of three parts: the dynamic feature enhancement (DFE) module, the spatiotemporal coupling (STC) module, and the temporal position embedding (TPE) module. Specifically, we discover the impact of traffic data features on TFF based on the DFE module, assign dynamic weights of various features for time steps, and adjust the intrinsic relevance of traffic data. Then, we propose the STC module to characterize the complex coupling relationships of road network nodes in spatial and temporal dimensions and the dynamic intrinsic interactions of spatiotemporal correlations. The STC module comprises a dynamic graph attention network (DGAT) and an adaptive gated temporal convolutional network (AGTCN). Deep characterization for the dynamic topology of road networks is mined by DGAT, which captures real-time dynamic spatial correlations, and hidden features in the nonlinear temporal dimension are extracted by AGTCN to learn long-term temporal dependency. Finally, we put forward a TPE module to incorporate temporal position information into spatiotemporal relationships and adaptively learn hidden features of individual nodes to understand spatiotemporal variation features effectively. Experimental results from four real-world datasets demonstrate that the STS-DGAT model outperforms other baseline models.},
  archive      = {J_NCA},
  author       = {Xia, Dawen and Lin, Zhan and Chen, Yan and Hu, Yang and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s00521-024-09675-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13745-13759},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatiotemporal synchronous dynamic graph attention network for traffic flow forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applying kumaraswamy distribution on stick-breaking process:
A dirichlet neural topic model approach. <em>NCA</em>, <em>36</em>(22),
13731–13744. (<a
href="https://doi.org/10.1007/s00521-024-09783-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural topic modeling has increasingly raised extensive attention due to its capacity on generating coherent topics and flexible deep neural structures. However, the widely used Dirichlet distribution in shallow topic models is difficult to reparameterize. Therefore, most existing neural topic models assume the Gaussian as the prior of topic proportions for reparameterization. Gaussian distribution does not have the sparsity like Dirichlet distribution, which limits the model’s topic extraction ability. To address this issue, we propose a novel neural topic model approximating the Dirichlet prior with the reparameterizable Kumaraswamy distribution, namely Kumaraswamy Neural Topic Model (KNTM). Specifically, we adopted the stick-breaking process for posterior inference with the Kumaraswamy distribution as the base distribution. Besides, to capture the dependencies among topics, we propose a Kumaraswamy Recurrent Neural Topic Model (KRNTM) based on the recurrent stick-breaking construction to ensure that the model can still generate coherent topical words in high-dimensional topic space. We examined our method on five prevalent benchmark datasets over six Dirichlet-approximating neural topic models, among which KNTM has the lowest perplexity and KRNTM performance best on topic coherence and topic uniqueness. Qualitative analysis of the top topical words verifies that our proposed models can extract more semantically coherent topics compared with state-of-the-art models, further demonstrating our method’s effectiveness. This work contributes to the broader application of VAEs with Dirichlet priors.},
  archive      = {J_NCA},
  author       = {Ouyang, Jihong and Wang, Teng and Cao, Jingyue and Wang, Yiming},
  doi          = {10.1007/s00521-024-09783-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13731-13744},
  shortjournal = {Neural Comput. Appl.},
  title        = {Applying kumaraswamy distribution on stick-breaking process: A dirichlet neural topic model approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of monkeypox infection from clinical symptoms
with adaptive artificial bee colony-based artificial neural network.
<em>NCA</em>, <em>36</em>(22), 13715–13730. (<a
href="https://doi.org/10.1007/s00521-024-09782-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2022, the World Health Organization declared an outbreak of monkeypox, a viral zoonotic disease. With time, the number of infections with this disease began to increase in most countries. A human can contract monkeypox by direct contact with an infected human, or even by contact with animals. In this paper, a diagnostic model for early detection of monkeypox infection based on artificial intelligence methods is proposed. The proposed method is based on training the artificial neural network (ANN) with the adaptive artificial bee colony algorithm for the classification problem. In the study, the ABC algorithm was preferred instead of classical training algorithms for ANN because of its effectiveness in numerical optimization problem solutions. The ABC algorithm consists of food and limit parameters and three procedures: employed, onlooker and scout bee. In the algorithm standard, artificial onlooker bees are produced as much as the number of artificially employed bees and an equal number of limit values are assigned for all food sources. In the advanced adaptive design, different numbers of artificial onlooker bees are used in each cycle, and the limit numbers are updated. For effective exploitation, onlooker bees tend toward more successful solutions than the average fitness value of the solutions, and limit numbers are updated according to the fitness values of the solutions for efficient exploration. The performance of the proposed method was investigated on CEC 2019 test suites as examples of numerical optimization problems. Then, the system was trained and tested on a dataset representing the clinical symptoms of monkeypox infection. The dataset consists of 240 suspected cases, 120 of which are infected and 120 typical cases. The proposed model&#39;s results were compared with those of ten other machine learning models trained on the same dataset. The deep learning model achieved the best result with an accuracy of 75%. It was followed by the random forest model with an accuracy of 71.1%, while the proposed model came third with an accuracy of 71%.},
  archive      = {J_NCA},
  author       = {Muhammed Kalo Hamdan, Ahmed and Ekmekci, Dursun},
  doi          = {10.1007/s00521-024-09782-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13715-13730},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of monkeypox infection from clinical symptoms with adaptive artificial bee colony-based artificial neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A single-stream adaptive scene layout modeling method for
scene recognition. <em>NCA</em>, <em>36</em>(22), 13703–13714. (<a
href="https://doi.org/10.1007/s00521-024-09772-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene recognition has been the foundation of research in computer vision fields. Because scene images typically are composed of specific regions distributed in some layout, so modeling layouts of various scenes is a key clue for scene recognition. Existing methods usually require an additional stream to detect regions for subsequent modeling, which accumulate errors and may miss important information. Meanwhile, they use manual features to model relations between regions, which weakens the representation ability of layouts. In this paper, we propose a single-stream adaptive scene layout modeling approach based on a layout modeling module (LMM), which constructs layouts without additional detection streams and adaptively captures the relations to take advantage of graph attention network. LMM is directly concatenated to a convolutional neural network, where each pixel of the activation maps of the last convolutional layer is defined as a region that is the initial input node of the LMM. LMM first models the layout of each region, and then uses all regions with layout information to model the entire scene. Layout relations are encoded as edges, which are automatically analyzed according to region co-occurrence and relative position. Our work can be understood as optimizing features of the activation maps from a scene layout modeling perspective for scene recognition. Experimental results on MIT67, SUN397, and Places365 show that our single-stream model achieves competitive performance.},
  archive      = {J_NCA},
  author       = {Wang, Qun and Zhu, Feng and Lin, Zhiyuan and Wang, Jianyu and Li, Xiang and Zhao, Pengfei},
  doi          = {10.1007/s00521-024-09772-1},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13703-13714},
  shortjournal = {Neural Comput. Appl.},
  title        = {A single-stream adaptive scene layout modeling method for scene recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Age-invariant face network (AFN): A discriminative model
towards age-invariant face recognition. <em>NCA</em>, <em>36</em>(22),
13689–13702. (<a
href="https://doi.org/10.1007/s00521-024-09752-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age-invariant face recognition (AIFR) is a significant research task in general face recognition, and it aims at eliminating gradual discordance of individual’s facial appearance caused by aging process. Previous discriminative methods decompose facial components over one-dimensional feature vectors which overlooks critical facial information and hypothesize linear relationships over aging process which is inadequate to describe complex correlations. In this paper, we propose an enhanced AIFR model, namely age-invariant face network (AFN), to eliminate the discrepancy of aging process over facial semblance. Specifically, we propose attentive factorization module (AFM) leveraging attention mechanism to decompose facial features into identity-related features and age-related features in two-dimensional space on both local and contextual levels. We take both linear and nonlinear correlation analyses into account for a better reflection of aging/rejuvenation process and hence propose a hybrid correlation regularizer (HCR) to supervise the decorrelation between factorized features. Both identity features and age features are supervised simultaneously in a multi-task learning framework where only identity features are used in test phase for evaluation of AIFR performance. Experiments across common cross-age datasets (e.g., FG-Net, CACD-VS, CALFW, AgeDB-30) show the effectiveness of proposed AFN. Further, our proposed AFN is validated over LFW dataset to demonstrate its effectiveness on general face recognition task.},
  archive      = {J_NCA},
  author       = {Li, Jiarui and Zhou, Li and Chen, Jie},
  doi          = {10.1007/s00521-024-09752-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13689-13702},
  shortjournal = {Neural Comput. Appl.},
  title        = {Age-invariant face network (AFN): A discriminative model towards age-invariant face recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PINN-CHK: Physics-informed neural network for high-fidelity
prediction of early-age cement hydration kinetics. <em>NCA</em>,
<em>36</em>(22), 13665–13687. (<a
href="https://doi.org/10.1007/s00521-024-09791-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cement hydration kinetics, characterized by heat generation in early-age concrete, poses a modeling challenge. This work proposes a physics-informed neural network (PINN) named PINN-CHK designed for cement hydration kinetics, to predict early-age temperature rises in cement paste. PINN-CHK leverages data-driven solutions to craft a high-fidelity prediction model, encompassing material properties and maturity functions in cement hydration. Trained on heated cement paste data, it simultaneously fits experimental results and underlying physics, yielding a mesh-free simulation. Incorporating governing partial differential equations (PDEs), and initial and boundary conditions into its loss function, PINN-CHK architecture undergoes rigorous benchmark testing, demonstrating unparalleled predictive accuracy compared to conventional deep-learning methods. It excels in predicting complete temperature fields during spatial–temporal cement hydration, achieving a remarkable relative L2 error as low as 0.00341. PINN-CHK achieves exceptional convergence and accuracy with only 5% of the training data, ushering in a new era in this crucial field. This innovative approach bridges the gap between theory and practice, offering an attractive alternative to conventional finite element solvers for enhanced comprehension of cement hydration kinetics and concrete maturity and strength development in cement-based materials.},
  archive      = {J_NCA},
  author       = {Rahman, Md Asif and Zhang, Tianjie and Lu, Yang},
  doi          = {10.1007/s00521-024-09791-y},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13665-13687},
  shortjournal = {Neural Comput. Appl.},
  title        = {PINN-CHK: Physics-informed neural network for high-fidelity prediction of early-age cement hydration kinetics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise-tolerant zeroing neural network control for a novel
compliant actuator in lower-limb exoskeletons. <em>NCA</em>,
<em>36</em>(22), 13647–13663. (<a
href="https://doi.org/10.1007/s00521-024-09789-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the safety of direct physical interaction between humans and lower-limb exoskeletons, the actuator of the lower-limb exoskeleton should possess compliance, force controllability, and back-drivability. In this paper, a novel compact compliant force control actuator with worm gear and gear rack as transmission modes is designed to provide flexible power to the lower-limb exoskeleton. The worm gear is utilized to amplify the torque generated by the motor in the compact compliant actuator, while the gear rack is established to improve the bearing capacity. Yet, the friction is occurred between the worm gear, rack and other mechanical configurations which may lead to non-negligible force control error of the compliant actuator. A noise-tolerant zeroing neural network controller is proposed to suppress noises. Additionally, theoretical proofs are provided for the convergence performance of the noise-tolerant zeroing neural network controller, as well as the suppression of constant noise, linear disturbances, and bounded random noise. The proposed noise-tolerant zeroing neural network controller is validated on the compliant actuator through numerical simulations, experimental results, and comparison experiments, demonstrating its effectiveness in suppressing various noise and improving the convergence, stability, and robustness of the compliant actuator system. Additionally, the controller is further verified through walking experiments conducted on a knee robot.},
  archive      = {J_NCA},
  author       = {Sun, Zhongbo and Xu, Changxian and Wang, Gang and Liu, Yongbai and Zhao, Liming and Dong, Mingjie},
  doi          = {10.1007/s00521-024-09789-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13647-13663},
  shortjournal = {Neural Comput. Appl.},
  title        = {Noise-tolerant zeroing neural network control for a novel compliant actuator in lower-limb exoskeletons},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ASGSA: Global semantic-aware network for action
segmentation. <em>NCA</em>, <em>36</em>(22), 13629–13645. (<a
href="https://doi.org/10.1007/s00521-024-09776-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action segmentation is vital for video understanding because it heuristically divides complex untrimmed videos into short semantic clips. Real-world human actions exhibit complex temporal dynamics, encompassing variations in duration, rhythm, and range of motions, etc. While deep networks have been successfully applied to these tasks, they face challenges in effectively adapting to these complex variations due to the inherent difficulty in capturing semantic information from a global perspective. Merely relying on distinguishing visual representations in local regions leads to the issue of over-segmentation. In an attempt to address this practical issue, we propose a novel approach named ASGSA, which aims to obtain smoother segmentation results by extracting instructive semantic information. Our core component, Global Semantic-Aware module, provides an effective way to encode the long-range temporal relation in the long untrimmed video. Specifically, we exploit a hierarchical temporal context aggregation, which is identified by a gated-mechanism selection to control the information passage at different scales. In addition, an adaptive fusion strategy is designed to guide the segmentation with the extracted semantic information. Simultaneously, to obtain higher-quality video representation without extra annotations, we resort to self-supervised training strategy and propose the Video Speed Prediction module. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on all three challenging benchmark datasets (Breakfast, 50Salads, GTEA) and significantly improves the F1 score@50, which represents the reduction of over-segmentation. The code is available at https://github.com/ten000/ASGSA .},
  archive      = {J_NCA},
  author       = {Bian, Qingyun and Zhang, Chun and Ren, Keyan and Yue, Tianyi and Zhang, Yunlu},
  doi          = {10.1007/s00521-024-09776-x},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13629-13645},
  shortjournal = {Neural Comput. Appl.},
  title        = {ASGSA: Global semantic-aware network for action segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory tracking control of a line-following quadcopter
using multilayer type-2 fuzzy petri nets controller. <em>NCA</em>,
<em>36</em>(22), 13617–13627. (<a
href="https://doi.org/10.1007/s00521-024-09750-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel approach to achieve precise trajectory tracking control for a line-following quadcopter by employing a multilayer type-2 fuzzy Petri nets controller (MT2PNC). The MT2PNC dynamically adapts its parameters based on tracking errors, allowing for real-time adjustments to the quadcopter’s tilt angles and flight direction. The effectiveness of the controller is thoroughly evaluated through both simulations and experimental studies. In the experimental study, a camera is integrated into the quadcopter to capture line images, which are then processed using sophisticated image processing algorithms to extract essential line information. This extracted data is subsequently fed into the MT2PNC, enabling the quadcopter to precisely follow the reference line. The simulation and experimental results conclusively demonstrate the superior control efficacy of the MT2PNC, showcasing its remarkable ability to accurately track the quadcopter’s trajectory. The proposed control method exhibits great promise for line-following and trajectory-tracking applications, and its practical implementation holds substantial potential.},
  archive      = {J_NCA},
  author       = {Le, Tien-Loc and Hung, Nguyen Huu},
  doi          = {10.1007/s00521-024-09750-7},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13617-13627},
  shortjournal = {Neural Comput. Appl.},
  title        = {Trajectory tracking control of a line-following quadcopter using multilayer type-2 fuzzy petri nets controller},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the ability of convolutional neural networks for
remote sensing image segmentation using transformers. <em>NCA</em>,
<em>36</em>(22), 13605–13616. (<a
href="https://doi.org/10.1007/s00521-024-09743-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of remote sensing images has emerged as a compelling undertaking in computer vision owing to its use in the development of several applications. The U-Net style has been extensively utilized in many picture segmentation applications, yielding remarkable achievements. Nevertheless, the U-Net has several constraints in the context of remote sensing picture segmentation, mostly stemming from the limited scope of the convolution kernels. The transformer is a deep learning model specifically developed for sequence-to-sequence translation. It incorporates a self-attention mechanism to efficiently process many inputs, selectively retaining the relevant information and discarding the irrelevant inputs by adjusting the weights. However, it highlights a constraint in the localization capability caused by the absence of fundamental characteristics. This work presents a novel approach called U-Net–transformer, which combines the U-Net and transformer models for the purpose of remote sensing picture segmentation. The suggested solution surpasses individual models, such as U-Net and transformers, by combining and leveraging their characteristics. Initially, the transformer obtains the overall context by encoding tokenized picture patches derived from the feature maps of the convolutional neural network (CNN). Next, the encoded feature maps undergo upsampling through a decoder and are then merged with the high-resolution feature maps of the CNN model. This enables the localization to be more accurate. The transformer serves as an unconventional encoder for segmenting remote sensing images. It enhances the U-Net model by capturing localized spatial data, hence improving the capacity to capture intricate details. The U-Net–transformer, as suggested, has demonstrated exceptional performance in remote sensing picture segmentation across many benchmark datasets. The given findings demonstrated the efficacy of integrating the U-Net and transformer model for the purpose of segmenting remote sensing images.},
  archive      = {J_NCA},
  author       = {Barr, Mohammad},
  doi          = {10.1007/s00521-024-09743-6},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13605-13616},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing the ability of convolutional neural networks for remote sensing image segmentation using transformers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid connectionist/LCS for hidden-state problems.
<em>NCA</em>, <em>36</em>(22), 13579–13603. (<a
href="https://doi.org/10.1007/s00521-024-09758-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes and evaluates the performance of a learning classifier system (lcs) inspired algorithm called Temporal Reinforcement And Classification Architecture (traca) on maze navigation tasks which contain hidden state. The evaluation of traca includes comparisons with other learning algorithms on selected difficult maze navigation tasks. Not all lcss are capable of learning all types of hidden-state mazes so traca is specifically compared against selected other lcs-based approaches that are most capable on these tasks, including xcsmh, AgentP (G), and AgentP (SA). Each algorithm is evaluated using a maze navigation task that has been identified as among the most difficult due to recurring aliased regions. The comparisons between algorithms include training time, test performance, and the size of the learned rule sets. The results indicate that each algorithm has its own advantages and drawbacks. For example, on the most difficult maze traca’s average steps to the goal are 10.1 while AgentP (G) are 7.87; however, traca requires an average of only 354 training trials compared with 537 for AgentP (G). Following the maze tasks, traca is also tested on two variations in a truck driving task where it must learn to navigate four lanes of slower vehicles while avoiding collisions. The results show that traca can achieve a low number of collisions with relatively few trials (as low as 24 collisions over 5000 time steps after 10,000 training time steps) but may require multiple network construction attempts to achieve high performance.},
  archive      = {J_NCA},
  author       = {Mitchell, Matthew},
  doi          = {10.1007/s00521-024-09758-z},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13579-13603},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid connectionist/LCS for hidden-state problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). E-waste circular economy decision-making: A comprehensive
approach for sustainable operation management in the UK. <em>NCA</em>,
<em>36</em>(22), 13551–13577. (<a
href="https://doi.org/10.1007/s00521-024-09754-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-waste generation has broadly increased worldwide and is called intense pressure on sustainable practice implementation firms by recycling and redesigning the products. Thus, e-waste operation management in developed countries like the UK has become the top priority and is subjected to multiple sustainable circular economies (CE) contributing factors, including social, technical, environmental, and governmental policies. The authorized decision-makers can benefit from a well-established systematic decision-making tool to assess and evaluate the e-waste operation management considering the potential CE contributing factors. An extensive literature overview is expanded to identify the most relevant and influential contributing factors to e-waste CE. The city of London Metropolitan has been selected as the case location. In this regard, it is necessary to utilize an advanced multi-criteria decision-making tool to explore the interdependency and causality of CE-relevant factors. The present study proposed an innovative decision-making approach to address the multiple contributing factors of causality, interdependency, data, and model uncertainty in practice. It uses the step-wise weighted influence nonlinear gauge system method integrated with Fermatean fuzzy linguistic sets. This study conducted a sensitivity analysis to evaluate the effectiveness of the proposed decision-making approach in e-waste operation management. The results are promising, clearly demonstrating the framework’s competence. The CE index, crucial in designing e-waste operation management strategies, was calculated to be 2.8036. Among the various factors analyzed, “Environmental Management Systems” emerged as the most significant driving factor. This underscores the critical need to improve environmental management systems within e-waste operations.},
  archive      = {J_NCA},
  author       = {Yazdi, Mohammad and Moradi, Rosita and Nedjati, Arman and Ghasemi Pirbalouti, Reza and Li, He},
  doi          = {10.1007/s00521-024-09754-3},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13551-13577},
  shortjournal = {Neural Comput. Appl.},
  title        = {E-waste circular economy decision-making: A comprehensive approach for sustainable operation management in the UK},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Finite-time multistability of a multidirectional
associative memory neural network with multiple fractional orders based
on a generalized gronwall inequality. <em>NCA</em>, <em>36</em>(22),
13527–13549. (<a
href="https://doi.org/10.1007/s00521-024-09736-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addressed the finite-time multistability of a Caputo fractional order multidirectional associative memory neural network (FMAMNN) with multiple orders, where the fractional orders are not limited to 0 to 1. There are three main findings. Firstly, by using Brouwer fixed point theorem, the existence conditions of multiple equilibria of FMAMNN with Gaussian-wavelet-type activation functions were obtained, and the number of equilibria is $$(2+s^2)^l$$ , where the exponent l is determined by the number of neurons, and s is the number of segments in the middle of Gaussian-wavelet-type activation function. Another important contribution of this article is the generalization of the Gronwall inequality. By utilizing the multivariable Mittag-Leffler function, a more general form of the Gronwall inequality was obtained, which can be applied to systems with many different fractional derivatives. Lastly, based on the generalized Gronwall inequality, and using the Laplace transform, inverse Laplace transform, some conditions of finite-time multistability of FMAMNN were found, which depend on all fractional orders. Numerical calculations show that compared to the existing finite-time stability conditions of neural networks, the conditions based on the generalized Gronwall inequality have less conservatism. An example was given to show the validity of theoretical results.},
  archive      = {J_NCA},
  author       = {Liu, Zhiguang and Xu, Xiangyu and Zhou, Tiejun},
  doi          = {10.1007/s00521-024-09736-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13527-13549},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time multistability of a multidirectional associative memory neural network with multiple fractional orders based on a generalized gronwall inequality},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CEA-net: A co-interactive external attention network for
joint intent detection and slot filling. <em>NCA</em>, <em>36</em>(22),
13513–13525. (<a
href="https://doi.org/10.1007/s00521-024-09733-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intent detection and slot filling are two crucial tasks for spoken language understanding, and they are closely related. The accuracy of spoken language understanding depends strongly on the effectiveness of the interaction between intent and slot representations. However, previous studies have primarily focused on exploring the interaction of intent and slot representations within individual utterances while neglecting the relevance of different utterances. The paper proposes the CEA-Net, which utilizes co-interactive external attention as its core mechanism to effectively capture information from multiple utterances and perform information interaction between the two tasks. Experimental results demonstrate that the CEA-Net achieves competitive results on the ATIS and SNIPS benchmarks while reducing the number of parameters by about 44% compared with the previous best open-source approach. Furthermore, since our framework models the correlation of multiple utterances, it shows promising effectiveness and robustness even with limited training resources or datasets.},
  archive      = {J_NCA},
  author       = {Wu, Di and Jiang, Liting and Yin, Lili and Li, Zhe and Huang, Hao},
  doi          = {10.1007/s00521-024-09733-8},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13513-13525},
  shortjournal = {Neural Comput. Appl.},
  title        = {CEA-net: A co-interactive external attention network for joint intent detection and slot filling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diluie: Constructing diverse demonstrations of in-context
learning with large language model for unified information extraction.
<em>NCA</em>, <em>36</em>(22), 13491–13512. (<a
href="https://doi.org/10.1007/s00521-024-09728-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated promising in-context learning capabilities, especially with instructive prompts. However, recent studies have shown that existing large models still face challenges in specific information extraction (IE) tasks. Moreover, it could have more effectively utilized various prompts such as instruction tuning, diverse demonstrations of in-context learning, and long-range token sequences for assisting language modeling in understanding context. In this study, we propose DILUIE, a unified information extraction framework based on in-context learning with diverse demonstration examples. DILUIE is encoded with an EVA attention mechanism and incremental encoding technology. Based on the constructed diverse demonstrations, we expand the size of instances efficiently in both instruction tuning and in-context learning to gain insights into the potential benefits of utilizing diverse information extraction datasets. To deepen the understanding of context, we further design three auxiliary tasks to assist in aligning contextual semantics. Experimental results demonstrate that DILUIE achieves 2.23 and 2.53% improvements in terms of Micor-/Macor-F1 on average relative to the current state-of-the-art baseline, which also significantly outperforms the GPT-3.5-turbo in zero-shot settings, and the average token length of achieving the best performance over tasks is around 15k. Furthermore, we observe that in-context learning shows enhanced performance when provided with more demonstrations during multiple-shot instruction tuning (8 k). Additionally, increasing the length of instructions (10 k) can result in a more substantial improvement in the upper limits of scaling for in-context learning. Code is available on https://github.com/Phevos75/DILUIE .},
  archive      = {J_NCA},
  author       = {Guo, Qian and Guo, Yi and Zhao, Jin},
  doi          = {10.1007/s00521-024-09728-5},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13491-13512},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diluie: Constructing diverse demonstrations of in-context learning with large language model for unified information extraction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RSTFusion: An end-to-end fusion network for infrared and
visible images based on residual swin transfomer. <em>NCA</em>,
<em>36</em>(22), 13467–13489. (<a
href="https://doi.org/10.1007/s00521-024-09716-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion techniques have emerged as powerful methods to harness the unique advantages of diverse sensors, resulting in improved image quality through the preservation of complementary and redundant information from the original images. While deep learning-based methods have gained widespread adoption in this domain, their predominant reliance on convolutional neural networks and limited utilization of transforms pose certain limitations. Notably, convolutional operations fail to effectively capture long-range dependency between images, which hampers the generation of fused images with optimal complementarities. Because of this, we provide an original end-to-end fusion model built on the swin transform. By modeling long-range dependency using a full-attention feature-encoding backbone, which is a pure transform network with stronger representational capabilities than convolutional neural networks, the model overcomes the shortcomings of manual design as well as complex activity-level measurement and fusion rule design. In addition, we present three loss function strategies that are created expressly to enhance similarity constraints and network parameter training, improving the quality of the detailed information in the fused images. Finally, experimental results on four datasets indicated that our method reached the state-of-the-art in both subjective and objective evaluation compared to eleven state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Li, Kaixin and Tang, Haojie and Liu, Gang and Chang, Rui and Xing, Mengliang and Tang, Jianchao},
  doi          = {10.1007/s00521-024-09716-9},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13467-13489},
  shortjournal = {Neural Comput. Appl.},
  title        = {RSTFusion: An end-to-end fusion network for infrared and visible images based on residual swin transfomer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCHIAO: A modified coronavirus herd immunity-aquila
optimization algorithm based on chaotic behavior for solving engineering
problems. <em>NCA</em>, <em>36</em>(22), 13381–13465. (<a
href="https://doi.org/10.1007/s00521-024-09533-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a hybrid Modified Coronavirus Herd Immunity Aquila Optimization Algorithm (MCHIAO) that compiles the Enhanced Coronavirus Herd Immunity Optimizer (ECHIO) algorithm and Aquila Optimizer (AO). As one of the competitive human-based optimization algorithms, the Coronavirus Herd Immunity Optimizer (CHIO) exceeds some other biological-inspired algorithms. Compared to other optimization algorithms, CHIO showed good results. However, CHIO gets confined to local optima, and the accuracy of large-scale global optimization problems is decreased. On the other hand, although AO has significant local exploitation capabilities, its global exploration capabilities are insufficient. Subsequently, a novel metaheuristic optimizer, Modified Coronavirus Herd Immunity Aquila Optimizer (MCHIAO), is presented to overcome these restrictions and adapt it to solve feature selection challenges. In this paper, MCHIAO is proposed with three main enhancements to overcome these issues and reach higher optimal results which are cases categorizing, enhancing the new genes’ value equation using the chaotic system as inspired by the chaotic behavior of the coronavirus and generating a new formula to switch between expanded and narrowed exploitation. MCHIAO demonstrates it’s worth contra ten well-known state-of-the-art optimization algorithms (GOA, MFO, MPA, GWO, HHO, SSA, WOA, IAO, NOA, NGO) in addition to AO and CHIO. Friedman average rank and Wilcoxon statistical analysis (p-value) are conducted on all state-of-the-art algorithms testing 23 benchmark functions. Wilcoxon test and Friedman are conducted as well on the 29 CEC2017 functions. Moreover, some statistical tests are conducted on the 10 CEC2019 benchmark functions. Six real-world problems are used to validate the proposed MCHIAO against the same twelve state-of-the-art algorithms. On classical functions, including 24 unimodal and 44 multimodal functions, respectively, the exploitative and explorative behavior of the hybrid algorithm MCHIAO is evaluated. The statistical significance of the proposed technique for all functions is demonstrated by the p-values calculated using the Wilcoxon rank-sum test, as these p-values are found to be less than 0.05.},
  archive      = {J_NCA},
  author       = {Selim, Heba and Haikal, Amira Y. and Labib, Labib M. and Saafan, Mahmoud M.},
  doi          = {10.1007/s00521-024-09533-0},
  journal      = {Neural Computing and Applications},
  month        = {8},
  number       = {22},
  pages        = {13381-13465},
  shortjournal = {Neural Comput. Appl.},
  title        = {MCHIAO: A modified coronavirus herd immunity-aquila optimization algorithm based on chaotic behavior for solving engineering problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comments on “an application of parametric approach for
interval differential equation in inventory model for deteriorating
items with selling-price-dependent demand.” <em>NCA</em>,
<em>36</em>(21), 13375–13380. (<a
href="https://doi.org/10.1007/s00521-024-10003-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper points out the interval form deficiencies in the recent paper “An application of parametric approach for interval differential equation in inventory model for deteriorating items with selling-price-dependent demand” by Rehman et al. (Neural Comput Appl 32(17):14069–14085, 2020). The comments in this paper pertain mainly to the drawbacks of interval arithmetic (SIA) presented in Section 3 of Rehman et al. (2020) referencing the convention of converting an interval-valued model into a parametric form. Proposed corrections to the overestimation of the interval form through examples are presented.},
  archive      = {J_NCA},
  author       = {Younus, Awais and Javed, Nida},
  doi          = {10.1007/s00521-024-10003-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13375-13380},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comments on “An application of parametric approach for interval differential equation in inventory model for deteriorating items with selling-price-dependent demand”},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Machine learning models for modeling the
biosorption of fe(III) ions by activated carbon from olive stone.
<em>NCA</em>, <em>36</em>(21), 13373. (<a
href="https://doi.org/10.1007/s00521-024-10038-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Massaoudi, Ayman and Echouchene, Fraj and Ben Ayed, Mossaad and Berguiga, Abdelwahed and Harchay, Ahlem and Al-Ghamdi, Sara and Belmabrouk, Hafedh},
  doi          = {10.1007/s00521-024-10038-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13373},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Machine learning models for modeling the biosorption of Fe(III) ions by activated carbon from olive stone},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Machine learning models for modeling the biosorption of
fe(III) ions by activated carbon from olive stone. <em>NCA</em>,
<em>36</em>(21), 13357–13372. (<a
href="https://doi.org/10.1007/s00521-024-09826-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using experimental results related to the biosorption of Fe(III) by activated carbon derived from olive pit waste, we developed and evaluated four artificial neural network (ANN) models in this study, namely MLP-ANN, RBF-ANN, GR-ANN, and PSO-ANN, to predict the removal efficiency of Fe(III) during the adsorption process. The purpose of these models was to forecast the effect of the following five important operational variables: the initial concentration, time, stirring speed, temperature, and biosorbent dose. We conducted a thorough assessment of the performance of these models and compared their ability to predict the removal capacity. Several statistical metrics have been used to quantify the quality of the different models. The results calculated by the machine learning models were analyzed and compared with the experimental results. The obtained values of the coefficient of determination were 0.9997 for the PSO-ANN model, 0.991 for the GR-ANN model, 0.983 for the RBF-ANN model, and 0.837 for the MLP-ANN model concerning the removal efficiency. All the studied models are able to accurately predict the adsorbed quantity. ANOVA analysis was used to evaluate the effect of the parameters inherent to the PSO-ANN model. The PSO-ANN model proves to be a powerful tool for estimating the efficiency of Fe(III) ion removal.},
  archive      = {J_NCA},
  author       = {Massaoudi, Ayman and Echouchene, Fraj and Ben Ayed, Mossaad and Berguiga, Abdelwahed and Harchay, Ahlem and Al-Ghamdi, Sara and Belmabrouk, Hafedh},
  doi          = {10.1007/s00521-024-09826-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13357-13372},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning models for modeling the biosorption of Fe(III) ions by activated carbon from olive stone},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Air combat maneuver decision based on deep reinforcement
learning with auxiliary reward. <em>NCA</em>, <em>36</em>(21),
13341–13356. (<a
href="https://doi.org/10.1007/s00521-024-09720-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For air combat maneuvering decision, the sparse reward during the application of deep reinforcement learning limits the exploration efficiency of the agents. To address this challenge, we propose an auxiliary reward function considering the impact of angle, range, and altitude. Furthermore, we investigate the influences of the network nodes, layers, and the learning rate on decision system, and reasonable parameter ranges are provided, which can serve as a guideline. Finally, four typical air combat scenarios demonstrate good adaptability and effectiveness of the proposed scheme, and the auxiliary reward significantly improves the learning ability of deep Q network (DQN) by leading the agents to explore more intently. Compared with the original deep deterministic policy gradient and soft actor critic algorithm, the proposed method exhibits superior exploration capability with higher reward, indicating that the trained agent can adapt to different air combats with good performance.},
  archive      = {J_NCA},
  author       = {Zhang, Tingyu and Wang, Yongshuai and Sun, Mingwei and Chen, Zengqiang},
  doi          = {10.1007/s00521-024-09720-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13341-13356},
  shortjournal = {Neural Comput. Appl.},
  title        = {Air combat maneuver decision based on deep reinforcement learning with auxiliary reward},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Text-based person search by non-saliency enhancing and
dynamic label smoothing. <em>NCA</em>, <em>36</em>(21), 13327–13339. (<a
href="https://doi.org/10.1007/s00521-024-09691-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current text-based person re-identification (re-ID) models tend to learn salient features of image and text, which however is prone to failure in identifying persons with very similar dress, because their image contents with observable but indescribable difference may have identical textual description. To address this problem, we propose a re-ID model based on saliency masking to learn non-salient but highly discriminative features, which can work together with the salient features to provide more robust pedestrian identification. To further improve the performance of the model, a cross-modal projection matching loss with dynamic label smoothing (named CMPM-DS) is proposed to train our model, and our CMPM-DS can adaptively adjust the smoothing degree of the true distribution. We conduct extensive ablation and comparison experiments on two popular re-ID benchmarks to demonstrate the efficiency of our model and loss function, and our model achieves SOTA, improving the existing best R@1 by 0.33% on CUHK-PEDE and 4.45% on RSTPReID.},
  archive      = {J_NCA},
  author       = {Pang, Yonghua and Zhang, Canlong and Li, Zhixin and Wei, Chunrong and Wang, Zhiwen},
  doi          = {10.1007/s00521-024-09691-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13327-13339},
  shortjournal = {Neural Comput. Appl.},
  title        = {Text-based person search by non-saliency enhancing and dynamic label smoothing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale deep echo state network for time series
prediction. <em>NCA</em>, <em>36</em>(21), 13305–13325. (<a
href="https://doi.org/10.1007/s00521-024-09761-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo state network (ESN) has widely attracted many researchers due to its training process without backpropagation. However, it is hard for single ESN to fit those complex and polytrophic situations. Under this case, a novel multiscale deep ESN (MDESN) is developed in this study, which integrates the deep learning, parallel structure and multiscale reservoir state matrix mode, respectively. The deep framework is responsible for collecting multivariate dimensional reservoir states; Upgradation of various reservoir states could efficiently dig hidden characteristics for decoding. The parallel structure could be trained simultaneously to decrease time consumption through the multiple thread method. According to the multivariate high dimensional mapping method, MDESN could obtain more robust generalization information compared to the state-of-the-art models. MDESN is evaluated in two chaos prediction benchmarks (Lorenz and Mackey-Glass) and real solar irradiance predictions. Various prediction horizons including one-step-ahead and multi-step-ahead prediction are designed and conducted respectively to verify the effectiveness and robustness of MDESN. Furthermore, RMSE, MAE, MAPE, and R are adopted to evaluate our proposed model. The statistical results demonstrate that MDESN has the best-performing adaptability and robustness compared to classical ESN, deep ESN (DESN), and other state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Li, Tao and Guo, Zhijun and Li, Qian and Wu, Zhou},
  doi          = {10.1007/s00521-024-09761-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13305-13325},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-scale deep echo state network for time series prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed-time cluster synchronization of coupled inertial
neural networks: A lifting dimension approach. <em>NCA</em>,
<em>36</em>(21), 13293–13303. (<a
href="https://doi.org/10.1007/s00521-024-09717-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the prescribed-time cluster synchronization of coupled inertial neural networks. By variable transformation, the coupled inertial neural networks are converted into high-order systems. An effective prescribed-time control applicable to high-order systems is introduced by virtue of a time-varying scaling function. Moreover, a dimension-lifting approach is utilized to derive sufficient criteria for achieving prescribed-time cluster synchronization under the proposed control. Compared with existing Lyapunov–Krasovskii functional methods, the criteria obtained in this paper are in form of low-dimensional linear matrix inequalities and therefore can be easily verified. A numerical example is provided to demonstrate the effectiveness of proposed results.},
  archive      = {J_NCA},
  author       = {Liu, Peng and Yong, Jian and Sun, Junwei and Wang, Yanfeng and Zhao, Junhong},
  doi          = {10.1007/s00521-024-09717-8},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13293-13303},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prescribed-time cluster synchronization of coupled inertial neural networks: A lifting dimension approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shape completion with azimuthal rotations using spherical
gidding-based invariant and equivariant network. <em>NCA</em>,
<em>36</em>(21), 13269–13292. (<a
href="https://doi.org/10.1007/s00521-024-09712-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud completion aims to restore full shapes of objects from their partial views obtained by 3D optical scanners. In order to make point cloud completion become more robust to azimuthal rotations and more adaptive to real-world scenarios, we propose a novel network for simultaneous rotation invariant and equivariant completion with no need of data augmentation, while other existing approaches require separately trained models for different completion types. Our method includes several main steps: First, Density Compensation Mapping (DCM) as well as Aggregative Gaussian Gridding (AGG) modules are introduced to transfer partial point clouds to spherical signals and avoid unbalanced sampling. Second, an encoder based on group correlation is designed to extract rotation invariant global features and equivariant azimuthal features from spherical signals. Third, parallel groups of decoders are proposed to realize rotation invariant completion based on feature fusion. Finally, a feature remapping module as well as Pose Voting Alignment (PVA) algorithm are proposed to unify feature space and realize rotation equivariant completion. Based on these modules, we find that the application of group correlation can be extended to the domain of shape completion; equivariant and invariant completions can be unified in one pipeline, and our inherent rotation equivariant and invariant framework can achieve competitive performances when comparing with existing representative methods.},
  archive      = {J_NCA},
  author       = {Wu, Hang and Miao, Yubin and Fu, Ruochong},
  doi          = {10.1007/s00521-024-09712-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13269-13292},
  shortjournal = {Neural Comput. Appl.},
  title        = {Shape completion with azimuthal rotations using spherical gidding-based invariant and equivariant network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vibration analysis and control of aircraft landing systems
using proposed neural controllers. <em>NCA</em>, <em>36</em>(21),
13255–13268. (<a
href="https://doi.org/10.1007/s00521-024-09704-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, landing gears used in aircraft are the basic systems that carry the weight of aircraft systems and provide them to move on the ground. During the landing of aircraft, big and sudden vibrations occur as soon as the wheels come into contact with the runway. This situation negatively affects human safety, comfort and also the life of the landing gear system. Therefore, it is important to keep this vibration at permissible levels. This paper presents an improved vibration control method that controls the amplitudes of vibrations of landing systems. This paper presents proposed vibration control method that controls the angular position variables of the landing gear mechanism to control the vibrations occurring during landing. For different runway conditions and 200 km/h landing speed, the angular joint variables of the landing gear mechanism links are controlled using standard controller and a proposed neural controller structure. The simulation results are shown that the proposed neural controllers have better performance at vibration control of landing systems during landing.},
  archive      = {J_NCA},
  author       = {Yıldırım, Şahin and Durmuşoğlu, Aslı},
  doi          = {10.1007/s00521-024-09704-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13255-13268},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vibration analysis and control of aircraft landing systems using proposed neural controllers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DWT-BILSTM-based models for day-ahead hourly global
horizontal solar irradiance forecasting. <em>NCA</em>, <em>36</em>(21),
13243–13253. (<a
href="https://doi.org/10.1007/s00521-024-09701-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of electricity generation from renewable energy sources is crucial for the operation, planning and management of smart grids. For reliable planning and operation of photovoltaic (PV) systems in grid-connected or islanded utilities, an hourly day-ahead forecast of PV output is critical. The forecast of PV power can be done indirectly by estimating solar irradiance. For forecasting day-ahead hourly global horizontal irradiance (GHI), two forecasting models with different multivariate inputs are proposed in this paper, and the results are compared. These models use a hybrid algorithm of discrete wavelet decomposition and bidirectional long short-term memory (BILSTM). The inputs of the first model contain GHI and weather type data. The other model allows for observation of the effect of meteorological values including GHI, temperature, humidity, wind speed, and weather type data. The forecasting performance of deep learning algorithms which contain recurrent neural network (RNN), long short-term memory (LSTM), and BILSTM algorithms for day ahead hourly solar irradiance forecasting problems are also compared. To evaluate the performance of proposed models, two datasets are used for Model 1 and one dataset is used for Model 2. An experiment is also done to demonstrate that the proposed Model 1 is applicable in datasets collected in the vicinity of the city of Trabzon. On the other hand, BILSTM algorithm outperforms RNN and LSTM algorithms. It is seen that the test successes of both proposed models are better than the results given in the literature.},
  archive      = {J_NCA},
  author       = {Çevik Bektaş, Sibel and Altaş, Ismail H.},
  doi          = {10.1007/s00521-024-09701-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13243-13253},
  shortjournal = {Neural Comput. Appl.},
  title        = {DWT-BILSTM-based models for day-ahead hourly global horizontal solar irradiance forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposed intrinsic mode functions and deep learning
algorithms for water quality index forecasting. <em>NCA</em>,
<em>36</em>(21), 13223–13242. (<a
href="https://doi.org/10.1007/s00521-024-09698-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The water quality index (WQI) serves as a global representation of river water quality (WQ). Existing studies related to the WQI have mainly focused on two aspects: (i) a WQI point estimation using multiple WQ inputs; and (ii) a one-step-ahead WQI forecasting with datasets of lower temporal resolution. These approaches, however, are limited in their ability to forecast future trends of the WQI for timely and prompt responses to pollution events. In this study, the deep learning algorithms, namely the long short-term memory (LSTM) and the gated recurrent unit (GRU), were selected for direct multi-step-ahead WQI forecasting. To enhance the capability of the models in capturing their temporal patterns, the input signal was pre-decomposed using the empirical mode decomposition (EMD) and variational mode decomposition (VMD) into several intrinsic mode functions (IMFs). The characteristics of these IMFs were then analyzed and used to ease model learning on capturing their temporal patterns. Our study shows that the selection of signal decomposition strategies significantly impact the model performance. Both deep learning algorithms offered comparable performances, with the VMD-LSTM exhibiting the lowest prediction errors (MAPE = 1.9237%) and the highest Kling–Gupta efficiency (KGE = 0.6761) over a two-month test period. To the best of our knowledge, this is the first paper that applies a direct forecast approach for the multi-step-ahead WQI forecasting, using the IMFs obtained from the EMD and VMD decompositions. The performance of the model was evaluated through a rolling forward setup to ensure its consistency across different test periods. The proposed modeling framework holds the potential to assist policymakers and stakeholders in decision-making, particularly in planning remedies and efficient water resource management.},
  archive      = {J_NCA},
  author       = {Wai, Kok Poh and Koo, Chai Hoon and Huang, Yuk Feng and Chong, Woon Chan},
  doi          = {10.1007/s00521-024-09698-8},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13223-13242},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decomposed intrinsic mode functions and deep learning algorithms for water quality index forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation-wise transformer network and reinforcement learning
for visual navigation. <em>NCA</em>, <em>36</em>(21), 13205–13221. (<a
href="https://doi.org/10.1007/s00521-024-09693-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of object goal navigation is to drive an embodied agent to find the location of a given target only using visual observation. The mapping from visual perception of observation determines the navigation actions. Heterogeneous relationships in the observation are the essential part of the scene graph, which can guide the agent to find the target more easily. In this work, we propose a novel Heterogeneous Zone Graph Visual Transformer formulation for graph representation and visual perception. It consists of two key ideas: (1) Heterogeneous Zone Graph (HZG) that explores the heterogeneous target-related zones graph and spatial information. It allows the agent to navigate efficiently. (2) Relation-wise Transformer Network (RTNet) that transforms the relationship between previously observed objects and navigation actions. RTNet extracts rich nodes and edges features as pays more attention to the target-related zone. We model self-attention on the node-to-node encoder and cross-attention on the edge-to-node decoder. We evaluate our methods on the AI2THOR dataset and show superior navigation performance. Code and datasets can be found in https://github.com/zhoukang12321/RTNet_VN_2023 .},
  archive      = {J_NCA},
  author       = {He, Yu and Zhou, Kang},
  doi          = {10.1007/s00521-024-09693-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13205-13221},
  shortjournal = {Neural Comput. Appl.},
  title        = {Relation-wise transformer network and reinforcement learning for visual navigation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Luminance domain-guided low-light image enhancement.
<em>NCA</em>, <em>36</em>(21), 13187–13203. (<a
href="https://doi.org/10.1007/s00521-024-09687-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-light conditions often suffer from low contrast, high noise, and uneven brightness due to nightlight, backlight, and shadow. These challenges make it difficult to use them as high-quality inputs for visual tasks. Existing low-light enhancement methods tend to increase overall image brightness, which can cause overexposure of normal-light areas after enhancement. To solve this problem, this paper proposes an Uneven Dark Vision Network (UDVN) that consists of two sub-networks. The Luminance Domain Network (LDN) uses Direction-aware Spatial Context (DSC) and Feature Enhancement Module (FEM) to segment different light regions in the image and output the luminance domain mask. Guided by this mask, the Light Enhancement Network (LEN) uses the Cross-Domain Transformation Residual block (CDTR) to adaptively illuminate different regions with various lights. We also introduce a new region loss function to constrain the LEN to better enhance the quality of different light regions. In addition, we have constructed a new low-light synthesis dataset (UDL) that is larger, more diverse, and includes uneven lighting states in the real world. Extensive experiments on several benchmark datasets demonstrate that our proposed method is highly competitive with state-of-the-art (SOTA) methods. Specifically, it outperforms other methods in light recovery and detail preservation when processing uneven low-light images. The UDL dataset is publicly available at: https://github.com/YuhangLi-li/UDVN .},
  archive      = {J_NCA},
  author       = {Li, Yuhang and Wang, Chao and Liang, Bing and Cai, Feifan and Ding, Youdong},
  doi          = {10.1007/s00521-024-09687-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13187-13203},
  shortjournal = {Neural Comput. Appl.},
  title        = {Luminance domain-guided low-light image enhancement},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quasisynchronization of reaction-diffusion neural networks
with time-varying delays by static/dynamic event-triggered control and
its application to secure communication. <em>NCA</em>, <em>36</em>(21),
13171–13186. (<a
href="https://doi.org/10.1007/s00521-024-09778-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the quasisynchronization problems of reaction-diffusion neural networks (RDNNs) with time-varying delays via event-triggered control. Firstly, a static event-triggered mechanism and a dynamic event-triggered mechanism are designed to significantly reduce computation costs and save communication resources, respectively. These two different event-triggered control strategies are also able to meet the requirements of various situations. Based on the static event-triggered mechanism, the dynamic event-triggered mechanism is designed to further reduce the sampling frequency by introducing an internal dynamic variable, and several quasisynchronization criteria are derived. However, the quasisynchronization error bounds are related to triggering parameters and can be flexible adjusted, which reduces the conservatism of the existing quasisynchronization results and extends the application of proposed control strategies. Meanwhile, there exists positive lower bounds for the inter event time which can exclude the Zeno behavior. Finally, numerical simulations are given to demonstrate the superiority of the obtained theoretical results, and one example is given to show the chaotic quasisynchronization of the proposed RDNNs in the application of secure communication.},
  archive      = {J_NCA},
  author       = {Cao, Yanyi and Liu, Nian and Zhang, Tao and Zhang, Chuanfu},
  doi          = {10.1007/s00521-024-09778-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13171-13186},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quasisynchronization of reaction-diffusion neural networks with time-varying delays by static/dynamic event-triggered control and its application to secure communication},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning hierarchy-aware complex knowledge graph embeddings
for link prediction. <em>NCA</em>, <em>36</em>(21), 13155–13169. (<a
href="https://doi.org/10.1007/s00521-024-09775-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding is a widely used technique that represents entities and relations in a low-dimensional space to predict missing links in knowledge graphs. However, most existing knowledge graph embedding methods focus solely on modeling multiple relation patterns, such as symmetry/antisymmetric, inversion, and composition, while ignoring semantic hierarchies consisting in real-world scenes. This limitation leads to inaccurate embeddings of entities and relations, which, in turn, negatively affects downstream tasks. To address this issue, we present a novel model, named Dual Hierarchical scaling Knowledge graph Embedding (DHKE), which maps entities and relations into complex space to model semantic hierarchies and relation patterns simultaneously. DHKE treats the embeddings of entities as their semantic hierarchies, and allocates two scaling vectors to each relation to enable transformations between hierarchies. Furthermore, DHKE assigns a rotation vector to each relation to distinguish between entities at the same semantic hierarchy and to model multiple relation patterns. Our experimental results and analysis indicate that DHKE outperforms existing methods and that DHKE is capable of modeling both semantic hierarchies and multiple relation patterns simultaneously. Notably, DHKE can capture semantic hierarchies of entities without extra information about entities, which are more suitable for real-world data.},
  archive      = {J_NCA},
  author       = {Zhang, Jinglin and Shen, Bo and Zhang, Yu},
  doi          = {10.1007/s00521-024-09775-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13155-13169},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learning hierarchy-aware complex knowledge graph embeddings for link prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intercity customized passenger transportation service plan
optimization design with spatial-temporal accessibility based on
BIRCH-VNS. <em>NCA</em>, <em>36</em>(21), 13127–13154. (<a
href="https://doi.org/10.1007/s00521-024-09759-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional intercity passenger transportation is inefficient, inflexible, and financially unrewarding, failing to meet the demands of intercity travel. To address these issues, this study utilizes historical carpooling order data, extracts travel patterns, and devises a comprehensive plan for intercity customized passenger transport services. Firstly, a formalized description of issues related to long-distance cross-city travel, multiple lines, and scheduling around highway entry and exit points is addressed. Secondly, a single-objective integer linear programming model is constructed, aimed at maximizing the total profit for the operating company. Finally, from a spatial-temporal network perspective, a refined balanced iterative reducing and clustering using hierarchies (BIRCH) algorithm is designed for alternative station selection. To achieve a rapid and effective solution to the model, the approach is combined with a variable neighborhood search algorithm. Experimental results on historical carpooling data from Anxi County and Xiamen City demonstrate that the proposed algorithm, compared to the combination of BIRCH and genetic algorithms, exhibits shorter computation time, higher quality, and stability. Additionally, various parameter analysis and sensitivity experiments demonstrate the effectiveness of parameters used.},
  archive      = {J_NCA},
  author       = {Hu, Die and Wang, Cheng and Chen, Jianwei},
  doi          = {10.1007/s00521-024-09759-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13127-13154},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intercity customized passenger transportation service plan optimization design with spatial-temporal accessibility based on BIRCH-VNS},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain-invariant feature learning with label information
integration for cross-domain classification. <em>NCA</em>,
<em>36</em>(21), 13107–13126. (<a
href="https://doi.org/10.1007/s00521-024-09755-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for unsupervised cross-domain classification learn a common low-dimensional subspace using images from a well-labeled source domain and an unlabeled target domain. To achieve domain-invariant feature extraction, researchers typically focus on minimizing the distribution discrepancy. However, these methods often overlook the fact that label information contains critical categorization information for discriminative subspace learning. This paper proposes a novel method, named domain-invariant feature learning with label information integration (DILI), which integrates metric learning and label information extraction to learn a cross-domain discriminant subspace. DILI first reduces the distances between the source and target domains to mitigate the marginal distribution discrepancy. Then, it reduces the distances between cross-domain samples from the same class to mitigate the conditional distribution discrepancy. Dual terms are imposed to balance the label information of both domains to learn common features, and a discriminant subspace is learned for cross-domain tasks. This method obtains domain-invariant features, while the label information of the source domain and pseudo labels from the target domain are used to improve the discriminant of subspaces. Experimental results on eight cross-domain datasets show that DILI outperforms some state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Jiang, Lin and Wu, Jigang and Zhao, Shuping and Li, Jiaxing},
  doi          = {10.1007/s00521-024-09755-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13107-13126},
  shortjournal = {Neural Comput. Appl.},
  title        = {Domain-invariant feature learning with label information integration for cross-domain classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of machine learning models to predict daily
streamflow in a semiarid river catchment. <em>NCA</em>, <em>36</em>(21),
13087–13106. (<a
href="https://doi.org/10.1007/s00521-024-09748-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we employ explainable machine learning (ML) models to predict daily streamflow ( $$Q_{\rm{flow}}$$ ) by leveraging hydro-meteorological parameters. The predictive matrix incorporates crucial factors such as daily rainfall, temperature, relative humidity, solar radiation, wind speed, and the one-day lag value of $$Q_{\rm{flow}}$$ . Notably, among these parameters, the one-day lag value of $$Q_{\rm{flow}}$$ , along with rainfall, solar radiation, temperature, and relative humidity emerge as highly influential predictors. We apply various ML models, including bagging ensemble learning, boosting ensemble learning, Gaussian process regression (GPR), and automated machine learning (Auto ML). Following a rigorous evaluation, the bagging ensemble learning model stands out as the most effective with a correlation coefficient (R = 0.80) and root-mean-square error (RMSE = 218). Further, we compare the $$Q_{\rm{flow}}$$ predicted using ML models with a process-based hydrological model (SWAT) that was executed using a similar set of climatic variables as the input parameters. In our case, the predictive strength of the ML model (R = 0.80; RMSE = 218) to estimate ( $$Q_{\rm{flow}}$$ ) is greater than the SWAT (R = 0.82; RMSE = 281). In conclusion, by emphasizing the importance of explainable ML models and highlighting the significance of specific hydro-meteorological parameters, our study contributes to advancing the field of hydrology and water resource management.},
  archive      = {J_NCA},
  author       = {Kumar, Amit and Gaurav, Kumar and Singh, Abhilash and Yaseen, Zaher Mundher},
  doi          = {10.1007/s00521-024-09748-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13087-13106},
  shortjournal = {Neural Comput. Appl.},
  title        = {Assessment of machine learning models to predict daily streamflow in a semiarid river catchment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Natural language requirements testability measurement based
on requirement smells. <em>NCA</em>, <em>36</em>(21), 13051–13085. (<a
href="https://doi.org/10.1007/s00521-024-09730-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Requirements form the basis for defining software systems’ obligations and tasks. Testable requirements help prevent failures, reduce maintenance costs, and make it easier to perform acceptance tests. However, despite the importance of measuring and quantifying requirements testability, no automatic approach for measuring requirements testability has been proposed based on the requirements smells, which are at odds with the requirements testability. This paper presents a mathematical model to evaluate and rank the natural language requirements testability based on an extensive set of nine requirements smells, detected automatically, and acceptance test efforts determined by requirement length and its application domain. Most of the smells stem from uncountable adjectives, context-sensitive, and ambiguous words. A comprehensive dictionary is required to detect such words. We offer a neural word embedding technique to generate such a dictionary automatically. Using the dictionary, we could automatically detect Polysemy smell (domain-specific ambiguity) for the first time in 10 application domains. Our empirical study on nearly 1000 software requirements from six well-known industrial and academic projects demonstrates that the proposed smell detection approach outperforms Smella, a state-of-the-art tool, in detecting requirements smells. The Precision and Recall of smell detection are improved with an average of 0.03 and 0.33, respectively, compared to the state-of-the-art. The proposed requirement testability model measures the testability of 985 requirements with a mean absolute error of 0.12 and a mean squared error of 0.03, demonstrating the model’s potential for practical use.},
  archive      = {J_NCA},
  author       = {Zakeri-Nasrabadi, Morteza and Parsa, Saeed},
  doi          = {10.1007/s00521-024-09730-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13051-13085},
  shortjournal = {Neural Comput. Appl.},
  title        = {Natural language requirements testability measurement based on requirement smells},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A metaheuristic-based algorithm for optimizing node
deployment in wireless sensor network. <em>NCA</em>, <em>36</em>(21),
13027–13049. (<a
href="https://doi.org/10.1007/s00521-024-09722-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication quality is compromised when wireless sensor network (WSN) operate in harsh environments, which can be improved by supplementing the nodes. This paper proposes a deployment strategy to optimize the placement of new nodes in WSN, specifically in complex environments with limited communication. To achieve this, the paper introduces the concept of strong connectivity relationships and presents a novel metaheuristic algorithm, namely double-state differential evolution (DSDE), which divides the optimization process into two states and adopts different optimization strategies. The proposed DSDE can improve the overall network communication glowing at a lower computing cost. Extensive experiments show that the proposed DSDE has better performance than state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Xie, Meng and Pi, Dechang and Dai, Chenglong and Xu, Yue},
  doi          = {10.1007/s00521-024-09722-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13027-13049},
  shortjournal = {Neural Comput. Appl.},
  title        = {A metaheuristic-based algorithm for optimizing node deployment in wireless sensor network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Selection of waste receiving companies for sustainable
industrial symbiosis network: An application a case in ankara for
foundry industry waste. <em>NCA</em>, <em>36</em>(21), 13009–13026. (<a
href="https://doi.org/10.1007/s00521-024-09683-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past twenty years, besides the technological and innovative efforts for production processes, there have been activities for the recovery and quality improvement of waste based on the development of sustainable solutions. These activities bring us closer to zero waste by protecting natural resources and reducing the environmental impact of production facilities. One of the essential approaches in this process is the industrial symbiosis (IS) approach. Efforts to implement the industrial symbiosis approach in an industrial park constitute the motivation of the study. The study aims to identify alternative enterprises that can evaluate the wastes generated in the main production process of the foundry industry with industrial symbiosis and rank them to establish a symbiotic relationship. First, the Pythagorean Fuzzy Analytical Hierarchy Process (PF-AHP) model has been developed to evaluate organizational factors, waste-specific factors, and economic and environmental sustainability criteria for establishing an IS network among alternative businesses. Then, alternative businesses were ranked to establish a symbiosis network with the PF-TOPSIS method. The proposed method contributes to the solution of a real-life problem that may arise when there are multiple alternatives to cooperate in the field of industrial symbiosis. By contributing this framework to the literature, the robustness of the results has been demonstrated through sensitivity analysis and comparative analysis. According to the results obtained, it was seen that the importance levels of economic factors came to the fore. Furthermore, among the alternatives, enterprises with high waste exchange potential, such as cement, took first place in the ranking.},
  archive      = {J_NCA},
  author       = {Yazıcı, Emre and Alakaş, Hacı Mehmet and Eren, Tamer},
  doi          = {10.1007/s00521-024-09683-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {13009-13026},
  shortjournal = {Neural Comput. Appl.},
  title        = {Selection of waste receiving companies for sustainable industrial symbiosis network: An application a case in ankara for foundry industry waste},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward accurate and realistic garment texture transfer with
attention to details. <em>NCA</em>, <em>36</em>(21), 12991–13007. (<a
href="https://doi.org/10.1007/s00521-024-09653-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The categories and styles of garment are constantly diversifying. For designers, it is a pressing issue to evaluate how different fabrics will look on them in a timely manner for users. In this paper, we present a novel garment texture transfer framework from a single person image. Based on the garment model constructed in the person image, we render the texture to the model surface using parallax mapping. To determine the relative positions of the garments when exporting the images, we calculate the contour center moments of the garment mask and the center of mass coordinates of the 3D model and use their consistency to perform position calibration. Finally, we align the rendered garment image with the figure image to obtain the final transfer effect. Experiments demonstrated that our method is robust to different character pose with different garments and background. Qualitative experimental results show that our method accurately and realistically relocates the texture of the garment in the image of the person while preserving the original folds of the garment. Quantitative comparisons with other methods show that our method is optimal in several metrics.},
  archive      = {J_NCA},
  author       = {He, Wentao and Song, Bingpeng and Zhang, Ning and xiang, Jun and Pan, Ruru},
  doi          = {10.1007/s00521-024-09653-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12991-13007},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward accurate and realistic garment texture transfer with attention to details},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lgvc: Language-guided visual context modeling for 3D visual
grounding. <em>NCA</em>, <em>36</em>(21), 12977–12990. (<a
href="https://doi.org/10.1007/s00521-024-09764-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D visual grounding is crucial for understanding cross-modal scenes, linking visual objects to their corresponding language descriptions. Traditional methods often use fixed attention patterns in visual encoders, limiting the utility of language-guided attention mechanisms. To address this, we introduce a novel language-guided visual context modeling (LGVC) strategy. Our approach enriches the visual encoding at multiple levels through language knowledge: (1) A Language-Object Embedding (LOE) Module directs attention toward language-relevant proposals in 3D visual scenes, and (2) a Language-Relation Embedding (LRE) Module explores the relationships among objects in the context of accompanying text. Extensive experiments show that LGVC efficiently filters out language-irrelevant proposals and aligns multimodal entities, outperforming state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Geng, Liang and Yin, Jianqin and Niu, Yingchun},
  doi          = {10.1007/s00521-024-09764-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12977-12990},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lgvc: Language-guided visual context modeling for 3D visual grounding},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sign language translation with hierarchical memorized
context in question answering scenarios. <em>NCA</em>, <em>36</em>(21),
12951–12976. (<a
href="https://doi.org/10.1007/s00521-024-09763-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based sign language translation (SLT) targets to translate sign language videos into understandable natural language sentences. Current SLT methods ignore the utilization of contextual information in specific dialogue scenarios, which may lead to incorrect translations that do not match the dialogue content. Accordingly, this work proposes a novel framework for SLT in the question answering scenarios, called SLQA, which attempts to learn contextual knowledge from multimodal QA pairs between the hearing and the deaf to improve the model reasoning capabilities of SLT. The SLQA framework is composed of two main components: One is to integrate local context under the guidance of semantic relevance within the QA pair, and the other is to excavate the hierarchical memorized context from a three-layer memory hierarchy, i.e., scenario, dialogue and cue memory, by exploiting the logical dependency between QA pairs. To facilitate SLQA research, we further contribute the SLQA dataset with abundant natural language and sign language QA pairs. Extensive experimental results and analysis of our method are reported on SLQA and four public benchmark datasets. With the proposed SLQA framework, we obtain a substantial improvement over previous state-of-the-art SLT methods, showing about 13.2 improvements for BLEU-4 on the SLQA test set, which demonstrates the effectiveness of our method.},
  archive      = {J_NCA},
  author       = {Gao, Liqing and Feng, Wei and Shi, Peng and Han, Ruize and Lin, Di and Wan, Liang},
  doi          = {10.1007/s00521-024-09763-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12951-12976},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sign language translation with hierarchical memorized context in question answering scenarios},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognition2Vocation: Meta-learning via ConvNets and
continuous transformers. <em>NCA</em>, <em>36</em>(21), 12935–12950. (<a
href="https://doi.org/10.1007/s00521-024-09749-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the suitability of individuals for a vocation via leveraging the knowledge within cognitive factors comes with numerous applications: employment resourcing, occupation counseling, and workload management. Accordingly, the enterprises aim to hire the most suitable person from a massive array of similar applicants, maximizing performance and minimizing the gap between strategic indicators and predefined targets. While cognitive factors signify the best-suited person from similarly skilled workers, inferring pertinent latent cues from noisy and growing social network contents is time-intensive. To tackle the challenges involved, we propose a framework that, on the one hand, extends influential features based on the correlations between cognitive cues and, on the other hand, leverages a novel continuous transformer to mitigate the overlapping and approximation issues in discrete modeling. Rather than relying on discrete patterns that may evolve frequently, we use continuous elements that include not only numerous aggregating components but also sense minor irregular fluctuations. In a hybrid manner, we fuse multiple base models to transfer a higher representation to the meta-learning unit, agglomerating outputs from gradient boosters and the ConvNets. The experimental results show that our proposed framework can outperform trending vocation estimation methods by 1.36% in F1-Score and approximately 1% in accuracy.},
  archive      = {J_NCA},
  author       = {Kamran, Sara and Hosseini, Saeid and Esmailzadeh, Sayna and Kangavari, Mohammad Reza and Hua, Wen},
  doi          = {10.1007/s00521-024-09749-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12935-12950},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cognition2Vocation: Meta-learning via ConvNets and continuous transformers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EMARec: A sequential recommendation with exponential moving
average. <em>NCA</em>, <em>36</em>(21), 12917–12933. (<a
href="https://doi.org/10.1007/s00521-024-09718-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing dynamic preference features from user historical behavioral data is widely applied to improve the accuracy of recommendations in sequential recommendation tasks. However, existing deep neural network-based sequential recommendation methods often ignore the noise information in user behavioral data that influence recommendation effectiveness, making recommendation models sensitive to noisy data. Additionally, these deep learning-based recommendation models often require a large number of parameters to capture user behavior patterns, leading to higher time complexity and susceptibility to overfitting due to noise fluctuations. To address these issues, in this paper, we apply the moving average concept from the field of time-series analysis to sequential recommendation tasks. The approach smooths sequence data, removes noise, making the data more stable and reliable, increases the model’s insensitivity to noise information, and better understands the evolution of user interests and behavioral patterns. Specifically, in our experiments, the moving average algorithm effectively denoises sequential data with low time complexity. Therefore, we propose a Sequential Recommendation with Exponential Moving Average with MLP architecture that makes the model more competitive in terms of time complexity. Experimental results conducted on two datasets demonstrate that EMARec outperforms state-of-the-art sequential recommendation methods across various common evaluation metrics.},
  archive      = {J_NCA},
  author       = {Chen, Rui and Wang, Zonglin and Tang, Cundong and Zhang, Jianwei and Li, Pu and Kong, Xiangjie and Huang, Min},
  doi          = {10.1007/s00521-024-09718-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12917-12933},
  shortjournal = {Neural Comput. Appl.},
  title        = {EMARec: A sequential recommendation with exponential moving average},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Blockfd: Blockchain-based federated distillation against
poisoning attacks. <em>NCA</em>, <em>36</em>(21), 12901–12916. (<a
href="https://doi.org/10.1007/s00521-024-09715-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a novel framework that distributes the model training to the participant devices to realize privacy-preserving machine learning. To achieve this, clients upload the parameters of the local model to the central server for aggregation rather than the raw data. Despite the potential of FL, one of the significant challenges in FL applications is the communication constraints caused by the transmission of the high-dimensional parameter. To overcome this, federated distillation (FD) has been widely studied to address the significant communication overhead through transmitting the low-dimensional logits, which is used to assist the training of the local model rather than transmitting the model parameters. However, the traditional FD framework applies the centralized architecture, which is vulnerable to single-point-of-failure. Moreover, the emerging poisoning attacks also significantly impact the security of FD. Specifically, attackers can easily launch poisoning attack by uploading crafted logits, leading to inaccurate global logits aggregation and hazard the accuracy of local models. To address these issues, we propose a federated distillation framework based on blockchain, named BlockFD, by exploiting two mechanisms in blockchain architecture to realize decentralized and security FD. First, we propose a novel multi-dimension consensus algorithm (BlockFD-PoM) that leverages multiple attributions to perform consensus process, solving the existing computation-intensive and unfair problems of traditional consensus algorithms, such as the PoW and the PoS. Second, we introduce an aggregation-based validation algorithm (BFV) such that the legitimacy of local logits can be verified to guarantee the security of FD aggregation. Extensive evaluation results show that the proposed BlockFD framework can effectively and fairly realize decentralized federated distillation. Besides that, the proposed BFV algorithm can efficiently prevent federated distillation from poisoning attacks while maintaining the loss within 2.77%.},
  archive      = {J_NCA},
  author       = {Li, Ye and Zhang, Jiale and Zhu, Junwu and Li, Wenjuan},
  doi          = {10.1007/s00521-024-09715-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12901-12916},
  shortjournal = {Neural Comput. Appl.},
  title        = {Blockfd: Blockchain-based federated distillation against poisoning attacks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VGGish transfer learning model for the efficient detection
of payload weight of drones using mel-spectrogram analysis.
<em>NCA</em>, <em>36</em>(21), 12883–12899. (<a
href="https://doi.org/10.1007/s00521-024-09661-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an accurate model for predicting different payload weights from 3DR SOLO drone acoustic emission. The dataset consists of eleven different payload weights, ranging from 0 to 500 g with a 50 g increment. Initially, the dataset&#39;s drone sounds are broken up into 34 frames, each frame was about 5 s. Then, Mel-spectrogram and VGGish model are employed for feature extraction from these sound signals. CNN network is utilized for classification, and during the training phase, the network&#39;s weights are iteratively updated using the Adam optimization algorithm. Finally, two experiments are performed to evaluate the model. The first experiment is performed utilizing the original data (before augmentation), while the second used the augmented data. Different payload weights are identified with a potential accuracy of 99.98%, sensitivity of 99.98%, and specificity of 100% based on experimental results. Moreover, a comprehensive comparison with prior works that utilized the same dataset validates the superiority of the proposed model.},
  archive      = {J_NCA},
  author       = {El-Latif, Eman I. Abd and El-Sayad, Noha Emad and Mohammed, Kamel K. and Darwish, Ashraf and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-024-09661-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12883-12899},
  shortjournal = {Neural Comput. Appl.},
  title        = {VGGish transfer learning model for the efficient detection of payload weight of drones using mel-spectrogram analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous domain adaptation by class centroid matching
and local discriminative structure preservation. <em>NCA</em>,
<em>36</em>(21), 12865–12881. (<a
href="https://doi.org/10.1007/s00521-024-09786-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous domain adaptation (HDA) aims at facilitating the target model training by leveraging knowledge from the heterogeneous source domain. HDA is a challenging problem since the domains are not consistent in not only data distribution but also feature space. Most HDA methods attend to search for a subspace, where the features and the distributions across domains can be aligned. However, these methods barely consider the shared semantic label space of two domains and do not align the decision boundaries of the two domains, which may cause misclassification. To address the above issue, we propose a novel HDA method called Class centroid Matching and local Discriminative structure Preservation (CMDP), which can transfer discriminative semantic source knowledge to the target domain. Specifically, we project cross-domain samples to regress the label matrix to align the discriminative directions of two domains. Then, we introduce the inner product strategy to align the distance and angle of the class centroids across domains, such that the discriminative source knowledge can more sufficiently transfer to the target domain. Besides, to further improve the quality of the class centroids in each domain, we propose a novel cross-domain graph embedding strategy to exploit the structure information of data more thoroughly. A simple and efficient optimization algorithm is designed to solve the CMDP model. Extensive experiments on heterogeneous datasets validate the superiority of our proposal over several advanced methods.},
  archive      = {J_NCA},
  author       = {Chen, Yuqing and Zhou, Heng and Wang, Zhi and Zhong, Ping},
  doi          = {10.1007/s00521-024-09786-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12865-12881},
  shortjournal = {Neural Comput. Appl.},
  title        = {Heterogeneous domain adaptation by class centroid matching and local discriminative structure preservation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A vision-based nondestructive detection network for rail
surface defects. <em>NCA</em>, <em>36</em>(21), 12845–12864. (<a
href="https://doi.org/10.1007/s00521-024-09781-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inspection and diagnosis of building engineering involve rail surface defect detection, which plays a crucial role in assessing the quality of railway tracks. However, achieving accurate detection remains a significant challenge for infrastructure construction due to the challenging factors, such as complex background, poor texture, the irregular shapes and sizes of rail surface defects, etc. To address these challenges, combined with vision sensor, this paper proposes an automatic vision-based rail surface defect detection network, which leverages a combination of convolutional neural network (CNN) and transformer. Specifically, an effective encoding path based on an improved Res2N-et is presented to obtain stronger contextual information. Meanwhile, to address the limitation of feature representation on global context information, the transformer block is introduced into the bottleneck layer to capture essential global context information. Moreover, an attention-based edge enhancement block is proposed to mitigate the loss of local edge details and strengthen the focus on key feature information, to acquire more discriminant features. To further enrich the feature representation capability, this paper introduces an efficient feature aggregation block, which combines the global features extracted by the transformer and the local features extracted by CNN, to achieve effective feature complementarity and enhances overall detection performance. Combined with public NRSD-MN dataset, proposed model obtains $$87.3\%$$ and $$77.9\%$$ on PA metric, $$85.9\%$$ and $$83.4\%$$ in mIoU metric among artificial dataset with natural dataset. Meanwhile, it also obtains $$84.0\%$$ PA metric and $$87.0\%$$ mIoU metric in SEPR dataset. Experiments have proven the superiority of proposed model though the performance comparison with latest models, which presents an effective and promising rail surface defect detection solution for railway track quality assessment, and can be instrumental in ensuring safe and efficient railway operations.},
  archive      = {J_NCA},
  author       = {Bai, Suli and Yang, Lei and Liu, Yanhong},
  doi          = {10.1007/s00521-024-09781-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12845-12864},
  shortjournal = {Neural Comput. Appl.},
  title        = {A vision-based nondestructive detection network for rail surface defects},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuro-symbolic artificial intelligence: A survey.
<em>NCA</em>, <em>36</em>(21), 12809–12844. (<a
href="https://doi.org/10.1007/s00521-024-09960-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of the growing discipline of neuro-symbolic artificial intelligence (AI) is to develop AI systems with more human-like reasoning capabilities by combining symbolic reasoning with connectionist learning. We survey the literature on neuro-symbolic AI during the last two decades, including books, monographs, review papers, contribution pieces, opinion articles, foundational workshops/talks, and related PhD theses. Four main features of neuro-symbolic AI are discussed, including representation, learning, reasoning, and decision-making. Finally, we discuss the many applications of neuro-symbolic AI, including question answering, robotics, computer vision, healthcare, and more. Scalability, explainability, and ethical considerations are also covered, as well as other difficulties and limits of neuro-symbolic AI. This study summarizes the current state of the art in neuro-symbolic artificial intelligence.},
  archive      = {J_NCA},
  author       = {Bhuyan, Bikram Pratim and Ramdane-Cherif, Amar and Tomar, Ravi and Singh, T. P.},
  doi          = {10.1007/s00521-024-09960-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12809-12844},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neuro-symbolic artificial intelligence: A survey},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A real noise resistance for anti-tampering quick response
code. <em>NCA</em>, <em>36</em>(21), 12791–12807. (<a
href="https://doi.org/10.1007/s00521-024-10036-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traceability via quick response (QR) codes is regarded as a clever way to learn specifics about a product’s history, from its creation to its transit and preservation before reaching consumers. The QR code can, however, be easily copied and faked. Therefore, we suggest a novel strategy to prevent tampering with this code. The method is divided into two primary phases: concealing a security element in the QR code and determining how similar the QR code on the goods is to the real ones. For the first problem, error-correcting coding is used to encode and decode the secret feature in order to manage faults in noisy communication channels. A deep neural network is used to both conceal and extract the information encoded in a QR code, and the suggested network creates watermarked QR code images with good quality and noise tolerance. The network has the ability to be resilient to actual distortions brought on by the printing and photographing processes. In order to measure the similarity of QR codes, we create neural networks based on the Siamese network design. To assess whether a QR code is real or fraudulent, the hidden characteristic extracted from the acquired QR code and the outcome of QR code similarity estimation are merged. With an average accuracy of 98%, the proposed technique performs competitively and has been used in practice for QR code authentication.},
  archive      = {J_NCA},
  author       = {Loc, Cu Vinh and Viet, Truong Xuan and Viet, Tran Hoang and Thao, Le Hoang and Viet, Nguyen Hoang},
  doi          = {10.1007/s00521-024-10036-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12791-12807},
  shortjournal = {Neural Comput. Appl.},
  title        = {A real noise resistance for anti-tampering quick response code},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ZoomViT: An observation behavior-based fine-grained
recognition scheme. <em>NCA</em>, <em>36</em>(21), 12775–12789. (<a
href="https://doi.org/10.1007/s00521-024-09961-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image recognition aims to distinguish many images with subtle differences and identify the sub-categories to which they belong. Recently, vision transformer (ViT) has achieved promising results in many computer vision tasks. In this paper, we introduce human observation behavior into ViT and propose a novel transformer-based network, named ZoomViT. We divide the fine-grained recognition into two steps &quot;look closer&quot; and &quot;contrast.&quot; Firstly, looking closer is to observe finer local regions and multi-scale features, and avoid the adverse effect of background on recognition. We design the zoom-in module to track the attention flow by integrating the attention weights to zoom in the discriminative foreground regions. Subsequently, the straight image splitting like ViT may harm recognition adversely. Therefore, we design the zoom-out module combining overlapping cutting and downsampling to maintain the integrity of local neighboring structures and the running efficiency of the model in recognition. Finally, we propose to contrast the features of known sub-categories to supervise the model to learn subtle differences among different sub-categories. The consistency of features extracted from different batches increases over time; for this reason, we proposed a variable-length queue to store features from different batches to efficiently and fully conduct contrastive learning. We experimentally demonstrate the state-of-the-art performance of our model on four popular fine-grained benchmarks: CUB-200-2011, Stanford Dogs, NABirds, and iNat2017.},
  archive      = {J_NCA},
  author       = {Ma, Zhipeng and Yang, Yongquan and Wang, Haicheng and Huang, Lei and Wei, Zhiqiang},
  doi          = {10.1007/s00521-024-09961-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12775-12789},
  shortjournal = {Neural Comput. Appl.},
  title        = {ZoomViT: An observation behavior-based fine-grained recognition scheme},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on wind power forecasting with machine learning
approaches. <em>NCA</em>, <em>36</em>(21), 12753–12773. (<a
href="https://doi.org/10.1007/s00521-024-09923-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power forecasting techniques have been well developed over the last half-century. There has been a large number of research literature as well as review analyses. Over the past 5 decades, considerable advancements have been achieved in wind power forecasting. A large body of research literature has been produced, including review articles that have addressed various aspects of the subject. However, these reviews have predominantly utilized horizontal comparisons and have not conducted a comprehensive analysis of the research that has been undertaken. This survey aims to provide a systematic and analytical review of the technical progress made in wind power forecasting. To accomplish this goal, we conducted a knowledge map analysis of the wind power forecasting literature published in the Web of Science database over the last 2 decades. We examined the collaboration network and development context, analyzed publication volume, citation frequency, journal of publication, author, and institutional influence, and studied co-occurring and bursting keywords to reveal changing research hotspots. These hotspots aim to indicate the progress and challenges of current forecasting technologies, which is of great significance for promoting the development of forecasting technology. Based on our findings, we analyzed commonly used traditional machine learning and advanced deep learning methods in this field, such as  classical neural networks, and recent Transformers, and discussed emerging technologies like large language models. We also provide quantitative analysis of the advantages, disadvantages, forecasting accuracy, and computational costs of these methods. Finally, some open research questions and trends related to this topic were discussed, which can help improve the understanding of various power forecasting methods. This survey paper provides valuable insights for wind power engineers.},
  archive      = {J_NCA},
  author       = {Yang, Yang and Lou, Hao and Wu, Jinran and Zhang, Shaotong and Gao, Shangce},
  doi          = {10.1007/s00521-024-09923-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12753-12773},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey on wind power forecasting with machine learning approaches},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based magnetic resonance image
super-resolution: A survey. <em>NCA</em>, <em>36</em>(21), 12725–12752.
(<a href="https://doi.org/10.1007/s00521-024-09890-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is a medical imaging technique used to show anatomical structures and physiological processes of the human body. Due to limitations like image acquisition time, hardware capabilities, or uncooperative patients, the resolution of MR images is insufficient. Super-resolution (SR) is a crucial method to enhance the resolution of images without expensive scanning equipment. Recent years have witnessed significant progress in MR image super-resolution. Therefore, this survey presents a thorough overview of current developments in deep learning-based MR image super-resolution methods. In general, we can roughly divide the MRI super-resolution methods into single-contrast MR image SR methods and multi-contrast MR image SR methods. Additionally, we introduce the multi-task learning approaches about the MR image super-resolution. We also summarize other crucial topics, such as the degradation model, the definition of the super-resolution problem, the dataset, loss functions, and image quality assessment. Lastly, we indicate the challenges in the field of super-resolution and draw a conclusion to our survey.},
  archive      = {J_NCA},
  author       = {Ji, Zexin and Zou, Beiji and Kui, Xiaoyan and Liu, Jun and Zhao, Wei and Zhu, Chengzhang and Dai, Peishan and Dai, Yulan},
  doi          = {10.1007/s00521-024-09890-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12725-12752},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based magnetic resonance image super-resolution: A survey},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel deep learning approach (bi-xBcNet-96) considering
green AI to discover breast cancer using mammography images.
<em>NCA</em>, <em>36</em>(21), 12701–12723. (<a
href="https://doi.org/10.1007/s00521-024-09815-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical decision support systems (CDSSs) can effectively detect illnesses such as breast cancer (BC) using a variety of medical imaging techniques. BC is a key factor contributing to the rise in the death rate among women worldwide. Early detection will lessen its impact, which may motivate patients to have quick surgical therapy. Computer-aided diagnosis (CAD) systems are designed to provide radiologists recommendations to assist them in diagnosing BC. However, it is still restricted and limited, the interpretability cost, time consumption, and complexity of architecture are not considered. These limitations limit their use in healthcare devices. Therefore, we thought of presenting a revolutionary deep learning (DL) architecture based on recurrent and convolutional neural networks called Bi-xBcNet-96. In order to decrease carbon emissions while developing the DL model for medical image analysis and meet the objectives of sustainable artificial intelligence, this study seeks to attain high accuracy at the lowest computing cost. It takes into consideration the various characteristics of the pathological variation of BC disease in mammography images to obtain high detection accuracy. It consists of six stages: identifying the region of interest, detecting spatial features, discovering the effective features of the BC pathological types that have infected nearby cells in a concentrated area, identifying the relationships between distantly infected cells in some BC pathological types, weighing the extracted features, and classifying the mammography image. According to experimental findings, Bi-xBcNet-96 beat other comparable works on the benchmark datasets, attaining a classification accuracy of 98.88% in DDSM dataset, 100% in INbreast dataset with 5.08% and 0.3% improvements over the state-of-the-art methods, respectively. Furthermore, a 95.79% reduction in computing complexity was achieved.},
  archive      = {J_NCA},
  author       = {El-Mawla, Nesma Abd and Berbar, Mohamed A. and El-Fishawy, Nawal A. and El-Rashidy, Mohamed A.},
  doi          = {10.1007/s00521-024-09815-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12701-12723},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel deep learning approach (Bi-xBcNet-96) considering green AI to discover breast cancer using mammography images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review and meta-analysis of artificial neural
network, machine learning, deep learning, and ensemble learning
approaches in field of geotechnical engineering. <em>NCA</em>,
<em>36</em>(21), 12655–12699. (<a
href="https://doi.org/10.1007/s00521-024-09893-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANN), machine learning (ML), deep learning (DL), and ensemble learning (EL) are four outstanding approaches that enable algorithms to extract information from data and make predictions or decisions autonomously without the need for direct instructions. ANN, ML, DL, and EL models have found extensive application in predicting geotechnical and geoenvironmental parameters. This research aims to provide a comprehensive assessment of the applications of ANN, ML, DL, and EL in addressing forecasting within the field related to geotechnical engineering, including soil mechanics, foundation engineering, rock mechanics, environmental geotechnics, and transportation geotechnics. Previous studies have not collectively examined all four algorithms—ANN, ML, DL, and EL—and have not explored their advantages and disadvantages in the field of geotechnical engineering. This research aims to categorize and address this gap in the existing literature systematically. An extensive dataset of relevant research studies was gathered from the Web of Science and subjected to an analysis based on their approach, primary focus and objectives, year of publication, geographical distribution, and results. Additionally, this study included a co-occurrence keyword analysis that covered ANN, ML, DL, and EL techniques, systematic reviews, geotechnical engineering, and review articles that the data, sourced from the Scopus database through the Elsevier Journal, were then visualized using VOS Viewer for further examination. The results demonstrated that ANN is widely utilized despite the proven potential of ML, DL, and EL methods in geotechnical engineering due to the need for real-world laboratory data that civil and geotechnical engineers often encounter. However, when it comes to predicting behavior in geotechnical scenarios, EL techniques outperform all three other methods. Additionally, the techniques discussed here assist geotechnical engineering in understanding the benefits and disadvantages of ANN, ML, DL, and EL within the geo techniques area. This understanding enables geotechnical practitioners to select the most suitable techniques for creating a certainty and resilient ecosystem.},
  archive      = {J_NCA},
  author       = {Yaghoubi, Elaheh and Yaghoubi, Elnaz and Khamees, Ahmed and Vakili, Amir Hossein},
  doi          = {10.1007/s00521-024-09893-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12655-12699},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review and meta-analysis of artificial neural network, machine learning, deep learning, and ensemble learning approaches in field of geotechnical engineering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review on evaluating mental stress by deep learning using
EEG signals. <em>NCA</em>, <em>36</em>(21), 12629–12654. (<a
href="https://doi.org/10.1007/s00521-024-09809-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental stress is a common problem that affects individuals all over the world. Stress reduces human functionality during routine work and may lead to severe health defects. Early detection of stress is important for preventing diseases and other negative health-related consequences of stress. Several neuroimaging techniques have been utilized to assess mental stress, however, due to its ease of use, robustness, and non-invasiveness, electroencephalography (EEG) is commonly used. This paper aims to fill a knowledge gap by reviewing the different EEG-related deep learning algorithms with a focus on Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTMs) for the evaluation of mental stress. The review focuses on data representation, individual deep neural network model architectures, hybrid models, and results amongst others. The contributions of the paper address important issues such as data representation and model architectures. Out of all reviewed papers, 67% used CNN, 9% LSTM, and 24% hybrid models. Based on the reviewed literature, we found that dataset size and different representations contributed to the performance of the proposed networks. Raw EEG data produced classification accuracy around 62% while using spectral and topographical representation produced up to 88%. Nevertheless, the roles of generalizability across different deep learning models and individual differences remain key areas of inquiry. The review encourages the exploration of innovative avenues, such as EEG data image representations concurrently with graph convolutional neural networks (GCN), to mitigate the impact of inter-subject variability. This novel approach not only allows us to harmonize structural nuances within the data but also facilitates the integration of temporal dynamics, thereby enabling a more comprehensive assessment of mental stress levels.},
  archive      = {J_NCA},
  author       = {Badr, Yara and Tariq, Usman and Al-Shargie, Fares and Babiloni, Fabio and Al Mughairbi, Fadwa and Al-Nashash, Hasan},
  doi          = {10.1007/s00521-024-09809-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {21},
  pages        = {12629-12654},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review on evaluating mental stress by deep learning using EEG signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: An enhanced diabetic retinopathy detection
and classification approach using deep convolutional neural network.
<em>NCA</em>, <em>36</em>(20), 12627. (<a
href="https://doi.org/10.1007/s00521-024-10040-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Hemanth, D. Jude and Deperlioglu, Omer and Kose, Utku},
  doi          = {10.1007/s00521-024-10040-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12627},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An enhanced diabetic retinopathy detection and classification approach using deep convolutional neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Prediction of monthly groundwater level using a
new hybrid intelligent approach in the tabriz plain, iran. <em>NCA</em>,
<em>36</em>(20), 12625. (<a
href="https://doi.org/10.1007/s00521-024-10037-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Mirzania, Ehsan and Achite, Mohammed and Elshaboury, Nehal and Katipoğlu, Okan Mert and Saroughi, Mohsen},
  doi          = {10.1007/s00521-024-10037-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12625},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Prediction of monthly groundwater level using a new hybrid intelligent approach in the tabriz plain, iran},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Prediction of monthly groundwater level using a new hybrid
intelligent approach in the tabriz plain, iran. <em>NCA</em>,
<em>36</em>(20), 12609–12624. (<a
href="https://doi.org/10.1007/s00521-024-09681-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the groundwater level (GWL) is essential in water resource management and irrigation planning in arid and semi-arid areas. In this study, an artificial neural network (ANN) was combined with newly developed wild horse optimizer (WHO) and egret swarm optimization algorithm (ESOA) techniques to predict a one month lead-time GWL in the Tabriz plain of Iran. For the prediction of the GWL, the number of months and years, the one month lag of average temperature, evaporation, precipitation, and GWL were used as inputs. Model performances were compared using root mean square error (RMSE), Nash–Sutcliffe efficiency (NSE), coefficient of determination (R2), and relative strength ratio (RSR) statistical indicators and scatter diagrams, time series graph, violin graph, and Taylor diagram. As a result of the analysis, the most successful estimation results were obtained with the input combinations of year, month, average temperature, evaporation, precipitation, and GWL (t − 1) for the prediction of the one month lead-time GWL. According to the results of evaluation indicators in the testing phase, ANN with (R2 = 0.871, RMSE = 0.306 (m), NSE = 0.832, and RSR = 0.410), WHO–ANN (R2 = 0.932, RMSE = 0.200 (m), NSE = 0.929, and RSR = 0.267), and ESOA–ANN (R2 = 0.952, RMSE = 0.164 (m), NSE = 0.951, and RSR = 0.220). In addition, it was revealed that the ESOA–ANN hybrid model showed higher prediction success than the WHO–ANN and standalone ANN models. The study outputs contribute to decision-makers and planners for controlling land subsidence, assessing GWL and aquifer compaction, irrigation planning, and effective management of water resources.},
  archive      = {J_NCA},
  author       = {Mirzania, Ehsan and Achite, Mohammed and Elshaboury, Nehal and Katipoğlu, Okan Mert and Saroughi, Mohsen},
  doi          = {10.1007/s00521-024-09681-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12609-12624},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of monthly groundwater level using a new hybrid intelligent approach in the tabriz plain, iran},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: AGG: Attention-based gated convolutional GAN
with prior guidance for image inpainting. <em>NCA</em>, <em>36</em>(20),
12605–12608. (<a
href="https://doi.org/10.1007/s00521-024-10016-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yu, Xiankang and Dai, Lei and Chen, Zhihua and Sheng, Bin},
  doi          = {10.1007/s00521-024-10016-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12605-12608},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: AGG: attention-based gated convolutional GAN with prior guidance for image inpainting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). AGG: Attention-based gated convolutional GAN with prior
guidance for image inpainting. <em>NCA</em>, <em>36</em>(20),
12589–12604. (<a
href="https://doi.org/10.1007/s00521-024-09785-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting has made great achievements recently, but it is often tough to generate a semantically consistent image when faced with large missing areas in complex scenes. To address semantic and structural alignment in existing methods for image inpainting, this paper proposes an end-to-end attention-based gated convolution GAN with prior guidance named AGG, which designs the spatial and channel attention mechanisms for full extraction of semantic and structural features. Moreover, AGG constructs the attention-based upsampling module based on the channel attention to refine the feature map and capture more details from features of up-level low sizes. AGG uses the image contour as prior, allowing the gated convolution and attention mechanism may fill the image efficiently by focusing on the contour information. The attention-based gated convolution can effectively capture the global features and compensate for the limitations of the restricted receptive field of the naive convolution. Compared to other models, AGG generates images with finer outline features and no common problems such as the watermark and blur, which shows the best overall performance on the Paris StreetView, CelebA-HQ, and Places2 datasets. The best FID, LPIPS, PSNR, and SSIM values achieved by AGG are 2.18, 0.046, 30.82, and 0.951 on the CelebA-HQ dataset, with at least 3.21% and 6.52% performance improvement on FID and LPIPS compared to state-of-the-art methods, respectively. The source code will be available at https://github.com/Shawn-Yu-1/AGGNet .},
  archive      = {J_NCA},
  author       = {Yu, Xiankang and Dai, Lei and Chen, Zhihua and Sheng, Bin},
  doi          = {10.1007/s00521-024-09785-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12589-12604},
  shortjournal = {Neural Comput. Appl.},
  title        = {AGG: Attention-based gated convolutional GAN with prior guidance for image inpainting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction: Autism spectrum disorder diagnosis using fractal
and non-fractal-based functional connectivity analysis and machine
learning methods. <em>NCA</em>, <em>36</em>(20), 12587. (<a
href="https://doi.org/10.1007/s00521-024-10017-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Rakshe, Chetan and Kunneth, Suja and Sundaram, Soumya and Murugappan, Murugappan and Ronickom, Jac Fredo Agastinose},
  doi          = {10.1007/s00521-024-10017-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12587},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Autism spectrum disorder diagnosis using fractal and non-fractal-based functional connectivity analysis and machine learning methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autism spectrum disorder diagnosis using fractal and
non-fractal-based functional connectivity analysis and machine learning
methods. <em>NCA</em>, <em>36</em>(20), 12565–12585. (<a
href="https://doi.org/10.1007/s00521-024-09770-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a neurological condition characterized by impaired functional connectivity (FC) networks in the brain. There are several brain networks associated with ASD that have been studied for ASD diagnosis, but the results are inconsistent. A functional magnetic resonance imaging (fMRI) study was performed to address this gap by comparing brain networks among autistic individuals and individuals with typical development (TD) using data from the ABIDE-I and ABIDE-II databases. Blood oxygen level-dependent (BOLD) time series were extracted from 236 regions of interest (ROI) in fMRI data using three atlases: Gordon’s, Harvard Oxford, and Diedrichsen. Consequently, 27,730 nonlinear features are extracted from FC matrices, including fractals, non-fractals, and Pearson correlation coefficients (PCC). A parametric and nonparametric classifier was used to analyze the top 0.1%, 0.3%, 0.5%, 0.7%, 1%, 2%, and 3% of features based on the XGBoost feature ranking algorithm. In the study, we found that non-fractal brain FC measures can accurately identify ASD and TD more effectively than fractal and PCC measures. Classifiers performed well, with FC features at the top 0.3%. The classification model at OHSU was more accurate than the model at other sites. There was 100% accuracy at a single site and 96.17% accuracy at all sites using a multilayer perceptron classifier with non-fractal features. The classifier model shows that Cingulo-Parietal Task Control (13.6%), Retro-Splenial Temporal (RST) (13.3%), and Salience (11.6%) are significant contributors. The optimal performance was observed in features derived from networks such as RST and default (4 connections), auditory and Fronto-Parietal Task Control (3 connections), Cingulo-Opercular Task Control (COTC), and ventral attention (3 connections) within COTC (3 connections), visual and COTC (3 connections), and cerebellum and COTC (3 connections). Based on the results, non-fractal-based FC has value in distinguishing ASD from TD using resting-state fMRI.},
  archive      = {J_NCA},
  author       = {Rakshe, Chetan and Kunneth, Suja and Sundaram, Soumya and Murugappan, Murugappan and Agastinose Ronickom, Jac Fredo},
  doi          = {10.1007/s00521-024-09770-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12565-12585},
  shortjournal = {Neural Comput. Appl.},
  title        = {Autism spectrum disorder diagnosis using fractal and non-fractal-based functional connectivity analysis and machine learning methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solution of engineering design and truss topology problems
with improved forensic-based investigation algorithm based on dynamic
oppositional based learning. <em>NCA</em>, <em>36</em>(20), 12529–12563.
(<a href="https://doi.org/10.1007/s00521-024-09737-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The forensic-based investigation (FBI) is a metaheuristic algorithm inspired by the criminal investigation process. The collaborative efforts of the investigation and pursuit teams demonstrate the FBI’s involvement during the exploitation and exploration phases. When choosing the promising population, the FBI algorithm’s population selection technique focuses on the same region. This research aims to propose a dynamic population selection method for the original FBI and thereby enhance its convergence performance. To achieve this objective, the FBI may employ dynamic oppositional learning (DOL), a dynamic version of the oppositional learning methodology, to dynamically navigate to local minima in various locations. Therefore, the proposed advanced method is named DOLFBI. The performance of DOLFBI on the CEC2019 and CEC2022 benchmark functions is evaluated by comparing it with several other popular metaheuristics in the literature. As a result, DOLFBI yielded the lowest fitness value in 18 of 22 benchmark problems. Furthermore, DOLFBI has shown promising results in solving real-world engineering problems. It can be argued that DOLFBI exhibits the best convergence performance in cantilever beam design, speed reducer, and tension/compression problems. DOLFBI is often utilized in truss engineering difficulties to determine the minimal weight. Its success is comparable to other competitive MAs in the literature. The Wilcoxon signed-rank and Friedman rank tests further confirmed the study’s stability. Convergence and trajectory analyses validate the superior convergence concept of the proposed method. When the proposed study is compared to essential and enhanced MAs, the results show that DOLFBI has a competitive framework for addressing complex optimization problems due to its robust convergence ability compared to other optimization techniques. As a result, DOLFBI is expected to achieve significant success in various optimization challenges, feature selection, and other complex engineering or real-world problems.},
  archive      = {J_NCA},
  author       = {Kutlu Onay, Funda},
  doi          = {10.1007/s00521-024-09737-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12529-12563},
  shortjournal = {Neural Comput. Appl.},
  title        = {Solution of engineering design and truss topology problems with improved forensic-based investigation algorithm based on dynamic oppositional based learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FPGA-based small-world spiking neural network with
anti-interference ability under external noise. <em>NCA</em>,
<em>36</em>(20), 12505–12527. (<a
href="https://doi.org/10.1007/s00521-024-09667-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic hardware has become hotspot in the field of brain-like computing due to its advantages. However, the presence of external noise imposes challenges with respect to maintaining normal function of neuromorphic hardware. Biological brains have self-adaptability to external noise, meaning that a brain-like hardware with bio-plausibility can be expected to improve robustness. The purpose of this paper is to implement a highly fitted brain-like hardware with anti-interference ability (AIA) while preserving bio-plausibility. We propose a method of implementing a small-world spiking neural network (SWSNN) with bio-plausibility based on a field-programmable gate array (FPGA), in which the nodes are Izhikevich neuron modules, the edges are synaptic plasticity modules, and the topology is a small-world network. Then, the AIAs of the FPGA-based SNNs with different external noises are evaluated by two anti-interference indices. Further, taking a speech recognition task as the case study, the AIAs of these FPGA-based SNNs are verified in application. Finally, the AIA mechanism of the FPGA-based SNNs is discussed. Our results demonstrate that: (i) In the FPGA-based SWSNN, the FPGA-based Izhikevich neuron modules and the synaptic plasticity modules highly fit to the corresponding simulation results, and the topology conforms to the small-world property of human functional brain networks. (ii) Based on two anti-interference indices, the FPGA-based SWSNN outperforms the FPGA-based SNNs with other topologies, which is further verified by the speech recognition accuracy. (iii) Our discussions hint that the synaptic plasticity is intrinsic factor of the AIA, and the topology is a factor affecting the AIA.},
  archive      = {J_NCA},
  author       = {Guo, Lei and Liu, Yongkang and Wu, Youxi and Xu, Guizhi},
  doi          = {10.1007/s00521-024-09667-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12505-12527},
  shortjournal = {Neural Comput. Appl.},
  title        = {FPGA-based small-world spiking neural network with anti-interference ability under external noise},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). End-to-end tire defect detection model based on transfer
learning techniques. <em>NCA</em>, <em>36</em>(20), 12483–12503. (<a
href="https://doi.org/10.1007/s00521-024-09664-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual inspection of defective tires post-production is vital for human safety, as faulty tires can lead to explosions, accidents, and loss of life. With the advancement of technology, transfer learning (TL) plays an influential role in many computer vision applications, including the tire defect detection problem. However, automatic tire defect detection is difficult for two reasons. The first is the presence of complex anisotropic multi-textured rubber layers. Second, there is no standard tire X-ray image dataset to use for defect detection. In this study, a TL-based tire defect detection model is proposed using a new dataset from a global tire company. First, we collected and labeled the dataset consisting of 3366 X-ray images of faulty tires and 20,000 images of qualified tires. Although the dataset covers 15 types of defects arising from different design patterns, our primary focus is on binary classification to detect the presence or absence of defects. This challenging dataset was split into 70, 15, and 15% for training, validation, and testing, respectively. Then, nine common pre-trained models were fine-tuned, trained, and tested on the proposed dataset. These models are Xception, InceptionV3, VGG16, VGG19, ResNet50, ResNet152V2, DenseNet121, InceptionResNetV2, and MobileNetV2. The results show that the fine-tuned VGG19, DenseNet21 and InceptionNet models achieve compatible results with the literature. Moreover, the Xception model outperformed the compared TL models and literature methods in terms of recall, precision, accuracy, and F1 score. Moreover, it achieved on the testing dataset 73.7, 88, 80.2, and 94.75% of recall, precision, F1 score, and accuracy, respectively, and on the validation dataset 73.3, 90.24, 80.9, and 95% of recall, precision, F1 score, and accuracy, respectively.},
  archive      = {J_NCA},
  author       = {Saleh, Radhwan A. A. and Konyar, Mehmet Zeki and Kaplan, Kaplan and Ertunç, H. Metin},
  doi          = {10.1007/s00521-024-09664-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12483-12503},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end tire defect detection model based on transfer learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gaze-infused BERT: Do human gaze signals help pre-trained
language models? <em>NCA</em>, <em>36</em>(20), 12461–12482. (<a
href="https://doi.org/10.1007/s00521-024-09725-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research delves into the intricate connection between self-attention mechanisms in large-scale pre-trained language models, like BERT, and human gaze patterns, with the aim of harnessing gaze information to enhance the performance of natural language processing (NLP) models. We analyze the correlation between BERT attention and five distinct gaze signals based on the Spearman correlation, discovering that neither all attention layers nor all gaze signals accurately capture word importance. Building on this insight, we propose gaze-infused BERT, a novel model that integrates gaze signals into BERT for performance enhancement. Specifically, we first utilize a gaze prediction model based on RoBERTa to estimate five gaze signals, our lightweight model utilizes the entropy weight method (EWM) to generate a comprehensive gaze representation by combining five diverse gaze signals. This representation is then embedded into the transformer encoder while performing the self-attention between the input sequence, enriching contextual information and boosting performance. Extensive evaluations on the 15 datasets demonstrate that gaze-infused BERT consistently outperforms baseline models across various NLP tasks, highlighting the potential of integrating human gaze signals into pre-trained language models.},
  archive      = {J_NCA},
  author       = {Wang, Bingbing and Liang, Bin and Zhou, Lanjun and Xu, Ruifeng},
  doi          = {10.1007/s00521-024-09725-8},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12461-12482},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gaze-infused BERT: Do human gaze signals help pre-trained language models?},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning framework for end-to-end
semiconductor process control. <em>NCA</em>, <em>36</em>(20),
12443–12460. (<a
href="https://doi.org/10.1007/s00521-024-09710-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on bringing state-of-the-art artificial intelligence and deep reinforcement learning to the manufacturing of semiconductor devices. The main goal of this research is to lay down the foundation of an end-to-end system for manufacturing control. In contrast to most of the research published in this field, the goal of this algorithm is not to conceptualize the different processes as separate entities but rather to try to control the chain of semiconductor processes as a whole. Therefore, we treat the process chain as an ecosystem where we control all processes using agents that learn to cooperate to produce the best wafers and semiconductor devices. In order to achieve that, we developed an architecture called an ensemble of independent preprocessors (EIP). We applied it with the deep reinforcement learning technique called soft actor-critic (SAC) in various environments, including environments comporting simulated semiconductor devices. The introduced technique strongly outperformed standard statistical methods and allowed us to find new sets of optimal manufacturing parameters different from the true ones. We hope that this work and the presentation of our framework will encourage practitioners to experiment with such systems and make further advancements in the field of decision-making for semiconductor manufacturing.},
  archive      = {J_NCA},
  author       = {Hirtz, Thomas and Tian, He and Shahzad, Shazrah and Wu, Fan and Yang, Yi and Ren, Tian-Ling},
  doi          = {10.1007/s00521-024-09710-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12443-12460},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep reinforcement learning framework for end-to-end semiconductor process control},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ha-gnn: A novel graph neural network based on hyperbolic
attention. <em>NCA</em>, <em>36</em>(20), 12427–12442. (<a
href="https://doi.org/10.1007/s00521-024-09689-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are powerful tools for data mining on graph-structured data in various domains, such as social science, finance, and biology. However, most existing GNNs operate in Euclidean space and may fail to preserve the intrinsic network properties, such as self-similarity and hierarchy, that characterize many real-world graphs. Hyperbolic graph neural networks (HGNNs) address this limitation by embedding graphs into hyperbolic space, which can better capture the hierarchical structures of networks. However, HGNNs often involve complex computations in hyperbolic space or its tangent space during training, which may hinder their efficiency. In this paper, we propose hyperbolic attention graph neural networks (HA-GNN), which can leverage both network structure and node features for graph representation learning in an efficient way. Specifically, we design a structural properties attention mechanism that measures the structural connection between nodes based on their hyperbolic embeddings. We also design a node features attention mechanism that quantifies the feature similarity between nodes. We then combine these two attentions to obtain a hyperbolic attention that weights the relevance between all connected nodes. We conduct extensive experiments on five real-world networks and demonstrate that our model consistently and significantly outperforms other state-of-the-art methods. For example, on the Cora network, our model achieves an accuracy of 83.1 (± 0.4) on node classification tasks, which is 1.6% higher than the best baseline method in Euclidean space.},
  archive      = {J_NCA},
  author       = {Qu, Hongbo and Song, Yu-Rong and Zhang, Minglei and Jiang, Guo-Ping and Li, Ruqi and Song, Bo},
  doi          = {10.1007/s00521-024-09689-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12427-12442},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ha-gnn: A novel graph neural network based on hyperbolic attention},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Imbalanced instance selection based on laplacian matrix
decomposition with weighted k-nearest-neighbor graph. <em>NCA</em>,
<em>36</em>(20), 12397–12425. (<a
href="https://doi.org/10.1007/s00521-024-09676-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data are an essential component for building machine learning models. Linearly separable high-quality data are conducive to building efficient classification models. However, the collected dataset is not of high quality, and the number of instances for difference class is not absolutely consistent. Therefore, models built on these datasets are vulnerable to problems such as class-imbalance, class-overlap, and other problems. Traditional instance selection algorithms mainly determine whether there is redundancy or overlap in instances based on the degree of similarity between instances. Therefore, these methods only focus on the local information of the dataset and ignore the global approximate relationship of the instances in the dataset. In this paper, an instance selection method based on the global relationship of instances in the dataset is proposed, called instance selection based on Laplacian matrix decomposition with weighted k-nearest-neighbor graph (LMD-WNG). First, this method tries to construct a new distance-weighted Laplacian matrix using the weighted k-nearest-neighbor graph. Then, the distance-weighted Laplacian matrix is decomposed using a Schur decomposition method. Finally, according to the eigenvalues of the decomposed real matrix, a training dataset suitable for model learning is selected, and a classifier is constructed on the new training data. The experimental results show that as the imbalance ratio increases, LMD-WNG becomes more sensitive to parameter k. When the significance level is $$p = 0.05$$ , the analysis results using Friedman ranking and the Holm’s post hoc test show that LMD-WNG is significantly better than or similar to other state-of-the-art algorithms on 30 datasets.},
  archive      = {J_NCA},
  author       = {Dai, Qi and Liu, Jian-wei and Wang, Long-hui},
  doi          = {10.1007/s00521-024-09676-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12397-12425},
  shortjournal = {Neural Comput. Appl.},
  title        = {Imbalanced instance selection based on laplacian matrix decomposition with weighted k-nearest-neighbor graph},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised action representation learning from partial
consistency skeleton sequences. <em>NCA</em>, <em>36</em>(20),
12385–12395. (<a
href="https://doi.org/10.1007/s00521-024-09671-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, self-supervised representation learning for skeleton-based action recognition has achieved remarkable results using skeleton sequences with the advance of contrastive learning methods. However, existing methods often overlook the local information within the skeleton data, so as to not efficiently learn fine-grained features. To leverage local features to enhance representation capacity and capture discriminative representations, we design an adaptive self-supervised contrastive learning framework for action recognition called AdaSCLR. In AdaSCLR, we introduce an adaptive spatiotemporal graph convolutional network to learn the topology of different samples and hierarchical levels and apply an attention mask module to extract salient and non-salient local features from the global features, emphasizing their significance and facilitating similarity-based learning. In addition, AdaSCLR extracts information from the upper and lower limbs as local features to assist the model in learning more discriminative representation. Experimental results show that our approach is better than the state-of-the-art methods on NTURGB+D, NTU120-RGB+D, and PKU-MMD datasets.},
  archive      = {J_NCA},
  author       = {Lin, Biyun and Zhan, Yinwei},
  doi          = {10.1007/s00521-024-09671-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12385-12395},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-supervised action representation learning from partial consistency skeleton sequences},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model predictive control for a bending pneumatic muscle
based on an online modified generalized prandtl–ishlinskii model.
<em>NCA</em>, <em>36</em>(20), 12371–12383. (<a
href="https://doi.org/10.1007/s00521-024-09666-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumatic actuators exhibit significant potential across various applications owing to their compliance, yet achieving precise motion control remains challenging due to rate-dependent and asymmetric hysteresis. While the Prandtl–Ishlinskii model adeptly captures intricate hysteresis traits, its practical control usage often necessitates intricate inversions, resulting in elevated computational burden and limited accommodation of system uncertainties and model inaccuracies. This study introduces an online, rate-dependent modified generalized Prandtl–Ishlinskii model derived via the gradient descent algorithm. This model is seamlessly amalgamated with a model predictive control strategy, addressing the inversion challenge inherent in the Prandtl–Ishlinskii model. Leveraging integration with a three-layer fuzzy neural network controller, the proposed approach achieves closed-loop trajectory tracking control for a soft bending pneumatic muscle. Convergence analysis, grounded in Lyapunov theory, underscores the efficacy of the proposed model. Comprehensive real-world comparative experiments affirm the approach’s effectiveness and reliability.},
  archive      = {J_NCA},
  author       = {Ru, Hongge and Yang, Yuqi and Wang, Bo and Huang, Jian},
  doi          = {10.1007/s00521-024-09666-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12371-12383},
  shortjournal = {Neural Comput. Appl.},
  title        = {Model predictive control for a bending pneumatic muscle based on an online modified generalized Prandtl–Ishlinskii model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment analysis in social internet of things using
contextual representations and dilated convolution neural network.
<em>NCA</em>, <em>36</em>(20), 12357–12370. (<a
href="https://doi.org/10.1007/s00521-024-09771-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The methodologies based on neural networks are substantial to accomplish sentiment analysis in the Social Internet of Things (SIoT). With social media sentiment analysis, significant insights can produce efficient and intelligent applications. Neural networks such as recurrent neural networks (RNNs) and convolution neural networks (CNNs) have been considered widely in many text classification tasks. However, RNNs are computationally expensive and require complex training to capture contextual information and long-term dependencies. Similarly, traditional CNNs must stack multiple convolutional layers, requiring massive computations and additional parameters. To address these problems, this work initialized the novel architecture, in which contextual representations (CRs) based on the textual framework are proposed at the initial step. In CRs, state-of-the-art word representation models, such as GloVe (global vectors) and FastText (subword information), collectively produce word representations upon the input sequence using a weight mechanism. Secondly, a unique way is introduced: a three-parallel layered dilated convolutional network with global mean pooling. The experimental results show that the proposed methods when compared with baseline methods, the dilation in CNNs following CRs significantly increases the accuracy from 72.45 to 98.98% and reduces computational resources.},
  archive      = {J_NCA},
  author       = {Abid, Fazeel and Rasheed, Jawad and Hamdi, Mohammed and Alshahrani, Hani and Al Reshan, Mana Saleh and Shaikh, Asadullah},
  doi          = {10.1007/s00521-024-09771-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12357-12370},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sentiment analysis in social internet of things using contextual representations and dilated convolution neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast and enhanced shallow learning framework for solving
free boundary options pricing problems. <em>NCA</em>, <em>36</em>(20),
12327–12356. (<a
href="https://doi.org/10.1007/s00521-024-09740-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider various nonstandard and nonlinear free boundary options pricing problems comprising the nonlinear free boundary local volatility model, exotic options, and dividend paying pricing model and present a fast and enhanced shallow learning framework for solving free boundary options pricing problems with auxiliary neural operators (ANOs). To this end, we first rigorously explore the efficacy of some featured activation functions (FAFs) for solving these models with ANOs. We observe that some existing and ad hoc activation functions perform well, but are not suitable for generalization. Rather, they should be enhanced to be adaptable to specific model characteristics and conditions based on their positivity, boundedness, convexity, vanishing points, discontinuous points, exploding points, etc. By adapting some of the existing activation functions and accustoming new ones, we then obtain a fast and enhanced shallow learning method which substantially improve the performance of neural network methodologies for nonstandard options pricing models.},
  archive      = {J_NCA},
  author       = {Nwankwo, Chinonso and Ware, Tony and Dai, Weizhong},
  doi          = {10.1007/s00521-024-09740-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12327-12356},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fast and enhanced shallow learning framework for solving free boundary options pricing problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical reinforcement thompson composition.
<em>NCA</em>, <em>36</em>(20), 12317–12326. (<a
href="https://doi.org/10.1007/s00521-024-09732-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern real-world control problems call for continuous control domains and robust, sample efficient and explainable control frameworks. We are presenting a framework for recursively composing control skills to solve compositional and progressively complex tasks. The framework promotes reuse of skills, and as a result quick adaptability to new tasks. The decision tree can be observed, providing insight into the agents’ behavior. Furthermore, the skills can be transferred, modified or trained independently, which can simplify reward shaping and increase training speeds considerably. This paper is concerned with efficient composition of control algorithms using reinforcement learning and soft attention. Compositional and temporal abstraction is the key to improving learning and planning in reinforcement learning. Our Thompson sampling inspired soft-attention model is demonstrated to efficiently solve the composition problem.},
  archive      = {J_NCA},
  author       = {Tanık, Güven Orkun and Ertekin, Şeyda},
  doi          = {10.1007/s00521-024-09732-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12317-12326},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical reinforcement thompson composition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid feature weighting and selection-based strategy to
classify the high-dimensional and imbalanced medical data. <em>NCA</em>,
<em>36</em>(20), 12299–12316. (<a
href="https://doi.org/10.1007/s00521-024-09713-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms generally assume that the data are balanced in nature. However, medical datasets suffer from the curse of dimensionality and class imbalance problems. The medical datasets are obtained from the patient information which creates an imbalance in class distribution as the number of normal persons is more than the number of patients and contains a large number of features to represent a sample. It tends to the machine learning algorithms biased toward the majority class which degrades their classification performance for minority class samples and increases the computation overhead. Therefore, oversampling, feature selection and feature weighting-based four strategies are proposed to deal with the problems of class imbalance and high dimensionality. The key idea behind the proposed strategies is to generate a balanced sample space along with the optimal weighted feature space of the most relevant and discriminative features. The Synthetic Minority Oversampling Technique is utilized to generate the synthetic minority class samples and reduce the bias toward the majority class. An Improved Elephant Herding Optimization algorithm is applied to select the optimal features and weights for reducing the computation overhead and improving the interpretation ability of the learning algorithms by providing weights to relevant features. In addition, thirteen methods are developed from the proposed strategies to deal with the problems of high-dimensionality and imbalanced data. The optimized $$k$$ -Nearest Neighbor ( $$k$$ -NN) learning algorithm is utilized to perform classification. The performance of the proposed methods is evaluated and compared for sixteen high-dimensional imbalanced medical datasets. Further, Freidman’s mean rank test is applied to show the statistical difference between the proposed methods. Experimental and statistical results show that the proposed Feature Weighting followed by the Feature Selection (FW–FS) method performed significantly better than the other proposed methods for classification accuracy, g-mean, f-score, and AUC metrics. In addition, the performance of the proposed FW–FS method is compared with eleven state-of-the-art algorithms. The results express the effectiveness of the proposed FW–FS method in dealing with high-dimensional imbalanced medical datasets than other state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Singh, Harpreet and Kaur, Manpreet and Singh, Birmohan},
  doi          = {10.1007/s00521-024-09713-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12299-12316},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid feature weighting and selection-based strategy to classify the high-dimensional and imbalanced medical data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IHHO: An improved harris hawks optimization algorithm for
solving engineering problems. <em>NCA</em>, <em>36</em>(20),
12185–12298. (<a
href="https://doi.org/10.1007/s00521-024-09603-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris Hawks optimization (HHO) algorithm was a powerful metaheuristic algorithm for solving complex problems. However, HHO could easily fall within the local minimum. In this paper, we proposed an improved Harris Hawks optimization (IHHO) algorithm for solving different engineering tasks. The proposed algorithm focused on random location-based habitats during the exploration phase and on strategies 1, 3, and 4 during the exploitation phase. The proposed modified Harris hawks in the wild would change their perch strategy and chasing pattern according to updates in both the exploration and exploitation phases. To avoid being stuck in a local solution, random values were generated using logarithms and exponentials to explore new regions more quickly and locations. To evaluate the performance of the proposed algorithm, IHHO was compared to other five recent algorithms [grey wolf optimization, BAT algorithm, teaching–learning-based optimization, moth-flame optimization, and whale optimization algorithm] as well as three other modifications of HHO (BHHO, LogHHO, and MHHO). These optimizers had been applied to different benchmarks, namely standard benchmarks, CEC2017, CEC2019, CEC2020, and other 52 standard benchmark functions. Moreover, six classical real-world engineering problems were tested against the IHHO to prove the efficiency of the proposed algorithm. The numerical results showed the superiority of the proposed algorithm IHHO against other algorithms, which was proved visually using different convergence curves. Friedman&#39;s mean rank statistical test was also inducted to calculate the rank of IHHO against other algorithms. The results of the Friedman test indicated that the proposed algorithm was ranked first as compared to the other algorithms as well as three other modifications of HHO.},
  archive      = {J_NCA},
  author       = {Akl, Dalia T. and Saafan, Mahmoud M. and Haikal, Amira Y. and El-Gendy, Eman M.},
  doi          = {10.1007/s00521-024-09603-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12185-12298},
  shortjournal = {Neural Comput. Appl.},
  title        = {IHHO: An improved harris hawks optimization algorithm for solving engineering problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Point-of-interest recommendation based on LBSN with
multi-aspect fusion of social and individual features. <em>NCA</em>,
<em>36</em>(20), 12163–12184. (<a
href="https://doi.org/10.1007/s00521-024-09711-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-of-interest (POI) recommendation is of paramount importance to user travel efficiency since users always expect their intended POIs can be recommended within a specified geospatial range. However, existing methods may not well establish user–user, user–POI, and POI–POI relatedness in a feature-interaction manner and social influence may not be infused into the recommendation process through feature fusion, causing unstable recommendation accuracy in different real-world datasets with multiple variables. A multi-aspect fusion of social and individual features POI recommendation method is proposed in this study, establishing feature interaction gate with user check-in ability, POI popularity, and POI physical characteristics involved. Furthermore, these multi-aspect feature interactions are exploited to incorporate multimodal data and establish information sharing and delivery between users in internal fusion through embedded factorization machine variants imposing individual influence and social influence in location-based social network (LBSN) on recommendation results. Moreover, relatedness enhancement module is established to balance contextual influence and social influence on user next movement decision in external fusion such that direct external information can be transmitted and shared, which diversifies recommendation results. Extensive experiments are conducted on two real-world datasets, and the results show that the proposed model achieves significantly superiority compared with its state-of-the-art baseline models and effectiveness of each proposed modules.},
  archive      = {J_NCA},
  author       = {Zhang, Yishan and Liu, Yu},
  doi          = {10.1007/s00521-024-09711-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12163-12184},
  shortjournal = {Neural Comput. Appl.},
  title        = {Point-of-interest recommendation based on LBSN with multi-aspect fusion of social and individual features},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multi-view GCN for loan default risk prediction.
<em>NCA</em>, <em>36</em>(20), 12149–12162. (<a
href="https://doi.org/10.1007/s00521-024-09695-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a significant application of machine learning in financial scenarios, loan default risk prediction aims to evaluate the client’s default probability. However, most existing deep learning solutions treat each application as an independent individual, neglecting the explicit connections among different application records. Besides, these attempts suffer from the problem of missing data and imbalanced distribution (i.e., the default records are small samples against all the applications). We believe similar records could provide some auxiliary signals, which are of critical importance to alleviate the data missing issue and facilitate data argumentation. To this end, we propose multi-view loan application graphs, dubbed MLAGs. By evaluating the similarity between the records, a loan application graph can be constructed. Furthermore, we arrange different similarity thresholds to organize various graph structures for multi-graph constructions; thus, a variety of representations can be generated via information propagation and aggregation for small sample argumentation. Consequently, the imbalanced data distribution and missing values issues can be alleviated effectively. We conduct experiments on three public datasets from real-world home credit and P2P lending platforms, which show that MGCN outperforms both conventional and deep learning models. Ablation studies also illustrated the validity of each module design.},
  archive      = {J_NCA},
  author       = {Li, Zihao and Chen, Yakun and Wang, Xianzhi and Yao, Lina and Xu, Guandong},
  doi          = {10.1007/s00521-024-09695-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12149-12162},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-view GCN for loan default risk prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of battery energy storage in mitigating demand
fluctuations of distribution networks caused by uncertain weather
conditions using multi-objective bonobo optimizer. <em>NCA</em>,
<em>36</em>(20), 12131–12148. (<a
href="https://doi.org/10.1007/s00521-024-09686-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluctuations in demand can have a significant impact on electrical distribution networks, causing variations in voltage and frequency, imbalances between power output and consumption, and putting strain on system components. This study suggests using optimized battery energy storage systems controlled by the Bonobo Optimizer (BO) algorithm, along with renewable photovoltaic sources, to mitigate the effects of system demand fluctuations (SDF). The utilization of the BO is intended to minimize the SDF and alleviate energy losses in the 69-bus system amidst uncertain demand situations from residential, commercial, and industrial sectors. The optimal compromise solution is obtained by implementing both single-objective and multi-objective optimizations utilizing two techniques: the fuzzy-based function approach and the technique for order of preference by similarity to the ideal solution. Diverse metrics are utilized to evaluate the excellence of the suggested approach, including power, voltage, and stability. The results demonstrate a significant increase in the load factor, with values of 98.86%, 99.64%, and 99.90% observed for the three forms of demand, compared to the load factors of 57.25%, 73.95%, and 73.22% seen in the base scenario. Moreover, there have been improvements in the voltage profile and system stability. Furthermore, a significant reduction in system energy loss has been seen in the multi-objective optimization case study.},
  archive      = {J_NCA},
  author       = {Eid, Ahmad},
  doi          = {10.1007/s00521-024-09686-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12131-12148},
  shortjournal = {Neural Comput. Appl.},
  title        = {The role of battery energy storage in mitigating demand fluctuations of distribution networks caused by uncertain weather conditions using multi-objective bonobo optimizer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolution inspired binary flower pollination for the
uncapacitated facility location problem. <em>NCA</em>, <em>36</em>(20),
12117–12130. (<a
href="https://doi.org/10.1007/s00521-024-09684-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper introduces a modified flower pollination algorithm (FPA) enhanced by evolutionary operators to solve the uncapacitated facility location problem (UFLP), which is one of the well-known location science problems. The aim in UFLP is to select some locations to open facilities among a certain number of candidate locations so as to minimize the total cost, which is the sum of facility opening costs and transportation costs. Since UFLP is a binary optimization problem, FPA, which is introduced to solve real-valued optimization problems, is redesigned to be able to conduct search in binary domains. This constitutes one of the contributions of the present study. In this context, some evolutionary operators such as crossover and mutation are adopted by the proposed FPA. Next, the mutation operator is further enhanced by making use of an adaptive procedure that introduces greater level of diversity at earlier iterations and encourages intensification toward the end of search. Thus, while premature convergence and local optima problems at earlier iterations are avoided, a more intensified search around the found promising regions is performed. Secondarily, as demonstrated in this study, by making use of the reported evolutionary procedures, FPA is able to run in binary spaces without employing any additional auxiliary procedures such as transfer functions. All available benchmarking instances are solved by the proposed approach. As demonstrated by the comprehensive experimental study that includes statistically verified results, the developed approach is found as a promising algorithm that can be extended to numerous binary optimization problems.},
  archive      = {J_NCA},
  author       = {Ozsoydan, Fehmi Burcin and Kasırga, Ali Erel},
  doi          = {10.1007/s00521-024-09684-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12117-12130},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolution inspired binary flower pollination for the uncapacitated facility location problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepAHR: A deep neural network approach for recognizing
arabic handwritten recognition. <em>NCA</em>, <em>36</em>(20),
12103–12115. (<a
href="https://doi.org/10.1007/s00521-024-09674-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic handwritten character recognition plays a significant role in various applications across multiple fields. With the growing interest in automatic handwriting recognition and the advancement of deep learning methods, researchers have achieved significant improvements in the development of English handwriting recognition methods. However, the recognition of Arabic handwriting has received insufficient attention. In this paper, a novel &quot;DeepAHR&quot; model is presented to accurately and efficiently recognize Arabic handwritten characters using deep learning techniques. The &quot;DeepAHR&quot; model is based on a convolutional neural network (CNN) and is trained using two recent public datasets: Hijaa and Arabic handwritten characters dataset (AHCD). The overall accuracies of the proposed model were 98.66% and 88.24% on the AHCD and Hijaa datasets, respectively.The experimental results showed that DeepAHR outperformed state-of-the-art methods in the literature. These promising results provide evidence of the successful use of the DeepAHR model for recognizing handwritten Arabic characters},
  archive      = {J_NCA},
  author       = {AlShehri, Helala},
  doi          = {10.1007/s00521-024-09674-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12103-12115},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepAHR: A deep neural network approach for recognizing arabic handwritten recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RDGMEF: A multi-exposure image fusion framework based on
retinex decompostion and guided filter. <em>NCA</em>, <em>36</em>(20),
12083–12102. (<a
href="https://doi.org/10.1007/s00521-024-09779-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-exposure image fusion (MEF) technique directly fuses a series of images with the same scene but different exposure levels into one high-quality image with more scene details. Presently, most MEF algorithms employ the original image as the input or process the Y-channel to emphasize achieving optimal exposure levels. The texture details and color saturation of the fused image can be easily influenced by lighting factors. In order to deal with the problem of unclear texture details and color distortion easily in the existing multi-exposure image fusion algorithms, a MEF algorithm based on Retinex decomposition and guided filter is proposed, termed as RDGMEF. With Retinex decomposition, the multi-exposure image is divided into two parts: reflection image and luminance image, which are then fused using different fusion algorithms, respectively. The reflection image excludes the influence of lighting factors and has clearer texture detail information, which can be well used as a guidance image to direct the guided filter to generate the weight map required for fusion; for the illumination image, which only contains lighting information, a simple weighted average based on the degree of exposure can achieve very good results. The fused reflection image greatly restores the degraded texture information in the unevenly exposed region, and the illumination image does not suffer from color distortion due to the large differences in light intensity.},
  archive      = {J_NCA},
  author       = {Chang, Rui and Liu, Gang and Tang, Haojie and Qian, Yao and Tang, Jianchao},
  doi          = {10.1007/s00521-024-09779-8},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12083-12102},
  shortjournal = {Neural Comput. Appl.},
  title        = {RDGMEF: A multi-exposure image fusion framework based on retinex decompostion and guided filter},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal design and operation of battery energy storage
systems in renewable power plants to reach maximum total electric sale
revenues. <em>NCA</em>, <em>36</em>(20), 12061–12082. (<a
href="https://doi.org/10.1007/s00521-024-09769-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper applies jellyfish search optimization algorithm (JSOA) to maximize electric sale revenue for renewable power plants (RNPPs) with the installation of battery energy storage systems (BESS). Wind turbines (WTs) and solar photovoltaic arrays (SPVAs) are major power sources; meanwhile, the BESS can store energy generated at low-electricity price hours and supply the electricity to loads at other high-electricity price hours. In the first four cases with one operating day, JSOA and three other algorithms are implemented. JSOA reaches greater total revenue than the three other ones. BESS can support a renewable power plant (RNPP) to get more revenue by $495.2. Applying JSOA for two other cases with the change of requested saving energy levels and capacity of BESS, the results indicate that for increasing 10% saving energy or the reduction of 10% BESS capacity, the profit can be reduced by 10% of the maximum profit. In the last study case, BESS is connected between two plants in Vietnam, the Adani Phuoc Minh wind power plant and the Adani Phuoc Minh solar power plant, over one operating year. BESS supports the two power plants, reaching a profit of $733,322.5, about 4.15% of total revenue from the system without BESS. Considering BESS’s investment costs, the profit of BESS over ten operating years is greater than the costs of the cheapest BESS technology by $3,703,225. However, the profit is smaller than other more modern BESS technologies. So, using BESS can bring a high profit to RNPPs, and the selection of BESS technologies impacts the economic issue of the RNPPs.},
  archive      = {J_NCA},
  author       = {Phan, Tan Minh and Nguyen, Thang Trung and Duong, Minh Quan and Nguyen, Thuan Thanh},
  doi          = {10.1007/s00521-024-09769-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12061-12082},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal design and operation of battery energy storage systems in renewable power plants to reach maximum total electric sale revenues},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot classification of ultrasound breast cancer images
using meta-learning algorithms. <em>NCA</em>, <em>36</em>(20),
12047–12059. (<a
href="https://doi.org/10.1007/s00521-024-09767-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical datasets often have a skewed class distribution and a lack of high-quality annotated images. However, deep learning methods require a large amount of labeled data for classification. In this study, we present a few-shot learning approach for the classification of ultrasound breast cancer images using meta-learning methods. We used prototypical networks and model agnostic meta-learning (MAML) algorithms as meta-learning methods. The breast ultrasound images (BUSI) dataset, which has three classes and is difficult to use in meta-learning, was used for meta-testing in a cross-domain approach along with other datasets for meta-training. Our proposed approach yielded an accuracy range of 0.882–0.889, achieved by implementing the ResNet50 backbone with ProtoNet in a 10-shot setting. These results represent a significant improvement ranging from 6.27 to 7.10% over the baseline accuracy of 0.831. The results showed that ProtoNet outperformed the MAML method for all k-shot settings. In addition, the use of ResNet models as the backbone network for feature extraction was found to be more successful than the use of a four-layer convolutional model. Our proposed method is the first attempt to apply meta-learning for few-shot classification in the BUSI dataset while providing higher accuracy compared to deep learning methods for medical images with small-scale datasets and few classes. The methodology used in this study can be adapted to other datasets with similar problems.},
  archive      = {J_NCA},
  author       = {Işık, Gültekin and Paçal, İshak},
  doi          = {10.1007/s00521-024-09767-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12047-12059},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot classification of ultrasound breast cancer images using meta-learning algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new histogram equalization technique for contrast
enhancement of grayscale images using the differential evolution
algorithm. <em>NCA</em>, <em>36</em>(20), 12029–12045. (<a
href="https://doi.org/10.1007/s00521-024-09739-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image contrast enhancement is a crucial computer vision step aiming to improve the quality of the visual information in processed images. In the literature, several proposed methods for image contrast enhancement are Histogram Equalization-based (HE) techniques that use one transformation function and optimize its parameters for mapping the pixels to new gray-intensity values. However, using only one transformation function would leave other enhancement options unexplored. Therefore, the proposed approach generates several transformation functions and selects the one that best improves the image&#39;s contrast. This method is based on the Differential Evolution (DE) algorithm, which produces multiple candidate solutions representing transformation functions. The transformation functions map the input pixel values in their enhanced versions to equalize the histogram and improve the image&#39;s contrast. Furthermore, a new formulation is proposed as the objective function based on the number of edge pixels, the intensity of the pixels, image entropy, and the number of gray intensity levels. The performance of this approach has been tested on low-contrast dataset images and compared to similar HE techniques, such as AVHEQ, BBHE, RSESIHE, MMBEBHE, and ESIHE. The results demonstrate the proposed algorithm&#39;s robustness and high performance in improving the grayscale images&#39; contrast.},
  archive      = {J_NCA},
  author       = {Rivera-Aguilar, Beatriz A. and Cuevas, Erik and Pérez, Marco and Camarena, Octavio and Rodríguez, Alma},
  doi          = {10.1007/s00521-024-09739-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12029-12045},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new histogram equalization technique for contrast enhancement of grayscale images using the differential evolution algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anomaly graph: Leveraging dynamic graph convolutional
networks for enhanced video anomaly detection in surveillance and
security applications. <em>NCA</em>, <em>36</em>(20), 12011–12028. (<a
href="https://doi.org/10.1007/s00521-024-09738-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video abnormality behavior identification plays a pivotal role in improving the safety and security of surveillance systems by identifying unusual events within video streams. However, existing methods face challenges in capturing complex spatiotemporal anomalies effectively. To address this, we propose an anomaly graph approach that leverages dynamic graph representations and dynamic graph convolutional networks (GCN) for video anomaly detection. Anomaly graph constructs dynamic graphs where nodes represent objects or regions of interest within video frames while the edges encode spatial and temporal relationships. The GCN architecture extracts spatiotemporal embeddings from the dynamic graphs and allows the model to identify anomalies involving both spatial and temporal cues. Anomaly graph introduces uniqueness scores to quantify frame distinctiveness for precise anomaly detection while it employs adaptive reconstruction errors to pinpoint spatially localized anomalies. Real-time alerts are generated for detected anomalies to ensure timely responses to security incidents, and online fine-tuning (OLT) is incorporated as a dynamic learning mechanism to adapt to evolving anomaly patterns existing in dynamic environments. The extensive experimentation on benchmark datasets including UCSD Ped2 and CUHK Avenue is carried out for diverse performance measures, and the anomaly graph exhibits enhanced performance in the detection of anomalous events by achieving a detection accuracy of 98.72% and precision of 97.18%. Moreover, it is found to have achieved better values compared to other related methods for video anomaly detection. Overall, the anomaly graph introduces a robust video anomaly detection framework that excels in identifying complex spatiotemporal anomalies and empowers surveillance and security systems to detect anomalies more effectively.},
  archive      = {J_NCA},
  author       = {Chiranjeevi, V. Rahul and Malathi, D.},
  doi          = {10.1007/s00521-024-09738-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {12011-12028},
  shortjournal = {Neural Comput. Appl.},
  title        = {Anomaly graph: Leveraging dynamic graph convolutional networks for enhanced video anomaly detection in surveillance and security applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EmapDiffP: A novel learning algorithm for convolutional
neural network optimization. <em>NCA</em>, <em>36</em>(20), 11987–12010.
(<a href="https://doi.org/10.1007/s00521-024-09708-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) having multiple hidden layers are very efficient to learn large volume datasets and applied in a wide range of applications. The DNNs are trained on these datasets using learning algorithms to learn the relationships among different variables. The base method that makes DNNs successful is stochastic gradient descent (SGD). The gradient reveals the way that a function’s steepest rate of alteration is occurring. No matter how the gradient behaves, the key issue with basic SGD is that all parameters must adjust in equal-sized increments. Consequently, creating adaptable step sizes for every parameter is an effective method of deep model optimization. Gradient-based adaptive techniques utilize local changes in gradients or the square roots of exponential moving averages of squared previous gradients. However, current optimizers continue to struggle with effectively utilizing optimization curved knowledge. The novel emapDiffP optimizer suggested in this study utilizes the prior two parameters to generate a non-periodic and non-negative function, and the upgrade parameter makes use of a partly adaptive value to account for learning rate adjustability. Thus, the optimization steps become smoother with a more accurate step size for the immediate past parameter, a partial adapting value, and the largest two momentum values as the denominator of parameter updating. The rigorous tests on benchmark datasets show that the presented emapDiffP performs significantly better than its counterparts. In terms of classification accuracy, the emapDiffP algorithm gives the best classification accuracy on CIFAR10, MNIST, and Mini-ImageNet datasets for all examined networks and on the CIFAR100 dataset for most of the networks examined. It offers the best classification accuracy on the ImageNet dataset with the ResNet18 model. For image classification tasks on various datasets, the suggested emapDiffP technique offers outstanding training speed. With MNIST, CIFAR100, and ImageNet datasets, the suggested approach achieves the lowest training times; with CIFAR10, it takes the second-lowest training times. The proposed emapDiffP performs better than existing approaches in the majority of circumstances when used on the Set5 dataset for the image super-resolution challenge. Additionally, compared to previous approaches, the suggested method performs better on a variety of NLP tasks and object detection tasks.},
  archive      = {J_NCA},
  author       = {Bhakta, Shubhankar and Nandi, Utpal and Changdar, Chiranjit and Ghosal, Sudipta Kr and Pal, Rajat Kumar},
  doi          = {10.1007/s00521-024-09708-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11987-12010},
  shortjournal = {Neural Comput. Appl.},
  title        = {EmapDiffP: A novel learning algorithm for convolutional neural network optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-based stock picking using value investing
and quality features. <em>NCA</em>, <em>36</em>(20), 11963–11986. (<a
href="https://doi.org/10.1007/s00521-024-09700-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Value Investing stands as one of the most time-honored strategies for long-term equity investment in financial markets, specifically in the domain of stocks. The essence of this approach lies in the estimation of a company&#39;s &quot;intrinsic value,&quot; which serves as an investor&#39;s most refined gage of the company&#39;s true worth. Once the investor arrives at an estimation of the intrinsic value for a given company, she proceeds to contemplate purchasing the company&#39;s stocks solely if the prevailing market price of the stocks significantly deviates below the estimated intrinsic value, thus presenting an enticing buying opportunity. This deviation, referred to as the &quot;margin of safety,&quot; represents the disparity between the intrinsic value and the current market capitalization of the company. Within the scope of this endeavor, our objective is to automate the stock selection process for value investing across a vast spectrum of US companies. To accomplish this, we harness a combination of value-investing principles and quality features derived from historical financial reports and market capitalization data, thereby enabling the identification of favorable value-driven opportunities. Our methodology entails the utilization of an ensemble of classifiers, where the class is determined as a function of the margin of safety. Consequently, the model is trained to discern stocks that exhibit value characteristics warranting investment. Remarkably, our model attains a success rate surpassing 80%, effectively identifying stocks capable of yielding an annualized return of 15% within a three-year timeframe from the recommended stock purchase date provided by the model.},
  archive      = {J_NCA},
  author       = {Priel, Ronen and Rokach, Lior},
  doi          = {10.1007/s00521-024-09700-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11963-11986},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-based stock picking using value investing and quality features},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement imitation learning for reliable and efficient
autonomous navigation in complex environments. <em>NCA</em>,
<em>36</em>(20), 11945–11961. (<a
href="https://doi.org/10.1007/s00521-024-09678-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) and imitation learning (IL) are quite two useful machine learning techniques that were shown to be potential in enhancing navigation performance. Basically, both of these methods try to find a policy decision function in a reinforcement learning fashion or through imitation. In this paper, we propose a novel algorithm named Reinforcement Imitation Learning (RIL) that naturally combines RL and IL together in accelerating more reliable and efficient navigation in dynamic environments. RIL is a hybrid approach that utilizes RL for policy optimization and IL as some kind of learning from expert demonstrations with the inclusion of guidance. We present the comparison of the convergence of RIL with conventional RL and IL to provide the support for our algorithm’s performance in a dynamic environment with moving obstacles. The results of the testing indicate that the RIL algorithm has better collision avoidance and navigation efficiency than traditional methods. The proposed RIL algorithm has broad application prospects in many specific areas such as an autonomous driving, unmanned aerial vehicles, and robots.},
  archive      = {J_NCA},
  author       = {Kumar, Dharmendra},
  doi          = {10.1007/s00521-024-09678-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11945-11961},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement imitation learning for reliable and efficient autonomous navigation in complex environments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance evaluation and optimization of convolutional
neural network architectures for tomato plant disease eleven classes
based on augmented leaf images dataset. <em>NCA</em>, <em>36</em>(20),
11919–11943. (<a
href="https://doi.org/10.1007/s00521-024-09670-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient plant disease identification is prime important for Agricultural productivity. This paper proposes a method of automatic leaf extraction and classification with improved accuracy compared with existing techniques. Images acquired from natural fields are complex, with background information that needs to be accurately segmented to identify areas of interest. Grab cut is a semi-automatic approach to extract foreground objects, which might occasionally degrade an object’s properties. This paper suggests a better Grab cut for automatically extracting leaves from real-field images. The enhanced dataset of 23,617 images with eleven tomato leaf classes are created using the plant village dataset and actual field images. This paper addresses a wide range of issues related to convolutional neural network optimization, including how the number of layers affects the results of leaf disease detection and the creation of tiny models for portable devices. Five models, VGG 16, MobileNet, and custom architecture with input sizes of 98 $$\times$$ 98, 160 $$\times$$ 160, and 256 $$\times$$ 256, have been optimized and evaluated through several trials. Training and testing involve varying the input size, the number of layers, the optimizer, the dropout, the batch normalization, and the transfer learning. This paper presents and analyzes the findings of thirty experiments on various architecture. The proposed modified sequential eleven-layer architecture achieves accuracy compared with MobileNet and a reduced model size of 3.9 MB for input size 160 and 4.5 MB for input size 98.},
  archive      = {J_NCA},
  author       = {Karande, Shital and Garg, Bindu},
  doi          = {10.1007/s00521-024-09670-6},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11919-11943},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance evaluation and optimization of convolutional neural network architectures for tomato plant disease eleven classes based on augmented leaf images dataset},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring deep echo state networks for image classification:
A multi-reservoir approach. <em>NCA</em>, <em>36</em>(20), 11901–11918.
(<a href="https://doi.org/10.1007/s00521-024-09656-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo state networks (ESNs) belong to the class of recurrent neural networks and have demonstrated robust performance in time series prediction tasks. In this study, we investigate the capability of different ESN architectures to capture spatial relationships in images without transforming them into temporal sequences. We begin with three pre-existing ESN-based architectures and enhance their design by incorporating multiple output layers, customising them for a classification task. Our investigation involves an examination of the behaviour of these modified networks, coupled with a comprehensive performance comparison against the baseline vanilla ESN architecture. Our experiments on the MNIST data set reveal that a network with multiple independent reservoirs working in parallel outperforms other ESN-based architectures for this task, achieving a classification accuracy of 98.43%. This improvement on the classical ESN architecture is accompanied by reduced training times. While the accuracy of ESN-based architectures lags behind that of convolutional neural network-based architectures, the significantly lower training times of ESNs with multiple reservoirs operating in parallel make them a compelling choice for learning spatial relationships in scenarios prioritising energy efficiency and rapid training. This multi-reservoir ESN architecture overcomes standard ESN limitations regarding memory requirements and training times for large networks, providing more accurate predictions than other ESN-based models. These findings contribute to a deeper understanding of the potential of ESNs as a tool for image classification.},
  archive      = {J_NCA},
  author       = {López-Ortiz, E. J. and Perea-Trigo, M. and Soria-Morillo, L. M. and Sancho-Caparrini, F. and Vegas-Olmos, J. J.},
  doi          = {10.1007/s00521-024-09656-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11901-11918},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring deep echo state networks for image classification: A multi-reservoir approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective deep actor-critic reinforcement learning method
for solving the flexible job shop scheduling problem. <em>NCA</em>,
<em>36</em>(20), 11877–11899. (<a
href="https://doi.org/10.1007/s00521-024-09654-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop scheduling problem (FJSP) is a classic NP-hard problem, and the quality of its scheduling solution directly affects the operational efficiency of the manufacturing system. However, the traditional scheduling algorithms suffer from poor generalization when solving FJSP; there are problems such as long computational time and dimensional disasters, especially as the scale of FJSP increases. Therefore, an effective deep actor-critic reinforcement learning (DACRL) method is proposed for solving FJSP. Firstly, the FJSP is modeled as a multi-agent Markov decision process (MMDP), the state space, action space, and reward function in the MMDP are designed. Secondly, a DACRL model is constructed to solve FJSP. The actor network is responsible for choosing the most suitable scheduling rule in different states, while the critic network is responsible for outputting the value function of the actions and providing feedback to the actor network to better adjust the scheduling strategy. Finally, the proposed DACRL method is validated on benchmark FJSP instances of different scales. The experimental results show that the proposed method significantly outperforms the heuristic scheduling rules and double deep Q-network (DDQN) in terms of solution quality. Compared with the meta-heuristic algorithms and the self-learning genetic algorithm (SLGA), the proposed method has higher solution efficiency with the same solution quality.},
  archive      = {J_NCA},
  author       = {Wan, Lanjun and Cui, Xueyan and Zhao, Haoxin and Li, Changyun and Wang, Zhibing},
  doi          = {10.1007/s00521-024-09654-6},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11877-11899},
  shortjournal = {Neural Comput. Appl.},
  title        = {An effective deep actor-critic reinforcement learning method for solving the flexible job shop scheduling problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cultural heritage digital twin: Modeling and representing
the visual narrative in leonardo da vinci’s mona lisa. <em>NCA</em>,
<em>36</em>(20), 11859–11876. (<a
href="https://doi.org/10.1007/s00521-024-10010-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, Artificial Intelligence/Knowledge Representation methods are used for the digital modeling of cultural heritage elements. Accordingly, the new concept of digital cultural heritage twin is presented as composed of a physical component and an immaterial component of the cultural entity. The former concerns the physical aspects, i.e. style, name of the artist, execution time, dimension, etc. The latter represents the emotional and intangible aspects transmitted by the entity, i.e. emotions, thoughts, opinions. In order to digitally model the physical and immaterial components of the twin, the Narrative Knowledge Representation Language has been formally introduced and described. It is particularly suitable for representing the immaterial aspects of the cultural entity, as it is capable of modeling in a simple but rigorous and efficient way complex situations and events, behaviours, attitudes, etc. As an experiment, NKRL has been adopted for representing some of the most relevant intangible items of the visual narrative underlying the hidden painting that lies beneath the Mona Lisa (La Gioconda) image painted by Leonardo Da Vinci on the same poplar panel. Real-time application of the resulting knowledge base opens up novel possibilities for the development of virtual objects, chatbots and expert systems, as well as the definition of semantic search platforms related to cultural heritage.},
  archive      = {J_NCA},
  author       = {Amelio, Alessia and Zarri, Gian Piero},
  doi          = {10.1007/s00521-024-10010-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11859-11876},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cultural heritage digital twin: Modeling and representing the visual narrative in leonardo da vinci’s mona lisa},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Art authentication with vision transformers. <em>NCA</em>,
<em>36</em>(20), 11849–11858. (<a
href="https://doi.org/10.1007/s00521-023-08864-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, transformers, initially developed for language, have been successfully applied to visual tasks. Vision transformers have been shown to push the state of the art in a wide range of tasks, including image classification, object detection, and semantic segmentation. While ample research has shown promising results in art attribution and art authentication tasks using convolutional neural networks, this paper examines whether the superiority of vision transformers extends to art authentication, improving, thus, the reliability of computer-based authentication of artworks. Using a carefully compiled dataset of authentic paintings by Vincent van Gogh and two contrast datasets, we compare the art authentication performances of Swin transformers with those of EfficientNet. Using a standard contrast set containing imitations and proxies (works by painters with styles closely related to van Gogh), we find that EfficientNet achieves the best performance overall. With a contrast set that only consists of imitations, we find the Swin transformer to be superior to EfficientNet by achieving an authentication accuracy of over 85%. These results lead us to conclude that vision transformers represent a strong and promising contender in art authentication, particularly in enhancing the computer-based ability to detect artistic imitations.},
  archive      = {J_NCA},
  author       = {Schaerf, Ludovica and Postma, Eric and Popovici, Carina},
  doi          = {10.1007/s00521-023-08864-8},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11849-11858},
  shortjournal = {Neural Comput. Appl.},
  title        = {Art authentication with vision transformers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BIM-FM integrated solution resourcing to digital techniques.
<em>NCA</em>, <em>36</em>(20), 11833–11847. (<a
href="https://doi.org/10.1007/s00521-023-08907-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The facility management (FM) has been suffering significant changes since the introduction of building information modeling (BIM) in the Architecture, Engineering, Construction and Operation (AECO) sector. However, there are still challenges in BIM implementation during the building use phase, such as the difficulties related to the personalization of the maintenance management information for each case, and modeling the as-built conditions. Disclosing building data to all the stakeholders involved in the building life cycle is also a challenging task. So, this paper aims to present an integrated solution for BIM–FM to categorize and prioritize maintenance management, with the resource to digital techniques. For this purpose, the methodology developed consists of 1—the recognition and preparation of the site conditions; 2—Image collection using an Unmanned Aerial Vehicle (UAV); 3—Image processing and software comparison; 4—Obtaining point cloud and its integration in a BIM software; 5—3D building modeling in Revit software, 5—Damage detection through Photogrammetry Point Cloud, and 6—Placement of building anomalies by means of placeholders. This work allows exploring BIM–FM representation and data integration for building condition assessment and its representation in a collaborative tool. This methodology will enhance the usability of BIM methodology in FM since it allows the data update in the model, avoids the information loss or fragmentation of the building life cycle and gives access to BIM users and non-users.},
  archive      = {J_NCA},
  author       = {Matos, Raquel and Rodrigues, Hugo and Costa, Aníbal and Rodrigues, Fernanda},
  doi          = {10.1007/s00521-023-08907-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11833-11847},
  shortjournal = {Neural Comput. Appl.},
  title        = {BIM-FM integrated solution resourcing to digital techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving recognition of deteriorated historical persian
geometric patterns by fusion decision methods. <em>NCA</em>,
<em>36</em>(20), 11809–11831. (<a
href="https://doi.org/10.1007/s00521-024-09932-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Historical architecture has different special styles attributed to each era, dynasty, or region. These styles are common features such as geometric properties, ratios, scales, colors, and artistic techniques. Historical geometric ornaments have an enormous capability for classification based on their geometric characteristics. Smart pattern recognition allows researchers to classify huge databases of heritage for useful internet searches. So, our main goal in this paper is to implement the detection of categories in geometric patterns for classification and documentation in which by the photography of ornaments in every monument, the type of patterns and the number of every type of pattern would be estimated quickly. Furthermore, due to occurring deterioration in these patterns, our method also contributes to recognizing the deteriorated patterns. When we encounter numerous pieces of deteriorated patterns, manual recognition in order to reassemble and reconstruct is usually impossible or time-consuming. With the aid of artificial intelligence, in this paper, our aim is to seek to solve the automatic recognition of historical geometric patterns, even patterns having deterioration as an occlusion via image processing and machine learning methods. A challenging issue that researchers would tackle in detecting historical geometric pattern’s types is the variety in geometric textures, especially when they have occlusion such as deterioration. This issue leads to limited success in classifying via extracting only one feature. The other issue is that the extracted feature must be invariant to the transformation, such as scale, rotation, and noise variation. To cope with the challenges mentioned above and accurately classify, we plan to use the fusion method based on extracting global and local features. So, the features extracted from images in this research are based on local and global. In other words, the proposed fusion strategy lies both in feature and decision level, but the core is the proposed three combination methods in fusion decision methods. In this method, the dataset is composed of four main Persian geometric pattern types: Tond dah, Kond tablghenas, Hashtva 4 lengeh, and HashtvatablKond. So, the model will be trained by extracting global and local features of the images separately. Random forest, as the prevalent machine learning algorithm, is proposed for training data and predicting the class of input images. Finally, the probability of prediction for random forest classifiers is fused by the Decision Templates (DT) combiner, Naïve Bayes (NB) combiner, and Dempster–Shafer combination methods. In comparison with the individual classifier accuracy results of 80% and 85% for global and local features respectively, our proposed approach achieves an improved accuracy of 90%, 88%, and 90% in three fusion decision methods including DT combiner, NB combiner, and Dempster–Shafer combination methods.},
  archive      = {J_NCA},
  author       = {Hajebi, Bita and Hajebi, Pooya},
  doi          = {10.1007/s00521-024-09932-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11809-11831},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving recognition of deteriorated historical persian geometric patterns by fusion decision methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-self-supervised learning model to recognize
handwritten characters in ancient documents in indian scripts.
<em>NCA</em>, <em>36</em>(20), 11791–11808. (<a
href="https://doi.org/10.1007/s00521-023-09372-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An optical character recognition (OCR) system segments the character from the given document before recognizing it. The recognition of such character images requires the class labels to be associated with each character sample in the training set, and this requires the placing of all the samples of each segmented character in various distinct folders. However, it has to be done manually, and thus, it is a time-consuming process. The ancient documents suffer from humidity spots, ink stains, and faded portions of text which makes the character recognition task even more challenging for the ancient documents. The present article proposes a novel semi-self-supervised learning-based OCR method to recognize each character segmented from the ancient documents handwritten in Devanagari and Maithili scripts. The proposed method has two modules—feature extraction module and recognition module. The feature extraction module has extracted deep hierarchical features from each pre-segmented character image employing generative self-supervised learning approach. The recognition module has focused on important features using an attention mechanism and learns the long temporal sequence using the Gated Recurrent Unit variant of recurrent neural network classifier to classify each segmented character into its proper class. The feature extraction module in the proposed method has been trained using the 60% (unlabelled) of the dataset, whereas the recognition module has been trained using the 5% (manually labelled) of the dataset. The performance of the proposed novel OCR method has been evaluated on two self-generated datasets of ancient handwritten documents in Devanagari and Maithili scripts. The experimental results demonstrate that the proposed OCR method outperforms the state-of-the-art (SOTA) methods in this regard. The proposed OCR method has improved the character recognition accuracy in comparison with the SOTA methods by 2.27% and 3.48% in Devanagari and Maithili scripts, respectively.},
  archive      = {J_NCA},
  author       = {Jindal, Amar and Ghosh, Rajib},
  doi          = {10.1007/s00521-023-09372-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11791-11808},
  shortjournal = {Neural Comput. Appl.},
  title        = {A semi-self-supervised learning model to recognize handwritten characters in ancient documents in indian scripts},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). U-DIADS-bib: A full and few-shot pixel-precise dataset for
document layout analysis of ancient manuscripts. <em>NCA</em>,
<em>36</em>(20), 11777–11789. (<a
href="https://doi.org/10.1007/s00521-023-09356-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document Layout Analysis, which is the task of identifying different semantic regions inside of a document page, is a subject of great interest for both computer scientists and humanities scholars as it represents a fundamental step towards further analysis tasks for the former and a powerful tool to improve and facilitate the study of the documents for the latter. However, many of the works currently present in the literature, especially when it comes to the available datasets, fail to meet the needs of both worlds and, in particular, tend to lean towards the needs and common practices of the computer science side, leading to resources that are not representative of the humanities real needs. For this reason, the present paper introduces U-DIADS-Bib, a novel, pixel-precise, non-overlapping and noiseless document layout analysis dataset developed in close collaboration between specialists in the fields of computer vision and humanities. Furthermore, we propose a novel, computer-aided, segmentation pipeline in order to alleviate the burden represented by the time-consuming process of manual annotation, necessary for the generation of the ground truth segmentation maps. Finally, we present a standardized few-shot version of the dataset (U-DIADS-BibFS), with the aim of encouraging the development of models and solutions able to address this task with as few samples as possible, which would allow for more effective use in a real-world scenario, where collecting a large number of segmentations is not always feasible.},
  archive      = {J_NCA},
  author       = {Zottin, Silvia and De Nardin, Axel and Colombi, Emanuela and Piciarelli, Claudio and Pavan, Filippo and Foresti, Gian Luca},
  doi          = {10.1007/s00521-023-09356-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11777-11789},
  shortjournal = {Neural Comput. Appl.},
  title        = {U-DIADS-bib: A full and few-shot pixel-precise dataset for document layout analysis of ancient manuscripts},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning approach to classify country and value of
modern coins. <em>NCA</em>, <em>36</em>(20), 11759–11775. (<a
href="https://doi.org/10.1007/s00521-023-09355-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Artificial Intelligence (AI) to preserve and promote cultural heritage has experienced significant growth in recent years. Among the various areas of cultural heritage, numismatics have emerged as a particularly promising field where we can develop AI solutions. Numismatics refers to the study of coins, tokens, paper money, and medals, which play a critical role in understanding human history and culture. However, there are still limited resources available to help researchers and collectors in the identification of coins. This is due to the vast number of coins in circulation, which presents a significant challenge in developing smart tools for classification tasks. This paper aims to provide a contribution to this setting. In particular, we start by creating a new dataset called EURO-Coin, which consists of images showing the side of coins with reliefs and is designed to facilitate the training and testing of AI models for euro coin classification. Then, we propose two approaches that leverage Convolutional Neural Networks and self-attention layers to classify the country and value of the coins. In our experiments, we obtain an accuracy of 86.9% for country classification and an accuracy of 96.4% for value classification. Finally, we conduct an ablation study to evaluate the impact of the preprocessing activities and attention layers in our approaches.},
  archive      = {J_NCA},
  author       = {Cirillo, Stefano and Solimando, Giandomenico and Virgili, Luca},
  doi          = {10.1007/s00521-023-09355-6},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11759-11775},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning approach to classify country and value of modern coins},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Training a shallow NN to erase ink seepage in historical
manuscripts based on a degradation model. <em>NCA</em>, <em>36</em>(20),
11743–11757. (<a
href="https://doi.org/10.1007/s00521-023-09354-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In historical recto–verso manuscripts, very often the text written on the opposite page of the folio penetrates through the fiber of the paper, so that the texts on the two sides appear mixed. This is a very impairing damage that cannot be physically removed, and hinders both the work of philologists and palaeographers and the automatic analysis of linguistic contents. A procedure based on neural networks (NN) is proposed here to clean up the complex background of the manuscripts from this interference. We adopt a very simple shallow NN whose learning phase employs a training set generated from the data itself using a theoretical blending model that takes into account ink diffusion and saturation. By virtue of the parametric nature of the model, various levels of damage can be simulated in the training set, favoring a generalization capability of the NN. More explicitly, the network can be trained without the need for a large class of other similar manuscripts, but is still able, at least to some extent, to classify manuscripts with varying degrees of corruption. We compare the performance of this NN and other methods both qualitatively and quantitatively on a reference dataset and heavily damaged historical manuscripts.},
  archive      = {J_NCA},
  author       = {Savino, Pasquale and Tonazzini, Anna},
  doi          = {10.1007/s00521-023-09354-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11743-11757},
  shortjournal = {Neural Comput. Appl.},
  title        = {Training a shallow NN to erase ink seepage in historical manuscripts based on a degradation model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing cultural relationships visual cues through deep
learning models in a cross-dataset setting. <em>NCA</em>,
<em>36</em>(20), 11727–11742. (<a
href="https://doi.org/10.1007/s00521-023-08966-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To study the evolution of specific cultures and times different kinds of pictures could be adopted. Family album photos may reveal socio-historical insights regarding those specific cultures and times. Along this path, this work addresses the problem of automatically dating an image by resorting to the analysis of an analog family album photo dataset. In particular, the IMAGO collection, which contains Italian photos shot in the 20th century, was considered. Thanks to the IMAGO dataset, it was possible to apply different deep learning-based architectures to date images belonging to photo albums without needing any other sources of information. In addition, we carried out cross-dataset experiments, which also involved models trained on American datasets, observing temporal shifts which may be due to known intercultural influences. We further explore such a possibility by qualitatively analyzing the cross-dataset interpretation of the trained deep-learning models with the Uniform Manifold Approximation and Projection (UMAP) algorithm. In conclusion, deep learning models revealed their potential in terms of possible applications to intercultural research, from different points of view.},
  archive      = {J_NCA},
  author       = {Stacchio, Lorenzo and Angeli, Alessia and Lisanti, Giuseppe and Marfia, Gustavo},
  doi          = {10.1007/s00521-023-08966-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11727-11742},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analyzing cultural relationships visual cues through deep learning models in a cross-dataset setting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). JointMETRO: A 3D reconstruction model for human figures in
works of art based on transformer. <em>NCA</em>, <em>36</em>(20),
11711–11725. (<a
href="https://doi.org/10.1007/s00521-023-08844-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sculptures and paintings are an important part of our cultural heritage, and 3D reconstruction of the human in them can help us better preserve and inherit this heritage. By creating 3D models of sculptures and paintings, these artworks become more accessible to a wider audience. This allows more people to appreciate and learn about different cultures and their heritage. 3D human reconstruction based on Transformer structures has recently achieved state-of-the-art results, but this approach requires a large number of parameters and expensive computations. The neglected computational complexity and the size of the model make it difficult to use such models for practical applications. In this paper, we propose a lightweight method based on human body joints and Transformer, called JointMETRO (Joint MEsh TRansfOrmer). It reconstructs the human body mesh from 2D human joints and has better capability to reconstruct characters in artistic works. We propose a joint extraction module, which obtains the locations of the 13 human joint points and the confidence coefficient of each joint, and a mesh regression module, which is used to combine the extracted pose features with a mesh template to obtain the final reconstructed human mesh structure. Finally, the accuracy of the reconstructed human model can be seen visually by applying different colors to the mesh vertices based on the confidence coefficient of each joint. We have demonstrated the efficiency of the model through extensive evaluation on both the Human3.6M and 3DPW datasets. On the complex in-the-wild 3DPW dataset, JointMETRO achieved better accuracy than the pose-based SOTA method.},
  archive      = {J_NCA},
  author       = {Pang, Shanchen and Peng, Rongrong and Dong, Yukun and Yuan, Qi and Wang, Shengtao and Sun, Junqi},
  doi          = {10.1007/s00521-023-08844-y},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11711-11725},
  shortjournal = {Neural Comput. Appl.},
  title        = {JointMETRO: A 3D reconstruction model for human figures in works of art based on transformer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparison of methods for image classification of cultural
heritage using transfer learning for feature extraction. <em>NCA</em>,
<em>36</em>(20), 11699–11709. (<a
href="https://doi.org/10.1007/s00521-023-08764-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image recognition and classification in the domain of cultural heritage is a complex task that usually requires good image quality and a large dataset. Small dataset is an apparent problem when data availability is limited, often resulting in poor classification performance. The aim of this study is to analyze and compare the performance of four machine learning algorithms, namely random forest, multilayer perceptron classifier, Naïve Bayes, and decision tree, that are used to classify features extracted using eleven pre-trained deep learning architectures from a small set of images representing cultural heritage. The findings imply that random forest and multilayer perceptron classifiers are the most appropriate for the task of image classification of small cultural heritage datasets, as they obtained the highest performance compared to the other two algorithms, particularly when DenseNet121, EfficientNetB0 and NASNetMobile architectures are used for feature extraction. In addition, for the classification of features extracted using NASNetMobile all the four utilized machine learning algorithms obtained high accuracy ranging from 88.89 to 95.56%.},
  archive      = {J_NCA},
  author       = {Janković Babić, Radmila},
  doi          = {10.1007/s00521-023-08764-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {20},
  pages        = {11699-11709},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparison of methods for image classification of cultural heritage using transfer learning for feature extraction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A novel approach for automated detection of
focal EEG signals using empirical wavelet transform. <em>NCA</em>,
<em>36</em>(19), 11697. (<a
href="https://doi.org/10.1007/s00521-024-10034-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Bhattacharyya, Abhijit and Sharma, Manish and Pachori, Ram Bilas and Sircar, Pradip and Acharya, U. Rajendra},
  doi          = {10.1007/s00521-024-10034-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11697},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel approach for automated detection of focal EEG signals using empirical wavelet transform},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Effect of legendre–fenchel denoising and
SVD-based dimensionality reduction algorithm on hyperspectral image
classification. <em>NCA</em>, <em>36</em>(19), 11695. (<a
href="https://doi.org/10.1007/s00521-024-10033-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Reshma, R. and Sowmya, V. and Soman, K. P.},
  doi          = {10.1007/s00521-024-10033-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11695},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Effect of Legendre–Fenchel denoising and SVD-based dimensionality reduction algorithm on hyperspectral image classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Fast and robust absolute camera pose
estimation with known focal length. <em>NCA</em>, <em>36</em>(19),
11693. (<a href="https://doi.org/10.1007/s00521-024-10032-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Cao, Ming Wei and Jia, Wei and Zhao, Yang and Li, Shu Jie and Liu, Xiao Ping},
  doi          = {10.1007/s00521-024-10032-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11693},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Fast and robust absolute camera pose estimation with known focal length},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Applications of artificial intelligence and
hybrid neural network methods with new bonding method to prevent
electroshock risk and insulation faults in high-voltage underground
cable lines. <em>NCA</em>, <em>36</em>(19), 11691. (<a
href="https://doi.org/10.1007/s00521-024-10031-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Akbal, Bahadır},
  doi          = {10.1007/s00521-024-10031-6},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11691},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Applications of artificial intelligence and hybrid neural network methods with new bonding method to prevent electroshock risk and insulation faults in high-voltage underground cable lines},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Hybrid rough-bijective soft set
classification system. <em>NCA</em>, <em>36</em>(19), 11689. (<a
href="https://doi.org/10.1007/s00521-024-10030-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Inbarani, H. Hannah and Kumar, S. Udhaya and Azar, Ahmad Taher and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-024-10030-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11689},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Hybrid rough-bijective soft set classification system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Salient object detection using a
covariance-based CNN model in low-contrast images. <em>NCA</em>,
<em>36</em>(19), 11687. (<a
href="https://doi.org/10.1007/s00521-024-10029-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Mu, Nan and Xu, Xin and Zhang, Xiaolong and Zhang, Hong},
  doi          = {10.1007/s00521-024-10029-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11687},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Salient object detection using a covariance-based CNN model in low-contrast images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: An overview, examples, and impacts offered
by emerging services and analytics in cloud computing virtual reality.
<em>NCA</em>, <em>36</em>(19), 11685. (<a
href="https://doi.org/10.1007/s00521-024-10028-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Chang, Victor},
  doi          = {10.1007/s00521-024-10028-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11685},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An overview, examples, and impacts offered by emerging services and analytics in cloud computing virtual reality},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A novel image segmentation approach based
on neutrosophic c-means clustering and indeterminacy filtering.
<em>NCA</em>, <em>36</em>(19), 11683. (<a
href="https://doi.org/10.1007/s00521-024-10027-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Guo, Yanhui and Xia, Rong and Şengür, Abdulkadir and Polat, Kemal},
  doi          = {10.1007/s00521-024-10027-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11683},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel image segmentation approach based on neutrosophic c-means clustering and indeterminacy filtering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Noise-estimation-based anisotropic
diffusion approach for retinal blood vessel segmentation. <em>NCA</em>,
<em>36</em>(19), 11681. (<a
href="https://doi.org/10.1007/s00521-024-10026-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ben Abdallah, Mariem and Azar, Ahmad Taher and Guedri, Hichem and Malek, Jihene and Belmabrouk, Hafedh},
  doi          = {10.1007/s00521-024-10026-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11681},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Noise-estimation-based anisotropic diffusion approach for retinal blood vessel segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Classification of nucleotide sequences for
quality assessment using logistic regression and decision tree
approaches. <em>NCA</em>, <em>36</em>(19), 11679. (<a
href="https://doi.org/10.1007/s00521-024-10025-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kurt, Serkan and Öz, Ersoy and Aşkm, Öyküm Esra and Öz, Yeliz Yücel},
  doi          = {10.1007/s00521-024-10025-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11679},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Classification of nucleotide sequences for quality assessment using logistic regression and decision tree approaches},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Application of empirical mode decomposition
(EMD) for automated identification of congestive heart failure using
heart rate signals. <em>NCA</em>, <em>36</em>(19), 11677. (<a
href="https://doi.org/10.1007/s00521-024-10024-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Acharya, U. Rajendra and Fujita, Hamido and Sudarshan, Vidya K. and Oh, Shu Lih and Muhammad, Adam and Koh, Joel E. W. and Tan, Jen Hong and Chua, Chua K. and Chua, Kok Poo and Tan, Ru San},
  doi          = {10.1007/s00521-024-10024-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11677},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Application of empirical mode decomposition (EMD) for automated identification of congestive heart failure using heart rate signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Editorial: Neural computing in
next-generation virtual reality technology. <em>NCA</em>,
<em>36</em>(19), 11675. (<a
href="https://doi.org/10.1007/s00521-024-10023-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Lv, Zhihan and Wang, Jim Jingyan and Luo, Xiaonan},
  doi          = {10.1007/s00521-024-10023-6},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11675},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: editorial: neural computing in next-generation virtual reality technology},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A novel hybrid approach based on principal
component analysis and tolerance rough similarity for face
identification. <em>NCA</em>, <em>36</em>(19), 11673. (<a
href="https://doi.org/10.1007/s00521-024-10022-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Lavanya, B. and Inbarani, H. Hannah},
  doi          = {10.1007/s00521-024-10022-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11673},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel hybrid approach based on principal component analysis and tolerance rough similarity for face identification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Covering-based rough set classification
system. <em>NCA</em>, <em>36</em>(19), 11671. (<a
href="https://doi.org/10.1007/s00521-024-10021-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kumar, S. Senthil and Inbarani, H. Hannah and Azar, Ahmad Taher and Polat, Kemal},
  doi          = {10.1007/s00521-024-10021-8},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11671},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Covering-based rough set classification system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Fuzzy logic-based segmentation of
manufacturing defects on reflective surfaces. <em>NCA</em>,
<em>36</em>(19), 11669. (<a
href="https://doi.org/10.1007/s00521-024-10020-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Öztürk, Şaban and Akdemir, Bayram},
  doi          = {10.1007/s00521-024-10020-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11669},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Fuzzy logic-based segmentation of manufacturing defects on reflective surfaces},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Application of fuzzy c-means clustering
algorithm to spectral features for emotion classification from speech.
<em>NCA</em>, <em>36</em>(19), 11667. (<a
href="https://doi.org/10.1007/s00521-024-10019-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Demircan, Semiye and Kahramanli, Humar},
  doi          = {10.1007/s00521-024-10019-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11667},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Application of fuzzy C-means clustering algorithm to spectral features for emotion classification from speech},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Muscular synergy classification and
myoelectric control using high-order cross-cumulants. <em>NCA</em>,
<em>36</em>(19), 11665. (<a
href="https://doi.org/10.1007/s00521-024-10018-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Orosco, Eugenio C. and di Sciascio, Fernando},
  doi          = {10.1007/s00521-024-10018-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11665},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Muscular synergy classification and myoelectric control using high-order cross-cumulants},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: HierMDS: A hierarchical multi-document
summarization model with global–local document dependencies.
<em>NCA</em>, <em>36</em>(19), 11663. (<a
href="https://doi.org/10.1007/s00521-024-09842-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Li, Shuaimin and Xu, Jungang},
  doi          = {10.1007/s00521-024-09842-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11663},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: HierMDS: a hierarchical multi-document summarization model with global–local document dependencies},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: Comparative study of ML models for IIoT
intrusion detection: Impact of data preprocessing and balancing.
<em>NCA</em>, <em>36</em>(19), 11661. (<a
href="https://doi.org/10.1007/s00521-024-09841-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Eid, Abdulrahman Mahmoud and Soudan, Bassel and Nassif, Ali Bou and Injadat, MohammadNoor},
  doi          = {10.1007/s00521-024-09841-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11661},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: comparative study of ML models for IIoT intrusion detection: impact of data preprocessing and balancing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction: A deep learning approach to text-based
personality prediction using multiple data sources mapping.
<em>NCA</em>, <em>36</em>(19), 11659. (<a
href="https://doi.org/10.1007/s00521-024-09651-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sirasapalli, Joshua Johnson and Malla, Ramakrishna Murty},
  doi          = {10.1007/s00521-024-09651-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: A deep learning approach to text-based personality prediction using multiple data sources mapping},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-organizing maps applied to the analysis and
identification of characteristics related to air quality monitoring
stations and its pollutants. <em>NCA</em>, <em>36</em>(19), 11643–11657.
(<a href="https://doi.org/10.1007/s00521-024-09793-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to address the growing problem of air pollution, it is necessary to implement innovative regulations and practical solutions to reduce and control its impact. Numerous studies have recommended using multivariate statistical methods to identify the connections and characteristics of atmospheric pollutants, which can provide valuable information about their generation, dispersion, and contribution to the deterioration of air quality. This study thoroughly examines the air quality in Salvador, Bahia, using the Self-Organizing Maps (SOM) technique. The data used in the analysis spans from 2011 to 2016 and comes from air quality monitoring stations. The dataset includes hourly measurements of pollutants such as SO2, CO, O3, particulate matter, and meteorological data (wind speed, ambient temperature, relative humidity, the standard deviation of wind direction, rainfall, and wind direction). The SOM analysis successfully identifies significant clusters, revealing associations between high concentrations of specific pollutants and environmental variables. For example, clusters with elevated SO2 concentrations are observed in areas that suggest the presence of local sources of pollution. The validation of the results using Principal Component Analysis strengthens the findings. These findings are essential for developing air quality management policies, as they highlight areas of concern and offer insights for mitigation strategies. This study demonstrates the effectiveness of the SOM technique in environmental analysis and emphasizes the importance of domain knowledge in comprehensively interpreting air pollution patterns.},
  archive      = {J_NCA},
  author       = {Costa, Emanoel L. R. and Braga, Taiane and Dias, Leonardo A. and de Albuquerque, Édler L. and Fernandes, Marcelo A. C.},
  doi          = {10.1007/s00521-024-09793-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11643-11657},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-organizing maps applied to the analysis and identification of characteristics related to air quality monitoring stations and its pollutants},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sub-region aware retrieval-based network with multimodal
prior knowledge guidance for microvascular invasion prediction in PET/CT
imaging. <em>NCA</em>, <em>36</em>(19), 11623–11641. (<a
href="https://doi.org/10.1007/s00521-024-09777-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate preoperative microvascular invasion (MVI) prediction using PET/CT imaging is important for guiding surgical plans and treatment strategies for hepatocellular carcinoma (HCC) patients. Deep learning (DL)-based approaches have shown effectiveness in medical imaging-based diagnostics. However, most DL-based methods for automatic MVI diagnosis depend on detailed annotations of HCC regions by clinicians, then perform feature extraction and directly output MVI risk scores, which can increase application complexity and lack transparency in decision-making. Therefore, we propose the sub-region aware retrieval-based network (SRANet), utilizing the prior knowledge of modality complementarity and localization of HCC in PET/CT images for tumor area location and feature extraction. Specifically, in the feature extraction stage, to better highlight lesion areas, we designed the prior knowledge guided fusion (PKGF) block. PKGF integrates knowledge from PET and CT through attention mechanism-based intermodal interaction and implicitly weights features to calibrate different modalities. Furthermore, we developed a sub-region aware module (SRAM) that employs class activation schemes and peak selection to identify and highlight sparse, salient sub-regions in tumor areas, relying solely on coarse-grained supervision. Additionally, we design a new loopback Siamese training strategy, guiding the model to focus on lesion areas through the semantic invariance of lesion features. Finally, we employ a retrieval strategy to present similar slices, providing clinicians with transparent references and enhancing the understandability of MVI predictions beyond simple risk scores. Experimental results show SRANet outperforms leading methods, achieving a slice-level AUC of 0.855 and an individual-level AUC of 0.796, highlighting its potential for clinical application.},
  archive      = {J_NCA},
  author       = {Wu, Nan and Wang, Yutao and Zhang, Jian and Yu, Zhongfei and Jin, Wei},
  doi          = {10.1007/s00521-024-09777-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11623-11641},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sub-region aware retrieval-based network with multimodal prior knowledge guidance for microvascular invasion prediction in PET/CT imaging},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preference detection of the humanoid robot face based on EEG
and eye movement. <em>NCA</em>, <em>36</em>(19), 11603–11621. (<a
href="https://doi.org/10.1007/s00521-024-09765-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The face of a humanoid robot can affect the user experience, and the detection of face preference is particularly important. Preference detection belongs to a branch of emotion recognition that has received much attention from researchers. Most of the previous preference detection studies have been conducted based on a single modality. In this paper, we detect face preferences of humanoid robots based on electroencephalogram (EEG) signals and eye movement signals for single modality, canonical correlation analysis fusion modality, and bimodal deep autoencoder (BDAE) fusion modality, respectively. We validated the theory of frontal asymmetry by analyzing the preference patterns of EEG and found that participants had higher alpha wave energy for preference faces. In addition, hidden preferences extracted by EEG signals were better classified than preferences from participants&#39; subjective feedback, and also, the classification performance of eye movement data was improved. Finally, experimental results showed that BDAE multimodal fusion using frontal alpha and beta power spectral densities and eye movement information as features performed best, with the highest average accuracy of 83.13% for the SVM and 71.09% for the KNN.},
  archive      = {J_NCA},
  author       = {Wang, Pengchao and Mu, Wei and Zhan, Gege and Wang, Aiping and Song, Zuoting and Fang, Tao and Zhang, Xueze and Wang, Junkongshuai and Niu, Lan and Bin, Jianxiong and Zhang, Lihua and Jia, Jie and Kang, Xiaoyang},
  doi          = {10.1007/s00521-024-09765-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11603-11621},
  shortjournal = {Neural Comput. Appl.},
  title        = {Preference detection of the humanoid robot face based on EEG and eye movement},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). End-to-end dynamic residual focal transformer network for
multimodal medical image fusion. <em>NCA</em>, <em>36</em>(19),
11579–11601. (<a
href="https://doi.org/10.1007/s00521-024-09729-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal medical image fusion aims to improve the clinical practicability of medical images by integrating complementary information from multiple medical images. However, in traditional fusion methods, the fusion rules based on prior knowledge or logic usually cannot match the feature representation perfectly, which results in partial information loss. Furthermore, most deep learning-based fusion methods depend on convolutional operations, which only focus on local features and have limited retention of context information. To address the above issues, we propose an end-to-end dynamic residual focal transformer network for multimodal medical image fusion, termed DRFT. The DRFT framework is an end-to-end network with no need to manually design fusion rules. Firstly, the context-gated convolution is introduced to construct the context dynamic extraction module (CDEM) to extract the key semantic information more accurately from multimodal medical images. Then, a new residual transformer fusion module (RTFM) is designed by incorporating the focal transformer into the residual mechanism, which can not only extract the deep semantic features, but also adaptively learn the optimal fusion scheme. Finally, the nest architecture is employed to extract multiscale features. In addition, a new objective function consisting of global detail loss and fusion enhancement loss is designed to enrich the modal information in the fused image. Notably, the proposed network does not require the two-stage training strategy as opposed to the traditional encoder–decoder fusion structure. Extensive experimental results on mainstream datasets show that, compared with the state-of-the-art methods, the proposed DRFT delivers better performance in both qualitative and quantitative evaluation.},
  archive      = {J_NCA},
  author       = {Zhang, Weihao and Yu, Lei and Wang, Huiqi and Pedrycz, Witold},
  doi          = {10.1007/s00521-024-09729-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11579-11601},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end dynamic residual focal transformer network for multimodal medical image fusion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced pyramidal residual networks for single image
super-resolution. <em>NCA</em>, <em>36</em>(19), 11563–11577. (<a
href="https://doi.org/10.1007/s00521-024-09702-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several super-resolution (SR) techniques are introduced in the literature, including traditional and machine learning-based algorithms. Especially, deep learning-based SR approaches emerge with demands for better quality images providing deeper subpixel enhancement. Dealing with the image enhancement task in the satellite images domain, a new SR method for single image SR, namely Enhanced Deep Pyramidal Residual Networks, is introduced in this study. The proposed method overcomes the potential instability problem of Enhanced Deep Residual Networks for Single Image Super-Resolution (EDSR) approach by gradually increasing the feature maps depending upon Pyramidal Residual Networks architecture. The EDSR itself is a good algorithm in the SR domain. However, it has a strict structure for increasing the block size. To overcome this problem with the aim of increasing the algorithm’s performance, the pyramidal residual networks gradually increasing hypothesis is utilized in the proposed approach, which is the main contribution and novelty of this study. Besides, by using the pyramidal residual networks gradually increasing hypothesis in the proposed approach, the parameter size of the models is also reduced, which affects the computational time. Two different models are proposed by considering addition and multiplication manners, and the proposed models are evaluated using well-known remote sensing datasets NWPU-RESISC45 and UC Merced. The results obtained by the proposed model are compared with the results of traditional image enhancement algorithms together with the EDSR itself, EDSR with deeper structure, Super-Resolution Generative Adversarial Networks approach, and Residual Local Feature Networks approach in terms of peak signal to noise ratio (PSNR) and structural similarity index measure (SSIM) metrics and showed that the proposed models present better quality images. Moreover, considering the computational time and complexity, it is shown that some proposed models achieve approximately 27% less output parameter having similar PSNR and SSIM values and computational time for EDSR itself and 65% less output parameter having better PSNR and SSIM values and 16% lower computational time for EDSR with deeper structure.},
  archive      = {J_NCA},
  author       = {Babaoğlu, İsmail and Kahveci, Semih and Kılıç, Alper},
  doi          = {10.1007/s00521-024-09702-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11563-11577},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced pyramidal residual networks for single image super-resolution},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical fuzzy regression functions for mixed predictors
and an application to real estate price prediction. <em>NCA</em>,
<em>36</em>(19), 11545–11561. (<a
href="https://doi.org/10.1007/s00521-024-09673-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorical features appear in datasets from almost every practice area, including real estate datasets. One of the most critical handicaps of machine learning algorithms is that they are not designed to capture the qualitative nature of the categorical features, leading to sub-optimal predictions for the datasets with categorical observations. This study focuses on a new fuzzy regression functions framework, namely hierarchical fuzzy regression functions, that can handle categorical features properly for the regression task. The proposed framework is benchmarked with linear regression, support vector machines, deep neural networks, and adaptive neuro-fuzzy inference systems with real estate data having categorical features from six markets. It is observed that the proposed method produces better prediction performance for real estate price prediction than the benchmark methods in a wide variety of real estate markets. Since we provide all the required software codes to implement the proposed hierarchical fuzzy regression functions framework, our approach offers practitioners a readily applicable, high-performing tool for real estate price prediction and other regression problems involving categorical independent features.},
  archive      = {J_NCA},
  author       = {Demirhan, Haydar and Baser, Furkan},
  doi          = {10.1007/s00521-024-09673-3},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11545-11561},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical fuzzy regression functions for mixed predictors and an application to real estate price prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsteady flow of hybrid nanofluid over a permeable shrinking
inclined rotating disk with radiation and velocity slip effects.
<em>NCA</em>, <em>36</em>(19), 11525–11544. (<a
href="https://doi.org/10.1007/s00521-024-09792-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A nanofluid refers to a suspension of nanoparticles in a conventional fluid, which finds unique applications in diverse sectors, including engineering, technology, and medicine. When multiple nanoparticles are suspended, it creates a hybrid nanofluid. In this study, we aim to investigate an unsteady flow of hybrid nanofluid over a permeable shrinking inclined rotating disk subjected to heat radiation, magnetohydrodynamics and slip effects. The chosen nanoparticles for this study are alumina (Al2O3) and copper (Cu), incorporated into a base fluid of water (H2O) to create the hybrid nanofluid. An appropriate method of similarity transformation is executed along a set of partial differential equations that were reduced to a system of nonlinear ordinary differential equations, where numerical outcomes were then obtained via bvp4c in MATLAB software, with the influence of various parameters such as unsteadiness parameter, nanoparticle volume fraction, shrinking, radiation, magnetic and velocity slip parameters, shown in tables and figures. Multiple solutions (including dual, upper, and lower branch solutions) are identified for the governing similarity equations. Through the conducted stability analysis, it is determined that the upper branch solutions exhibit stability and physically realizable in practice, while the lower branch solutions are unstable. Our numerical findings showed that dual solutions exist when $$\varepsilon_{c} \le \varepsilon \le - 1$$ , where $$\varepsilon_{c} &lt; 0$$ is the critical value of $$\varepsilon$$ for which the boundary value problem poses physical solutions applicable in practice. Yet, the boundary value problem lacks a similarity solution for $$\varepsilon \le \varepsilon_{c} \le 0$$ , and the complete set of partial differential equations needs to be solved numerically. Improvements in heat transfer rate are observed concerning the radiation parameter, nanoparticle fraction, and shrinking parameter. Furthermore, azimuthal velocity profiles show an increase influenced by velocity slip and magnetic parameters. The non-dimensional physical parameters, including stretching/shrinking, suction, slip, and unsteadiness, are also considered and their effects are presented in figures and tables.},
  archive      = {J_NCA},
  author       = {Abu Bakar, Shahirah and Pop, Ioan and Md Arifin, Norihan},
  doi          = {10.1007/s00521-024-09792-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11525-11544},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsteady flow of hybrid nanofluid over a permeable shrinking inclined rotating disk with radiation and velocity slip effects},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepDepth: Prediction of o(6)-methylguanine-DNA
methyltransferase genotype in glioblastoma patients using multimodal
representation learning based on deep feature fusion. <em>NCA</em>,
<em>36</em>(19), 11507–11523. (<a
href="https://doi.org/10.1007/s00521-024-09757-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning aims to extract meaningful features from medical images that are often multimodal, i.e., captured using multiple imaging modalities, to provide a more comprehensive understanding of the underlying anatomy and pathology. The primary objective is to improve the quality of features that can help in accurate diagnosis, disease detection, and treatment planning. With more than one modality, the extracted features must be integrated efficiently to capture the complex relationships between them. Integrating features in medical imaging-based classification problems, such as those involving magnetic resonance imaging-based diagnosis, remains a significant challenge. Current approaches to multimodal medical imaging classification often focus on features from a single modality or concatenate them into a high-dimensional feature vector, resulting in overfitting. Intermediate methods like deep fusion that combine features at a mid-level or deeper level have shown promise in offering a better representation. Depthwise convolution is a promising alternative in the deep learning paradigm that has demonstrated strong performance while requiring less computation. This paper presents a novel method in deep fusion based on depthwise 1D convolution. The proposed architecture is compared with other methods based on different fusion techniques and machine learning classifiers. The effectiveness of this method is demonstrated through experiments involving the brain tumor segmentation (BraTs-21) competition, Task-2, which involves predicting O(6)-methylguanine-DNA methyltransferase promoter status, a biomarker for glioblastoma, as a binary classification problem using multimodal magnetic resonance images. The proposed approach involves calculating radiomic features directly from magnetic resonance images and deep features from pre-trained deep learning models, selecting valuable features from both sets and then deep feature fusion using depthwise 1D convolution followed by fully connected layers for classification. In this approach, the deep fusion and classifier part is trainable. To make the proposed framework generalizable, we have trained and tested the model with the public BraTs-21 dataset and externally tested the model on a public Lumiere dataset. The experimental results show the promising performance of this approach. The proposed method got the best AUC score of 0.748 with minimum BCE loss of 0.62 on BraTs-21 as compared to other methods.},
  archive      = {J_NCA},
  author       = {Keerthiveena, B. and Sheikh, Mohammad Tufail and Kodamana, Hariprasad and Rathore, Anurag S.},
  doi          = {10.1007/s00521-024-09757-0},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11507-11523},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepDepth: Prediction of o(6)-methylguanine-DNA methyltransferase genotype in glioblastoma patients using multimodal representation learning based on deep feature fusion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Traffic flow management by detecting and estimating vehicles
density based on object detection model. <em>NCA</em>, <em>36</em>(19),
11495–11505. (<a
href="https://doi.org/10.1007/s00521-024-09753-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The huge growth in the number of vehicles is causing serious traffic management problems. Existing roads must handle traffic more than expected which presents serious challenges including congestion and safety. Intelligent traffic management systems were proposed as a solution to solve such problems. This intelligent system is charged to estimate vehicle density and manage the traffic flow accordingly. A wide variety of sensors was deployed for the traffic management system such as cameras, ultrasonic sensors, radar, infrared sensors, and acoustic sensors. In this work, an intelligent traffic flow management system was proposed based on data provided by public surveillance cameras. For this purpose, a real-time vehicle detection and counting model based on You Look Only Once (YOLO) v6 was deployed. The proposed model was trained and evaluated on different publicly available datasets such as BDD 100K and KITTI. Extensive experimentations proved the efficacy of the proposed model for detecting vehicles while operating under real-time constraints. The proposed traffic flow management system was evaluated using real videos for different traffic scenarios, and good results were achieved.},
  archive      = {J_NCA},
  author       = {Said, Yahia and Alassaf, Yahya and Alsariera, Yazan and Ghodhbani, Refka and Saidani, Taoufik and Ben Rhaiem, Olfa and Makhdoum, Moayad Khaled},
  doi          = {10.1007/s00521-024-09753-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11495-11505},
  shortjournal = {Neural Comput. Appl.},
  title        = {Traffic flow management by detecting and estimating vehicles density based on object detection model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Edge artificial intelligence for big data: A systematic
review. <em>NCA</em>, <em>36</em>(19), 11461–11494. (<a
href="https://doi.org/10.1007/s00521-024-09723-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing, artificial intelligence (AI), and machine learning (ML) concepts have become increasingly prevalent in Internet of Things (IoT) applications. As the number of IoT devices continues to grow, relying solely on cloud computing for real-time data processing and analysis is proving to be more challenging. The synergy between edge computing and AI is particularly intriguing due to AI&#39;s reliance on rapid data processing, a capability facilitated by edge computing. Edge AI represents a significant paradigm shift, leveraging AI within edge computing frameworks to reduce reliance on internet connections and mitigate data latency issues. This approach accelerates data processing, supporting use cases that demand real-time inference. Additionally, as cloud storage costs continue to rise, the feasibility of streaming and storing large volumes of data comes into question. Edge AI offers a compelling solution by performing big data analytics closer to the end device where edge computing is deployed. This paper presents a systematic literature review (SLR) of 85 articles published between 2018 and 2023 within Edge AI. The study provides a comprehensive examination of the analysis of measurement environments and assesses factors applied to Edge AI for big data. It offers taxonomies specific to Edge AI within the big data domain, presents case studies, and outlines the challenges and open issues inherent in Edge AI for big data.},
  archive      = {J_NCA},
  author       = {Hemmati, Atefeh and Raoufi, Parisa and Rahmani, Amir Masoud},
  doi          = {10.1007/s00521-024-09723-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11461-11494},
  shortjournal = {Neural Comput. Appl.},
  title        = {Edge artificial intelligence for big data: A systematic review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Various optimized machine learning techniques to predict
agricultural commodity prices. <em>NCA</em>, <em>36</em>(19),
11439–11459. (<a
href="https://doi.org/10.1007/s00521-024-09679-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent increases in global food demand have made this research and, therefore, the prediction of agricultural commodity prices, almost imperative. The aim of this paper is to build efficient artificial intelligence methods to effectively forecast commodity prices in light of these global events. Using three separate, well-structured models, the commodity prices of eleven major agricultural commodities that have recently caused crises around the world have been predicted. In achieving its objective, this paper proposes a novel forecasting model for agricultural commodity prices using the extreme learning machine technique optimized with the genetic algorithm. In predicting the eleven commodities, the proposed model, the extreme learning machine with the genetic algorithm, outperforms the model formed by the combination of long short-term memory with the genetic algorithm and the autoregressive integrated moving average model. Despite the fluctuations and changes in agricultural commodity prices in 2022, the extreme learning machine with the genetic algorithm model described in this study successfully predicts both qualitative and quantitative behavior in such a large number of commodities and over such a long period of time for the first time. It is expected that these predictions will provide benefits for the effective management, direction and, if necessary, restructuring of agricultural policies by providing food requirements that adapt to the dynamic structure of the countries.},
  archive      = {J_NCA},
  author       = {Sari, Murat and Duran, Serbay and Kutlu, Huseyin and Guloglu, Bulent and Atik, Zehra},
  doi          = {10.1007/s00521-024-09679-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11439-11459},
  shortjournal = {Neural Comput. Appl.},
  title        = {Various optimized machine learning techniques to predict agricultural commodity prices},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced vision transformer with scale-aware and
spatial-aware attention for thighbone fracture detection. <em>NCA</em>,
<em>36</em>(19), 11425–11438. (<a
href="https://doi.org/10.1007/s00521-024-09672-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformers (ViTs) have recently outperformed convolutional neural networks (CNNs) across a variety of deep learning tasks. In the field of orthopedic medicine, the thighbone serves as a critical support structure for the lower body, and a timely and accurate diagnosis of its fractures is important to preventing lifelong walking disabilities. Despite the successes of CNNs in the computer-aided diagnosis of thighbone fractures, the potential of ViTs in this realm remains unexplored. Consequently, we initially explored the direct application of off-the-shelf ViT models on thighbone fracture detection but found the results did not fully satisfy the requirement of radiologists. To address this gap, we propose a one-stage hybrid method that combines enhanced vision transformers with the CNN attention mechanisms, specifically for thighbone fracture detection. Our method improves a pyramid vision transformer architecture and employs overlapping patch embedding to preserve the local continuity in X-rays. For dynamic feature fusion across spatial and scale dimensions, we use a series of attention mechanisms consisting of two distinct types: scale-aware attention and spatial-aware attention. These mechanisms can integrate feature maps output from the neck structure, thereby improving the representation of thighbone fractures. We validate the proposed method using a meticulously curated dataset of 4000 thighbone X-rays, annotated by experienced radiologists. Ablation studies confirm the effectiveness of each modification in our proposed framework. Experimental results show that our method achieves an average precision (AP) of 53.7% and an $$AP_{50}$$ of 87.0%, thereby surpassing all previous state-of-the-art methods in thighbone fracture detection.},
  archive      = {J_NCA},
  author       = {Guan, Bin and Yao, Jinkun and Zhang, Guoshan},
  doi          = {10.1007/s00521-024-09672-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11425-11438},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced vision transformer with scale-aware and spatial-aware attention for thighbone fracture detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CSGAT-net: A conditional pedestrian trajectory prediction
network based on scene semantic maps and spatiotemporal graph attention.
<em>NCA</em>, <em>36</em>(19), 11409–11423. (<a
href="https://doi.org/10.1007/s00521-024-09784-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian behavior exhibits high levels of dynamism, and pedestrian trajectories are influenced not only by the pedestrians themselves, but also by interactions with surrounding objects. Efficiently understanding pedestrian motion behavior and modeling its interactions play a crucial role in fields like autonomous driving. Addressing issues related to dynamic feature extraction and interaction modeling in pedestrian trajectory prediction tasks, this paper introduces the conditional pedestrian trajectory prediction network (CSGAT-Net) based on semantic segmentation maps and spatiotemporal graph attention. CSGAT-Net models the physical environment and pedestrian behavior information in the scene as a semantic map, and it leverages graph attention networks to extract pedestrian interaction features. Finally, it predicts pedestrian future trajectories using a variational autoencoder. Comparative experiments conducted on publicly available datasets, ETH and UCY, show that our model exhibits favorable objective evaluation metrics and subjective prediction performance. Particularly, in terms of ADE and FDE metrics, CSGAT-Net outperforms current state-of-the-art methods, indicating that our model can reasonably and accurately predict pedestrian trajectories in different scenarios.},
  archive      = {J_NCA},
  author       = {Yang, Xin and Fan, Jiangfeng and Wang, Xiangcheng and Li, Tao},
  doi          = {10.1007/s00521-024-09784-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11409-11423},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSGAT-net: A conditional pedestrian trajectory prediction network based on scene semantic maps and spatiotemporal graph attention},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning based ankle–foot movement classification for
prosthetic foot. <em>NCA</em>, <em>36</em>(19), 11397–11407. (<a
href="https://doi.org/10.1007/s00521-024-09780-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary motivation behind this study is the aspiration to design a prosthetic foot that demonstrates enhanced functionality, enabling more active and prompt responses, particularly tailored for individuals with below-knee amputations. This goal underscores the intention to create a prosthetic foot with the capability to execute foot movements in a more natural and effective manner. A new 1D-ResCNN model has been proposed for the rapid and accurate classification of foot movements based on user intent in the context of a prosthetic limb. This research introduces an innovative approach by integrating inertial measurement units with deep learning algorithms to advance the development of more functional prosthetic feet, specifically tailored for below-knee amputees. Leveraging wearable technologies, this method allows for the prolonged monitoring of foot movements within the users’ natural environments. The dual benefits of cost reduction and enhanced user experience are achieved through this combination of advanced technologies, providing a promising avenue for the evolution of prosthetic foot design and usage. The results obtained with this model are satisfying both in terms of speed and accuracy with 99.8% compared to other methods in the literature.},
  archive      = {J_NCA},
  author       = {Aydin Fandakli, Selin and Okumus, Halil I.},
  doi          = {10.1007/s00521-024-09780-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11397-11407},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning based ankle–foot movement classification for prosthetic foot},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MultiPINN: Multi-head enriched physics-informed neural
networks for differential equations solving. <em>NCA</em>,
<em>36</em>(19), 11371–11395. (<a
href="https://doi.org/10.1007/s00521-024-09766-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the physics-informed neural network (PINN) has attracted much attention in solving partial differential equations (PDEs). The success is due to the strong generalization ability of the neural network (NN), which is supported by the universal approximation theorem, and its mesh-free implementation. In this paper, we propose a multi-head NN enriched PINN (MultiPINN) for solving differential equations. The trial function is built based on the radial basis function (RBF)-interpolation, which makes NN training parameters partially interpre. The loss function is constructed by embedding the physics information of differential equations and boundary conditions. Then the parameters in MultiPINN are trained using the ADAM optimizer. A significant feature of MultiPINN is that it combines the traditional RBF interpolation method with machine learning (ML) techniques. The ML technique is employed to learn the basis feature enrichment that provides global information. The multi-head mechanism is used so that each node has multiple bases, which can improve the accuracy of the MultiPINN solution. Two ordinary differential equations and three partial differential equations, i.e. the convection equation, the Burgers equation, and the Poisson equation, are used in the numerical experiments. The experimental outcomes demonstrate that MultiPINN produces solutions consistent with both analytical solutions and solutions obtained through traditional numerical methods. Additionally, MultiPINN shows robustness and adaptability over the other NN-based methods in the implementations.},
  archive      = {J_NCA},
  author       = {Li, Kangjie},
  doi          = {10.1007/s00521-024-09766-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11371-11395},
  shortjournal = {Neural Comput. Appl.},
  title        = {MultiPINN: Multi-head enriched physics-informed neural networks for differential equations solving},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting the maximum dry density and optimum moisture
content from soil index properties using efficient soft computing
techniques. <em>NCA</em>, <em>36</em>(19), 11339–11369. (<a
href="https://doi.org/10.1007/s00521-024-09734-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to achieve the densest possible state of soil for constructing dams and roads. This requires assessing the compaction characteristics, Optimum Moisture Content (OMC), and Maximum Dry Density (MDD) to determine the soil&#39;s suitability for earthworks. However, this process is resource-intensive and time-consuming. To streamline the assessment, the study incorporates six parameters: gravel (G), sand (S), fine (F) contents, plastic limit (PL), liquid limit (LL), and plasticity index (PI). Four different models are used to predict compaction characteristics: artificial neural network (ANN), nonlinear regression (NLR), linear regression (LR), and multilinear regression (MLR). The study utilized a substantial dataset of 2162 entries, considering various soil gradation and plasticity properties as input variables. To evaluate the models&#39; effectiveness, several statistical measures, including coefficient of determination (R2), scatter index (SI), root mean squared error (RMSE), mean absolute error (MAE), a20-index, and Objective (OBJ) value, were employed. The ANN model outperformed other models in predicting OMC, with RMSE, MAE, OBJ, SI, a20-index, and R2 values of 3.51, 2.31, 4.26, 0.202, 0.7, and 0.92%, respectively. However, for predicting MDD, the ANN model had the highest R2 value (R2 = 0.87), but the minimum RMSE (1.01), MAE (0.8), a20-index (0.998), and OBJ (1.07) were obtained from the MLR and LR models. Furthermore, sensitivity analyses revealed that the plastic limit significantly influences the OMC, while the gravel content plays a dominant role in predicting MDD.},
  archive      = {J_NCA},
  author       = {Ali, Hunar Farid Hama and Omer, Bashdar and Mohammed, Ahmed Salih and Faraj, Rabar H.},
  doi          = {10.1007/s00521-024-09734-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11339-11369},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting the maximum dry density and optimum moisture content from soil index properties using efficient soft computing techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An artificial neural network-source apportionment-based
prediction model for carbon monoxide from total number of ships calling
by ports in malaysia. <em>NCA</em>, <em>36</em>(19), 11323–11337. (<a
href="https://doi.org/10.1007/s00521-024-09699-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution has been a significant issue in recent years due to rising industrialization and maritime activity around the globe, making air pollution forecasting a crucial concept in environmental study. This prompted the deployment of principal component analysis (PCA) for the source apportionment amongst the air quality parameters and the artificial neural network (ANN) for the prediction of the significant air quality parameters in ports area for this study. The study was carried out in seven federal ports across Malaysia for the period of 2009 and 2018, and 14 air quality parameters were calculated using information on air quality acquired from the Department of the Environment. The results of the study showed PCA identified NOx, NO, SO, NO2, CO, and PM10 as the variables of significance with a variation of 44.31% with CO exhibiting the highest factor loading (0.968). Artificial Neural Network-Source Apportionment accurately predicted CO as the major pollutant with R2 in training (0.7492) and validation (0.7492). This study has successfully established a connection between the source of apportionment of air pollutant parameters and the total number of ships, as well as an effective alternative tool for predicting the most significant air quality air pollutant parameters in Malaysian ports, which can be applied in other regions to comprehend ship emission trends.},
  archive      = {J_NCA},
  author       = {Samsudin, Mohd Saiful and Azid, Azman and Rani, Nurul Latiffah Abd and Zaudi, Muhammad Amar and Saharuddin, Shazlyn Millenana and Tan, Mou Leong and Koki, Isa Baba},
  doi          = {10.1007/s00521-024-09699-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11323-11337},
  shortjournal = {Neural Comput. Appl.},
  title        = {An artificial neural network-source apportionment-based prediction model for carbon monoxide from total number of ships calling by ports in malaysia},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-powered multimodal biometric authentication:
Integrating dynamic signatures and facial data for enhanced online
security. <em>NCA</em>, <em>36</em>(19), 11311–11322. (<a
href="https://doi.org/10.1007/s00521-024-09690-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant increase in online activities in the wake of recent global events has underlined the importance of biometric person authentication on digital platforms. Although many biometric devices may be used for precise biometric authentication, acquiring the necessary technology, such as 3D sensors or fingerprint scanners, can be prohibitively expensive and logistically challenging. Addressing the demands of online environments, where access to specialized hardware is limited, this paper introduces an innovative approach. In this work, by fusing static and dynamic signature data with facial data captured through regular computer cameras, a dataset of 1750 samples from 25 individuals is constructed. Deep learning models, including convolutional neural networks (CNN), long short-term memory (LSTM), gated recurrent unit (GRU), and temporal convolutional networks (TCN), are employed to craft a robust multi-classification model. This integration of various deep learning algorithms has demonstrated remarkable performance enhancements in biometric authentication. This research also underscores the potential of merging dynamic and static biometric features, derived from readily available sources, to yield a high-performance recognition framework. As online interactions continue to expand, the combination of various biometric modalities holds potential for enhancing the security and usability of virtual environments.},
  archive      = {J_NCA},
  author       = {Salturk, Serkan and Kahraman, Nihan},
  doi          = {10.1007/s00521-024-09690-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11311-11322},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-powered multimodal biometric authentication: Integrating dynamic signatures and facial data for enhanced online security},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MERPAL: Multicollinearity regressive multilayer
perceptron-based traffic-aware scheme for IoT-enabled smart cities.
<em>NCA</em>, <em>36</em>(19), 11297–11309. (<a
href="https://doi.org/10.1007/s00521-024-09652-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of smart cities, driven by advancements in information transmission and the fusion of sensor technologies with IoT, faces challenges from substantial data traffic affecting Quality of Service factors like throughput and causing data loss and delivery delays. In order to improve traffic-aware data transmission in IoT-based smart city applications, a novel deep learning technique called the Multicollinearity Deming Regression-based Deep Perceptive NeurAl Learning Classifier (MERPAL) method is introduced. The proposed Deep Multilayer Perceptive Classifier consists of multiple layers such as input, output, and a number of hidden layers for assessing the given input. The number of nodes taken as input is passed to the primary hidden layer, where the energy and bandwidth availability of the nodes are assessed. The second hidden layer then uses the Multicollinearity Deming Regression to evaluate the estimated energy level and bandwidth of the nodes. After that, the analyzed results are given to the soft step activation function in the third hidden layer. The activation function identifies the best nodes based on energy level and bandwidth availability for efficient data delivery and helps minimize the network traffic. The simulation results indicate that MERPAL demonstrates superior performance compared to existing methods, exhibiting a 7% enhancement in data packet delivery ratio, a 15% increase in throughput, along with a reduction of 20% in packet loss and 14% in delay.},
  archive      = {J_NCA},
  author       = {Rani, Sheeja and Raj, Pravija and Khedr, Ahmed M.},
  doi          = {10.1007/s00521-024-09652-8},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11297-11309},
  shortjournal = {Neural Comput. Appl.},
  title        = {MERPAL: Multicollinearity regressive multilayer perceptron-based traffic-aware scheme for IoT-enabled smart cities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of annual rice imports emphasizes on systematic
error reduction with smoothing series and optimal parameter selection
techniques. <em>NCA</em>, <em>36</em>(19), 11275–11295. (<a
href="https://doi.org/10.1007/s00521-024-09742-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From an economic perspective, rice is not only a principal staple food for nearly half of the world’s population but also a significant commodity in many countries. Consequently, the accuracy of demand uncertainty concerning rice imports, which can be useful information to support critical decision-making on trading and food security management, is very challenging. The proposed model of simple exponential smoothing, support vector regression, and generalized simulated annealing is proposed and developed to predict annual rice imports based on twenty datasets across importer countries. The proposed model takes advantage of both suitable parameter selection and noise reduction in systematic error reduction with smoothing series to achieve more accuracy and precision. The empirical results revealed that the proposed model can improve accuracy based on five accuracy measures and is significantly different from other models at 0.05 significance levels. Moreover, the proposed model can provide consistency and reliability for forecasting rice imports in advance. Consequently, the proposed model can be a promising tool to support decision-making for policymakers.},
  archive      = {J_NCA},
  author       = {Sujjaviriyasup, Thoranin},
  doi          = {10.1007/s00521-024-09742-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11275-11295},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of annual rice imports emphasizes on systematic error reduction with smoothing series and optimal parameter selection techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-attention-based network to improve heavy rainfall
prediction over the complex terrain of assam. <em>NCA</em>,
<em>36</em>(19), 11257–11273. (<a
href="https://doi.org/10.1007/s00521-024-09682-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heavy rainfall events prediction at the local scale imposes a big challenge for meteorological agencies over the complex terrain areas in India such as Assam, Uttarakhand, and Himachal Pradesh and causes flash floods with severe consequences throughout the area causing a huge socio-economical loss over these regions. Assam is currently experiencing severe flooding in June 2023. Due to the limits of deterministic numerical weather models in accurately forecasting these events, this work investigates the incorporation of deep learning (DL) models, particularly spatial attention-based U-Net, using simulated daily collected rainfall outputs from various parametrization schemes. This is a pioneering effort to improve district-scale rainfall using the spatio-attention U-Net DL method, particularly over the orographically complex region such as Assam. The proposed model outperformed individual and ensemble Weather Research and Forecasting (WRF) model outputs over four days in June 2022, demonstrating greater abilities to forecast rainfall at the district scale with a mean absolute error of less than 10 mm. Additionally, the proposed model considerably outperformed WRF models by 51.3% in categorical rainfall prediction, achieving a high prediction accuracy of 91.9%. Furthermore, the proposed model has demonstrated improved spatial variation as compared to the WRF model by correctly predicting severe rainfall occurrences at the district scale, including Barpeta, Kamrup, Kokrajhar, and Nalbari. The WRF projections regularly underestimated rainfall intensity ( 150 mm). On the quantitative estimation of rainfall thresholds using different skill scores, Equitable threat score values are more than 0.5 for all categories for the proposed model. In a nutshell, the findings of the study have direct implications for improving early warning systems and associated follow-up action in terms of developing efficient strategies toward better preparedness, mitigation, and adaptation measures over complex hilly regions to reduce loss of lives and properties.},
  archive      = {J_NCA},
  author       = {Trivedi, Dhananjay and Sharma, Omveer and Pattnaik, Sandeep},
  doi          = {10.1007/s00521-024-09682-2},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11257-11273},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatio-attention-based network to improve heavy rainfall prediction over the complex terrain of assam},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A coarse-to-fine small object detection framework based on a
background complexity classification strategy. <em>NCA</em>,
<em>36</em>(19), 11241–11255. (<a
href="https://doi.org/10.1007/s00521-024-09625-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection has achieved great progress and is used in various tasks. However, detecting small objects with lack of appearance information is still a challenging task. It is found that even if the training set with rich images is used to train a network, the small objects in the image with different background complexity cannot be well detected. To address the above issue, this paper proposes a novel small object detection framework based on a background complexity classification strategy specific to the contradiction by adopting the idea of &quot;divide and rule&quot; in philosophy. Firstly, a Background Complexity Classification Network (BCCResNet) is proposed to coarsely classify the input images into three categories according to the complexity of their background textures. Then, a detection network with parallel structure is designed by using mainstream models to detect small objects for three categories of images. Extensive experiments are conducted on two small object detection datasets, i.e., AI-TOD and DOTAv1.0. Our proposed method can significantly improve AP of small object detection, showing effectiveness and advantages.},
  archive      = {J_NCA},
  author       = {Wang, Runshi and Yang, Jinfu and Xu, Yifei and Li, Haoqing},
  doi          = {10.1007/s00521-024-09625-x},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11241-11255},
  shortjournal = {Neural Comput. Appl.},
  title        = {A coarse-to-fine small object detection framework based on a background complexity classification strategy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage dispatching approach for one-to-many
ride-sharing with sliding time windows. <em>NCA</em>, <em>36</em>(19),
11213–11239. (<a
href="https://doi.org/10.1007/s00521-024-09631-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ride-sharing has transformed people’s travel habits with the development of various ride-sharing platforms, which can enhance the utilization of transportation resources, alleviate traffic congestion, and reduce carbon emissions. However, the development of a general and efficient matching framework is challenging due to the dynamic real-time conditions and uncertainty of ride-sharing problems in the real world. Additionally, previous research has identified limitations in terms of model practicability and algorithmic solution speed. To address these issues, a two-stage dispatching approach for one-to-many ride-sharing with sliding time windows is proposed. The dynamic ride-sharing problem is formally defined, and an integer programming model is constructed to solve it. A multi-rider distance and time constraint algorithm uses a distance matrix and sliding time windows to preprocess data before matching is proposed, thereby optimizing data quality and improving computational efficiency. The ride-sharing process is divided into a reservation order matching stage based on path similarity and a real-time order matching stage based on path distance degree. A two-stage collaborative mechanism is designed to guide the collaboration of the two stages. Furthermore, numerical experiments are conducted using two real-world datasets from developing and developed country regions to verify the efficiency and practicability of the proposed approach.},
  archive      = {J_NCA},
  author       = {Liu, Yongwu and Xie, Binglei and Xu, Gangyan and Zhao, Jinqiu and Li, Tianyu},
  doi          = {10.1007/s00521-024-09631-z},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11213-11239},
  shortjournal = {Neural Comput. Appl.},
  title        = {A two-stage dispatching approach for one-to-many ride-sharing with sliding time windows},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smart hydropower management: Utilizing machine learning and
deep learning method to enhance dam’s energy generation efficiency.
<em>NCA</em>, <em>36</em>(19), 11195–11211. (<a
href="https://doi.org/10.1007/s00521-024-09613-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable energy sources and hydroelectric power generation in large parts of the electricity market are crucial as environmental pollution worsens . Utilizing meteorological data from the region, where the Hirfanlı Dam is located, this study employs machine learning (ML) and introduces a novel hybrid Genetic Grey Wolf Optimizer (GGW0)-based Convolutional Neural Network/Recurrent Neural Network (CNN/RNN) regression technique to predict hydroelectric power production (PP). In the first section of the study, various ML techniques SVR (Support Vector Regression), ELM (Extreme Learning Machine), RFR (Random Forest Regression), ANN (Artificial Neural Networks) and WKNNR (Weighted K-Nearest Neighbor) are presented with the Principal Component Analysis (PCA) method and the minimum–maximum method in the normalization of the features. A novel GGWO and CNN/RNN model)-Long Short-Term Memory (LSTM) regression technique is introduced in the second section. GGWO is used to select features, while the proposed CNN/RNN-LSTM model is employed for feature extraction and prediction of PP. The study demonstrates that the ELM algorithm in Method I outperforms other ML models, achieving a correlation coefficient (r) of 0.977 and the mean absolute error (MAE) of 0.4 with the best feature subset. Additionally, the proposed CNN/RNN hybrid model in Method II yields even better results, with r and MAE values of 0.9802 and 0.314, respectively. The research contributes to the field of renewable energy prediction, and the results can aid in efficient decision making for electricity generation and resource management.},
  archive      = {J_NCA},
  author       = {Sahin, Muhammet Emin and Ozbay Karakus, Mucella},
  doi          = {10.1007/s00521-024-09613-1},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11195-11211},
  shortjournal = {Neural Comput. Appl.},
  title        = {Smart hydropower management: Utilizing machine learning and deep learning method to enhance dam’s energy generation efficiency},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised air quality estimation with graph neural
network assistance and attention enhancement. <em>NCA</em>,
<em>36</em>(19), 11171–11193. (<a
href="https://doi.org/10.1007/s00521-024-09637-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid progress of industrial development, urbanization, and traffic has caused air quality degradation that negatively affects human health and environmental sustainability, especially in developed countries. However, due to the limited number of sensors available, the air quality index at many locations is not monitored. Therefore, many research, including statistical and machine learning approaches, have been proposed to tackle the problem of estimating air quality value at an arbitrary location. Most of the existing research perform interpolation process based on traditional techniques that leverage distance information. In this work, we propose a novel deep-learning-based model for air quality value estimation. This approach follows the encoder–decoder paradigm, with the encoder and decoder trained separately using different training mechanisms. In the encoder component, we proposed a new self-supervised graph representation learning approach for spatio-temporal data. For the decoder component, we designed a deep interpolation layer that employs two attention mechanisms and a fully connected layer using air quality data at known stations, distance information, and meteorology information at the target point to predict air quality at arbitrary locations. The experimental results demonstrate significant improvements in estimation accuracy achieved by our proposed model compared to state-of-the-art approaches. For the MAE indicator, our model enhances the estimation accuracy from 4.93% to 34.88% on the UK dataset, and from 6.89% to 31.94% regarding the Beijing dataset. In terms of the RMSE, the average improvements of our method on the two datasets are 13.33% and 14.37%, respectively. The statistics for MAPE are 36.05% and 13.25%, while for MDAPE, they are 24.48% and 36.33%, respectively. Furthermore, the value of $$R_2$$ score attained by our proposed model also shows considerable improvement, with increases of 5.39% and 32.58% compared to that of comparison benchmarks. Our source code and data are available at https://github.com/duclong1009/Unsupervised-Air-Quality-Estimation .},
  archive      = {J_NCA},
  author       = {Vu, Viet Hung and Nguyen, Duc Long and Nguyen, Thanh Hung and Nguyen, Quoc Viet Hung and Nguyen, Phi Le and Huynh, Thanh Trung},
  doi          = {10.1007/s00521-024-09637-7},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11171-11193},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-supervised air quality estimation with graph neural network assistance and attention enhancement},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced prairie dog optimization with levy flight and
dynamic opposition-based learning for global optimization and
engineering design problems. <em>NCA</em>, <em>36</em>(19), 11137–11170.
(<a href="https://doi.org/10.1007/s00521-024-09648-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new prairie dog optimization algorithm version called EPDO. This new version aims to address the issues of premature convergence and slow convergence that were observed in the original PDO algorithm. To improve performance, several modifications are introduced in EPDO. First, a dynamic opposite learning strategy is employed to increase the diversity of the population and prevent premature convergence. This strategy helps the algorithm avoid falling into local optima and promotes global optimization. Additionally, the Lévy dynamic random walk technique is utilized in EPDO. This modified Lévy flight with random walk reduces the algorithm’s running time for the test function’s ideal value, accelerating its convergence. The proposed approach is evaluated using 33 benchmark problems from CEC 2017 and compared against seven other comparative techniques: GWO, MFO, ALO, WOA, DA, SCA, and RSA. Numerical results demonstrate that EPDO produces good outcomes and performs well in solving benchmark problems. To further validate the results and assess reliability, the authors employ average rank tests, the measurement of alternatives, and ranking according to the compromise solution (MARCOS) method, as well as a convergence report of EPDO and other algorithms. Furthermore, the effectiveness of the EPDO algorithm is demonstrated by applying it to five design problems. The results indicate that EPDO achieves impressive outcomes and proves its capability to address practical issues. The algorithm performs well in solving benchmark and practical design problems, as supported by the numerical results and validation methods used in the study.},
  archive      = {J_NCA},
  author       = {Biswas, Saptadeep and Shaikh, Azharuddin and Ezugwu, Absalom El-Shamir and Greeff, Japie and Mirjalili, Seyedali and Bera, Uttam Kumar and Abualigah, Laith},
  doi          = {10.1007/s00521-024-09648-4},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11137-11170},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced prairie dog optimization with levy flight and dynamic opposition-based learning for global optimization and engineering design problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSCL-FHFN: Two-stage contrastive learning and feature
hierarchical fusion network for multimodal sentiment analysis.
<em>NCA</em>, <em>36</em>(19), 11121–11135. (<a
href="https://doi.org/10.1007/s00521-024-09634-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis faces two challenges: modality representation and modality fusion. Most of the existing models rely only on the feature extraction network to learn modality representation, and the fusion mechanism adopted by some models does not perform well. These factors are not conducive to the model learning rich emotional information and further affect the model’s predictive ability. To solve these problems, we propose a multimodal sentiment analysis model based on two-stage contrastive learning and feature hierarchical fusion network (TSCL-FHFN). First, we apply the idea of contrastive learning to unimodal feature representation and multimodal fusion feature representation respectively. By designing a two-stage contrastive learning task, TSCL-FHFN learns similar features for data with the same emotion category and learns distinguishable features for data with different emotion categories. This enables the model to better learn the features of emotional differences. Second, in order to further explore the deep semantic association of multimodal data, we propose a multimodal feature hierarchical fusion network (FHFN). The core idea is to design an attention-based directional cross-modal transformer so that one modality can receive information from the other modality, thereby obtaining complementary information between two modalities. Then, FHFN uses the low-rank tensor fusion method to further learn interactive information between multiple modalities. Finally, we conduct a series of comparative experiments on CMU-MOSI and CMU-MOSEI datasets. Compared with the current representative models, the TSCL-FHFN model achieves better experimental results. In addition, ablation experiments further verify the effectiveness of the improved TSCL-FHFN model.},
  archive      = {J_NCA},
  author       = {Li, Yuqiang and Weng, Wenxuan and Liu, Chun},
  doi          = {10.1007/s00521-024-09634-w},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11121-11135},
  shortjournal = {Neural Comput. Appl.},
  title        = {TSCL-FHFN: Two-stage contrastive learning and feature hierarchical fusion network for multimodal sentiment analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-CODP decision models for supplier selection and order
allocation in customized logistics service supply chain. <em>NCA</em>,
<em>36</em>(19), 11097–11119. (<a
href="https://doi.org/10.1007/s00521-024-09647-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem of positioning customer order decoupling point (CODP) in customized logistics service supply chain and to provide logistics service integrators (LSI) with various CODP decision-making and supplier selection solutions. We consider LSI, logistics service providers (LSPs) and customers and propose multiobjective nonlinear team optimization models for multi-CODP location, including minimizing the cost to the LSI and maximizing the synthetic satisfaction of LSPs and customers. This paper adopts an improved nondominated sorting genetic algorithm (NSGA-II), in which the key modules such as the crossover operations, chromosome structure and mutation operations are reconstructed, to solve the team models and investigate the Pareto-optimal front for the two objectives. To demonstrate the validity of NSGA-II and the reliability of mathematical models, cases from a specific dataset are generated and solved. Moreover, a classic genetic algorithm (GA) is applied to solve for the two objectives separately. The optimal solutions found by GA are $$f_{1}$$ = 2027.491, $$f_{2}$$ = 0.7704 and $$f_{1}$$ = 2454.512, $$f_{2}$$ = 0.8909. The corresponding optimal solutions in the Pareto-optimal solution set are $$f_{1}$$ = 2053.675, $$f_{2}$$ = 0.7715 and $$f_{1}$$ = 2427.114, $$f_{2}$$ = 0.8843. We find that the optimal solutions provided by GA cannot dominate any solution in the Pareto-optimal solution set, indicating that the results are valid and sufficiently convergent. In summary, the results of this paper provide LSI with easy access to various supplier selection schemes with multi-CODP, which is essential to reduce the cognitive burden on decision makers and address the diverse customization needs of many challenging real-world logistics issues.},
  archive      = {J_NCA},
  author       = {Hu, Xiaojian and Xu, Liangcheng and Yao, Gang and Wu, Zhening},
  doi          = {10.1007/s00521-024-09647-5},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11097-11119},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-CODP decision models for supplier selection and order allocation in customized logistics service supply chain},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SightAid: Empowering the visually impaired in the kingdom of
saudi arabia (KSA) with deep learning-based intelligent wearable vision
system. <em>NCA</em>, <em>36</em>(19), 11075–11095. (<a
href="https://doi.org/10.1007/s00521-024-09619-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Kingdom of Saudi Arabia, visual impairment poses significant challenges for approximately 17.5% of school-aged children, mainly due to refractive errors. These challenges extend to everyday navigation, environmental interaction, and overall life quality. Motivated by the desire to empower visually impaired individuals, who face navigational limitations, difficulties in object recognition, and inadequate assistance from traditional technologies, we propose SightAid. This innovative wearable vision system utilizes a deep learning-based framework, addressing the gaps left by current assistive solutions. Traditional methods, such as canes and GPS devices, often fail to meet the nuanced and dynamic needs of the visually impaired, especially in accurately identifying objects, understanding complex environments, and providing essential real-time feedback for independent navigation. SightAid comprises a seven-phase framework involving data collection, preprocessing, and training of a sophisticated deep neural network with multiple convolutional and fully connected layers. This system is integrated into smart glasses with augmented reality displays, enabling real-time object detection and recognition. Interaction with users is facilitated through audio or haptic feedback, informing them about the location and type of objects detected. A continuous learning mechanism, incorporating user feedback and new data, ensures the system&#39;s ongoing refinement and adaptability. For performance assessment, we utilized the MNIST dataset, and an Indoor Objects Detection dataset tailored for the visually impaired, featuring images of everyday objects crucial for safe indoor navigation. SightAid demonstrates remarkable performance with accuracy up to 0.9874, recall values between 0.98 and 0.99, F1-scores ranging from 0.98 to 0.99, and AUC-ROC values reaching as high as 0.9999. These metrics significantly surpass those of traditional methods, highlighting SightAid&#39;s potential to substantially improve the independence and safety of visually impaired individuals in various environments.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and Farsi, Mohammed and Badawy, Mahmoud and Elhosseini, Mostafa},
  doi          = {10.1007/s00521-024-09619-9},
  journal      = {Neural Computing and Applications},
  month        = {7},
  number       = {19},
  pages        = {11075-11095},
  shortjournal = {Neural Comput. Appl.},
  title        = {SightAid: Empowering the visually impaired in the kingdom of saudi arabia (KSA) with deep learning-based intelligent wearable vision system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Virtual reality research of the dynamic
characteristics of soft soil under metro vibration loads based on BP
neural networks. <em>NCA</em>, <em>36</em>(18), 11027. (<a
href="https://doi.org/10.1007/s00521-024-09951-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Cui, Kai and Qin, Xiaotong},
  doi          = {10.1007/s00521-024-09951-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11027},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Virtual reality research of the dynamic characteristics of soft soil under metro vibration loads based on BP neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Quality assessment for virtual reality
technology based on real scene. <em>NCA</em>, <em>36</em>(18), 11025.
(<a href="https://doi.org/10.1007/s00521-024-09950-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Jiang, Bin and Yang, Jiachen and Jiang, Na and Lv, Zhihan and Meng, Qinggang},
  doi          = {10.1007/s00521-024-09950-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11025},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Quality assessment for virtual reality technology based on real scene},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Adaptive hexagonal fuzzy hybrid filter for
rician noise removal in MRI images. <em>NCA</em>, <em>36</em>(18),
11023. (<a href="https://doi.org/10.1007/s00521-024-09949-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kala, R. and Deepa, P.},
  doi          = {10.1007/s00521-024-09949-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11023},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Adaptive hexagonal fuzzy hybrid filter for rician noise removal in MRI images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Automated screening of congestive heart
failure using variational mode decomposition and texture features
extracted from ultrasound images. <em>NCA</em>, <em>36</em>(18), 11021.
(<a href="https://doi.org/10.1007/s00521-024-09948-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Raghavendra, U. and Acharya, U. Rajendra and Gudigar, Anjan and Shetty, Ranjan and Krishnananda, N. and Pai, Umesh and Samanth, Jyothi and Nayak, Chaithra},
  doi          = {10.1007/s00521-024-09948-9},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11021},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Automated screening of congestive heart failure using variational mode decomposition and texture features extracted from ultrasound images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Sine–cosine algorithm for feature selection
with elitism strategy and new updating mechanism. <em>NCA</em>,
<em>36</em>(18), 11019. (<a
href="https://doi.org/10.1007/s00521-024-09947-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sindhu, R. and Ngadiran, Ruzelita and Yacob, Yasmin Mohd and Zahri, Nik Adilah Hanin and Hariharan, M.},
  doi          = {10.1007/s00521-024-09947-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11019},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Sine–cosine algorithm for feature selection with elitism strategy and new updating mechanism},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A comparative study on parameters of
leaf-shaped patch antenna using hybrid artificial intelligence network
models. <em>NCA</em>, <em>36</em>(18), 11017. (<a
href="https://doi.org/10.1007/s00521-024-09946-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ozkaya, Umut and Seyfi, Levent},
  doi          = {10.1007/s00521-024-09946-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11017},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A comparative study on parameters of leaf-shaped patch antenna using hybrid artificial intelligence network models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Signal detection based on empirical mode
decomposition and teager–kaiser energy operator and its application to p
and s wave arrival time detection in seismic signal analysis.
<em>NCA</em>, <em>36</em>(18), 11015. (<a
href="https://doi.org/10.1007/s00521-024-09945-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kirbas, Ismail and Peker, Musa},
  doi          = {10.1007/s00521-024-09945-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11015},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Signal detection based on empirical mode decomposition and Teager–Kaiser energy operator and its application to p and s wave arrival time detection in seismic signal analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: ANN-based MPPT algorithm for solar PMSM
drive system fed by direct-connected PV array. <em>NCA</em>,
<em>36</em>(18), 11013. (<a
href="https://doi.org/10.1007/s00521-024-09944-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Deniz, Erkan},
  doi          = {10.1007/s00521-024-09944-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: ANN-based MPPT algorithm for solar PMSM drive system fed by direct-connected PV array},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A novel feature selection method for brain
tumor MR image classification based on the fisher criterion and
parameter-free bat optimization. <em>NCA</em>, <em>36</em>(18), 11011.
(<a href="https://doi.org/10.1007/s00521-024-09943-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kaur, Taranjit and Saini, Barjinder Singh and Gupta, Savita},
  doi          = {10.1007/s00521-024-09943-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11011},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A novel feature selection method for brain tumor MR image classification based on the fisher criterion and parameter-free bat optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Adaptive artificial intelligence for
automatic identification of defect in the angular contact bearing.
<em>NCA</em>, <em>36</em>(18), 11009. (<a
href="https://doi.org/10.1007/s00521-024-09942-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Kumar, Anil and Kumar, Rajesh},
  doi          = {10.1007/s00521-024-09942-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11009},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Adaptive artificial intelligence for automatic identification of defect in the angular contact bearing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Reality of virtual damage identification
based on neural networks and vibration analysis of a damaged bridge
under a moving vehicle. <em>NCA</em>, <em>36</em>(18), 11007. (<a
href="https://doi.org/10.1007/s00521-024-09941-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Xiong, Chun-bao and Lu, Hua-li and Zhu, Jin-song},
  doi          = {10.1007/s00521-024-09941-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11007},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Reality of virtual damage identification based on neural networks and vibration analysis of a damaged bridge under a moving vehicle},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Virtual reality of interior noises of
vehicles based on boundary element and neural networks. <em>NCA</em>,
<em>36</em>(18), 11005. (<a
href="https://doi.org/10.1007/s00521-024-09940-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhang, Yan-tian and Zhou, Jun-yi and Xie, Yan-zhao},
  doi          = {10.1007/s00521-024-09940-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11005},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Virtual reality of interior noises of vehicles based on boundary element and neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A fuzzy-based adaptive multi-input–output
scheme in lieu of diabetic and hypertension management for
post-operative patients: An human–machine interface approach with its
continuum. <em>NCA</em>, <em>36</em>(18), 11003. (<a
href="https://doi.org/10.1007/s00521-024-09939-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Alavudeen Basha, A. and Vivekanandan, S.},
  doi          = {10.1007/s00521-024-09939-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11003},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: a fuzzy-based adaptive multi-input–output scheme in lieu of diabetic and hypertension management for post-operative patients: an human–machine interface approach with its continuum},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Pivot variable location-based clustering
algorithm for reducing dead nodes in wireless sensor networks.
<em>NCA</em>, <em>36</em>(18), 11001. (<a
href="https://doi.org/10.1007/s00521-024-09881-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Jancy, S. and Jayakumar, C.},
  doi          = {10.1007/s00521-024-09881-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {11001},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Pivot variable location-based clustering algorithm for reducing dead nodes in wireless sensor networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Placement delivery array design for the
coded caching scheme in medical data sharing. <em>NCA</em>,
<em>36</em>(18), 10999. (<a
href="https://doi.org/10.1007/s00521-024-09880-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sun, Rong and Zheng, Huihui and Liu, Jingwei and Du, Xiaojiang and Guizani, Mohsen},
  doi          = {10.1007/s00521-024-09880-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10999},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Placement delivery array design for the coded caching scheme in medical data sharing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An artificial intelligence strategy for the deployment of
future microservice-based applications in 6G networks. <em>NCA</em>,
<em>36</em>(18), 10971–10997. (<a
href="https://doi.org/10.1007/s00521-024-09643-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future applications to be supported by 6G networks are envisaged to be realized by loosely-coupled and independent microservices. In order to achieve an optimal deployment of applications, smart resource management strategies will be required, working in a cost-effective and resource-efficient manner. Current cloud computing services are challenged to meet the explosive growth and demand of future use cases such as virtual/augmented/mixed reality (VR/AR/MR). The purpose of edge computing (EC) is to better address latency and transmission requirements of those future stringent applications. However, a high flexibility and a rapid decision-making will be required since EC suffers from limited resources availability. For this reason, this work proposes an artificial intelligence (AI) technique, based on reinforcement learning (RL), to make intelligent decisions on the optimal tier and edge-site selection to serve any request according to the application’s category, constraints, and conflicting costs. In addition, when deployed at the edge-network, a heuristic has been proposed for the mapping of microservices within the selected edge-site. That heuristic will exploit a ranking methodology based on the network topology and available network and compute resources while preserving the revenue of the mobile network operator (MNO). Simulation results show that the performance of the proposed RL approach is close to the optimal solution by reaching the cost minimization objective within a 8.3% margin; moreover, RL outperforms considered benchmark algorithms in most of the conducted experiments.},
  archive      = {J_NCA},
  author       = {Ssemakula, John Bosco and Gorricho, Juan-Luis and Kibalya, Godfrey and Serrat-Fernandez, Joan},
  doi          = {10.1007/s00521-024-09643-9},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10971-10997},
  shortjournal = {Neural Comput. Appl.},
  title        = {An artificial intelligence strategy for the deployment of future microservice-based applications in 6G networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A BERT-encoded ensembled CNN model for suicide risk
identification in social media posts. <em>NCA</em>, <em>36</em>(18),
10955–10970. (<a
href="https://doi.org/10.1007/s00521-024-09642-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suicide is a significant public health issue that devastates individuals and society. Early warning systems are crucial in preventing suicide. The purpose of this research is to create a deep learning model to identify suicide risk using a combination of bidirectional encoder representations from transformers (BERT) and an ensemble of multiple convolutional neural networks (CNN). BERT is used to encode the text data into numerical representations that capture the context-aware meaning of words and phrases, while ensemble CNN is used to analyze the encoded text data to identify patterns and relationships relevant to suicide risk. The model is trained on a large corpus of text data from social media and suicide notes and evaluated on a validation set of labeled data. The results of the proposed model perform better than the recent approaches in detecting suicide risk and can potentially be a valuable tool for suicide prevention efforts.},
  archive      = {J_NCA},
  author       = {Gorai, Joy and Shaw, Dilip Kumar},
  doi          = {10.1007/s00521-024-09642-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10955-10970},
  shortjournal = {Neural Comput. Appl.},
  title        = {A BERT-encoded ensembled CNN model for suicide risk identification in social media posts},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global instance relation distillation for convolutional
neural network compression. <em>NCA</em>, <em>36</em>(18), 10941–10953.
(<a href="https://doi.org/10.1007/s00521-024-09635-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous instance-relation knowledge distillation methods transfer structural relations between instances from the heavy teacher network to the lightweight student network, effectively enhancing the accuracy of the student. However, these methods have two limitations: (1) The modeling of relation knowledge only relies on the current mini-batch instances, causing the instance relations to be incomplete. (2) The information flow hidden in the evolution of instance relations throughout the network has been neglected. To address these problems, we propose a Global Instance Relation Distillation (GIRD) for convolutional neural network compression, which improves both the instance-level and relation-level globality. Firstly, we design a feature reutilization mechanism to store previously learned features to break through the shackles of the mini-batch. Secondly, we model the pairwise similarity-relation based on stored features to reveal more complete instance relations. Furthermore, we construct the pairwise relation-evolution across different layers to reflect the information flow. Extensive experiments on benchmark datasets demonstrate that our proposed method outperforms state-of-the-art approaches in various visual tasks.},
  archive      = {J_NCA},
  author       = {Hu, Haolin and Zeng, Huanqiang and Xie, Yi and Shi, Yifan and Zhu, Jianqing and Chen, Jing},
  doi          = {10.1007/s00521-024-09635-9},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10941-10953},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global instance relation distillation for convolutional neural network compression},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human attention detection system using deep learning and
brain–computer interface. <em>NCA</em>, <em>36</em>(18), 10927–10940.
(<a href="https://doi.org/10.1007/s00521-024-09628-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain–Computer Interface is tested as a successful method in improving human cognitive functions such as attention and memory. Attention plays a significant role in areas ranging from a person’s day-to-day life to educational domain and professional activities. When attention is evaluated using camera-based techniques, the users may suffer privacy issues. Using Brain–Computer Interface (BCI) to obtain a measure of attention will be useful in this regard. The paper proposes a Human Attention Recognition System (HARS) in which EEG signal acquisition is used to obtain the attention of the individual, Renyi’s entropy-based mutual information method is used for feature selection and a deep learning-based classifier is used to classify the signals. HADS is not camera-based: therefore, faces of the subjects are not revealed. EEG signals were collected using the Ultracortex Mark III dry electrodes and were visualised using OpenBCI GUI (Graphical User Interface). The experiment is validated using the publicly available Confused Student EEG dataset from Kaggle, giving an accuracy of 99.21%. The results indicate that the proposed method can identify attention levels accurately and can be effectively used in educational systems, biofeedback and medical research.},
  archive      = {J_NCA},
  author       = {Nair, S. Anju Latha and Megalingam, Rajesh Kannan},
  doi          = {10.1007/s00521-024-09628-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10927-10940},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human attention detection system using deep learning and brain–computer interface},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of multitask mental workload using gamma band
power features. <em>NCA</em>, <em>36</em>(18), 10915–10926. (<a
href="https://doi.org/10.1007/s00521-024-09627-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive fatigue occurs in various situations and is an essential condition to detect. In this study, how single and multi-tasking tests affect cognitive workload was examined, and multi-tasking was detected using electroencephalography (EEG) signals. In the cognitive workload paradigm, single-task tests with blocks 1 and 2 and multi-tasking tests with block 3 were created. EEG signals obtained from these blocks were treated as different frequency bands and lengths, and binary classification was performed. Two binary classifications were made: block 1–block 3 and block 2–block 3. According to the results, the highest classification accuracy for block 1–block 3 was obtained as 97.11% using the gamma frequency band and 5-s EEG length. For block 2–block 3, the highest classification accuracy was obtained as 90.88% using the gamma frequency band and 5-s EEG length. As a result, this study distinguished multi-tasking and single task with high classification accuracy. The developed model can be used to detect attention deficit and inability to focus. In addressing the prevalent challenges of distinguishing cognitive fatigue in single—task versus multitasking scenarios, our study offers a new method, which achieve a remarkable accuracy rate, thereby illuminating a new path in the research of cognitive fatigue.},
  archive      = {J_NCA},
  author       = {Korkmaz, Onur Erdem and Korkmaz, Sevde Gül and Aydemir, Onder},
  doi          = {10.1007/s00521-024-09627-9},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10915-10926},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of multitask mental workload using gamma band power features},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast point completion network. <em>NCA</em>,
<em>36</em>(18), 10897–10913. (<a
href="https://doi.org/10.1007/s00521-024-09624-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds in the real world are often sparse and incomplete. Point cloud completion aims to restore incomplete point clouds into meaningful shapes. In recent years, point cloud completion has attracted the interest of many researchers. In most existing methods, the efficiency of completion is generally ignored in favor of producing meaningful shapes with adequate details. This paper proposes a fast point completion network (FPCN). FPCN is mainly composed of a multi-scale attention encoder (MSAE) and a structural refinement (SR) module. MSAE first obtains multi-scale geometric information by extracting incomplete inputs at different resolutions. After that, MSAE fuses multi-scale geometric information through cross-attention mechanisms. Compared with existing mainstream encoders, MSAE can extract rich geometric information from input point clouds with low complexity. The SR module aims to extract local information from the coarse point clouds to guide the process of extending points. Furthermore, the process of extending points is achieved by a replication strategy. Compared to existing folding-based decoders, the SR module can produce fine point clouds with more local details. Compared to existing transformer-based decoders, the SR module has a lower calculation price by employing a replication strategy to generate high-resolution point clouds. In conclusion, FPCN can restore partial point clouds into meaningful shapes efficiently, and the outcomes of completion contain sufficient details. Extensive experiments on various datasets demonstrate the performance and efficiency of the FPCN in point cloud completion. Source code is available at https://github.com/doldolOuO/FPCN .},
  archive      = {J_NCA},
  author       = {Fang, Chenghao and Yang, Bing and Ye, Hailiang and Cao, Feilong},
  doi          = {10.1007/s00521-024-09624-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10897-10913},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast point completion network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online learning of stable robust adaptive controllers design
based on data-dependent feedback linearization with application to
rotary inverted pendulum. <em>NCA</em>, <em>36</em>(18), 10881–10896.
(<a href="https://doi.org/10.1007/s00521-024-09621-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces an online (supervised) learning method to design nonlinear auto-regressive moving average (NARMA) controllers for feedback-linearized nonlinear single-input single-output (SISO) systems. The algorithm ensures Schur stability of the overall closed-loop system and provides adaptiveness and robustness for the NARMA controllers. The first stage of the method derives, in a data-dependent way, a feedback-linearized model of the nonlinear plant by using its input and output sample pairs. The method’s second stage, which constitutes the novel part of the presented study, builds up an online learning scheme for the linear auto-regressive moving average (ARMA) controller based on an already learned feedback-linearized model of the nonlinear plant. During online supervised learning, ARMA parameters of the feedback-linearized SISO plant model and the closed-loop ARMA model are computed by minimizing the plant identification and the closed-loop system tracking errors. Both errors are defined as $${{\ell}}_{1,{\varvec{\varepsilon}}}$$ , namely ε-insensitive loss functions that provide NARMA controller the robustness against noise and outliers. The proposed online learning control algorithm is applied to a rotary inverted pendulum model and to a real rotary inverted pendulum setup. The tracking performance of the developed controller is compared with those of the linear quadratic regulator and coupled sliding mode controller in terms of mean square error.},
  archive      = {J_NCA},
  author       = {Soydemir, Mehmet Uğur and Şahin, Savaş and Kocaoğlu, Aykut and Bulucu, Parvin and Güzeliş, Cüneyt},
  doi          = {10.1007/s00521-024-09621-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10881-10896},
  shortjournal = {Neural Comput. Appl.},
  title        = {Online learning of stable robust adaptive controllers design based on data-dependent feedback linearization with application to rotary inverted pendulum},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting white shark optimizer for global optimization and
cloud scheduling problem. <em>NCA</em>, <em>36</em>(18), 10853–10879.
(<a href="https://doi.org/10.1007/s00521-024-09599-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing adoption of cloud computing in both public and private sector enterprises, the industry has experienced rapid expansion. To fully unlock the potential of cloud computing, efficient task scheduling becomes crucial. In cloud computing, task scheduling involves optimizing the allocation of tasks to a diverse range of resources, such as virtual machines, with the goals of reducing makespan, maximizing resource utilization, and minimizing response times. This challenge becomes even more pronounced for large-scale tasks due to the NP-hard nature of the problem. Consequently, the integration of metaheuristic algorithms into task scheduling has emerged as a solution to equitably distribute complex and diverse tasks across limited resources within acceptable timeframes. To enhance the quality of cloud computing services, this research introduces the modified white shark optimizer (mWSO) as an alternative task scheduling technique. The improved variant mWSO boosts the performance of the original WSO by introducing the following three enhancement steps: (1) introduce memory-based WSO to boost the exploitation phase, (2) propose an exploration-exploitation balance phase to enhance the exploration phase, and (3) introduce a control randomization parameter to balance exploration and exploitation properly. The mWSO is subjected to testing on both the global optimization problems from CEC2020 and cloud task scheduling problems. The experimental results of mWSO demonstrate high performance for CEC2020 competition benchmarks compared to other state-of-the-art and recent metaheuristic algorithms. In the case of the task scheduling problem, the mWSO achieved − 0.01 to 13.53% and 0.62–10.42% makespan and energy consumption reduction, respectively, for CEA-Curie workloads. For HPC2N workloads, mWSO achieved 7.27–29.53% makespan reduction and 3.52–26.08% energy savings over the compared metaheuristics. The statistical validity of the performance is also verified using Wilcoxon’s rank-sum test. The experimental results and comparison analysis reveal the consistent and better performance of the proposed mWSO to solve optimization problems.},
  archive      = {J_NCA},
  author       = {Mostafa, Reham R. and Chhabra, Amit and Khedr, Ahmed M. and Hashim, Fatma A.},
  doi          = {10.1007/s00521-024-09599-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10853-10879},
  shortjournal = {Neural Comput. Appl.},
  title        = {Boosting white shark optimizer for global optimization and cloud scheduling problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learn &amp; drop: Fast learning of cnns based on layer
dropping. <em>NCA</em>, <em>36</em>(18), 10839–10851. (<a
href="https://doi.org/10.1007/s00521-024-09592-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new method to improve the training efficiency of deep convolutional neural networks. During training, the method evaluates scores to measure how much each layer’s parameters change and whether the layer will continue learning or not. Based on these scores, the network is scaled down such that the number of parameters to be learned is reduced, yielding a speed-up in training. Unlike state-of-the-art methods that try to compress the network to be used in the inference phase or to limit the number of operations performed in the back-propagation phase, the proposed method is novel in that it focuses on reducing the number of operations performed by the network in the forward propagation during training. The proposed training strategy has been validated on two widely used architecture families: VGG and ResNet. Experiments on MNIST, CIFAR-10 and Imagenette show that, with the proposed method, the training time of the models is more than halved without significantly impacting accuracy. The FLOPs reduction in the forward propagation during training ranges from 17.83% for VGG-11 to 83.74% for ResNet-152. As for the accuracy, the impact depends on the depth of the model and the decrease is between 0.26% and 2.38% for VGGs and between 0.4 and 3.2% for ResNets. These results demonstrate the effectiveness of the proposed technique in speeding up learning of CNNs. The technique will be especially useful in applications where fine-tuning or online training of convolutional models is required, for instance because data arrive sequentially.},
  archive      = {J_NCA},
  author       = {Cruciata, Giorgio and Cruciata, Luca and Lo Presti, Liliana and van Gemert, Jan and La Cascia, Marco},
  doi          = {10.1007/s00521-024-09592-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10839-10851},
  shortjournal = {Neural Comput. Appl.},
  title        = {Learn &amp; drop: Fast learning of cnns based on layer dropping},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A vision-based approach for detecting occluded objects in
construction sites. <em>NCA</em>, <em>36</em>(18), 10825–10837. (<a
href="https://doi.org/10.1007/s00521-024-09580-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety of workers and machinery during operations is a critical task in the construction sites. However, an inevitable circumstance in construction sites is the complex and dynamic environment, which often leads to occlusions. When detecting occluded objects in construction sites, general vision-based approaches tend to exhibit lower accuracy and may even miss detections, resulting in potential safety hazards. To handle this issue, this paper proposes a vision-based approach for detecting occluded objects in construction sites. Firstly, the proposed detection algorithm adopts the state-of-the-art YOLOv7 as its backbone. To enhance its capability in capturing contextual information of occluded objects, a novel channel attention mechanism is employed. Then, a design scheme for the detector head is provided by integrating a novel loss function Scylla-Intersection over Union (SIoU) and the non-maximum suppression (NMS) strategy. With the help of the loss function SIoU, the network can compute the loss values of occluded objects more accurately. To ensure that the network can select the right predicted box which closely aligns with the ground truth, the Euclidean distance is utilized as spatial penalty factor during the NMS stage. By implementing these two strategies, the proposed method can preserve both the category information and bounding boxes of occluded objects, which makes them possible to be detected. Finally, detailed experiments are done to verify the proposed method. Experimental results demonstrate that the proposed method has the potential for improving the detection accuracy. Moreover, it shows a better performance in detecting occluded objects in the dynamic construction sites compared to the existing baselines.},
  archive      = {J_NCA},
  author       = {Wang, Qian and Liu, Hongbin and Peng, Wei and Tian, Chenlu and Li, Chengdong},
  doi          = {10.1007/s00521-024-09580-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10825-10837},
  shortjournal = {Neural Comput. Appl.},
  title        = {A vision-based approach for detecting occluded objects in construction sites},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot transfer learning for wearable IMU-based human
activity recognition. <em>NCA</em>, <em>36</em>(18), 10811–10823. (<a
href="https://doi.org/10.1007/s00521-024-09645-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has proven to be highly effective for human activity recognition (HAR) when large amount of labelled data is available for the target task. However, training a deep learning model to generalize well on a new task with just-few observations of labelled data is an active area of research. In this paper, a novel few-shot transfer learning (FSTL) approach is proposed for classification of human activities using just few instances (shots) of the data obtained from a wearable system assembled to collect inertial sensor data for different human activities, performed by two users. First, a deep learning model is trained on a large publicly available HAR dataset. The model parameters of such a model are then fine-tuned using the Reptile algorithm to determine the optimal initial parameter set using which, the model will classify activities with just few-shots of data from the target task. The proposed FSTL approach yields an average classification accuracy of 74.86 ± 0.71% and 79.20 ± 1.05% for 3-way, 5-shot classification of new activities performed by a single user and same set of activities performed by a new user, respectively. When the pre-trained weights are used as the initial weights in the Reptile algorithm, the generalization ability of the model improves by about 10% for 3-way, 5-shot classification as compared to using few-shot learning without parameter transfer.},
  archive      = {J_NCA},
  author       = {Ganesha, H. S. and Gupta, Rinki and Gupta, Sindhu Hak and Rajan, Sreeraman},
  doi          = {10.1007/s00521-024-09645-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10811-10823},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot transfer learning for wearable IMU-based human activity recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic-specific multimodal relation learning for sentiment
analysis. <em>NCA</em>, <em>36</em>(18), 10799–10809. (<a
href="https://doi.org/10.1007/s00521-024-09644-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) seeks to understand human affection by leveraging signals from multiple modalities. A core challenge in MSA is the effective extraction of sentimental relations between these signals, as this can enhance a model’s consistency and accuracy. Existing studies typically use multimodal matching tasks to learn all semantic relations between modalities and then use downstream task to obtain the specific semantics from the multimodal representation. However, there are multiple semantics between modalities, such as action semantics, scene semantics and sentiment semantics. Relying solely on specific tasks to filter these semantics often results in a surplus of redundant information in the multimodal representation, potentially degrading MSA accuracy. In addition, the unimodal semantic expression is also important. In this paper, we propose a semantic-specific multimodal relation learning method to correlate modalities with specific semantics. Specifically, with smaller computational resources, we enhance unimodal sentimental semantic expression while diminishing non-sentimental semantic information in the multimodal representation. We conducted experiments on multimodal sentiment analysis datasets, CMU-MOSI, CMU-MOSEI and CH-SIMS. The results show that our method outperforms the current state-of-the-art. Notably, on the Acc2 evaluation metric, our approach exhibits an average accuracy improvement of 0.75 compared to the best baseline.},
  archive      = {J_NCA},
  author       = {Wu, Rui and Luo, YuanYi and Liu, JiaFeng and Tang, XiangLong},
  doi          = {10.1007/s00521-024-09644-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10799-10809},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic-specific multimodal relation learning for sentiment analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HayCAMJ: A new method to uncover the importance of main
filter for small objects in explainable artificial intelligence.
<em>NCA</em>, <em>36</em>(18), 10791–10798. (<a
href="https://doi.org/10.1007/s00521-024-09640-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual XAI methods enable experts to reveal importance maps highlighting intended classes over input images. This research paper presents a novel approach to visual explainable artificial intelligence (XAI) for object detection in deep learning models. The study investigates the effectiveness of activation maps generated by five different methods, namely GradCAM, GradCAM++, EigenCAM, HayCAM, and a newly proposed method called &quot;HayCAMJ&quot;, in detecting objects within images. The experiments were conducted on two datasets (Pascal VOC 2007 and Pascal VOC 2012) and three models (ResNet18, ResNet34, and MobileNet). Zero padding was applied to resize and center the objects due to the large objects in the images. The results show that HayCAMJ performs better than other XAI techniques in detecting small objects. This finding suggests that HayCAMJ has the potential to become a promising new approach for object detection in deep classification models.},
  archive      = {J_NCA},
  author       = {Ornek, Ahmet Haydar and Ceylan, Murat},
  doi          = {10.1007/s00521-024-09640-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10791-10798},
  shortjournal = {Neural Comput. Appl.},
  title        = {HayCAMJ: A new method to uncover the importance of main filter for small objects in explainable artificial intelligence},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved QT ınterval estimation using conditional generative
adversarial networks. <em>NCA</em>, <em>36</em>(18), 10777–10789. (<a
href="https://doi.org/10.1007/s00521-024-09639-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {QT interval carries essential information about ventricular depolarization and repolarization. Therefore, in many investigations, it is vital to determine the QT interval accurately and monitor the corresponding QT interval variations. This paper presents a novel implementation of the Generative Adversarial Networks (GAN) to predict the QT waveform interval from the electrocardiogram. The network then estimates the Q and T locations to determine the QT interval. The accuracy of the proposed method in measuring the QT interval was 94.10%. The procedure is evaluated against ground truth performed by expert physicians, and the limits of agreement are used as the measure of performance. The bias in the estimate of the Q locations was 2.92 ms, with 11.48 ms as an upper limit of agreement and − 5.65 ms as the lower limit. The bias in estimating the T location was 1.14 ms with an upper limit of 15.04 ms and a lower limit of − 12.79 ms. Moreover, the bias in the estimate of the QT interval was − 7.10 ms with an upper limit of 50.17 ms and a lower limit of − 64.38 ms. These limits of agreements are clinically acceptable and show that the estimate of the QT interval agrees with the expert’s annotations.},
  archive      = {J_NCA},
  author       = {Al−Zaben, Awad and Al−Abed, Mohammad},
  doi          = {10.1007/s00521-024-09639-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10777-10789},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved QT ınterval estimation using conditional generative adversarial networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic landslide detection and visualization by using
deep ensemble learning method. <em>NCA</em>, <em>36</em>(18),
10761–10776. (<a
href="https://doi.org/10.1007/s00521-024-09638-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid detection of damages occurring as a result of natural disasters is vital for emergency response. In recent years, remote sensing techniques have been commonly used for the automatic categorization and localization of such events using satellite images. Trained based on natural disaster images, a convolutional neural network (CNN) has been applied as a highly successful method, with its ability to reveal outstanding features. Studies aiming to detect target points obtained as a result of extracting visual features from natural images within these networks have achieved their goals. In this study, ensemble learning methods have been suggested as a means to develop the detection of landslide areas from landslide satellite images. Landslide image dataset has been trained for their categorization in CNN models and then they have been used again to localize landslide regions. While model predictions develop overall performance and status, different ensemble strategies have been used and integrated to reduce the sensitivity to prediction variance and training data. Class-selective relevance mapping (CRM) has been used to visualize individual CNN models and ensemble learned behaviors. As a result of the comparisons made based on mean average precision metrics and the criteria of intersection over union, model ensembles have proved to show higher localization performance than any other individual model.},
  archive      = {J_NCA},
  author       = {Hacıefendioğlu, Kemal and Varol, Nehir and Toğan, Vedat and Bahadır, Ümit and Kartal, Murat Emre},
  doi          = {10.1007/s00521-024-09638-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10761-10776},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic landslide detection and visualization by using deep ensemble learning method},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the resilience of error-prone computing
environments using a hybrid multi-objective optimization algorithm for
edge-centric cloud computing systems. <em>NCA</em>, <em>36</em>(18),
10733–10760. (<a
href="https://doi.org/10.1007/s00521-024-09636-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of advanced technologies like cloud and edge computing has facilitated efficient resource coordination, resulting in improved overall management and widespread applicability. Simultaneously, addressing energy consumption, reliability, and server and communication link failure rates has become a pressing research concern. To address this challenge, an advanced combined-decomposition whale optimization algorithm has been developed. This algorithm utilizes a unique combined-decomposition operator to identify nearly optimal server coalitions, enhancing the quality of service performance. Through a training process at various utilization levels, servers determine their optimal utilization for achieving the maximum energy-to-reliability trade-off ratio. Then, a head server with the highest optimal utilization leads each of these clusters of servers. Unlike other population-based clustering methods, this algorithm incorporates the whale optimization algorithm, extending its exploration and exploitation capabilities beyond other leading scheduling algorithms. The integration of these techniques successfully achieves the dual objective of balancing energy and reliability, addressing existing challenges, and ensuring optimal energy-reliability trade-offs. Simulation experiments using various evaluation metrics demonstrate that the proposed approach enhances energy efficiency by approximately 17 to 35% and reliability by 25 to 55%, all while meeting quality service standards.},
  archive      = {J_NCA},
  author       = {Khaleel, Mustafa Ibrahim},
  doi          = {10.1007/s00521-024-09636-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10733-10760},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing the resilience of error-prone computing environments using a hybrid multi-objective optimization algorithm for edge-centric cloud computing systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RaSTFormer: Region-aware spatiotemporal transformer for
visual homogenization recognition in short videos. <em>NCA</em>,
<em>36</em>(18), 10713–10732. (<a
href="https://doi.org/10.1007/s00521-024-09633-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surge in network traffic, the homogenization of short video content is becoming increasingly prominent, resulting in low-quality entertainment due to proliferation and infringement. Therefore, recognizing visual homogeneity in short videos is of great significance. Considering the extremely similar dynamic evolution in specific regions from intra and inter-frames, introducing region-aware attention is attractive to achieve homogenization recognition. Therefore, we propose a region-aware spatiotemporal Transformer (RaSTFormer) for visual homogenization recognition, including: (1) a region-aware Transformer encoder is designed to extract multi-region frame-level features from short videos; (2) a multi-layer spatiotemporal Transformer decoder is used to aggregate multi-region frame-level features, generating shot-level spatiotemporal features; and (3) measuring symmetric shot-level chamfer similarity to recognize visual homogeneous content. Specially, we established a real-world video homogenization dataset, BJUT-HCD, and conducted extensive experiments. The proposed RaSTFormer achieved the highest mean average precision (mAP) of 98.13% and a top-1 accuracy of 99.37%, outperforming SOTA methods. The results show that our method achieves competitive performance in visual homogenization recognition in short videos.},
  archive      = {J_NCA},
  author       = {Zhang, Shuying and Zhang, Jing and Zhang, Hui and Zhuo, Li},
  doi          = {10.1007/s00521-024-09633-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10713-10732},
  shortjournal = {Neural Comput. Appl.},
  title        = {RaSTFormer: Region-aware spatiotemporal transformer for visual homogenization recognition in short videos},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedSH: A federated learning framework for safety helmet
wearing detection. <em>NCA</em>, <em>36</em>(18), 10699–10712. (<a
href="https://doi.org/10.1007/s00521-024-09632-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety helmet wearing detection based on video surveillance is an important means of safety monitoring in many industrial scenes. The training of safety helmet wearing detection models requires large and well-labeled dataset. However, the incidence of security violations is relatively low, which results in insufficient samples for training deep detection models. Safety helmet wearing detection is a common requirement in many scenarios such as construction sites, substations, and factory workshops. Aggregating data from multiple companies for model training would improve the performance of the detection model. Traditional centralized training methods are not feasible because aggregating data in centralized locations (such as the cloud) can raise concerns about data privacy and the high cost of data communication and storage. This paper proposes FedSH, a novel cloud-edge-based federated learning framework, which learns a shared global safety helmet wearing detection model in the cloud from multiple companies at the network edges and achieves data privacy protection by keeping company data locally. In addition, this paper designs reweighting mechanisms and applies transfer learning to address class imbalance and non-IID problems in the training data, so as to obtain an accurate and personalized detection model. Extensive experiments have been conducted on real surveillance video datasets. The experimental results demonstrate that FedSH outperforms the existing widely used federated learning methods with an accuracy improvement of at least 3.4%; the reduction in accuracy is within the range of 5% compared with centralized learning methods. FedSH effectively achieves a good balance between model performance, privacy protection, and communication efficiency.},
  archive      = {J_NCA},
  author       = {Huang, Zhiqing and Zhang, Xiao and Zhang, Yanxin and Zhang, Yusen},
  doi          = {10.1007/s00521-024-09632-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10699-10712},
  shortjournal = {Neural Comput. Appl.},
  title        = {FedSH: A federated learning framework for safety helmet wearing detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human action recognition using multi-stream attention-based
deep networks with heterogeneous data from overlapping sub-actions.
<em>NCA</em>, <em>36</em>(18), 10681–10697. (<a
href="https://doi.org/10.1007/s00521-024-09630-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based Human Action Recognition is difficult owing to the variations in the same action performed by various people, the temporal variations in actions, and the difference in viewing angles. Researchers have recently adopted multi-modal visual data fusion strategies to address the limitations of single-modality methodologies. Many researchers strive to produce more discriminative features because most existing techniques’ success relies on feature representation in the data modality under consideration. Human action consists of several sub-actions whose duration vary between individuals. This paper proposes a multifarious learning framework employing action data in depth and skeleton formats. Firstly, a novel action representation named Multiple Sub-action Enhanced Depth Motion Map (MS-EDMM), integrating depth features from overlapping sub-actions, is proposed. Secondly, an efficient method is introduced for extracting spatio-temporal features from skeleton data. This is achieved by dividing the skeleton sequence into sub-actions and summarizing skeleton joint information for five distinct human body regions. Next, a multi-stream deep learning model with Attention-guided CNN and residual LSTM is proposed for classification, followed by several score fusion operations to reap the benefits of streams trained with multiple data types. The proposed method demonstrated a superior performance of 1.62% over an existing method that utilized skeleton and depth data, achieving an accuracy 89.76% on a single-view UTD-MHAD dataset. Furthermore, on the multi-view NTU RGB+D dataset demonstrated encouraging performance with an accuracy of 89.75% in cross-view and 83.8% in cross-subject evaluations.},
  archive      = {J_NCA},
  author       = {M, Rashmi and Guddeti, Ram Mohana Reddy},
  doi          = {10.1007/s00521-024-09630-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10681-10697},
  shortjournal = {Neural Comput. Appl.},
  title        = {Human action recognition using multi-stream attention-based deep networks with heterogeneous data from overlapping sub-actions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discriminative latent semantics-preserving similarity
embedding hashing for cross-modal retrieval. <em>NCA</em>,
<em>36</em>(18), 10655–10680. (<a
href="https://doi.org/10.1007/s00521-024-09616-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a significant increase in interest in cross-modal hashing technology. For hash code learning, most previous supervision methods use label information to create a similarity matrix in a straightforward manner. However, there are still the following challenges: (1) The asymmetric similarity matrix method only considers the similarity of labels, and the discriminant constraint in Hamming space is ignored; (2) there are optimization errors between the cross-modal semantic correlation of the Hamming space and the nonlinearity of the feature space; and (3) the cross-modal hash matrix is in a dynamic state during the optimization process, and the hash code is easily disturbed and there is bit uncertainty. To this end, we propose the Discriminative Latent Semantics-preserving Similarity Embedding Cross-modal Hashing (DLSSECH) method. Specifically, to reduce the quantization error, we introduce a non-asymmetric similarity decomposition based on orthogonal rotation bias. It can decompose the bitwise correlation of the learned hash code to capture more discriminative semantic information and compact hash code. In addition, to capture the cross-modal semantic correlation of nonlinear feature transformation and reduce quantization error, we propose the latent correlation error matrices based on orthogonal rotation decomposition. The model maintains the maximum difference in semantic dependencies between the projected data and its semantic representation. Finally, we use a sparse common hash matrix and non-asymmetric similarity decomposition factors to solve the uncertainty of the dynamic changes of the hash code. The effectiveness of DLSSECH has demonstrated through experiments on four cross-modal retrieval datasets, where it outperformed some state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Chen, Yongfeng and Tan, Junpeng and Yang, Zhijing and Cheng, Yongqiang and Chen, Ruihan},
  doi          = {10.1007/s00521-024-09616-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10655-10680},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discriminative latent semantics-preserving similarity embedding hashing for cross-modal retrieval},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Operational wind and turbulence nowcasting capability for
advanced air mobility. <em>NCA</em>, <em>36</em>(18), 10637–10654. (<a
href="https://doi.org/10.1007/s00521-024-09614-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study introduces “WindAware”, a wind and turbulence prediction system that provides nowcasts of wind and turbulence parameters every 5 min up to 6 h over a predetermined airway over Chicago, Illinois, USA, based on 100 m high-resolution simulations (HRSs). This system is a long short-term memory-based recurrent neural network (LSTM-RNN) that uses existing ground-based wind data to provide nowcasts (forecasts up to 6 h every 5 min) of wind speed, wind direction, wind gust, and eddy dissipation rate to support the Uncrewed Aircraft Systems (UASs) safe integration into the National Airspace System (NAS). These HRSs are validated using both ground-based measurements over airports and upper-air radiosonde observations and their skill is illustrated during lake-breeze events. A reasonable agreement is found between measured and simulated winds especially when the boundary layer is convective, but the timing and inland penetration of lake-breeze events are overall slightly misrepresented. The WindAware model is compared with the classic multilayer perceptron (MLP) and the eXtreme Gradient Boosting (XGBoost) models. It is demonstrated by comparison to high-resolution simulations that WindAware provides more accurate predictions than the MLP over the 6 h lead times and has almost similar performance as the XGBoost model although the XGBoost’s training is the fastest using its parallelized implementation. WindAware also has higher prediction errors when validated against lake-breeze events data due to their under-representation in the training dataset.},
  archive      = {J_NCA},
  author       = {Chrit, Mounir and Majdi, Marwa},
  doi          = {10.1007/s00521-024-09614-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10637-10654},
  shortjournal = {Neural Comput. Appl.},
  title        = {Operational wind and turbulence nowcasting capability for advanced air mobility},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient economic operation based on load dispatch of power
systems using a leader white shark optimization algorithm. <em>NCA</em>,
<em>36</em>(18), 10613–10635. (<a
href="https://doi.org/10.1007/s00521-024-09612-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes the use of a leader white shark optimizer (LWSO) with the aim of improving the exploitation of the conventional white shark optimizer (WSO) and solving the economic operation-based load dispatch (ELD) problem. The ELD problem is a crucial aspect of power system operation, involving the allocation of power generation resources to meet the demand while minimizing operational costs. The proposed approach aims to enhance the performance and efficiency of the WSO by introducing a leadership mechanism within the optimization process, which aids in more effectively navigating the complex ELD solution space. The LWSO achieves increased exploitation by utilizing a leader-based mutation selection throughout each generation of white sharks. The efficacy of the proposed algorithm is tested on 13 engineer benchmarks non-convex optimization problems from CEC 2020 and compared with recent metaheuristic algorithms such as dung beetle optimizer (DBO), conventional WSO, fox optimizer (FOX), and moth-flame optimization (MFO) algorithms. The LWSO is also used to address the ELD problem in different case studies (6 units, 10 units, 11 units, and 40 units), with 20 separate runs using the proposed LWSO and other competitive algorithms being statistically assessed to demonstrate its effectiveness. The results show that the LWSO outperforms other metaheuristic algorithms, achieving the best solution for the benchmarks and the minimum fuel cost for the ELD problem. Additionally, statistical tests are conducted to validate the competitiveness of the LWSO algorithm.},
  archive      = {J_NCA},
  author       = {Hassan, Mohamed H. and Kamel, Salah and Selim, Ali and Shaheen, Abdullah and Yu, Juan and El-Sehiemy, Ragab},
  doi          = {10.1007/s00521-024-09612-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10613-10635},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient economic operation based on load dispatch of power systems using a leader white shark optimization algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient CNN-based disaster events classification using
UAV-aided images for emergency response application. <em>NCA</em>,
<em>36</em>(18), 10599–10612. (<a
href="https://doi.org/10.1007/s00521-024-09610-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural disasters can be unpredictable and catastrophic. Even after the event, the repercussions are prolonged due to the incompetence of disaster management strategies. To mitigate the effects of a natural hazard, disaster management teams have to rapidly come forth with innovative plans of action. To contain the damage that a disaster causes, the response time, and preparedness of a disaster management team is crucial. Having a forewarning about the nature of the disaster can prove to be beneficial for the management team. Remote/unreachable areas such as deep parts of the forests, far-flung rural areas, oceans and other hard to reach locations are at a higher risk of receiving poorer aid and response due to the lack of communication and connectivity with the rest of the world. Our paper provides a solution for this particular problem by suggesting UAV/Drones for surveillance and monitoring in these inaccessible, disaster struck areas. The drones not only monitor the situation but constantly click pictures and send them to a base station, where the images are used to collect insights about the type of disaster that has to be dealt with. The paper proposes a deep learning model based on feature concatenation for classification of disasters which can be deployed at the base station, and can receive data in the form of images from a UAV/drone hovering over the affected place. The proposed model is efficient and able to achieve a higher accuracy as compared to the leading CNN models and closely related recent works as well.},
  archive      = {J_NCA},
  author       = {Bashir, Munzir Hubiba and Ahmad, Musheer and Rizvi, Danish Raza and El-Latif, Ahmed A. Abd},
  doi          = {10.1007/s00521-024-09610-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10599-10612},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient CNN-based disaster events classification using UAV-aided images for emergency response application},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global scale solar energy harnessing: An advanced
intra-hourly diffuse solar irradiance predicting framework for solar
energy projects. <em>NCA</em>, <em>36</em>(18), 10585–10598. (<a
href="https://doi.org/10.1007/s00521-024-09608-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffuse horizontal irradiance (DHI) forecasts are critical for adopting solar photovoltaic technology. Yet, they can lack reliability given the limited and uncertain meteorological data available for desert areas. This research develops a new sine cosine dipper throated optimization (SCDTO) technique, targeting DHI prediction even given such data constraints. SCDTO uniquely hybridizes sine cosine metaheuristics, adept at exploration, with dipper throat optimization, providing focused exploitation. This hybridization aims to create a robust ensemble model capable of delivering reliable DHI predictions despite climatic uncertainty. The ensemble model, employing various input combinations, was rigorously evaluated across multiple meteorological stations. The SCDTO algorithm exhibited remarkable performance improvements, yielding substantial reductions exceeding 93% in root mean squared error and 98% in mean absolute error at key stations in Morocco, including Tan-Tan, Zagora, Erfoud, and Oujda. Comparative analyses against established optimization algorithms consistently underscored the superior predictive capabilities of SCDTO. Visualizations, including box plots and histograms, demonstrated SCDTO’s efficacy in minimizing prediction errors, particularly for Tan-Tan, Zagora, and Erfoud stations. Also, statistical validation through one-way analysis of variance (ANOVA) further affirmed the significance of the proposed SCDTO method. Therefore, this hybrid metaheuristic optimization enables more accurate DHI predictions from limited meteorological data.},
  archive      = {J_NCA},
  author       = {El-kenawy, El-Sayed M. and Bailek, Nadjem and Bouchouicha, Kada and Zerouali, Bilel and Hassan, Muhammed A. and Kuriqi, Alban and Jamil, Basharat and Colak, Ilhami and Khalil, Adel and Ibrahim, Abdelhameed},
  doi          = {10.1007/s00521-024-09608-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10585-10598},
  shortjournal = {Neural Comput. Appl.},
  title        = {Global scale solar energy harnessing: An advanced intra-hourly diffuse solar irradiance predicting framework for solar energy projects},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Fusion-s2igan: An efficient and effective single-stage
framework for speech-to-image generation. <em>NCA</em>, <em>36</em>(18),
10567–10584. (<a
href="https://doi.org/10.1007/s00521-024-09618-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of a speech-to-image transform is to produce a photo-realistic picture directly from a speech signal. Current approaches are based on a stacked modular framework that suffers from three vital issues: (1) Training separate networks is time-consuming, inefficient and the convergence of the final generative model depends on the previous generators; (2) The quality of precursor images is ignored; (3) Multiple discriminator networks need to be trained. We propose an efficient and effective single-stage framework called Fusion-S2iGan to yield perceptually plausible and semantically consistent image samples on the basis of spoken descriptions. Fusion-S2iGan introduces a visual+speech fusion module (VSFM), with a pixel-attention module (PAM), a speech-modulation module (SMM) and a weighted-fusion module (WFM), to inject the speech embedding from a speech encoder into the generator while improving the quality of synthesized pictures. The PAM module models the semantic affinities between pixel regions and by assigning larger weights to significant locations. The VSFM module adopts SMM to modulate visual feature maps using fine-grained linguistic cues present in the speech vector. Subsequently, the weighted-fusion model (WFM) captures the semantic importance of the image-attention mask and the speech-modulation module at the level of the channels, in an adaptive manner. Fusion-S2iGan spreads the bimodal information over all layers of the generator network to reinforce the visual feature maps at various hierarchical levels in the architecture. A series of experiments is conducted on four benchmark data sets: CUB birds, Oxford-102, Flickr8k and Places-subset. Results demonstrate the superiority of Fusion-S2iGan compared to the state-of-the-art models with a multi-stage architecture and a performance level that is close to traditional text-to-image approaches.},
  archive      = {J_NCA},
  author       = {Zhang, Zhenxing and Schomaker, Lambert},
  doi          = {10.1007/s00521-024-09618-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10567-10584},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fusion-s2igan: An efficient and effective single-stage framework for speech-to-image generation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive modelling of cohesion and friction angle of soil
using gene expression programming: A step towards smart and sustainable
construction. <em>NCA</em>, <em>36</em>(18), 10545–10566. (<a
href="https://doi.org/10.1007/s00521-024-09626-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve smart and sustainable construction goals, machine learning (ML) techniques can serve as a cost-effective and efficient substitute for labour-intensive, laboratory, or in situ approaches in parameter estimation essential for infrastructure design. Of these, soil&#39;s shear strength parameters, notably cohesion (c) and friction angle (φ), typically govern the design of geo-structures. For quick and cost-effective estimation of these parameters, the earlier studies proposed ML-based predictive models that were less practical and accurate or consider an excessive number of input variables. To minimize these limitations, our study proposes new models of c and φ using gene expression programming (GEP) based on readily available soil attributes such as sand content (S), depth (D), specific gravity (Gs), liquid limit (LL), plastic limit (PL), and fine content (FC). The newly proposed models show excellent accuracy as the values of R2, RMSE (root mean square error), MAE (mean absolute error), RSE (relative standard error) for c-predictive model were 0.984, 1.13, 0.878, 0.017, respectively, and were 0.927, 1.123, 0.922, 0.072, respectively, for φ-predictive model. Through sensitivity analysis, FC and LL emerged as the most critical parameters influencing c, while Gs and PL proved sensitive for determining φ. In comparison with existing models, the c-predictive model displays R2 enhancements of 11.84–45.87% and RMSE improvements of 65.9–92.03%, while the φ-predictive model showcases R2 gains of 13.16–23.75% and RMSE improvements of 58.79–69.29%. By integrating predictive prowess with sustainable and smart construction principles, our study plots a realistic course for efficient geo-structural design.},
  archive      = {J_NCA},
  author       = {Nawaz, Muhammad Naqeeb and Alshameri, Badee and Maqsood, Zain and Hassan, Waqas},
  doi          = {10.1007/s00521-024-09626-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10545-10566},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive modelling of cohesion and friction angle of soil using gene expression programming: A step towards smart and sustainable construction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MC-MIL: Video surveillance anomaly detection with
multi-instance learning and multiple overlapped cameras. <em>NCA</em>,
<em>36</em>(18), 10527–10543. (<a
href="https://doi.org/10.1007/s00521-024-09611-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection approaches have limiting aspects regarding the representativeness of the information since the video data is captured from a single perspective and may not distinguish all relevant aspects of the scene. The lack of sufficient labeled data is also a challenging aspect of building video anomaly detection approaches. Although multiple instance learning (MIL) has been explored extensively in the weakly supervised video anomaly detection (WS-VAD) literature since it is less hungry for labeled data, there are no studies that exploit multiple overlapping camera views to provide wider representativeness of vision data under MIL assumption. In this work, we show the performance of the video anomaly detection task can be improved by using multiple cameras to capture spatiotemporal information from different perspectives. We propose the approach MC-MIL (Video Anomaly Detection with Multiple Overlapped Cameras and Multiple Instance Learning) framework, which consists of a training scheme with multiple cameras under multiple instance learning for video anomaly detection. We specialize our proposed framework for the two-camera case as a proof of concept for performance evaluation. Due to the lack of datasets for this task, we relabeled the multiple-camera PETS-2009 benchmark dataset for the anomaly detection task from multiple overlapped camera views to evaluate the MC-MIL algorithm. The result shows a significant performance improvement in the AUC ROC score compared to the single-camera configuration and with the literature.},
  archive      = {J_NCA},
  author       = {Pereira, Silas S. L. and Maia, José Everardo Bessa},
  doi          = {10.1007/s00521-024-09611-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10527-10543},
  shortjournal = {Neural Comput. Appl.},
  title        = {MC-MIL: Video surveillance anomaly detection with multi-instance learning and multiple overlapped cameras},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimum sensors allocation for drones multi-target tracking
under complex environment using improved prairie dog optimization.
<em>NCA</em>, <em>36</em>(18), 10501–10525. (<a
href="https://doi.org/10.1007/s00521-024-09602-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel hybrid optimization method to solve the resource allocation problem for multi-target multi-sensor tracking of drones. This hybrid approach, the Improved Prairie Dog Optimization Algorithm (IPDOA) with the Genetic Algorithm (GA), utilizes the strengths of both algorithms to improve the overall optimization performance. The goal is to select a set of sensors based on norms of weighted distances cost function. The norms are the Euclidean distance and the Mahalanobis distance between the drone location and the sensors. The second one depends on the predicted covariance of the tracker. The Extended Kalman Filter (EKF) is used for state estimation with proper clutter and detection models. Since we use Multi-objects to track, the Joint Probability Distribution Function (JPDA) estimates the best measurement values with a preset gating threshold. The goal is to find a sensor or minimum set of sensors that would be enough to generate high-quality tracking based on optimum resource allocation. In the experimentation simulated with Stone Soup, one radar among five radars is selected at every time step of 50-time steps for 200 tracks distributed over 20 different ground truths. The proposed IPDOA provided optimum solutions for this complex problem. The obtained solution is an optimum offline solution that is used to select one or more sensors for any future flights within the vicinity of the 5 radars. Environment and conditions are assumed to be similar in future drone flights within the radars’ defined zone. The IPDOA performance was compared with the other 8 metaheuristic optimization algorithms and the testing showed its superiority over those techniques for solving this complex problem. The proposed simulated model can find the most relevant sensor(s) capable of generating the best quality tracks based on weighted distance criteria (Euclidean and Mahalanobis ). That would cut down the cost of operating extra sensors and then it would be possible to move them to other vicinity.},
  archive      = {J_NCA},
  author       = {Zitar, Raed Abu and Alhadhrami, Esra and Abualigah, Laith and Barbaresco, Frederic and Seghrouchni, Amal ElFallah},
  doi          = {10.1007/s00521-024-09602-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10501-10525},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimum sensors allocation for drones multi-target tracking under complex environment using improved prairie dog optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SHuffled ant lion optimization approach with an
exponentially weighted random walk strategy. <em>NCA</em>,
<em>36</em>(18), 10475–10499. (<a
href="https://doi.org/10.1007/s00521-024-09566-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant Lion Optimization (ALO) method is one of the population-based nature-inspired optimization algorithms which mimics the hunting strategy of antlions. ALO is successfully employed for solving many complicated optimization problems. However, it is reported in the literature that the original ALO has some limitations such as the requirement of high number of iterations and possibility of trapping to local optimum solutions, especially for complex or large-scale problems. For this purpose, the SHuffled Ant Lion Optimization (SHALO) approach is proposed by conducting two improvements in the original ALO. Performance of the proposed SHALO approach is evaluated by solving some unconstrained and constrained problems for different conditions. Furthermore, the identified results are statistically compared with the ones obtained by using the original ALO, two improved ALOs which are the self-adaptive ALO (saALO) and the exponentially weighted ALO (EALO), Genetic Algorithm (GA), and Particle Swarm Optimization (PSO) approaches. Identified results indicated that the proposed SHALO approach significantly improves the solution accuracy with a mean success rate of 76% in terms of finding the global or near-global optimum solutions and provides better results than ALO (22%), saALO (25%), EALO (14%), GA (28%), and PSO (49%) approaches for the same conditions.},
  archive      = {J_NCA},
  author       = {Durgut, Pinar G. and Tozak, Mirac Bugse and Ayvaz, M. Tamer},
  doi          = {10.1007/s00521-024-09566-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10475-10499},
  shortjournal = {Neural Comput. Appl.},
  title        = {SHuffled ant lion optimization approach with an exponentially weighted random walk strategy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning model for early prediction of material
fracture in tensile testing. <em>NCA</em>, <em>36</em>(18), 10461–10474.
(<a href="https://doi.org/10.1007/s00521-024-09641-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensile testing (aka tension testing) is a widely employed mechanical testing technique for analyzing materials’ properties and behavior under applied stress. Tensile testing plays a pivotal role in helping engineers to make informed decision about material selection and usage. Despite its importance, there is a limited numbers of studies that explored the potential of AI techniques for real time monitoring and material behavior prediction in tensile testing. To this end, this work presents a deep learning model designed to predict the material’s condition throughout tensile testing and provide an early warning prior to fracture. By leveraging a comprehensive dataset of tension test video samples, the proposed model utilizes both convolution and recurrent neural networks to extract pertinent spatial and temporal visual features, thereby predicting the frames at which material deformation and fracture occur. The evaluation results of our research showed that the proposed model achieved a predictive ability with an F1-score of 97%, on average. The implications of our research are significant for industries and researchers in the field of materials science and engineering. By accurately predicting material status, our model enables autonomous, real time analysis of material behavior during tensile testing, leading to better time and cost efficiency in various applications.},
  archive      = {J_NCA},
  author       = {Jubair, Fahed and Alhamayel, Ahmad and Aljaiose, Raed and Darabkh, Khalid A.},
  doi          = {10.1007/s00521-024-09641-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10461-10474},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning model for early prediction of material fracture in tensile testing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DeepCraftFuse: Visual and deeply-learnable features work
better together for esophageal cancer detection in patients with
barrett’s esophagus. <em>NCA</em>, <em>36</em>(18), 10445–10459. (<a
href="https://doi.org/10.1007/s00521-024-09615-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Limitations in computer-assisted diagnosis include lack of labeled data and inability to model the relation between what experts see and what computers learn. Even though artificial intelligence and machine learning have demonstrated remarkable performances in medical image computing, their accountability and transparency level must be improved to transfer this success into clinical practice. The reliability of machine learning decisions must be explained and interpreted, especially for supporting the medical diagnosis. While deep learning techniques are broad so that unseen information might help learn patterns of interest, human insights to describe objects of interest help in decision-making. This paper proposes a novel approach, DeepCraftFuse, to address the challenge of combining information provided by deep networks with visual-based features to significantly enhance the correct identification of cancerous tissues in patients affected with Barrett’s esophagus (BE). We demonstrate that DeepCraftFuse outperforms state-of-the-art techniques on private and public datasets, reaching results of around 95% when distinguishing patients affected by BE that is either positive or negative to esophageal cancer.},
  archive      = {J_NCA},
  author       = {Souza Jr., Luis A. and Pacheco, André G. C. and Passos, Leandro A. and Santana, Marcos C. S. and Mendel, Robert and Ebigbo, Alanna and Probst, Andreas and Messmann, Helmut and Palm, Christoph and Papa, João Paulo},
  doi          = {10.1007/s00521-024-09615-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10445-10459},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepCraftFuse: Visual and deeply-learnable features work better together for esophageal cancer detection in patients with barrett’s esophagus},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). E-SDNN: Encoder-stacked deep neural networks for DDOS attack
detection. <em>NCA</em>, <em>36</em>(18), 10431–10443. (<a
href="https://doi.org/10.1007/s00521-024-09622-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing reliance on internet-based services has heightened the vulnerability of network infrastructure to cyberattacks, particularly distributed denial of service (DDoS) attacks. These attacks can cause severe disruptions and significant financial losses. Early detection of malicious traffic is crucial in effectively combating such threats. This paper presents an innovative approach called the Encoder-Stacked deep neural networks (E-SDNN) model, which leverages Stacked/bagged multi-layer perceptrons (MLP) for accurate DDoS attack detection. The proposed method employs an encoder to select pertinent features from a preprocessed dataset, enabling precise attack detection. Extensive experiments were conducted on benchmark cybersecurity datasets, namely CICDS2017 and CICDDoS2019, encompassing various DDoS attack scenarios. The experimental results demonstrate the superiority of the E-SDNN model compared to state-of-the-art methods. The proposed E-SDNN model achieved an impressive overall accuracy rate of 99.94% and 98.86% for CICDDS2017 and CICDDoS2019, respectively.},
  archive      = {J_NCA},
  author       = {Benmohamed, Emna and Thaljaoui, Adel and Elkhediri, Salim and Aladhadh, Suliman and Alohali, Mansor},
  doi          = {10.1007/s00521-024-09622-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10431-10443},
  shortjournal = {Neural Comput. Appl.},
  title        = {E-SDNN: Encoder-stacked deep neural networks for DDOS attack detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online sequential extreme learning machine approach for
breast cancer diagnosis. <em>NCA</em>, <em>36</em>(18), 10413–10429. (<a
href="https://doi.org/10.1007/s00521-024-09617-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilisation of DM (Data Mining) and ML (Machine Learning) approaches in the BC (Breast Cancer) diagnosis has recently gained a lot of consideration. However, most of these works still need enhancement since either they were assessed utilising insufficient evaluation-metrics, or they weren’t statistically-assessed, or both. Lately, one-of-the-most effective and well-known ML approaches is OSELM (Online Sequential Extreme Learning Machine), it has seen as an efficient and reputable technique for classifying-data, however it has not been implemented in BC diagnosis problem. Consequently, this research proposes the OSELM approach in-order-to enhance the rate of accuracy for the BC diagnosis. The OSELM technique has the ability to (a) capability to be applied on both (multi-class and binary) classification, (b) prevent overfitting, as well as (c) It has a comparable ability to kernel-based SVM (Support Vector Machine) and operates with a neural-network-structure. In this research, two different BC datasets (WDBC (Wisconsin Diagnostic Breast Cancer) and WBCD (Wisconsin Breast Cancer Database)) were utilised to evaluate the OSELM approach performance. The experiments outcomes have revealed the outstanding-performance of the proposed OSELM approach, which attained an average of precision 94.09%, recall 95.57%, accuracy 96.13%, G-Mean 94.82%, F-Measure 94.80%, specificity 96.51%, and MCC 91.76% using WDBC dataset. Besides, attained an average of precision 95.08%, recall 98.89%, accuracy 97.89%, G-Mean 96.96%, F-Measure 96.93%, specificity 97.41%, and MCC 95.39% using WBCD dataset. This indicates that the OSELM approach is a reliable technique for the BC diagnosis and might be suitable for solving other-applications-related issues in the sector of healthcare. Besides, it can serve as a valuable decision-support tool for oncologists, providing additional information and insights to aid in their diagnoses and treatment plans.},
  archive      = {J_NCA},
  author       = {Albadr, Musatafa Abbas Abbood and AL-Dhief, Fahad Taha and Man, Li and Arram, Anas and Abbas, Ali Hashim and Homod, Raad Z.},
  doi          = {10.1007/s00521-024-09617-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10413-10429},
  shortjournal = {Neural Comput. Appl.},
  title        = {Online sequential extreme learning machine approach for breast cancer diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Phased progressive learning with
coupling-regulation-imbalance loss for imbalanced data classification.
<em>NCA</em>, <em>36</em>(18), 10411. (<a
href="https://doi.org/10.1007/s00521-024-09806-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Xu, Liang and Cheng, Yi and Zhang, Fan and Wu, Bingxuan and Shao, Pengfei and Liu, Peng and Shen, Shuwei and Yao, Peng and Xu, Ronald X.},
  doi          = {10.1007/s00521-024-09806-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10411},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Phased progressive learning with coupling-regulation-imbalance loss for imbalanced data classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Phased progressive learning with
coupling-regulation-imbalance loss for imbalanced data classification.
<em>NCA</em>, <em>36</em>(18), 10391–10410. (<a
href="https://doi.org/10.1007/s00521-024-09483-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks often perform poorly when faced with datasets that suffer from quantity imbalances and classification difficulties. Despite advances in the field, existing two-stage approaches still exhibit dataset bias or domain shift. To counter this, a phased progressive learning schedule has been proposed that gradually shifts the emphasis from representation learning to training the upper classifier. This approach is particularly beneficial for datasets with larger imbalances or fewer samples. Another new method a coupling-regulation-imbalance loss function is proposed, which combines three parts: a correction term, focal loss, and LDAM loss. This loss is effective in addressing quantity imbalances and outliers, while regulating the focus of attention on samples with varying classification difficulties. These approaches have yielded satisfactory results on several benchmark datasets, including Imbalanced CIFAR10, Imbalanced CIFAR100, ImageNet-LT, and iNaturalist 2018, and can be easily generalized to other imbalanced classification models. Deep convolutional neural networks often perform poorly when faced with datasets that suffer from quantity imbalances and classification difficulties. Despite advances in the field, existing two-stage approaches still exhibit dataset bias or domain shift. To counter this, a phased progressive learning schedule has been proposed that gradually shifts the emphasis from representation learning to training the upper classifier. This approach is particularly beneficial for datasets with larger imbalances or fewer samples. Another new method a coupling-regulation-imbalance loss function is proposed, which combines three parts: a correction term, focal loss, and LDAM loss. This loss is effective in addressing quantity imbalances and outliers, while regulating the focus of attention on samples with varying classification difficulties. These approaches have yielded satisfactory results on several benchmark datasets, including Imbalanced CIFAR10, Imbalanced CIFAR100, ImageNet-LT, and iNaturalist 2018, and can be easily generalized to other imbalanced classification models.},
  archive      = {J_NCA},
  author       = {Xu, Liang and Cheng, Yi and Zhang, Fan and Wu, Bingxuan and Shao, Pengfei and Liu, Peng and Shen, Shuwei and Yao, Peng and Xu, Ronald X.},
  doi          = {10.1007/s00521-024-09483-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {18},
  pages        = {10391-10410},
  shortjournal = {Neural Comput. Appl.},
  title        = {Phased progressive learning with coupling-regulation-imbalance loss for imbalanced data classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A streak detection approach for
comprehensive two-dimensional gas chromatography based on image
analysis. <em>NCA</em>, <em>36</em>(17), 10389. (<a
href="https://doi.org/10.1007/s00521-024-09878-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Li, Bo and Reichenbach, Stephen E. and Tao, Qingping and Zhu, Rongbo},
  doi          = {10.1007/s00521-024-09878-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10389},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A streak detection approach for comprehensive two-dimensional gas chromatography based on image analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Grid quorum-based spatial coverage for IoT
smart agriculture monitoring using enhanced multi-verse optimizer.
<em>NCA</em>, <em>36</em>(17), 10387. (<a
href="https://doi.org/10.1007/s00521-024-09877-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Abdel-Basset, Mohamed and Shawky, Laila A. and Eldrandaly, Khalid},
  doi          = {10.1007/s00521-024-09877-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10387},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Grid quorum-based spatial coverage for IoT smart agriculture monitoring using enhanced multi-verse optimizer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Securing e-health records using keyless
signature infrastructure blockchain technology in the cloud.
<em>NCA</em>, <em>36</em>(17), 10385. (<a
href="https://doi.org/10.1007/s00521-024-09876-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Nagasubramanian, Gayathri and Sakthivel, Rakesh Kumar and Patan, Rizwan and Gandomi, Amir H. and Sankayya, Muthuramalingam and Balusamy, Balamurugan},
  doi          = {10.1007/s00521-024-09876-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10385},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Securing e-health records using keyless signature infrastructure blockchain technology in the cloud},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Automatic detection of lung cancer from
biomedical data set using discrete AdaBoost optimized ensemble learning
generalized neural networks. <em>NCA</em>, <em>36</em>(17), 10383. (<a
href="https://doi.org/10.1007/s00521-024-09875-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Shakeel, P. Mohamed and Tolba, Amr and Al-Makhadmeh, Zafer and Jaber, Mustafa Musa},
  doi          = {10.1007/s00521-024-09875-9},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10383},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Automatic detection of lung cancer from biomedical data set using discrete AdaBoost optimized ensemble learning generalized neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: An adaptive QoS computation for medical
data processing in intelligent healthcare applications. <em>NCA</em>,
<em>36</em>(17), 10381. (<a
href="https://doi.org/10.1007/s00521-024-09874-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Sodhro, Ali Hassan and Malokani, Abdul Sattar and Sodhro, Gul Hassan and Muzammall, Muhammad and Zongwei, Luo},
  doi          = {10.1007/s00521-024-09874-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10381},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: An adaptive QoS computation for medical data processing in intelligent healthcare applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Classification of stroke disease using
machine learning algorithms. <em>NCA</em>, <em>36</em>(17), 10379. (<a
href="https://doi.org/10.1007/s00521-024-09844-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Govindarajan, Priya and Soundarapandian, Ravichandran Kattur and Gandomi, Amir H. and Patan, Rizwan and Jayaraman, Premaladha and Manikandan, Ramachandran},
  doi          = {10.1007/s00521-024-09844-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10379},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Classification of stroke disease using machine learning algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic decision-making framework for benchmarking
brain–computer interface applications: A fuzzy-weighted
zero-inconsistency method for consistent weights and VIKOR for stable
rank. <em>NCA</em>, <em>36</em>(17), 10355–10378. (<a
href="https://doi.org/10.1007/s00521-024-09605-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benchmarking brain–computer interface (BCI) applications, considering all available smart training environment (STE) criteria, is a challenging task due to the following issues: inconsistent weights, static ranks and ranking stability measurements. Therefore, this study aims to develop a dynamic decision-making framework for benchmarking BCI applications based on STE criteria through three integrated phases. In the first phase, the adaptivity of the decision matrix is identified concerning two dimensions: 27 BCI applications as alternatives and 10 STE criteria. In the second phase, the consistency of weights is evaluated and constructed to each STE criterion via the fuzzy-weighted zero-inconsistency (FWZIC) method and the VIekriterijumsko KOmpromisno Rangiranje (VIKOR) method for benchmarking the BCI applications. In the third phase, four sensitive scenarios are developed for measuring the consistency of the STE criteria’s weights and the ranking performance of the BCI applications. The experimental result shows that the ‘ease of use’ STE criterion obtains a high-affected weight with a value of 0.13, while other criteria, augmented reality, hybrid and desktop use (stationary), obtain less weight with a 0.075 value. Additionally, BCI applications A5 and A6 are robust and stable among the others based on the consistency of weights concerning the four scenarios, and they are further candidates to be deployed in real-life applications. The overall ranking results are stable and less affected when applied to the four sensitive scenarios due to the robustness of the integrated FWZIC-VIKOR method of the proposed dynamic framework. The outcome of this framework is objectively validated in terms of five groups, and the ranking results are reliable and the closest to the decision-makers&#39; viewpoints. The proposed framework considers a good solution for choosing a dependable application to support the user and community of BCI systems with a stable STE environment.},
  archive      = {J_NCA},
  author       = {Al-qaysi, Z. T. and Albahri, A. S. and Ahmed, M. A. and Salih, Mahmood M.},
  doi          = {10.1007/s00521-024-09605-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10355-10378},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic decision-making framework for benchmarking brain–computer interface applications: A fuzzy-weighted zero-inconsistency method for consistent weights and VIKOR for stable rank},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel deep learning model for detection of inconsistency
in e-commerce websites. <em>NCA</em>, <em>36</em>(17), 10339–10353. (<a
href="https://doi.org/10.1007/s00521-024-09590-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On most e-commerce websites, there are two crucial factors that customers rely on to assess product quality and dependability: customer reviews provided online and related ratings. Reviews offer feedback to customers about the product’s merits, reasons for negative reviews, and feelings of satisfaction or dissatisfaction with the provided service. As for ratings, they express customer opinions about the product’s quality as numerical values from one to five (one or two for the worst opinion, three for the neutral opinion, and four or five for the best opinion). Usually, the customer reviews may be inconsistent with their relevant ratings; the customer may write the worst review despite providing a four- or five-star rating or write the best review with only a one- or two-star rating. Due to this inconsistency, customers may need help to identify relevant information. Therefore, it is required to develop a model that can classify reviews as either positive or negative, depending on the polarity of thoughts, to demonstrate if there is an inconsistency between customer reviews and their actual ratings by comparing them with the ratings resulting from the model. This paper proposes an efficient deep learning (DL) model for classifying customer reviews and assessing whether there is inconsistency. The recommended model’s performance and stability are examined on a large dataset of product reviews from Amazon e-commerce. The experimental findings showed that the proposed model dominates and significantly outperforms its peers regarding prediction accuracy and other performance measures.},
  archive      = {J_NCA},
  author       = {Kassem, Mohamed A. and Abohany, Amr A. and El-Mageed, Amr A. Abd and Hosny, Khalid M.},
  doi          = {10.1007/s00521-024-09590-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10339-10353},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel deep learning model for detection of inconsistency in e-commerce websites},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A methodological framework for optimizing the energy
consumption of deep neural networks: A case study of a cyber threat
detector. <em>NCA</em>, <em>36</em>(17), 10297–10338. (<a
href="https://doi.org/10.1007/s00521-024-09588-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing prevalence of deep neural networks (DNNs) across various fields raises concerns about their increasing energy consumption, especially in large data center applications. Identifying the best combination of optimization techniques to achieve maximum energy efficiency while maintaining system performance is challenging due to the vast number of techniques available, their complex interplay, and the rigorous evaluation required to assess their impact on the model. To address this gap, we propose an open-source methodological framework for the systematic study of the influence of various optimization techniques on diverse tasks and datasets. The goal is to automate experimentation, addressing common pitfalls and inefficiencies of trial and error, saving time, and allowing fair and reliable comparisons. The methodology includes model training, automatic application of optimizations, export of the model to a production-ready format, and pre- and post-optimization energy consumption and performance evaluation at inference time using various batch sizes. As a novelty, the framework provides pre-configured &quot;optimization strategies&quot; for combining state-of-the-art optimization techniques that can be systematically evaluated to determine the most effective strategy based on real-time energy consumption and performance feedback throughout the model life cycle. As an additional novelty, &quot;optimization profiles&quot; allow the selection of the optimal strategy for a specific application, considering user preferences regarding the trade-off between energy efficiency and performance. Validated through an empirical study on a DNN-based cyber threat detector, the framework demonstrates up to 82% reduction in energy consumption during inference with minimal accuracy loss.},
  archive      = {J_NCA},
  author       = {Karamchandani, Amit and Mozo, Alberto and Gómez-Canaval, Sandra and Pastor, Antonio},
  doi          = {10.1007/s00521-024-09588-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10297-10338},
  shortjournal = {Neural Comput. Appl.},
  title        = {A methodological framework for optimizing the energy consumption of deep neural networks: A case study of a cyber threat detector},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fault detection of wind turbine system based on data-driven
methods: A comparative study. <em>NCA</em>, <em>36</em>(17),
10279–10296. (<a
href="https://doi.org/10.1007/s00521-024-09604-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection plays a crucial role in ensuring the safety, availability, and reliability of modern industrial processes. This study focuses on data-driven fault detection methods, which have gained significant attention across various industrial sectors due to the rapid development of industrial automation technologies and the availability of extensive datasets. The objectives of this paper are to comprehensively review and present the theoretical foundations of widely used data-driven fault detection approaches. Specifically, these approaches are applied to fault detection in wind turbine systems, with performance evaluation conducted using multiple statistical measures. The data utilized in this study were collected from a simulated benchmark of a wind turbine system. The data-driven methods are tested under the assumption that the wind turbine operates in a steady-state region. Additionally, a comparative study is conducted to identify and discuss the primary challenges associated with the practical application of these methods in real-world scenarios. Simulation results show the effectiveness and efficacy of data-driven approaches concerning the sensitivity and robustness of wind turbine sensor faults as applied in practical industrial environments.},
  archive      = {J_NCA},
  author       = {Elshenawy, Lamiaa M. and Gafar, Ahmed A. and Awad, Hamdi A. and AbouOmar, Mahmoud S.},
  doi          = {10.1007/s00521-024-09604-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10279-10296},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fault detection of wind turbine system based on data-driven methods: A comparative study},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Object modeling through weightless tracking. <em>NCA</em>,
<em>36</em>(17), 10257–10278. (<a
href="https://doi.org/10.1007/s00521-024-09601-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method to perform the real-time creation of models that are used to represent aspects of tracked objects in video frames. Object modeling is done during the task of tracking previously unseen selected objects, and both tracking and model creation are implemented using the WiSARD weightless neural network and occur in real time, starting from no prior knowledge. The main purpose of this work is to track an object through camera images and, simultaneously, create a model that describes the presented appearances along with the transitions between each learned aspect. To achieve this goal, an object tracker based on the ClusWiSARD weightless neural network model was used to determine the states that describe the observed objects. In this way, it is possible to obtain a system that capture knowledge about the visual structures of the learned objects, creating relationships between the possible appearances, and being able to transit over the model aspects in an appropriate way. Furthermore, the created models have visual representations that can be used to show the learned aspects and validate the state transitions, in addition to being able to visualize occluded parts of objects.},
  archive      = {J_NCA},
  author       = {do Nascimento, Daniel N. and França, Felipe M. G.},
  doi          = {10.1007/s00521-024-09601-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10257-10278},
  shortjournal = {Neural Comput. Appl.},
  title        = {Object modeling through weightless tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating the quality of visual explanations on chest x-ray
images for thorax diseases classification. <em>NCA</em>,
<em>36</em>(17), 10239–10255. (<a
href="https://doi.org/10.1007/s00521-024-09587-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are extensively used but often lack transparency due to their complex internal mechanics. To bridge this gap, the field of explainable AI (XAI) strives to make these models more interpretable. However, a significant obstacle in XAI is the absence of quantifiable metrics for evaluating explanation quality. Existing techniques, reliant on manual assessment or inadequate metrics, face limitations in scalability, reproducibility, and trustworthiness. Recognizing these issues, the current study specifically addresses the quality assessment of visual explanations in medical imaging, where interpretability profoundly influences diagnostic accuracy and trust in AI-assisted decisions. Introducing novel criteria such as informativeness, localization, coverage, multi-target capturing, and proportionality, this work presents a comprehensive method for the objective assessment of various explainability algorithms. These newly introduced criteria aid in identifying optimal evaluation metrics. The study expands the domain’s analytical toolkit by examining existing metrics, which have been prevalent in recent works for similar applications, and proposing new ones. Rigorous analysis led to selecting Jensen–Shannon divergence (JS_DIV) as the most effective metric for visual explanation quality. Applied to the multi-label, multi-class diagnosis of thoracic diseases using a trained classifier on the CheXpert dataset, local interpretable model-agnostic explanations (LIME) with diverse segmentation strategies interpret the classifier’s decisions. A qualitative analysis on an unseen subset of the VinDr-CXR dataset evaluates these metrics, confirming JS_DIV’s superiority. The subsequent quantitative analysis optimizes LIME’s hyper-parameters and benchmarks its performance across various segmentation algorithms, underscoring the utility of an objective assessment metric in practical applications.},
  archive      = {J_NCA},
  author       = {Rahimiaghdam, Shakiba and Alemdar, Hande},
  doi          = {10.1007/s00521-024-09587-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10239-10255},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating the quality of visual explanations on chest X-ray images for thorax diseases classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving precipitation estimates for turkey with multimodel
ensemble: A comparison of nonlinear artificial neural network method
with linear methods. <em>NCA</em>, <em>36</em>(17), 10219–10238. (<a
href="https://doi.org/10.1007/s00521-024-09598-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble analysis is proven to provide advantages in climate change impact assessment based on outputs from climate models. Ensembled series are shown to outperform single-model assessments through increased consistency and stability. This study aims to test the improvement of precipitation estimates through the use of ensemble analysis for south and southwestern Turkey which is known to have complex climatic features due to varying topography and interacting climate forcings. The analysis covers an evaluation of the performance of eight regional climate models (RCMs) from the EUR-11 domain available from the CORDEX database. The historical outputs are evaluated for their representativeness of the current climate of the Mediterranean region and its surroundings in Turkey through a comparison with long-term monthly precipitation time series obtained from ground-based precipitation observations by the use of statistical performance indicators and Taylor diagrams. This is followed by a comparative evaluation of three ensemble methodologies, simple average of the models, multiple linear regression for superensemble, and artificial neural networks (ANN). The analysis results show that the overall performance of ensembled time series is better compared to individual RCMs. ANN generally provided the best performance when all RCMs are used as inputs. Improvement in the performance of ensembling due to the use of nonlinear models is further confirmed by fuzzy inference systems (FIS). Both ANN and FIS generated monthly precipitation time series with higher correlations with those of observations. However, extreme events are poorly represented in the ensembled time series, and this may result in inefficiency in the design of various water structures such as spillways and storm water drainage systems that are based on high return period events.},
  archive      = {J_NCA},
  author       = {Mesta, Buket and Akgun, O. Burak and Kentel, Elcin},
  doi          = {10.1007/s00521-024-09598-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10219-10238},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving precipitation estimates for turkey with multimodel ensemble: A comparison of nonlinear artificial neural network method with linear methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spread patterns of COVID-19 in european countries: Hybrid
deep learning model for prediction and transmission analysis.
<em>NCA</em>, <em>36</em>(17), 10201–10217. (<a
href="https://doi.org/10.1007/s00521-024-09597-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has profoundly impacted healthcare systems and economies worldwide, leading to the implementation of travel restrictions and social measures. Efforts such as vaccination campaigns, testing, and surveillance have played a crucial role in containing the spread of the virus and safeguarding public health. There needs to be more research exploring the transmission dynamics of COVID-19, particularly within European nations. Therefore, the primary objective of this research was to examine the spread patterns of COVID-19 across various European countries. Doing so makes it possible to implement preventive measures, allocate resources, and optimize treatment strategies based on projected case and mortality rates. For this purpose, a hybrid prediction model combining CNN and LSTM models was developed. The performance of this hybrid model was compared against several other models, including CNN, k-NN, LR, LSTM, MLP, RF, SVM, and XGBoost. The empirical findings revealed that the CNN-LSTM hybrid model exhibited superior performance compared to alternative models in effectively predicting the transmission of COVID-19 within European nations. Furthermore, examining the peak of case and death dates provided insights into the dynamics of COVID-19 transmission among European countries. Chord diagrams were drawn to analyze the inter-country transmission patterns of COVID-19 over 5-day and 14-day intervals.},
  archive      = {J_NCA},
  author       = {Utku, Anıl and Akcayol, M. Ali},
  doi          = {10.1007/s00521-024-09597-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10201-10217},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spread patterns of COVID-19 in european countries: Hybrid deep learning model for prediction and transmission analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M-mix: Patternwise missing mix for filling the missing
values in traffic flow data. <em>NCA</em>, <em>36</em>(17), 10183–10200.
(<a href="https://doi.org/10.1007/s00521-024-09579-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world traffic flow data often contain missing values, which can limit its usability. Although existing deep learning-based imputation methods have shown promising results by reconstructing observed values, they often overlook certain missing patterns in the dataset and perform worse on filling real missing values. This paper addresses this issue and proposes a novel masking method called Patternwise Missing Mix (M-Mix) for masked modeling-based traffic flow data imputation. M-Mix generates masks by mixing existing missing values in the target datasets to preserve the missing pattern information, thereby enhancing the performance of imputing real missing values. Additionally, a dual-objective loss function is proposed for model optimization, which predicts masked values for higher robustness and reconstructs observed values to maintain semantic correctness. Through extensive experiments on real-world datasets, M-Mix consistently demonstrates superior performance compared to other masking methods.},
  archive      = {J_NCA},
  author       = {Guo, Xiaoyu and Xing, Weiwei and Wei, Xiang and Liu, Weibin and Zhang, Jian and Lu, Wei},
  doi          = {10.1007/s00521-024-09579-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10183-10200},
  shortjournal = {Neural Comput. Appl.},
  title        = {M-mix: Patternwise missing mix for filling the missing values in traffic flow data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parkinson classification neural network with mass algorithm
for processing speech signals. <em>NCA</em>, <em>36</em>(17),
10165–10181. (<a
href="https://doi.org/10.1007/s00521-024-09596-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s disease (PD) is a condition that degenerates over time and impairs speech and pronunciation because brain cells have died. This research work aims to predict parkinson disease using the voice features extracted from speech signals recorded from PD individuals with dysphonic speech disorders by employing deep learning algorithms. PD is challenging to diagnose early on in the clinical presentation. To address the issue in machine learning methods, this paper proposes a neural network model by processing speech signals to classify PD using the University of California Irvine (UCI) machine learning repository dataset. Initially, a pre-loss reduction module is created by using pre-sampling to make the dataset balanced by reducing the dimensionality and maintaining the size of the space without influencing the learning process for data preparation. The relevant features are derived using a novel multi-agent salp swarm (MASS) algorithm, and a novel Parkinson classification neural network (PCNN) is proposed to classify Parkinson&#39;s patients with high accuracy employing these derived features. The result shows that the models that use MASS-PCNN produce higher classification accuracy of 99.1%, precision of 97.8%, recall of 94.7% and F1-score of 0.995 when paralleled to the existing models. As an outcome, the suggested model will perform superior to common convolutional neural networks.},
  archive      = {J_NCA},
  author       = {Akila, B. and Nayahi, J. Jesu Vedha},
  doi          = {10.1007/s00521-024-09596-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10165-10181},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parkinson classification neural network with mass algorithm for processing speech signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relative vectoring using dual object detection for
autonomous aerial refueling. <em>NCA</em>, <em>36</em>(17), 10143–10163.
(<a href="https://doi.org/10.1007/s00521-024-09589-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Once realized, autonomous aerial refueling will revolutionize unmanned aviation by removing current range and endurance limitations. Previous attempts at establishing vision-based solutions have come close but rely heavily on near perfect extrinsic camera calibrations that often change midflight. In this paper, we propose dual object detection, a technique that overcomes such requirement by transforming aerial refueling imagery directly into receiver aircraft reference frame probe-to-drogue vectors regardless of camera position and orientation. These vectors are precisely what autonomous agents need to successfully maneuver the tanker and receiver aircraft in synchronous flight during refueling operations. Our method follows a common 4-stage process of capturing an image, finding 2D points in the image, matching those points to 3D object features, and analytically solving for the object pose. However, we extend this pipeline by simultaneously performing these operations across two objects instead of one using machine learning and add a fifth stage that transforms the two pose estimates into a relative vector. Furthermore, we propose a novel supervised learning method using bounding box corrections such that our trained artificial neural networks can accurately predict 2D image points corresponding to known 3D object points. Simulation results show that this method is reliable, accurate (within 3 cm at contact), and fast (45.5 fps).},
  archive      = {J_NCA},
  author       = {Worth, Derek and Choate, Jeffrey and Lynch, James and Nykl, Scott and Taylor, Clark},
  doi          = {10.1007/s00521-024-09589-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10143-10163},
  shortjournal = {Neural Comput. Appl.},
  title        = {Relative vectoring using dual object detection for autonomous aerial refueling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asphalt pavement patch identification with image features
based on statistical properties using machine learning. <em>NCA</em>,
<em>36</em>(17), 10123–10141. (<a
href="https://doi.org/10.1007/s00521-024-09586-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding patches is a crucial step in a pavement performance survey. The study develops a machine learning and image processing algorithm-established automatic method for identifying asphalt pavement patches. The GrayLevel Co-Occurrence Matrix and image texture-based features derived from color channel statistics are used as input parameters to describe the condition of the pavement. For feature extraction, image processing methods like the projective integral of images, steerable filters, and an improved image thresholding method were used. Support Vector Machine is employed for categorizing the differentiating patched regions from non-patch ones. The suggested combination of image texture analytical methods has been trained using an IA data set created from 400 image samples. The feature set, which combines the characteristics of cracked objects with those generated from the projective integral, can produce the desired result. To make the model’s execution simpler, a patch recognition program was created and implemented in MATLAB. As a result, the recently created method has the potential to be an instrument for traffic management organizations through the assessment of pavement performance. The results of the experiments indicate that the newly developed method may achieve excellent accuracy prediction results with a classifier performance rate of about 96%. Such a method could enable transportation authorities to assess the state of asphalt pavement.},
  archive      = {J_NCA},
  author       = {Alfwzan, Wafa F. and Alballa, Tmader and Al-Dayel, Ibrahim A. and Selim, Mahmoud M.},
  doi          = {10.1007/s00521-024-09586-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10123-10141},
  shortjournal = {Neural Comput. Appl.},
  title        = {Asphalt pavement patch identification with image features based on statistical properties using machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid computational approach to process real-time
streaming multi-sources data and improve classification for emergency
patients triage services: Moving forward to an efficient IoMT-based
real-time telemedicine systems. <em>NCA</em>, <em>36</em>(17),
10109–10122. (<a
href="https://doi.org/10.1007/s00521-024-09600-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of Medical Things (IoMT)-based real-time telemedicine systems, patients can utilize a wide range of medical devices and sensors, which leads to the continuous generation of massive amounts of data. The high speed of data generation poses challenges in collecting, organizing, processing, and making decisions about patients’ emergency levels. Existing methods for classifying (triaging) patients in such environments often yield inaccurate triage levels, necessitating a computational approach to enhance accuracy. This research aims to handle data from multiple heterogeneous sources in IoMT-based real-time telemedicine systems, analyze the data to accurately triage patients with the most urgent cases, and provide swift healthcare services. The proposed solution, the Data Processing with Triaging Model (DPTM), employs a hybrid approach that combines principal component analysis and decision tree algorithms. The model was tested using 55,680 patients with two chronic diseases: heart disease and hypertension. The computational results demonstrate the promising effectiveness of DPTM in accommodating and managing the requests of 55,680 patients. The proposed system achieves an impressive accuracy of 93%, surpassing four other algorithms. In conclusion, DPTM enhances medical services, reduces hospital overcrowding, and ensures accurate services for all patients, with a 93% accuracy rate.},
  archive      = {J_NCA},
  author       = {Salman, Omar Sadeq and Abdul Latiff, Nurul Mu’azzah and Salman, Omar H. and Syed Ariffin, Sharifah Hafizah},
  doi          = {10.1007/s00521-024-09600-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10109-10122},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid computational approach to process real-time streaming multi-sources data and improve classification for emergency patients triage services: Moving forward to an efficient IoMT-based real-time telemedicine systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-assisted medical image compression challenges
and opportunities: Systematic review. <em>NCA</em>, <em>36</em>(17),
10067–10108. (<a
href="https://doi.org/10.1007/s00521-024-09660-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the preceding decade, there has been a discernible surge in the prominence of artificial intelligence, marked by the development of various methodologies, among which deep learning emerges as a particularly auspicious technique. The captivating attribute of deep learning, characterised by its capacity to glean intricate feature representations from data, has served as a catalyst for pioneering approaches and methodologies spanning a multitude of domains. In the face of the burgeoning exponential growth in digital medical image data, the exigency for adept image compression methodologies has become increasingly pronounced. These methodologies are designed to preserve bandwidth and storage resources, thereby ensuring the seamless and efficient transmission of data within medical applications. The critical nature of medical image compression accentuates the imperative to confront the challenges precipitated by the escalating deluge of medical image data. This review paper undertakes a comprehensive examination of medical image compression, with a predominant focus on sophisticated, research-driven deep learning techniques. It delves into a spectrum of approaches, encompassing the amalgamation of deep learning with conventional compression algorithms and the application of deep learning to enhance compression quality. Additionally, the review endeavours to explicate these fundamental concepts, elucidating their inherent characteristics, merits, and limitations.},
  archive      = {J_NCA},
  author       = {Bourai, Nour El Houda and Merouani, Hayet Farida and Djebbar, Akila},
  doi          = {10.1007/s00521-024-09660-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10067-10108},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-assisted medical image compression challenges and opportunities: Systematic review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid approach to real-time multi-target tracking.
<em>NCA</em>, <em>36</em>(17), 10055–10066. (<a
href="https://doi.org/10.1007/s00521-024-09799-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Object Tracking, also known as Multi-Target Tracking, is an important area of computer vision with various applications in different domains. The advent of deep learning has had a profound impact on this field, forcing researchers to explore innovative avenues. Deep learning methods have become the cornerstone of today&#39;s state-of-the-art solutions, consistently delivering exceptional tracking results. However, the significant computational demands of deep learning models require powerful hardware resources that do not always match real-time tracking requirements, limiting their practical applicability in real-world scenarios. Thus, there is an imperative to strike a balance by merging robust deep learning strategies with conventional approaches to enable more accessible, cost-effective solutions that meet real-time requirements. This paper embarks on this endeavor by presenting a hybrid strategy for real-time multi-target tracking. It effectively combines a classical optical flow algorithm with a deep learning architecture tailored for human crowd tracking systems. This hybrid approach achieves a commendable balance between tracking accuracy and computational efficiency. The proposed architecture, subjected to extensive experimentation in various settings, demonstrated notable results, achieving a Mean Object Tracking Accuracy (MOTA) of 0.608. This level of performance placed it as the highest ranking solution on the MOT15 benchmark, surpassing the state-of-the-art benchmark of 0.549, and consistently ranked among the superior models on the MOT17 and MOT20 benchmarks. Additionally, the incorporation of the optical flow phase resulted in a substantial reduction in processing time, nearly halving the duration, while simultaneously maintaining accuracy levels comparable to established techniques.},
  archive      = {J_NCA},
  author       = {Scarrica, Vincenzo M. and Panariello, Ciro and Ferone, Alessio and Staiano, Antonino},
  doi          = {10.1007/s00521-024-09799-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10055-10066},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid approach to real-time multi-target tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data augmentation based on shape space exploration for
low-size datasets: Application to 2D shape classification. <em>NCA</em>,
<em>36</em>(17), 10031–10054. (<a
href="https://doi.org/10.1007/s00521-024-09798-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel 2D shape data augmentation approach based on intra-class shape space exploration. The proposed method relies on a geodesic interpolation between shapes, leveraging invariant-based morphing techniques. By blending a 2D shape pair belonging to a given class, we are able to generate nonlinear augmentations, hence covering more variations within the shape space. In particular, we formulate data augmentation as an optimization problem that minimizes the deformations between two shapes using the Generalized Finite Fourier Invariant Descriptor. The proposed augmentation technique is evaluated using numerous Convolution Neural Network architectures for 2D shape classification. The results indicate the superiority of the proposed method as compared to state-of-the-art techniques when considering small-scale datasets.},
  archive      = {J_NCA},
  author       = {Ghorbel, Emna and Ghorbel, Faouzi},
  doi          = {10.1007/s00521-024-09798-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10031-10054},
  shortjournal = {Neural Comput. Appl.},
  title        = {Data augmentation based on shape space exploration for low-size datasets: Application to 2D shape classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive charging scheme for large-scale wireless
rechargeable sensor networks inspired by deep q-network. <em>NCA</em>,
<em>36</em>(17), 10015–10030. (<a
href="https://doi.org/10.1007/s00521-024-09658-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Wireless Rechargeable Sensor Networks utilize a Mobile Charger (MC) to prevent node failure by replenishing the sensor node’s energy. Existing studies primarily focus on small-size networks using a single-node charging method, lacking scalability for large-scale networks with diverse energy consumption rates. Additionally, previous charging algorithms are often sensitive to a pre-established charging request threshold, reducing flexibility in charging decisions. This study addresses the challenges by proposing an adaptive charging scheme for large-scale networks. First, we exploit the “multi-node charging” strategy, where the MC charges multiple sensors simultaneously to maximize charging utilities. We then model the charging problem as a Markov Decision Process and devise a Graph Neural Network-based representation method to reduce the state space’s dimension. Subsequently, the Deep Q-Network algorithm will determine the MC’s optimal charging policy, which automatically selects the next charging location in each round. Extensive experiments demonstrate our proposal’s efficiency, reducing approximately 51% of node failures compared to the most related works.},
  archive      = {J_NCA},
  author       = {Vuong, An Dinh and Tran, Huong Thi and Pham, Hoang Nguyen Quang and Bui, Quang Minh and Ngo, Trang Phuong and Huynh, Binh Thanh Thi},
  doi          = {10.1007/s00521-024-09658-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {10015-10030},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive charging scheme for large-scale wireless rechargeable sensor networks inspired by deep Q-network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residual deep fuzzy system with randomized fuzzy modules for
accurate time series forecasting. <em>NCA</em>, <em>36</em>(17),
9989–10014. (<a
href="https://doi.org/10.1007/s00521-024-09663-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data-driven modular deep fuzzy model has demonstrated excellent forecasting performance due to its clear architecture and powerful fuzzy inference ability. However, the fixed structure predesigned for specific types of datasets limits the further improvement of generalization ability, especially when facing high-dimensional datasets with the challenging problem of rule explosion, thereby suffering from the time-consuming training process. To overcome these limitations, a novel randomized fuzzy modules (RFMs) stacked residual deep fuzzy system (RFM-RDFS) is proposed in this study. Firstly, to obtain high-precision outputs, this paper presents a residual deep fuzzy framework by stacking RFMs layer by layer, where the modules in the current layer only learn the residual of the previous layer. Secondly, to improve the design freedom for different applications, the RFM with multiple inputs is raised, where the input variables are allocated by a sliding window along the input spaces of the layers, so the number of the parallel modules in the same layer can be flexibly adjusted. Meanwhile, in the RFM, inspired by the extreme learning machine, the centers and widths of Gaussian membership functions are randomly generated, which can greatly accelerate the training speed. Thirdly, to strengthen the approximation performance, the consequent parameters of the fuzzy rules in each RFM are learned by minimizing the loss function with the regularization terms through the ridge regression algorithm. Finally, extensive experiments on various datasets are conducted to compare the proposed RFM-RDFS with several state-of-the-art shallow and deep models. The detailed comparison results clearly show that the proposed RFM-RDFS is more flexible and compact, and has greater advantages in terms of the interpretability, generalization ability and robustness.},
  archive      = {J_NCA},
  author       = {Liu, Yunxia and Peng, Wei and Wang, Haixia and Li, Chengdong and Lu, Xiao},
  doi          = {10.1007/s00521-024-09663-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9989-10014},
  shortjournal = {Neural Comput. Appl.},
  title        = {Residual deep fuzzy system with randomized fuzzy modules for accurate time series forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural network approaches for single-cell data: A
recent overview. <em>NCA</em>, <em>36</em>(17), 9963–9987. (<a
href="https://doi.org/10.1007/s00521-024-09662-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are reshaping our understanding of biomedicine and diseases by revealing the deep connections among genes and cells. As both algorithmic and biomedical technologies have advanced significantly, we are entering a transformative phase of personalized medicine. While pioneering tools like graph attention networks (GATs) and graph convolutional neural networks (Graph CNN) are advancing graph-based learning, the rise of single-cell sequencing techniques is reshaping our insights on cellular diversity and function. Numerous studies have combined GNNs with single-cell data, showing promising results. In this work, we highlight the GNN methodologies tailored for single-cell data over the recent years. We outline the diverse range of graph deep learning architectures that center on GAT methodologies. Furthermore, we underscore the several objectives of GNN strategies in single-cell data contexts, ranging from cell-type annotation, data integration and imputation, gene regulatory network reconstruction, clustering and many others. This review anticipates a future where GNNs become central to single-cell analysis efforts, particularly as vast omics datasets are continuously generated and the interconnectedness of cells and genes enhances our depth of knowledge in biomedicine.},
  archive      = {J_NCA},
  author       = {Lazaros, Konstantinos and Koumadorakis, Dimitris E. and Vlamos, Panagiotis and Vrahatis, Aristidis G.},
  doi          = {10.1007/s00521-024-09662-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9963-9987},
  shortjournal = {Neural Comput. Appl.},
  title        = {Graph neural network approaches for single-cell data: A recent overview},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Selective arguments representation with dual relation-aware
network for video situation recognition. <em>NCA</em>, <em>36</em>(17),
9945–9961. (<a
href="https://doi.org/10.1007/s00521-024-09655-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Argument visual states are helpful for detecting structured components of events in videos, and existing methods tend to use object detectors to generate their candidates. However, directly leveraging object features captured by bounding boxes overlooks a deep understanding of object relations and differences between them and real arguments. In this work, we propose a novel framework to generate selective contextual representations of videos, thereby reducing the interference of useless or incorrect object features. Firstly, we construct grid-based object features as graphs based on the internal grid connection and then use graph convolutional network to execute feature aggregation. Secondly, a weighted geometric attention module is designed to obtain the contextual representation of objects, which explicitly combines visual similarity and geometric correlation with different importance proportions. Then, we propose a dual relation-aware selection module for further feature selection. Finally, we utilize labels as the ladder to bridge the gap between object features and semantic roles, while considering the proximity in the semantic space. Experimental results and extensive ablation studies on the VidSitu indicate that our method effectively obtains a deep understanding of events in videos and outperforms state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Liu, Wei and He, Qing and Wang, Chao and Peng, Yan and Xie, Shaorong},
  doi          = {10.1007/s00521-024-09655-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9945-9961},
  shortjournal = {Neural Comput. Appl.},
  title        = {Selective arguments representation with dual relation-aware network for video situation recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey on spatio-temporal series prediction with deep
learning: Taxonomy, applications, and future directions. <em>NCA</em>,
<em>36</em>(17), 9919–9943. (<a
href="https://doi.org/10.1007/s00521-024-09659-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of data acquisition and storage technology, spatio-temporal (ST) data in various fields are growing explosively, so many ST prediction methods have emerged. The review presented in this paper mainly studies the prediction of ST series. We propose a new taxonomy organized along three dimensions: ST series prediction methods (focusing on time feature learning, focusing on spatial feature learning, and focusing on spatial–temporal feature learning), techniques of ST series prediction (the RNN-, CNN-, and transformer-based models, as well as the CNN-based-composite model and GNN-based-composite models, and the miscellaneous model) and ST series prediction results (single target and multi-target). We first introduce and explain each dimension of the taxonomy in detail. After providing this three-dimensional view, we comprehensively review and compare the recent related ideas in the literature and analyze their advantages and limitations. Moreover, we summarize the key information of the existing literature and provide guidance for researchers to select suitable models. Second, we summarize the different applications of deep learning models in ST series prediction based on current literature and list relevant datasets and download links per application classifications. Lastly, we comprehensively analyze the current innovation and challenges and suggest future directions for researching ST series prediction after comparing and analyzing the computing performance of these forecasting models. In addition, each method or model solves one aspect of the challenge, which means that two or more methods should be combined to solve more challenges at the same time. We hope this article provides readers a broader and deeper understanding of the field of ST series research.},
  archive      = {J_NCA},
  author       = {Sun, Feiyan and Hao, Wenning and Zou, Ao and Shen, Qianyan},
  doi          = {10.1007/s00521-024-09659-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9919-9943},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey on spatio-temporal series prediction with deep learning: Taxonomy, applications, and future directions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating bidirectional feature pyramid network and
lightweight network: A YOLOv5-GBC distracted driving behavior detection
model. <em>NCA</em>, <em>36</em>(17), 9903–9917. (<a
href="https://doi.org/10.1007/s00521-023-09043-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distracted driving is one of the leading causes of traffic accidents and has become a bottleneck for improving driver assistance technologies. It is still a challenge to detect distracted driving behavior in real-life scenarios, which have the features of complex backgrounds, different target scales, and resolutions. In this context, a lightweight YOLOv5-GBC model is proposed for real-time distracted driving detection in this work. Firstly, the lightweight network GhostConv is used to perform lightweight operations on the convolutional layers, aiming to reduce a large number of parameters and computations. Secondly, the path aggregation network structure is improved to enhance the model fusion ability for different scale features, and coordinated attention is introduced to enhance the model extraction ability for effective information. The proposed YOLOv5-GBC model can predict different types of distracted driving. Finally, this work conducts extensive experiments; the results show that the proposed model has a mean accuracy (mAP) of 91.8%, which is 3.9% better than the baseline model, with a reduction of 6.5% and 9.1% in the weight file and Floating-point Operations Per Second, respectively. It outperforms the models of Faster-RCNN, SSD, YOLOv3-tiny, and YOLOv4-tiny, which indicates that the proposed model can identify distracted driving behaviors efficiently and rapidly.},
  archive      = {J_NCA},
  author       = {Du, Yingjie and Liu, Xiaofeng and Yi, Yuwei and Wei, Kun},
  doi          = {10.1007/s00521-023-09043-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9903-9917},
  shortjournal = {Neural Comput. Appl.},
  title        = {Incorporating bidirectional feature pyramid network and lightweight network: A YOLOv5-GBC distracted driving behavior detection model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decision-making in low-carbon supply chain networks
considering demand uncertainty. <em>NCA</em>, <em>36</em>(17),
9891–9901. (<a
href="https://doi.org/10.1007/s00521-024-09595-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies supply chain pricing and production/ordering decisions under carbon tax policy and retailer’s stochastic demand. Firstly, a supply chain model with random demand obeying normal distribution is established. Based on this, a stochastic optimization problem with the goal of maximizing expected social welfare is constructed. The multi-agent consensus is used to solve the optimization problem, and the pricing and production/ordering decisions with random demand obeying normal distribution are obtained. Finally, the theoretical results are verified by numerical simulation, and the influence and effectiveness of multi-agent consensus theory on supply chain decision-making are demonstrated in the presence of random demand and sudden failure of an enterprise in the supply chain and further analyze the impact of carbon tax policy on supply chain decision-making.},
  archive      = {J_NCA},
  author       = {Li, Yuxian and Wang, Jiuhe},
  doi          = {10.1007/s00521-024-09595-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9891-9901},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decision-making in low-carbon supply chain networks considering demand uncertainty},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Micro drill defect detection with hybrid BP networks,
clusters selection and crossover. <em>NCA</em>, <em>36</em>(17),
9875–9889. (<a
href="https://doi.org/10.1007/s00521-024-09594-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the solution requirements, linear BP neural networks are designed which are consistent with the feature curves of the fitted equation, when the neural networks reach the equilibrium and stable state, so a optimization problem is transformed into the process of BP neural network reaching its equilibrium point. In order to obtain the global optimal solution, all the individuals of the 210 parallel neural networks are classified into several clusters, whose centroids are perturbed by the Levy flight, which is beneficial for the system to jump out of local extremum. At the same time, new clusters are obtained by clusters’ selection, and new individuals with crossover operator within each cluster and between clusters, so the computation decreases significantly. Then, new individuals are accepted by Metropolis criteria. Finally, when the BP neural network reaches the global optimal equilibrium state, the corresponding feature curves of the micro drill’s end faces is obtained. As such, the detection of the chip, rounded corner and other defects of the micro drill and some technical indexes are gotten.},
  archive      = {J_NCA},
  author       = {Ge, Dong-yuan and Su, Rui-xuan and Yao, Xi-fan and Li, Jian},
  doi          = {10.1007/s00521-024-09594-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9875-9889},
  shortjournal = {Neural Comput. Appl.},
  title        = {Micro drill defect detection with hybrid BP networks, clusters selection and crossover},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on the influencing factors and the differences
between the initial trust and continuous trust of online health
community users. <em>NCA</em>, <em>36</em>(17), 9849–9874. (<a
href="https://doi.org/10.1007/s00521-024-09593-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet medical and health services are services that require high levels of trust. We identify factors that influence user trust based on trust source credibility model and trust transitivity model and explore differences in initial and continuous trust formation among users of online health communities from the perspective of trust dynamics. We found that the type of service provision, etc., which represents benevolence trust, whether doctors provide personal photographs, which represents integrity trust, and the overall recommendation popularity, number of electronic gifts, thank you letters, patient votes and positive service quality ratings, which represent trust transitivity, all significantly affect users&#39; initial and continuous trust, but there are differences in the degree of influence on the two types of trust. The doctor&#39;s title in the ability trust only has a significant effect on users&#39; initial trust and does not have a significant effect on continuous trust. The three dimensions of ability, benevolence and integrity in the trust source credibility model have a greater impact on users&#39; initial trust than on their continuous trust, while trust transitivity has a greater impact on users&#39; continuous trust than on their initial trust. Overall, in addition to traditional influences such as doctor&#39;s title, online information can also support users&#39; decision making, indicating that online health communities can provide useful information to alleviate the current information asymmetry between doctors and patients.},
  archive      = {J_NCA},
  author       = {Wang, Zongrun and Liang, Lin and Liu, Xin and Liao, Minglong},
  doi          = {10.1007/s00521-024-09593-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9849-9874},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on the influencing factors and the differences between the initial trust and continuous trust of online health community users},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on factors influencing the consumer repurchase
intention: Data mining of consumers’ online reviews based on machine
learning. <em>NCA</em>, <em>36</em>(17), 9837–9848. (<a
href="https://doi.org/10.1007/s00521-024-09591-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fierce competition in the market makes it necessary for enterprises to not only consider how to increase consumers’ purchase intention but also study to maintain high customer loyalty for continuous purchases. Taking the smartphone brands on the Jingdong platform (hereafter referred to as JD) as an example, the study collected 60,000 review data and using NLP technology for data mining, factors that may affect consumers’ willingness to repurchase were extracted. Based on Theory of Reasoned Action (TRA), the questionnaire was made for empirical research. The results showed that the four factors, product attributes, service quality, brand image and price significantly affect consumers’ repurchase intention, while service quality had the strongest effect among them, implications of the research are discussed.},
  archive      = {J_NCA},
  author       = {Zhang, Jianming and Zheng, Hao and Liu, Jie and Shen, Wei},
  doi          = {10.1007/s00521-024-09591-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9837-9848},
  shortjournal = {Neural Comput. Appl.},
  title        = {Research on factors influencing the consumer repurchase intention: Data mining of consumers’ online reviews based on machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The multiple relationships among knowledge heterogeneity,
knowledge transfer and knowledge innovation as moderated by
microstructure holes. <em>NCA</em>, <em>36</em>(17), 9819–9836. (<a
href="https://doi.org/10.1007/s00521-023-09415-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The positive relationship between knowledge transfer and knowledge innovation is recognized by most scholars, while knowledge heterogeneity, as a knowledge situation of the enterprise organization, affects knowledge transfer within enterprise organizations. Therefore, as a state, knowledge transfer can be regarded as a result of knowledge heterogeneity, and it becomes the intermediary state between knowledge heterogeneity and knowledge innovation. The organizational structure of individuals within an enterprise organization may affect these three elements and their interrelationships. In this paper, data are collected by means of on-the-spot investigation and a network questionnaire for analysis. The results show that the microstructure state of the individual in the enterprise organization plays a moderating role for the first three elements. The lower that the micro-restriction of the individual is, the more favorable the knowledge heterogeneity is for the inverted U-shaped impact of knowledge transfer and knowledge innovation and the more favorable the occurrence of knowledge innovation.},
  archive      = {J_NCA},
  author       = {Wang, Lubang and Dong, Guohui and Xu, Ying and Zhang, Xinming},
  doi          = {10.1007/s00521-023-09415-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9819-9836},
  shortjournal = {Neural Comput. Appl.},
  title        = {The multiple relationships among knowledge heterogeneity, knowledge transfer and knowledge innovation as moderated by microstructure holes},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prognosis prediction of high grade serous adenocarcinoma
based on multi-modal convolution neural network. <em>NCA</em>,
<em>36</em>(17), 9805–9817. (<a
href="https://doi.org/10.1007/s00521-023-09231-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prognostic analysis for high grade serous adenocarcinoma (HGSC) holds significant clinical importance. However, current prognostic analysis primarily relies on statistical techniques like logistic regression and chi-square analysis alongside traditional machine learning methods based on pattern recognition. These approaches face challenges in addressing the limited reliability and validity of evaluation results, as well as the absence of reliable prognostic indicators. To identify a reliable prognostic evaluation method for high grade serous adenocarcinoma, a novel prognostic evaluation method was constructed using multi-modal deep learning techniques and compared with existing methods using data from 210 patients with high grade serous adenocarcinoma (stage III). The experimental results showed that the accuracy of this method for prognostic analysis was 80.0%, and the detection rate for poor prognosis cases was 82.87%, which was superior to current methods. Our proposed method could also automatically extract key features from different datasets and efficiently predict patient outcomes. Overall, this study laid the groundwork to overcome the difficulties in the prognostic evaluation of HGSC, help clinicians better understand the pathogenesis, and improve the long-term survival rates of this patient population.},
  archive      = {J_NCA},
  author       = {Liao, Xin and Li, Li and Gan, Zongyuan and Li, Kang and Zheng, Xin},
  doi          = {10.1007/s00521-023-09231-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9805-9817},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prognosis prediction of high grade serous adenocarcinoma based on multi-modal convolution neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rapid density estimation of tiny pests from sticky traps
using qpest RCNN in conjunction with UWB-UAV-based IoT framework.
<em>NCA</em>, <em>36</em>(17), 9779–9803. (<a
href="https://doi.org/10.1007/s00521-023-09230-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision agriculture has long struggled with the surveillance and control of pests. Traditional methods for estimating pest density and distribution through manual reconnaissance are often time-consuming and labor-intensive. To address these challenges, this study proposes a novel farmland detection system utilizing UAVs, yellow sticky traps, and deep learning techniques. The system includes a UAV based on UWB communication and positioning technology to collect picture information of sticky traps arranged in farmland. Moreover, a faster and more accurate Qpest-RCNN model is used to count the number of insects in the collected sticky traps. The bivariate kernel density estimation establishes the pest density distribution map. Regarding the dynamic monitoring of pest density in agricultural fields, it primarily involves four components: reaching the designated area, flight learning, image acquisition, and visual counting of insects and calculation of insect density. Experimental results demonstrate that UAVs require less time to adjust flight posture during image acquisition after undergoing flight learning, resulting in more concise flight trajectories. The Qpest-RCNN model introduces a variety of mechanisms based on the characteristics of the collected sticky trap data set to improve the faster-R-CNN model. We used two data sets separately to train the model, which were collected by sticky traps placed in greenhouses and open-air experimental fields. The data set from the greenhouse is an open-source dataset provided by M. Deserno et. al, map, precision, and recall of model are 0.923, 0.989, and 0.919, respectively. When the data set collected in the experimental farmland is used to train the model, map, precision, and recall of model are 0.781, 0.851, and 0.789, respectively. In the meantime, we explored the effects of species interference on visual insect statistics and the optimization effect of species hypothesis on statistics in two environments. At the same time, the inference speed of the improved model is about a quarter faster than the FPS of the original Faster-RCNN during inference. Through Qpest-RCNN, the number of insects captured on sticky traps can be counted quickly and accurately and the bivariate kernel density estimation is used to draw the pest density distribution map to observe the pest distribution of the whole farmland visually. This pest-density farmland detection system is valuable for agriculture by helping farmers control pests, reduce crop damage, and increase yield and quality.},
  archive      = {J_NCA},
  author       = {Juan, Yong and Ke, Ziyi and Chen, Ziqiang and Zhong, Debiao and Chen, Weifeng and Yin, Liang},
  doi          = {10.1007/s00521-023-09230-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9779-9803},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rapid density estimation of tiny pests from sticky traps using qpest RCNN in conjunction with UWB-UAV-based IoT framework},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient scheduling technology for a bioidentification
simulation model based on a lightweight container. <em>NCA</em>,
<em>36</em>(17), 9767–9777. (<a
href="https://doi.org/10.1007/s00521-023-09229-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of biometric technology, an increasing number of application scenarios require biometric identification systems for identity authentication, such as cell phones, gate control, and banks. The performance and operational efficiency of bioidentification systems directly impact their effectiveness in application scenarios. Traditional bioidentification technology requires a large number of devices and sites to build bioidentification systems. Bioidentification simulation model technology based on lightweight containers can simulate bioidentification systems in different scenarios through virtualization technology, which can save hardware costs while enabling efficient testing and debugging. In this context, improving the operational efficiency of bioidentification simulation models has become an important research direction. In this paper, efficient scheduling technology for a bioidentification simulation model based on lightweight containers is investigated to explore how to use container technology to improve the operational efficiency and security of the bioidentification simulation model to better serve modern bioidentification applications. For a 4-core 4G light load, the results show that the response time based on the resource scheduling strategy was 30 ms and the throughput was 30 requests per second; in contrast, the response time based on the load scheduling strategy was 45 ms, and the throughput was 27 requests per second. The system performance with the resource scheduling strategy under the same load with identical containers was significantly better than that under the load scheduling strategy. By using lightweight container technology, the operational efficiency of the bioidentification simulation model can be effectively improved while also improving the security of the system.},
  archive      = {J_NCA},
  author       = {Yu, Chunyang and Xu, Jun},
  doi          = {10.1007/s00521-023-09229-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9767-9777},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient scheduling technology for a bioidentification simulation model based on a lightweight container},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personalized learning efficiency data analysis based on
multi-scale convolution architecture and hybrid loss. <em>NCA</em>,
<em>36</em>(17), 9753–9766. (<a
href="https://doi.org/10.1007/s00521-023-09099-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized learning has gained significant attention in education as a means to cater to the diverse needs of learners and optimize educational outcomes. However, ensuring the efficiency of personalized learning remains a challenge. It requires the ability to accurately analyze and interpret vast amounts of data collected from learners. Traditional analytical approaches often struggle to handle the complexity and heterogeneity of this data, limiting the potential for personalized learning interventions. To address these challenges, this paper proposes a personalized learning efficiency data analysis network (PLEDANet) based on machine learning. First, PLEDANet redesigns a convolutional neural network based on the ResNet structure. The network performs convolutions using multiple convolution kernels of different scales to extract diverse feature information from personalized learning efficiency data. To enhance the extraction and representation of fine-grained differentiated features, PLEDANet introduces a hybrid attention module to combine channel and spatial information among feature maps. Second, PLEDANet designs a hybrid loss function for model training, which consists of the AM-softmax loss and the Center loss. The former increases the inter-class distance of features by imposing a fixed angular margin, while the latter reduces the intra-class distance by constraining the samples and feature centers. Finally, extensive experiments are conducted on PLEDANet. The experimental results validate the superiority of PLEDANet for personalized learning efficiency analysis.},
  archive      = {J_NCA},
  author       = {Jin, Dan and Wen, Xiaolan and Wen, Yiming},
  doi          = {10.1007/s00521-023-09099-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9753-9766},
  shortjournal = {Neural Comput. Appl.},
  title        = {Personalized learning efficiency data analysis based on multi-scale convolution architecture and hybrid loss},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A pediatric bone age assessment method for hand bone x-ray
images based on dual-path network. <em>NCA</em>, <em>36</em>(17),
9737–9752. (<a
href="https://doi.org/10.1007/s00521-023-09098-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone age assessment is a common diagnostic method used for abnormal growth and development in children. Despite recent significant advancements in convolutional neural network (CNN)-based intelligent bone age assessment in children, there remains room for improvement in assessment accuracy. Studies have indicated that a dual-path network (DPN) can incorporate different features of a CNN and improve the potential of the model to extract critical features compared to a single structural CNN. Attention mechanisms can also contribute to the enhanced ability of the model to extract channel and spatial features. Therefore, we propose a dual attention dual-path network (DADPN) to improve the accuracy of pediatric bone age assessment. DPN serves as a backbone network in DADPN by incorporating residual and dense connections. DPN was modified using two different attention mechanisms while containing gender information to compensate for physiological differences in bone age between males and females. Experiments were performed using this method with the RSNA Pediatric Bone Age Challenge dataset and compared to nine representative bone age assessment methods. This method achieved an optimal assessment accuracy with a mean absolute error (MAE) of 4.76 months. The experimental results suggest that the DADPN can extract the effective features of pediatric hand bone X-ray images and improve bone age assessment accuracy more than other deep learning methods.},
  archive      = {J_NCA},
  author       = {Wang, Shuang and Jin, Shuyan and Xu, Kun and She, Jiayan and Fan, Jipeng and He, Mingji and Stephen, Liao Shaoyi and Gao, Zhongjun and Liu, Xiaobo and Yao, Keqin},
  doi          = {10.1007/s00521-023-09098-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9737-9752},
  shortjournal = {Neural Comput. Appl.},
  title        = {A pediatric bone age assessment method for hand bone X-ray images based on dual-path network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial attack defense algorithm based on convolutional
neural network. <em>NCA</em>, <em>36</em>(17), 9723–9735. (<a
href="https://doi.org/10.1007/s00521-023-09045-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the defense of CNN network traffic classifiers against adversarial sample attacks, the author proposes a batch adversarial training method that utilizes the characteristics of backpropagation errors during the training process, and completing both sample gradient and parameter gradient calculations in one backpropagation process can significantly improve training efficiency. Meanwhile, since the adversarial samples used for training are generated on the target model, they can effectively defend against white box attacks. The author proposes an enhanced adversarial training method to further defend against black box attacks and overcome the transferability of adversarial samples. Using multiple models to generate adversarial samples with inconsistent sample gradients increases the diversity of adversarial samples and enhances the ability to defend against black box attacks. Through experiments on the actual traffic dataset USTC-TFC2016, we generate network traffic for adversarial samples to simulate attacks. With classification accuracy rates for FGSM adversarial samples of 49.72% and 54.32%, respectively, the experimental results show that the enhanced adversarial approach proposed by the author has a more vital ability to defend adversarial samples than defense distillation and adversarial sample detection. The classification accuracy of enhanced adversarial training can reach 75.37%, significantly higher than defense distillation and adversarial sample detection. The authors suggested adversarial training strategy can successfully improve CNN traffic classifiers’ defense capabilities.},
  archive      = {J_NCA},
  author       = {Zhang, Chengyuan and Wang, Ping},
  doi          = {10.1007/s00521-023-09045-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9723-9735},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adversarial attack defense algorithm based on convolutional neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequential recommendation based on multipair contrastive
learning with informative augmentation. <em>NCA</em>, <em>36</em>(17),
9707–9721. (<a
href="https://doi.org/10.1007/s00521-023-09044-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the recommendation accuracy degradation problem encountered in sequential recommendation cases caused by data sparsity—such as short historical user behaviour sequences and limited information—this paper proposes a sequential recommendation model based on multipair contrastive learning with informative augmentation (IA-MPCL). The model aims to better learn user preference representations. Initially, a self-attention network is utilized to maintain the intrinsic relevance of the original sequences and introduce virtual interaction items for short sequences to achieve informative enhancement. Subsequently, multiple positive samples are generated by data augmentation methods to form multiple pairs of positive and negative samples. A multipair contrastive loss is constructed to eliminate the negative impact of fake positive and negative samples on the training process of the self-attention network. Finally, an adaptive loss weighting mechanism is proposed to dynamically regulate the role of the contrastive loss during multitask training. Through comparison experiments involving baseline methods and experiments conducted on datasets with different sparsity levels, the results show that IA-MPCL achieves significant improvements in terms of both recommendation accuracy and data sparsity resistance.},
  archive      = {J_NCA},
  author       = {Yin, Pei and Zhao, Jun and Ma, Zi-jie and Tan, Xiao},
  doi          = {10.1007/s00521-023-09044-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9707-9721},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sequential recommendation based on multipair contrastive learning with informative augmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuralGLS: Learning to guide local search with graph
convolutional network for the traveling salesman problem. <em>NCA</em>,
<em>36</em>(17), 9687–9706. (<a
href="https://doi.org/10.1007/s00521-023-09042-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling salesman problem (TSP) aims to find the shortest tour that visits each node of a given graph exactly once. TSPs have significant importance as numerous practical problems can be naturally formulated as TSPs. Various algorithms have been developed for solving TSPs, including combinatorial optimization algorithms and deep learning-based approaches. However, these algorithms often face a trade-off between providing exact solutions with long running times and delivering fast but approximate solutions. Therefore, achieving both efficiency and solution quality simultaneously remains a major challenge. In this study, we propose a data-driven algorithm called NeuralGLS to address this challenge. NeuralGLS is a hybrid algorithm that combines deep learning techniques with guided local search (GLS). It incorporates a self-adaptive graph convolutional network (GCN) that takes into account neighborhoods of varying sizes, accommodating TSP instances with different graph sizes. This GCN calculates a regret value for each edge in a given TSP instance. Subsequently, the algorithm utilizes a mixed strategy to construct an initial tour and then employs a GLS module to iteratively improve the tour guided by the acquired regret values until a high-quality tour is obtained. Experimental results on diverse benchmark datasets and real-world TSP instances demonstrate the effectiveness of NeuralGLS in generating high-quality solutions within reasonable computation time. Furthermore, when compared to several state-of-the-art algorithms, our NeuralGLS algorithm exhibits superior generalization performance on both real-world and larger-scale TSP instances. Notably, NeuralGLS also outperforms another hybrid algorithm that also incorporates GLS by reducing the mean optimality gap for real-world TSP instances from 1.318% to 0.958%, with both methods achieving results within the same computation time. This remarkable improvement in solution quality amounts to an impressive relative enhancement of 27.31%.},
  archive      = {J_NCA},
  author       = {Sui, Jingyan and Ding, Shizhe and Xia, Boyang and Liu, Ruizhi and Bu, Dongbo},
  doi          = {10.1007/s00521-023-09042-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9687-9706},
  shortjournal = {Neural Comput. Appl.},
  title        = {NeuralGLS: Learning to guide local search with graph convolutional network for the traveling salesman problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the evolutionary game of rumor control based on
prospect theory. <em>NCA</em>, <em>36</em>(17), 9675–9685. (<a
href="https://doi.org/10.1007/s00521-023-09027-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased volume of rumors and attention on related topics during the COVID-19 pandemic have had a significant negative social impact. To combat rumors, it is crucial to study the actors involved in their spread. In this study, we first introduce prospect theory and construct an evolutionary game model between network operators and government regulators. We investigate collusion between network operators and Internet rumormongers as well as the regulatory behavior of government agencies. Second, we use prospect value to replace traditional expected utility to construct a profit prospect matrix and apply the dynamic replicator equation to analyze the equilibrium stability of the model. The stability conditions of the game between the two parties are closely related to the government’s regulatory costs, and the strength of government punishment after collusion is detected. Finally, we propose relevant countermeasures against collusion problems during the network rumor control period.},
  archive      = {J_NCA},
  author       = {Zhao, Jinghua and Lan, Ting and Rong, Haiying and Liu, Shanshan},
  doi          = {10.1007/s00521-023-09027-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9675-9685},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring the evolutionary game of rumor control based on prospect theory},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Re-HGNM: A repeat aware hypergraph neural machine for
session-based recommendation. <em>NCA</em>, <em>36</em>(17), 9661–9674.
(<a href="https://doi.org/10.1007/s00521-023-08985-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph neural network (HGNN) for session-based recommendation (SBR) is quite rare but has been rewarded with promising performance. However, under the hypergraph framework, no works have emphasized the importance of repeat consumption, which is an important consumption pattern in SBR (e.g., people watch movies or listen to music repeatedly over time) and limits the performance of SBR in a beyond graph topology manner. For filling this gap and better recommendation performance, this paper incorporates repeat consumption into HGNNs and proposes a new recommendation machine, named Re-HGNM, which leverages the powerful expressiveness of HGNNs in representation learning and takes repeat consumption into account by considering the relationship between repeat behaviors and modeling repeat recommendations. Specially, in the encoder of Re-HGNM, we process sessions as hyperedges, in which the repeated behaviors are merged, to constitute hypergraph that conveys not only the complex relations between unique items but the relationships between repeat behaviors. After learning item representation by hypergraph convolution, a repeat-explore module is employed to determine whether to make repeat recommendation. In repeat mode, the next click must be in old items; thereby, the shrunk prediction space makes it easier to find the target item. Therefore, in the decoding stage, two decoders correspondingly work under two separate modes. Finally, compared with the current best baseline, Re-HGNM relatively improved P@20 by 58.37%, 8.70%, 1.28%, and 1.16% and MRR@20 by 25.52%, 10.31%, 10.76%, and 2.76% on the Tmall, RetailRocket, Nowplaying, and Diginetica, to be the current state-of-the-art model for SBR.},
  archive      = {J_NCA},
  author       = {Peng, Yuze and Xu, Shengjun and Huang, Yihua},
  doi          = {10.1007/s00521-023-08985-0},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9661-9674},
  shortjournal = {Neural Comput. Appl.},
  title        = {Re-HGNM: A repeat aware hypergraph neural machine for session-based recommendation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Monocular vehicle speed detection based on improved YOLOX
and DeepSORT. <em>NCA</em>, <em>36</em>(17), 9643–9660. (<a
href="https://doi.org/10.1007/s00521-023-08963-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A monocular vehicle speed detection method based on improved YOLOX and DeepSORT is proposed for the simple scene of fixed shooting angle without high precision but requiring control cost. For continuous video frames collected from a monocular fixed perspective, the vehicle is first identified by using the YOLOX object detection network improved by ELAN module and the CAENet attention mechanism constructed by CA attention and ECANet. Then, the DeepSORT target tracking algorithm is used to match the recognition results of the object detection network output in the before and after frames to find the same target in different frames. Finally, a coordinate system transformation algorithm is used to convert the position distance of the target moving in different frame images into the actual ground plane distance and divide it by the detection interval time to obtain the vehicle speed. The experimental results show that our improved object detection model can increase mAP by 2% to 4% compared with YOLOX in different versions. Compared with the original model, the target tracking using the improved YOLOX is improved by 4.3% on MOTA. The speed limiting precision of speed detection is 75% in the corresponding speed range in experimental testing site 1 and the mean error of the effective velocity value measured by our speed measurement method is 2.10 km/h in experimental testing site 2, which is better than the mean error of 5.46 km/h obtained by the radar pistol velocimeter. This detection method enables economical and efficient vehicle speed detection in simple scenes.},
  archive      = {J_NCA},
  author       = {Zhang, Kaiyu and Wu, Fei and Sun, Haojun and Cai, Meiyu},
  doi          = {10.1007/s00521-023-08963-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9643-9660},
  shortjournal = {Neural Comput. Appl.},
  title        = {Monocular vehicle speed detection based on improved YOLOX and DeepSORT},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk mechanism evaluation of the metaverse network economy
based on transformer serialization analysis. <em>NCA</em>,
<em>36</em>(17), 9631–9641. (<a
href="https://doi.org/10.1007/s00521-023-08914-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaverse network economy is built on the blockchain protocol network and occurs in the metaverse virtual space by the virtual digital avatar. This is a series of economic activities that produce, exchange, distribute and consume digital products, and interact, integrate and promote with the real economy in real space. The network economic system of the metaverse is gradually formed in the process of adapting to the development of digital economy. While these products and services bring convenience, they are accompanied by more complex and diverse economic risks. Based on transformer serialization analysis, this paper proposes an analytical method of economic risk mechanism of metacosmic network to complete the evaluation of economic risk. First, this work proposes an improved transformer (ITransformer). The probabilistic sparse self-attention (PSSA) and self-attention distillation (SAD) are proposed to improve the performance. This can mine more discriminative temporal features. Secondly, this work designed a dual-stream ITransformer (DSIT) to evaluate the economic risks of the metaverse network via ITransformer. This can process the global and local features in the metaverse economic data with high performance. Finally, this work has performed massive experiments on dual-stream ITransformer pipeline. Experimental results verify the effectiveness and feasibility of DSIT.},
  archive      = {J_NCA},
  author       = {Li, Hongfei and Huang, Jieyu},
  doi          = {10.1007/s00521-023-08914-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9631-9641},
  shortjournal = {Neural Comput. Appl.},
  title        = {Risk mechanism evaluation of the metaverse network economy based on transformer serialization analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlled blockchain enabled data record security for
healthcare applications. <em>NCA</em>, <em>36</em>(17), 9617–9629. (<a
href="https://doi.org/10.1007/s00521-023-08835-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identity management (IM) solutions are designed for facilitating and managing in digital field that identifies to perform the authentication operation which has been widely used for the real-world applications. The blockchain-based IM solutions are provided which allows the user to take the control of his or her identity. The existing blockchain-based IM models and based identified the research gap and other opportunities that will improve the present research work. Also, the information for owners who are trustworthy, traceable, secure ownership for the medical data that created seriousness in the security issues. The techniques and systems were centralized made difficult for sharing the medical data that have increased the single point of failure. The blockchain technology enabled the transparent, dependable, and auditable computing in various industries that used the decentralized network in the public ledger. The main objective is to exchange data in a safe and secure manner by using unalterable logs. To achieve and to improve the transparency, security and privacy, the verifiable digital signature with controlled blockchain enabled data records (DVS-CBDR) is introduced. Performance study of the proposed system has been assessed by a number of studies, examining throughput (170 tx/s), transaction response time (21 s), latency (5 s), memory usage (200 MB), and CPU utilization (98 Hz) which is better than patient-controlled blockchain enabled electronic health records for healthcare (PcBEHR).},
  archive      = {J_NCA},
  author       = {Chintapalli, Siva Surya Narayana and Paramesh, S. P. and Nijaguna, G. S. and Jeyaraj, Jane Rubel Angelina and Subhash, P.},
  doi          = {10.1007/s00521-023-08835-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {17},
  pages        = {9617-9629},
  shortjournal = {Neural Comput. Appl.},
  title        = {Controlled blockchain enabled data record security for healthcare applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Alcoholism identification via convolutional
neural network based on parametric ReLU, dropout, and batch
normalization. <em>NCA</em>, <em>36</em>(16), 9615. (<a
href="https://doi.org/10.1007/s00521-024-09873-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Wang, Shui-Hua and Muhammad, Khan and Hong, Jin and Sangaiah, Arun Kumar and Zhang, Yu-Dong},
  doi          = {10.1007/s00521-024-09873-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9615},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Alcoholism identification via convolutional neural network based on parametric ReLU, dropout, and batch normalization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: A-COA: An adaptive cuckoo optimization
algorithm for continuous and combinatorial optimization. <em>NCA</em>,
<em>36</em>(16), 9613. (<a
href="https://doi.org/10.1007/s00521-024-09872-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Boveiri, H. R. and Elhoseny, M.},
  doi          = {10.1007/s00521-024-09872-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9613},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: A-COA: an adaptive cuckoo optimization algorithm for continuous and combinatorial optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Refining parkinson’s neurological disorder
identification through deep transfer learning. <em>NCA</em>,
<em>36</em>(16), 9611. (<a
href="https://doi.org/10.1007/s00521-024-09843-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Naseer, Amina and Rani, Monail and Naz, Saeeda and Razzak, Muhammad Imran and Imran, Muhammad and Xu, Guandong},
  doi          = {10.1007/s00521-024-09843-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9611},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Refining parkinson’s neurological disorder identification through deep transfer learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Fuzzy rank correlation-based segmentation
method and deep neural network for bone cancer identification.
<em>NCA</em>, <em>36</em>(16), 9609. (<a
href="https://doi.org/10.1007/s00521-024-09808-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Altameem, Torki},
  doi          = {10.1007/s00521-024-09808-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9609},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Fuzzy rank correlation-based segmentation method and deep neural network for bone cancer identification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Retraction note: Decision-level fusion scheme for
nasopharyngeal carcinoma identification using machine learning
techniques. <em>NCA</em>, <em>36</em>(16), 9607–9608. (<a
href="https://doi.org/10.1007/s00521-024-09807-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ghani, Mohd Khanapi Abd and Mohammed, Mazin Abed and Arunkumar, N. and Mostafa, Salama A. and Ibrahim, Dheyaa Ahmed and Abdullah, Mohamad Khir and Jaber, Mustafa Musa and Abdulhay, Enas and Ramirez-Gonzalez, Gustavo and Burhanuddin, M. A.},
  doi          = {10.1007/s00521-024-09807-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9607-9608},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Decision-level fusion scheme for nasopharyngeal carcinoma identification using machine learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction: HATDO: Hybrid archimedes tasmanian devil
optimization CNN for classifying offensive comments and non-offensive
comments. <em>NCA</em>, <em>36</em>(16), 9605. (<a
href="https://doi.org/10.1007/s00521-024-09607-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Aarthi, B. and Chelliah, Balika J.},
  doi          = {10.1007/s00521-024-09607-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9605},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: HATDO: hybrid archimedes tasmanian devil optimization CNN for classifying offensive comments and non-offensive comments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning-based framework for object recognition in
ecological environments with dense focal loss and occlusion.
<em>NCA</em>, <em>36</em>(16), 9591–9604. (<a
href="https://doi.org/10.1007/s00521-024-09582-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In precision agricultural analysis, the remote sensing of geospatial data holds substantial potential for multi-purpose crop surveys, targeting automatic crop area delineation, health monitoring, and yield estimation. Advanced remote sensing methods, when integrated with machine learning techniques, have significantly advanced agricultural analyses. This study introduces a three-tiered framework. Firstly, orchard areas are delineated using the ESA Sentinel-2 multispectral instrument (MSI) at 10 m resolution, employing the normalized differential vegetation index (NDVI). In the second stage, mango tree canopies are detected from hand-annotated true color composite imagery using two variants of a convolutional neural network. The first variant, CanopyNet-1, is built directly over RetinaNet foundational layers, achieving a mean average precision (mAP) of 0.79, a precision of 0.80, and a recall of 0.76. The second variant, CanopyNet-2, builds upon DeepForest, a generalized tree canopy trained model, also using RetinaNet at its base. CanopyNet-2 demonstrates superior performance, achieving a mAP of 0.83, a precision of 0.98, and a recall of 0.96, notably surpassing conventional models such as YOLOv5 and Faster R-CNN. Lastly, the health of the orchard is characterized using 3-m-resolution multispectral imagery. Cumulatively, our framework, with its tiered approach, exhibits high accuracy in both tree canopy delineation and health characterization, suggesting it as a comprehensive solution for large-scale orchard monitoring and yield optimization.},
  archive      = {J_NCA},
  author       = {Afsar, Muhammad Munir and Bakhshi, Asim Dilawar and Hussain, Ejaz and Iqbal, Javed},
  doi          = {10.1007/s00521-024-09582-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9591-9604},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning-based framework for object recognition in ecological environments with dense focal loss and occlusion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved binary snake optimizer with gaussian mutation
transfer function and hamming distance for feature selection.
<em>NCA</em>, <em>36</em>(16), 9567–9589. (<a
href="https://doi.org/10.1007/s00521-024-09581-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The snake optimizer (SO) is a highly efficient bio-inspired algorithm for solving continuous optimization problems. This algorithm mathematically simulates the unique foraging and mating behaviors observed in snake populations in nature. However, this algorithm cannot be directly applied to solve binary optimization problems, such as feature selection. Feature selection is a significant data preprocessing step in data mining, aimed at reducing data dimensionality, lowering computational costs in terms of time and space, and improving the predictive accuracy of classifiers. To address this limitation, an improved binary version of SO (IBSO) is proposed for feature selection, which incorporates the concept of hamming distance and introduces a novel mutation transfer function (MTF). IBSO extends the application of the conventional SO to binary optimization problems by introducing hamming distance and presents a new binary position update strategy. Furthermore, IBSO utilizes a MTF based on a Gaussian distribution. The MTF not only transforms each dimension of each individual in the population into binary space but also enhances the local random search capability and increases the population diversity of the algorithm. Finally, the experiment is conducted on 27 standard benchmark datasets from UC Irvine Machine Learning Repository and IBSO is compared with several state-of-the-art binary swarm intelligence algorithms to analyze the effectiveness and efficiency of IBSO. The results show that IBSO can obtain the best fitness values with less CPU time. Besides, to evaluate the validity of the proposed MTF, IBSO is compared with other binary versions of SO with different well-known transfer functions.},
  archive      = {J_NCA},
  author       = {Bao, Xinyu and Kang, Hui and Li, Hongjuan},
  doi          = {10.1007/s00521-024-09581-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9567-9589},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved binary snake optimizer with gaussian mutation transfer function and hamming distance for feature selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep graph-level clustering using pseudo-label-guided mutual
information maximization network. <em>NCA</em>, <em>36</em>(16),
9551–9566. (<a
href="https://doi.org/10.1007/s00521-024-09575-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the problem of partitioning a set of graphs into different groups such that the graphs in the same group are similar while the graphs in different groups are dissimilar. This problem was rarely studied previously, although there has been a lot of work on node clustering and graph classification. The problem is challenging because it is difficult to measure the similarity or distance between graphs. One feasible approach is using graph kernels to compute a similarity matrix for the graphs and then performing spectral clustering, but the effectiveness of existing graph kernels in measuring the similarity between graphs is very limited. To solve the problem, we propose a novel method called Deep Graph-Level Clustering (DGLC). DGLC utilizes a graph isomorphism network to learn graph-level representations by maximizing the mutual information between the representations of entire graphs and sub-structures, under the regularization of a clustering module that ensures discriminative representations via pseudo-labels. DGLC achieves graph-level representation learning and graph-level clustering in an end-to-end manner. The experimental results on six benchmark datasets of graphs show that our DGLC has state-of-the-art performance in comparison to many baselines.},
  archive      = {J_NCA},
  author       = {Cai, Jinyu and Han, Yi and Guo, Wenzhong and Fan, Jicong},
  doi          = {10.1007/s00521-024-09575-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9551-9566},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep graph-level clustering using pseudo-label-guided mutual information maximization network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A maximal-clique-based clustering approach for
multi-observer multi-view data by using k-nearest neighbor with
s-pseudo-ultrametric induced by a fuzzy similarity. <em>NCA</em>,
<em>36</em>(16), 9525–9550. (<a
href="https://doi.org/10.1007/s00521-024-09560-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partitioning multi-view data is a recent challenge in clustering methods, which traditionally consider single-view data. In clustering techniques, finding the similarity or distance between objects, handled by metrics in $$\mathbb {R}^{n}$$ , plays a central role in community detection. Under this framework, different algorithms have been developed where the output relies on an exact distance calculated based on the objects’ features. As feature information might be qualitative data defined in an ambiguous environment, this study offers a new class of metrics, so-called S-distance, as a dual of a fuzzy T-similarity, which successfully produces a collective distance based on all views/observers and provides a more flexible framework to define distance under uncertainty. Besides, most existing approaches handle multi-view clustering by aggregating each view’s clusters or using an iterative optimization method; both are time-consuming. Here, by transforming the multi-view clustering problem into node clustering, we suggest a new approach without iteration for multi-view and multi-observer data. Our proposed method, GMSkNN, uses an attribute-structural similarity relation between nodes to get more coherent clusters. To this end, we first build a k-nearest neighbor (kNN) directed graph using the proposed S-distance, then transform it into an undirected graph based on the neighborhood information of the nodes so that the resultant graph is characterized based on nodes interactions and initial features information of the nodes. Next, a new maximal-clique-based clustering is designed to complete the node partitioning. The proposed clustering algorithm is programmed and tested on synthetic and four real-world datasets using the R software. The clustering results are analyzed based on several indexes. This analysis shows the efficiency of the proposed algorithm compared to the traditional clustering methods.},
  archive      = {J_NCA},
  author       = {Khameneh, Azadeh Zahedi and Ghaznavi, Mehrdad and Kilicman, Adem and Mahad, Zahari and Mardani, Abbas},
  doi          = {10.1007/s00521-024-09560-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9525-9550},
  shortjournal = {Neural Comput. Appl.},
  title        = {A maximal-clique-based clustering approach for multi-observer multi-view data by using k-nearest neighbor with S-pseudo-ultrametric induced by a fuzzy similarity},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the empirical performance of different covariance-matrix
forecasting methods. <em>NCA</em>, <em>36</em>(16), 9503–9524. (<a
href="https://doi.org/10.1007/s00521-024-09574-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study of financial time series, covariance/correlation matrices play a central role in risk-related applications, including financial contagion and portfolio selection. Different methodologies have been used in their prediction, from methods based on Financial Econometrics DCC-GARCH (Engle in J Bus Econ Stat 20(3):339–350, 2002), to others linked to Ecophysics like Random Matrix Theory (Wang et al. in Comput Econ 51:607–635, 2018), and more recently to Machine Learning (Fiszeder and Orzeszko in Appl Intell 51(10):7029–7042, 2021). Despite these developments, there is no state-of-the-art study that compares all these methods and assesses their predictive power in an out-of-sample setting. Indeed, in this work, we focus on measuring the out-of-sample predictive power of correlation matrices of these different statistical methods, in particular from three different fields that have converged in recent years in the analysis of financial data: Econometrics, Econophysics, and Machine Learning. Thus, using a moving window scheme, we studied the correlation matrices of 29 stock market indexes from different latitudes of the world. Among our findings, we see the relationship between the measures of Eigen Entropy found in the market, with the error found in the forecast of each method in the form of Square Forecast Error. We find that in the period from 2008 to 2022, considering 2608 moving windows, the out-of-sample error tends to converge between the different methods, highlighting the performance of DCC-GARCH.},
  archive      = {J_NCA},
  author       = {Torres, Rafael and Villena, Marcelo},
  doi          = {10.1007/s00521-024-09574-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9503-9524},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the empirical performance of different covariance-matrix forecasting methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A prediction model for plastic hinge length of rectangular
RC columns using gene expression programming. <em>NCA</em>,
<em>36</em>(16), 9481–9501. (<a
href="https://doi.org/10.1007/s00521-024-09578-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the reinforced concrete (RC) columns which are exposed extreme loads such as earthquake effects, the plastic hinge length can be defined as the length of the region where flexural moments exceed the yielding capacity, and the plastic deformations are concentrated. More accurate estimation of plastic hinge length increases the reliability of the seismic design. However, a sensitivity prediction of plastic hinge length is difficult due to a large number of model parameters. Therefore, this study aims to predict the plastic hinge length using the gene expression programming (GEP). An experimental database of 133 RC columns gathered from the literature was utilized for prediction with GEP. The results of GEP model are statistically compared with those of 13 models existing in the literature proposed by various researchers. The comparison results reveal that the proposed GEP-based formulation has the best efficiency among all models. Furthermore, a sensitivity analysis and parametric study are conducted to identify the most influential parameters affecting the GEP formulation.},
  archive      = {J_NCA},
  author       = {Alacali, Sema and Arslan, Guray},
  doi          = {10.1007/s00521-024-09578-1},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9481-9501},
  shortjournal = {Neural Comput. Appl.},
  title        = {A prediction model for plastic hinge length of rectangular RC columns using gene expression programming},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Moth flame algorithm-based optimization of a reduced switch
multilevel inverter topology suitable for standalone application.
<em>NCA</em>, <em>36</em>(16), 9437–9479. (<a
href="https://doi.org/10.1007/s00521-024-09576-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating demand for sustainable and environmentally friendly energy sources has driven substantial growth in renewable energy adoption across residential and industrial sectors. To effectively meet this demand, the development of efficient and sustainable renewable energy conversion methods is crucial, with inverters playing a pivotal role in achieving this objective. While researchers strive to enhance inverter power handling capabilities and reduce output harmonic contents, the incorporation of additional power electronic switches and peripheral devices presents challenges such as increased circuit cost, complexity, and size. Additionally, the utilization of high-frequency switching techniques for achieving low output harmonics results in elevated switching losses and electromagnetic interference, adversely affecting sensitive electronic devices. This research introduces a novel approach to address these issues through the introduction of a reduced switch multilevel inverter topology. Unlike existing systems, the proposed topology employs a reduced number of power electronic switches and direct current sources to generate a stable output voltage waveform. Operating in a symmetric mode, the topology achieves a nine-level output voltage with enhanced harmonic elimination capabilities. A multiple-stepped selective harmonic elimination (SHE-PWM) switching control technique, employing a 1/3/3/1 distribution ratio, is utilized to extend the harmonic elimination range from 3 to 7 lower-order harmonics. To optimize the switching angles required for the proposed topology, the moth flame optimization (MFO) algorithm is employed and compared with particle swarm optimization (PSO) and whale optimization algorithms (WOA). The MFO algorithm exhibits faster convergence to the global optima, achieving an optimal fitness value of 3.322e−08 at 0.78 modulation points. This results in total harmonic distortion values of 0.7%, 0.757%, and 1.069% for MFO, PSO, and WOA, respectively, with corresponding total losses of 71.609W, 71.794W, and 79.792W. The proposed inverter topology is simulated using PSIM software and experimentally verified using a typhoon HIL-402 hardware-in-the-loop testing device. The simulation and experimental results provide compelling evidence for the superior performance of the MFO algorithm compared to PSO and WOA in achieving improved inverter performance. The proposed topology, in conjunction with the MFO algorithm, presents a promising solution for efficient and sustainable renewable energy conversion, thereby contributing to the advancement of renewable energy technologies in both residential and industrial settings.},
  archive      = {J_NCA},
  author       = {Shanono, Ibrahim Haruna and Abdullah, Nor Rul Hasma and Daniyal, Hamdan and Muhammad, Aisha},
  doi          = {10.1007/s00521-024-09576-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9437-9479},
  shortjournal = {Neural Comput. Appl.},
  title        = {Moth flame algorithm-based optimization of a reduced switch multilevel inverter topology suitable for standalone application},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting manta rays foraging optimizer by trigonometry
operators: A case study on medical dataset. <em>NCA</em>,
<em>36</em>(16), 9405–9436. (<a
href="https://doi.org/10.1007/s00521-024-09565-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of attributes has become a crucial research focus in the domains of pattern recognition, machine learning, and big data analysis. In essence, the contemporary challenge revolves around reducing dimensionality while maintaining both a quick response time and improved classification performance. Metaheuristics algorithms (MAs) have emerged as pivotal tools in addressing this issue. Firstly, the problem of attribute selection was approached using the manta ray foraging optimization (MRFO) approach, but the majority of MAs suffer from a problem of convergence toward local minima. To mitigate this challenge, an enhanced variant of MRFO, known as MRFOSCA, employs trigonometric operators inspired by the sine cosine algorithm (SCA) to tackle the feature selection problem. The k-nearest neighbor (k-NN) technique is employed for feature-set selection. Additionally, the statistical significance of the proposed algorithms is assessed using the nonparametric Wilcoxon’s rank-sum test at a 5% significance level. The outcomes are assessed and compared against some well-known MAs, including the original MRFO and SCA, as well as Harris Hawks optimizer, dragonfly algorithm, grasshopper optimizer algorithm, whale optimizer algorithm, salp swarm algorithm, and grey wolf optimizer. The experimental and comparison analyses validate the pretty effective performance of the proposed methods on low- and high-dimensional datasets by providing the highest accuracy in 85% of the feature selection benchmarks.},
  archive      = {J_NCA},
  author       = {Neggaz, Nabil and Neggaz, Imene and Abd Elaziz, Mohamed and Hussien, Abdelazim G. and Abulaigh, Laith and Damaševičius, Robertas and Hu, Gang},
  doi          = {10.1007/s00521-024-09565-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9405-9436},
  shortjournal = {Neural Comput. Appl.},
  title        = {Boosting manta rays foraging optimizer by trigonometry operators: A case study on medical dataset},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extended intuitionistic fuzzy ABAC method for evaluating
innovative project ideas. <em>NCA</em>, <em>36</em>(16), 9375–9404. (<a
href="https://doi.org/10.1007/s00521-024-09563-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The innovation process typically follows a predefined sequence of phases: idea generation, screening, evaluation/selection, development, and launch/diffusion. This process exhibits a dynamic and cyclic structure. At each stage, potential ideas may undergo elimination or redefinition based on considerations such as their problem–solution fit or product–market fit. Consequently, the idea evaluation phase can be conducted continuously, involving varying numbers of potential ideas. To address the challenges associated with this process, a systematic approach for selecting the best new project ideas is essential. This study introduces the IF-ABAC method, which extends the alternative-by-alternative comparison-based (ABAC) method to the intuitionistic fuzzy (IF) environment. The proposed approach represents the first combination of fuzzy sets and ABAC within a group decision-making environment. The IF-ABAC method is employed during the evaluation phase, with the best–worst method determining the criteria weights. The study describes how the IF-ABAC approach adeptly manages changes in the set of alternatives after the decision process, addressing the dynamics inherent in decision-making environments. The study further includes an analysis of innovative business ideas in a real case study from Turkey, demonstrating the feasibility and efficiency of the proposed approach. A comprehensive sensitivity analysis is conducted to illustrate the stability and utility of the method. Finally, the results are compared with three other IF-based multi-criteria decision-making methods from the literature. The study concludes by asserting that the proposed IF-ABAC method provides a comprehensive and practical approach to select innovation project ideas in an environment of uncertainty and complexity.},
  archive      = {J_NCA},
  author       = {Cubukcu, Ahmet and Ervural, Bilal and Ayaz, Halil Ibrahim},
  doi          = {10.1007/s00521-024-09563-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9375-9404},
  shortjournal = {Neural Comput. Appl.},
  title        = {An extended intuitionistic fuzzy ABAC method for evaluating innovative project ideas},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new deep neuro-fuzzy system for lyme disease detection and
classification using UNet, inception, and XGBoost model from medical
images. <em>NCA</em>, <em>36</em>(16), 9361–9374. (<a
href="https://doi.org/10.1007/s00521-024-09583-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lyme disease, caused by a bacterium transmitted through the bite of an infected tick, is often misdiagnosed due to its similarity to other conditions like drug rash. This research introduces an innovative approach by integrating prominent deep learning models, including UNet, Inception Model, and XGBoost, into the Deep Neuro-Fuzzy System. Utilizing a comprehensive Kaggle dataset, authors study aims to achieve heightened accuracy in recognizing and segmenting Lyme disease from medical images. Implemented in Python, authors advanced image processing methods demonstrate exceptional performance, reaching an outstanding accuracy of 97.36% after the recognition stage. To further enhance accuracy, authors introduce an additional layer of sophistication through the incorporation of the mayfly optimization (MO) approach. This strategic integration of MO contributes to the outstanding accuracy achieved by their models. This research not only addresses the challenges of Lyme disease misdiagnosis but also presents a robust framework for medical image recognition. Leveraging the collaborative and open nature of Kaggle and the versatility of the Python programming ecosystem, authors work contributes to advancing the field of Lyme disease detection and medical image processing.},
  archive      = {J_NCA},
  author       = {Priyan, S. Vishnu and Dhanasekaran, S. and Karthick, P. Vivek and Silambarasan, D.},
  doi          = {10.1007/s00521-024-09583-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9361-9374},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new deep neuro-fuzzy system for lyme disease detection and classification using UNet, inception, and XGBoost model from medical images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel decomposition-based architecture for multilingual
speech emotion recognition. <em>NCA</em>, <em>36</em>(16), 9347–9359.
(<a href="https://doi.org/10.1007/s00521-024-09577-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilingual speech emotion recognition (MLSER) is a significant and demanding research domain to improve the utility of human–computer interaction systems. Identifying the emotions from the spoken sentence is one of the most challenging tasks due to the dependency of the MLSER system on spoken languages. This study proposes a novel decomposition-based architecture for MLSER. The architecture includes silence removal, mode tuning, signal reconstruction, feature extraction, feature optimization and classification. In preprocessing, the silence part is removed using short-time energy and spectral centroid. After that, variational mode decomposition is applied for signal decomposition, where the improved Bhattacharyya distance is explored for the decomposition mode tuning. The tuned modes are examined for noise removal, and the signal is reconstructed using denoised modes. The spectral and prosodic features are computed from the reconstructed signal. The optimized features are obtained from the extracted features using the ReliefF algorithm. Finally, the fine k-nearest neighbor classifier is explored with optimized features to identify the emotions. For the experiment, three publicly available emotion databases, namely the English language-based Ryerson audio–visual database (RAVDESS), German language-based emotional speech Berlin database (Emo-DB) and Italian emotional speech database (EMOVO), are used. The proposed method yielded 90.7%, 94% and 91.1% accuracy for English, German and Italian language-based database, respectively. A multilingual database is created with these three databases, and the proposed method yields 93.4% accuracy for this database. The proposed framework provides more efficient and minimum language dependency compared to available traditional and deep learning-based approaches.},
  archive      = {J_NCA},
  author       = {Ravi and Taran, Sachin},
  doi          = {10.1007/s00521-024-09577-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9347-9359},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel decomposition-based architecture for multilingual speech emotion recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PCDR-DFF: Multi-modal 3D object detection based on point
cloud diversity representation and dual feature fusion. <em>NCA</em>,
<em>36</em>(16), 9329–9346. (<a
href="https://doi.org/10.1007/s00521-024-09561-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multi-modal 3D object detection techniques based on point clouds and images have received increasing attention. However, existing methods for multi-modal feature fusion are often relatively singular, and single point cloud representation methods also have some limitations. For example, voxelization may result in the loss of fine-grained information, while 2D images lack depth information, which can restrict the accuracy of detection. Therefore, in this work, we propose a novel method for multi-modal 3D object detection based on point cloud diversity representation and dual feature fusion, PCDR-DFF, to improve the prediction accuracy of 3D object detection. Firstly, point clouds are projected to the image coordinate system and extract multi-level features of the point cloud corresponding to the image using a 2D backbone network. Then, the point clouds are jointly characterized using graphs and pillars, and the 3D features of the point clouds are extracted using graph neural networks and residual connectivity. Finally, a dual feature fusion method is designed to improve the accuracy of detection with the help of a well-designed multi-point fusion model and multi-feature fusion mechanism embedded with a spare 3D-U Net. Extensive experiments on the KITTI dataset demonstrate the effectiveness and competitiveness of our proposed models in comparison with other methods.},
  archive      = {J_NCA},
  author       = {Xia, Chenxing and Li, Xubing and Gao, Xiuju and Ge, Bin and Li, Kuan-Ching and Fang, Xianjin and Zhang, Yan and Yang, Ke},
  doi          = {10.1007/s00521-024-09561-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9329-9346},
  shortjournal = {Neural Comput. Appl.},
  title        = {PCDR-DFF: Multi-modal 3D object detection based on point cloud diversity representation and dual feature fusion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leukemia classification using different CNN-based
algorithms-comparative study. <em>NCA</em>, <em>36</em>(16), 9313–9328.
(<a href="https://doi.org/10.1007/s00521-024-09554-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leukemia or blood cancer has its roots in the bone marrow. It is distinguished by irregular white blood cell proliferation. Early diagnosis of leukemia is crucial to increase the effectiveness of its treatment. However, manual methods to detect and classify leukemia from blood microscopic images are time-consuming and susceptible to inter and intra-observer variations. Therefore, a low-cost, fully automated, and robust system for leukemia detection and classification is required. Many algorithms have been found in the literature to detect it but not to classify its four different types with high accuracy. The proposed study uses different CNN-based algorithms to detect leukemia and classify its types. AlexNet, DenseNet, ResNet, and VGG16 were used. Images from three datasets were tested; 108 images from the ALL-IDB dataset, 547 images ASH Image bank, and 15 images captured in the biomems and bionanotechnology laboratory at JUST. The best results were achieved by retraining a pre-trained model through transfer learning with fine-tuning weights. All models used gave acceptable accuracies, reaching 99.8%, 99.7%, and 94% for training, validation, and testing sets, respectively. The proposed study provides clear, accurate, and reliable guidance to researchers who are working on leukemia detection and classification, and hence provides the medical staff with an easy and effective system to diagnose leukemia without any human intrusion; furthermore, it is expected to save time and effort at a lower price.},
  archive      = {J_NCA},
  author       = {Al-Bashir, Areen K. and Khnouf, Ruba E. and Bany Issa, Lamis R.},
  doi          = {10.1007/s00521-024-09554-9},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9313-9328},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leukemia classification using different CNN-based algorithms-comparative study},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel approach for parkinson’s disease detection using
vold-kalman order filtering and machine learning algorithms.
<em>NCA</em>, <em>36</em>(16), 9297–9311. (<a
href="https://doi.org/10.1007/s00521-024-09569-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is the second most common neurological disorder caused by damage to dopaminergic neurons. Therefore, it is important to develop systems for early and automatic diagnosis of PD. For this purpose, a study that will contribute to the development of systems for the automatic diagnosis of PD is presented. The Electroencephalography  (EEG) signals were decomposed into sub-bands using adaptive decomposition methods, such as empirical mode decomposition, variational mode decomposition, and Vold-Kalman order filtering (VKF). Various features were extracted from the sub-band decomposed signals, and the significant ones were determined by Chi-squared test. These important features were applied as input to support vector machine (SVM), fitch neural network (FNN), k-nearest neighbours (KNN), and decision trees (DT), machine learning (ML) models and classification was performed. We analysed the performance of ML models by obtaining accuracy, sensitivity, specificity, positive predictive value, negative predictive values, F1-score, false-positive rate, kappa statistics, and area under the curve. The classification process was performed for two cases: PD ON-HC and PD OFF-HC groups. The most successful method in this study was the VKF method, which was applied for the first time in this field with the approach specified for both cases. In both instances, the SVM algorithm was employed as the ML model, with classifier performance criterion values close to 100%. The results obtained in this study seem to be successful compared to the results of recent research on the diagnosis of PD.},
  archive      = {J_NCA},
  author       = {Latifoğlu, Fatma and Penekli, Sultan and Orhanbulucu, Fırat and Chowdhury, Muhammad E. H.},
  doi          = {10.1007/s00521-024-09569-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9297-9311},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel approach for parkinson’s disease detection using vold-kalman order filtering and machine learning algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SA-DCPNet: Scale-aware deep convolutional pyramid network
for crowd counting. <em>NCA</em>, <em>36</em>(16), 9283–9295. (<a
href="https://doi.org/10.1007/s00521-024-09572-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting is one of the most complex research topics in the field of computer vision. There are many challenges associated with this task, including severe occlusion, scale variation, and complex background. Multi-column networks are commonly used for crowd counting, but they suffer from scale variation and feature similarity, which leads to poor analysis of crowd sequences. To address these issues, we propose a scale-aware deep convolutional pyramid network for crowd counting. We have introduced a scale-aware deep convolutional pyramid module by integrating message passing and global attention mechanisms into a multi-column network. The proposed network minimizes the problem of scale variation using SA-DPCM and uses a multi-column variance loss function to handle issues with feature similarity. Experiments have been performed over the ShanghaiTech and UCF-CC-50 datasets, which show the better performance of the proposed method in terms of mean absolute error and root mean square error.},
  archive      = {J_NCA},
  author       = {Tyagi, Bhawana and Nigam, Swati and Singh, Rajiv},
  doi          = {10.1007/s00521-024-09572-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9283-9295},
  shortjournal = {Neural Comput. Appl.},
  title        = {SA-DCPNet: Scale-aware deep convolutional pyramid network for crowd counting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive modeling for mitigating fugitive emissions in
industrial valve seal stacks: A comparative analysis of configuration
efficacies. <em>NCA</em>, <em>36</em>(16), 9263–9281. (<a
href="https://doi.org/10.1007/s00521-024-09584-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the development and application of advanced predictive modeling techniques to address the critical environmental challenge of fugitive emission mitigation in industrial valve seal stacks, specifically in the context of the oil and gas sector. Emphasizing the reduction of greenhouse gas emissions, the research systematically evaluates the effectiveness of multiple seal-stack configurations in minimizing emissions. The experimental framework utilizes argon gas as a surrogate for methane to simulate real-world scenarios. The research employs a comprehensive suite of predictive models, including advanced statistical and machine learning algorithms such as linear regression, ridge regression, Lasso (least absolute shrinkage and selection operator), MARS (multivariate adaptive regression splines), and elastic net. These models are rigorously tested to ascertain their predictive accuracy in estimating the emission levels of two different seal-stack arrangements. Each seal stack contains five individual seals of PTFE and AFLAS in different sequences. The MARS model, identified for its superior performance, is then applied to predict the efficacy of various seal-stack configurations against the stringent ISO 15848–1 standards for allowable emission limits. The results of this comparative analysis offer critical insights into the optimal combination of seal stacks, contributing significantly to the advancement of environmental sustainability practices in industrial applications. This research not only provides a methodological framework for predictive analysis in this domain but also underscores the importance of integrating environmental considerations into industrial design and operation.},
  archive      = {J_NCA},
  author       = {Sakib, Ahmed Nazmus and Bhuiyan, Md Monjur Hossain and Corral, Alfredo Becerril and Siddique, Zahed and Chowdhury, Monsur},
  doi          = {10.1007/s00521-024-09584-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9263-9281},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive modeling for mitigating fugitive emissions in industrial valve seal stacks: A comparative analysis of configuration efficacies},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive modeling of physical and mechanical properties of
pervious concrete using XGBoost. <em>NCA</em>, <em>36</em>(16),
9245–9261. (<a
href="https://doi.org/10.1007/s00521-024-09553-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High permeability of pervious concrete (PC) makes it a special type of concrete utilised for certain applications. However, the complexity of the behaviour and properties of PC leads to costly, time consuming and energy demanding experimental works to accurately determine the mechanical and physical properties of PC. This study presents a predictive model to predict the mechanical and physical properties of PC using Extreme Gradient Boost (XGBoost). The compressive strength, tensile strength, density and porosity of PC was predicted using four models evaluated using different statistical parameters. These statistical measures are the root mean squared error (RMSE), square of correlation coefficient (R2), mean absolute error (MAE) and mean absolute percentage error (MAPE). The estimation of these properties by the XGBoost models were in agreement with the experimental measurements. The performance of XGBoost is further validated by comparing its estimations to those obtained from four corresponding support vector regression (SVR) models. The comparison showed that XGBoost generally outperformed SVR with lower RMSE of 0.58 to SVR’s 0.74 for compressive strength, 0.17 to SVR’s 0.21 for tensile strength, 0.98 to SVR’s 1.28 for porosity, and 34.97 to SVR’s 44.06 for density. Due to high correlation between the predicted and experimentally obtained properties, the XGBoost models are able to provide quick and reliable information on the properties of PC which are experimentally costly and time consuming. A feature importance and contribution analysis of the input/predictor variables showed that the cement proportion is the most important and contributory factor in the estimation of physical and mechanical properties of PC.},
  archive      = {J_NCA},
  author       = {Mustapha, Ismail B. and Abdulkareem, Zainab and Abdulkareem, Muyideen and Ganiyu, Abideen},
  doi          = {10.1007/s00521-024-09553-w},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9245-9261},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predictive modeling of physical and mechanical properties of pervious concrete using XGBoost},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal neural network with handcrafted features for
skeleton-based action recognition. <em>NCA</em>, <em>36</em>(16),
9221–9243. (<a
href="https://doi.org/10.1007/s00521-024-09559-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of human action recognition (HAR) can be found in many computer vision practical applications. Various data modalities have been considered for solving this task, including joint-based skeletal representations which are suitable for real-time applications on platforms with limited computational resources. We propose a spatio-temporal neural network that uses handcrafted geometric features to classify human actions from video data. The proposed deep neural network architecture combines graph convolutional and temporal convolutional layers. The experiments performed on public HAR datasets show that our model obtains results similar to other state-of-the-art methods but has a lower inference time while offering the possibility to obtain an explanation for the classified action.},
  archive      = {J_NCA},
  author       = {Nan, Mihai and Trăscău, Mihai and Florea, Adina-Magda},
  doi          = {10.1007/s00521-024-09559-4},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9221-9243},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatio-temporal neural network with handcrafted features for skeleton-based action recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic detection of code smells using metrics and CodeT5
embeddings: A case study in c#. <em>NCA</em>, <em>36</em>(16),
9203–9220. (<a
href="https://doi.org/10.1007/s00521-024-09551-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code smells are poorly designed code structures indicating that the code may need to be refactored. Recognizing code smells in practice is complex, and researchers strive to develop automatic code smell detectors. An obstacle to developing these solutions is the datasets’ limitations. Manually labeled datasets were collected to investigate the developers’ perceptions of code smells. They are characterized by a high label disagreement that hurts the performance of Machine Learning (ML) models trained using them. Furthermore, all large, manually labeled datasets are developed for Java. We recently created a novel dataset for C# to alleviate these issues. This paper evaluates ML code smell detection approaches on our novel dataset. We consider two feature representations to train ML models: (1) code metrics and (2) CodeT5 embeddings. This study is the first to consider the CodeT5 state-of-the-art neural source code embedding for code smell detection in C#. To prove the effectiveness of ML, we consider multiple metrics-based heuristics as alternatives. In our experiments, the best-performing approach was the ML classifier trained on code metrics (F-measure of 0.87 for Long Method and 0.91 for Large Class detection). However, the performance improvement over CodeT5 features is negligible if we consider the advantages of automatically inferring features. Finally, our ML model surpassed less experienced annotators and nearly matched the most experienced annotator, suggesting it can assist less experienced developers under tight deadlines. To the best of our knowledge, this is the first study to compare the performance of automatic smell detectors against human performance.},
  archive      = {J_NCA},
  author       = {Kovačević, Aleksandar and Luburić, Nikola and Slivka, Jelena and Prokić, Simona and Grujić, Katarina-Glorija and Vidaković, Dragan and Sladić, Goran},
  doi          = {10.1007/s00521-024-09551-y},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9203-9220},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic detection of code smells using metrics and CodeT5 embeddings: A case study in c#},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive neuro-fuzzy based hybrid classification model for
emotion recognition from EEG signals. <em>NCA</em>, <em>36</em>(16),
9189–9202. (<a
href="https://doi.org/10.1007/s00521-024-09573-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition using physiological signals has gained significant attention in recent years due to its potential applications in various domains, such as healthcare and entertainment. EEG signals have been particularly useful in emotion recognition due to their non-invasive nature and high temporal resolution. However, the development of accurate and efficient algorithms for emotion classification using EEG signals remains a challenging task. This paper proposes a novel hybrid algorithm for emotion classification based on EEG signals, which combines multiple adaptive network models and probabilistic neural networks. The research aims to improve the recognition accuracy of three and four emotions, which has been a challenge for existing approaches. The proposed model consists of N adaptively neuro-fuzzy inference system (ANFIS) classifiers designed in parallel, in which N is the number of emotion classes. The selected features with the most appropriate distribution for classification are given as input vectors to the ANFIS structures, and the system is trained. The outputs of these trained ANFIS models are combined to create a feature vector, which provides the inputs for adaptive networks, and the system is trained to acquire the emotional recognition output. The performance of the proposed model has been evaluated for classification on well-known emotion benchmark datasets, including DEAP and Feeling Emotions. The study results indicate that the model achieves an accuracy rate of 73.49% on the DEAP datasets and 95.97% on the Feeling Emotions datasets. These results demonstrate that the proposed model efficiently recognizes emotions and exhibits a promising classification performance.},
  archive      = {J_NCA},
  author       = {Bardak, F. Kebire and Seyman, M. Nuri and Temurtaş, Feyzullah},
  doi          = {10.1007/s00521-024-09573-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9189-9202},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive neuro-fuzzy based hybrid classification model for emotion recognition from EEG signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated retinal disease classification using hybrid
transformer model (SViT) using optical coherence tomography images.
<em>NCA</em>, <em>36</em>(16), 9171–9188. (<a
href="https://doi.org/10.1007/s00521-024-09564-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical coherence tomography (OCT) is a widely used imaging technique in ophthalmology for diagnosis and treatment. Recent advances in deep neural networks (DNNs) and vision transformers (ViTs) have paved the way for automated eye/retinal disease classifications and segmentations using OCT or spectral domain OCT (SD-OCT) images. Diabetic macular edema (DME), choroidal neovascularization (CNV), and Drusen are particularly challenging to accurately classify using OCT images because of their subtle differences and intricate features. Currently, the algorithms reported in the literature using DNNs or ViTs are computationally complex, consider fewer diseases, and are less accurate. This study proposes a hybrid SqueezeNet-vision transformer (SViT) model that combines the strengths of SqueezeNet and vision transformer (ViT), capturing local and global features of OCT images to achieve more accurate classification with less computational complexity. The proposed model uses the OCT2017 dataset for training, testing, and validation, and it performs both binary classification (normal vs disorders) as well as multiclass classification (DME, CNV, Drusen, and normal). As compared to state-of-the-art CNN-based and standalone Transformer models, the proposed SViT model achieves an overall classification accuracy of 99.90% for multiclass classification (CNV: 100%, DME: 99.9%, Drusen: 100%, and normal: 100%). With a good generalization ability, the model can be used to improve patient care and clinical decision-making across a broader range of applications.},
  archive      = {J_NCA},
  author       = {Hemalakshmi, G. R. and Murugappan, M. and Sikkandar, Mohamed Yacin and Begum, S. Sabarunisha and Prakash, N. B.},
  doi          = {10.1007/s00521-024-09564-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9171-9188},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated retinal disease classification using hybrid transformer model (SViT) using optical coherence tomography images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-varying neural networks for multi-input multi-output
systems: A reactive batch distillation modeling case study.
<em>NCA</em>, <em>36</em>(16), 9157–9170. (<a
href="https://doi.org/10.1007/s00521-024-09556-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel time-varying neural network (TVNN) architecture incorporating time dependency explicitly, proposed recently, for modeling nonlinear non-stationary dynamic systems is further developed in the present study to extend it to multi-input multi-output (MIMO) systems, and two configurations are proposed to represent dynamics of multivariable batch chemical processes. The first model (TVNN-multi-input single-output (MISO) model) consists of an input layer with M inputs representing the past samples of process inputs and outputs, a hidden layer with polynomial activation function, and a second hidden layer of L neurons acted upon by an explicitly time-dependent modulation function, which are combined to result in the output layer with a single output. This model is developed for each output in the MIMO system. In the second model (TVNN-MIMO model), multiple outputs are incorporated in the output layer. Back-propagation learning algorithm is formulated for the proposed neural network structures to determine the weights for each network configuration. The modeling capability of these networks is evaluated by employing it to represent the dynamics of a reactive batch distillation column for an esterification reaction. The results show that both the proposed neural networks configurations represent each composition of the reactive batch distillation dynamics accurately. Further, both the TVNNs exhibited better performance than time-independent networks trained using the same configuration. Both the TVNN configurations resulted in comparable performance, while the TVNN-MIMO model is more compact and requires less number of parameters. The present study illustrates that the proposed approach can be applied to represent dynamics of any batch/semi-batch process.},
  archive      = {J_NCA},
  author       = {Kumar, P. Naveen and Ganesh, B. and Teja, M. Vamsi and Rani, K. Yamuna},
  doi          = {10.1007/s00521-024-09556-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9157-9170},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time-varying neural networks for multi-input multi-output systems: A reactive batch distillation modeling case study},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mutual information-based neighbor selection method for
causal effect estimation. <em>NCA</em>, <em>36</em>(16), 9141–9155. (<a
href="https://doi.org/10.1007/s00521-024-09555-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of causal effects from observational data has been the main objective in several high-impact scientific domains, while the golden standard for calculating the true causal effect is through the conduction of randomized controlled trials. The abundance of this type of data, which are continuously produced and collected, makes them potentially valuable for estimating causal effects. However, observational data may lead to erroneous treatment effect estimation, since they often suffer from various forms of bias. A recent work has shown that causal effect estimation provided by neural network-based model can be improved by leveraging information from the outcome of neighboring instances in the covariate space. In this work, we propose an information-theoretic methodology for selecting the neighbors to be considered in the estimation of the treatment effect for each sample. The proposed methodology, named Mutual Information-based Neighbor selection for Treatment effect estimation (MINT), selects the optimal number of neighbors as well as the type of distance metric with respect to pre-defined criteria. Then, the average outcome of the neighbors in the treatment and control groups is used as an informative input to the estimator, in addition to the covariates. The presented numerical experiments demonstrate that the adoption of the proposed MINT methodology with the state-of-the-art Dragonnet model is able to develop a reliable and accurate model for treatment effect estimation.},
  archive      = {J_NCA},
  author       = {Kiriakidou, Niki and Livieris, Ioannis E. and Pintelas, Panagiotis},
  doi          = {10.1007/s00521-024-09555-8},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9141-9155},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mutual information-based neighbor selection method for causal effect estimation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-fault diagnosis and fault degree identification in
hydraulic systems based on fully convolutional networks and deep feature
fusion. <em>NCA</em>, <em>36</em>(16), 9125–9140. (<a
href="https://doi.org/10.1007/s00521-024-09548-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normal and stable operations of hydraulic systems are of great importance to the safety and efficiency of industrial production processes. Accurate and prompt diagnosis of fault types and degrees can ensure hydraulic systems return to normal in the early stage of faults and thus can prevent serious accidents. However, the structure of hydraulic systems is complex, and some faults may occur simultaneously. In addition, many hydraulic systems have multi-rate data collected from different sensors. Such problems cause great challenges to fault diagnosis in hydraulic systems. Motivated by the above issues, this paper proposes a deep learning method to diagnose faults and identify fault degrees in hydraulic systems using fully convolutional networks (FCNs) and deep feature fusion. The main contributions are twofold: (1) A new fault diagnosis framework is designed to identify both the fault types and degrees in the presence of multiple faults; and (2) deep feature extractors composed of multiple superimposed convolutional blocks are designed to extract deep features from multi-rate time series, and such features are then fused via flattening and concatenating and fed into the fault diagnosis model. Case studies based on a hydraulic system test bed are provided to demonstrate the effectiveness and superiority of the proposed fault diagnosis method.},
  archive      = {J_NCA},
  author       = {Zhang, Peng and Hu, Wenkai and Cao, Weihua and Chen, Luefeng and Wu, Min},
  doi          = {10.1007/s00521-024-09548-7},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9125-9140},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-fault diagnosis and fault degree identification in hydraulic systems based on fully convolutional networks and deep feature fusion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving speed control characteristics of PMDC motor drives
using nonlinear PI control. <em>NCA</em>, <em>36</em>(16), 9113–9124.
(<a href="https://doi.org/10.1007/s00521-024-09568-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a nonlinear PI controller for improved speed regulation in permanent magnet direct current (PMDC) motor drive systems. The nonlinearity comes from the exponential (Exp) block placed in front of the classical PI controller, which uses a tunable exponential function to map the speed error nonlinearly. Such a configuration has not been studied till now, thus meriting further investigation. We consider an exponential PI (EXP-PI) controller and to attain the best performance from this controller, its parameters are optimized offline using salp swarm algorithm (SSA), which borrows its inspiration from the way of forage and navigation of salps living in deep oceans. To indicate the credibility of SSA tuned EXP-PI controller convincingly, numerous experiments on speed regulation in PMDC motor have been implemented using DSP of TMS320F28335. The results obtained are also compared to similar results in the literature. It is shown that the proposed approach performs well in practice by ensuring tight tracking of the speed reference and superb torque disturbance rejection for the closed loop control. Furthermore, superior performance is achieved by the proposed nonlinear PI controller with respect to a fixed-gain PI controller.},
  archive      = {J_NCA},
  author       = {Çelik, Emre and Bal, Güngör and Öztürk, Nihat and Bekiroglu, Erdal and Houssein, Essam H. and Ocak, Cemil and Sharma, Gulshan},
  doi          = {10.1007/s00521-024-09568-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9113-9124},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving speed control characteristics of PMDC motor drives using nonlinear PI control},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid deep learning models for time series forecasting of
solar power. <em>NCA</em>, <em>36</em>(16), 9095–9112. (<a
href="https://doi.org/10.1007/s00521-024-09558-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting solar power production accurately is critical for effectively planning and managing renewable energy systems. This paper introduces and investigates novel hybrid deep learning models for solar power forecasting using time series data. The research analyzes the efficacy of various models for capturing the complex patterns present in solar power data. In this study, all of the possible combinations of convolutional neural network (CNN), long short-term memory (LSTM), and transformer (TF) models are experimented. These hybrid models also compared with the single CNN, LSTM and TF models with respect to different kinds of optimizers. Three different evaluation metrics are also employed for performance analysis. Results show that the CNN–LSTM–TF hybrid model outperforms the other models, with a mean absolute error (MAE) of 0.551% when using the Nadam optimizer. However, the TF–LSTM model has relatively low performance, with an MAE of 16.17%, highlighting the difficulties in making reliable predictions of solar power. This result provides valuable insights for optimizing and planning renewable energy systems, highlighting the significance of selecting appropriate models and optimizers for accurate solar power forecasting. This is the first time such a comprehensive work presented that also involves transformer networks in hybrid models for solar power forecasting.},
  archive      = {J_NCA},
  author       = {Salman, Diaa and Direkoglu, Cem and Kusaf, Mehmet and Fahrioglu, Murat},
  doi          = {10.1007/s00521-024-09558-5},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9095-9112},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid deep learning models for time series forecasting of solar power},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-learning methodology based on meta-unsupervised
algorithm for meta-model selection to solve few-shot base-tasks.
<em>NCA</em>, <em>36</em>(16), 9073–9094. (<a
href="https://doi.org/10.1007/s00521-024-09549-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans can solve image classification tasks by learning from a few images and reusing prior-knowledge. In Artificial Intelligence, deep-learning models have been implemented to simulate human learning and face problems with little data available, few-shot learning. Nevertheless, one crucial problem of deep-learning is the selection of architectures and initial parameters that accomplish the requirements for a specific task. Therefore, we propose a novel methodology based on the meta-learning paradigm, which reuses prior- and meta-knowledge to select the best architecture and its initial parameters to solve different few-shot image classification tasks, as humans do. Our methodology was designed to understand the knowledge flow of the meta-learning paradigm by dividing the learning into prior-models, meta-models, meta-unsupervised algorithm, and base-models. We considered 9 architectures of deep convolutional neural networks as prior-models. Also, we propose a meta-unsupervised algorithm inspired by the human-cognitive problem-solving process, which acquires knowledge by solving tasks to recommend initial parameters to solve other new tasks. Furthermore, we propose a New Task Distribution Scheme to better evaluate few-shot learning models and analyze the difficulty of the new tasks. We evaluated our meta-learning methodology by applying the NTDS to the Mini-ImageNet and Caltech-UCSD-Birds-200-2011 (CUB) datasets. The achieved Adjusted Mutual Information average scores are 0.955 (zero-shot) and 0.957 (five-shot) for Mini-ImageNet, and 0.822 (zero-shot) and 0.848 (five-shot) for CUB. Moreover, we demonstrated the applicability of our meta-learning methodology in a real-world scenario using a new copro-parasite dataset. The performances of our meta-learning methodology are competitive regarding the state-of-the-art unsupervised few-shot learning models.},
  archive      = {J_NCA},
  author       = {Rivas-Posada, Eduardo and Chacon-Murguia, Mario I.},
  doi          = {10.1007/s00521-024-09549-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9073-9094},
  shortjournal = {Neural Comput. Appl.},
  title        = {Meta-learning methodology based on meta-unsupervised algorithm for meta-model selection to solve few-shot base-tasks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG signal-based classification of mental tasks using a
one-dimensional ConvResT model. <em>NCA</em>, <em>36</em>(16),
9053–9072. (<a
href="https://doi.org/10.1007/s00521-024-09550-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of mental or cognitive tasks in real time using single- or multi-channel EEG signals is an important field of research for neurofeedback and portable brain–computer interface systems. Exploring aspects of the electroencephalogram (EEG) data is an important research project because it sheds insight into the brain activity related to cognitive intents. CNNs have become a popular deep network design among the many others used for EEG data feature extraction, and this exploration offers considerable promise for this application. Due to many learnable parameters and a small number of EEG trials, most CNN-based techniques currently in use experience overfitting. This work presents the creation of a deep network model for classifying two distinct tasks from EEG data that is expressive, lightweight and efficient. It is based on the ResNet theory. In this work, we present a ConvResT architecture for two tasks classification, through the utilization of the conventional convolutional classification technique, which is enhanced by fusing a different residual connection and transformer mechanism, where the layers before the transformer are repeated once and twice. The Res block uses three different residual connections like normal, pre-activation and identity skip connection. Each Res connection leads to one model, which explored to three ConvResT models. The proposed models are evaluated on a real-world public dataset. Evaluation metrics like mean ROC and mean accuracy for loops 1 and 2 recalculated for individual subject. The highest subject independent classification of 96%, 97% and 98% obtained in loop 1 and 96%, 93% and 97% in loop 2 of mean ROC, and 91%, 92% and 93% in loops 1 and 2 of mean accuracy. In all the three ConvResT models, when compared with the other two models Res with identity skip connection achieved good results by an average mean ROC of 85.83% and 79.38% in loops 1 and 2 and an average mean accuracy of 78.22% and 78.19% in loops 1 and 2.},
  archive      = {J_NCA},
  author       = {Manasa, Gunda and Nirde, Krashana D. and Gajre, Suhas S. and Manthalkar, Ramachandra R.},
  doi          = {10.1007/s00521-024-09550-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9053-9072},
  shortjournal = {Neural Comput. Appl.},
  title        = {EEG signal-based classification of mental tasks using a one-dimensional ConvResT model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing coffee bean classification: A comparative analysis
of pre-trained deep learning models. <em>NCA</em>, <em>36</em>(16),
9023–9052. (<a
href="https://doi.org/10.1007/s00521-024-09623-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coffee bean production can encounter challenges due to fluctuations in global coffee prices, impacting the economic stability of some countries that heavily depend on coffee production. The primary objective is to evaluate how effectively various pre-trained models can predict coffee types using advanced deep learning techniques. The selection of an optimal pre-trained model is crucial, given the growing popularity of specialty coffee and the necessity for precise classification. We conducted a comprehensive comparison of several pre-trained models, including AlexNet, LeNet, HRNet, Google Net, Mobile V2 Net, ResNet (50), VGG, Efficient, Darknet, and DenseNet, utilizing a coffee-type dataset. By leveraging transfer learning and fine-tuning, we assess the generalization capabilities of the models for the coffee classification task. Our findings emphasize the substantial impact of the pre-trained model choice on the model&#39;s performance, with certain models demonstrating higher accuracy and faster convergence than conventional alternatives. This study offers a thorough evaluation of pre-trained architectural models regarding their effectiveness in coffee classification. Through the evaluation of result metrics, including sensitivity (1.0000), specificity (0.9917), precision (0.9924), negative predictive value (1.0000), accuracy (1.0000), and F1 score (0.9962), our analysis provides nuanced insights into the intricate landscape of pre-trained models.},
  archive      = {J_NCA},
  author       = {Hassan, Esraa},
  doi          = {10.1007/s00521-024-09623-z},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {9023-9052},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing coffee bean classification: A comparative analysis of pre-trained deep learning models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for named entity recognition: A survey.
<em>NCA</em>, <em>36</em>(16), 8995–9022. (<a
href="https://doi.org/10.1007/s00521-024-09646-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) aims to identify the required entities and their types from unstructured text, which can be utilized for the construction of knowledge graphs. Traditional methods heavily rely on manual feature engineering and face challenges in adapting to large datasets within complex linguistic contexts. In recent years, with the development of deep learning, a plethora of NER methods based on deep learning have emerged. This paper begins by providing a succinct introduction to the definition of the problem and the limitations of traditional methods. It enumerates commonly used NER datasets suitable for deep learning methods and categorizes them into three classes based on the complexity of named entities. Then, some typical deep learning-based NER methods are summarized in detail according to the development history of deep learning models. Subsequently, an in-depth analysis and comparison of methods achieving outstanding performance on representative and widely used datasets is conducted. Furthermore, the paper reproduces and analyzes the recognition results of some typical models on three different types of typical datasets. Finally, the paper concludes by offering insights into the future trends of NER development.},
  archive      = {J_NCA},
  author       = {Hu, Zhentao and Hou, Wei and Liu, Xianxing},
  doi          = {10.1007/s00521-024-09646-6},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {8995-9022},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning for named entity recognition: A survey},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying the most accurate machine learning
classification technique to detect network threats. <em>NCA</em>,
<em>36</em>(16), 8977–8994. (<a
href="https://doi.org/10.1007/s00521-024-09562-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insider threats have recently become one of the most urgent cybersecurity challenges facing numerous businesses, such as public infrastructure companies, major federal agencies, and state and local governments. Our purpose is to find the most accurate machine learning (ML) model to detect insider attacks. In the realm of machine learning, the most convenient classifier is usually selected after further evaluation trials of candidate models which can cause unseen data (test data set) to leak into models and create bias. Accordingly, overfitting occurs because of frequent training of models and tuning hyperparameters; the models perform well on the training set while failing to generalize effectively to unseen data. The validation data set and hyperparameter tuning are utilized in this study to prevent the issues mentioned above and to choose the best model from our candidate models. Furthermore, our approach guarantees that the selected model does not memorize data of the threats occurring in the local area network (LAN) through the usage of the NSL-KDD data set. The following results are gathered and analyzed: support vector machine (SVM), decision tree (DT), logistic regression (LR), adaptive boost (AdaBoost), gradient boosting (GB), random forests (RFs), and extremely randomized trees (ERTs). After analyzing the findings, we conclude that the AdaBoost model is the most accurate, with a DoS of 99%, a probe of 99%, access of 96%, and privilege of 97%, as well as an AUC of 0.992 for DoS, 0.986 for probe, 0.952 for access, and 0.954 for privilege.},
  archive      = {J_NCA},
  author       = {Farouk, Mohamed and Sakr, Rasha Hassan and Hikal, Noha},
  doi          = {10.1007/s00521-024-09562-9},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {8977-8994},
  shortjournal = {Neural Comput. Appl.},
  title        = {Identifying the most accurate machine learning classification technique to detect network threats},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic literature review of soft set theory.
<em>NCA</em>, <em>36</em>(16), 8951–8975. (<a
href="https://doi.org/10.1007/s00521-024-09552-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft set theory, initially introduced through the seminal article “Soft set theory—First results” in 1999, has gained considerable attention in the field of mathematical modeling and decision-making. Despite its growing prominence, a comprehensive survey of soft set theory, encompassing its foundational concepts, developments, and applications, is notably absent in the existing literature. We aim to bridge this gap. This survey delves into the basic elements of the theory, including the notion of a soft set, the operations on soft sets, and their semantic interpretations. It describes various generalizations and modifications of soft set theory, such as N-soft sets, fuzzy soft sets, and bipolar soft sets, highlighting their specific characteristics. Furthermore, this work outlines the fundamentals of various extensions of mathematical structures from the perspective of soft set theory. Particularly, we present basic results of soft topology and other algebraic structures such as soft algebras and $$\sigma$$ -algebras. This article examines a selection of notable applications of soft set theory in different fields, including medicine and economics, underscoring its versatile nature. The survey concludes with a discussion on the challenges and future directions in soft set theory, emphasizing the need for further research to enhance its theoretical foundations and broaden its practical applications. Overall, this survey of soft set theory serves as a valuable resource for practitioners, researchers, and students interested in understanding and utilizing this flexible mathematical framework for tackling uncertainty in decision-making processes.},
  archive      = {J_NCA},
  author       = {Alcantud, José Carlos R. and Khameneh, Azadeh Zahedi and Santos-García, Gustavo and Akram, Muhammad},
  doi          = {10.1007/s00521-024-09552-x},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {8951-8975},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic literature review of soft set theory},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Machine learning for human emotion recognition:
A comprehensive review. <em>NCA</em>, <em>36</em>(16), 8949. (<a
href="https://doi.org/10.1007/s00521-024-09649-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Younis, Eman M. G. and Mohsen, Someya and Houssein, Essam H. and Ibrahim, Osman Ali Sadek},
  doi          = {10.1007/s00521-024-09649-3},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {8949},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: machine learning for human emotion recognition: a comprehensive review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Machine learning for human emotion recognition: A
comprehensive review. <em>NCA</em>, <em>36</em>(16), 8901–8947. (<a
href="https://doi.org/10.1007/s00521-024-09426-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion is an interdisciplinary research field investigated by many research areas such as psychology, philosophy, computing, and others. Emotions influence how we make decisions, plan, reason, and deal with various aspects. Automated human emotion recognition (AHER) is a critical research topic in Computer Science. It can be applied in many applications such as marketing, human–robot interaction, electronic games, E-learning, and many more. It is essential for any application requiring to know the emotional state of the person and act accordingly. The automated methods for recognizing emotions use many modalities such as facial expressions, written text, speech, and various biosignals such as the electroencephalograph, blood volume pulse, electrocardiogram, and others to recognize emotions. The signals can be used individually(uni-modal) or as a combination of more than one modality (multi-modal). Most of the work presented is in laboratory experiments and personalized models. Recent research is concerned about in the wild experiments and creating generic models. This study presents a comprehensive review and an evaluation of the state-of-the-art methods for AHER employing machine learning from a computer science perspective and directions for future research work.},
  archive      = {J_NCA},
  author       = {Younis, Eman M. G. and Mohsen, Someya and Houssein, Essam H. and Ibrahim, Osman Ali Sadek},
  doi          = {10.1007/s00521-024-09426-2},
  journal      = {Neural Computing and Applications},
  month        = {6},
  number       = {16},
  pages        = {8901-8947},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning for human emotion recognition: A comprehensive review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new content-aware image resizing based on rényi entropy
and deep learning. <em>NCA</em>, <em>36</em>(15), 8885–8899. (<a
href="https://doi.org/10.1007/s00521-024-09517-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most popular techniques for changing the purpose of an image or resizing a digital image with content awareness is the seam-carving method. The performance of image resizing algorithms based on seam machining shows that these algorithms are highly dependent on the extraction of importance map techniques and the detection of salient objects. So far, various algorithms have been proposed to extract the importance map. In this paper, a new method based on Rényi entropy is proposed to extract the importance map. Also, a deep learning network has been used to detect salient objects. The simulator results showed that combining Rényi’s importance map with a deep network of salient object detection performed better than classical seam-carving and other extended seam-carving algorithms based on deep learning.},
  archive      = {J_NCA},
  author       = {Ayubi, Jila and Chehel Amirani, Mehdi and Valizadeh, Morteza},
  doi          = {10.1007/s00521-024-09517-0},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8885-8899},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new content-aware image resizing based on rényi entropy and deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stacked dynamic memory-coattention network for answering
why-questions in arabic. <em>NCA</em>, <em>36</em>(15), 8867–8883. (<a
href="https://doi.org/10.1007/s00521-024-09525-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answering non-factoid questions, especially why-questions, poses a challenge for traditional question answering systems (QASs) that are predominantly designed for fact-based queries. Recent advancements in QASs have incorporated attention and memory mechanisms to better capture the intricate relationship between context and query, resulting in more precise answers. Two prominent mechanisms in this domain are the dynamic memory network (DMN) and the dynamic coattention network (DCN). In this study, we propose a novel model named stacked dynamic memory-coattention network (SDMCN) that combines the memory mechanism of DMN with the coattention mechanism of DCN to extract answers for why-questions in Arabic. Our model was evaluated across three distinct Arabic why-question datasets: DAWQAS, LEMAZA, and WA. It achieved accuracies of 81.85%, 83.6%, and 89%, and $$F$$ -scores of 80.55%, 82.42%, and 87.52% in the DAWQAS, LEMAZA, and WA datasets, respectively. These results not only underscore the SDMCN’s effectiveness but also highlight its superiority over the individual baseline models of DMN and DCN, with the SDMCN achieving a mean $$F$$ -score of 83.50% and a weighted $$F$$ -score of 82.36%. These results demonstrate the effectiveness of our model for answering why-questions in Arabic.},
  archive      = {J_NCA},
  author       = {Alwaneen, Tahani H. and Azmi, Aqil M.},
  doi          = {10.1007/s00521-024-09525-0},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8867-8883},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stacked dynamic memory-coattention network for answering why-questions in arabic},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel strong supervised learning infusing expertisements:
Focused on warship classification model. <em>NCA</em>, <em>36</em>(15),
8855–8866. (<a
href="https://doi.org/10.1007/s00521-024-09510-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image detection deep learning models are being used in various fields such as autonomous vehicles, medical, and agriculture. In the defense field, various efforts are being made to apply deep learning models to surveillance systems. Since the defense field deals with important issues such as combat, the reliability of the model is important. Therefore, this study intends to propose a new “strong supervised learning method” to ensure explainability of the defense image classification model. The proposed method is using the knowledge of military experts and the HITL (Human In The Loop) method in which humans and AI interact. This is the learning that provides the data of important parts of objects in addition to the general supervised learning which provides input data and labeling data. The learning process for the additionally provided data is carried out through a loss function of SSIM (Structural Similarity Index Map), which measures the similarity between data of important parts and a feature map of a convolutional neural network. In order to evaluate the proposed methodology, the model learned by general supervised learning and the model learned by the proposed method were compared. The comparison criteria were as follows: first, evaluation of similarity between the results of Grad CAM, a Visual Explain method, along with the data the important parts designated by experts; and second, the classification accuracy of objects. As a result of the experiment using the VGG16, ResNet50, InceptionV3, and Xception models, the similarity between the data of the Grad CAM and the region of interest was improved by an average of 15.52% based on the entire image area. In addition, the classification accuracy showed an average improvement of 4.72% based on Test Set.},
  archive      = {J_NCA},
  author       = {Park, Jinyoung and Moon, Hoseok},
  doi          = {10.1007/s00521-024-09510-7},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8855-8866},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel strong supervised learning infusing expertisements: Focused on warship classification model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel k-step fault estimation and fault-tolerant control
scheme in wireless power transfer systems. <em>NCA</em>,
<em>36</em>(15), 8843–8853. (<a
href="https://doi.org/10.1007/s00521-024-09515-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel incipient fault estimation and fault-tolerant control approach for wireless power transfer (WPT) systems with disturbances and incipient sensor faults. Firstly, the dynamic models of the WPT system and incipient faults are established. Then, a k-step incipient fault estimation observer method is analyzed for estimating the states and incipient faults of the system. Based on it, a nonlinear dynamic output feedback fault-tolerant controller is devised to ensure the stability of the WPT system when considering incipient faults and disturbances. Further, the designed controller can monitor the system in real time without the knowledge of the system states. Besides, the stability analysis approach is rigorous, and the proof method can also apply to other similar systems. At last, the simulation example shows that the proposed fault diagnosis method is correct and effective.},
  archive      = {J_NCA},
  author       = {Hua, Xingxing and Dai, Xin and Sun, Shaoxin and Sun, Yue},
  doi          = {10.1007/s00521-024-09515-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8843-8853},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel k-step fault estimation and fault-tolerant control scheme in wireless power transfer systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HILP: Hardware-in-loop pruning of convolutional neural
networks towards inference acceleration. <em>NCA</em>, <em>36</em>(15),
8825–8842. (<a
href="https://doi.org/10.1007/s00521-024-09539-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful deployment of convolutional neural networks on resource-constrained hardware platforms is challenging for ubiquitous AI applications. For latency-sensitive scenarios, real-time inference requires model compression techniques such as network pruning to achieve the purpose of inference acceleration. However, many researches focus on hardware-independent filter pruning methods, which cannot balance the contribution of pruned structure to latency and the accuracy drop. Although some pruning methods have introduced latency constraints into the pruning process, most of them are based on look-up tables, which omits the key step of hardware optimization, resulting in significant deviation in latency estimation. In this paper, we propose a novel latency-constrained pruning method, named hardware-in-loop pruning (HILP). It is based on the fast optimal pruning rate search within the layer and layer-wise hybrid pruning, which can prioritize removing the less important layers with considerable latency contributions. The proposed hardware-in-loop pipeline enables the hardware optimization module to be integrated into the entire framework. During pruning, an intermediate network architecture is automatically transformed to a deployable model for accurate latency measurement. The latency-optimized intermediate architecture is then selected by traversing all layers for next progressive step. HILP is generally applicable to any platform that provides a hardware optimization toolchain, such as NVIDIA GPU and Cambricon NPU. We evaluate HILP on both image classification task using ResNet50 with ImageNet and object detection task using YOLOv3 with COCO, HILP can reduce the inference latency of these two networks to 60% and 75%, respectively, within the range of accuracy variation not exceeding 0.6%. Extensive experiment results have proven that HILP is able to achieve a significant advantage in latency-accuracy performance compared to state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Li, Dong and Ye, Qianqian and Guo, Xiaoyue and Sun, Yunda and Zhang, Li},
  doi          = {10.1007/s00521-024-09539-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8825-8842},
  shortjournal = {Neural Comput. Appl.},
  title        = {HILP: Hardware-in-loop pruning of convolutional neural networks towards inference acceleration},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced chameleon swarm algorithm for global
optimization and multi-level thresholding medical image segmentation.
<em>NCA</em>, <em>36</em>(15), 8775–8823. (<a
href="https://doi.org/10.1007/s00521-024-09524-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is crucial in using digital images for disease diagnosis, particularly in post-processing tasks such as analysis and disease identification. Segmentation of magnetic resonance imaging (MRI) and computed tomography images pose distinctive challenges attributed to factors such as inadequate illumination during the image acquisition process. Multilevel thresholding is a widely adopted method for image segmentation due to its effectiveness and ease of implementation. However, the primary challenge lies in selecting the optimal set of thresholds to achieve accurate segmentation. While Otsu’s between-class variance and Kapur’s entropy assist in identifying optimal thresholds, their application to cases requiring more than two thresholds can be computationally intensive. Meta-heuristic algorithms are commonly employed in literature to calculate the threshold values; however, they have limitations such as a lack of precise convergence and a tendency to become stuck in local optimum solutions. In this paper, we introduce an improved chameleon swarm algorithm (ICSA) to address these limitations. ICSA is designed for image segmentation and global optimization tasks, aiming to improve the precision and efficiency of threshold selection in medical image segmentation. ICSA introduces the concept of the “best random mutation strategy” to enhance the search capabilities of the standard chameleon swarm algorithm (CSA). This strategy leverages three distribution functions—Levy, Gaussian, and Cauchy—for mutating search individuals. These diverse distributions contribute to improved solution quality and help prevent premature convergence. We conduct comprehensive experiments using the IEEE CEC’20 complex optimization benchmark test suite to evaluate ICSA’s performance. Additionally, we employ ICSA in image segmentation, utilizing Otsu’s approach and Kapur’s entropy as fitness functions to determine optimal threshold values for a set of MRI images. Comparative analysis reveals that ICSA outperforms well-known metaheuristic algorithms when applied to the CEC’20 test suite and significantly improves image segmentation performance, proving its ability to avoid local optima and overcome the original algorithm’s drawbacks. Medical image segmentation is essential for employing digital images for disease diagnosis, particularly for post-processing activities such as analysis and disease identification. Due to poor illumination and other acquisition-related difficulties, radiologists are especially concerned about the optimal segmentation of brain magnetic resonance imaging (MRI). Multilevel thresholding is the most widely used image segmentation method due to its efficacy and simplicity of implementation. The issue, however, is selecting the optimum set of criteria to effectively segment each image. Although methods like Otsu’s between-class variance and Kapur’s entropy help locate the optimal thresholds, using them for more than two thresholds requires a significant amount of processing resources. Meta-heuristic algorithms are commonly employed in literature to calculate the threshold values; however, they have limitations such as a lack of precise convergence and a tendency to become stuck in local optimum solutions. Due to the aforementioned, we present an improved chameleon swarm algorithm (ICSA) in this paper for image segmentation and global optimization tasks to be able to address these weaknesses. In the ICSA method, the best random mutation strategy has been introduced to improve the searchability of the standard CSA. The best random strategy utilizes three different types of distribution: Levy, Gaussian, and Cauchy to mutate the search individuals. These distributions have different functions, which help enhance the quality of the solutions and avoid premature convergence. Using the IEEE CEC’20 test suite as a recent complex optimization benchmark, a comprehensive set of experiments is carried out in order to evaluate the ICSA method and demonstrate the impact of combining the best random mutation strategy with the original CSA in improving both the performance of the solutions and the rate at which they converge. Furthermore, utilizing the Otsu approach and Kapur’s entropy as a fitness function, ICSA is used as an image segmentation method to select the ideal threshold values for segmenting a set of MRI images. Within the experiments, the ICSA findings are compared with well-known metaheuristic algorithms. The comparative findings showed that ICSA performs better than other competitors in solving the CEC’20 test suite and has a significant performance boost in image segmentation.},
  archive      = {J_NCA},
  author       = {Mostafa, Reham R. and Houssein, Essam H. and Hussien, Abdelazim G. and Singh, Birmohan and Emam, Marwa M.},
  doi          = {10.1007/s00521-024-09524-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8775-8823},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced chameleon swarm algorithm for global optimization and multi-level thresholding medical image segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimation of solar cell parameters through utilization of
adaptive sine–cosine particle swarm optimization algorithm.
<em>NCA</em>, <em>36</em>(15), 8757–8773. (<a
href="https://doi.org/10.1007/s00521-024-09534-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the growing demand for clean and sustainable energy sources, there has been an increasing interest in solar cells and photovoltaic panels. Nevertheless, determining the right design parameters to achieve the most efficient energy output that aligns with the energy system&#39;s needs can be quite challenging. This complexity arises from the intricate models and the inherent inaccuracies in the available information. To tackle this challenge, this paper introduces the adaptive sine–cosine particle swarm optimization algorithm (ASCA-PSO) as a method for estimating the parameters of solar cells and photovoltaic modules. The ASCA-PSO approach combines the strengths of the SCA and PSO algorithms in a two-tier process. In this process, SCA search agents explore the search space, while the PSO search agents leverage the outcomes derived from SCA exploration. This study evaluates the effectiveness of ASCA-PSO in accurately estimating the parameters of single- and double-diode models using data from two commercial solar cells. The findings are compared with those of cutting-edge methods. It is demonstrated that ASCA-PSO can identify global solutions for multifaceted and intricate objective functions. Furthermore, it proves to be a viable option for designing solar cells even in the presence of noise.},
  archive      = {J_NCA},
  author       = {Issa, Mohamed and Helmi, Ahmed M. and Ghetas, Mohamed},
  doi          = {10.1007/s00521-024-09534-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8757-8773},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimation of solar cell parameters through utilization of adaptive sine–cosine particle swarm optimization algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel formulation for predicting the shear strength of RC
walls using meta-heuristic algorithms. <em>NCA</em>, <em>36</em>(15),
8727–8756. (<a
href="https://doi.org/10.1007/s00521-024-09514-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforced concrete (RC) shear walls play a pivotal role in resisting seismic and lateral loads within structural frameworks. A thorough examination of the existing literature was undertaken, covering a range of experimental and theoretical studies related to the design of RC shear walls. It was emphasized that comprehending shear failure behavior and precisely predicting the shear strength of RC walls holds considerable significance. To address this, the study proposes two models that integrate the support vector regression method with meta-heuristic optimization algorithms (Bat and GOA), utilizing 228 sets of experimental data. In identifying the parameters influencing the shear strength of RC shear walls, the study focused on eight influential factors. The comparison of the two proposed models in the current research with existing models and experimental data demonstrated their commendable accuracy, surpassing the performance of suggested empirical formulations. The prediction errors associated with the proposed models, when compared to experimental data, were notably low. An innovative approach was introduced in the research, presenting a novel method for predicting shear strength using the support vector regression method and the Bat optimization algorithm. A notable advantage of this formulation lies in its capacity to predict the shear strength across various configurations, including squat, cylindrical, and thin RC shear walls. Unlike some existing equations for predicting shear strength, this formulation exhibits no limitations. Through a comparative analysis with established equations, the computational framework’s results suggest its successful applicability in building codes and construction practices. The proposed method contributes to the accurate prediction of shear strength in diverse RC shear wall configurations, offering a valuable tool for structural engineering applications.},
  archive      = {J_NCA},
  author       = {Parsa, Payam and Naderpour, Hosein and Ezami, Nima},
  doi          = {10.1007/s00521-024-09514-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8727-8756},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel formulation for predicting the shear strength of RC walls using meta-heuristic algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active phase recognition method of hydrogenation catalyst
based on multi-feature fusion mask CenterNet. <em>NCA</em>,
<em>36</em>(15), 8711–8725. (<a
href="https://doi.org/10.1007/s00521-024-09544-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to realize the intelligent recognition and statistics of hydrogenation catalyst image information, this paper presents a new method to judge the active phase by image recognition, which is different from traditional methods. Firstly, considering that hydrogenation catalyst image targets are small and easy to stack, the feature extraction network in the CenterNet model is optimized by adding the multi-feature fusion module to improve the accuracy of the network in edge positioning. Secondly, according to the linear shape of the hydrogenation catalyst, the mask branch is added to the CenterNet model to train the hydrogenation catalyst stripes with unclear target to reduce the leakage rate of the hydrogenation catalyst. The experimental results show that the detection accuracy of the improved CenterNet network is 91 $$\%$$ , 7 $$\%$$ higher than that of the original one, with a decline in detection rate by 12 $$\%$$ . The method proposed in this paper can accurately identify and segment the hydrogenation catalyst in the electron microscope image, which can provide technical support for the statistics and analysis of the hydrogenation catalyst image.},
  archive      = {J_NCA},
  author       = {Wang, Zhujun and Sun, Tianhe and Li, Haobin and Cui, Ailin and Bao, Song},
  doi          = {10.1007/s00521-024-09544-x},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8711-8725},
  shortjournal = {Neural Comput. Appl.},
  title        = {Active phase recognition method of hydrogenation catalyst based on multi-feature fusion mask CenterNet},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Forecasting wholesale prices of yellow corn through the
gaussian process regression. <em>NCA</em>, <em>36</em>(15), 8693–8710.
(<a href="https://doi.org/10.1007/s00521-024-09531-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For market players and policy officials, commodity price forecasts are crucial problems that are challenging to address due to the complexity of price time series. Given its strategic importance, corn crops are hardly an exception. The current paper evaluates the forecasting issue for China’s weekly wholesale price index for yellow corn from January 1, 2010 to January 10, 2020. We develop a Gaussian process regression model using cross validation and Bayesian optimizations over various kernels and basis functions that could effectively handle this sophisticated commodity price forecast problem. The model provides precise out-of-sample forecasts from January 4, 2019 to January 10, 2020, with a relative root mean square error, root mean square error, and mean absolute error of 1.245%, 1.605, and 0.936, respectively. The models developed here might be used by market players for market evaluations and decision-making as well as by policymakers for policy creation and execution.},
  archive      = {J_NCA},
  author       = {Jin, Bingzi and Xu, Xiaojie},
  doi          = {10.1007/s00521-024-09531-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8693-8710},
  shortjournal = {Neural Comput. Appl.},
  title        = {Forecasting wholesale prices of yellow corn through the gaussian process regression},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Predicting rumor veracity on social media with
cross-channel interaction of multi-task. <em>NCA</em>, <em>36</em>(15),
8681–8692. (<a
href="https://doi.org/10.1007/s00521-024-09519-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, malicious rumors on social media have caused increasingly negative impacts. Given the rapid dissemination nature of rumors, it is urgent to design automatic methods to detect the veracity of rumors. Previous studies have shown that the multi-task learning paradigm with the stance classification could facilitate the successful detection of rumors, but the shared layers in multi-task learning tend to yield a compromise between the general and the task-specific representation of structural information. To address this issue, we propose a novel Multi-Task Learning framework with Shared Multi-channel Interactions (MTL-SMI), which is composed of two shared channels and two task-specific graph channels. The shared channels extract task-invariant text features and structural features, and the task-specific graph channels, by interacting with the shared channels, extract the task-enhanced structural features. These channels are learned jointly to enhance the ability of representation learning. The experimental results on two real-world datasets demonstrate the superiority of MTL-SMI against strong baselines.},
  archive      = {J_NCA},
  author       = {Liu, Yudong and Yang, Xiaoyu and Zhang, Xi and Tang, Zhihao and Chen, Zongyi and Zheng, Liwen},
  doi          = {10.1007/s00521-024-09519-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8681-8692},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting rumor veracity on social media with cross-channel interaction of multi-task},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DFMA-ICH: A deformable mixed-attention model for
intracranial hemorrhage lesion segmentation based on deep supervision.
<em>NCA</em>, <em>36</em>(15), 8657–8679. (<a
href="https://doi.org/10.1007/s00521-024-09545-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intracranial hemorrhage (ICH) is a common and critical disease in clinical, with rapid progression, high disability, and mortality rates. Existing segmentation methods, such as U-Net and TransUNet, perform poorly for the problems in ICH segmentation such as small bleeding lesions, partial volume effects, and edge tissue adhesion with edema in ICH data. To solve these issues more efficiently, a deformable mixed-attention model based on deep supervision for ICH lesion segmentation (DFMA-ICH) is proposed in this study. DFMA-ICH consists of the short-term dense concatenate network (STDC) as the backbone with a mixed-attention method, an attention refining residual module (ARRM), and a mixed feature fusion module (MFFM). The mixed-attention method includes multi-scale spatial attention (MSP) and channel attention mechanism (SE) to extract rich lesion information. The double-pooling attention module (DPA) in ARRM is designed to correct features. In MFFM, different attention modules are constructed to reasonably combine low- and high-level features, and deformable convolution (DConv) is applied for boundary optimization. DFMA-ICH is trained by the deep supervision method to equalize the corresponding outputs at different stages. Overall, DFMA-ICH outperforms other advanced models on both spontaneous and traumatic ICH datasets by transfer learning with the Dice of 86.03, 80.98%, and HD of 12.35, 47.28 mm, respectively. Moreover, DFMA-ICH incurs the lowest time-space cost and exhibits the fastest inference speed. The study confirms that the proposed DFMA-ICH can provide an accurate and efficient method for ICH segmentation.},
  archive      = {J_NCA},
  author       = {Xiao, Hanguang and Shi, Xinyi and Xia, Qingling and Chen, Lihua and Chen, Diyou and Li, Yulin and Li, Li and Liu, Qiyuan and Zhao, Hui},
  doi          = {10.1007/s00521-024-09545-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8657-8679},
  shortjournal = {Neural Comput. Appl.},
  title        = {DFMA-ICH: A deformable mixed-attention model for intracranial hemorrhage lesion segmentation based on deep supervision},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multitask co-training framework for improving speech
translation by leveraging speech recognition and machine translation
tasks. <em>NCA</em>, <em>36</em>(15), 8641–8656. (<a
href="https://doi.org/10.1007/s00521-024-09547-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-to-end speech translation (ST) has attracted substantial attention due to its less error accumulation and lower latency. Based on triplet ST data $$\langle$$ speech-transcription-translation $$\rangle$$ , multitask learning (MTL) that utilizes machine translation $$\langle$$ transcription-translation $$\rangle$$ or automatic speech recognition $$\langle$$ speech-transcription $$\rangle$$ task to assist in training ST model is widely employed. However, current MTL methods often suffer from subnet role mismatch, semantic inconsistency, or usually focus only on transferring knowledge from automatic speech recognition (ASR) or machine translation (MT) task, leading to insufficient transferring of cross-task knowledge. To solve these problems, we propose the multitask co-training network (MCTN) to jointly model ST, MT, and ASR tasks. Specifically, the ASR task enables the acoustic encoder to better capture local information of speech frames, and the MT task enhances the translation capability of the model. MCTN benefits from three key aspects: a well-designed multitask framework to fully exploit the association between tasks, a model decoupling and parameter sharing method to maintain consistency in subnet roles, and a co-training strategy to utilize task information in triplet ST data. Our experiments show that MCTN achieves state-of-the-art results, when using only MuST-C dataset, and significantly outperforms strong end-to-end ST baselines and cascaded systems when external data are available.},
  archive      = {J_NCA},
  author       = {Zhou, Yue and Yuan, Yuxuan and Shi, Xiaodong},
  doi          = {10.1007/s00521-024-09547-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8641-8656},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multitask co-training framework for improving speech translation by leveraging speech recognition and machine translation tasks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IndianFoodNet: Effective indian multi-food identification
and recommendation for hypertensive patients using deep convolutional
neural network. <em>NCA</em>, <em>36</em>(15), 8625–8640. (<a
href="https://doi.org/10.1007/s00521-024-09537-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The food consumption has a direct effect on the health of an individual. Eating food without awareness of its ingredients may result in eating style-based diseases such as hypertension, diabetes, and several others. As per recent WHO survey, the number of persons with hypertension is very large in numbers. There is essentially a need of novel technique that can provide food recommendation to hypertensive persons, out of their multi-food items in their meals. In this research work, Indian multi-food items of the meal are recognized using fine-tuned deep convolutional neural network model. Further, in existing research works, only single food image is recognized, which is not relevant to real-life food consumption. In our proposed approach, contour-based image segmentation technique is used for multi-food meal. In existing research works, no dataset is available on Indian food items for hypertensive persons. The key contribution of this research work is the preparation of Indian food dataset of 30 classes for hypertensive patients. There are 15 Recommended food classes for the hypertensive person and 15 classes are not recommended foods to maintain the class balance (as calibrated through a professional dietitian) (Dr. Shuchi Upadhyay, Dietitian and Nutrition expert, UPES, Dehradun). The novel contribution is to present ‘IndianFood30’ dataset of hypertensive patients for research purposes. Further, a novel IndianFoodNet model is presented which is trained on these 30 Indian food classes. Several pre-trained models are available for research purposes, but there is no pre-trained model on Indian food for hypertensive persons. Food ingradients exhibit high intra-class variance, and these complex features are extracted using our proposed approach. The accuracy of the proposed approach is compared with state-of-the-art models such as VGGNet, Inception V3, GoogleNet, and ResNet. Our proposed approach is also compared with some recent techniques on some of the existing datasets such as UEC Food-100, UEC Food-256, and Food-101 datasets to show the performance and effectiveness of the proposed model. Experiment analysis validates that our proposed approach outperforms existing approaches significantly.},
  archive      = {J_NCA},
  author       = {Tiwari, Rajeev and Bathla, Gourav and Upadhyay, Shuchi},
  doi          = {10.1007/s00521-024-09537-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8625-8640},
  shortjournal = {Neural Comput. Appl.},
  title        = {IndianFoodNet: Effective indian multi-food identification and recommendation for hypertensive patients using deep convolutional neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CFTNet: A robust credit card fraud detection model enhanced
by counterfactual data augmentation. <em>NCA</em>, <em>36</em>(15),
8607–8623. (<a
href="https://doi.org/10.1007/s00521-024-09546-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Establishing a reliable credit card fraud detection model has become a primary focus for academia and the financial industry. The existing anti-fraud methods face challenges related to low recall rates, inaccurate results, and insufficient causal modeling ability. This paper proposes a credit card fraud detection model based on counterfactual data enhancement of the triplet network. Firstly, we convert the problem of generating optimal counterfactual explanations (CFs) into a policy optimization of agents in the discrete–continuous mixed action space, thereby ensuring the stable generation of optimal CFs. The triplet network then utilizes the feature similarity and label difference of positive example samples and CFs to enhance the learning of the causal relationship between features and labels. Experimental results demonstrate that the proposed method improves the accuracy and robustness of the credit card fraud detection model, outperforming existing methods. The research outcomes are of significant value for both credit card anti-fraud research and practice while providing a novel approach to causal modeling issues across other fields.},
  archive      = {J_NCA},
  author       = {Kong, Menglin and Li, Ruichen and Wang, Jia and Li, Xingquan and Jin, Shengzhong and Xie, Wanying and Hou, Muzhou and Cao, Cong},
  doi          = {10.1007/s00521-024-09546-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8607-8623},
  shortjournal = {Neural Comput. Appl.},
  title        = {CFTNet: A robust credit card fraud detection model enhanced by counterfactual data augmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximizing renewable energy integration with battery storage
in distribution systems using a modified bald eagle search optimization
algorithm. <em>NCA</em>, <em>36</em>(15), 8577–8605. (<a
href="https://doi.org/10.1007/s00521-024-09526-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to environmental concerns associated with conventional energy production, the use of renewable energy sources (RES) has rapidly increased in power systems worldwide, with photovoltaic (PV) and wind turbine (WT) technologies being the most frequently integrated. This study proposes a modified Bald Eagle Search Optimization Algorithm (LBES) to enhance the performance of the conventional BES optimizer and optimize the size and location of RES-based Distribution Generation (DG) and Battery Energy Storage Systems (BESS) in distribution systems (DS) to minimize power and energy losses. The modified BES algorithm enhances the exploration phase by utilizing both crossover and mutation techniques with the top three leaders. Moreover, a loss sensitivity factor (LSF) is applied to expedite the solution process by identifying appropriate candidate buses. The variability of solar irradiation and wind speed is modeled using Weibull and Beta probability distribution functions (PDF). To address issues related to high penetration of renewables and demand fluctuations, BESS is used to improve power supply continuity and mitigate fluctuations. The suggested approach is tested on typical 33- and 118-bus systems and compared to alternative methods. The results show significant reduction in energy losses (49.32%, 67.82%, and 64.89% for the 33-bus system and 41.9157%, 60.3766%, and 54.8317% for the 118-bus system) when integrating PV, WT-based DG, and PV + BESS units into the DS.},
  archive      = {J_NCA},
  author       = {Khasanov, Mansur and Kamel, Salah and Hassan, Mohamed H. and Domínguez-García, Jose Luis},
  doi          = {10.1007/s00521-024-09526-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8577-8605},
  shortjournal = {Neural Comput. Appl.},
  title        = {Maximizing renewable energy integration with battery storage in distribution systems using a modified bald eagle search optimization algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A seq2seq learning method for microscopic emission
estimation of on-road vehicles. <em>NCA</em>, <em>36</em>(15),
8565–8576. (<a
href="https://doi.org/10.1007/s00521-024-09512-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microscopic emission estimation based on driving states plays a crucial role in controlling the pollution of on-road vehicles. Existing research has evolved from fitting nonlinear models of driving cycles and emission factors to utilizing neural networks to exploit driving patterns and construct a nonlinear mapping between driving states and emission values. However, due to the small percentage of driving-cycle related to high emissions, it is still challenging to capture the vehicle emission peaks, which lead to the most noteworthy high-emission characteristics being regarded as abnormal disturbances instead. To address the issue, this paper proposes a peak-sensitive microscopic emission estimation framework characterized by sequence-to-sequence learning for on-road vehicles. Sequence-to-sequence learning emphasizes serial pattern mapping from driving sequences to emission sequences to provide more statistical constraints and reduce the estimation uncertainty brought by unstable driving behaviors. Specifically, the framework aims at capturing context features related to high emissions from sequences dynamically in an adaptive and self-learning way and is composed of a driving states embedding module and a dynamic aggregation module. Particularly, an incremental tracking loss (ITL) is proposed to adjust the incremental emissions at adjacent time steps by supervising the differences of the generated sequences, enabling the model to track sudden changes in emissions. Extensive experiments are conducted on the on-board diagnostics (OBD) dataset with 12628 sampling records collected from a heavy-duty diesel vehicle. The results show that the estimation accuracy of our proposed method is significantly better than state-of-the-art methods, and it can effectively capture high-emission peaks.},
  archive      = {J_NCA},
  author       = {Zhao, Zhenyi and Cao, Yang and Xu, Zhenyi and Kang, Yu},
  doi          = {10.1007/s00521-024-09512-5},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8565-8576},
  shortjournal = {Neural Comput. Appl.},
  title        = {A seq2seq learning method for microscopic emission estimation of on-road vehicles},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Black-box attacks on face recognition via affine-invariant
training. <em>NCA</em>, <em>36</em>(15), 8549–8564. (<a
href="https://doi.org/10.1007/s00521-024-09543-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network (DNN)-based face recognition has shown impressive performance in verification; however, recent studies reveal a vulnerability in deep face recognition algorithms, making them susceptible to adversarial attacks. Specifically, these attacks can be executed in a black-box manner with limited knowledge about the target network. While this characteristic is practically significant due to hidden model details in reality, it presents challenges such as high query budgets and low success rates. To improve the performance of attacks, we establish the whole framework through affine-invariant training, serving as a substitute for inefficient sampling. We also propose AI-block—a novel module that enhances transferability by introducing generalized priors. Generalization is achieved by creating priors with stable features when sampled over affine transformations. These priors guide attacks, improving efficiency and performance in black-box scenarios. The conversion via AI-block enables the transfer gradients of a surrogate model to be used as effective priors for estimating the gradients of a black-box model. Our method leverages this enhanced transferability to boost both transfer-based and query-based attacks. Extensive experiments conducted on 5 commonly utilized databases and 7 widely employed face recognition models demonstrate a significant improvement of up to 11.9 percentage points in success rates while maintaining comparable or even reduced query times.},
  archive      = {J_NCA},
  author       = {Sun, Bowen and Su, Hang and Zheng, Shibao},
  doi          = {10.1007/s00521-024-09543-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8549-8564},
  shortjournal = {Neural Comput. Appl.},
  title        = {Black-box attacks on face recognition via affine-invariant training},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSAT: Biologically inspired multistage adaptive threshold
for conversion of spiking neural networks. <em>NCA</em>,
<em>36</em>(15), 8531–8547. (<a
href="https://doi.org/10.1007/s00521-024-09529-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) can do inference with low power consumption due to their spike sparsity. Although SNNs can be combined with neuromorphic hardware to achieve efficient inference, they are often difficult to train directly due to discrete non-differentiable spikes. As an alternative, ANN-SNN conversion is an efficient way to achieve deep SNNs by converting well-trained artificial neural networks (ANNs). However, the existing methods commonly use constant threshold for conversion. A high constant threshold value prevents neurons from rapidly delivering spikes to deeper layers and causes high time delay. In addition, the same response for different inputs may result in information loss during the information transmission. Inspired by the biological adaptive threshold mechanism, we propose a multistage adaptive threshold (MSAT) method to alleviate this problem. Instead of using a single, constant value, the threshold is adjusted in multistages, adapting to each neuron’s firing history and input properties. Specifically, for each neuron, the dynamic threshold is positively correlated with the average membrane potential and negatively correlated with the rate of depolarization. The adaptation to membrane potential and input allows a timely adjustment of the threshold to fire spikes faster and transmit more information. Moreover, we analyze the spikes of inactivated neurons error, which is pervasive in early time steps. We also propose spike confidence accordingly to measure confidence about the neurons that correctly deliver spikes. Such spike confidence in early time steps is used to determine whether to elicit the spike to alleviate the spikes of inactivated neurons error. Combined with the proposed methods, we examine the performance on CIFAR-10, CIFAR-100, and ImageNet datasets. We also conduct sentiment classification and speech recognition experiments on the IDBM and Google speech commands datasets, respectively. Experiments show that our methods can achieve near-lossless and lower latency ANN-SNN conversion. In summary, we build a biologically inspired multistage adaptive threshold for converted SNN, with comparable performance to state-of-the-art methods while improving energy efficiency.},
  archive      = {J_NCA},
  author       = {He, Xiang and Li, Yang and Zhao, Dongcheng and Kong, Qingqun and Zeng, Yi},
  doi          = {10.1007/s00521-024-09529-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8531-8547},
  shortjournal = {Neural Comput. Appl.},
  title        = {MSAT: Biologically inspired multistage adaptive threshold for conversion of spiking neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal meta-learning through meta-learned task
representations. <em>NCA</em>, <em>36</em>(15), 8519–8529. (<a
href="https://doi.org/10.1007/s00521-024-09540-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot meta-learning involves training a model on multiple tasks to enable it to efficiently adapt to new, previously unseen tasks with only a limited number of samples. However, current meta-learning methods assume that all tasks are closely related and belong to a common domain, whereas in practice, tasks can be highly diverse and originate from multiple domains, resulting in a multimodal task distribution. This poses a challenge for existing methods as they struggle to learn a shared representation that can be easily adapted to all tasks within the distribution. To address this challenge, we propose a meta-learning framework that can handle multimodal task distributions by conditioning the model on the current task, resulting in a faster adaptation. Our proposed method learns to encode each task and generate task embeddings that modulate the model’s activations. The resulting modulated model become specialized for the current task and leads to more effective adaptation. Our framework is designed to work in a realistic setting where the mode from which a task is sampled is unknown. Nonetheless, we also explore the possibility of incorporating auxiliary information, such as the task-mode-label, to further enhance the performance of our method if such information is available. We evaluate our proposed framework on various few-shot regression and image classification tasks, demonstrating its superiority over other state-of-the-art meta-learning methods. The results highlight the benefits of learning to embed task-specific information in the model to guide the adaptation when tasks are sampled from a multimodal distribution.},
  archive      = {J_NCA},
  author       = {Vettoruzzo, Anna and Bouguelia, Mohamed-Rafik and Rögnvaldsson, Thorsteinn},
  doi          = {10.1007/s00521-024-09540-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8519-8529},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal meta-learning through meta-learned task representations},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ICapS-MS: An improved capuchin search algorithm-based
mobile-sink sojourn location optimization and data collection scheme for
wireless sensor networks. <em>NCA</em>, <em>36</em>(15), 8501–8517. (<a
href="https://doi.org/10.1007/s00521-024-09520-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data collection using Mobile Sink (MS) is one of the best approaches to address the hot spot issue resulting from multihop data collection and extend the lifetime of Wireless Sensor Networks wherein the MS tours a few specific locations called sojourn locations that serve as data collecting points (DCPs). The best choice of these locations is an NP-hard problem, and the optimum or nearly optimum results can be achieved by applying meta-heuristic optimization methods. It is challenging to create an effective algorithm that allows MS for data collection irrespective of the network topology changes caused by node failures since these changes affect node coverage, data transmission, and network lifespan. Hence, an effort must be made to ensure a trade-off between the MS trajectory and the number of hops. Different MS-based techniques have been proposed; however, most of them fell short of addressing the above goals. With this inspiration, we propose iCapS-MS, which is an integrated approach that utilizes an improved Capuchin Search Algorithm (iCapSA) to determine the best set of DCPs and enhanced Ant Colony Optimization (e-ACO)-based MS trajectory design. Using iCapSA, the best DCPs are selected such that almost every node is served in one-hop communication with the shortest feasible hop distance and minimum coverage intersection between DCPs. The best trajectory for MS is established using e-ACO method. The results demonstrate that iCapS-MS outperforms existing methods based on several performance metrics.},
  archive      = {J_NCA},
  author       = {Al Aghbari, Zaher and Pravija Raj, P V and Mostafa, Reham R. and Khedr, Ahmed M.},
  doi          = {10.1007/s00521-024-09520-5},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8501-8517},
  shortjournal = {Neural Comput. Appl.},
  title        = {ICapS-MS: An improved capuchin search algorithm-based mobile-sink sojourn location optimization and data collection scheme for wireless sensor networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A double actor-critic learning system embedding improved
monte carlo tree search. <em>NCA</em>, <em>36</em>(15), 8485–8500. (<a
href="https://doi.org/10.1007/s00521-024-09513-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the bias between the estimated value and the true value, overestimation is a basic problem in reinforcement learning, which leads to a lower total reward because of the incorrect action decisions. In order to reduce the impact of overestimation on reinforcement learning, we propose a double Actor-Critic learning system embedding improved Monte Carlo Tree Search (DAC-IMCTS). The proposed learning system consists of a reference module, a simulation module and an outcome module. The reference module and the simulation module are designed to compute the upper bound and lower bound of the expected reward of the agent, respectively. And the outcome module is developed to learn the agent’s control policies. The reference module, constructed based on the Actor-Critic framework, provides an upper confidence bound of the expected reward. Different from the classic Actor-Critic learning system, we introduce a simulation module into the new learning system to estimate the lower confidence bound of the expected reward. We propose an improved MCTS in this module to sample the policy distribution more efficiency. Based on the lower and upper confidence bounds, we propose a confidence interval weighted estimation algorithm (CIWE) in the outcome module for generating the target expected reward. We then prove that the target expected reward generated by our method has zero expectation bias, which reduces the overestimation that exists in the classic Actor-Critic learning system. We evaluate our learning system on OpenAI Gym experimental tasks. The experimental results show that our proposed model and algorithm outperform the state-of-the-art learning systems.},
  archive      = {J_NCA},
  author       = {Zhu, Hongjun and Xie, Yong and Zheng, Suijun},
  doi          = {10.1007/s00521-024-09513-4},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8485-8500},
  shortjournal = {Neural Comput. Appl.},
  title        = {A double actor-critic learning system embedding improved monte carlo tree search},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lifelong learning with selective attention over seen classes
and memorized instances. <em>NCA</em>, <em>36</em>(15), 8473–8484. (<a
href="https://doi.org/10.1007/s00521-024-09542-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catastrophic forgetting challenges lifelong classification learning of modern neural networks, especially when observations arrive from a data stream and the boundaries of classification tasks are unknown. In this study, we focus on the online task-free setting and formulate the continual learning of a sequence of classification tasks as a dynamically weighted loss minimization problem. Specifically, we present Learning with Selective Attention over seen Classes, which minimizes the empirical loss on each seen class, and enforces the losses of different classes to be reconciled with gradient-weighted attention. To ensure an efficient and accurate loss estimation without reserving and rehearsing all the previously seen data, we further propose Learning with Selective Attention over memorized Instances, which relies on a hard attention to select replay samples sharing both stream-sensitivity and distribution-diversity from an elaborately maintained exemplar reservoir. Experimental results on four lifelong learning benchmarks validate the superiority of the proposed approach.},
  archive      = {J_NCA},
  author       = {Wang, Zhijun and Wang, Hongxing},
  doi          = {10.1007/s00521-024-09542-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8473-8484},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lifelong learning with selective attention over seen classes and memorized instances},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HBNet: An integrated approach for resolving class imbalance
and global local feature fusion for accurate breast cancer
classification. <em>NCA</em>, <em>36</em>(15), 8455–8472. (<a
href="https://doi.org/10.1007/s00521-024-09541-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer, a widespread global disease, represents a significant threat to women’s health and lives. Many researchers have proposed computer-aided diagnosis systems for classifying breast cancer. The majority of the approaches primarily utilize deep learning methods, which overlook the crucial necessity of incorporating both local information for precise tumor detection. In addition, available breast cancer datasets are imbalanced in nature. Therefore, this paper presents the hybrid breast network (HBNet) for detection of breast cancer, designed to address two critical challenges: class imbalance and incorporation of both global and local information in achieving precise tumor classification. To overcome the problem of class imbalance, HBNet incorporates the borderline synthetic minority oversampling technique. Simultaneously, it employs a feature fusion approach to combine deep and handcrafted features extracted by utilizing ResNet50 and HOG which incorporates global and local information. Moreover, the proposed method integrates the block-matching and 3D denoising filter to effectively eliminate multiplicative noise that has enhanced the performance of the system. The proposed HBNet is evaluated with BUSI and UDIAT datasets and achieved an average accuracy of 95.824% and 90.37%, respectively.},
  archive      = {J_NCA},
  author       = {Abhisheka, Barsha and Biswas, Saroj Kumar and Purkayastha, Biswajit},
  doi          = {10.1007/s00521-024-09541-0},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8455-8472},
  shortjournal = {Neural Comput. Appl.},
  title        = {HBNet: An integrated approach for resolving class imbalance and global local feature fusion for accurate breast cancer classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video deepfake detection using particle swarm optimization
improved deep neural networks. <em>NCA</em>, <em>36</em>(15), 8417–8453.
(<a href="https://doi.org/10.1007/s00521-024-09536-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As complexity and capabilities of Artificial Intelligence technologies increase, so does its potential for misuse. Deepfake videos are an example. They are created with generative models which produce media that replicates the voices and faces of real people. Deepfake videos may be entertaining, but they may also put privacy and security at risk. A criminal may forge a video of a politician or another notable person in order to affect public opinions or deceive others. Approaches for detecting and protecting against these types of forgery must evolve as well as the methods of generation to ensure that proper information is supplied and to mitigate the risks associated with the fast evolution of deepfakes. This research exploits the effectiveness of deepfake detection algorithms with the application of a Particle Swarm Optimization (PSO) variant for hyperparameter selection. Since Convolutional Neural Networks excel in recognizing objects and patterns in visual data while Recurrent Neural Networks are proficient at handling sequential data, in this research, we propose a hybrid EfficientNet-Gated Recurrent Unit (GRU) network as well as EfficientNet-B0-based transfer learning for video forgery classification. A new PSO algorithm is proposed for hyperparameter search, which incorporates composite leaders and reinforcement learning-based search strategy allocation to mitigate premature convergence. To assess whether an image or a video is manipulated, both models are trained on datasets containing deepfake and genuine photographs and videos. The empirical results indicate that the proposed PSO-based EfficientNet-GRU and EfficientNet-B0 networks outperform the counterparts with manual and optimal learning configurations yielded by other search methods for several deepfake datasets.},
  archive      = {J_NCA},
  author       = {Cunha, Leandro and Zhang, Li and Sowan, Bilal and Lim, Chee Peng and Kong, Yinghui},
  doi          = {10.1007/s00521-024-09536-x},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8417-8453},
  shortjournal = {Neural Comput. Appl.},
  title        = {Video deepfake detection using particle swarm optimization improved deep neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 drug repurposing model based on pigeon-inspired
optimizer and rough sets theory. <em>NCA</em>, <em>36</em>(15),
8397–8415. (<a
href="https://doi.org/10.1007/s00521-024-09518-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering the most effective anti-SARS-CoV-2 drugs is the optimal solution to get back to a normal life without COVID-19. Drug repurposing, also known as drug repositioning, has become one of the most important solutions for developing new COVID-19 drugs. However, this alternative requires long-term laboratory experiments to reach the optimal drug that involves the best combination of drug features to resist the COVID-19 virus. In response to this challenge, the COVID-19 drug repurposing (C19-DR) model based on pigeon-inspired optimizer (PIO) and rough sets theory (RST) is proposed. The proposed model presents a new rough set-based feature selection technique that uses a pigeon-inspired optimizer algorithm to find and validate the optimal reduct of drug features to design an effective COVID-19 drug. Moreover, the proposed model can investigate the efficiency of multiple medications against the COVID-19 virus based on the half-maximal inhibitory concentration (IC50) threshold. The effectiveness of the proposed COVID-19 drug repurposing model has been validated using a laboratory drug dataset consisting of 60 medications. The practical results show that the optimized rough set reduct of {hydrogen bonding acceptor (HBA) and number of chiral centers} is the most significant reduct that can be used to design an effective COVID-19 drug. Moreover, the proposed drug design model could verify the efficiency of a selected dataset of drug models based on evaluating the IC50 metric. The verification results proved the high effectiveness of the proposed model in evaluating the predicted IC50 with an accuracy of 91.4% and MSE of 0.034. These findings might be a promising solution that can assist researchers in developing and repurposing novel medications to treat COVID-19 and its new viral mutants.},
  archive      = {J_NCA},
  author       = {Gad, Ibrahim and Torky, Mohamed and Elshaier, Yaseen A. M. M. and Darwish, Ashraf and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-024-09518-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8397-8415},
  shortjournal = {Neural Comput. Appl.},
  title        = {COVID-19 drug repurposing model based on pigeon-inspired optimizer and rough sets theory},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum mayfly optimization based feature subset selection
with hybrid CNN for biomedical parkinson’s disease diagnosis.
<em>NCA</em>, <em>36</em>(15), 8383–8396. (<a
href="https://doi.org/10.1007/s00521-024-09516-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s disease (PD) arises from brain cell damage and necessitates early detection for effective treatment and symptom management. While various methods such as voice, speech, and written exams have been explored, utilizing automated tools is crucial to enhance accuracy. Recent advancements in artificial intelligence (AI) and deep learning (DL) provide an opportunity for precise early-stage PD identification. This study introduces a novel approach known as Quantum Mayfly Optimization-based feature subset selection with hybrid convolutional neural network (QMFOFS-HCNN) to improve PD detection and classification. QMFOFS-HCNN is designed to identify optimal feature subsets and overcome the dimensionality challenge. It combines a quantum mayfly optimization approach for feature selection with a convolutional neural network with attention-based long short-term memory for PD detection and classification. Additionally, hyperparameter selection is optimized using the Nadam optimizer. Experimental validation using benchmark datasets yielded compelling results. The QMFOFS-HCNN technique achieved accuracy rates: 96.35% for HandPD Spiral, 96.7% for HandPD Meander, 98.5% for Speech PD, and a perfect 100% for Voice PD datasets. These quantitative findings underscore the potential of AI and DL to enhance early PD detection accuracy significantly. These results offer promising prospects for improving healthcare outcomes in managing PD and related neurological disorders.},
  archive      = {J_NCA},
  author       = {Mansour, Romany F.},
  doi          = {10.1007/s00521-024-09516-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8383-8396},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantum mayfly optimization based feature subset selection with hybrid CNN for biomedical parkinson’s disease diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of BiLSTM-CRF model with different embeddings
for product name extraction in unstructured turkish text. <em>NCA</em>,
<em>36</em>(15), 8371–8382. (<a
href="https://doi.org/10.1007/s00521-024-09532-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) plays a pivotal role in Natural Language Processing by identifying and classifying entities within textual data. While NER methodologies have seen significant advancements, driven by pretrained word embeddings and deep neural networks, the majority of these studies have focused on text with well-defined grammar and structure. A significant research gap exists concerning NER in informal or unstructured text, where traditional grammar rules and sentence structure are absent. This research addresses this crucial gap by focusing on the detection of product names within unstructured Turkish text. To accomplish this, we propose a deep learning-based NER model which combines a Bidirectional Long Short-Term Memory (BiLSTM) architecture with a Conditional Random Field (CRF) layer, further enhanced by FastText embeddings. To comprehensively evaluate and compare our model’s performance, we explore different embedding approaches, including Word2Vec and Glove, in conjunction with the Bidirectional Long Short-Term Memory and Conditional Random Field (BiLSTM-CRF) model. Furthermore, we conduct comparisons against BERT to assess the efficacy of our approach. Our experimentation utilizes a Turkish e-commerce dataset gathered from the internet, where traditional grammatical and structural rules may not apply. The BiLSTM-CRF model with FastText embeddings achieved an F1 score value of 57.40%, a precision value of 55.78%, and a recall value of 59.12%. These results indicate promising performance in outperforming other baseline techniques. This research contributes to the field of NER by addressing the unique challenges posed by unstructured Turkish text and opens avenues for improved entity recognition in informal language settings, with potential applications across various domains.},
  archive      = {J_NCA},
  author       = {Arslan, Serdar},
  doi          = {10.1007/s00521-024-09532-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8371-8382},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application of BiLSTM-CRF model with different embeddings for product name extraction in unstructured turkish text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CASA: Cost-effective EV charging scheduling based on deep
reinforcement learning. <em>NCA</em>, <em>36</em>(15), 8355–8370. (<a
href="https://doi.org/10.1007/s00521-024-09530-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of electric vehicles (EVs), the demand for public charging services is steadily increasing. Consequently, the development of effective charging scheduling strategies, aimed at optimizing the utilization of limited charging infrastructure, has become a key problem. Considering the diversity of user demands, we propose a Cost-Aware Charging Scheduling Architecture (CASA). This architecture considers both urgent and nonurgent charging customers by designing two charging modes with different power levels and associated costs. However, optimizing multiple objectives simultaneously while ensuring the interests of all parties involved in the charging demand response presents a challenge. Moreover, the uncertainty in customer charging demands and Time-of-Use (TOU) tariff further complicates the establishment of the model. To address the aforementioned challenges, this study formulates EV charging scheduling as a Markov Decision Process (MDP) based on deep reinforcement learning (DRL), employing the Deep Q-Network (DQN) algorithm for solution derivation. The objective is to minimize the operational costs of charging stations while ensuring the quality of service (QoS) requirements for customers. The simulation results demonstrate that CASA exhibits superior performance in optimizing both the average response time and service success rate, compared to commonly used baselines for charging scheduling. Furthermore, the CASA approach achieves a significant reduction in operating costs of EV charging station.},
  archive      = {J_NCA},
  author       = {Zhang, Ao and Liu, Qingzhi and Liu, Jinwei and Cheng, Long},
  doi          = {10.1007/s00521-024-09530-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8355-8370},
  shortjournal = {Neural Comput. Appl.},
  title        = {CASA: Cost-effective EV charging scheduling based on deep reinforcement learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A 3D-convolutional-autoencoder embedded
siamese-attention-network for classification of hyperspectral images.
<em>NCA</em>, <em>36</em>(15), 8335–8354. (<a
href="https://doi.org/10.1007/s00521-024-09527-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of hyperspectral images (HSI) into categories that correlate to various land cover sorts such as water bodies, agriculture and urban areas, has gained significant attention in research due to its wide range of applications in fields, such as remote sensing, computer vision, and more. Supervised deep learning networks have demonstrated exceptional performance in HSI classification, capitalizing on their capacity for end-to-end optimization and leveraging their strong potential for nonlinear modeling. However, labelling HSIs, on the other hand, necessitates extensive domain knowledge and is a time-consuming and labour-intensive exercise. To address this issue, the proposed work introduces a novel semi-supervised network constructed with an autoencoder, Siamese action, and attention layers that achieves excellent classification accuracy with labelled limited samples. The proposed convolutional autoencoder is trained using the mass amount of unlabelled data to learn the refinement representation referred to as 3D-CAE. The added Siamese network improves the feature separability between different categories and attention layers improve classification by focusing on discriminative information and neglecting the unimportant bands. The efficacy of the proposed model’s performance was assessed by training and testing on both same-domain as well as cross-domain data and found to achieve 91.3 and 93.6 for Indian Pines and Salinas, respectively.},
  archive      = {J_NCA},
  author       = {Ranjan, Pallavi and Kumar, Rajeev and Girdhar, Ashish},
  doi          = {10.1007/s00521-024-09527-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8335-8354},
  shortjournal = {Neural Comput. Appl.},
  title        = {A 3D-convolutional-autoencoder embedded siamese-attention-network for classification of hyperspectral images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimal and smart e-waste collection using neural network
based on sine cosine optimization. <em>NCA</em>, <em>36</em>(15),
8317–8333. (<a
href="https://doi.org/10.1007/s00521-024-09523-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic waste (e-waste) is considered a major issue that our world is tackling nowadays. This electronic waste causes various health issues to animals as well as human beings which further results in environmental pollution in developing countries like India. To overcome these issues, proper e-waste collection is proposed by using the dynamic sine cosine-based neural network optimization (DSCNN) approach. The major objective of this approach involves collecting waste from the individual, hence handling the widespread adoption and use of smartphones. To enhance waste planning collection, residents upload a photograph of their waste to the waste collection company’s server, which mechanically recognizes and categorizes the image. A new classification and detection scheme using the DSCNN approach is proposed for efficient e-waste collection planning and correctly detects the type and quantity of waste components in images. The identification and classification accuracy of the uploaded images is very accurate; this method describes the e-waste collection process in various streets and buildings in Maharashtra, India. Experimental results describe that the proposed approach readily achieves the proper allocation of vehicle collection, vehicle routing plan, and household e-waste collection, resulting in reduced collection costs. Moreover, the proposed DSCNN method is compared to various other methods like random forest algorithm (RFA), fractional henry gas optimization (FHGO), behavior-based swarm model by the fuzzy controller (BSFC), and deep learning convolutional neural network (DL-CNN). The DSCNN approach yielded an e-waste collection detection accuracy of 97%. The accuracy rates of 94%, 95%, 93%, and 92.15% are obtained from the DL-CNN, FHGO, BSFC, and RFA.},
  archive      = {J_NCA},
  author       = {Ravi, Srivel and Venkatesan, S. and Arun kumar and Lakshmi Kanth Reddy, K.},
  doi          = {10.1007/s00521-024-09523-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8317-8333},
  shortjournal = {Neural Comput. Appl.},
  title        = {An optimal and smart E-waste collection using neural network based on sine cosine optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-channel augmented attentive dense-convolutional
network for power image splicing tamper detection. <em>NCA</em>,
<em>36</em>(15), 8301–8316. (<a
href="https://doi.org/10.1007/s00521-024-09511-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power image tampering brings certain security risks to the safe operation of power grids, among which splicing tampering is the most common. Although image tampering detection has received much attention in recent years, relatively little research has been conducted on the practical application to power systems, and the detection results are poor due to the difficulty of learning subtle edge features of tampered regions and the lack of power image tampering dataset for training. In order to effectively detect image tampering regions, this paper proposes a splicing tampering detection model with a Dual-channel Augmented Attentive Dense-convolutional Network (DAAD-Net) structure. The model consists of three main parts: backbone network feature extraction, augmented attention feature extraction, and tampered region detection. Firstly, the backbone network feature extraction module fuses the original tampered image features with the image residual features and transfers them into the backbone network to extract the feature map. Secondly, the augmented attention feature extraction module extracts the tampered region features in the higher and lower layers using hierarchical encoding and decoding operations. Finally, the extracted feature maps of each layer are sent to the tampered region detection module, and by combining the loss of each feature map for optimizing the network parameters. Additionally, we produced a power image tampering dataset containing 552 samples. Experiments demonstrate that the proposed method outperforms current state-of-the-art models, with 1% to 31% improvement in evaluation indicators, and has good robustness to noise and JPEG compression attacks.},
  archive      = {J_NCA},
  author       = {Xing, Jianhao and Tian, Xiuxia and Han, Yi},
  doi          = {10.1007/s00521-024-09511-6},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8301-8316},
  shortjournal = {Neural Comput. Appl.},
  title        = {A dual-channel augmented attentive dense-convolutional network for power image splicing tamper detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MXception and dynamic image for hand gesture recognition.
<em>NCA</em>, <em>36</em>(15), 8281–8300. (<a
href="https://doi.org/10.1007/s00521-024-09509-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gesture detection has recently attracted a lot of attention due to its wide range of applications, notably in human–computer interaction (HCI). However, when it comes to video-based gesture recognition, elements in the background unrelated to gestures slow down the system’s classification rate. This paper presents an algorithm designed for the recognition of large-scale gestures. In the training phase, we utilize RGB-D videos, where the depth modality videos are derived from RGB modality videos using UNET and subsequently employed for testing. However, it’s worth noting that in real-time applications of the proposed dynamic hand gesture recognition (DHGR) system, only RGB modality videos are needed. The algorithm begins by creating two dynamic images: one from the estimated depth video and the other from the RGB video. Dynamic images generated from RGB video excel in capturing spatial information; while, those derived from depth video excel in encoding temporal aspects. These two dynamic images are merged to form an RGB-D dynamic image (RDDI). The RDDI is then fed into a modified Xception-based CNN model for the purpose of gesture classification and recognition. In order to evaluate the system’s performance, we conducted experiments using the EgoGesture and MSR Gesture datasets. The results are highly promising, with a reported classification accuracy of 91.64% for the EgoGesture dataset and an impressive 99.41% for the MSR Gesture dataset. The results demonstrated that the suggested system outperformed some existing techniques.},
  archive      = {J_NCA},
  author       = {Karsh, Bhumika and Laskar, Rabul Hussain and Karsh, Ram Kumar},
  doi          = {10.1007/s00521-024-09509-0},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8281-8300},
  shortjournal = {Neural Comput. Appl.},
  title        = {MXception and dynamic image for hand gesture recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fractal dimensions and machine learning for detection of
parkinson’s disease in resting-state electroencephalography.
<em>NCA</em>, <em>36</em>(15), 8257–8280. (<a
href="https://doi.org/10.1007/s00521-024-09521-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is an incurable neurological disorder that degenerates the cerebrospinal nervous system and hinders motor functions. Electroencephalography (EEG) signal analysis can provide reliable information regarding PD conditions. However, EEG is a complex, multichannel, and nonlinear signal with noise that problematizes identifying PD symptoms. A few studies have employed fractal dimension (FD) to extract distinguishing PD features from EEG signals. However, no exploratory study exists, as per our knowledge, on the efficiency of the different FD measures. We aim to conduct a comparative analysis of the various FDs that, as feature extraction measures, can discriminate PD patients who are ON and OFF medication from healthy controls using ML architecture. This study has implemented and analyzed several techniques for segmentation, feature extraction, and ML models. The results show that k-nearest neighbors (KNN) classifier with Higuchi FD and 90% overlap for segmented window delivers the highest accuracies, yielding a mean accuracy of $$99.65\pm 0.15\%$$ for PD patients ON medication and $$99.45\pm 0.18\%$$ for PD patients OFF medication, respectively. The model accurately identifies the signs of the disease in resting-state EEG with almost equivalent accuracy in both OFF and ON medication patients. To enhance the interpretability in our study, we leveraged XGB’s feature importance to generate brain topographic plots. This integration of explainable AI (XAI) enhanced the transparency and comprehensibility of our model’s classifications. Additionally, a comparison between the performance of FD and a few entropy measures has also been drawn to validate the significance of FD as a superior feature extraction measure. This study contributes to the body of knowledge with an architectural pipeline for detecting PD in resting-state EEG while emphasizing fractal dimension as an effective way of extracting salient features from EEG signals.},
  archive      = {J_NCA},
  author       = {Lal, Utkarsh and Chikkankod, Arjun Vinayak and Longo, Luca},
  doi          = {10.1007/s00521-024-09521-4},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {15},
  pages        = {8257-8280},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fractal dimensions and machine learning for detection of parkinson’s disease in resting-state electroencephalography},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). In-use calibration: Improving domain-specific fine-grained
few-shot recognition. <em>NCA</em>, <em>36</em>(14), 8235–8255. (<a
href="https://doi.org/10.1007/s00521-024-09501-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to recognize novel visual classes from few samples is challenging but promising. Previous studies have shown that few-shot model tends to overfit and lead to poor generalization performance, which is because it finds a biased distribution based on a few samples. In addition, in agriculture-specific domains, there are more serious research challenges such as imbalanced disease distribution, one-shot representation biases, fine-grained recognition, and granularity shift. As far as we know, this study is the first work on the fine-grained “Coarse-to-Fine” few-shot plant disease classification, which classifies “fine-grained novel classes” (specific to disease severity) based on “coarse-grained base classes” (specific to plant species). A complete two-stage in-use calibration strategy is presented in this paper. Firstly, we propose an attention-based inverse Mahalanobis distance weighted prototype calibration module (AIPCM). By transferring statistics from sample-rich coarse-grained base classes to sample-scarce fine-grained novel classes, we achieve prototype calibration for 1-shot sample and obtain an unbiased distribution in the feature space. Secondly, to generate more reasonable decision boundaries, we propose a prior-driven task-adapted decision boundary calibration module (TDBCM) based on class-covariance metric. The original Euclidean/Cosine distance is updated to the Mahalanobis distance by introducing the prior mean and covariance of the high-dimensional features. Experimental results on several datasets demonstrate that our model outperforms the state-of-the-art (SOTA) models. It can be said that our work is a valuable supplement to the domain-specific agricultural applications.},
  archive      = {J_NCA},
  author       = {Li, Minghui and Yao, Hongxun},
  doi          = {10.1007/s00521-024-09501-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8235-8255},
  shortjournal = {Neural Comput. Appl.},
  title        = {In-use calibration: Improving domain-specific fine-grained few-shot recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enrichment multi-layer arabic text classification model
based on siblings patterns extraction. <em>NCA</em>, <em>36</em>(14),
8221–8234. (<a
href="https://doi.org/10.1007/s00521-023-09405-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ontologies extraction is the cornerstone for a meaningful knowledge representation. Ontologies represent the semantic relations repository in a readable format with a clear representation of the domain knowledge. This made the automated ontologies construction a promising research objective with a direct and clear impact in many related fields, including knowledge base systems, text classification, etc. In this research, a workflow is set up for successful ontology learning from Arabic textual data. One of the bottlenecks for the text analytics field is the continuous requirement of up-to-date resources such as lexicons. This challenge is one of the main focuses of the current research, which proposes an automated ontology extraction method with no use of pre-defined resources. The research proposes a novel generic ontology learning and document classification model based on no utilization of prior text analysis resources. Moreover, a self-enrichment approach is proposed to ensure continuous knowledge construction. The research extends the ontology learning process to include the ontologies’ semantic relationships, targeting a higher level of extraction and model enrichment. Two experiments have been applied with two different datasets that belong to different fields to ensure the generality of the proposed model. The results of the two experiments confirmed the high accuracy of the proposed model and its positive contribution to the classification task. The results of the ontology learning task reached 95%, while the classification task revealed the advancement of the Bagging algorithm over other machine learning algorithms with an accuracy equal to 97.92%.},
  archive      = {J_NCA},
  author       = {Idrees, Amira M. and Al-Solami, Abdul Lateef Marzouq},
  doi          = {10.1007/s00521-023-09405-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8221-8234},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enrichment multi-layer arabic text classification model based on siblings patterns extraction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reinforcement learning (RL)-based hybrid method for ground
penetrating radar (GPR)-driven buried object detection. <em>NCA</em>,
<em>36</em>(14), 8199–8219. (<a
href="https://doi.org/10.1007/s00521-024-09466-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ground penetrating radar (GPR) systems are effective sensors for discovering various types of objects buried underground, such as military mines, metal objects, and pieces of underground infrastructures. A GPR system can be manually operated by a human or can be an integral part of a host platform. The host platform may be semi- or fully autonomous and may operate in different environments such as land vehicles or more recently air-borne drones. One challenge for the fully or semi-autonomous host platforms in particular is to find an efficient search procedure that would reduce the operation time and optimize resource utilization. Most of the current approaches are based on pre-defined search patterns which, for large and sparse areas, could mean unnecessary waste of time and resources. In this paper, we introduce a method that combines a coarse and therefore relatively low cost initial search pattern with a Reinforcement Learning (RL) driven efficient navigation path for eventual target detection, by exploiting the signal processing pipeline of the onboard GPR. We illustrate the applicability of the method using a well-known, high fidelity GPR simulation environment and a novel RL framework. Our results suggest that combination of a coarse navigation scheme and an RL-based training procedure based on GPR scan returns can lead to a more efficient target discovery procedure for host platforms.},
  archive      = {J_NCA},
  author       = {Alpdemir, Mahmut Nedim and Sezgin, Mehmet},
  doi          = {10.1007/s00521-024-09466-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8199-8219},
  shortjournal = {Neural Comput. Appl.},
  title        = {A reinforcement learning (RL)-based hybrid method for ground penetrating radar (GPR)-driven buried object detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing cardiac diagnostics through semantic-driven image
synthesis: A hybrid GAN approach. <em>NCA</em>, <em>36</em>(14),
8181–8197. (<a
href="https://doi.org/10.1007/s00521-024-09452-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac image synthesis and analysis are pivotal in modern healthcare for accurate diagnosis and treatment of cardiovascular conditions. This study introduces a pioneering approach—hybrid GAN with semantic resonance—for the generation and analysis of synthetic cardiac images. Drawing from a diverse dataset encompassing local and global views, acquired through various modalities like MRI, CT, and echocardiography, the critical need for both accuracy and clinical relevance in cardiac image synthesis is addressed. In the architectural setup, a hybrid GAN is defined, comprising both local and global components. The local generator excels in capturing intricate details, while the global generator contextualizes the overall cardiac structure. A fundamental innovation lies in the incorporation of pre-trained CNN classifiers specialized in recognizing cardiac pathologies, anatomical structures, and clinical features. These classifiers provide conditional guidance to the generators, ensuring that the synthesized images align semantically with clinical expectations. The training phase employs a pioneering approach, integrating real-time feedback from the classifiers to steer the image synthesis process. The generators, discriminators, and classifiers are optimized, with a dual emphasis on adversarial loss for authenticity and classification loss for diagnostic significance. The accuracy obtained by the proposed approach is 98.96%. Further, the SSIM and PSNR values attained by the proposed approach are 0.955 and 45.23, which is higher than the existing approaches like GAN, CNN, VAE, DenseNet, VGG19, DeepCardiac, Pix2Pix GAN and Cycle-GAN, respectively. Validation on an independent test dataset underscores the generalization capabilities of the proposed hybrid GAN. Furthermore, post-processing techniques refine the generated images, elevating their clinical relevance. Results visualization presents the prowess of the proposed approach, providing a holistic view of local and global perspectives within synthetic images.},
  archive      = {J_NCA},
  author       = {Gurusubramani, S. and Latha, B.},
  doi          = {10.1007/s00521-024-09452-0},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8181-8197},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing cardiac diagnostics through semantic-driven image synthesis: A hybrid GAN approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of machine learning strategies for simplified
detection of autism spectrum disorder based on the gut microbiome
composition. <em>NCA</em>, <em>36</em>(14), 8163–8180. (<a
href="https://doi.org/10.1007/s00521-024-09458-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies relating the gut microbiota composition and autism spectrum disorder focus on finding the statistical differences in microbiome composition between neurotypical and autistic subjects. Since microbiota composition involves high-dimensional variables, establishing inferential or causal relationships using only statistical information is complex, hindering advances toward early functional treatment. Complementary machine learning strategies related to the study of autism spectrum disorder are focused on early diagnosis, substituting the expensive screening tests without providing a possible guide to future alternatives to reduce autism spectrum disorder symptoms. Such techniques may offer better outcomes as a direct approach complemented with statistical analysis to optimize patient healthcare based on an early and simplified detection process. This work evaluates several classic machine learning models, including random forests, support vector machines, k-nearest neighbors, Naïve Bayes, and artificial neural network models. The developed models were assessed to identify less-known patterns and their underlying structures to prior published research on the relationship between gut microbiome composition and an autism spectrum disorder. The differences and similarities between the discovered patterns and existing research are discussed to detect a minimal set of strains that may define the presence of autism spectrum disorder. The best-evaluated models were an artificial neural network and a k-nearest neighbor model, reaching an accuracy of 94.7% in the testing partition with only two missed classifications from 38 previously unseen testing samples. These outcomes support the potential of machine learning strategies to construct a useful pre-diagnostic tool for autism spectrum disorder based on relative gut microbiome distribution.},
  archive      = {J_NCA},
  author       = {Olaguez-Gonzalez, Juan M. and Schaeffer, S. Elisa and Breton-Deval, Luz and Alfaro-Ponce, Mariel and Chairez, Isaac},
  doi          = {10.1007/s00521-024-09458-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8163-8180},
  shortjournal = {Neural Comput. Appl.},
  title        = {Assessment of machine learning strategies for simplified detection of autism spectrum disorder based on the gut microbiome composition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-stage classification for lung cancer detection and
staging using hybrid deep learning techniques. <em>NCA</em>,
<em>36</em>(14), 8141–8161. (<a
href="https://doi.org/10.1007/s00521-024-09425-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer, a malignant disease originating in the lungs, presents significant challenges in early detection and staging. It occurs when abnormal lung cells grow uncontrollably, forming tumors that disrupt lung function. Timely detection is vital for better treatment outcomes. Staging, which assesses the cancer’s extent and severity, guides treatment decisions and prognosis predictions. Lung cancer diagnosis and staging face obstacles like symptom absence, similar imaging findings to other lung conditions, limited screening methods, invasive biopsies, complex staging procedures, variable tumor behavior, metastasis detection challenges, clinical overlap, comorbidities, and observer variability. Overcoming these hurdles is crucial for improving lung cancer care. In this study, we present a dual-stage classification model aimed at detecting and staging lung cancer using a combination of advanced deep learning techniques. We introduce a distinctive approach that commences with the development of a modified U-Net incorporating dual attention and pyramid atrous pooling. This modification enhances target segmentation accuracy, ultimately leading to improved detection precision. We further enhance our methodology by extracting texture, color, and shape features from the segmented target area. In the initial classification stage, we employ a hybrid Xception and custom CNN model, effectively distinguishing between normal and abnormal cases for tumor detection. In the subsequent stage, we extract additional locational features from the abnormal characteristics, utilizing them as input for our innovative hybrid adaptive learning neural network to achieve accurate lung cancer staging. This multistage approach represents a significant novelty in our study, aiming to enhance both detection and staging of lung cancer. To validate the model’s performance, we conducted experiments on several datasets, including LIDC-IDRI, NSCLC-radiomics–genomics, NSCLC-radiomics, and NSCLC radiogenomics. Our results demonstrate the effectiveness of our model in comparison with existing methods, as assessed through various quality evaluation metrics.},
  archive      = {J_NCA},
  author       = {Subash, Jenita and Kalaivani, S.},
  doi          = {10.1007/s00521-024-09425-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8141-8161},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dual-stage classification for lung cancer detection and staging using hybrid deep learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A topic-enhanced dirichlet model for short text stream
clustering. <em>NCA</em>, <em>36</em>(14), 8125–8140. (<a
href="https://doi.org/10.1007/s00521-024-09480-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short text streams, such as social media comments, are continuously generated, making effective clustering methods essential for extracting valuable information. However, existing research fails to address the problem of topic concentration in clustering, which leads to multiple topics being confused in one cluster, making it challenging to summarize the center of clustering. To tackle this issue, this paper proposes a novel topic-enhanced clustering method called TEDM, based on the Dirichlet model. The method uses dynamic clustering, leveraging topic information to improve the sampling of documents and better cluster documents on the same topic. TEDM constructs a dynamic word relation graph to extract topic terms, which is updated with the stream of documents to cope with the dynamic changes in topics. Extensive experimental studies demonstrate that TEDM outperforms state-of-the-art works on multiple real datasets.},
  archive      = {J_NCA},
  author       = {Liu, Kan and He, Jiarui and Chen, Yu},
  doi          = {10.1007/s00521-024-09480-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8125-8140},
  shortjournal = {Neural Comput. Appl.},
  title        = {A topic-enhanced dirichlet model for short text stream clustering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the adversarial robustness of generative autoencoders in
the latent space. <em>NCA</em>, <em>36</em>(14), 8109–8123. (<a
href="https://doi.org/10.1007/s00521-024-09438-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generative autoencoders, such as the variational autoencoders or the adversarial autoencoders, have achieved great success in lots of real-world applications, including image generation and signal communication. However, little concern has been devoted to their robustness during practical deployment. Due to the probabilistic latent structure, variational autoencoders (VAEs) may confront problems such as a mismatch between the posterior distribution of the latent and real data manifold, or discontinuity in the posterior distribution of the latent. This leaves a back door for malicious attackers to collapse VAEs from the latent space, especially in scenarios where the encoder and decoder are used separately, such as communication and compressed sensing. In this work, we provide the first study on the adversarial robustness of generative autoencoders in the latent space. Specifically, we empirically demonstrate the latent vulnerability of popular generative autoencoders through attacks in the latent space. We also evaluate the difference between variational autoencoders and their deterministic variants and observe that the latter performs better in latent robustness. Meanwhile, we identify a potential trade-off between the adversarial robustness and the degree of the disentanglement of the latent codes. Additionally, we also verify the feasibility of improvement for the latent robustness of generative autoencoders through adversarial training. In summary, we suggest concerning the adversarial latent robustness of the generative autoencoders, analyze several robustness-relative issues, and give some insights into a series of key challenges.},
  archive      = {J_NCA},
  author       = {Lu, Mingfei and Chen, Badong},
  doi          = {10.1007/s00521-024-09438-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8109-8123},
  shortjournal = {Neural Comput. Appl.},
  title        = {On the adversarial robustness of generative autoencoders in the latent space},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Invisible backdoor learning in regional transform domain.
<em>NCA</em>, <em>36</em>(14), 8097–8108. (<a
href="https://doi.org/10.1007/s00521-024-09506-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid developing deep learning is highly required by resources and computing resources, which easily leads to backdoor learnings. It is difficult for existing schemes to strike a balance among trigger concealment, the effect and the stability. Sometimes, simple manipulation of the image may disable the trigger. In this paper, we propose an invisible backdoor learning scheme in regional transform domain. The high-frequency region remains unchanged while the left region is transformed so that the trigger is added in the high frequency. Experimental results show that the attack success rate (ASR) of our scheme reaches more than 99%, while the accuracy of the model (BA) decreases by less than 1%. Our scheme can resist common defense methods and the samples; visual quality of our scheme is better than others.},
  archive      = {J_NCA},
  author       = {Sun, Yuyuan and Lu, Yuliang and Yan, Xuehu and Wang, Xuan},
  doi          = {10.1007/s00521-024-09506-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8097-8108},
  shortjournal = {Neural Comput. Appl.},
  title        = {Invisible backdoor learning in regional transform domain},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive temperature scaling for robust calibration of deep
neural networks. <em>NCA</em>, <em>36</em>(14), 8073–8095. (<a
href="https://doi.org/10.1007/s00521-024-09505-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the post-hoc calibration of modern neural networks, a problem that has drawn a lot of attention in recent years. Despite the plethora of calibration methods proposed, there is no consensus yet on the inherent complexity of the task and, while some authors claim that simple functions solve the problem, others suggest that more expressive models are needed to capture misscalibration. As a first approach, we focus on the task of confidence scaling, specifically on post-hoc methods that generalize Temperature Scaling, which we refer to as the Adaptive Temperature Scaling family. We begin by demonstrating that while complex models like neural networks provide an advantage when there is ample data, they fail in scenarios where it is limited, notably common in fields like medical diagnosis. We then show how under this ideal data conditions the more expressive methods learn a relationship between the entropy of a prediction and its level of overconfidence, and based on this observation, we propose Entropy-based Temperature Scaling, a simple method that scales the confidence of a prediction according to this relationship. Results show that our method obtains state-of-the-art performance and is robust against data scarcity. Moreover, our proposed model enables a deeper understanding of the calibration process by the interpretation of the entropy as a measure of uncertainty in the network outputs.},
  archive      = {J_NCA},
  author       = {Balanya, Sergio A. and Maroñas, Juan and Ramos, Daniel},
  doi          = {10.1007/s00521-024-09505-4},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8073-8095},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive temperature scaling for robust calibration of deep neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video q &amp;a based on two-stage deep exploration of
temporally-evolving features with enhanced cross-modal attention
mechanism. <em>NCA</em>, <em>36</em>(14), 8055–8071. (<a
href="https://doi.org/10.1007/s00521-024-09482-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal attention learning in video question answering (VideoQA) is a challenging task, as it requires consideration of information recognition within modalities and information interaction and fusion between modalities. Existing methods employs the cross-attention mechanism to compute feature similarity between modalities, thereby aggregating relevant information in a shared space. However, heterogeneous features have different distributions in the shared space, making it difficult to directly match semantics, which may affect similarity calculation. To address this issue, a novel enhanced cross-modal attention mechanism (ECAM) is proposed in this paper that pre-fuses two modalities to generate an enhanced key with feature importance distributions to effectively solve the semantic mismatch. Compared with the existing cross-attention mechanism, ECAM can realize the semantic matching between multiple modalities more accurately and pay more attention to the relevant feature regions. In the multi-modal fusion phase, a two-stage fusion strategy is proposed to exploit the advantages of the two fusion methods to deeply explore the complex and diverse dependency relationships between the multi-modal features. Collectively supported by these two newly designed modules, we proposed the VideoQA solution based on two-stage deep exploration of temporally-evolving features with enhanced cross-modal attention mechanism which is able to conquer challenging semantic understanding and question answering tasks. Extensive experiments on four VideoQA datasets show that the new approach attains superior results in comparison with state-of-the-art peer methods. Moreover, experiments on the latest joint task datasets prove that ECAM is a general mechanism that can be easily adapted to solve other visual-linguistic tasks.},
  archive      = {J_NCA},
  author       = {Luo, Yuanmao and Wang, Ruomei and Zhang, Fuwei and Zhou, Fan and Liu, Mingyang and Feng, Jiawei},
  doi          = {10.1007/s00521-024-09482-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8055-8071},
  shortjournal = {Neural Comput. Appl.},
  title        = {Video q &amp;A based on two-stage deep exploration of temporally-evolving features with enhanced cross-modal attention mechanism},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive feature decomposition for single image layer
separation. <em>NCA</em>, <em>36</em>(14), 8039–8053. (<a
href="https://doi.org/10.1007/s00521-024-09478-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge of image layer separation stems from recognizing different components in a single image. Typical methods optimize the modeling of different components by performing low-level supervision on the separated image to minimize its per-pixel difference from the groundtruth, which relies on substantial training samples to learn diverse components robustly and avoid overfitting spurious coupled patterns. In this work, we perform supervision on the contrastive distribution between the predicted separated images. Specifically, our proposed method separates components in parallel and seeks to maximize the distribution consistency between the separated components’ contrast and their corresponding groundtruth contrast in the latent space. Such supervision pushes the model to focus on contrastive modeling between different components of the input image. Besides, the learned latent representations of different components directly guide the weight optimization of convolution kernels in the decoder, which achieves more comprehensive separation than traditional skip connection while reconstructing target images by the decoder. We validate the effectiveness and generalization of our CFDNet on two single image layer separation tasks, including image reflection separation and intrinsic image decomposition. Extensive experiments demonstrate that our CFDNet consistently outperforms other state-of-the-art methods specifically designed for either of image separation applications.},
  archive      = {J_NCA},
  author       = {Feng, Xin and Li, Jingyuan and Ji, Haobo and Pei, Wenjie and Lu, Guangming and Zhang, David},
  doi          = {10.1007/s00521-024-09478-4},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8039-8053},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contrastive feature decomposition for single image layer separation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modified archimedes optimization algorithm for global
optimization problems: A comparative study. <em>NCA</em>,
<em>36</em>(14), 8007–8038. (<a
href="https://doi.org/10.1007/s00521-024-09497-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Archimedes Optimization Algorithm (AOA) is a recent optimization algorithm inspired by Archimedes’ Principle. In this study, a Modified Archimedes Optimization Algorithm (MDAOA) is proposed. The goal of the modification is to avoid early convergence and improve balance between exploration and exploitation. Modification is implemented by a two phase mechanism: optimizing the candidate positions of objects using the dimension learning-based (DL) strategy and recalculating predetermined five parameters used in the original AOA. DL strategy along with problem specific parameters lead to improvements in the balance between exploration and exploitation. The performance of the proposed MDAOA algorithm is tested on 13 standard benchmark functions, 29 CEC 2017 benchmark functions, optimal placement of electric vehicle charging stations (EVCSs) on the IEEE-33 distribution system, and five real-life engineering problems. In addition, results of the proposed modified algorithm are compared with modern and competitive algorithms such as Honey Badger Algorithm, Sine Cosine Algorithm, Butterfly Optimization Algorithm, Particle Swarm Optimization Butterfly Optimization Algorithm, Golden Jackal Optimization, Whale Optimization Algorithm, Ant Lion Optimizer, Salp Swarm Algorithm, and Atomic Orbital Search. Experimental results suggest that MDAOA outperforms other algorithms in the majority of the cases with consistently low standard deviation values. MDAOA returned best results in all of 13 standard benchmarks, 26 of 29 CEC 2017 benchmarks (89.65%), optimal placement of EVCSs problem and all of five real-life engineering problems. Overall success rate is 45 out of 48 problems (93.75%). Results are statistically analyzed by Friedman test with Wilcoxon rank-sum as post hoc test for pairwise comparisons.},
  archive      = {J_NCA},
  author       = {Nurmuhammed, Mustafa and Akdağ, Ozan and Karadağ, Teoman},
  doi          = {10.1007/s00521-024-09497-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {8007-8038},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified archimedes optimization algorithm for global optimization problems: A comparative study},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating robustness of support vector machines with the
lagrangian dual approach. <em>NCA</em>, <em>36</em>(14), 7991–8006. (<a
href="https://doi.org/10.1007/s00521-024-09490-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples bring a considerable security threat to support vector machines (SVMs), especially those used in safety-critical applications. Thus, robustness verification is an essential issue for SVMs, which can provide provable robustness against various adversarial attacks. The evaluation results obtained through robustness verification can provide a security guarantee for the use of SVMs. The existing verification method does not often perform well in verifying SVMs with nonlinear kernels. To this end, we propose a method to improve the verification performance for SVMs with nonlinear kernels. We first formalize the adversarial robustness evaluation of SVMs as an optimization problem with a feedforward neural network representation. Then, the lower bound of the original problem is obtained by solving the Lagrangian dual problem. Finally, the adversarial robustness of SVMs is evaluated concerning the lower bound. We evaluate the adversarial robustness of SVMs with linear and nonlinear kernels on the MNIST and Fashion-MNIST datasets. The experimental results show that our method achieves a higher percentage of provable robustness on the test set compared to the state-of-the-art.},
  archive      = {J_NCA},
  author       = {Liu, Yuting and Gu, Hong and Qin, Pan},
  doi          = {10.1007/s00521-024-09490-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7991-8006},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluating robustness of support vector machines with the lagrangian dual approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed-time synchronization of time-varying coupled
competitive neural networks with impulsive effects. <em>NCA</em>,
<em>36</em>(14), 7971–7990. (<a
href="https://doi.org/10.1007/s00521-024-09504-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of fixed-time synchronization of time-varying coupled competitive neural networks with impulsive effects. Synchronizing impulses and desynchronizing impulses are each taken into account. The innovative pure power-law control is designed in this paper to avoid vibratory behaviors, which is more straightforward and effective than the common design including the linear and power-law terms. Note that the key difficulty is determining how to ensure fixed-time synchronization and estimate the settling time in an impulsive sense since the impulsive influences may lead to the discontinuity of the states. However, the theoretical framework of fixed-time synchronization under desynchronizing impulses has not been constructed much in the existing literature, which deeply motivated us to contribute to this analysis. By using the average impulsive intervals method, graph theory, and the Lyapunov method, two cases of the settling time along with the fixed-time synchronization criteria regarding the synchronizing and desynchronizing impulses are given. Lastly, a numerical example is provided to show the viability and accuracy of the discovered theoretical results.},
  archive      = {J_NCA},
  author       = {Xu, Yao and Wang, Haodong and Mao, Yuheng and Wu, Yongbao and Li, Wenxue},
  doi          = {10.1007/s00521-024-09504-5},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7971-7990},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fixed-time synchronization of time-varying coupled competitive neural networks with impulsive effects},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid bio-inspired metaheuristic approach for design
compressive strength of high-strength concrete-filled high-strength
steel tube columns. <em>NCA</em>, <em>36</em>(14), 7953–7969. (<a
href="https://doi.org/10.1007/s00521-024-09494-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The specifications of AISC 360 and Eurocode 4 for the design of composite columns limit the maximum steel tube yield stress and concrete compressive strength. In this study, the limitations mentioned in the design codes are evaluated, and a new simplified relation for the nominal compressive capacity of square high-strength concrete-filled high-strength steel tube (HsCHsST) stub columns is proposed. The present study was carried out in three parts. The first part involves compiling a test database of square-filled composite columns with high-strength materials to achieve the aptest relation. The second part consists of developing a simplified relation for determining the effects of material strength on the nominal compressive strength of columns ( $${P}_{{\text{n}}}$$ ) based on the compiled database using a hybrid gene expression programming-invasive weed optimization algorithm. Finally, a new resistance factor ( $${\phi }_{{\text{c}}}$$ ) for axially loaded HsCHsST columns is determined in the third part. The predicted results for nominal compressive strength were compared with specifications of AISC 360 and Eurocode 4 in terms of various performance parameters based on measured results to validate the proposed relation. This study’s findings can be used as a suitable tool in the design compressive strength of square HsCHsST members.},
  archive      = {J_NCA},
  author       = {Ahmadi, Masoud and Ebadi-Jamkhaneh, Mehdi and Dalvand, Ahmad and Rezazadeh Eidgahee, Danial},
  doi          = {10.1007/s00521-024-09494-4},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7953-7969},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid bio-inspired metaheuristic approach for design compressive strength of high-strength concrete-filled high-strength steel tube columns},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust generation expansion planning in power grids under
renewable energy penetration via honey badger algorithm. <em>NCA</em>,
<em>36</em>(14), 7923–7952. (<a
href="https://doi.org/10.1007/s00521-024-09485-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust reliability Generation Expansion Planning (GEP) turns out to be a crucial step for an efficient energy management system in a modern power grid, especially under renewable energy employment. The integration of all such components in a GEP model makes it a large-scale, nonlinear, and mixed-variable mathematical modeling problem. In this paper, the presence of wind energy uncertainty is analyzed. Both long and short-term uncertainties are incorporated into the proposed GEP model. The first step concerns the impact of long-term wind uncertainties through the annual variations of the capacity credit of two real sites in Egypt at Zafaranh and Shark El-ouinate. The second step deals with the short-term uncertainties of each wind site. The wind speed uncertainty of each wind site is modeled by probability distribution function. Then, wind power is estimated from the wind power curve for each wind site and Monte-Carlo Simulation is performed. Fast Gas Turbine and/or Pump Hydro Storage are incorporated to cope with short-term uncertainties. Sensitivity analysis is implemented for 3, 6, and 12 stages as short and long planning horizons to minimize the total costs with wind energy penetration and emission reduction over planning horizons. Also, a novel Honey Badger Algorithm (HBA) with model modifications such as Virtual Mapping Procedure, Penalty Factor Approach, and the Modified of Intelligent Initial Population Generation is utilized for solving the proposed GEP problem. The obtained results are compared with other algorithms to ensure the superior performance of the proposed HBA. According to the results of the applicable test systems, the proposed HBA performs better than the others, with percentage reductions over CSA, AO, BES, and PSO ranging up to 4.2, 2.72, 2.7, and 3.4%, respectively.},
  archive      = {J_NCA},
  author       = {Abou El-Ela, Adel A. and El-Sehiemy, Ragab A. and Shaheen, Abdullah M. and Shalaby, Ayman S. and Mouwafi, Mohamed T.},
  doi          = {10.1007/s00521-024-09485-5},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7923-7952},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust generation expansion planning in power grids under renewable energy penetration via honey badger algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Emotion recognition based on phase-locking value brain
functional network and topological data analysis. <em>NCA</em>,
<em>36</em>(14), 7903–7922. (<a
href="https://doi.org/10.1007/s00521-024-09479-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional threshold-based methods in brain functional network analysis have some drawbacks. First, the process of determining thresholds is often based on trial and error, lacking standardization, and exhibiting strong subjectivity. Second, this subjectivity may lead to the loss of emotion-related information, limiting a comprehensive understanding and accurate identification of underlying neural processes. To overcome these problems, the persistent homology (PH) theory based on topological data analysis was introduced in this study, and a PH-based framework for emotion recognition in functional brain networks was proposed. Firstly, the EEG signals were divided into five frequency bands ( $$\delta$$ , $$\theta$$ , $$\alpha$$ , $$\beta$$ , and $$\gamma$$ ) and segmented into multiple time series using non-overlapping sliding windows. Secondly, considering the coupling relationship between brain regions in different emotional states, the degree of phase synchronization between channels was calculated using the phase-locking value (PLV), and the PLV-based brain functional network was constructed. The PLV brain functional network was then analyzed with PH to extract multiple persistent topological features and combine them into richer feature vectors. These persistent topological features include persistence landscapes, Betti curves, persistent entropy, amplitudes, and non-diagonal points. Finally, these persistent feature vectors are used as inputs to a classifier and used for emotion recognition using machine learning algorithms and majority voting methods. Experimental analyses were conducted on the DEAP dataset to evaluate the proposed model. Further validation of the model was implemented on the DREAMER dataset and SEED dataset. The results show that the model achieves good results in EEG emotion recognition. The average accuracy reached 89.94, 87.61, and 83.24%, respectively. In this study, we extracted potential features of EEG data by applying PH to the exploration of functional brain networks, which avoided the reliance on manually determined thresholds and enabled a more comprehensive and accurate method of emotion recognition. Compared with traditional functional brain network methods, our method retains more original information related to functional brain networks in a stable and threshold-free manner.},
  archive      = {J_NCA},
  author       = {Wang, Zhong-min and Li, Sha and Zhang, Jie and Liang, Chen},
  doi          = {10.1007/s00521-024-09479-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7903-7922},
  shortjournal = {Neural Comput. Appl.},
  title        = {Emotion recognition based on phase-locking value brain functional network and topological data analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prostate cancer grading framework based on deep transfer
learning and aquila optimizer. <em>NCA</em>, <em>36</em>(14), 7877–7902.
(<a href="https://doi.org/10.1007/s00521-024-09499-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate cancer is the one of the most dominant cancer among males. It represents one of the leading cancer death causes worldwide. Due to the current evolution of artificial intelligence in medical imaging, deep learning has been successfully applied in diseases diagnosis. However, most of the recent studies in prostate cancer classification suffers from either low accuracy or lack of data. Therefore, the present work introduces a hybrid framework for early and accurate classification and segmentation of prostate cancer using deep learning. The proposed framework consists of two stages, namely classification stage and segmentation stage. In the classification stage, 8 pretrained convolutional neural networks were fine-tuned using Aquila optimizer and used to classify patients of prostate cancer from normal ones. If the patient is diagnosed with prostate cancer, segmenting the cancerous spot from the overall image using U-Net can help in accurate diagnosis, and here comes the importance of the segmentation stage. The proposed framework is trained on 3 different datasets in order to generalize the framework. The best reported classification accuracies of the proposed framework are 88.91% using MobileNet for the “ISUP Grade-wise Prostate Cancer” dataset and 100% using MobileNet and ResNet152 for the “Transverse Plane Prostate Dataset” dataset with precisions 89.22% and 100%, respectively. U-Net model gives an average segmentation accuracy and AUC of 98.46% and 0.9778, respectively, using the “PANDA: Resized Train Data (512 × 512)” dataset. The results give an indicator of the acceptable performance of the proposed framework.},
  archive      = {J_NCA},
  author       = {Balaha, Hossam Magdy and Shaban, Ahmed Osama and El-Gendy, Eman M. and Saafan, Mahmoud M.},
  doi          = {10.1007/s00521-024-09499-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7877-7902},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prostate cancer grading framework based on deep transfer learning and aquila optimizer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint contrastive learning for prompt-based few-shot
language learners. <em>NCA</em>, <em>36</em>(14), 7861–7875. (<a
href="https://doi.org/10.1007/s00521-024-09502-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of prompt learning and contrastive learning has recently been a promising approach to few-shot learning in NLP field. However, most of these studies only focus on the semantic-level relevance and intra-class information of data in the class level while ignoring the importance of fine-grained instance-level feature representations. This paper proposes a joint contrastive learning (JCL) framework that leverages instance-level contrastive learning to learn fine-grained differences of feature representations and class-level contrastive learning to learn richer intra-class information. The experimental results demonstrate that the proposed JCL method is effective and has strong generalization ability. Our code is available at https://github.com/2251821381/JCL .},
  archive      = {J_NCA},
  author       = {Zhu, Zhengzhong and Zhang, Xuejie and Wang, Jin and Zhou, Xiaobing},
  doi          = {10.1007/s00521-024-09502-7},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7861-7875},
  shortjournal = {Neural Comput. Appl.},
  title        = {Joint contrastive learning for prompt-based few-shot language learners},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sliding mode synchronization of uncertain memristor cellular
neural network and application in secure communication. <em>NCA</em>,
<em>36</em>(14), 7845–7859. (<a
href="https://doi.org/10.1007/s00521-024-09500-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this research is to investigate the synchronization and control for uncertain memristor-based cellular neural network and its application in secure communication. To address the issue, a novel sliding mode function is designed, on which the system states can effectively converge to the equilibrium point after reaching the sliding mode surface. Moreover, the corresponding controller is constructed by employing the proposed sliding mode function. The proposed control strategy achieves the synchronization of the uncertain memristor-based cellular neural network, and effectively addresses the integral saturation existing in traditional one. In addition, the control performance, including convergence speed, control accuracy, robustness and security, are significantly enhanced. Furthermore, the stability of the system is discussed based on Lyapunov theory. Finally, comparative tests and application examples are presented to verify the effectiveness of the proposed scheme.},
  archive      = {J_NCA},
  author       = {Zheng, Wei and Qu, Shaocheng and Tang, Qian},
  doi          = {10.1007/s00521-024-09500-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7845-7859},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sliding mode synchronization of uncertain memristor cellular neural network and application in secure communication},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep non-blind deblurring network for saturated blurry
images. <em>NCA</em>, <em>36</em>(14), 7829–7843. (<a
href="https://doi.org/10.1007/s00521-024-09495-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-blind image deblurring has attracted a lot of attention in the field of low-level vision. However, the existing non-blind deblurring methods cannot effectively deal with a saturated blurry image. The key point is that the degradation model of saturated blurry images does not satisfy the linear convolution model of a conventional blurry image. To solve the problem, in this paper, we proposed a novel deep non-blind deblurring method, dubbed saturated image non-blind deblurring network(SDBNet). The SDBNet contains two trainable sub-network, i.e., confident estimate network (CEN) and detail enhance network (DEN). Specifically, the SDBNet uses CEN to estimate the confidence map for the saturated blurry image, which is used to recognize saturated pixels in the blurry image, and then uses the confidence map, and blur kernel to restore the blurry image. Finally, we use DEN to enhance the edges and textures of the restored image. We first pre-train CEN and DEN. In order to effectively pre-train CEN, we propose a new robust function, which is used to generate label data for CEN. The experimental results show that compared with several existing non-blind deblurring methods, SDBNet can effectively restore saturated blurry images and better restore the texture, edge, and other structural information of blurry images.},
  archive      = {J_NCA},
  author       = {Fu, Bo and Fu, Shilin and Wu, Yuechu and Mao, Yuanxin and Ren, Yonggong and Thanh, Dang N. H.},
  doi          = {10.1007/s00521-024-09495-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7829-7843},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep non-blind deblurring network for saturated blurry images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cascade 2D attentional decoders with context-enhanced
encoder for scene text recognition. <em>NCA</em>, <em>36</em>(14),
7817–7827. (<a
href="https://doi.org/10.1007/s00521-024-09493-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sequence decoding framework has dominated the field of scene text recognition. In this framework, the RNN-based (recurrent neural network) decoder is one of the main approaches. The attention mechanism is a key module in the RNN-based decoder. In the decoding stage, the character is decoded based on an estimated attention map. The precision of the attention map is extremely important to the accuracy of the final output. In practice, we find the estimated attention map has encountered attention misalignment phenomena. To address this issue, in this paper, we innovatively propose Cascade 2D attentional decoders with context-enhanced encoder for scene text recognition; we name it CASTER. We employ a thin plate spline transformation to rectify original images with oriented or curved texts and a 31-layer ResNet as backbone to extract visual features. Then, we leverage a two-stage decode mechanism: localization and decoding (coarse decoder) and re-localization and re-decoding (refined decoder) to predict the character sequence. We also introduce a novel context-enhanced encoder by a 2D contextual fusion module to capture the context information. The CASTER can localize the attention region of each character more accurately than the one-stage attention method and thus improve the final recognition performance. Extensive experiments show that CASTER achieves state-of-the-art performance on several standard benchmarks. Our method obtains, respectively, 96.1%, 93.3% and 94.4% recognition accuracies on regular (IIIT5K, SVT) and irregular (CUTE) text datasets.},
  archive      = {J_NCA},
  author       = {Chi, Hongmei and Cai, Jiaxin and Li, Xinran},
  doi          = {10.1007/s00521-024-09493-5},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7817-7827},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cascade 2D attentional decoders with context-enhanced encoder for scene text recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GeoTrans: A transfer learning approach for estimating
petrophysical properties from geophysical sensors data. <em>NCA</em>,
<em>36</em>(14), 7799–7816. (<a
href="https://doi.org/10.1007/s00521-024-09489-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Petrophysical properties estimation is vital in reservoir characterisation domain to identify the prospect locations of presence of petroleum. Geophysical sensing with seismic survey and well logging provide such information of subsurface without completely digging over the reservoir. Machine learning models are popular in this domain to estimate the petrophysical properties from seismic signals and well logging. However, the performance is affected when the available labelled data are limited to model a reservoir. Transfer learning has a significant contribution in handling the limited labelled data issue in many application domains. But its applicability is almost unexplored in this domain as it is necessary to first identify the relevant model to transfer. In this paper, we propose a novel transfer learning approach for the estimation of petrophysical properties in a real-world reservoir dataset having inadequate labelled data samples. The proposed solution transfers the contextual knowledge of reservoir facies classes to the predictive model of petrophysical properties. Both the tasks share the common domain information and provided the improved generalisation performance considering the out-of-fold prediction in blind wells. Moreover, the analysis of results depicts better convergence and accuracy compared to its considered baselines.},
  archive      = {J_NCA},
  author       = {Saikia, Pallabi and Baruah, Rashmi Dutta},
  doi          = {10.1007/s00521-024-09489-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7799-7816},
  shortjournal = {Neural Comput. Appl.},
  title        = {GeoTrans: A transfer learning approach for estimating petrophysical properties from geophysical sensors data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-dimensional feature attention aggregation network for
cloud and snow recognition of high satellite images. <em>NCA</em>,
<em>36</em>(14), 7779–7798. (<a
href="https://doi.org/10.1007/s00521-024-09477-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud and snow in remote sensing images typically block the underlying surface information and interfere with the extraction of available information, so detecting cloud and snow becomes a critical problem in remotely sensed image processing. The current methods for detecting clouds and snow are susceptible to interference from complex background, making it difficult to recover cloud edge details and causing missing and false detection phenomena. To address these issues, a cross-dimensional feature attention aggregation network is suggested to realize the segmentation of clouds and snow. To address the problem of interference induced by the similar spectral characteristics of clouds and snow, the context attention aggregation module is added to conflate feature maps of various dimensions and screen the information. Multi-scale strip convolution module (MSSCM) and its improved version MSSCMs are used to extract edge characteristics at different scales and improve the harsh segmentation border. Also, adding deep feature semantic information extraction module to deep features to guide the classification of the model to avoid the interference of complex background. Finally, a ’los beatles’ module is used to replace the traditional linear combination in the decoding stage, and the feature information of different granularity is fused and extracted to enhance the model’s detection efficiency. In this paper, experiments are carried out on the public datasets: CSWV, HRC $$\_$$ WHU and L8 $$\_$$ SPARCS. The MIOU scores on the three datasets are 89.507 $$\%$$ , 91.674 $$\%$$ and 80.722 $$\%$$ , respectively. Comparative experiment findings demonstrate that the network presented in this article can attain the highest detection accuracy and good detection efficiency with low parameters.},
  archive      = {J_NCA},
  author       = {Hu, Kai and Zhang, Enwei and Xia, Min and Wang, Huiqin and Ye, Xiaoling and Lin, Haifeng},
  doi          = {10.1007/s00521-024-09477-5},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7779-7798},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-dimensional feature attention aggregation network for cloud and snow recognition of high satellite images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic bias alignment and discrimination enhancement for
unsupervised domain adaptation. <em>NCA</em>, <em>36</em>(14),
7763–7777. (<a
href="https://doi.org/10.1007/s00521-024-09507-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to explore the knowledge of labeled source domain to help training the model of unlabeled target domain. By now, while most existing UDA approaches typically learn domain-invariant representations by directly matching the distributions across the domains, they pay less attention on respecting the cross-domain similarity and discrimination exploration. To address these issues, this article designs a kind of UDA with dynamic bias alignment and discrimination enhancement (UDA-DBADE). Specifically, in UDA-DBADE we define a dynamic balance factor by the ratio of the normalized cross-domain discrepancy to the discrimination, which decreases gradually in the process of UDA-DBADE. Afterward, we construct domain alignment with adversarial learning as well as distinguishable representations through advancing the discrepancy of multiple classifiers, and dynamically balance them with the defined dynamic factor. In this way, a larger weight is originally assigned on the domain alignment and then gradually on the discrimination enhancement in the learning process of UDA-DBADE. In addition, we further construct a bias matrix to characterize the discrimination alignment between the source and target domain samples. Compared to current state-of-the-art methods, UDA-DBADE achieves an average accuracy of 88.8% and 89.8% on Office-31 dataset and ImageCLEF-DA dataset, respectively. Finally, extensive experiments demonstrate that UDA-DBADE has an excellent performance.},
  archive      = {J_NCA},
  author       = {Tian, Qing and Yang, Hong and Cheng, Yao},
  doi          = {10.1007/s00521-024-09507-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7763-7777},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic bias alignment and discrimination enhancement for unsupervised domain adaptation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust deep image-watermarking method by a modified siamese
network. <em>NCA</em>, <em>36</em>(14), 7743–7762. (<a
href="https://doi.org/10.1007/s00521-024-09496-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The risk of copyrighted data theft has increased with the growth of digital communication and easy access to digital data. Using watermarking methods has always been an active research subject against unauthorized users to protect copyrighted data. Deep watermarking methods were introduced in recent years to face this challenge, however, the robustness of these methods against graphic attacks and generating high-quality marked-images are still one of the important challenges in this issue. Also, exposure of these methods to the risk of intellectual property infringement is another important challenge in this subject. To address the quality degradation challenge of marked-images, we propose a blind deep image-watermarking method inspired by the Siamese network in which the watermark-codes will be embedded in the network’s weights instead of cover-images. Also, a cover-atmosphere is defined for each cover-image which includes the cover-image and its various attacked versions. Favorable robustness is achieved by mapping each cover-atmosphere to its corresponding watermark-code space. Moreover, an independent subspace for non-watermark-images is considered to map into a null-code which makes the method robust against intellectual property infringement attack. The results obtained from the experiment show that the suggested approach outperforms existing methods and can withstand different types of graphical and surrogate model attacks.},
  archive      = {J_NCA},
  author       = {Bartani, Ako and Akhlaghian Tab, Fardin and Abdollahpouri, Alireza and Ramezani, Mohsen},
  doi          = {10.1007/s00521-024-09496-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7743-7762},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust deep image-watermarking method by a modified siamese network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting fake information with knowledge-enhanced
AutoPrompt. <em>NCA</em>, <em>36</em>(14), 7725–7742. (<a
href="https://doi.org/10.1007/s00521-024-09491-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of fake news on the Internet poses a challenge to accessing authentic information. Fake news detection plays a crucial role in filtering out false information and improving information accuracy. However, practical implementation faces challenges like high annotation costs, limited samples, poor training results, and weak model generalization. To tackle these issues, we propose knowledge-enhanced AutoPrompt (KEAP) for fake news detection. This method leverages prompt templates generated by the T5 model to transform the fake news detection task into a prompt learning-based task. We also incorporate external entity knowledge to enhance detection capabilities. Carefully designed prompts activate the model’s latent knowledge, improving performance in low-resource scenarios and model generalization. Experiments on GossipCop and PolitiFact datasets demonstrate the superiority of prompt learning over existing methods without extra text during testing. KEAP achieves an average F1 score improvement of 2.79 $$\%$$ compared to state-of-the-art methods in few-shot settings.},
  archive      = {J_NCA},
  author       = {Che, Xun and Yang, Gang and Chen, Yadang and Li, Qianmu},
  doi          = {10.1007/s00521-024-09491-7},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7725-7742},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detecting fake information with knowledge-enhanced AutoPrompt},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New optimized chaotic encryption with BCOVIDOA for efficient
security of medical images in IoMT systems. <em>NCA</em>,
<em>36</em>(14), 7705–7723. (<a
href="https://doi.org/10.1007/s00521-024-09508-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Medical Things systems involve medical data transmissions between patients, medical experts, and medical centers over public networks. The sensitivity of the medical images&#39; contents and the personal information in the medical images required high levels of security. Chaotic maps are successfully used in image encryption due to their high security and computational efficiency. Initial random sequences generate the keys for chaotic map confusion and diffusion processes. Selection of the initial parameters is the cornerstone of the success of chaotic maps in securing digital images. In this paper, the authors proposed utilizing the novel binary Coronavirus disease optimization algorithm to determine the optimal initial sequences for the chaotic maps that lead to the generation of the optimal secret keys. The proposed algorithm selects the optimal initial keys using a hybrid fitness function. The generated optimal secret keys are then used for medical image encryption/decryption. Several medical images from different modalities are utilized for testing, and the results are compared to the latest encryption techniques according to various criteria. The experimental results ensure the robustness of the proposed algorithm to various attacks and its superior performance to similar algorithms.},
  archive      = {J_NCA},
  author       = {Alsahafi, Yousef S. and Khalid, Asmaa M. and Hamza, Hanaa M. and Hosny, Khalid M.},
  doi          = {10.1007/s00521-024-09508-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7705-7723},
  shortjournal = {Neural Comput. Appl.},
  title        = {New optimized chaotic encryption with BCOVIDOA for efficient security of medical images in IoMT systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep-GAN: An improved model for thyroid nodule
identification and classification. <em>NCA</em>, <em>36</em>(14),
7685–7704. (<a
href="https://doi.org/10.1007/s00521-024-09492-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tailoring a deep convolutional neural network (DCNN) is a tedious and time-consuming task in the field of medical image analysis. In this research paper, Deep-generative adversial neural network (Deep-GAN) based model is proposed using grid search optimization (GSO) technique for identification and classification of thyroid nodule. The main objective of this work is to propose a deep learning (DL) model for the identification and classification of thyroid nodules without user or specialist intervention. The proposed model has gone through four phases namely (i) data acquisition, (ii) pre-processing (iii) data augmentation using GAN technique and (iv) optimization and classification using Deep-GAN model. Two pre-trained architectures namely Alex-Net and Visual Geometry Group (VGG-16) are considered for the identification and classification of thyroid nodule in ultrasonography (USG) images. From the experiment, it is found that Alex-GAN model has shown an improvement of 2 to 4 percentage points in comparison with VGG-GAN model and reported literature on Thyroid digital image database (TDID) public and collected dataset.},
  archive      = {J_NCA},
  author       = {Srivastava, Rajshree and Kumar, Pardeep},
  doi          = {10.1007/s00521-024-09492-6},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7685-7704},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep-GAN: An improved model for thyroid nodule identification and classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new hybrid approach for grapevine leaves recognition based
on ESRGAN data augmentation and GASVM feature selection. <em>NCA</em>,
<em>36</em>(14), 7669–7683. (<a
href="https://doi.org/10.1007/s00521-024-09488-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grapevine leaf is a commodity that is collected only once a year and has a high return on investment due to its export. However, only certain types of grapevine leaves are consumed. Therefore, it is extremely important to distinguish the types of grapevine leaves. In particular, performing this process automatically on industrial machines will reduce human errors, workload, and thus cost. In this study, a new hybrid approach based on a convolutional neural network is proposed that can automatically distinguish the types of grapevine leaves. In the proposed approach, firstly, the overfitting of network models is prevented by applying data augmentation techniques. Second, new synthetic images were created with the ESRGAN technique to obtain detailed texture information. Third, the top blocks of the MobileNetV2 and VGG19 CNN models were replaced with the newly designed top block, effectively extracting features with the data. Fourthly, the GASVM algorithm was adapted and used to create a subset of the features to eliminate the ineffective and unimportant ones from the obtained features. Finally, SVM classification was performed with the feature subset consisting of 314 features, and approximately 2% higher accuracy and MCC score were obtained compared to the approaches in the literature.},
  archive      = {J_NCA},
  author       = {Doğan, Gürkan and Imak, Andaç and Ergen, Burhan and Sengur, Abdulkadir},
  doi          = {10.1007/s00521-024-09488-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7669-7683},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new hybrid approach for grapevine leaves recognition based on ESRGAN data augmentation and GASVM feature selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance evaluation of cluster-based federated machine
learning. <em>NCA</em>, <em>36</em>(14), 7657–7668. (<a
href="https://doi.org/10.1007/s00521-024-09487-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a collaborative training method for machine learning (ML) that aggregates model weights from multiple participants during the training phase. The learning phase of machine learning techniques is distributed, in which each participating device trains a model using its local data set and sends model weights to a centralized node. The central node aggregates weights and sends the updated weights back to devices. The process continues until a specific threshold is reached such accuracy, response time. In this paper, we present a performance evaluation of FL in a clustering-based multi-hop network to simulate the effect of the dynamic environment on the accuracy of the global model. It is observed that a minimum number of participating nodes is required within a cluster to maintain a high level of global accuracy. A global threshold value needs to be defined to maintain high global accuracy and avoid degradation of model performance.},
  archive      = {J_NCA},
  author       = {Sattar, Karim Asif and Baroudi, Uthman},
  doi          = {10.1007/s00521-024-09487-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7657-7668},
  shortjournal = {Neural Comput. Appl.},
  title        = {Performance evaluation of cluster-based federated machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Siamada: Visual tracking based on siamese adaptive learning
network. <em>NCA</em>, <em>36</em>(14), 7639–7656. (<a
href="https://doi.org/10.1007/s00521-024-09481-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Siamese trackers based on region proposal networks (RPN) have gained a lot of popularity. However, the design of RPN requires manual tuning of parameters such as object-anchor intersection over union (IoU) and relative weights for different tasks, which is a difficult and expensive process for model training. To address this issue, we propose a novel Siamese adaptive learning network (SiamAda) for visual tracking, allowing the model trained in a flexible way. Rather than IoU-based anchor assignment, the proposed network uses spatial alignment and model learning status as criteria for anchor quality evaluation, and a Gaussian mixture distribution for adaptive assignment. Moreover, aiming at the inconsistency problem between classification confidence and localization accuracy, a localization branch is designed to predict the IoU for each candidate anchor box, responsible for localization quality assessment. Furthermore, to avoid the tricky relative weight tuning between each task’s loss, multi-task learning with homoscedastic uncertainty is employed to adaptively weigh these multiple losses. Extensive experiments on challenging benchmarks, namely OTB2015, VOT2018, DTB70, UAV20L, GOT-10k and LaSOT validate the superiority of our tracker. The ablation studies also illustrate the advantage of each strategy presented in this paper.},
  archive      = {J_NCA},
  author       = {Lu, Xin and Li, Fusheng and Yang, Wanqi},
  doi          = {10.1007/s00521-024-09481-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7639-7656},
  shortjournal = {Neural Comput. Appl.},
  title        = {Siamada: Visual tracking based on siamese adaptive learning network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Masked self-supervised ECG representation learning via
multiview information bottleneck. <em>NCA</em>, <em>36</em>(14),
7625–7637. (<a
href="https://doi.org/10.1007/s00521-024-09486-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, self-supervised learning-based models have been widely used for electrocardiogram (ECG) representation learning. However, most of the models utilize contrastive learning that strongly depend on data augmentation. In this paper, we propose a masked self-supervised learning model based on multiview information bottleneck principle. Our method masks the ECG signal instances in the time and frequency domains at a high ratio and then uses the autoencoder to reconstruct the original input. Not only the intra-view relations within each view but also the inter-view relations between two views are exploited in ECG representation learning. Furthermore, we use the multiview information bottleneck principle to remove redundant information in the time and frequency domains, so that the representations of both views contain more task-relevant information. Our model is pre-trained on three larger ECG datasets at once and fine-tuned on each classification task. Experimental results show that our model not only outperforms state-of-the-art models with self-supervised learning, but also outperforms models with supervised learning.},
  archive      = {J_NCA},
  author       = {Yang, Shunxiang and Lian, Cheng and Zeng, Zhigang and Xu, Bingrong and Su, Yixin and Xue, Chenyang},
  doi          = {10.1007/s00521-024-09486-4},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7625-7637},
  shortjournal = {Neural Comput. Appl.},
  title        = {Masked self-supervised ECG representation learning via multiview information bottleneck},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time sign language recognition based on YOLO algorithm.
<em>NCA</em>, <em>36</em>(14), 7609–7624. (<a
href="https://doi.org/10.1007/s00521-024-09503-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on real-time hand gesture recognition in the Turkish sign language detection system. YOLOv4-CSP based on convolutional neural network (CNN), a state-of-the-art object detection algorithm, is used to provide real-time and high-performance detection. The YOLOv4-CSP algorithm is created by adding CSPNet to the neck of the original YOLOv4 to improve network performance. A new object detection model has been proposed by optimizing the YOLOv4-CSP algorithm in order to provide more efficient detection in Turkish sign language. The model uses CSPNet throughout the network to increase the learning ability of the network. However, Proposed YOLOv4-CSP has a learning model with Mish activation function, complete intersection of union (CIoU) loss function and transformer block added. The Proposed YOLOv4-CSP algorithm has faster learning with transfer learning than previous versions. This allows the proposed YOLOv4-CSP algorithm to perform a faster restriction and recognition of static hand signals simultaneously. To evaluate the speed and detection performance of the proposed YOLOv4-CSP model, it is compared with previous YOLO series, which offers real-time detection, as well. YOLOv3, YOLOv3-SPP, YOLOv4-CSP and proposed YOLOv4-CSP models are trained with a labeled dataset consisting of numbers in Turkish Sign language, and their performances on the hand signals recognitions are compared. With the proposed method, 98.95% precision, 98.15% recall, 98.55 F1 score and 99.49% mAP results are obtained in 9.8 ms. The proposed method for detecting numbers in Turkish sign language outperforms other algorithms with both real-time performance and accurate hand sign prediction, regardless of background.},
  archive      = {J_NCA},
  author       = {Alaftekin, Melek and Pacal, Ishak and Cicek, Kenan},
  doi          = {10.1007/s00521-024-09503-6},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {14},
  pages        = {7609-7624},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time sign language recognition based on YOLO algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parametric RSigELU: A new trainable activation function for
deep learning. <em>NCA</em>, <em>36</em>(13), 7595–7607. (<a
href="https://doi.org/10.1007/s00521-024-09538-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activation functions are used to extract meaningful relationships from real-world problems with the help of deep learning models. Thus, the development of activation functions which affect deep learning models’ performances is of great interest to researchers. In the literature, mostly, nonlinear activation functions are preferred since linear activation functions limit the learning performances of the deep learning models. Non-linear activation functions can be classified as fixed-parameter and trainable activation functions based on whether the activation function parameter is fixed (i.e., user-given) or modified during the training process of deep learning models. The parameters of the fixed-parameter activation functions should be specified before the deep learning model training process. However, it takes too much time to determine appropriate function parameter values and can cause the slow convergence of the deep learning model. In contrast, trainable activation functions whose parameters are updated in each iteration of deep learning models training process achieve faster and better convergence by obtaining the most suitable parameter values for the datasets and deep learning architectures. This study proposes parametric RSigELU (P+RSigELU) trainable activation functions, such as P+RSigELU Single (P+RSigELUS) and P+RSigELU Double (P+RSigELUD), to improve the performance of fixed-parameter activation function of RSigELU. The performances of the proposed trainable activation functions were evaluated on the benchmark datasets of MNIST, CIFAR-10, and CIFAR-100 datasets. Results show that the proposed activation functions outperforms PReLU, PELU, ALISA, P+FELU, PSigmoid, and GELU activation functions found in the literature. To access the codes of the activation function; https://github.com/serhatklc/P-RsigELU-Activation-Function .},
  archive      = {J_NCA},
  author       = {Kiliçarslan, Serhat and Celik, Mete},
  doi          = {10.1007/s00521-024-09538-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7595-7607},
  shortjournal = {Neural Comput. Appl.},
  title        = {Parametric RSigELU: A new trainable activation function for deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective optimization and sustainable design: A
performance comparison of metaheuristic algorithms used for on-grid and
off-grid hybrid energy systems. <em>NCA</em>, <em>36</em>(13),
7559–7594. (<a
href="https://doi.org/10.1007/s00521-024-09585-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alternative energy sources are needed for a sustainable world due to rapidly increasing energy consumption, fossil fuels, and greenhouse gases worldwide. A hybrid renewable energy system (HRES) must be optimally dimensioned to be responsive to sudden load changes and cost-effective. In this study, the aim is to reduce the carbon emissions of a university campus by generating electricity from a hybrid energy production system with solar panels, wind turbine, a diesel generator, and battery components. On the university campus where the hybrid energy system will be installed, the ambient temperature, solar radiation, wind speed, and load demands have been recorded in our database. Optimization algorithms were used to select the power values of the system components to be installed using these data in an efficient and inexpensive manner according to the ambient conditions. For optimal sizing of HRES components, gray wolf optimizer combined with cuckoo search (GWOCS) technique was investigated using MATLAB/Simulink. In this way, it has been tried to increase their efficiency by combining current optimization techniques. The cornerstone of our optimization efforts for both on-grid and off-grid models pivots on a constellation of critical decision variables: the power harvested from wind turbines, the productivity of solar panels, the capacity of battery storage, and the power contribution of diesel generators. In our pursuit of minimizing the annual cost metric, we employ a tailor-made function, meticulously upholding an array of constraints, such as the quotient of renewable energy and the potential risk of power disruption. A robust energy management system is integral to our design, orchestrating the delicate power flow balance among micro-grid components—vital for satisfying energy demand. Upon analyzing the outcomes of the study, it is apparent that the proposed Scenario 1 HRES effectively utilizes solar and battery components within the off-grid model, surpassing the efficiency of four other hybrid scenarios under consideration. Regarding optimization processes, the off-grid model exhibits superior results with the implementation of the GWOCS algorithm, delivering faster and more reliable solutions relative to other methodologies. Conversely, the optimization of the on-grid model reaches its optimal performance with the application of the cuckoo search algorithm. A comprehensive comparison from both technical and economic view points suggests the on-grid model as the most feasible and suitable choice. Upon completion of the optimization process, the load demand is catered to by a combination of a 2963.827-kW solar panel, a 201.8896-kW battery, and an additional purchase of 821.9 MWh from the grid. Additionally, an energy surplus sale of 1379.8 MWh to the grid culminates in an annual cost of system (ACS) of 475782.8240 USD, a total net present cost of 4815520.2794 USD, and a levelized cost of energy of 0.12754 USD/kWh. Solar panels cover the entire system, and the renewable energy fraction is 100%.},
  archive      = {J_NCA},
  author       = {Güven, Aykut Fatih and Yörükeren, Nuran and Mengi, Onur Özdal},
  doi          = {10.1007/s00521-024-09585-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7559-7594},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective optimization and sustainable design: A performance comparison of metaheuristic algorithms used for on-grid and off-grid hybrid energy systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing of brain tumor diagnosis with developed local
binary patterns methods. <em>NCA</em>, <em>36</em>(13), 7545–7558. (<a
href="https://doi.org/10.1007/s00521-024-09476-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain tumor is one of the most lethal diseases that can affect human health and cause death. Invasive biopsy techniques are one of the most common methods of identifying brain tumor disease. As a result of this procedure, bleeding may occur during the procedure, which could harm some brain functions. Consequently, this invasive biopsy process may be extremely dangerous. To overcome such a dangerous process, medical imaging techniques, which can be used by experts in the field, can be used to conduct a thorough examination and obtain detailed information about the type and stage of the disease. Within the scope of the study, the dataset was examined, and this dataset consisted of brain images with tumors and brain images of normal patients. Numerous studies on medical images were conducted and obtained with high accuracy within the hybrid model algorithms. The dataset&#39;s images were enhanced using three distinct local binary patterns (LBP) algorithms in the developed model within the scope of the study: the LBP, step-LBP (nLBP), and angle-LBP (αLBP) algorithms. In the second stage, classification algorithms were used to evaluate the results from the LBP, nLBP and αLBP algorithms. Among the 11 classification algorithms used, four different classification algorithms were chosen as a consequence of the experimental process since they produced the best results. The classification algorithms with the best outcomes are random forest (RF), optimized forest (OF), rotation forest (RF), and instance-based learner (IBk) algorithms, respectively. With the developed model, an extremely high success rate of 99.12% was achieved within the IBk algorithm. Consequently, the clinical service can use the developed method to diagnose tumor-based medical images.},
  archive      = {J_NCA},
  author       = {Gül, Mehmet and Kaya, Yılmaz},
  doi          = {10.1007/s00521-024-09476-6},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7545-7558},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparing of brain tumor diagnosis with developed local binary patterns methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Yaru3DFPN: A lightweight modified 3D UNet with feature
pyramid network and combine thresholding for brain tumor segmentation.
<em>NCA</em>, <em>36</em>(13), 7529–7544. (<a
href="https://doi.org/10.1007/s00521-024-09475-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gliomas are the most common and aggressive form of all brain tumors, with a median survival rate of fewer than two years, especially for the highest-grade glioma patient. Accurate and reproducible brain tumor segmentation is essential for an effective treatment plan and diagnosis to reduce the risk of further spread. Automated brain tumor segmentation is challenging because it can appear in the brain with variations in shape, size, and position from one patient to another. Several deep learning architectures have been created to handle automatic segmentation with good performance results on 3D MRI images. However, these architectures are generally large and require high hardware specifications and a large amount of memory and storage. This paper proposes a lightweight modified 3D UNet architecture with an outstanding performance level called Yaru3DFPN. The architecture is built based on the UNet. The block used is ResNet and is modified to use pre-activation strategies and GroupNormalization for batch normalization. In the expanding section, features are arranged into pyramid features. The final output is thresholded using the combining thresholding method. This architecture is light and fast. This proposal was tested using BraTS datasets with the highest dice performance of 80.90%, 86.27%, and 92.02% for ET, TC, and WT areas, respectively. This result outperformed all other comparative architectures and promised to be developed for clinical application.},
  archive      = {J_NCA},
  author       = {Akbar, Agus Subhan and Fatichah, Chastine and Suciati, Nanik and Za’in, Choiru},
  doi          = {10.1007/s00521-024-09475-7},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7529-7544},
  shortjournal = {Neural Comput. Appl.},
  title        = {Yaru3DFPN: A lightweight modified 3D UNet with feature pyramid network and combine thresholding for brain tumor segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretability of deep learning models in analysis of
spanish financial text. <em>NCA</em>, <em>36</em>(13), 7509–7527. (<a
href="https://doi.org/10.1007/s00521-024-09474-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence methods based on deep learning (DL) have recently made significant progress in many different areas including free text classification and sentiment analysis. We believe that corporate governance is one of these areas, where DL can generate very valuable and differential knowledge, for example, by analyzing the biographies of independent directors, which allows for qualitative modeling of their profile in an automatic way. For this technology to be accepted it is important to be able to explain how it generates its results. In this work we have developed a six-dimensional labeled dataset of independent director biographies, implemented three recurrent DL models based on LSTM and transformers along with four ensembles, one of which is an innovative proposal based on a multi-layer perceptron (MLP), trained them using Spanish language and economics and finance terminology and performed a comprehensive test study that demonstrates the accuracy of the results. We have also performed a complete study of explainability using the SHAP methodology by comparatively analyzing the developed models. We have achieved a mean error (MAE) of 8% in the modeling of the open text biographies, which has allowed us to perform a case study of time analysis that has detected significant variations in the composition of the Standard Expertise Profile (SEP) of the boards of directors, related to the crisis of the period 2008–2013. This work shows that DL technology can be accurately applied to free text analysis in the finance and economic domain, by automatically analyzing large volumes of data to generate knowledge that would have been unattainable by other means.},
  archive      = {J_NCA},
  author       = {Vaca, César and Astorgano, Manuel and López-Rivero, Alfonso J. and Tejerina, Fernando and Sahelices, Benjamín},
  doi          = {10.1007/s00521-024-09474-8},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7509-7527},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interpretability of deep learning models in analysis of spanish financial text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An end-to-end machine learning approach with explanation for
time series with varying lengths. <em>NCA</em>, <em>36</em>(13),
7491–7508. (<a
href="https://doi.org/10.1007/s00521-024-09473-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate prediction of complex product quality parameters from process time series by an end-to-end learning approach remains a significant challenge in machine learning. A special difficulty is the application of industrial batch process data because many batch processes generate variable length time series. In the industrial application of such methods, explainability is often desired. In this study, a 1D convolutional neural network (CNN) algorithm with a masking layer is proposed to solve the problem for time series of variable length. In addition, a novel combination of 1D CNN and class activation mapping (CAM) technique is part of this study to better understand the model results and highlight some regions of interest in the time series. As a comparative state-of-the-art unsupervised machine learning method, the One-Nearest Neighbours (1NN) algorithm combined with dynamic time warping (DTW) was used. Both methods are investigated as end-to-end learning methods with balanced and unbalanced class distributions and with scaled and unscaled input data, respectively. The FastDTW and DTAIDistance algorithms were investigated for the DTW calculation. The data set is made up of sensor signals that was collected during the production of plastic parts. The objective was to predict a quality parameter of plastic parts during production. For this research, the quality parameter will be a difficult or only destructively measurable parameter and both methods will be investigated for their applicability to this prediction task. The application of the proposed approach to an industrial facility for producing plastic products shows a prediction accuracy of 83.7%. It can improve the reverence method by approximately 1.4%. In addition to the slight increase in accuracy, the CNN training time was significantly reduced compared to the DTW calculation.},
  archive      = {J_NCA},
  author       = {Schneider, Manuel and Greifzu, Norbert and Wang, Lei and Walther, Christian and Wenzel, Andreas and Li, Pu},
  doi          = {10.1007/s00521-024-09473-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7491-7508},
  shortjournal = {Neural Comput. Appl.},
  title        = {An end-to-end machine learning approach with explanation for time series with varying lengths},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid particle swarm optimization algorithm for text
feature selection problems. <em>NCA</em>, <em>36</em>(13), 7471–7489.
(<a href="https://doi.org/10.1007/s00521-024-09472-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is a crucial preprocessing step that aims to eliminate irrelevant and redundant features, reduce the dimensionality of the feature space, and enhance clustering efficiency and effectiveness. FS is categorized as NP-Hard due to the high number of existing solutions. Various metaheuristic methods have been developed to address the FS problem, yielding promising results. Particularly, particle swarm optimization (PSO), an evolutionary computing (EC) approach guided by swarm intelligence, has gained widespread adoption owing to its implementation simplicity and potential for global search. This paper analyzes several variants of PSO algorithms and introduces a new FS method called HPSO. The proposed approach utilizes an asynchronously adaptive inertia weight and an improved constriction factor. Additionally, it incorporates a chaotic map and a MAD fitness function with a feature count penalty to tackle the clustering FS problem. The efficiency of the developed method is evaluated against the genetic algorithm (GA) and well-known variants of PSO algorithms, including PSOs with fixed inertia weights, PSOs with improved inertia weights, PSOs with fixed constriction factors, PSOs with improved constriction factors, PSOs with adaptive inertia weights, and PSO’s includes advanced learning exemplars and sophisticated structure topologies. This paper assesses two different reference text data sets, Reuters-21578 and Webkb. In comparison with competitive methods, the proposed HPSO method achieves higher clustering precision and selects a more informative feature set.},
  archive      = {J_NCA},
  author       = {Nachaoui, Mourad and Lakouam, Issam and Hafidi, Imad},
  doi          = {10.1007/s00521-024-09472-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7471-7489},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybrid particle swarm optimization algorithm for text feature selection problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight siamese transformer for few-shot semantic
segmentation. <em>NCA</em>, <em>36</em>(13), 7455–7469. (<a
href="https://doi.org/10.1007/s00521-024-09471-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation (FSS) is a challenging task that aims to segment new classes in query images with a few annotated support samples. One inherent challenge in FSS is the intra-class variation resulting from the limited availability of support samples and the diversity of query data. Current methods frequently employ prototype-support techniques to tackle this issue. However, it is important to note that a single support prototype shares limited commonalities with query features, and increases the difficulty of accurate segmentation. In this paper, we propose a lightweight and effective framework named Siamese Transformer (SiaT) with a mere 0.68M learnable parameters to enhance commonalities between prototypes and query features. The SiaT framework consists of two key modules: the Siamese Transformer Module (STM) and the Query Activation Module (QAM). The STM integrates two shared Transformer decoders for information propagation to generate two enhanced prototypes. One Transformer decoder facilitates the propagation of target-related information from the query to the original support prototype, while the other propagates foreground information from the support to the initial query prototype. The QAM utilizes the two enhanced prototypes from the STM as support information, engaging with query features through channel-wise allocation and concatenation, termed query activation. Moreover, SiaT showcases competitive performance on the widely used benchmarks PASCAL- $$5^i$$ and COCO- $$20^i$$ , which demonstrates its effectiveness in addressing the intra-class variation challenge within FSS tasks.},
  archive      = {J_NCA},
  author       = {Zhu, Hegui and Zhou, Yange and Jiang, Cong and Yang, Lianping and Jiang, Wuming and Wang, Zhimu},
  doi          = {10.1007/s00521-024-09471-x},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7455-7469},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight siamese transformer for few-shot semantic segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective speed control of brushless DC motor using cascade
1PDf-PI controller tuned by snake optimizer. <em>NCA</em>,
<em>36</em>(13), 7439–7454. (<a
href="https://doi.org/10.1007/s00521-024-09470-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a cascade one proportional derivative incorporating filter (1PDf)-proportional integral (PI) controller abbreviated as c-1PDf-PI to deal effectively with the speed control issue of brushless DC (BLDC) motors. Two problems exist with implementing this controller such as iterated integral overflow and derivation-based chattering owing to the noise. The former is resolved by using an equivalent expression for the integral operation, while the latter is addressed by putting a first-order filter on the derivative term. To achieve the best performance from the controller, snake optimizer (SO) is fruitfully employed for optimizing the controller parameters without need for expert knowledge/interpretation. Here, a more reasonable cost function to assess the candidate solutions is also described. Simulations and laboratory experiments using DSP of TI TMS320F28335 are performed and the results are presented which show that the reference tracking performance, torque disturbance capability and robustness of the c-1PDf-PI controller have potential. These results are also contrasted by those offered by PI and 1PDf speed control schemes individually, affirming the superior performance of our proposal. As per the results, discussion and observation of this research, we stress that good performance and simplicity are salient advantages of the c-1PDf-PI controller, rendering it a good alternative over the complicated controller designs.},
  archive      = {J_NCA},
  author       = {Çelik, Emre and Karayel, Mehmet},
  doi          = {10.1007/s00521-024-09470-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7439-7454},
  shortjournal = {Neural Comput. Appl.},
  title        = {Effective speed control of brushless DC motor using cascade 1PDf-PI controller tuned by snake optimizer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep neural networks watermark via universal deep hiding and
metric learning. <em>NCA</em>, <em>36</em>(13), 7421–7438. (<a
href="https://doi.org/10.1007/s00521-024-09469-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rising costs of model training, it is urgent to safeguard the intellectual property of deep neural networks. To achieve this, researchers have proposed various model watermarking techniques. Existing methods utilize visible trigger patterns, which are vulnerable to being detected by humans or detectors. Moreover, these approaches fail to establish active protection mechanisms that link the model with the user’s identity. In this study, we present an innovative imperceptible model watermarking approach that utilizes deep hiding to encode the user’s copyright verification information. This process superimposes a trigger pattern onto clean images, resulting in watermark trigger images. These watermark trigger images closely mimic the original images, achieving excellent stealthiness while enabling the retrieval of the user’s copyright verification information, thus definitively asserting ownership rights. Slight alterations made to the images to maintain stealthiness can weaken the triggering of the watermark pattern. We first leverage the triple loss in metric learning to tackle this challenge of training watermark samples. Using watermark trigger images as anchor samples and selecting appropriate positive and negative samples, we enhance the model’s capability to discern the watermark trigger. Experimental results on CIFAR-10, GTSRB, and Tiny-ImageNet confirm the defender’s capability to embed watermark successfully. The average watermark accuracy exceeds 90%, while the average performance loss is less than 0.05% points. It is also robust to existing watermark removal attacks and backdoor detection methods.},
  archive      = {J_NCA},
  author       = {Ye, Zhicheng and Zhang, Xinpeng and Feng, Guorui},
  doi          = {10.1007/s00521-024-09469-5},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7421-7438},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep neural networks watermark via universal deep hiding and metric learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated classification of alzheimer’s disease based on
deep belief neural networks. <em>NCA</em>, <em>36</em>(13), 7405–7419.
(<a href="https://doi.org/10.1007/s00521-024-09468-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When it comes to the causes of dementia, Alzheimer&#39;s disease is the most mysterious. There is no central genetic component connected to Alzheimer&#39;s disease. Previous approaches and tools for determining Alzheimer&#39;s disease genetic risk factors are unreliable. The brain images provided the bulk of the available information. In contrast, large-scale approaches in bioinformatics have seen significant development in recent years. It has encouraged efforts to identify the hereditary risk factors for developing Alzheimer&#39;s disease. A large amount of data on the brain&#39;s prefrontal cortex as a consequence of recent studies has allowed for the creation of classification and prediction models for Alzheimer&#39;s disease. Using the OASIS-4 dataset, which suffers from High Dimension Low Sample Size (HDLSS) problems, a Deep belief network with a Restricted Boltzmann Machine (RBM)-based classification model for processing multimodal data has been constructed. The multi-layer feature selection procedure that took into account both the technical and biological aspects of the characteristics to solve the HDLSS problem has been proposed. In molecular-level information, in the first stage of the two-tiered feature selection method, abnormal places in the dataset are found. Second, combining multiple different feature selection methods is used to refine the set of candidate genes. The principal component analysis is used for dimensionality reduction in MRI, and well pre-processed cognitive assessment scores like MMSE and ADA-cog are considered. Deep belief networks with multiple RBM are used to do unsupervised feature learning. Fivefold cross-validation has been used in all classification studies.},
  archive      = {J_NCA},
  author       = {Nanthini, K. and Tamilarasi, A. and Sivabalaselvamani, D. and Suresh, P.},
  doi          = {10.1007/s00521-024-09468-6},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7405-7419},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automated classification of alzheimer&#39;s disease based on deep belief neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time synchronization of complex-valued neural
networks with reaction-diffusion terms: An adaptive intermittent control
approach. <em>NCA</em>, <em>36</em>(13), 7389–7404. (<a
href="https://doi.org/10.1007/s00521-024-09467-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel approach to achieve finite-time synchronization (FTS) in a certain class of fractional-order complex-valued neural networks (CVNNs) containing reaction-diffusion terms. The proposed method uses intermittent control and provides a theoretical analysis to establish criteria for achieving FTS. This is achieved through new Lyapunov functions based on the proposed system, deriving inequalities in the complex domain. To realize FTS, the study designs complex-valued intermittent controllers for the targeted CVNNs relying solely on the information obtained from the controlled nodes. Moreover, an adaptive controller is introduced to effectively regulate the control gain, and the FTS of CVNNs is analyzed. The effectiveness of the proposed control strategies and derived results is demonstrated by numerical examples.},
  archive      = {J_NCA},
  author       = {Shanmugam, Saravanan and Narayanan, G. and Rajagopal, Karthikeyan and Ali, M. Syed},
  doi          = {10.1007/s00521-024-09467-7},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7389-7404},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time synchronization of complex-valued neural networks with reaction-diffusion terms: An adaptive intermittent control approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep ensemble learning approach for lower limb movement
recognition from multichannel sEMG signals. <em>NCA</em>,
<em>36</em>(13), 7373–7388. (<a
href="https://doi.org/10.1007/s00521-024-09465-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Walking is a complex task that requires consistent practice to master, and it involves the synchronisation between the lower limbs and the brain, making it challenging. While bipedal robots have been developed to mimic human walking, they must achieve an efficient gait due to structural differences and walking challenges. This study aims to produce a more human-like walk by analysing human lower extremity activities. To capture the bipedal robot locomotion learning process, an ensemble classifier based on deep learning is introduced to recognise human lower activities. A publicly available UC Irvine Machine Learning Repository (UCI) dataset on surface electromyography (sEMG) signal for the lower extremity of 11 fit participants and 11 participants with knee disorders for sitting while performing knee extension, walking, and standing while performing knee flexion is used. A hybrid ensemble of deep learning models comprising long short-term memory and convolution neural network is employed to classify activities, with reported average accuracies of 98.8%, 98.3%, and 99.3% for healthy subjects for sitting, standing and walking, respectively. Moreover, the ensemble model reported average accuracies of 98.2%, 98.1%, and 99.0% for individuals with knee pathology. Notably, this study holds promising significance, as it has yielded a considerable enhancement in performance as opposed to state-of-the-art work. The applications of this work are diverse and include improving postural stability in elderly subjects, aiding in the rehabilitation of patients recovering from stroke and trauma, generating walking trajectories for robots in complex environments, and reconstructing walking patterns in individuals with impairments.},
  archive      = {J_NCA},
  author       = {Tokas, Pratibha and Semwal, Vijay Bhaskar and Jain, Sweta},
  doi          = {10.1007/s00521-024-09465-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7373-7388},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep ensemble learning approach for lower limb movement recognition from multichannel sEMG signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EVAD: Encrypted vibrational anomaly detection with
homomorphic encryption. <em>NCA</em>, <em>36</em>(13), 7359–7372. (<a
href="https://doi.org/10.1007/s00521-024-09464-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main concerns of cloud-based services based on machine and deep learning algorithms is the privacy of users’ data. This is particularly relevant when companies want to leverage such services because they have to outsource potentially sensible data to be processed. In this work, the problem of privacy-preserving anomaly detection on industrial vibrational data with machine learning is tackled. It consists in the detection of irregularities or deviations from expected patterns in the vibration signals generated by industrial machinery and equipment. Such anomalies can be indicative of potential equipment failures, maintenance needs, or process deviations, making their timely detection critical for ensuring the smooth operation and reliability of industrial systems. We combine this industrial need with the ability to guarantee data privacy by proposing encrypted vibrational anomaly detection (EVAD). EVAD allows the detection of anomalies on vibrational data in a privacy-preserving manner by integrating, for the first time in the literature, one-class support vector machines and homomorphic encryption, the latter being a particular kind of encryption that allows the computation of some operations directly on encrypted data. Experimental results show that, on two publicly available datasets for vibrational anomaly detection, EVAD is able to distinguish, in a privacy-preserving manner, between nominal and anomaly situations, in an effective and efficient way. To the best of our knowledge, EVAD represents the first privacy-preserving solution for the detection of anomalies in vibrational data present in the literature.},
  archive      = {J_NCA},
  author       = {Falcetta, Alessandro and Roveri, Manuel},
  doi          = {10.1007/s00521-024-09464-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7359-7372},
  shortjournal = {Neural Comput. Appl.},
  title        = {EVAD: Encrypted vibrational anomaly detection with homomorphic encryption},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Alternative prioritization for mitigating urban
transportation challenges using a fermatean fuzzy-based intelligent
decision support model. <em>NCA</em>, <em>36</em>(13), 7343–7357. (<a
href="https://doi.org/10.1007/s00521-024-09463-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practitioners and decision-makers often face difficulties in selecting and prioritizing effective strategies to address challenges to sustainable urban transportation development. Although there has been considerable research conducted on the subject, the Tanzanian context, which is greatly affected by social and environmental problems, has received inadequate attention. Therefore, this study intends to bridge this gap by pinpointing the obstacles to sustainable urban transportation and proposing the most appropriate strategies to tackle them. The study proposes seven strategies and determines five criteria to prioritize them. To accomplish this, the study proposes a novel Fermatean fuzzy-based intelligent decision support model to assess the criteria weights and prioritizes strategies based on the weighted criteria. The study validates the proposed methodology by conducting a sensitivity analysis, which indicates that restricting car use (A5), improving sector coordination (A1), and conducting extensive research on transportation issues (A7) are the top three strategies for promoting sustainable urban transportation. The study’s findings hold significant value in providing urban transportation planners with helpful guidance to develop optimization techniques that can improve transportation systems.},
  archive      = {J_NCA},
  author       = {Bouraima, Mouhamed Bayane and Ayyildiz, Ertugrul and Ozcelik, Gokhan and Tengecha, Nyamatari Anselem and Stević, Željko},
  doi          = {10.1007/s00521-024-09463-x},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7343-7357},
  shortjournal = {Neural Comput. Appl.},
  title        = {Alternative prioritization for mitigating urban transportation challenges using a fermatean fuzzy-based intelligent decision support model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quasi-projective synchronization of discrete-time BAM neural
networks by discrete inequality techniques. <em>NCA</em>,
<em>36</em>(13), 7327–7341. (<a
href="https://doi.org/10.1007/s00521-024-09462-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we primarily concentrate on the quasi-projective synchronization of master–slave discrete-time BAM neural networks. Without using the LMI and matrix measure methods, by applying discrete inequalities and the Lyapunov sequences, constructing a discrete inequality group, then solving the inequality group, two novel criteria to guarantee the quasi-projective synchronization are obtained for the considered networks. The controllers designed, the approach, and the results in the paper are fully novel, which advance the development of the study of synchronization of discrete neural networks.},
  archive      = {J_NCA},
  author       = {Yang, Zhen and Zhang, Zhengqiu and Liao, Huaying},
  doi          = {10.1007/s00521-024-09462-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7327-7341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quasi-projective synchronization of discrete-time BAM neural networks by discrete inequality techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved social mimic optimization algorithm and its
application in bearing fault diagnosis. <em>NCA</em>, <em>36</em>(13),
7295–7326. (<a
href="https://doi.org/10.1007/s00521-024-09461-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key component of rotating machinery, it is of great significance for the timely diagnosis of bearing weak faults. Stochastic resonance is widely used for its special signal enhancement pattern, and the combination of system parameters determines its actual output effect. Because the social mimic optimization algorithm has the advantages of few parameters, fast convergence speed and strong exploitation capability, it is used to optimize the parameters of stochastic resonance system in this paper. Aiming at the problem that it is easy to fall into local optimum during optimization, inspired by the learning habits of elite, an elite social mimic optimization (ESMO) algorithm is proposed. Its improvement mainly includes five parts: integration of learning efficiency, exchange learning, looking for successors, innovation and breakthrough, elimination mechanism. And its superiority is verified by the comparison of 29 standard benchmark functions and 10 other well-known optimization algorithms. Aiming at the discontinuity of optimization space, the concept of survival rate (surr) is proposed, and the effectiveness of the ESMO algorithm in optimizing discontinuous variables is analyzed and verified. Aiming at the disadvantage that stochastic resonance can only process small frequency signals, a bearing weak fault diagnosis method based on frequency exchange and parameter compensation stochastic resonance is proposed. To verify its application ability in other fault diagnosis methods, a classification and recognition method based on BP neural network is proposed. Finally, the effectiveness and superiority of the ESMO algorithm are verified by simulation signals and bearing experimental data. The above analysis results prove that the ESMO algorithm has certain scientific and engineering application value in the optimization field and engineering application.},
  archive      = {J_NCA},
  author       = {Yu, Manhua and Jiang, Hong and Zhou, Jianxing and Zhang, Xiangfeng and Li, Jun},
  doi          = {10.1007/s00521-024-09461-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7295-7326},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved social mimic optimization algorithm and its application in bearing fault diagnosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Complex network robustness prediction using
attention-augmented CNN. <em>NCA</em>, <em>36</em>(13), 7279–7294. (<a
href="https://doi.org/10.1007/s00521-024-09460-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the strength of complex networks is crucial for evaluating their functionality and monitoring system security. Two primary perspectives for measuring network robustness are connectivity and controllability, which quantify how well a network maintains connectivity and controllability after experiencing complete attacks. However, conventional robustness calculation methods that use simulation attacks can be impractical for large-scale networks. Recent research has explored the use of deep learning methods for network robustness prediction, including PCR (short for predictor of controllability robustness), which uses a VGG (short for visual geometry group)-based convolutional neural network (CNN) and a linear filter. However, PCR has limitations, including inaccurate edge importance differentiation and fluctuating output curves. This paper presents ATTRP, an attention-based robustness predictor, which addresses these limitations. ATTRP uses a novel convolutional neural network with channel and spatial attention mechanisms to improve prediction accuracy and a robustness filter based on Savitzky–Golay smoothing to rectify the robustness curve. Experimental studies demonstrate that ATTRP outperforms other predictors, with much lower errors, while its computational speed is far superior to that of traditional attacking simulation. Overall, our research provides a more effective and efficient means of predicting network robustness, with potential applications in monitoring system security.},
  archive      = {J_NCA},
  author       = {Huang, Jie and Wu, Ruizi and Li, Junli},
  doi          = {10.1007/s00521-024-09460-0},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7279-7294},
  shortjournal = {Neural Comput. Appl.},
  title        = {Complex network robustness prediction using attention-augmented CNN},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CovLIS-MUnet segmentation model for covid-19 lung infection
regions in CT images. <em>NCA</em>, <em>36</em>(13), 7265–7278. (<a
href="https://doi.org/10.1007/s00521-024-09459-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most serious health concerns facing the world is coronavirus disease (COVID-19). COVID-19 is a virus that is highly infectious and contagious. The RT-PCR test is not the only way to diagnose COVID-19; many other alternatives are available like Lung Computed Tomography (CT) imaging. Large variances in texture, size, and location of infections make manual segmentation of lung CT images time-consuming and difficult. We present an effective segmentation model Covid-19 Lung Infection Segmentation based on a multi-special block Unet (CovLIS-MUnet) to improve the segmentation process. The primary goal of our study is to segment the lung and infection parts of CT scan images. We integrate a multi-special block (MSB) with a Convolutional block in the encoder and bridge phases, which helps to study contextual information and COVID-19 infection-related characteristics, thereby resulting in accurate segmentation results and improved prediction accuracy. The proposed method has been evaluated on a COVID-19 CT segmentation dataset. The findings of the qualitative experiments suggest that the CovLIS-MUnet model can accurately segment lung and COVID 19 affected areas, with accuracy 0.9964 and 0.998. The proposed CovLIS-MUnet consistently achieves much better segmentation performance across four widely used evaluation parameters, according to experimental data. The proposed model is good as compared to other existing models. Medical professionals will benefit greatly from the usage of CovLIS-MUnet segmentation architecture because, in addition to aiding in the diagnosis of COVID-19, it allows them to determine how serious the illness is through infection projections.},
  archive      = {J_NCA},
  author       = {Devi, Manju and Singh, Sukhdip and Tiwari, Shailendra},
  doi          = {10.1007/s00521-024-09459-7},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7265-7278},
  shortjournal = {Neural Comput. Appl.},
  title        = {CovLIS-MUnet segmentation model for covid-19 lung infection regions in CT images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive exploration of deep learning approaches for
pulmonary nodule classification and segmentation in chest CT images.
<em>NCA</em>, <em>36</em>(13), 7245–7264. (<a
href="https://doi.org/10.1007/s00521-024-09457-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately determining whether nodules on CT images of the lung are benign or malignant plays an important role in the early diagnosis and treatment of tumors. In this study, the classification and segmentation of benign and malignant nodules on CT images of the lung were performed using deep learning models. A new approach, C+EffxNet, is used for classification. With this approach, the features are extracted from CT images and then classified with different classifiers. In other phases of the study, a segmentation between benign and malignant was performed and, for the first time, a comparison of nodes was made during segmentation. The deep learning models InceptionV3, DenseNet121, and SeResNet101 were used as backbone models for feature extraction in the segmentation phase. In the classification phase, an accuracy of 0.9798, a precision of 0.9802, a recognition of 0.9798, an F1 score of 0.9798, and a kappa value of 0.9690 were achieved. During segmentation, the highest values of 0.8026 Jacard index and 0.8877 Dice coefficient were achieved.},
  archive      = {J_NCA},
  author       = {Canayaz, Murat and Şehribanoğlu, Sanem and Özgökçe, Mesut and Akıncı, M. Bilal},
  doi          = {10.1007/s00521-024-09457-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7245-7264},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive exploration of deep learning approaches for pulmonary nodule classification and segmentation in chest CT images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EvoFolio: A portfolio optimization method based on
multi-objective evolutionary algorithms. <em>NCA</em>, <em>36</em>(13),
7221–7243. (<a
href="https://doi.org/10.1007/s00521-024-09456-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal portfolio selection—composing a set of stocks/assets that provide high yields/returns with a reasonable risk—has attracted investors and researchers for a long time. As a consequence, a variety of methods and techniques have been developed, spanning from purely mathematics ones to computational intelligence ones. In this paper, we introduce a method for optimal portfolio selection based on multi-objective evolutionary algorithms, specifically Nondominated Sorting Genetic Algorithm-II (NSGA-II), which tries to maximize the yield and minimize the risk, simultaneously. The system, named EvoFolio, has been experimented on stock datasets in a three-years time-frame and varying the configurations/specifics of NSGA-II operators. EvoFolio is an interactive genetic algorithm, i.e., users can provide their own insights and suggestions to the algorithm such that it takes into account users’ preferences for some stocks. We have performed tests with optimizations occurring quarterly and monthly. The results show how EvoFolio can significantly reduce the risk of portfolios consisting only of stocks and obtain very high performance (in terms of return). Furthermore, considering the investor’s preferences has proved to be very effective in the portfolio’s composition and made it more attractive for end-users. We argue that EvoFolio can be effectively used by investors as a support tool for portfolio formation.},
  archive      = {J_NCA},
  author       = {Guarino, Alfonso and Santoro, Domenico and Grilli, Luca and Zaccagnino, Rocco and Balbi, Mario},
  doi          = {10.1007/s00521-024-09456-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7221-7243},
  shortjournal = {Neural Comput. Appl.},
  title        = {EvoFolio: A portfolio optimization method based on multi-objective evolutionary algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From mimic to counteract: A two-stage reinforcement learning
algorithm for google research football. <em>NCA</em>, <em>36</em>(13),
7203–7219. (<a
href="https://doi.org/10.1007/s00521-024-09455-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning has proven to be effective in various video games, such as Atari games, StarCraft II, Google research football (GRF), and Dota II. We participated in the 2022 IEEE Conference on Games Football AI Competition and ranked in the top eight. Despite recent efforts, building agents for GRF still suffers from multi-agent coordination, sparse rewards, and stochastic environments. To address these issues and achieve good outcomes in the competition, we devised a reinforcement learning algorithm that uses deep reinforcement learning from demonstrations and policy distillation. In this study, we innovatively propose a two-stage algorithm named mimic-to-counteract reinforcement learning (MCRL) based on the historical game logs of opponents, we encountered during the warm-up session and formulated partner agents function similarly to human sparring partners, whereby they simulate opponents with diverse styles of play, enabling primary players to practice against a range of policies, they may encounter in real competitions. Additionally, we trained numerous mentor agents capable of restraining the sparring partners. We distilled their policies and amalgamated them to train a potent primary agent. Empirical results show that the proposed MCRL algorithm can efficiently search for valuable strategies with stable updates and balance the relationship between policy iteration and policy style deviation. Also, the primary agent can learn diverse but coordinated counteracting strategies and ranks in the top eight in the competition.},
  archive      = {J_NCA},
  author       = {Zhao, Junjie and Lin, Jiangwen and Zhang, Xinyan and Li, Yuanbai and Zhou, Xianzhong and Sun, Yuxiang},
  doi          = {10.1007/s00521-024-09455-x},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7203-7219},
  shortjournal = {Neural Comput. Appl.},
  title        = {From mimic to counteract: A two-stage reinforcement learning algorithm for google research football},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simple but effective span-level tagging method for
discontinuous named entity recognition. <em>NCA</em>, <em>36</em>(13),
7187–7201. (<a
href="https://doi.org/10.1007/s00521-024-09454-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discontinuous named entity recognition (NER) is a more challenging task compared to continuous NER. It aims to extract discontinuous entities composed of multiple no-adjacent spans, which requires representing and combining all the spans of each discontinuous entity. However, discontinuous NER may suffer from decoding ambiguity due to the large space of span combinations and the lack of association information between spans. To address this problem, we propose a simple yet effective span-level tagging scheme for discontinuous NER. The tagging scheme defines simple span-level tags to represent and associate all the spans of each discontinuous entity simultaneously, effectively solving the decoding ambiguity problem. Moreover, the proposed model employs a co-predictor consisting of a span-level graph-based predictor and a position-aware biaffine predictor to predict span-level tags. The span-level graph-based predictor enhances span representations by employing graph convolutional network on span-level graphs to capture the dependence between spans of each discontinuous entity. The position-aware biaffine predictor incorporates relative position information into biaffine to enrich the structural information of span representations. To verify the effectiveness of our method, we conduct experiments on three benchmark datasets (i.e., CADEC, ShARe 13 and ShARe 14). The results show our method significantly outperforms previous state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Mao, Tingyun and Xu, Yaobin and Liu, Weitang and Peng, Jingchao and Chen, Lili and Zhou, Mingwei},
  doi          = {10.1007/s00521-024-09454-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7187-7201},
  shortjournal = {Neural Comput. Appl.},
  title        = {A simple but effective span-level tagging method for discontinuous named entity recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust classification approach to enhance clinic
identification from arabic health text. <em>NCA</em>, <em>36</em>(13),
7161–7185. (<a
href="https://doi.org/10.1007/s00521-024-09453-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification has critical applications, including healthcare, where it can assist patients in locating specialized clinics based on their symptom descriptions. This can enhance healthcare services by reducing misdiagnoses and efficiently guiding patients to appropriate specialists. This research focuses on building a model for multi-class text classification in Arabic healthcare. Two evaluation schemes were employed using health data from the Altibbi dataset. Various feature extraction techniques were employed, including term frequency-inverse document frequency (TF-IDF) and word-to-vector (Word2Vec). Classical machine learning models such as Logistic Regression (LR), Random Forest (RF), Multinomial Naïve Bayes (MNB), Stochastic Gradient Descent, and Support Vector Machine (SVM), along with ensemble classifications, were implemented. Evaluation measures were used to compare model performance, including precision, recall, and F1-score. Results indicated that TF-IDF generally outperformed Word2Vec regarding the F1-score across most classes. LR and RF consistently demonstrated strong performance, while MNB exhibited lower precision. Ensemble methods like stacking and bagging showed promise, with LR and RF performing well across multiple classes. The SVM model displayed lower precision in certain classes. Preliminary experiments with the transformer-based models for Arabic language AraBERT and MarBERT as feature extraction and classification models demonstrated impressive precision, recall, and F1 scores across various classes. The findings show the effectiveness of ensemble models using TF-IDF and Arabic transformer models in accurately classifying Arabic health texts. However, challenges related to standardization, semantic variations, data availability, and resources should be considered.},
  archive      = {J_NCA},
  author       = {Al-Fuqaha’a, Shrouq and Al-Madi, Nailah and Hammo, Bassam},
  doi          = {10.1007/s00521-024-09453-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7161-7185},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust classification approach to enhance clinic identification from arabic health text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal formation control for second-order nonlinear MASs
with collision avoidance and connectivity assurance. <em>NCA</em>,
<em>36</em>(13), 7143–7160. (<a
href="https://doi.org/10.1007/s00521-024-09451-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the optimal formation control issue with collision avoidance and connectivity assurance is investigated for a class of second-order uncertain nonlinear multi-agent systems. First, the neural networks are employed in order to deal with the unknown nonlinear dynamics of the system. Then, an optimal formation control scheme is developed in the framework of the identifier–actor–critic. By constructing a new performance metric function containing collision avoidance and connectivity constraints, it is demonstrated that asymptotic convergence of the tracking error can be achieved under the proposed control scheme. Finally, the effectiveness of the proposed control method is validated by the numerical simulation example.},
  archive      = {J_NCA},
  author       = {Tian, Zixin and Li, Yongming},
  doi          = {10.1007/s00521-024-09451-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7143-7160},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimal formation control for second-order nonlinear MASs with collision avoidance and connectivity assurance},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AlexDarkNet: Hybrid CNN architecture for real-time traffic
monitoring with unprecedented reliability. <em>NCA</em>,
<em>36</em>(13), 7133–7141. (<a
href="https://doi.org/10.1007/s00521-024-09450-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the proliferation of vehicles on roadways, accompanied by an escalating demand for augmented safety and refined traffic management, has fueled substantial progress in the domains of computer vision and deep learning methodologies. This technological surge has precipitated ground-breaking applications, with real-time vehicle detection emerging as a linchpin. Capability to accurately detect vehicles in a real-time holds profound implications across diverse domains. In the context of autonomous driving, it underpins essential functions such as path planning, collision avoidance, and decision-making, essential for the safe operation of autonomous vehicles. In the arena of traffic monitoring, it empowers transportation authorities to acquire real-time insights into traffic dynamics, congestion patterns, and incident detection, thereby optimizing traffic flow and resource allocation strategies. Furthermore, within surveillance systems, real-time vehicle detection equips security personnel with the means to swiftly identify potential security threats, enhancing overall situational awareness and safety. This paper contributes to this dynamic landscape by introducing an innovative architecture expressly crafted for vehicle detection. Leveraging state-of-the-art computer vision techniques and deep learning methodologies, this architecture addresses the evolving challenges posed by contemporary traffic scenarios. Through the enhancement of real-time vehicle detection capabilities, our aim is to fortify the foundations of safety, efficiency, and security within vehicular contexts. The paper includes a fusion of AlexNet and Darknet accompanied by a comparative analysis. It is expected to deliver unmatched dependability and accuracy in real-time traffic monitoring, setting a new standard for performance in this application.},
  archive      = {J_NCA},
  author       = {Joshi, Rakhi Madhukarrao and Rao, D. S.},
  doi          = {10.1007/s00521-024-09450-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7133-7141},
  shortjournal = {Neural Comput. Appl.},
  title        = {AlexDarkNet: Hybrid CNN architecture for real-time traffic monitoring with unprecedented reliability},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BO–SHAP–BLS: A novel machine learning framework for accurate
forecasting of COVID-19 testing capabilities. <em>NCA</em>,
<em>36</em>(13), 7119–7131. (<a
href="https://doi.org/10.1007/s00521-024-09449-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid spread of COVID-19 has resulted in a large number of infections and significant economic impact on countries worldwide, and COVID-19 testing is one of the important methods to identify infected individuals. The previous studies have indicated that with improved COVID-19 testing capabilities, more confirmed cases can be detected. Therefore, how to accurately forecast the COVID-19 testing capabilities is a key issue in controlling the spread of the pandemic. In this study, based on a dataset of COVID-19 including data from 184 countries and 893 regions, we propose a novel machine learning framework named BO–SHAP–BLS, which combines Shapley Additive Explanations (SHAP), Bayesian Optimization (BO), and Broad Learning System (BLS), for forecasting COVID-19 testing capabilities. Firstly, SHAP is used to analyze and rank the importance of the original features. Then, BO is adopted to optimize both the hyperparameters of BLS and the number of features simultaneously. Finally, BLS is adopted to predict the number of COVID-19 tests in various countries. Experimental results show that BO–SHAP–BLS significantly outperforms the other machine learning models, indicating higher accuracy in predicting the COVID-19 testing capabilities.},
  archive      = {J_NCA},
  author       = {Zhan, Choujun and Miao, Lingfeng and Lin, Junyan and Tan, Minghao and Tsang, Kim Fung and Hao, Tianyong and Min, Hu and Zhao, Xuejiao},
  doi          = {10.1007/s00521-024-09449-9},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7119-7131},
  shortjournal = {Neural Comput. Appl.},
  title        = {BO–SHAP–BLS: A novel machine learning framework for accurate forecasting of COVID-19 testing capabilities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fuzzy computing approach to aggregate expert opinions
using parabolic and exparabolic approximation procedures for solving
multi-criteria group decision-making problems. <em>NCA</em>,
<em>36</em>(13), 7105–7117. (<a
href="https://doi.org/10.1007/s00521-024-09448-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triangular fuzzy numbers (TFNs) are widely used for selection problems to determine expert opinions using linguistic expressions. Some aggregation procedures are developed to determine expert opinions more accurately. However, there is a need for a simple and more useful procedure to solve the selection problems more suitably. For this purpose, our study offers a triangular, exparabolic, and parabolic area calculation-based approximation approach for TFNs to aggregate the possible hedges (very and more or less) for TFNs. Hence, this aggregation procedure provides a tuning opportunity for classical TFN expressions to capture possible tuning processes to reflect the hesitancies of experts. The technique for order preferences by similarity to ideal solution (TOPSIS) method is applied in the two studies from extant literature, and suitable alternatives are determined as a result of the ranking process. Finally, a comparative analysis is presented to illustrate the efficiency of the proposed procedure. The conventional TOPSIS model’s ranking scores are very close for exemplified examples (i.e., 0.5308, 0.4510, 0.4550 and 0.5304, 0.4626, 0.4940), but the proposed model’s result has fluctuated for the same examples (i.e., 0.346, 0,669, 0,567 and 0.208, 0.991, 0.148). So, the main advantage of the proposed aggregation procedure is the alternative ranking scores separation capability analyzed with their linguistic diversification.},
  archive      = {J_NCA},
  author       = {Ic, Yusuf Tansel},
  doi          = {10.1007/s00521-024-09448-w},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7105-7117},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fuzzy computing approach to aggregate expert opinions using parabolic and exparabolic approximation procedures for solving multi-criteria group decision-making problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online content-based sequential recommendation considering
multimodal contrastive representation and dynamic preferences.
<em>NCA</em>, <em>36</em>(13), 7085–7103. (<a
href="https://doi.org/10.1007/s00521-024-09447-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The online content, including live streaming and short videos, provides abundant visual and textual product information to users, which offers insights into users’ multiple and changeable preferences toward product style, brand, color, etc. These dynamic preferences are helpful to the product recommender system to extract users’ purchasing patterns. However, existing sequential recommendation fails to combine with items’ multimodal characteristics and dynamic preferences. This paper proposes the Online Content-Based Sequence Recommendation method (named OCBSR), where dynamic preferences and multimodal representation such as visual images, textual descriptions, and item-ID of products are leveraged with convolutional autoencoder to map multimodal data into a unified latent space. We devise a multimodal transformer mechanism to aggregate the multimodal representation. A novel contrastive infomax loss is constructed through contrastive prototype representations and noise-contrastive sequences. The loss enhances the correlation between single-modality and multimodality preferences and learns the contrastive representation. Then, users’ dynamic preferences are extracted from the contrastive representation in each time step using the gated recurrent unit with skip connections. Experiments are conducted on two real-life multimodal datasets, H&amp;M and KuaiRec. The hit ratio (HR) and normalized discounted cumulative gain (NDCG) results indicate that our approach noticeably outperforms the current advanced recommenders. The HR increases by above 20% and 25% on H&amp;M and KuaiRec datasets, respectively; the NDCG rises about 12% and 24% on H&amp;M and KuaiRec datasets, respectively. The ablation study verifies each module’s effectiveness. This research contributes to online content literature and multimodal sequential recommendation in practice.},
  archive      = {J_NCA},
  author       = {Lu, Yusheng and Duan, Yongrui},
  doi          = {10.1007/s00521-024-09447-x},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7085-7103},
  shortjournal = {Neural Comput. Appl.},
  title        = {Online content-based sequential recommendation considering multimodal contrastive representation and dynamic preferences},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced multi-level features for very high resolution
remote sensing scene classification. <em>NCA</em>, <em>36</em>(13),
7071–7083. (<a
href="https://doi.org/10.1007/s00521-024-09446-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Very high resolution (VHR) remote sensing (RS) scene classification is a challenging task due to the higher inter-class similarity and intra-class variability problems. Recently, the existing deep learning (DL)-based methods have shown great promise in VHR RS scene classification. However, they still provide an unstable classification performance. To address such a problem, we herein propose a DL-based novel approach using an enhanced VHR attention module (EAM), which captures the richer salient multi-scale information for a more accurate representation of the VHR RS image during classification. Experimental results on three widely used VHR RS data sets show that the proposed approach yields a competitive and stable/consistent classification performance with the least standard deviation of 0.001. Further, the highest overall accuracies on the AID, NWPU, and UCM data sets are 95.39%, 93.04%, and 98.61%, respectively. Such encouraging, consistent and improved results shown through detailed ablation and comparative study provide a solution to the remote sensing community for the land use and land cover (LULC) classification problems with more trust and confidence. The source code of this work is available at https://github.com/csitaula/EAM .},
  archive      = {J_NCA},
  author       = {Sitaula, Chiranjibi and KC, Sumesh and Aryal, Jagannath},
  doi          = {10.1007/s00521-024-09446-y},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7071-7083},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced multi-level features for very high resolution remote sensing scene classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GaitASMS: Gait recognition by adaptive structured spatial
representation and multi-scale temporal aggregation. <em>NCA</em>,
<em>36</em>(13), 7057–7069. (<a
href="https://doi.org/10.1007/s00521-024-09445-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is one of the most promising video-based biometric technologies. The edge of silhouettes and motion are the most informative feature and previous studies have explored them separately and achieved notable results. However, due to occlusions and variations in viewing angles, their gait recognition performance is often affected by the predefined spatial segmentation strategy. Moreover, traditional temporal pooling usually neglects distinctive temporal information in gait. To address the aforementioned issues, we propose a novel gait recognition framework, denoted as GaitASMS, which can effectively extract the adaptive structured spatial representations and naturally aggregate the multi-scale temporal information. The Adaptive Structured Representation Extraction Module (ASRE) separates the edge of silhouettes by using the adaptive edge mask and maximizes the representation in semantic latent space. Moreover, the Multi-Scale Temporal Aggregation Module (MSTA) achieves effective modeling of long-short-range temporal information by temporally aggregated structure. Furthermore, we propose a new data augmentation, denoted random mask, to enrich the sample space of long-term occlusion and enhance the generalization of the model. Extensive experiments conducted on two datasets demonstrate the competitive advantage of proposed method, especially in complex scenes, i.e., BG and CL. On the CASIA-B dataset, GaitASMS achieves the average accuracy of 93.5% and outperforms the baseline on rank-1 accuracies by 3.4% and 6.3%, respectively, in BG and CL. The ablation experiments demonstrate the effectiveness of ASRE and MSTA. The source code is available at https://github.com/YanSun-github/GaitASMS .},
  archive      = {J_NCA},
  author       = {Sun, Yan and Long, Hu and Feng, Xueling and Nixon, Mark},
  doi          = {10.1007/s00521-024-09445-z},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7057-7069},
  shortjournal = {Neural Comput. Appl.},
  title        = {GaitASMS: Gait recognition by adaptive structured spatial representation and multi-scale temporal aggregation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). ATFTrans: Attention-weighted token fusion transformer for
robust and efficient object tracking. <em>NCA</em>, <em>36</em>(13),
7043–7056. (<a
href="https://doi.org/10.1007/s00521-024-09444-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, fully transformer-based trackers have achieved impressive tracking results, but this also brings a great deal of computational complexity. Some researchers have applied token pruning techniques to fully transformer-based trackers to diminish the computational complexity, but this leads to missing contextual information that is important for the regression task in the tracker. In response to the above issue, this paper proposes a token fusion method that speeds up inference while avoiding information loss and thus improving the robustness of the tracker. Specifically, the input of the transformer’s encoder contains search tokens and exemplar tokens, and the search tokens are divided into tracking object tokens and background tokens according to the similarity between search tokens and exemplar tokens. The tokens with greater similarity to the exemplar tokens are identified as tracking object tokens, and those with smaller similarity to the exemplar tokens are identified as background tokens. The tracking object tokens contain the discriminative features of the tracking object, for the sake of making the tracker pay more attention to the tracking object tokens while reducing the computational effort. All the tracking object tokens are kept, and then, the background tokens are weighted and fused to form new background tokens according to the attention weight of the background tokens to prevent the loss of contextual information. The token fusion method presented in this paper not only provides efficient inference of the tracker but also makes the tracker more robust. Extensive experiments are carried out on popular tracking benchmark datasets to verify the validity of the token fusion method.},
  archive      = {J_NCA},
  author       = {Xu, Liang and Wang, Liejun and Guo, Zhiqing},
  doi          = {10.1007/s00521-024-09444-0},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7043-7056},
  shortjournal = {Neural Comput. Appl.},
  title        = {ATFTrans: Attention-weighted token fusion transformer for robust and efficient object tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCMSTStream: Applying minimum spanning tree to KD-tree-based
micro-clusters to define arbitrary-shaped clusters in streaming data.
<em>NCA</em>, <em>36</em>(13), 7025–7042. (<a
href="https://doi.org/10.1007/s00521-024-09443-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stream clustering has emerged as a vital area for processing streaming data in real-time, facilitating the extraction of meaningful information. While efficient approaches for defining and updating clusters based on similarity criteria have been proposed, outliers and noisy data within stream clustering areas pose a significant threat to the overall performance of clustering algorithms. Moreover, the limitation of existing methods in generating non-spherical clusters underscores the need for improved clustering quality. As a new methodology, we propose a new stream clustering approach, MCMSTStream, to overcome the abovementioned challenges. The algorithm applies MST to micro-clusters defined by using the KD-Tree data structure to define macro-clusters. MCMSTStream is robust against outliers and noisy data and has the ability to define clusters with arbitrary shapes. Furthermore, the proposed algorithm exhibits notable speed and can handling high-dimensional data. ARI and Purity indices are used to prove the clustering success of the MCMSTStream. The evaluation results reveal the superior performance of MCMSTStream compared to state-of-the-art stream clustering algorithms such as DenStream, DBSTREAM, and KD-AR Stream. The proposed method obtained a Purity value of 0.9780 and an ARI value of 0.7509, the highest scores for the KDD dataset. In the other 11 datasets, it obtained much higher results than its competitors. As a result, the proposed method is an effective stream clustering algorithm on datasets with outliers, high-dimensional, and arbitrary-shaped clusters. In addition, its runtime performance is also quite reasonable.},
  archive      = {J_NCA},
  author       = {Erdinç, Berfin and Kaya, Mahmut and Şenol, Ali},
  doi          = {10.1007/s00521-024-09443-1},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7025-7042},
  shortjournal = {Neural Comput. Appl.},
  title        = {MCMSTStream: Applying minimum spanning tree to KD-tree-based micro-clusters to define arbitrary-shaped clusters in streaming data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered self-learning-based tracking control for
nonlinear constrained-input systems with uncertain disturbances.
<em>NCA</em>, <em>36</em>(13), 7007–7023. (<a
href="https://doi.org/10.1007/s00521-024-09442-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an online event-triggered self-learning scheme based on adaptive dynamic programming (ADP) is developed to address tracking control design for nonlinear systems with constrained input and uncertain disturbance. Firstly, the value function with non-quadratic function is defined for the augmented nominal system, and the constrained robust tracking problem is equivalent to the optimal control for solving the tracking event-triggered Hamilton–Jacobi–Bellman (ETHJB) equation. Then, a single-critic network is developed to obtain the value function and control law related to the solution of the tracking ETHJB equation, greatly reducing approximation errors and computational costs. To alleviate the requirement for the entire state sampling, we propose a triggering rule that ensures system stability while limiting control updates. Theoretical proof demonstrates that the tracking state of the closed-loop system and the weight approximation error of the neural network are uniformly ultimately bounded (UUB). Finally, two examples are provided to validate the availability of the proposed scheme.},
  archive      = {J_NCA},
  author       = {Peng, Binbin and Cui, Xiaohong and Zhou, Kun},
  doi          = {10.1007/s00521-024-09442-2},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {7007-7023},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered self-learning-based tracking control for nonlinear constrained-input systems with uncertain disturbances},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gravitational wave isolation with autoencoder neural network
cascade. <em>NCA</em>, <em>36</em>(13), 6993–7006. (<a
href="https://doi.org/10.1007/s00521-024-09441-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detectors at the Laser Interferometer Gravitational Wave Observatory (LIGO), along with its sister detectors Virgo and Kamioka Gravitational Wave Detector (KAGRA), endlessly collect data to be analyzed in search of gravitational wave signals (GW signals) produced primarily by massive merger events involving colliding black holes and neutron stars. These detectors are the foundation upon which the new field of gravitational wave astronomy is built. However, the algorithms used to sift through this incoming data are extremely computationally expensive. They constantly run the risk of lagging behind the detectors, which would be catastrophic for astronomers searching for merger events, and their inherent rigidity becomes an obstruction to the expansion of these detectors’ range and sensitivity. To simplify and expedite the process of detecting and isolating GW signals, this paper presents a neural network (NN) cascade to automatically isolate GW signals in raw LIGO data. Perfecting such a NN system would improve the speed and efficiency of detecting and analyzing GW signals. This study uses a 2-stage cascade of convolutional autoencoders (CAEs) to detect and reconstruct GW signals buried in LIGO data, finding that it is effective at accurately isolating GW signals with very low latency on just one graphics processing unit (GPU). Ultimately, it is found that it is practical and likely beneficial for astronomers to use such a cascade to process incoming LIGO data.},
  archive      = {J_NCA},
  author       = {Sengupta, Mayank},
  doi          = {10.1007/s00521-024-09441-3},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {6993-7006},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gravitational wave isolation with autoencoder neural network cascade},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient image restoration with style-guided context
cluster and interaction. <em>NCA</em>, <em>36</em>(13), 6973–6991. (<a
href="https://doi.org/10.1007/s00521-024-09440-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks (CNNs) and vision transformers (ViTs) have emerged as powerful tools for image restoration (IR). Nonetheless, they encountered some limitations due to their characteristics, such as CNNs sacrificing global reception and ViTs requiring large memory and graphics resources. To address these limitations and explore an alternative approach for improved IR performance, we propose two clustering-based frameworks for general IR tasks, which are style-guided context cluster U-Net (SCoC-UNet) and style-guided clustered point interaction U-Net (SCPI-UNet). The SCoC-UNet adopts a U-shaped architecture, comprising position embedding, Encoder, Decoder, and reconstruction block. Specifically, the input low-quality image is viewed as a set of unorganized points, each of which is first given location information by the continuous relative position embedding method. These points are then fed into a symmetric Encoder and Decoder which utilize style-guided context cluster (SCoC) blocks to extract potential context features and high-frequency information. Although SCoC-UNet has obtained decent performance for image restoration, its SCoC block can only capture connectivity at points within the same cluster, which may ignore long-range dependencies in different clusters. To address this issue, we further propose a SCPI-UNet based on SCoC-UNet, which leverages a style-guided clustered point interaction (SCPI) block in place of the SCoC block. The SCPI block utilizes a cross-attention mechanism to establish the connections of feature points between different clusters. Extensive experimental results demonstrate that the proposed SCoC-UNet and SCPI-UNet can handle several typical IR tasks (i.e., JPEG compression artifact reduction, image denoising, and super-resolution) and achieve superior quantitative and qualitative performance over some state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Qiao, Fengjuan and Zhu, Yonggui and Meng, Ming},
  doi          = {10.1007/s00521-024-09440-4},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {6973-6991},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient image restoration with style-guided context cluster and interaction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Comparative study of ML models for IIoT intrusion
detection: Impact of data preprocessing and balancing. <em>NCA</em>,
<em>36</em>(13), 6955–6972. (<a
href="https://doi.org/10.1007/s00521-024-09439-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the effectiveness of six prominent machine learning models—random forest, decision trees, K-nearest neighbor, logistic regression, support vector machines, and Naïve Bayes—for intrusion detection systems in industrial Internet of Things environments. The evaluation encompasses the effects of data preprocessing techniques, including feature engineering, data normalization, recoding, and missing data mitigation. Furthermore, the research delves into dataset balancing, examining the effects of six different techniques on model performance. The investigations are conducted using the domain-specific WUSTL-IIOT-2021 dataset, which captures the unique characteristics of IIoT data. The study also investigates multi-class attack identification utilizing an innovative SMOTE-based multi-class balancing approach to tackle dataset imbalances. The results indicate that data preprocessing and intelligent dataset balancing produce consistent enhancements in the classification performance of the selected models across binary and multi-classification tasks. Random forest emerges as the standout algorithm, delivering consistently high performance with computational efficiency.},
  archive      = {J_NCA},
  author       = {Eid, Abdulrahman Mahmoud and Soudan, Bassel and Nassif, Ali Bou and Injadat, MohammadNoor},
  doi          = {10.1007/s00521-024-09439-x},
  journal      = {Neural Computing and Applications},
  month        = {5},
  number       = {13},
  pages        = {6955-6972},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparative study of ML models for IIoT intrusion detection: Impact of data preprocessing and balancing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Early detection of depression through facial expression
recognition and electroencephalogram-based artificial
intelligence-assisted graphical user interface. <em>NCA</em>,
<em>36</em>(12), 6937–6954. (<a
href="https://doi.org/10.1007/s00521-024-09437-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychological disorders have increased globally at an alarming rate. Among these disorders, depression stands out as one of the leading and most prevalent conditions that have affected more than 280 million people. However, it remains widely undiagnosed and untreated due to lack of sensitive and reliable diagnostic tools. This underscores the imperative for the development of a sensitive and accurate diagnostic tool facilitating the early diagnosis of depression symptoms to mitigate the impending mental illness epidemic. To address this need, we developed an artificial intelligence (AI)-assisted tool utilizing facial expression-based emotion recognition and electroencephalogram (EEG) analysis for the detection of depression symptoms along with their severity level assessment. Our approach yielded successful detection of depression symptoms with an accuracy of 93.58%, a sensitivity of 92.70%, a specificity of 93.40%, and an f1-score of 93.68% through facial emotion recognition task. Additionally, severity level detection employing EEG biomarkers achieved an accuracy of 99.75%, a sensitivity of 99.75%, a specificity of 99.92%, and an f1-score of 99.75%. Consequently, a graphical user interface (GUI) tool was developed that seamlessly integrated the AI with facial image and EEG data inputs, enabling efficient recognition of depression from both real-time and pre-recorded data. The resulting AI assistant demonstrates high sensitivity, precision, and accuracy in the early detection of depression, establishing its potential as a reliable diagnostic tool. The application of our tool may be extended to clinicians, therapists, and hospitals for the identification of depression at its early stage.},
  archive      = {J_NCA},
  author       = {Kumar, Gajendra and Das, Tanaya and Singh, Kuldeep},
  doi          = {10.1007/s00521-024-09437-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6937-6954},
  shortjournal = {Neural Comput. Appl.},
  title        = {Early detection of depression through facial expression recognition and electroencephalogram-based artificial intelligence-assisted graphical user interface},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BinDMO: A new binary dwarf mongoose optimization algorithm
on based z-shaped, u-shaped, and taper-shaped transfer functions for
CEC-2017 benchmarks. <em>NCA</em>, <em>36</em>(12), 6903–6935. (<a
href="https://doi.org/10.1007/s00521-024-09436-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent swarm optimization algorithms have become increasingly common due to their success in solving real-world problems. Dwarf Mongoose Optimization (DMO) algorithm is a newly proposed intelligent swarm optimization algorithm in recent years. It was developed for continuous optimization problem solutions in its original paper. But real-world problems are not always problems that take continuously variable values. Real-world problems are often problems with discrete variables. Therefore, heuristic algorithms proposed for continuous optimization problems need to be updated to solve discrete optimization problems. In this study, DMO has been updated for binary optimization problems and the Binary DMO (BinDMO) algorithm has been proposed. In binary optimization, the search space consists of binary variable values. Transfer functions are often used in the conversion of continuous variable values to binary variable values. In this study, twelve different transfer functions were used (four Z-shaped, four U-shaped, and four Taper-shaped). Thus, twelve different BinDMO variations were obtained (BinDMO1, BinDMO2, …, BinDMO12). The achievements of BinDMO variations were tested on thirteen different unimodal and multimodal classical benchmark functions. The effectiveness of population sizes on the effectiveness of BinDMO was also investigated. When the results were examined, it was determined that the most successful BinDMO variation was BinDMO1 (with Z1-shaped transfer function). The most successful BinDMO variation was compared with three different binary heuristic algorithms selected from the literature (SO, PDO, and AFT) on CEC-2017 benchmark functions. According to the average results, BinDMO was the most successful binary heuristic algorithm. This has proven that BinDMO can be chosen as an alternative algorithm for binary optimization problems.},
  archive      = {J_NCA},
  author       = {BAS, Emine},
  doi          = {10.1007/s00521-024-09436-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6903-6935},
  shortjournal = {Neural Comput. Appl.},
  title        = {BinDMO: A new binary dwarf mongoose optimization algorithm on based Z-shaped, U-shaped, and taper-shaped transfer functions for CEC-2017 benchmarks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring emergent syllables in end-to-end automatic speech
recognizers through model explainability technique. <em>NCA</em>,
<em>36</em>(12), 6875–6901. (<a
href="https://doi.org/10.1007/s00521-024-09435-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic speech recognition systems based on end-to-end models (E2E-ASRs) can achieve comparable performance to conventional ASR systems while reproducing all their essential parts automatically, from speech units to the language model. However, they hide the underlying perceptual processes modelled, if any, and they have lower adaptability to multiple application contexts, and, furthermore, they require powerful hardware and an extensive amount of training data. Model-explainability techniques can explore the internal dynamics of these ASR systems and possibly understand and explain the processes conducting to their decisions and outputs. Understanding these processes can help enhance ASR performance and reduce the required training data and hardware significantly. In this paper, we probe the internal dynamics of three E2E-ASRs pre-trained for English by building an acoustic-syllable boundary detector for Italian and Spanish based on the E2E-ASRs’ internal encoding layer outputs. We demonstrate that the shallower E2E-ASR layers spontaneously form a rhythmic component correlated with prominent syllables, central in human speech processing. This finding highlights a parallel between the analysed E2E-ASRs and human speech recognition. Our results contribute to the body of knowledge by providing a human-explainable insight into behaviours encoded in popular E2E-ASR systems.},
  archive      = {J_NCA},
  author       = {Vitale, Vincenzo Norman and Cutugno, Francesco and Origlia, Antonio and Coro, Gianpaolo},
  doi          = {10.1007/s00521-024-09435-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6875-6901},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring emergent syllables in end-to-end automatic speech recognizers through model explainability technique},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label noisy samples in underwater inspection from the
oil and gas industry. <em>NCA</em>, <em>36</em>(12), 6855–6873. (<a
href="https://doi.org/10.1007/s00521-024-09434-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has shown remarkable success in various machine learning tasks, including multi-label classification. Multi-label classification is a supervised task where an input instance can be associated with multiple labels simultaneously, instead of exclusively one, as in the single-label scenario. When building a multi-label dataset for real-world applications, a recurrent problem is the presence of noisy labels. In this context, noisy labels refer to mislabeled data, which can potentially weaken the performance of supervised models. Although this issue may be well explored for single-label noise, it is still an emerging topic for multi-label applications. In this work, a novel deep learning model that handles multi-label noise is proposed, where we combine the Small Loss Approach Multi-label (SLAM) with a joint loss, in order to automatically identify and rectify noisy labels. The model outperforms in $$2.5\%$$ for the F1-score state-of-the-art (SOTA) models in the noisy version of the benchmark UcMerced. A new open noisy version of the benchmark TreeSATAI was developed and is now disclosed, where the performance gains reached $$1.8\%$$ in F-1 Score. Furthermore, the model was able to reduce the presence of noise from $$25\%$$ to $$5\%$$ in both sets. In addition, we evaluate the model on a real-world application of underwater inspections, to assist with the multi-label classification for an oil and gas company. Our model achieved gains in the F1-Score of $$10\%$$ when compared to a standard model (without noise-handling techniques), and up to $$2.7\%$$ and $$1.9\%$$ when compared to SOTA models SLAM and JoCoR, respectively.},
  archive      = {J_NCA},
  author       = {Sousa, First Vitor and Pereira, Second Amanda and Koher, Third Manoela and Pacheco, Fourth Marco},
  doi          = {10.1007/s00521-024-09434-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6855-6873},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-label noisy samples in underwater inspection from the oil and gas industry},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mountain gazelle optimizer for standalone hybrid power
system design incorporating a type of incentive-based strategies.
<em>NCA</em>, <em>36</em>(12), 6839–6853. (<a
href="https://doi.org/10.1007/s00521-024-09433-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this research study is to improve the performance of a standalone hybrid power system (SHPS) that consists of photovoltaic modules (PVMs), wind turbines (WTs), battery system (BS), and diesel engine (DE). The emphasis is on optimizing the system&#39;s design by incorporating demand response strategies (DRSs). Incorporating these strategies into the system can enhance system performance, stability, and profitability while also reducing the capacity of SHPS components and, consequently, lowering consumers&#39; bills. To achieve this objective, the sizing model incorporates a novel indicator called the load variation factor (LVF). This paper assesses and contrasts various scenarios, including SHPS without DRS, with DRS, and with DRS but no DE. In this article, interruptible/curtailable (I/C) as one of the DRSs is incorporated into the model used for sizing issues. A newly developed optimization algorithm called the mountain gazelle optimizer (MGO) is utilized for the multi-objective design of the proposed SHPS. The utilization of MGO will facilitate achieving the lowest possible values for each of the following: cost of energy (COE), loss of power supply probability (LPSP), and carbon dioxide (CO2) emissions. This work introduces a mathematical model for the entire system, which is subsequently simulated using MATLAB software. The results reveal that among all the scenarios analysed, scenario iii — which has an LVF of 30% — is the most cost-effective. It has the lowest COE, at 0.2334 $/kWh, hence the lowest net present cost (NPC), at 6,836,445.5 $.},
  archive      = {J_NCA},
  author       = {Abdelsattar, Montaser and Mesalam, Abdelgayed and Fawzi, Abdelrahman and Hamdan, I.},
  doi          = {10.1007/s00521-024-09433-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6839-6853},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mountain gazelle optimizer for standalone hybrid power system design incorporating a type of incentive-based strategies},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A periodicity aware transformer for crystal property
prediction. <em>NCA</em>, <em>36</em>(12), 6827–6838. (<a
href="https://doi.org/10.1007/s00521-024-09432-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crystals constitute a variety of important materials from everyday life to cutting-edge fields. The properties of a crystal are determined by its structure, as demonstrated by physics theory, which is essential for understanding and designing materials. In recent years, deep learning-based methods have been proposed to predict crystal material properties and achieved satisfactory performance. However, these methods have not adequately accounted for the key composition of crystals, i.e., periodicity. To address this issue, we propose a periodicity aware crystal transformer (PACT), which uses hierarchical self-attention mechanisms to enforce periodicity constraints on the crystal structure. Specifically, it applies unit-wise self-attention and crystal-wise self-attention to ensure that the surroundings of atoms or unit cells at periodic distances are identical. Extensive benchmark experiments demonstrate that our proposed model exhibits superior performance, achieving an average improvement of 7.07% over previous methods. Additionally, ablation studies show both unit-wise self-attention and crystal-wise in the hierarchical self-attention mechanisms are effective in modeling the periodicity.},
  archive      = {J_NCA},
  author       = {Liu, Ke and Yang, Kaifan and Gao, Shangde},
  doi          = {10.1007/s00521-024-09432-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6827-6838},
  shortjournal = {Neural Comput. Appl.},
  title        = {A periodicity aware transformer for crystal property prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep image matting with cross-layer contextual information
propagation. <em>NCA</em>, <em>36</em>(12), 6809–6825. (<a
href="https://doi.org/10.1007/s00521-024-09431-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural image matting focuses on accurately estimating the opacity of the foreground object in an arbitrary background. Recently, deep learning-based approaches made significant progress in the matting task benefit from their powerful learning ability for semantic features. However, artifacts, blurry structures, and miscalculated pixels still often appear in some difficult regions with background interference and complex details. To address the above issues, we propose a cross-layer contextual information propagation mechanism (CCIP) that can explicitly model the long-range correlations between global and unknown regions. Specifically, we first calculate region affinity at high-level features with rich structure and semantic information; then reconstruct the adjacent low-level features by propagating information from the global region to the unknown region under the guidance of the affinity matrix; finally, transfer the reconstructed information to the corresponding decoder stage to further improve the feature distinctiveness. In addition, we design a simple and effective supervision strategy in a deep-to-shallow manner to gradually optimize the edges and details of the foreground object. We conducted extensive experiments on the common dataset Composition-1k, the alphamatting.com benchmark, and some real-world images. Compared with previous methods, the proposed method achieves competitive performance on the Composition-1k dataset (30.3 on SAD, 6.8 on MSE, 13.3 on Grad, and 26.7 on Con) and alphamatting.com benchmark (17 on average SAD rank and 16.8 on average Grad rank), while simultaneously yielding high-quality matting results on real-world images.},
  archive      = {J_NCA},
  author       = {Zhou, Fenfen and Tian, Yingjie and Zhu, Siyu},
  doi          = {10.1007/s00521-024-09431-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6809-6825},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep image matting with cross-layer contextual information propagation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FCDS-DETR: Detection transformer based on feature correction
and double sampling. <em>NCA</em>, <em>36</em>(12), 6793–6808. (<a
href="https://doi.org/10.1007/s00521-024-09430-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recently proposed semantic-aligned matching detection transformer (SAM–DETR model) accelerates the convergence of the detection transformer (DETR) by mapping object queries into an identical embedding space as the encoder’s output feature map. However, SAM–DETR model has the problem of low detection accuracy compared to other DETR variants. We observe that the lower detection accuracy of SAM–DETR model is caused by the insufficient number of sample points and the inaccurate localization of the sample points during re-sampling, which blurs the generated attention map. This paper proposes an object detector based on a feature correction and double sampling DETR (FCDS-DETR) to solve this problem. FCDS-DETR takes SAM–DETR model as a baseline and builds on it by adding a feature correction module and a double sampling mechanism to achieve further improvement in detection accuracy with a limited number of additional parameters without sacrificing convergence speed. Firstly, FCDS-DETR improves the sampling point localization accuracy by adding a feature correction module to model the inter-channel dependence of the feature maps to be sampled. Secondly, the number of sampled points is increased by the double sampling mechanism, and attention fusion is used to fuse the attention weight maps corresponding to the two sets of sampled points to improve the recognizability of the attention weight maps. The experimental results show that the average precision is improved by +0.7 on the COCO dataset compared with the SAM–DETR model, and the number of parameters is increased by only 10.34 $$\%$$ , which improves the detection performance of the model very well.},
  archive      = {J_NCA},
  author       = {Wang, Min and Jiao, Zhiqiang and Huang, Zhanhua and Yu, Shihang},
  doi          = {10.1007/s00521-024-09430-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6793-6808},
  shortjournal = {Neural Comput. Appl.},
  title        = {FCDS-DETR: Detection transformer based on feature correction and double sampling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting SQL injection attacks by binary gray wolf
optimizer and machine learning algorithms. <em>NCA</em>,
<em>36</em>(12), 6771–6792. (<a
href="https://doi.org/10.1007/s00521-024-09429-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SQL injection is one of the important security issues in web applications because it allows an attacker to interact with the application&#39;s database. SQL injection attacks can be detected using machine learning algorithms. The effective features should be employed in the training stage to develop an optimal classifier with optimal accuracy. Identifying the most effective features is an NP-complete combinatorial optimization problem. Feature selection is the process of selecting the training dataset&#39;s smallest and most effective features. The main objective of this study is to enhance the accuracy, precision, and sensitivity of the SQLi detection method. In this study, an effective method to detect SQL injection attacks has been proposed. In the first stage, a specific training dataset consisting of 13 features was prepared. In the second stage, two different binary versions of the Gray-Wolf algorithm were developed to select the most effective features of the dataset. The created optimal datasets were used by different machine learning algorithms. Creating a new SQLi training dataset with 13 numeric features, developing two different binary versions of the gray wolf optimizer to optimally select the features of the dataset, and creating an effective and efficient classifier to detect SQLi attacks are the main contributions of this study. The results of the conducted tests indicate that the proposed SQL injection detector obtain 99.68% accuracy, 99.40% precision, and 98.72% sensitivity. The proposed method increases the efficiency of attack detection methods by selecting 20% of the most effective features.},
  archive      = {J_NCA},
  author       = {Arasteh, Bahman and Aghaei, Babak and Farzad, Behnoud and Arasteh, Keyvan and Kiani, Farzad and Torkamanian-Afshar, Mahsa},
  doi          = {10.1007/s00521-024-09429-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6771-6792},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detecting SQL injection attacks by binary gray wolf optimizer and machine learning algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized variable impedance control of modular robot
manipulators with physical human–robot interaction using gaussian
process-based motion intention estimation. <em>NCA</em>,
<em>36</em>(12), 6757–6769. (<a
href="https://doi.org/10.1007/s00521-024-09428-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a decentralized variable impedance control method of modular robot manipulators (MRM) with physical human-robot interaction (pHRI) using Gaussian process-based motion intention estimation. The dynamic model of MRM subsystem is established by using joint torque feedback (JTF) technique. Human limb dynamic model is regarded as mechanical impedance model, and human motion intention is estimated online based on Gaussian process. A variable impedance control method is proposed to make the MRM comply with human motion intention in the process of pHRI. A decentralized sliding mode control strategy is designed to achieve high performance position tracking and compensate the uncertainty of the controller. Based on Lyapunov theory, the uniform ultimately bounded of tracking error of each joint is proved. Finally, the effectiveness of the proposed control method under pHRI is verified by experiments. The experimental results show that the proposed method reduces the position tracking error by $$ \sim $$ 10% and the interaction force by $$\sim $$ 20% compared with the existing control methods.},
  archive      = {J_NCA},
  author       = {Dong, Bo and Li, Shijie and An, Tianjiao and Cui, Yiming and Zhu, Xinye},
  doi          = {10.1007/s00521-024-09428-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6757-6769},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decentralized variable impedance control of modular robot manipulators with physical human–robot interaction using gaussian process-based motion intention estimation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wavelet-based spectrum transfer with collaborative learning
for unsupervised bidirectional cross-modality domain adaptation on
medical image segmentation. <em>NCA</em>, <em>36</em>(12), 6741–6755.
(<a href="https://doi.org/10.1007/s00521-024-09427-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised cross-modality domain adaptation for medical image segmentation has made great progress with the development of adversarial learning-based methods, but the training of adversarial models is considerably complicated. In this paper, we propose a conceptually simple but effective unsupervised domain adaptation method to achieve adaptation on frequency spectrum components of target and source images decomposed by a novel spectrum transfer strategy. Specifically, we replace the high-frequency components of the source domain images with that of the target domain images for details feature adaptation and adjust the low-frequency components by histogram matching for style adaptation. Besides, we propose multi-direction collaborative learning on both target and source domains to further improve the performance. Experimental results demonstrate that our method significantly outperforms state-of-the-art UDA methods for medical image segmentation on two publicly available datasets (cardiac dataset, and abdominal multi-organ dataset) in both CT to MRI and MRI to CT domain adaptation scenarios},
  archive      = {J_NCA},
  author       = {Liu, Shaolei and Qu, Linhao and Yin, Siqi and Wang, Manning and Song, Zhijian},
  doi          = {10.1007/s00521-024-09427-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6741-6755},
  shortjournal = {Neural Comput. Appl.},
  title        = {Wavelet-based spectrum transfer with collaborative learning for unsupervised bidirectional cross-modality domain adaptation on medical image segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SRIME: A strengthened RIME with latin hypercube sampling and
embedded distance-based selection for engineering optimization problems.
<em>NCA</em>, <em>36</em>(12), 6721–6740. (<a
href="https://doi.org/10.1007/s00521-024-09424-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a strengthened RIME algorithm to tackle continuous optimization problems. RIME is a newly proposed physical-based evolutionary algorithm (EA) inspired by the soft and hard rime growth process of rime-ice, which has a powerful exploitation ability. But in complex optimization problems, RIME will easily trap into local optima and the optimization will become stagnation. Noticing this issue, we introduce three techniques to the original RIME: (1) Latin hypercube sampling replaces the random generator as the initialization strategy, (2) modified hard rime search strategy, and (3) embedded distance-based selection mechanism. We evaluate our proposed SRIME in 10-D, 30-D, 50-D, and 100-D CEC2020 benchmark functions and eight real-world engineering optimization problems with nine state-of-the-art EAs. Experimental and statistical results show that the introduction of three techniques can significantly accelerate the optimization of the RIME algorithm, and SRIME is a competitive optimization technique in real-world applications. Ablation experiments are also provided to analyze our proposed three techniques independently, and the embedded distance-based selection contributes most to the improvement of SRIME. The source code of SRIME can be found in https://github.com/RuiZhong961230/SRIME .},
  archive      = {J_NCA},
  author       = {Zhong, Rui and Yu, Jun and Zhang, Chao and Munetomo, Masaharu},
  doi          = {10.1007/s00521-024-09424-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6721-6740},
  shortjournal = {Neural Comput. Appl.},
  title        = {SRIME: A strengthened RIME with latin hypercube sampling and embedded distance-based selection for engineering optimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-document influence on readers: Augmenting social
emotion prediction by learning document interactions. <em>NCA</em>,
<em>36</em>(12), 6701–6719. (<a
href="https://doi.org/10.1007/s00521-024-09420-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social emotion prediction aims to predict readers’ emotion, for example, emotion distributions evoked by documents (e.g., news articles). It makes a significant contribution to social media applications, such as opinion summary, election prediction, and emotions investigation of society. While recent studies have focused on encoding consecutive word sequences in documents using neural network models and leveraging topical information, it is essential to acknowledge the influence of documents sharing similar topics or being related to similar events on evoking readers’ emotions. The interactions among documents can significantly impact social emotion prediction. In this paper, we propose a novel approach to model the interactions among documents by constructing a heterogeneous graph. This graph captures the interaction among documents based on global word co-occurrence patterns in a corpus and the emotional scores of words obtained from emotion lexicons. Additionally, we develop heterogeneous graph convolution attention network (HGCA) to embed the heterogeneous graph. This network effectively captures the importance of different neighboring nodes and different node types, enabling comprehensive emotion prediction. Furthermore, we develop Taylor series expansion-based Transformer (Tayformer) to derive initialized node representations that can be co-trained with our graph network while having low memory complexity. Experimental results on four benchmark datasets show the effectiveness of our method.},
  archive      = {J_NCA},
  author       = {Mou, Xu and Peng, Qinke and Sun, Zhao and Bashir, Muhammad Fiaz and Li, Haozhou},
  doi          = {10.1007/s00521-024-09420-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6701-6719},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-document influence on readers: Augmenting social emotion prediction by learning document interactions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing user and item representation with collaborative
signals for KG-based recommendation. <em>NCA</em>, <em>36</em>(12),
6681–6699. (<a
href="https://doi.org/10.1007/s00521-024-09419-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) shows great potential in improving recommendation systems. Recent studies have focused on developing end-to-end models based on graph neural networks. However, these previous approaches do not fully utilize collaborative signals, which are the collective information and feedback provided by multiple users in a recommendation system. Specifically, we think that collaborative signals could be better utilized in two points. Firstly, users’ collective information leads to differences in node importance in KG, offering opportunities to improve item representation. Secondly, an item’s collaborative filtering (CF) feature can reveal the multiple interests of a user, helping to gain fine-grained user representation. In this paper, we highlight the effect of node importance estimation and CF-based item clustering and propose the collaborative signals injection module. We integrate this module in our Collaborative Signals Enhanced Knowledge Graph recommendation (CSEKG) model. CSEKG outperforms state-of-the-art methods like KGIN (Wang et al. in Learning intents behind interactions with knowledge graph for recommendation. CoRR arXiv:2102.07057 , 2021) , KGCL (Yang et al. in Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval, 2022) , and KGRec (Yang et al. in Proceedings of the 29th ACM SIGKDD conference on knowledge discovery and data mining, 2023) through improving recall@20 by $$3.86\%$$ , $$5.15\%$$ , and $$2.88\%$$ on Last.FM, Amazon-Book and MovieLens-1M, respectively. Furthermore, we flexibly integrate the collaborative signals injection module into existing methods, such as LightGCN, KGAT and KGIN, which improves their performance. Further visualizing recommendation cases show the interpretability benefits brought by collaborative signals.},
  archive      = {J_NCA},
  author       = {Zhang, Yanlin and Gu, Xiaodong},
  doi          = {10.1007/s00521-024-09419-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6681-6699},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing user and item representation with collaborative signals for KG-based recommendation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous instance pooling and bag representation
selection approach for multiple-instance learning (MIL) using vision
transformer. <em>NCA</em>, <em>36</em>(12), 6659–6680. (<a
href="https://doi.org/10.1007/s00521-024-09417-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiple-instance learning (MIL), the existing bag encoding and attention-based pooling approaches assume that the instances in the bag have no relationship among them. This assumption is unsuited, as the instances in the bags are rarely independent in diverse MIL applications. In contrast, the instance relationship assumption-based techniques incorporate the instance relationship information in the classification process. However, in MIL, the bag composition process is complicated, and it may be possible that instances in one bag are related and instances in another bag are not. In present MIL algorithms, this relationship assumption is not explicitly modeled. The learning algorithm is trained based on one of two relationship assumptions (whether instances in all bags have a relationship or not). Hence, it is essential to model the assumption of instance relationships in the bag classification process. This paper proposes a robust approach that generates vector representation for the bag for both assumptions and the representation selection process to determine whether to consider the instances related or unrelated in the bag classification process. This process helps to determine the essential bag representation vector for every individual bag. The proposed method utilizes attention pooling and vision transformer approaches to generate bag representation vectors. Later, the representation selection subnetwork determines the vector representation essential for bag classification in an end-to-end trainable manner. The generalization abilities of the proposed framework are demonstrated through extensive experiments on several benchmark datasets. The experiments demonstrate that the proposed approach outperforms other state-of-the-art MIL approaches in bag classification.},
  archive      = {J_NCA},
  author       = {Waqas, Muhammad and Tahir, Muhammad Atif and Author, Muhammad Danish and Al-Maadeed, Sumaya and Bouridane, Ahmed and Wu, Jia},
  doi          = {10.1007/s00521-024-09417-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6659-6680},
  shortjournal = {Neural Comput. Appl.},
  title        = {Simultaneous instance pooling and bag representation selection approach for multiple-instance learning (MIL) using vision transformer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ImplantFormer: Vision transformer-based implant position
regression using dental CBCT data. <em>NCA</em>, <em>36</em>(12),
6643–6658. (<a
href="https://doi.org/10.1007/s00521-023-09411-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implant prosthesis is the most appropriate treatment for dentition defect or dentition loss, which usually involves a surgical guide design process to decide the implant position. However, such design heavily relies on the subjective experiences of dentists. In this paper, a transformer-based Implant Position Regression Network, ImplantFormer, is proposed to automatically predict the implant position based on the oral CBCT data. We creatively propose to predict the implant position using the 2D axial view of the tooth crown area and fit a centerline of the implant to obtain the actual implant position at the tooth root. Convolutional stem and decoder are designed to coarsely extract image features before the operation of patch embedding and integrate multi-level feature maps for robust prediction, respectively. As both long-range relationship and local features are involved, our approach can better represent global information and achieves better location performance. Extensive experiments on a dental implant dataset through fivefold cross-validation demonstrated that the proposed ImplantFormer achieves superior performance than existing methods.},
  archive      = {J_NCA},
  author       = {Yang, Xinquan and Li, Xuguang and Li, Xuechen and Wu, Peixi and Shen, Linlin and Deng, Yongqiang},
  doi          = {10.1007/s00521-023-09411-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6643-6658},
  shortjournal = {Neural Comput. Appl.},
  title        = {ImplantFormer: Vision transformer-based implant position regression using dental CBCT data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PushNet: 3D reconstruction from a single image by pushing.
<em>NCA</em>, <em>36</em>(12), 6629–6641. (<a
href="https://doi.org/10.1007/s00521-023-09408-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking inspiration from the recent advancements in deep learning within the three-dimensional (3D) domain, we propose an end-to-end deep learning framework to reconstruct 3D shapes in point cloud format from a single color image. While many state-of-the-art learning-based 3D reconstruction methods are constrained to fixed resolutions, our framework, named PushNet, can produce point clouds with arbitrary resolutions and only require sparse point clouds during training. It predicts a push force for each randomly sampled spacial point and leads the point to project onto the surface of the underlying 3D object in the image. The network also employs a parallel design, allowing it to be trained on sparse point clouds and then generate point clouds of any resolution without degrading the quality or requiring any fine-tuning. Experiments on synthetic datasets and real datasets demonstrate the effectiveness of our method for inferring 3D shapes. We also demonstrate that our predicted point clouds can produce high-fidelity meshes after applying surface reconstruction algorithms. Experiments on linear interpolation, point cloud upsampling, and textured 3D reconstruction also prove the effectiveness of our framework.},
  archive      = {J_NCA},
  author       = {Ping, Guiju and Wang, Han},
  doi          = {10.1007/s00521-023-09408-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6629-6641},
  shortjournal = {Neural Comput. Appl.},
  title        = {PushNet: 3D reconstruction from a single image by pushing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new metaheuristic-based MPPT controller for photovoltaic
systems under partial shading conditions and complex partial shading
conditions. <em>NCA</em>, <em>36</em>(12), 6613–6627. (<a
href="https://doi.org/10.1007/s00521-023-09407-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar photovoltaic energy is the potential energy in the universe for generating electricity and meeting the required load demand. However, on account of partial shading conditions, the difficult task in the PV system is to track global maxima instead of local maxima and maintain the uninterrupted power supply. To solve this problem, a new metaheuristic algorithm is introduced in this paper such as a heap-based optimizer (HBO). The proposed method is developed in MATLAB/Simulink software. The system is examined under distinct irradiation conditions and compared their performance with other methods. The simulation results reveal that the suggested HBO shows a reliable enhancement as compared to other studied methods with regard to tracking maximum power, convergence time, and settling time. The extracted power efficiencies are 99.85% for case 1, 99.96% for case 2, and 99.92% for case 3. It is found that HBO shows better enrichment than other studied methods.},
  archive      = {J_NCA},
  author       = {Kishore, Dokala Janandra Krishna and Mohamed, Mohd Rusllim and Sudhakar, Kumarasamy and Peddakapu, Kurukuri},
  doi          = {10.1007/s00521-023-09407-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6613-6627},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new metaheuristic-based MPPT controller for photovoltaic systems under partial shading conditions and complex partial shading conditions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task planning of space debris removal based on a
hierarchical exploration artificial bee colony algorithm. <em>NCA</em>,
<em>36</em>(12), 6597–6612. (<a
href="https://doi.org/10.1007/s00521-023-09399-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space debris poses a potentially catastrophic risk to large-scale LEO constellations due to its substantial cascading effects, thereby rendering efficient and timely debris removal a critical research area in contemporary aerospace engineering. This paper delves into the application of the three-dimensional traveling salesman problem with orbital transfer constraints for space debris removal task planning. To overcome the challenges of sparse optimal solutions and vulnerability to local optima in addressing large-scale space debris removal task planning problems, we introduce a new Hierarchical Exploration Artificial Bee Colony (HEABC) optimization algorithm. Initially, we present an innovative two-step search strategy that employs a short-and-long term hybrid approach to optimize search time utilization and enhance solution quality, thereby addressing the sparsity of optimal solutions in the HEABC algorithm. Subsequently, to mitigate the issue of converging to local optima in high-dimensional encoding-based search problems, we devise a dual population update strategy aimed at preserving the innate evolutionary driving force of the search population. This strategy ensures the continuous updating of the population, even in the absence of intrinsic driving forces. Ultimately, experimental results substantiate that our proposed HEABC algorithm attains superior task planning sequences in a reduced time span and exhibits heightened adaptability in comparison to various traditional search algorithms. This is corroborated by numerical experiments conducted on one publicly available and one STK-generated space debris datasets.},
  archive      = {J_NCA},
  author       = {Xia, Qing and Qiu, Shi and Liu, Ming and Lin, XiaoHui},
  doi          = {10.1007/s00521-023-09399-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6597-6612},
  shortjournal = {Neural Comput. Appl.},
  title        = {Task planning of space debris removal based on a hierarchical exploration artificial bee colony algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced user verification in IoT applications: A
fusion-based multimodal cancelable biometric system with ECG and PPG
signals. <em>NCA</em>, <em>36</em>(12), 6575–6595. (<a
href="https://doi.org/10.1007/s00521-023-09394-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core premise of cancelable biometrics lies in the creation of a distinct biometric template for every individual, which can be either canceled or regenerated as needed. This process requires the use of a uniquely-defined key during the generation of such template. The generated templates are tailored to be key-specific. This ensures that each distinct key will generate a unique template, while preserving the integrity and security of the original biometric data, ensuring that it remains uncompromised. In this paper, a cancelable biometric system based on electrocardiography (ECG) and photoplethysmography (PPG) signals is introduced. A signal fusion process is implemented for the two traits to generate a single template per user. In order to enhance the security of generated templates, a well-designed permutation stage is implemented according to a user-specific key. The permutation key is obtained through a well-designed look-up table created by the authors. The user verification is conducted on the cancelable template, without the need for any inversion processes. The user verification scheme depends on a two-pronged approach: robust feature extraction followed by the application of a machine learning (ML) classifier. The mel-frequency cepstral coefficients (MFCCs) extraction algorithm is employed for feature extraction due to the low frequency range of the adopted biometric signals and the nonlinearity of the filter bank used for MFCC extraction. Several ML classifiers are adopted to validate the system with cancelable templates without any inversion process. Simulation results with multilayer perceptron (MLP) and logistic regression (LR) classifiers demonstrated superior effectiveness of the proposed authentication framework, with accuracy rates up to 100% and 99.7% on the pulse transit time PPG and BIDMC datasets, respectively. Hence, the proposed system proves effective access control and user verification in the Internet-of-Things (IoT) applications.},
  archive      = {J_NCA},
  author       = {Siam, Ali I. and El-Shafai, Walid and Abou Elazm, Lamiaa A. and El-Bahnasawy, Nirmeen A. and Abd El-Samie, Fathi E. and Abou Elazm, Atef and El-Banby, Ghada M.},
  doi          = {10.1007/s00521-023-09394-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6575-6595},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced user verification in IoT applications: A fusion-based multimodal cancelable biometric system with ECG and PPG signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quran reciter identification using NASNetLarge.
<em>NCA</em>, <em>36</em>(12), 6559–6573. (<a
href="https://doi.org/10.1007/s00521-023-09392-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speaker identification has significant advantages for the field of human–computer interaction. Recently, many scholars have made contributions in this field and successfully created deep learning models for automatic speaker identification systems. However, most of the speech signal processing work is limited to English-only applications, despite numerous challenges with Arabic speech, particularly with the recitation of the Holy Quran, which is the Islamic holy book. In the light of these considerations, this study proposes a model for identifying the reciter of the Holy Quran using a dataset of 11,000 audio samples extracted from 20 Quran reciters. To enable feeding the audio samples&#39; visual representation to the pre-trained models, the audio samples are converted from their original audio representation to visual representation using the Mel-Frequency Cepstrum Coefficients. Six pre-trained deep learning models are evaluated separately in the proposed model. The results from the test dataset reveal that the NASNetLarge model achieved the highest accuracy rate of 98.50% among the pre-trained models used in this study.},
  archive      = {J_NCA},
  author       = {Saber, Hebat-Allah and Younes, Ahmed and Osman, Mohamed and Elkabani, Islam},
  doi          = {10.1007/s00521-023-09392-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6559-6573},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quran reciter identification using NASNetLarge},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MGFEEN: A multi-granularity feature encoding ensemble
network for remote sensing image classification. <em>NCA</em>,
<em>36</em>(12), 6547–6558. (<a
href="https://doi.org/10.1007/s00521-023-09383-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (DCNNs) have emerged as powerful tools in diverse remote sensing domains, but their optimization remains challenging due to their complex nature and the large number of parameters involved. Researchers have been exploring more sophisticated methodologies to improve image classification accuracy. In this paper, we introduce a multi-granularity feature encoding ensemble network (MGFEEN) that is designed to fine-tune features at different levels of granularity. The network is trained in a two-step process: First, the output of granularity level i is used as the input for the next level; then, a fully connected layer is added to the pre-trained network to advance to the next level. The effectiveness of the MGFEEN’s feature extraction is evaluated by feeding the globally extracted features to a softmax classifier for classification. By applying ensemble learning principles, our proposed MGFEEN achieves more accurate final predictions. We evaluate our model on three widely recognized benchmark datasets: UC-Merced, SIRIWHU, and EAC-Dataset. Notably, on the EAC-Dataset, our results show a significant 0.54% improvement in accuracy over a single-training-network setup, resulting in an impressive 98.70% accuracy level.},
  archive      = {J_NCA},
  author       = {Jean Bosco, Musabe and Jean Pierre, Rutarindwa and Muthanna, Mohammed Saleh Ali and Jean Pierre, Kwizera and Muthanna, Ammar and Abd El-Latif, Ahmed A.},
  doi          = {10.1007/s00521-023-09383-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6547-6558},
  shortjournal = {Neural Comput. Appl.},
  title        = {MGFEEN: A multi-granularity feature encoding ensemble network for remote sensing image classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating kinetic energy reduction for terminal ballistics
using a hyperparameter-optimized neural network. <em>NCA</em>,
<em>36</em>(12), 6531–6545. (<a
href="https://doi.org/10.1007/s00521-023-09382-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A coupled framework of ballistic simulations and an optimized machine learning (ML) model was developed to accurately predict the kinetic energy reduction of a projectile impacting a target. ML models can require a significant number of data points for proper training, testing, and validation. High-performance computing (HPC) resources can be used to simulate the ballistic impacts of various projectiles against several different target materials using appropriate physics-based hydrocodes. Computational modeling can explore areas where experiments would naturally be cost-prohibitive. These hydrocodes can evaluate large parametric spaces varying the projectile and target variables that are required to train an ML model. In this study a large, generated set of data points was used to develop an optimized artificial neural network (ANN) algorithm to create a fast-running model without prior knowledge of the mathematical relationships between all the input and output variables. The optimized ANN model was developed using Optuna in an HPC environment to tune the hyperparameters needed for the ANN model. This fast-running ML model could then be leveraged to investigate designing optimized targets that could protect against different types of projectiles. The results of this work showed that the optimized ANN model predicted the kinetic energy reduction with a mean absolute percentage error of 2.7% across the validation data. Overall, the optimized ANN model showed excellent agreement across the range of data considered by the computational models.},
  archive      = {J_NCA},
  author       = {Thompson, Brianna and Sherburn, Jesse and Ross, James and Zhang, Yi},
  doi          = {10.1007/s00521-023-09382-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6531-6545},
  shortjournal = {Neural Comput. Appl.},
  title        = {Estimating kinetic energy reduction for terminal ballistics using a hyperparameter-optimized neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based comprehensive review on pulmonary
tuberculosis. <em>NCA</em>, <em>36</em>(12), 6513–6530. (<a
href="https://doi.org/10.1007/s00521-023-09381-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In areas with high tuberculosis (TB) prevalence, high mortality rate has significantly increased over the past few decades. Even though tuberculosis can be treated, areas with high disease burden continue to have insufficient screening tools, leading to diagnostic delays and incorrect diagnoses. As a result of these challenges, a computer-aided diagnostics (CAD) system has been developed that can automatically detect tuberculosis. There are few different methods that can be used to screen for tuberculosis; however, chest X-ray (CXR) is most commonly used and strongly suggested because it is so effective in identifying lung irregularities. Over past ten years, we have seen a meteoric rise in amount of research conducted into application of machine learning strategies to examination of chest X-ray images for screening regarding pulmonary abnormalities. Particularly, we have also noticed significant interest in testing for TB. This attentiveness has increased in tandem with phenomenal progress that has been made in deep learning (DL), which is predominately founded on convolutional neural networks (CNNs). Because of these advancements, significant research contributions have been made in field of DL techniques for TB screening by utilizing CXR images. The main focus of this paper is to emphasize favorable methods and data collection, as well as methodological contributions, identify data collections, and identify challenges.},
  archive      = {J_NCA},
  author       = {Bansal, Twinkle and Gupta, Sheifali and Jindal, Neeru},
  doi          = {10.1007/s00521-023-09381-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6513-6530},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep learning-based comprehensive review on pulmonary tuberculosis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantized control for predefined-time synchronization of
inertial memristive neural networks. <em>NCA</em>, <em>36</em>(12),
6497–6512. (<a
href="https://doi.org/10.1007/s00521-023-09371-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the predefined-time synchronization of inertial memristive neural networks (IMNNs) is explored. Firstly, based on differential inclusion theory, the system with discontinuous connection weights is transformed into a differential inclusion. Secondly, two more general theorems are given to ensure that the zero solution of the error system is stable within a predefined time. Then, four quantized controllers with state variable and its first-order derivative are designed, which effectively avoids the complex analysis caused by reduced-order method and saves communication resources. Furthermore, some criteria of predefined-time synchronization for IMNNs are derived by using non-reduced order method and the new predefined-time stability theorem. Finally, the effectiveness of the obtained results is verified by a numerical simulation.},
  archive      = {J_NCA},
  author       = {Yan, Hongyun and Qiao, Yuanhua and Ren, Zhihua and Duan, Lijuan and Miao, Jun},
  doi          = {10.1007/s00521-023-09371-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6497-6512},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantized control for predefined-time synchronization of inertial memristive neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). YOLO-based CAD framework with ViT transformer for breast
mass detection and classification in CESM and FFDM images. <em>NCA</em>,
<em>36</em>(12), 6467–6496. (<a
href="https://doi.org/10.1007/s00521-023-09364-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer detection is considered a challenging task for the average experienced radiologist due to the variation of the lesions’ size and shape, especially with the existence of high fibro-glandular tissues. The revolution of deep learning and computer vision contributes recently in introducing systems that can provide an automated diagnosis for breast cancer that can act as a second opinion for doctors/radiologists. The most of previously proposed deep learning-based Computer-Aided Diagnosis (CAD) systems mainly utilized Convolutional Neural Networks (CNN) that focuses on local features. Recently, vision transformers (ViT) have shown great potential in image classification tasks due to its ability in learning the local and global spatial features. This paper proposes a fully automated CAD framework based on YOLOv4 network and ViT transformers for mass detection and classification of Contrast Enhanced Spectral Mammography (CESM) images. CESM is an evolution type of Full Field Digital Mammography (FFDM) images that provides enhanced visualization for breast tissues. Different experiments were conducted to evaluate the proposed framework on two different datasets that are INbreast and CDD-CESM that provides both FFDM and CESM images. The model achieved at mass detection a mean Average Precision (mAP) score of 98.69%, 81.52%, and 71.65% and mass classification accuracy of 95.65%, 97.61%, and 80% for INbreast, CE-CESM, and DM-CESM, respectively. The proposed framework showed competitive results regarding the state-of-the-art models in INbreast. It outperformed the previous work in the literature in terms of the F1-score by almost 5% for mass detection in CESM. Moreover, the experiments showed that the CESM could provide more morphological features that can be more informative, especially with the highly dense breast tissues.},
  archive      = {J_NCA},
  author       = {Hassan, Nada M. and Hamad, Safwat and Mahar, Khaled},
  doi          = {10.1007/s00521-023-09364-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6467-6496},
  shortjournal = {Neural Comput. Appl.},
  title        = {YOLO-based CAD framework with ViT transformer for breast mass detection and classification in CESM and FFDM images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear control strategies for 3-DOF control moment
gyroscope using deep reinforcement learning. <em>NCA</em>,
<em>36</em>(12), 6441–6465. (<a
href="https://doi.org/10.1007/s00521-023-09341-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is a compelling area of research within machine learning because it enables the improvement of control strategies for future manipulation of dynamic systems, leveraging previous data even without a precise model of the system. It usually makes complex, model-free predictions from data alone, which is actually consistent with the purpose of control in that they both aim to design systems using richly structured perceptions to execute planning and control strategies that adequately adapt to changing environments. The robust trajectory tracking control of intricate mechanical systems presents a challenging problem that necessitates effective control methods. In this paper, we propose a novel nonlinear control strategy based on deep reinforcement learning to solve the trajectory tracking problem of a 3-degree-of-freedom (3-DOF) control moment gyroscope (CMG). First, dynamic modeling of the 3-DOF CMG is used as a policy solver for the reinforcement learning training environment, and transfer learning is employed to bridge the reality gap. Then, the hyperparameters and reward functions of the neural network are optimized using the asynchronous successive halving algorithm. Ultimately, the twin delay depth determination policy gradient algorithm is trained in simulation to yield an agent capable of tracking user-defined trajectory routes as a nonlinear controller for the system. Both simulation and experimental results show that the proposed method works well for both high-frequency and low-frequency varying trajectory tracking control, and that the proposed method has better response speed and robustness than classic linear parameter-varying control methods and the state-of-the-art nonlinear parameter-varying method and the neural network-based feedback linearization adaptive control method.},
  archive      = {J_NCA},
  author       = {Xiong, Yan and Liu, Siyuan and Zhang, Jianxiang and Xu, Mingxing and Guo, Liang},
  doi          = {10.1007/s00521-023-09341-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6441-6465},
  shortjournal = {Neural Comput. Appl.},
  title        = {Nonlinear control strategies for 3-DOF control moment gyroscope using deep reinforcement learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel lightweight CNN-based error-reduced carry prediction
approximate full adder design for multimedia applications. <em>NCA</em>,
<em>36</em>(12), 6421–6440. (<a
href="https://doi.org/10.1007/s00521-023-09316-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximation approaches have been developed for very large-scale integration architecture to limit power consumption and increase effective throughput. The full adder (FA) and block-based designs are the approximate adder designs widely used in the existing techniques to accelerate the additions by partitioning a long carry propagation chain. However, these techniques require more power and area than the standard FA-based techniques. To overcome this issue, this paper presents an error-reduced carry prediction approximate full adder (ERCPAA) technique to achieve faster additions and performance by adding a constant truncation mechanism with an error reduction strategy. Deep learning and neural network technology had made great progress in recent years for field programmable gate array implementation and real-time object detection. It is essential to maintain high accuracy rates in image processing applications, as any errors introduced during the processing can significantly impact the quality of the output image and impact the hardware implementation. Therefore, we propose an ERCPAA that utilizes a lightweight convolutional neural network (ERCPAA–lightweight CNN) to fit well in a fixed-point CNN accelerator architecture. A lightweight CNN that is both thin (with fewer feature maps per layer) and deep (four layers) with just one fully connected hidden layer can enable faster training while achieving higher accuracy. In addition, in a few positions of the higher-order bits of the incorrect part, a full adder (FA) cell is used to simplify the traditional one-bit FA cell, creating an approximate summation and carry. The proposed method is verified by randomly selecting specific images from the Fruit 360, ImageNet, and the Caltech 256 Image Dataset. The proposed model offers an normalized mean error distance, error rate, and mean relative error distance values of 0.154, 6.55%, and 4.6E-4. The recognition accuracy of the proposed model in the ImageNet database is 96% with an execution time of 1420 µs.},
  archive      = {J_NCA},
  author       = {Nishanth, R. and Sulochana, C. Helen},
  doi          = {10.1007/s00521-023-09316-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6421-6440},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel lightweight CNN-based error-reduced carry prediction approximate full adder design for multimedia applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VITALT: A robust and efficient brain tumor detection system
using vision transformer with attention and linear transformation.
<em>NCA</em>, <em>36</em>(12), 6403–6419. (<a
href="https://doi.org/10.1007/s00521-023-09306-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor detection and classification are crucial steps in evaluating life-threatening abnormal tissues to provide appropriate treatment plans. For clinical assessment, Magnetic resonance imaging (MRI) is normally used because of its excellent quality and lack of ionizing radiation. However, as the volume of the data grows, manual processing of MRI images becomes expensive, time-taking, and error prone. Also, traditional automated detection systems struggle to handle complex image patterns, leading to reduced classification accuracy. So, this paper designs a reliable and effective brain tumor detection mechanism as a solution to these problems. The proposed &quot;Vision Transformer with Attention and Linear Transformation module (VITALT)&quot; system is a combination of modules such as Vision Transformer (ViT), Split bidirectional feature pyramid network (S-BiFPN), linear transformation module (LTM) and soft-quantization that effectively extracts features from complex brain structures. At first, to mitigate the training inaccuracies developed by dimension and quality constraints, the preprocessing steps such as resizing and normalization are executed. The preprocessed images are divided into number of patches and embedded into high-dimensional vector to provide more compact image representation. Subsequently, the global and local features in the image are captured through ViT module by learning the relationship between image patches. The multi-scale spatial features formed are then fused using S-BiFPN to increase the accuracy of prediction. By using LTM to improve the linear expression capability of the design, the characteristics that are most important for the classification of brain tumors are discovered. Also, soft quantization is used to minimize memory footprint and minimize quantization errors in detection. Finally, the head module with set of fully connected layers accurately classifies different classes of brain tumors. The experimental analysis conducted using four different benchmark brain tumor datasets shows the viability and reliability of the suggested VITALT system in predicting brain tumors, as measured by multiple evaluation metrics. The proposed system achieves classification accuracy of 99.08% for Dataset A, 98.97% for Dataset B, 98.82% for Dataset C and 99.15% for Dataset D. A high level of classification accuracy attained by the suggested system highlights its potential in medical imaging applications and its ability to contribute to improved surgical treatments.},
  archive      = {J_NCA},
  author       = {Poornam, S. and Angelina, J. Jane Rubel},
  doi          = {10.1007/s00521-023-09306-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6403-6419},
  shortjournal = {Neural Comput. Appl.},
  title        = {VITALT: A robust and efficient brain tumor detection system using vision transformer with attention and linear transformation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of intelligent music generation systems.
<em>NCA</em>, <em>36</em>(12), 6381–6401. (<a
href="https://doi.org/10.1007/s00521-024-09418-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of ChatGPT, the public’s perception of AI-generated content has begun to reshape. Artificial intelligence has significantly reduced the barrier to entry for non-professionals in creative endeavors, enhancing the efficiency of content creation. Recent advancements have seen significant improvements in the quality of symbolic music generation, which is enabled by the use of modern generative algorithms to extract patterns implicit in a piece of music based on rule constraints or a musical corpus. Nevertheless, existing literature reviews tend to present a conventional and conservative perspective on future development trajectories, with a notable absence of thorough benchmarking of generative models. This paper provides a survey and analysis of recent intelligent music generation techniques, outlining their respective characteristics and discussing existing methods for evaluation. Additionally, the paper compares the different characteristics of music generation techniques in the East and West as well as analysing the field’s development prospects.},
  archive      = {J_NCA},
  author       = {Wang, Lei and Zhao, Ziyi and Liu, Hanwei and Pang, Junwei and Qin, Yi and Wu, Qidi},
  doi          = {10.1007/s00521-024-09418-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6381-6401},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of intelligent music generation systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning applications in detection and diagnosis of
urology cancers: A systematic literature review. <em>NCA</em>,
<em>36</em>(12), 6355–6379. (<a
href="https://doi.org/10.1007/s00521-023-09375-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning integration in cancer diagnosis enhances accuracy and diagnosis speed which helps clinical decision-making and improves health outcomes. Despite all these benefits in cancer diagnosis, the present AI models in urology cancer diagnosis have not been sufficiently reviewed systematically. This paper reviews the artificial intelligence approaches used in cancer diagnosis, prediction, and treatment of urology cancer. AI models and their applications in urology subspecialties are evaluated and discussed. The Scopus, Microsoft Academic and PubMed/MEDLINE databases were searched in November 2022 using the terms “artificial intelligence”, “neural network”, “machine learning,” or “deep learning” combined with the phrase “urology cancers”. The search was limited to publications published within the previous 20 years to identify cutting-edge deep-learning applications published in English. Irrelevant review articles and publications were eliminated. The included research involves two kinds of research analysis: quantitative and qualitative. 48 articles were included in this survey. 25 studies proposed several approaches for prostate cancers, while 15 were for bladder cancers. 8 studies discussed renal cell carcinoma and kidney cancer. The models presented to detect urology cancers have achieved high detection accuracy (77–95%). Deep learning approaches that use convolutional neural networks have achieved the highest accuracy among other techniques. Although it is still progressing, the development of AI models for urology cancer detection, prediction, and therapy has shown significant promise. Additional research is required to employ more extensive, higher-quality, and more recent datasets to the clinical performance of the proposed AI models in urology cancer applications.},
  archive      = {J_NCA},
  author       = {Lubbad, M. and Karaboga, D. and Basturk, A. and Akay, B. and Nalbantoglu, U. and Pacal, I.},
  doi          = {10.1007/s00521-023-09375-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6355-6379},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning applications in detection and diagnosis of urology cancers: A systematic literature review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: A review of dialogue systems: Current trends
and future directions. <em>NCA</em>, <em>36</em>(12), 6353. (<a
href="https://doi.org/10.1007/s00521-024-09416-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Algherairy, Atheer and Ahmed, Moataz},
  doi          = {10.1007/s00521-024-09416-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6353},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: a review of dialogue systems: current trends and future directions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A review of dialogue systems: Current trends and future
directions. <em>NCA</em>, <em>36</em>(12), 6325–6351. (<a
href="https://doi.org/10.1007/s00521-023-09322-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in dialogue systems have recently been made in various fields as an easy to use and inexpensive option to support or replace workers. However, developing dialogue systems that produce satisfactory responses to user queries on par with human workers still presents significant challenges. The primary purpose of this review is to analyse prominent studies on dialogue systems in the literature. Comparison frameworks were developed to perform an in-depth analysis in terms of approaches, data sets and evaluation metrics. Unlike previous reviews, we thoroughly examined how reinforcement learning is applied to dialogue systems. We also analysed studies attempting to interleave the two main types of dialogue systems (i.e. open-domain dialogue and task-oriented dialogue). We present some open-source platforms for developing dialogue systems. Finally, we identified research gaps and discussed potential research directions.},
  archive      = {J_NCA},
  author       = {Algherairy, Atheer and Ahmed, Moataz},
  doi          = {10.1007/s00521-023-09322-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6325-6351},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of dialogue systems: Current trends and future directions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoolGust: Knowledge representation learning with commonsense
knowledge guidelines and constraints. <em>NCA</em>, <em>36</em>(12),
6305–6323. (<a
href="https://doi.org/10.1007/s00521-024-09423-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning serves as a crucial link between knowledge graphs and neural models. Knowledge graphs are typical symbolic models and require representation learning to obtain vector representations of entities and relationships. Existing efforts focus more on the structural characteristics of knowledge itself, such as the connections between entities and relationships under the same type of knowledge, neglecting the potential value of commonsense knowledge in guiding and constraining. In fact, commonsense knowledge implies the belonging tendency of entities in triplets. In this paper, we propose a novel knowledge representation learning model, CoolGust, which is guided and constrained by commonsense knowledge and can effectively utilize commonsense knowledge to seamlessly guide the belonging relationships of entities and enhance the model performance. Commonsense knowledge is essential for guiding humans to make wise decisions in unknown scenarios. We find that by utilizing commonsense knowledge as guides and constraints for entities, hidden knowledge entanglement structures can be formed in complex network applications, thereby constructing decisions consistent with situational logic. To verify the effectiveness of our model, we conducted experimental verification of two tasks, link prediction, and triple classification, on three public datasets. The experimental results demonstrate the effectiveness and advancedness of our proposed method.},
  archive      = {J_NCA},
  author       = {Wang, Chao},
  doi          = {10.1007/s00521-024-09423-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6305-6323},
  shortjournal = {Neural Comput. Appl.},
  title        = {CoolGust: Knowledge representation learning with commonsense knowledge guidelines and constraints},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of small object detection based on deep learning.
<em>NCA</em>, <em>36</em>(12), 6283–6303. (<a
href="https://doi.org/10.1007/s00521-024-09422-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection is widely used in a variety of fields such as automatic driving, UAV-based object detection, and aerial image detection. However, small objects carry limited information, making it difficult for detectors to detect small objects. In recent years, the development of deep learning has significantly improved the performance of small object detection. This paper provides a comprehensive review to help further the development of small target detection. We summarize the challenges related to small object detection and analyze solutions to these challenges in existing works, including integrating the feature at different layers, enriching available information, balancing the number of positive and negative samples for small objects, and increasing sufficient small object instances. We discuss related methods developed in three application areas, including automatic driving, UAV search and rescue, and aerial image detection. In addition, we thoroughly analyze the performance of typical small object detection methods on popular datasets. Finally, based on the comprehensive review of small object detection methods, we point out possible research directions for future studies.},
  archive      = {J_NCA},
  author       = {Wei, Wei and Cheng, Yu and He, Jiafeng and Zhu, Xiyue},
  doi          = {10.1007/s00521-024-09422-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6283-6303},
  shortjournal = {Neural Comput. Appl.},
  title        = {A review of small object detection based on deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Syntax-guided question generation using prompt learning.
<em>NCA</em>, <em>36</em>(12), 6271–6282. (<a
href="https://doi.org/10.1007/s00521-024-09421-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question generation (QG) aims to generate natural questions from relevant input. Existing state-of-the-art QG approaches primarily leverage pre-trained language models (PLMs) to encode the deep semantics within the input. Meanwhile, studies show that the input’s dependency parse tree (referred to as syntactic information) is promising in improving NLP-oriented tasks. However, how to incorporate syntactic information in PLMs to guide a QG process effectively still needs to be settled. This paper introduces a syntax-guided sentence-level QG model based on prompt learning. Specifically, we model the syntactic information by utilizing soft prompt learning, jointly considering the syntactic information from a constructed dependency parse graph and PLM to guide question generation. We conduct experiments on two benchmark datasets, SQuAD1.1 and MS MARCO. Experiment results show that our model exceeded both automatic and human evaluation metrics compared with mainstream approaches. Moreover, our case study shows that the model can generate more fluent questions with richer information.},
  archive      = {J_NCA},
  author       = {Hou, Zheheng and Bi, Sheng and Qi, Guilin and Zheng, Yuanchun and Ren, Zuomin and Li, Yun},
  doi          = {10.1007/s00521-024-09421-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {12},
  pages        = {6271-6282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Syntax-guided question generation using prompt learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adapting transfer learning models to dataset through pruning
and avg-TopK pooling. <em>NCA</em>, <em>36</em>(11), 6257–6270. (<a
href="https://doi.org/10.1007/s00521-024-09484-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on efficiently adapting transfer learning models to address the challenges of creating customized deep learning models for specific datasets. Designing a model from scratch can be time-consuming and complex due to factors like model complexity, size, and dataset structure. To overcome these obstacles, a novel approach is proposed using transfer learning models. The proposed method involves identifying relevant layers in transfer learning models and removing unnecessary ones using a layer-based variance pruning technique. This results in the creation of new models with improved computational efficiency and classification performance. By streamlining the models through layer-based variance pruning, the study achieves enhanced accuracy and faster computation. Experiments were conducted using the COVID-19 dataset and well-known transfer learning models, including InceptionV3, ResNet50V2, DenseNet201, VGG16, and Xception to validate the approach. Among these models, the variance-based layer pruning technique was applied to InceptionV3 and DenseNet201, yielding the best results. When these pruned models were combined with the new pooling layer, Avg-TopK, the proposed method achieved an outstanding image classification accuracy of 99.3%. Comparisons with previous models and literature studies indicate that the proposed approach outperforms existing methods, showcasing state-of-the-art performance. This high-performance approach provides great potential for diagnosing COVID-19 and monitoring disease progression, especially on hardware-limited devices. By leveraging transfer learning models, pruning, and efficient pooling techniques, the study presents a promising strategy for tackling challenges in custom model design, leading to exceptional results in such as image classification and segmentation tasks. The proposed methodology holds the potential to yield exceptional outcomes across a spectrum of tasks, encompassing disciplines such as image classification and segmentation.},
  archive      = {J_NCA},
  author       = {OZDEMIR, Cuneyt},
  doi          = {10.1007/s00521-024-09484-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6257-6270},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adapting transfer learning models to dataset through pruning and avg-TopK pooling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning model for credit card fraud detection
with data balancing techniques. <em>NCA</em>, <em>36</em>(11),
6231–6256. (<a
href="https://doi.org/10.1007/s00521-023-09410-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, credit card transaction fraud has resulted in massive losses for both consumers and banks. Subsequently, both cardholders and banks need a strong fraud detection system to reduce cardholder losses. Credit card fraud detection (CCFD) is an important method of fraud prevention. However, there are many challenges in developing an ideal fraud detection system for banks. First off, due to data security and privacy concerns, various banks and other financial institutions are typically not permitted to exchange their transaction datasets. These issues make traditional systems find it difficult to learn and detect fraud depictions. Therefore, this paper proposes federated learning for CCFD over different frameworks (TensorFlow federated, PyTorch). Second, there is a significant imbalance in credit card transactions across all banks, with a small percentage of fraudulent transactions outweighing the majority of valid ones. In order to demonstrate the urgent need for a comprehensive investigation of class imbalance management techniques to develop a powerful model to identify fraudulent transactions, the dataset must be balanced. In order to address the issue of class imbalance, this study also seeks to give a comparative analysis of several individual and hybrid resampling techniques. In several experimental studies, the effectiveness of various resampling techniques in combination with classification approaches has been compared. In this study, it is found that the hybrid resampling methods perform well for machine learning classification models compared to deep learning classification models. The experimental results show that the best accuracy for the Random Forest (RF); Logistic Regression; K-Nearest Neighbors (KNN); Decision Tree (DT), and Gaussian Naive Bayes (NB) classifiers are 99,99%; 94,61%; 99.96%; 99,98%, and 91,47%, respectively. The comparative results show that the RF outperforms with high performance parameters (accuracy, recall, precision and f score) better than NB; RF; DT and KNN. RF achieve the minimum loss values with all resampling techniques, and the results, when utilizing the proposed models on the entire skewed dataset, achieved preferable outcomes to the unbalanced dataset. Furthermore, the PyTorch framework achieves higher prediction accuracy for the federated learning model than the TensorFlow federated framework but with more computational time.},
  archive      = {J_NCA},
  author       = {Abdul Salam, Mustafa and Fouad, Khaled M. and Elbably, Doaa L. and Elsayed, Salah M.},
  doi          = {10.1007/s00521-023-09410-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6231-6256},
  shortjournal = {Neural Comput. Appl.},
  title        = {Federated learning model for credit card fraud detection with data balancing techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The efficiency of hybrid intelligent models to evaluate the
effect of the size of sand and clay metakaolin content on various
compressive strength ranges of cement mortar. <em>NCA</em>,
<em>36</em>(11), 6209–6229. (<a
href="https://doi.org/10.1007/s00521-023-09384-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to create a reliable model for estimating the compressive strength of cement mortar amended with metakaolin (MK) ingredients and predicting the impact of MK and the maximum diameter of the fine material (MDA) on the compressive strength of the mortar. This study collected 230 datasets from the research with various percentages and curing times. The water-to-binder ratio (w/b) ranges between 0.36 and 0.6 (by the weight of dry cement), sand to-binder ratio of 2–3, the metakaolin content of 0–30%, and the curing time is up to 90 days. Artificial neural network (ANN) models, nonlinear regression (NLR), multi-expression programming (MEP), and multivariate regression spline (MARS) models are the models. The coefficient of determination (R2), root-mean-squared error (RMSE), mean absolute error (MAE), scatter index (SI), standard deviation, and correlation coefficient between measured and predicted compressive strength are some of the evaluation tools that are used to measure the performance of the suggested models. The results show that the MARS model performs better with a high R2 and low RMSE and MAE than MEP, NLR, and ANN models. Based on the dispersion index, the MARS, MEP, and ANN, they have made good predictions about the compressive strength. According to the parametric analysis of MK and MDA, the ANN model effectively anticipated the impact of the previously mentioned model inputs and the ideal MK concentration for enhancing both long- and short-term compressive strength.},
  archive      = {J_NCA},
  author       = {Abdalla, Aso A. and Mohammed, Ahmed Salih},
  doi          = {10.1007/s00521-023-09384-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6209-6229},
  shortjournal = {Neural Comput. Appl.},
  title        = {The efficiency of hybrid intelligent models to evaluate the effect of the size of sand and clay metakaolin content on various compressive strength ranges of cement mortar},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Use of artificial neural networks in architecture:
Determining the architectural style of a building with a convolutional
neural networks. <em>NCA</em>, <em>36</em>(11), 6195–6207. (<a
href="https://doi.org/10.1007/s00521-023-09395-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discussion of &quot;can machines think?&quot; which started with the invention of the modern computer, brought along the question of &quot;can machines design?&quot; by researchers in the design field. These developments in information technologies have also affected the architecture. Artificial intelligence applications are encountered in many areas such as pricing estimation, energy conservation security systems of buildings, ventilation systems, user-oriented interactive design solutions, computer-aided programs used in the plan production phase and design process. When the literature on artificial intelligence applications in the architecture is reviewed, it can be seen that it generally includes shape grammars, graph theory, decision trees, constraint-based models, machine learning methods, RNN (Recursive Neural Networks), CNN (Convolutional Neural Network) and GAN (Generative Adversarial Network) algorithms. In this study, the use of artificial intelligence algorithms in architecture was examined, and an example was designed to determine the architectural structures of different periods by using CNN (Convolutional Neural Network). In the study, the open source TensorFlow library developed by Google and the Python programming language were used. Employing a statistical approach and utilizing convolutional neural networks (CNNs), a study has successfully classified the current flow patterns of buildings based on datasets comprising facades of Gothic, Modern, and Deconstructivist architectural styles. The findings demonstrate the efficacy of CNNs in accurately distinguishing the intricate details of diverse architectural styles. Recognizing elements from different periods using the CNN algorithm can examine not only individual buildings but also the relationship of buildings with their environments. It can also gain an important place in the field of conservation of the architectural discipline. The historical processes, aesthetic features and changes of protected buildings can be learned with the CNN algorithm and can guide restoration decisions. As a result of the study, the employed CNN-based model can correctly classify structures with 84.66% accuracy rate.},
  archive      = {J_NCA},
  author       = {Cantemir, Ece and Kandemir, Ozlem},
  doi          = {10.1007/s00521-023-09395-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6195-6207},
  shortjournal = {Neural Comput. Appl.},
  title        = {Use of artificial neural networks in architecture: Determining the architectural style of a building with a convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modelling and simulation of assisted hospital evacuation
using fuzzy-reinforcement learning based modelling approach.
<em>NCA</em>, <em>36</em>(11), 6165–6194. (<a
href="https://doi.org/10.1007/s00521-023-09389-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Available hospital evacuation simulation models usually focus on the movement of the evacuees while ignoring the crucial behavioural factors of the evacuees’ which impact the simulation results. For instance, the issue of patient prioritization behaviour during evacuation simulation is often overlooked and oversimplified in these models. Furthermore, to control the movement of the evacuees, almost all these models utilize rule-based artificial intelligence to develop navigation systems, which sometimes do not guarantee realistic and optimal movement behaviour. This research aims to address these problems by modelling feasible and novel solutions. In this research, we propose to develop a hospital evacuation simulation model which utilizes a hybrid of fuzzy logic and reinforcement learning to simulate assisted hospital evacuation using the Unity3D game engine. We propose a novel and effective approach to model patient prioritization using a fuzzy logic controller; a reinforcement learning based navigation system to tackle the issues related to the rule-based navigation system by proposing novel reward formulation, observation formulation, action formulation and training procedure. The results and findings exhibited by the proposed model are found to be in line with the available literature. For instance, available literature suggests that an increased number of patients increases the evacuation time, and an increased number of staff or exits decreases the evacuation time. The proposed model also demonstrates similar findings. Moreover, the proposed navigation system is found to take a “near shortest distance” to reach the target as the mean difference between “shortest vector distance” and “distance covered” is approximately 1.73 m. The proposed simulation model simulates the repeated patient collection more realistically and can be used to estimate the Required Safe Egress Time, which enables the establishment of safety performance levels. The evacuation performance of different scenarios can be compared using the proposed model. This research can play a vital role in future developments of hospital evacuation simulation models.},
  archive      = {J_NCA},
  author       = {Abir, Intiaz Mohammad and Mohd Ibrahim, Azhar and Toha, Siti Fauziah and Mohd Romlay, Muhammad Rabani},
  doi          = {10.1007/s00521-023-09389-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6165-6194},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modelling and simulation of assisted hospital evacuation using fuzzy-reinforcement learning based modelling approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Secure defense control for memristive recurrent neural
networks under denial-of-service attacks with quantized sampled-data
signals. <em>NCA</em>, <em>36</em>(11), 6147–6163. (<a
href="https://doi.org/10.1007/s00521-023-09370-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the secure defense control problem for memristive recurrent neural networks (MRNNs) under denial-of-service (DoS) attacks. Based on quantizer and logical processor techniques, a new secure defense control strategy is designed to maintain the performance of MRNNs subject to DoS attacks. The secure defense control strategy can not only effectively capture information about the dwell time of each DoS attack, but also can effectively reduce the amount of data to be transmitted and save communication resources. By constructing a Lyapunov–Krasovskii functional that depends on sampled information at $$t_k$$ and $$t_{k+1}$$ , some new stability criteria are derived for MRNNs under DoS attacks. By solving a set of LMIs, the control gain of the quantized sampled-data controller can be obtained. Thus, the corresponding secure quantized sampled-data controller is designed for MRNNs under DoS attacks. When there is no quantizer, the secure defense control problem for MRNNs under DoS attacks is also studied. Two numerical examples are given to confirm the effectiveness of the main results.},
  archive      = {J_NCA},
  author       = {Dong, Di and Zhang, Ruimei and Cheng, Yunjia and Zhang, Lei and Xie, Xiangpeng and Xiao, Jianying},
  doi          = {10.1007/s00521-023-09370-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6147-6163},
  shortjournal = {Neural Comput. Appl.},
  title        = {Secure defense control for memristive recurrent neural networks under denial-of-service attacks with quantized sampled-data signals},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated fuzzy and deep learning model for identification
of coconut maturity without human intervention. <em>NCA</em>,
<em>36</em>(11), 6133–6145. (<a
href="https://doi.org/10.1007/s00521-023-09402-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maturity of the coconut is judged manually based on the shape, color, weight, shaking sound, timeframe, etc. Currently, there is not much research being done to find solutions involving the latest techniques including fuzzy, machine learning and deep learning techniques for identifying maturity of the coconuts without human intervention. These techniques have significant challenges in detecting the multiple classes in coconut maturity due to difference in size and shape of the coconuts and the complex nature of their backgrounds as each coconut tree and each coconut bunch are unique. In this research work, we propose an integrated fuzzy and deep learning model (IFDM) to identify the maturity classes of coconut. Deep learning-based Mask R-CNN is used to classify and segment the coconut images. The combined fuzzy system (CFS) extracts the color, shape and scratch features with a fuzzy extraction technique for each feature. A probability-based fuzzy integration (PFI) method integrates the output from each fuzzy extraction to classify the coconuts. Decision-making probability (DMP) model combines the class probability of the probability-based fuzzy integration method and Mask R-CNN model to obtain the final coconut maturity class. The dataset with 10,000 images is used for training. Two test datasets, the first one containing 1754 real-time coconut images and the second containing 1000 cropped coconut images from the background, are used for testing. Using the proposed learning model in real time, an accuracy of 86.3% is obtained in classifying the maturity classes of coconuts. While integrating the models like Yolo v3, Yolo v5, Faster R-CNN, random forest and KNN with combined fuzzy system, Mask R-CNN performed better in terms of accuracy.},
  archive      = {J_NCA},
  author       = {Megalingam, Rajesh Kannan and Manoharan, Sakthiprasad Kuttankulangara and Maruthababu, Ragavendra Balasubramani},
  doi          = {10.1007/s00521-023-09402-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6133-6145},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrated fuzzy and deep learning model for identification of coconut maturity without human intervention},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A predictive analytics framework for sensor data using time
series and deep learning techniques. <em>NCA</em>, <em>36</em>(11),
6119–6132. (<a
href="https://doi.org/10.1007/s00521-023-09398-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT devices convert billions of objects into data-generating entities, enabling them to report status and interact with their surroundings. This data comes in various formats, like structured, semi-structured, or unstructured. In addition, it can be collected in batches or in real time. The problem now is how to benefit from all of this data gathered by sensing and monitoring changes like temperature, light, and position. In this paper, we propose a predictive analytics framework constructed on top of open-source technologies such as Apache Spark and Kafka. The framework focuses on forecasting temperature time series data using traditional and deep learning predictive analytics methods. The analysis and prediction tasks were performed using Autoregressive Integrated Moving Average (ARIMA), Seasonal Autoregressive Integrated Moving Average (SARIMA), Long Short-Term Memory (LSTM), and a novel hybrid model based on Convolution Neural Network (CNN) and LSTM. The purpose of this paper is to determine whether and how recently developed deep learning-based models outperform traditional algorithms in the prediction of time series data. The empirical studies conducted and reported in this paper demonstrate that deep learning-based models, specifically LSTM and CNN-LSTM, exhibit superior performance compared to traditional-based algorithms, ARIMA and SARIMA. More specifically, the average reduction in error rates obtained by LSTM and CNN-LSTM models were substantial when compared to other models indicating the superiority of deep learning. Moreover, the CNN-LSTM-based deep learning model exhibits a higher degree of closeness to the actual values when compared to the LSTM-based model.},
  archive      = {J_NCA},
  author       = {Selmy, Hend A. and Mohamed, Hoda K. and Medhat, Walaa},
  doi          = {10.1007/s00521-023-09398-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6119-6132},
  shortjournal = {Neural Comput. Appl.},
  title        = {A predictive analytics framework for sensor data using time series and deep learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-driven approach for high accurate spatiotemporal
precipitation estimation. <em>NCA</em>, <em>36</em>(11), 6099–6118. (<a
href="https://doi.org/10.1007/s00521-023-09397-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precipitation is a fundamental factor affecting many fields, including freshwater reservation, flood warning and prevention, agriculture, and hydropower planning. Observation-based precipitation data usually come from two primary sources, namely gauges and satellite images. The former provides high reliability but sparse coverage, while the latter offers fine-grained data but is still inaccurate. There have been several efforts to estimate precipitation, including mathematical and probabilistic models and machine learning-based techniques. All existing solutions consider the target problem as a satellite data calibration with gauge data as complementary information. However, this approach fails to provide accurate predictive results due to the sparsity of gauges and significant errors in satellite data. This paper presents a novel precipitation estimating method that highlights the importance of gauge data, the most trustworthy data source. To be more precise, we formulate the precipitation estimation issue as a spatial prediction task with the goal of predicting rainfall data for non-monitoring locations using gauge data at the monitored sites. To this end, we propose a data-driven approach that exploits the encoder–decoder architecture, graph neural network, and the multimodal data fusion strategy. Specifically, we design an encoder that leverages a graph neural network for capturing the spatial relationship among the gauges. Meanwhile, the decoder exploits the convolutional networks to learn the temporal correlation within the historical data. Finally, we integrate satellite images and meteorological information using a multimodal data fusion based on a multilayer perceptron to enhance prediction accuracy. The experimental results show that our proposed model increases the estimation accuracy from 24.3 to 65.2% compared to the state-of-the-art.},
  archive      = {J_NCA},
  author       = {Pham, Minh Khiem and Nguyen, Phi Le and Vu, Viet Hung and Truong, Thao Nguyen and Vo-Van, Hoa and Ngo-Duc, Thanh},
  doi          = {10.1007/s00521-023-09397-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6099-6118},
  shortjournal = {Neural Comput. Appl.},
  title        = {A data-driven approach for high accurate spatiotemporal precipitation estimation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predicting triplanar and bidirectional movements for a
transtibial prosthesis for rehabilitation using intelligent neural
networks. <em>NCA</em>, <em>36</em>(11), 6085–6098. (<a
href="https://doi.org/10.1007/s00521-023-09393-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, artificial neural networks (NN) are applied to the design of a transtibial prosthesis to adapt triplanar and bidirectional movements of human locomotion for rehabilitation. NN-based control is used because the prosthesis system is highly nonlinear and has variables with too many uncertainties caused by variations in ankle movements, weight damping, dorsiflexion, and flexion in the amputation area due to biological stimuli. To identify and detect these movements in the transtibial prosthesis, myoelectric signals are used that determine its position and adapt its trajectory through linear and rotary actuators. The input and desired parameters for the NN controller and the backpropagation algorithm are obtained based on the movements of the human ankle and foot based on their trajectory. The prototype is manufactured from different types of plastic using a 3D grapher, which can perform the main stages of human locomotion due to the learning carried out by the NN, reducing the risk of falls, and having a more comfortable and natural gait cycle in the rehabilitation of people. From the output response obtained from the NN controller, only a time delay is obtained without overshoot terms, and the trajectory tracking is adjusted. Simulation and experimental results show that the proposed NN-based control system can ensure the stability of the system and maintain good tracking of human locomotion.},
  archive      = {J_NCA},
  author       = {de la Cruz-Alejo, Jesus and Lobato-Cadena, J. Antonio and Arce-Vázquez, M. Belem and Mora-Ortega, Agustin},
  doi          = {10.1007/s00521-023-09393-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6085-6098},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predicting triplanar and bidirectional movements for a transtibial prosthesis for rehabilitation using intelligent neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ANN-based deep collocation method for natural convection in
porous media. <em>NCA</em>, <em>36</em>(11), 6067–6083. (<a
href="https://doi.org/10.1007/s00521-023-09385-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A deep collocation method (DCM) is proposed for studying the natural convection phenomenon in the porous media (NCPM). The buoyancy-driven convection analysis inside the porous media is a complex process governed by dynamical conservation laws. Furthermore, these conservation laws involve complex nonlinear governing equations, which are required special computational techniques in well-known numerical methods like finite element method (FEM), finite difference method (FDM), finite volume method (FVM), and others. Such numerical schemes often face computational limitations like mesh generation, dimensionality limitations, increased computation errors for complex domains, and challenges in modeling physics. This research employs an unsupervised deep learning (DL) approach to address and resolve the typical computational challenges encountered in traditional numerical methods when dealing with natural convection in complex porous enclosures. In contrast to mesh-based numerical methods, the computational procedure in the DL approach involves domain and boundary discretization, followed by the random sampling of collocation points throughout the entire physical domain and its boundaries. Furthermore, a loss function is defined based on the governing differential equations and boundary conditions, which are minimized at the collocation points to achieve the desired solution. A combination of gradient-based optimizers is deployed to obtain a better set of parameter values using the backpropagation algorithm. The entire setup of the feedforward neural network is trained to approximate the solution with acceptable accuracy. The study explores four configurations of porous enclosures for a nonlinear mathematical model of natural convection in porous media, with various combinations of Neumann and Dirichlet boundary conditions. Additionally, the results from the mesh-based FEM are chosen as reference data to validate the consistency and accuracy of the DCM results. In all cases, the DCM results exhibit excellent agreement with the FEM results.},
  archive      = {J_NCA},
  author       = {Kumar, Sumant and Kumar, B. V. Rathish and Murthy, S. V. S. S. N. V. G. Krishna},
  doi          = {10.1007/s00521-023-09385-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6067-6083},
  shortjournal = {Neural Comput. Appl.},
  title        = {ANN-based deep collocation method for natural convection in porous media},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Image recoloring for color vision deficiency compensation
using swin transformer. <em>NCA</em>, <em>36</em>(11), 6051–6066. (<a
href="https://doi.org/10.1007/s00521-023-09367-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People with color vision deficiency (CVD) have difficulty in distinguishing differences between colors. To compensate for the loss of color contrast experienced by CVD individuals, a lot of image recoloring approaches have been proposed. However, the state-of-the-art methods suffer from the failures of simultaneously enhancing color contrast and preserving naturalness of colors [without reducing the Quality of Vision (QOV)], high computational cost, etc. In this paper, we propose an image recoloring method using deep neural network, whose loss function takes into consideration the naturalness and contrast, and the network is trained in an unsupervised manner. Moreover, Swin transformer layer, which has long-range dependency mechanism, is adopted in the proposed method. At the same time, a dataset, which contains confusing color pairs to CVD individuals, is newly collected in this study. To evaluate the performance of the proposed method, quantitative and subjective experiments have been conducted. The experimental results showed that the proposed method is competitive to the state-of-the-art methods in contrast enhancement and naturalness preservation and has a real-time advantage. The code and model will be made available at https://github.com/Ligeng-c/CVD_swin .},
  archive      = {J_NCA},
  author       = {Chen, Ligeng and Zhu, Zhenyang and Huang, Wangkang and Go, Kentaro and Chen, Xiaodiao and Mao, Xiaoyang},
  doi          = {10.1007/s00521-023-09367-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6051-6066},
  shortjournal = {Neural Comput. Appl.},
  title        = {Image recoloring for color vision deficiency compensation using swin transformer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient utilization of deep learning for the detection of
fabric defects. <em>NCA</em>, <em>36</em>(11), 6037–6050. (<a
href="https://doi.org/10.1007/s00521-023-09137-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fabric inspection system is a sophisticated computer vision system that detects fabric defects, automatically. In recent years, human visual inspection has traditionally been used to detect fabric defects. However, this trend is inaccurate and may be expensive due to the need for highly-trained personnel. This paper describes a deep-learning-based fabric inspection system for detecting fabric defects instead of the dependence on personnel. To find the Region of Interest (RoI) in fabric images, the system depends on a saliency-based region detection technique to localize the defected areas in fabric images. The fabric images are then classified into defect-free and defective images using a Convolutional Neural Network (CNN). Four convolutional layers and four max-pooling layers are arranged in the suggested model. A fully-connected layer and a Softmax activation function are also used in the classification task. The results of the experiments indicate that the proposed system exceeds some other state-of-the-art systems in terms of both quality and robustness. The proposed system achieves an average accuracy of 95.8%. Hence, it can be used in applications related to fabric industry.},
  archive      = {J_NCA},
  author       = {Zahra, Aya and Amin, Mohamed and El-Samie, Fathi E. Abd and Emam, Mahmoud},
  doi          = {10.1007/s00521-023-09137-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6037-6050},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient utilization of deep learning for the detection of fabric defects},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of orbital tumors using convolutional neural
networks. <em>NCA</em>, <em>36</em>(11), 6025–6035. (<a
href="https://doi.org/10.1007/s00521-023-09406-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orbital tumors are the most common eye tumors that affect people all over the world. Early detection prevents the progression to other regions of the eye and the body. Also, early identification and treatment could reduce mortality. A computer-assisted diagnosis (CAD) system to help physicians diagnose tumors is in great demand in ophthalmology. In recent years, deep learning has demonstrated promising outcomes in computer vision systems. This work proposes a CAD system for detecting various forms of orbital tumors using convolutional neural networks. The system has three stages: preprocessing, data augmentation and classification. The proposed system was evaluated on two datasets of magnetic resonance imaging (MRI) images containing 1404 MRI T1-weighted images and 1560 MRI T2-weighted images. The results have shown that the system is capable of detecting and classifying the tumor in each image type, and the recognition rate for the T1-weighted image is 98% and for the T2-weighted image is 97%.},
  archive      = {J_NCA},
  author       = {Allam, Esraa and Salem, Abdel-Badeeh M. and Alfonse, Marco},
  doi          = {10.1007/s00521-023-09406-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6025-6035},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of orbital tumors using convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Customer satisfaction analysis with saudi arabia mobile
banking apps: A hybrid approach using text mining and predictive
learning techniques. <em>NCA</em>, <em>36</em>(11), 6005–6023. (<a
href="https://doi.org/10.1007/s00521-023-09400-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile banking is becoming increasingly popular as a new means of delivering financial services, particularly in places where many people lack access to traditional banking institutions. In the current banking industry, mobile banking software, sometimes known as apps, has largely replaced traditional branch banking services. Consumers’ banking experiences can be greatly enhanced, and bank processes can be simplified, with the advent of mobile banking via apps. Customers’ satisfaction with mobile banking apps has been an important issue in recent research. In addition, the assessment of mobile apps in online banking has gained significant popularity. There have been several studies on customers’ satisfaction with online banking; however, this issue is not widely investigated by machine learning techniques. Specifically, there is no study to investigate customers’ satisfaction with mobile banking apps and evaluate them using a comprehensive set of factors using predictive text mining and machine learning techniques. In this study, we develop a hybrid method using text mining and regression machine learning approaches to evaluate the factors impacting customers’ satisfaction with online banking apps in Saudi Arabia. The factors are discovered from users generated content (UGC) in mobile banking apps using latent Dirichlet allocation (LDA). The customers’ satisfaction is predicted using support vector regression (SVR) and principal component analysis (PCA). The results show that machine learning can be an effective approach to assessing customers’ satisfaction with online banking apps using the factors discovered by text mining from UGC.},
  archive      = {J_NCA},
  author       = {Alrizq, Mesfer and Alghamdi, Abdullah},
  doi          = {10.1007/s00521-023-09400-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {6005-6023},
  shortjournal = {Neural Comput. Appl.},
  title        = {Customer satisfaction analysis with saudi arabia mobile banking apps: A hybrid approach using text mining and predictive learning techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust and compact maximum margin clustering for
high-dimensional data. <em>NCA</em>, <em>36</em>(11), 5981–6003. (<a
href="https://doi.org/10.1007/s00521-023-09388-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of machine learning, clustering has become an increasingly popular research topic due to its critical importance. Many clustering algorithms have been proposed utilizing a variety of approaches. This study focuses on clustering of high-dimensional data using the maximum margin clustering approach. In this paper, two methods are introduced: The first method employs the classical maximum margin clustering approach, which separates data into two clusters with the greatest margin between them. The second method takes cluster compactness into account and searches for two parallel hyperplanes that best fit to the cluster samples while also being as far apart from each other as possible. Additionally, robust variants of these clustering methods are introduced to handle outliers and noise within the data samples. The stochastic gradient algorithm is used to solve the resulting optimization problems, enabling all proposed clustering methods to scale well with large-scale data. Experimental results demonstrate that the proposed methods are more effective than existing maximum margin clustering methods, particularly in high-dimensional clustering problems, highlighting the efficacy of the proposed methods.},
  archive      = {J_NCA},
  author       = {Cevikalp, Hakan and Chome, Edward},
  doi          = {10.1007/s00521-023-09388-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5981-6003},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust and compact maximum margin clustering for high-dimensional data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new semi-supervised clustering algorithm for probability
density functions and applications. <em>NCA</em>, <em>36</em>(11),
5965–5980. (<a
href="https://doi.org/10.1007/s00521-023-09404-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised clustering has gained significant attention from researchers due to its advantages over unsupervised clustering. However, existing studies have predominantly focused on discrete data. This paper pioneers the application of semi-supervised clustering to probability density functions. The proposed algorithm encompasses detailed implementation steps, a convergence proof, and the ability to address computational challenges. The algorithm has been effectively implemented on image data, resulting in the transformation of each image into a probability density function that is representative. In comparison to existing unsupervised algorithms, the efficacy of the proposed algorithm in partitioning and reducing computational costs is demonstrated through numerical examples and applications.},
  archive      = {J_NCA},
  author       = {Nguyen-Trang, Thao and Nguyen-Hoang, Yen and Vo-Van, Tai},
  doi          = {10.1007/s00521-023-09404-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5965-5980},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new semi-supervised clustering algorithm for probability density functions and applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network classification of eigenmodes in the
magnetohydrodynamic spectroscopy code legolas. <em>NCA</em>,
<em>36</em>(11), 5955–5964. (<a
href="https://doi.org/10.1007/s00521-023-09403-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A neural network is employed to address a non-binary classification problem of plasma instabilities in astrophysical jets, calculated with the Legolas code. The trained models exhibit reliable performance in the identification of the two instability types supported by these jets. We also discuss the generation of artificial data and refinement of predictions in general eigenfunction classification problems.},
  archive      = {J_NCA},
  author       = {De Jonghe, J. and Kuczyński, M. D.},
  doi          = {10.1007/s00521-023-09403-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5955-5964},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network classification of eigenmodes in the magnetohydrodynamic spectroscopy code legolas},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rainfall forecasting at long lead times for eastern
australia using artificial neural networks. <em>NCA</em>,
<em>36</em>(11), 5927–5953. (<a
href="https://doi.org/10.1007/s00521-023-09386-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting using artificial neural networks (ANNs) has previously been demonstrated to provide skilful monthly and seasonal rainfall forecasts for many parts of the world, including Australia. However, few rainfall forecasting studies have been reported for lead times beyond 12 months, which can be very useful for flood and drought management, management of dam infrastructure for hydroelectricity generation and for agriculture This investigation examines monthly rainfall forecasts using ANNs for Gympie, Lismore and Brisbane in eastern Australia, locations that have experienced severe flooding associated with very heavy rainfall during the past two decades, as well as periods of drought. These locations have long continuous rainfall records extending back more than 100 years. Monthly rainfall forecasts were generated for these locations for each month using ANNs provided by Neurosolutions Infinity. Input variables comprised both local values of rainfall and temperatures and large-scale climate indices including the Southern Oscillation Index and the Inter-Decadal Pacific Oscillation. The study shows that lead times using ANNs can be extended without significant loss in forecast skill. Average monthly rainfall forecast skill with lead times of 12, 36, 60 and 84 months for the three sites lay in the range 34.8–54.1% relative to climatology. This compares very favourably with reported skill using methods based on physical climate models where skill is often about equivalent to climatology (0%). At longer lead times between 108 and 156 months the skill scores using ANNs decline into the range 10.8–26.6%. The application of ANN forecasting can be very valuable in providing the public with much better warnings of flood and drought conditions than currently given by the Australian Bureau of Meteorology, allowing sufficient lead time to take appropriate action.},
  archive      = {J_NCA},
  author       = {Abbot, John},
  doi          = {10.1007/s00521-023-09386-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5927-5953},
  shortjournal = {Neural Comput. Appl.},
  title        = {Rainfall forecasting at long lead times for eastern australia using artificial neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BERT-CNN based evidence retrieval and aggregation for
chinese legal multi-choice question answering. <em>NCA</em>,
<em>36</em>(11), 5909–5925. (<a
href="https://doi.org/10.1007/s00521-023-09380-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal question answering is an important natural language processing application in the legal domain. The Judicial Examination of Chinese Question Answering dataset is the most prominent and more challenging legal question answering dataset, which offers many multiple-choice legal questions and meta-information about the questions labelled by skilled humans. The current approaches to this task rely solely on pre-trained language models and do not find effective ways to utilise legal knowledge. We propose a retrieving-then-answering framework for the task. Its core is the Graph-Based Evidence Retrieval and Aggregation Network. The network enhances the model’s ability to answer a question by leveraging the legal knowledge relevant to the question and its answer options. The experimental results show that our model outperforms the existing state-of-the-art methods. The results also indicate that our proposed approach to using evidence is practical.},
  archive      = {J_NCA},
  author       = {Li, Yanling and Wu, Jiaye and Luo, Xudong},
  doi          = {10.1007/s00521-023-09380-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5909-5925},
  shortjournal = {Neural Comput. Appl.},
  title        = {BERT-CNN based evidence retrieval and aggregation for chinese legal multi-choice question answering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: Aggregating efficient transformer and CNN
networks using learnable fuzzy measure for breast tumor malignancy
prediction in ultrasound images. <em>NCA</em>, <em>36</em>(11), 5907.
(<a href="https://doi.org/10.1007/s00521-024-09571-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Singh, Vivek Kumar and Mohamed, Ehab Mahmoud and Abdel-Nasser, Mohamed},
  doi          = {10.1007/s00521-024-09571-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5907},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Aggregating efficient transformer and CNN networks using learnable fuzzy measure for breast tumor malignancy prediction in ultrasound images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Aggregating efficient transformer and CNN networks using
learnable fuzzy measure for breast tumor malignancy prediction in
ultrasound images. <em>NCA</em>, <em>36</em>(11), 5889–5905. (<a
href="https://doi.org/10.1007/s00521-023-09363-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated classification of tumors in breast ultrasound (BUS) using deep learning-based methods has achieved remarkable success recently. The initial performance of the individual convolutional neural networks (CNNs) and vision-Transformer have been encouraging. However, artifacts like shadows, low contrast, speckle noise, and variations in tumor shape and sizes impose a kind of uncertainty that limits the performance of existing methods. The interpretation of classification results with a high confidence rate is strongly required in a real clinical setting. This work proposes an efficient method for predicting breast tumor malignancy (EPTM) in BUS images. EPTM comprises heterogeneous deep learning-based feature extraction models and a Choquet integral-based fusion mechanism. Specifically, EPTM incorporates efficient CNN and vision-Transformer methods to build accurate individual breast tumor malignancy prediction models (IMMs). The heterogeneous IMMs ensure complete feature representation of the breast tumors as each CNN or vision-Transformer captures different textural patterns in BUS images. EPTM applies learnable fuzzy measure-based Choquet integral to fuse the predictions of IMMs, where the gray wolf optimizer is employed for generating fuzzy measures. The experimental results confirm the versatility of the EPTM method evaluated on two publicly available datasets, namely UDIAT BUS and Baheya Hospital. EPTM yielded state-of-the-art results with the area under the curve of 0.932 and 0.98, respectively, in the UDIAT BUS and Baheya Hospital datasets. The source code of the proposed model is publicly available at https://github.com/vivek231/breastUS-classification .},
  archive      = {J_NCA},
  author       = {Singh, Vivek Kumar and Mohamed, Ehab Mahmoud and Abdel-Nasser, Mohamed},
  doi          = {10.1007/s00521-023-09363-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5889-5905},
  shortjournal = {Neural Comput. Appl.},
  title        = {Aggregating efficient transformer and CNN networks using learnable fuzzy measure for breast tumor malignancy prediction in ultrasound images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuProNet: Neural profiling networks for sound
classification. <em>NCA</em>, <em>36</em>(11), 5873–5887. (<a
href="https://doi.org/10.1007/s00521-023-09361-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world sound signals exhibit various aspects of grouping and profiling behaviors, such as being recorded from identical sources, having similar environmental settings, or encountering related background noises. In this work, we propose novel neural profiling networks (NeuProNet) capable of learning and extracting high-level unique profile representations from sounds. An end-to-end framework is developed so that any backbone architectures can be plugged in and trained, achieving better performance in any downstream sound classification tasks. We introduce an in-batch profile grouping mechanism based on profile awareness and attention pooling to produce reliable and robust features with contrastive learning. Furthermore, extensive experiments are conducted on multiple benchmark datasets and tasks to show that neural computing models under the guidance of our framework gain significant performance gaps across all evaluation tasks. Particularly, the integration of NeuProNet surpasses recent state-of-the-art (SoTA) approaches on UrbanSound8K and VocalSound datasets with statistically significant improvements in benchmarking metrics, up to 5.92% in accuracy compared to the previous SoTA method and up to 20.19% compared to baselines. Our work provides a strong foundation for utilizing neural profiling for machine learning tasks.},
  archive      = {J_NCA},
  author       = {Tran, Khanh-Tung and Vu, Xuan-Son and Nguyen, Khuong and Nguyen, Hoang D.},
  doi          = {10.1007/s00521-023-09361-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5873-5887},
  shortjournal = {Neural Comput. Appl.},
  title        = {NeuProNet: Neural profiling networks for sound classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stock price prediction: Comparison of different moving
average techniques using deep learning model. <em>NCA</em>,
<em>36</em>(11), 5861–5871. (<a
href="https://doi.org/10.1007/s00521-023-09369-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stock market is changing quickly, and its nonlinear characteristics make stock price prediction difficult. Predicting stock prices is challenging due to several factors, including a company’s financial performance, unforeseen circumstances, general economic conditions, politics, current assets, global situation, etc. Despite these terms, sufficient data are available to identify stock price movement trends using the different technical approaches. In this research, we empirically analyzed long short-term memory (LSTM) networks in the context of time-series prediction. Our investigation leveraged a diverse set of real-world datasets and provided quantitative insights into the performance of LSTMs. Across a spectrum of time-series forecasting tasks, LSTM models demonstrated an impressive mean absolute error (MAE) reduction of 23.4% compared to traditional forecasting methods. Specifically, LSTM achieved an average prediction accuracy of 89.7% in financial market predictions, outperforming baseline models by a significant margin. The aim is to obtain a value that can be compared to the present price of an asset to determine whether it is overvalued or undervalued, which anticipates the price patterns by analyzing previous market information, such as price and volume, compared to this stock analysis approach.},
  archive      = {J_NCA},
  author       = {Billah, Md Masum and Sultana, Azmery and Bhuiyan, Farzana and Kaosar, Mohammed Golam},
  doi          = {10.1007/s00521-023-09369-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5861-5871},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stock price prediction: Comparison of different moving average techniques using deep learning model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient CNN-based low-resolution facial detection from
UAVs. <em>NCA</em>, <em>36</em>(11), 5847–5860. (<a
href="https://doi.org/10.1007/s00521-023-09401-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face detection in UAV imagery requires high accuracy and low execution time for real-time mission-critical operations in public safety, emergency management, disaster relief and other applications. This study presents UWS-YOLO, a new convolutional neural network (CNN)-based machine learning algorithm designed to address these demanding requirements. UWS-YOLO’s key strengths lie in its exceptional speed, remarkable accuracy and ability to handle complex UAV operations. This algorithm presents a balanced and portable solution for real-time face detection in UAV applications. Evaluation and comparison with the state-of-the-art algorithms using standard and UAV-specific datasets demonstrate UWS-YOLO’s superiority. It achieves 59.29% of accuracy compared with 27.43% in a state-of-the-art solution RetinaFace and 46.59% with YOLOv7. Additionally, UWS-YOLO operates at 11 milliseconds, which is 345% faster than RetinaFace and 373% than YOLOv7.},
  archive      = {J_NCA},
  author       = {Diez-Tomillo, Julio and Martinez-Alpiste, Ignacio and Golcarenarenji, Gelayol and Wang, Qi and Alcaraz-Calero, Jose M.},
  doi          = {10.1007/s00521-023-09401-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5847-5860},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient CNN-based low-resolution facial detection from UAVs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of an efficient neural network model for detection
and classification of phase loss faults for three-phase induction motor.
<em>NCA</em>, <em>36</em>(11), 5827–5845. (<a
href="https://doi.org/10.1007/s00521-023-09387-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial applications, three-phase induction motors (IMs) are widely used, and they are subjected to many types of faults. One such fault is the loss of a motor phase caused by a blown fuse, a broken wire, mechanical damage, etc. When this fault occurs during motor operation, it continues to rotate but experiences rapid heating, which can ultimately lead to motor failure. Therefore, various protection devices are available to protect the motor against this fault, but most traditional protection devices do not offer a comprehensive classification of such a fault. So, in this paper, an efficient neural network model is presented for detecting and classifying 12 types of phase loss faults for a three-phase induction motor (IM) based on factors such as the unhealthy phase, fault location, and motor action modes (standstill, transient, and steady-state modes). Thus, the main goal of this work is to determine the motor mode during the fault, the defective phase, and its location to help the maintenance team repair the fault quickly. The system is simulated and tested using the “MATLAB/Simulink” software, employing a feed-forward neural network. The simulation results demonstrate that the proposed network achieves correct detection and classification of phase loss faults within a short time frame from the occurrence of the fault. Therefore, the proposed network model proves to be a simple and reliable solution for integration into the protection system of a three-phase IM, enabling the detection and classification of various phase loss faults.},
  archive      = {J_NCA},
  author       = {Dawood, Ahmed and Hasaneen, B. M. and Abdel-Aziz, A. M.},
  doi          = {10.1007/s00521-023-09387-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5827-5845},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of an efficient neural network model for detection and classification of phase loss faults for three-phase induction motor},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CellSegUNet: An improved deep segmentation model for the
cell segmentation based on UNet++ and residual UNet models.
<em>NCA</em>, <em>36</em>(11), 5799–5825. (<a
href="https://doi.org/10.1007/s00521-023-09374-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell nucleus segmentation is an important method that is widely used in the diagnosis and treatment of many diseases, as well as counting and identifying the cell nucleus. The main challenges when using this method are heterogeneous image intensities in the image, overlapping of cell nuclei, and noise. In order to overcome these difficulties, a hybrid segmentation model with attention block, CellSegUNet, is proposed, inspired by the advantageous points of UNet++  and Residual UNet models. With the proposed attention mechanism, semantic gaps that may occur are prevented by evaluating both horizontal and vertical features together. The serial and parallel connection of the convolutional blocks in the residual modules in the CellSegUNet model prevents data loss. Thus, features with stronger representation ability were obtained. The output layer, which is, especially proposed for the CellSegUNet model, calculated the differences between the data in each layer and the data in the input layer. The output value obtained from the layer level where the lowest value comes from constitutes the output of the whole system. At the same depth level, CellSegUNet versus UNet++  and ResUNet models were compared on Data Science Bowl (DSB), Sartorius Cell Instance Segmentation (SCIS), and Blood Cell Segmentation (BCS) datasets. With the CellSegUNet model, accuracy, dice, and jaccard metrics were obtained as 0.980, 0.970, 0.959 for the DSB dataset, 0.931, 0.957, 0.829 for the SCIS dataset and 0.976, 0.971, 0.927 for the BCS dataset, respectively. As a result, it is predicted that the proposed model can provide solutions to different segmentation problems.},
  archive      = {J_NCA},
  author       = {Metlek, Sedat},
  doi          = {10.1007/s00521-023-09374-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5799-5825},
  shortjournal = {Neural Comput. Appl.},
  title        = {CellSegUNet: An improved deep segmentation model for the cell segmentation based on UNet++ and residual UNet models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The deep learning applications in IoT-based bio- and medical
informatics: A systematic literature review. <em>NCA</em>,
<em>36</em>(11), 5757–5797. (<a
href="https://doi.org/10.1007/s00521-023-09366-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network, recurrent neural network, generative adversarial network, multilayer perception, and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F-score, latency, adaptability, and scalability.},
  archive      = {J_NCA},
  author       = {Amiri, Zahra and Heidari, Arash and Navimipour, Nima Jafari and Esmaeilpour, Mansour and Yazdani, Yalda},
  doi          = {10.1007/s00521-023-09366-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5757-5797},
  shortjournal = {Neural Comput. Appl.},
  title        = {The deep learning applications in IoT-based bio- and medical informatics: A systematic literature review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced PAPR reduction in DCO-OFDM using multi-point
constellations and DPSO optimization. <em>NCA</em>, <em>36</em>(11),
5747–5756. (<a
href="https://doi.org/10.1007/s00521-023-09409-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DC-biased optical OFDM (DCO-OFDM) is a commonly used method of OFDM in visible light communication (VLC). Unfortunately, VLC systems that use OFDM often experience a high peak-to-average power ratio (PAPR). To address this issue, this study proposes a novel method called the multi-point constellation method (MPC) to reduce PAPR in DCO-OFDM. The MPC method involves adding extra alternative constellation points around the existing points and using the discrete particle swarm optimization (DPSO) algorithm to select the constellation points with the lowest PAPR. The proposed MPC method is also combined with selective mapping (SLM), a well-known PAPR reduction technique in the literature. Simulation results show that the proposed MPC method outperforms the SLM method in reducing PAPR in 4-QAM and 16-QAM modulations when used in combination with SLM. Furthermore, increasing the number of iterations and particles in the DPSO algorithm improves the PAPR reduction performance of the proposed method even further.},
  archive      = {J_NCA},
  author       = {Aydin, Volkan and Hacioglu, Gokce},
  doi          = {10.1007/s00521-023-09409-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5747-5756},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced PAPR reduction in DCO-OFDM using multi-point constellations and DPSO optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the analog to digital converter using proteretic
hopfield neural network. <em>NCA</em>, <em>36</em>(11), 5735–5745. (<a
href="https://doi.org/10.1007/s00521-023-09373-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An artificial neural network (ANN) in information technology is a system of hardware or software modeled after the operation of neurons in the human brain. ANNs, often known as &quot;neural networks,&quot; are a form of deep learning technology that falls under the umbrella of Artificial Intelligence (AI). Commercial applications of these technologies typically focus on optimization and solving complex signal processing and pattern recognition problems. Multiple types of optimization techniques are utilized to determine the optimal neural network for a model. These procedures help determine and define the model’s accuracy, dependability, functionality, and capacity. The convergence of the neural network helps determine the number of training iterations required to generate the fewest errors. In this paper, we investigate an activation function to help reduce the training time of the analog-to-digital converter (ADC). A new Hopfield ADC model is proposed by using the proteretic activation function property. We supported our research by simulating the new ADC converter and comparing the traditional Hopfield ADC, the hysteretic ADC, and the proteretic ADC. Experiment and simulation demonstrate that the proteretic function provides a faster rate of convergence than other functions, thereby enhancing the performance of the ADC application.},
  archive      = {J_NCA},
  author       = {Abdulrahman, Aysar and Sayeh, Mohammad and Fadhil, Ahmed},
  doi          = {10.1007/s00521-023-09373-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5735-5745},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing the analog to digital converter using proteretic hopfield neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: GAL: Combining global and local contexts for
interpersonal relation extraction toward document-level chinese text.
<em>NCA</em>, <em>36</em>(11), 5733. (<a
href="https://doi.org/10.1007/s00521-024-09570-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ge, Jiawei and Cao, Jiuxin and Bao, Yingxing and Cao, Biwei and Liu, Bo},
  doi          = {10.1007/s00521-024-09570-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5733},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: GAL: combining global and local contexts for interpersonal relation extraction toward document-level chinese text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). GAL: Combining global and local contexts for interpersonal
relation extraction toward document-level chinese text. <em>NCA</em>,
<em>36</em>(11), 5715–5731. (<a
href="https://doi.org/10.1007/s00521-023-09336-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current interpersonal relation extraction toward Chinese text remains at the sentence-level, which narrows practical applications since most relational facts are implied through multiple sentences in the document. Moreover, considering huge differences between the Chinese and English languages (e.g., different ways of word segmentation and expression preferences), it is impractical to directly adopt models designed for English corpus to model Chinese implicit semantics. To address these challenges, we propose a novel model called GAL (global and local) to comprehend the Chinese context for interpersonal relation extraction at the document-level. Specifically, we devise the global and the local representation modules to encode the entity pair’s relation, perceiving related content from multi-perspectives. For the global representation module, we first design a heterogeneous graph comprised of the document node, entity nodes, and sentence nodes; then, we perform reasoning on it to obtain the global feature via R-GCN. For the local representation module, the robust hierarchical attention is conceived to capture the local semantic features from entity pair’s co-occurrence sentences. Finally, we concatenate the global and local representations for classification. Moreover, due to the lack of an open-source dataset, we employ the distant supervision method to construct the Chinese interpersonal relation extraction dataset at the document-level, DocIPRE. Various experimental results validate the better modeling ability of GAL as it achieves 54.55% on the F1 score, outperforming the state-of-the-art method by a significant margin (1.34% on F1). The source code and dataset will be available soon.},
  archive      = {J_NCA},
  author       = {Ge, Jiawei and Cao, Jiuxin and Bao, Yingxing and Cao, Biwei and Liu, Bo},
  doi          = {10.1007/s00521-023-09336-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5715-5731},
  shortjournal = {Neural Comput. Appl.},
  title        = {GAL: Combining global and local contexts for interpersonal relation extraction toward document-level chinese text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing crop recommendation systems with explainable
artificial intelligence: A study on agricultural decision-making.
<em>NCA</em>, <em>36</em>(11), 5695–5714. (<a
href="https://doi.org/10.1007/s00521-023-09391-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop Recommendation Systems are invaluable tools for farmers, assisting them in making informed decisions about crop selection to optimize yields. These systems leverage a wealth of data, including soil characteristics, historical crop performance, and prevailing weather patterns, to provide personalized recommendations. In response to the growing demand for transparency and interpretability in agricultural decision-making, this study introduces XAI-CROP an innovative algorithm that harnesses eXplainable artificial intelligence (XAI) principles. The fundamental objective of XAI-CROP is to empower farmers with comprehensible insights into the recommendation process, surpassing the opaque nature of conventional machine learning models. The study rigorously compares XAI-CROP with prominent machine learning models, including Gradient Boosting (GB), Decision Tree (DT), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multimodal Naïve Bayes (MNB). Performance evaluation employs three essential metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R2). The empirical results unequivocally establish the superior performance of XAI-CROP. It achieves an impressively low MSE of 0.9412, indicating highly accurate crop yield predictions. Moreover, with an MAE of 0.9874, XAI-CROP consistently maintains errors below the critical threshold of 1, reinforcing its reliability. The robust R2 value of 0.94152 underscores XAI-CROP&#39;s ability to explain 94.15% of the data&#39;s variability, highlighting its interpretability and explanatory power.},
  archive      = {J_NCA},
  author       = {Shams, Mahmoud Y. and Gamel, Samah A. and Talaat, Fatma M.},
  doi          = {10.1007/s00521-023-09391-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5695-5714},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing crop recommendation systems with explainable artificial intelligence: A study on agricultural decision-making},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ensemble of deep CNNs for automatic grading of breast
cancer in digital pathology images. <em>NCA</em>, <em>36</em>(11),
5673–5693. (<a
href="https://doi.org/10.1007/s00521-023-09368-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Histopathological diagnosis is the mainstay of present-day preventive medical care service to guide the therapy and treatment of breast cancer at an early stage. Manual examination of histologic data based on clinicians’ subjective knowledge is a time-consuming, labour-intensive, and costly method that necessitates clinical intervention and competence for a fair decision. In the recent work, we have developed an ensemble of five deep CNNs to classify three grades of breast cancer using quantitative image-based assessment of digital pathology slides without any manual intervention. To produce final predictions on the dataset, a fuzzy ranking algorithm is used. On the Databiox dataset, the suggested model attained an accuracy of 79%, 75%, 89%, and 82% at 4×, 10×, 20×, and 40× magnification, respectively. Furthermore, it has been observed that the stain-normalization strategy improves the model’s classification performance on the histopathological images. In this case, the Macenko stain-normalization technique is employed which further enhances the performance of the proposed ensemble model up to 80%, 100%, 100%, and 82% at 4×, 10×, 20×, and 40× magnification, respectively. Additionally, a comparative analysis with the existing state-of-the-art technique demonstrated the superiority of the proposed scheme.},
  archive      = {J_NCA},
  author       = {Sharma, Shallu and Kumar, Sumit and Sharma, Manoj and Kalkal, Ashish},
  doi          = {10.1007/s00521-023-09368-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5673-5693},
  shortjournal = {Neural Comput. Appl.},
  title        = {An ensemble of deep CNNs for automatic grading of breast cancer in digital pathology images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of anemia using harris hawks optimization
method and multivariate adaptive regression spline. <em>NCA</em>,
<em>36</em>(11), 5653–5672. (<a
href="https://doi.org/10.1007/s00521-023-09379-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining methods are important for the diagnosis and prediction of diseases. Early and accurate diagnosis of patients is vital for their treatment. Various methods have been used in the literature to classify anemia. However, due to the different characteristics of patient datasets, changes in dataset sizes, different parameter numbers and features, and different numbers of patient records, algorithm performances vary according to datasets. In this study, the Harris hawks algorithm (HHA) and the multivariate adaptive regression spline (MARS) were used to classify anemia based on blood data of 1732 patients from the Kaggle database of patients with and without anemia. Six different algorithms were proposed to determine the parameters of the linear anemia approximation, namely multilinear form HHA, multilinear quadratic form HHA, multilinear exponential form HHA, first-order MARS model, second-order MARS model, and the best performing MARS model. The performance of the six proposed algorithms has been analyzed and found to be better than the previous studies in the literature.},
  archive      = {J_NCA},
  author       = {Yagmur, Nagihan and Dag, İdiris and Temurtas, Hasan},
  doi          = {10.1007/s00521-023-09379-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {5653-5672},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of anemia using harris hawks optimization method and multivariate adaptive regression spline},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction: EOS-3D-DCNN: Ebola optimization search-based
3D-dense convolutional neural network for corn leaf disease prediction.
<em>NCA</em>, <em>36</em>(10), 5651. (<a
href="https://doi.org/10.1007/s00521-024-09522-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ashwini, C. and Sellam, V.},
  doi          = {10.1007/s00521-024-09522-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5651},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: EOS-3D-DCNN: ebola optimization search-based 3D-dense convolutional neural network for corn leaf disease prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Utilizing social media and machine learning
for personality and emotion recognition using PERS. <em>NCA</em>,
<em>36</em>(10), 5649. (<a
href="https://doi.org/10.1007/s00521-023-09105-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and El-Gendy, Eman M. and Saafan, Mahmoud M. and Gamel, Samah A.},
  doi          = {10.1007/s00521-023-09105-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5649},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Utilizing social media and machine learning for personality and emotion recognition using PERS},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Hierarchical reinforcement learning for
kinematic control tasks with parameterized action spaces. <em>NCA</em>,
<em>36</em>(10), 5647. (<a
href="https://doi.org/10.1007/s00521-023-09305-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Cao, Jingyu and Dong, Lu and Sun, Changyin},
  doi          = {10.1007/s00521-023-09305-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5647},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Hierarchical reinforcement learning for kinematic control tasks with parameterized action spaces},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction: Deep learning and internet of things for tourist
attraction recommendations in smart cities. <em>NCA</em>,
<em>36</em>(10), 5645. (<a
href="https://doi.org/10.1007/s00521-023-09280-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Cepeda-Pacheco, Juan Carlos and Domingo, Mari Carmen},
  doi          = {10.1007/s00521-023-09280-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5645},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Deep learning and internet of things for tourist attraction recommendations in smart cities},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing age-related postural sway classification using
partial least squares-discriminant analysis and hybrid feature set.
<em>NCA</em>, <em>36</em>(10), 5621–5643. (<a
href="https://doi.org/10.1007/s00521-024-09557-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature sets in a machine learning algorithm can have an impact on the robustness, interpretability, and characterization of the data. To detect age-related changes, traditional linear methods for analyzing center of pressure (COP) signals offer limited insight into the complex nonlinear dynamics of postural control. To overcome this limitation, a novel approach that combines a partial least squares-discriminant analysis (PLS-DA) classifier with the nonlinear dynamics of COP time series was proposed. Three small feature sets were compared: time-domain features alone, entropy-based features alone, and a hybrid approach incorporating both types of features. The performance of the PLS-DA model was assessed in four different eyes and surface conditions by using the accuracy, sensitivity, selectivity, precision metrics, and ROC curves. The results indicated that the PLS-DA model utilizing the hybrid feature set achieved significantly higher accuracy than the time-domain and entropy-based feature sets. The best classification performance was observed when the eyes were open on a compliant surface, with an overall accuracy of 89% for training and 88% for cross-validation. For the old group, while the results indicated 93% sensitivity, 94% specificity, and 93% precision in the training, the results revealed 88% sensitivity, 93% specificity, and 91% precision in cross-validation. Notably, the hybrid feature set yielded an AUC value of 0.96, indicating a superior performance. This study emphasizes the robust classification capabilities of PLS-DA for age-related postural changes and highlights the effectiveness of utilizing a small hybrid feature set to improve classification accuracy and reliability.},
  archive      = {J_NCA},
  author       = {Alcan, Veysel},
  doi          = {10.1007/s00521-024-09557-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5621-5643},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing age-related postural sway classification using partial least squares-discriminant analysis and hybrid feature set},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modified coot bird optimization algorithm for solving
community detection problem in social networks. <em>NCA</em>,
<em>36</em>(10), 5595–5619. (<a
href="https://doi.org/10.1007/s00521-024-09567-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection (CD) is a powerful way to extract meaningful information from networks such as political election networks, biological networks, social networks, technological networks. This study proposes a modified discrete version of Coot bird natural life model (COOT) optimization algorithm to solve CD problem in the networks. The basic COOT method is based on the different collective behaviors of the birds of the coot family. These collective actions of coots are regular and irregular movements on the water surface. The position update rule of the basic COOT method does not provide a balance between exploitation and exploration ability for the problem addressed in this study. Therefore, a new update mechanism is integrated into the basic COOT method to extend the local and global search tendencies of the basic COOT method. In the proposed COOT method (for short MCOOT), in order to create a new position for the current coot individual, first the original update mechanism of COOT method is carried out; then, the proposed update mechanism is executed. Three important modifications have been made in the new update mechanism: (1) Some dimensions of the current coot individual are randomly selected in the range of 1 to the dimension size of the problem; (2) the selected dimensions of the coot individual are updated according to the proposed update rule; (3) a genetic mutation operator is executed on the current coot position according to a mutation probability to improve the exploration ability. Furthermore, in the proposed MCOOT method, the continuous values of the current coot positions are converted to discrete values, because the CD problem is a discrete problem. Based on these modifications, in order to analyze and validate the effectiveness of the proposed MCOOT, it is applied on ten different small-sized or large-sized network problems. Finally, the experimental results of MCOOT method are compared with those of some state-of-the-art optimization methods in terms of solution quality and time evaluation. According to the experiments of our study, the proposed algorithm is obtained the best results for all community detection problems used in this study when compared with 22 other algorithms. As a result, the proposed method achieves superior or comparable performance in terms of solution quality and robustness according to the general results. Therefore, the proposed method can be much more competitive, especially for discrete problems.},
  archive      = {J_NCA},
  author       = {Aslan, Murat and Koç, İsmail},
  doi          = {10.1007/s00521-024-09567-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5595-5619},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified coot bird optimization algorithm for solving community detection problem in social networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IPSHO-fed: A hybrid federated learning and spotted hyena
optimization approach for trust assessment. <em>NCA</em>,
<em>36</em>(10), 5571–5594. (<a
href="https://doi.org/10.1007/s00521-023-09330-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of rapidly evolving intelligent transportation systems, the vehicle–road–cloud collaborative system emerges as a groundbreaking paradigm that integrates vehicles, road infrastructure, and cloud servers to optimize transportation-related tasks. However, the system’s success hinges on the reliable and secure exchange of data and model training among entities. Trust evaluation becomes paramount to ensure the credibility of information transmitted within the system and safeguard against potential security threats. To overcome this issue, an innovative trust evaluation scheme using the improved PSO-based spotted hyena optimization (IPSHO) algorithm is proposed. In this approach, each entity in the collaborative system is represented as a spotted hyena, and the algorithm’s integration with federated learning enables decentralized model training without sharing raw data. By leveraging the collective intelligence of the system, IPSHO collaboratively refines trust values and ensures personalized trust evaluation at the equipment, data, and model levels. Our simulation environment, implemented in MATLAB, models a realistic network of 100 sensor nodes representing vehicles, road infrastructure, and cloud servers. The entities communicate within a 100 m × 100 m area using secure channels. Through rigorous experimentation, the IPSHO algorithm&#39;s convergence behavior, its ability to find optimal trust values, and its performance against malicious nodes and hazardous events are assessed. The results demonstrate IPSHO&#39;s effectiveness in achieving accurate trust evaluations in diverse scenarios. Comparison with other optimization algorithms and trust evaluation methods reaffirms IPSHO’s superiority in enhancing trustworthiness assessment. The proposed scheme empowers legitimate nodes with the capability to discern trustworthiness and authenticity of information exchanged, ensuring the integrity and reliability of the vehicle–road–cloud collaborative system.},
  archive      = {J_NCA},
  author       = {Devi, R.},
  doi          = {10.1007/s00521-023-09330-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5571-5594},
  shortjournal = {Neural Comput. Appl.},
  title        = {IPSHO-fed: A hybrid federated learning and spotted hyena optimization approach for trust assessment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel physics informed-neural networks for estimation of
hydraulic conductivity of green infrastructure as a performance metric
by solving richards–richardson PDE. <em>NCA</em>, <em>36</em>(10),
5555–5569. (<a
href="https://doi.org/10.1007/s00521-023-09378-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green infrastructure (GI) is an ecologically informed approach to stormwater management that is potentially sustainable and effective. Infiltration-based GI systems, including rain gardens, permeable pavements, green roofs infiltrate surface water and stormwater run-off to recharge ground water systems. However, these systems are susceptible to clogging and deterioration of their function, and we have limited understanding of the evolution of their function due to the lack of long-term monitoring. The ability of these systems to infiltrate water depends on the unsaturated hydraulic conductivity function K of the soil. We introduce a novel approach based on physics informed neural networks (PINNs) to estimate K of a homogeneous column of soil using data from volumetric water content sensors and by solving the Richards–Richardson partial differential equation (RRE). We introduce and compare two different deep neural network architectures to solve RRE and estimate K. To generate the ground truth, we simulate three types of soil water dynamics using HYDRUS-1D and compare the results of these two neural network architectures in terms of the estimation of K. We investigate the effect of inter-sensor placement on the estimation of K. Both architectures show satisfactory performance on homogeneous soil with three volumetric water content sensors with different advantages. PINN-based estimation of K can be used fundamental tool for assessment of the evolution of the performance of GI over time, while requiring as input only the data from simple soil moisture sensors that are easily installed at the time of GI construction or even retrofitted.},
  archive      = {J_NCA},
  author       = {Elkhadrawi, Mahmoud and Ng, Carla and Bain, Daniel J. and Sargent, Emelia E. and Stearsman, Emma V. and Gray, Kimberly A. and Akcakaya, Murat},
  doi          = {10.1007/s00521-023-09378-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5555-5569},
  shortjournal = {Neural Comput. Appl.},
  title        = {Novel physics informed-neural networks for estimation of hydraulic conductivity of green infrastructure as a performance metric by solving Richards–Richardson PDE},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An accurate algorithm for land surface changes detection
based on deep learning and improved pixel clustering using SAR images.
<em>NCA</em>, <em>36</em>(10), 5545–5554. (<a
href="https://doi.org/10.1007/s00521-023-09377-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic Aperture Radar (SAR) was developed to map the terrain without the use of large antennas. Combined array is one of the radar methods that is applied from an aircraft or a space platform and in which an effective aperture of the antenna is created in a combined manner. The images obtained by these radars are very accurate. On the other hand, the surface of the earth always changes due to various factors. Accurate identification of these changes can be used in many applications, especially in Iraq due to its semidesert structure. In this research, an improved surface change detection algorithm based on morphological transformation, two-stage center-constrained FCM algorithm (TCCFCM) clustering and deep learning is presented. The simulation of the method of this research on MATLAB software shows that the proposed method is fast and inexpensive. The accuracy was 99.7%.},
  archive      = {J_NCA},
  author       = {Al-Dujaili, Mohammed Jawad},
  doi          = {10.1007/s00521-023-09377-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5545-5554},
  shortjournal = {Neural Comput. Appl.},
  title        = {An accurate algorithm for land surface changes detection based on deep learning and improved pixel clustering using SAR images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Comprehensive comparison of modified deep convolutional
neural networks for automated detection of external and middle ear
conditions. <em>NCA</em>, <em>36</em>(10), 5529–5544. (<a
href="https://doi.org/10.1007/s00521-023-09365-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Otitis media disease, a frequent childhood ailment, could have severe repercussions, including mortality. This disease induces permanent hearing loss, commonly seen in developing countries with limited medical resources. It is estimated that approximately 21,000 people worldwide die from reasons related to this disease each year. The main aim of this study is to develop a model capable of detecting external and middle ear conditions. Experiments were conducted to find the most successful model among the modified deep convolutional neural networks within two scenarios. According to the results, the modified EfficientNetB7 model could detect normal, chronic otitis media, earwax, myringosclerosis cases with high accuracy in Scenario 2. This model offers average values of 99.94% accuracy, 99.86% sensitivity, 99.95% specificity, and 99.86% precision. An expert system based on this model is expected to provide a second opinion to doctors in detecting external and middle ear conditions, particularly in primary healthcare institutions and hospitals lacking field specialists.},
  archive      = {J_NCA},
  author       = {Akyol, Kemal},
  doi          = {10.1007/s00521-023-09365-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5529-5544},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comprehensive comparison of modified deep convolutional neural networks for automated detection of external and middle ear conditions},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling transformer architecture with attention layer for
human activity recognition. <em>NCA</em>, <em>36</em>(10), 5515–5528.
(<a href="https://doi.org/10.1007/s00521-023-09362-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is necessary in numerous fields, involving medicine, sports, and security. Traditional HAR methods often rely on complex feature extraction from raw input data, while convolutional neural networks (CNN) are primarily designed for 2D data. The proposed approach seeks to overcome these limitations by leveraging both spatial and temporal attributes for improved action detection and enhancing the understanding of human movements across adjacent frames. This research aims to address the challenges of HAR by introducing a new model that combines a 3D CNN architecture with an attention layer. A 3D convolution transformer is employed to capture intricate spatial and temporal features, generate multiple data channels from input frames, and optimize performance through regularization and model ensemble techniques. The main findings reveal outstanding results on benchmark datasets, with an accuracy of 98.09% and 99.09% on the Weizmann and UCF101 datasets, respectively. These results underscore the model&#39;s effectiveness in accurately identifying human activities in movie-based natural environments.},
  archive      = {J_NCA},
  author       = {Pareek, Gunjan and Nigam, Swati and Singh, Rajiv},
  doi          = {10.1007/s00521-023-09362-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5515-5528},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modeling transformer architecture with attention layer for human activity recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal fusion for audio-image and video action
recognition. <em>NCA</em>, <em>36</em>(10), 5499–5513. (<a
href="https://doi.org/10.1007/s00521-023-09186-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Human Action Recognition (MHAR) is an important research topic in computer vision and event recognition fields. In this work, we address the problem of MHAR by developing a novel audio-image and video fusion-based deep learning framework that we call Multimodal Audio-Image and Video Action Recognizer (MAiVAR). We extract temporal information using image representations of audio signals and spatial information from video modality with the help of Convolutional Neutral Networks (CNN)-based feature extractors and fuse these features to recognize respective action classes. We apply a high-level weights assignment algorithm for improving audio-visual interaction and convergence. This proposed fusion-based framework utilizes the influence of audio and video feature maps and uses them to classify an action. Compared with state-of-the-art audio-visual MHAR techniques, the proposed approach features a simpler yet more accurate and more generalizable architecture, one that performs better with different audio-image representations. The system achieves an accuracy 87.9% and 79.0% on UCF51 and Kinetics Sounds datasets, respectively. All code and models for this paper will be available at https://tinyurl.com/4ps2ux6n .},
  archive      = {J_NCA},
  author       = {Shaikh, Muhammad Bilal and Chai, Douglas and Islam, Syed Mohammed Shamsul and Akhtar, Naveed},
  doi          = {10.1007/s00521-023-09186-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5499-5513},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal fusion for audio-image and video action recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CO emission predictions in municipal solid waste
incineration based on reduced depth features and long short-term memory
optimization. <em>NCA</em>, <em>36</em>(10), 5473–5498. (<a
href="https://doi.org/10.1007/s00521-023-09329-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon monoxide (CO) is a toxic gas emitted during municipal solid waste incineration (MSWI). Its emission prediction is conducive to pollutant reduction and optimized control of MSWI. The variables of MSWI exhibit redundant and interdependent correlations with CO emissions. Furthermore, the mapping relationship is difficult to characterize. Therefore, the work proposed a CO emission prediction method based on reduced depth features and long short-term memory (LSTM) optimization. The particle design for reduced depth feature and LSTM optimization was initially developed—incorporating an adaptive threshold range for feature selection based on the inherent characteristics of modeling data. Secondly, the nonlinear depth features were extracted using ultra-one-dimensional convolution and subsequently fed into an LSTM model for prediction construction. The hyperparameters of the convolutional layer and LSTM were updated based on the loss function. The generalization performance of the model was used as the fitness function of the optimization. Finally, the particle swarm optimization (PSO) was used to adaptively reduce depth features and model’s hyperparameters. The rationality and effectiveness of the proposed method were validated using the benchmark dataset and CO dataset of MSWI. R2 of the testing datasets for RB and CO were 0.9097 ± 3.64E-04 and 0.7636 ± 3.19E-03, respectively, by repeating 30 times.},
  archive      = {J_NCA},
  author       = {Zhang, Runyu and Tang, Jian and Xia, Heng and Pan, Xiaotong and Yu, Wen and Qiao, Junfei},
  doi          = {10.1007/s00521-023-09329-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5473-5498},
  shortjournal = {Neural Comput. Appl.},
  title        = {CO emission predictions in municipal solid waste incineration based on reduced depth features and long short-term memory optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: SW/SE-CNN: Semi-wavelet and specific image edge
extractor CNN for gaussian image denoising. <em>NCA</em>,
<em>36</em>(10), 5471. (<a
href="https://doi.org/10.1007/s00521-024-09528-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Esteki, Shahram and Naghsh-Nilchi, Ahmad R.},
  doi          = {10.1007/s00521-024-09528-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5471},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: SW/SE-CNN: semi-wavelet and specific image edge extractor CNN for gaussian image denoising},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). SW/SE-CNN: Semi-wavelet and specific image edge extractor
CNN for gaussian image denoising. <em>NCA</em>, <em>36</em>(10),
5447–5469. (<a
href="https://doi.org/10.1007/s00521-023-09314-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several state-of-the-art convolutional neural networks (CNNs)-based methods are available for image denoising tasks. CNNs are typically trained using the backpropagation algorithm, which requires all operations in the network to be differentiable. Most CNN operations satisfy this requirement and can be applied to backpropagation-based training algorithms. However, some transforms, including wavelet transform, which is useful for speeding up CNN computations as well as performing multi-resolution analysis, are not strictly differentiable. This paper addresses this challenge by proposing a wavelet-like transform that is differentiable. This new design is, in fact, a new CNN architecture named semi-wavelet, specific edge convolutional neural network (SW/SE-CNN), consisting of three newly designed layers. The first layer is a Semi-Wavelet (SW)-based layer which is a differential down-sampling operator for wavelet approximation. That is, the SW layer converts the input image into four channels. Three of these channels are estimations of the vertical, horizontal, and diagonal edges of the original image; and the fourth channel is a down-sampled version of it. The second proposed layer, called Semi-Wavelet Inverse (SWI), is to restore the original image by using the four SW output channels. Additionally, a specific edge extractor (SE), as another new layer, is designed on the basis of the well-known Sobel operator to extract specific edges of the image. The reason behind proposing the SE layer is to provide more edge information for the network; and the motive for including the SW layer is to speed the network up as well as multi-resolution analysis. Then, the new SW/SE-CNN architecture is implemented for Gaussian image denoising. The experimental results show that the new SW/SE-CNN outperformed the state-of-the-art methods for Gaussian image denoising based on the peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) measurements for grayscale as well as color images.},
  archive      = {J_NCA},
  author       = {Esteki, Shahram and Naghsh-Nilchi, Ahmad R.},
  doi          = {10.1007/s00521-023-09314-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5447-5469},
  shortjournal = {Neural Comput. Appl.},
  title        = {SW/SE-CNN: Semi-wavelet and specific image edge extractor CNN for gaussian image denoising},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-based novel continuous authentication
system using soft keyboard typing behavior and motion sensor data.
<em>NCA</em>, <em>36</em>(10), 5433–5445. (<a
href="https://doi.org/10.1007/s00521-023-09360-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smartphones utilize various authentication methods, including passwords, fingerprints, and face recognition. While this information is quite practical and easy to remember, it introduces several security issues. The primary concerns involve theft, password forgetfulness, or unauthorized password copying. Implementing behavioral biometrics for user authentication adds an extra layer of security. The main contribution of this study is the utilization of soft keyboard typing behavior, a behavioral biometric, for continuous user recognition. To achieve this, the phone&#39;s grip style and typing characteristics of users are scrutinized using data collected from motion sensors and the touchscreen panel. Another challenge in mobile device authentication pertains to recognition accuracy and processing time. To expedite and optimize data classification, a hybrid classification structure is suggested. This structure incorporates correlation-based feature selection and a straightforward logistic regression method, offering rapid and highly accurate classification outcomes—a further contribution of this study. Experimental results demonstrate that user identification can be accomplished in as little as 0.03 ms, with a classification accuracy of up to 93%. Continuous authentication systems offer greater security compared to one-time authentication systems. Nevertheless, these systems might not always yield the most precise results. Overcoming this challenge necessitates the development of an efficient software architecture. In line with this, an additional contribution of this study is an explanation of how to construct a continuous authentication system using the developed architecture.},
  archive      = {J_NCA},
  author       = {Sağbaş, Ensar Arif and Ballı, Serkan},
  doi          = {10.1007/s00521-023-09360-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5433-5445},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-based novel continuous authentication system using soft keyboard typing behavior and motion sensor data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HBS–STACK: Hierarchical biomarker selection and stacked
ensemble model for biomarker identification and cancer prediction on
multi-omics. <em>NCA</em>, <em>36</em>(10), 5413–5431. (<a
href="https://doi.org/10.1007/s00521-023-09359-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genomic and transcriptomic data development has provided new prospects for biomarker identification and cancer prediction. However, it is challenging to capture the biological dataset with complex and nonlinear associations using existing biomarkers and cancer diagnosis techniques. Machine learning offers enormous potential for creating feature selection techniques and models to identify cancer biomarkers. In this article, we propose a Hierarchical Biomarker Selection and Stacked Ensemble model for Biomarker Identification and Cancer Prediction (HBS–STACK) on miRNA, gene expression, and DNA Methylation (DM) datasets. Three-stage biomarker selection is developed comprising an aggregation of information between CpG sites and genes by considering the biological relations at stage 1, Fold Change and False Discovery Rate selection at stage 2, and Light Gradient Boosting Machine with Recursive Feature Elimination (LBGMRFE) selection at stage 3. The selected features and markers are integrated and passed to stacked ML models comprising Gradient Boosting Machine (GBM), Naïve Bayes (NB), Random Forest (RF) at level 1 learning, and DNN at level 2 learning. HBS–STACK is evaluated on breast cancer (BRCA) and is validated on kidney renal clear cell carcinoma (KIRC) from TCGA (The Cancer Genome Atlas) Portal and on Alzheimer Disease. We found several genomic and transcriptomic biomarkers comprising IQSEC1 for BRCA, ZFHX3, CTBP2, and SLC9AR2 for KIRC and TMEM61 for Alzheimer disease, respectively. The experimental results show that the HBS–STACK outperformed GBM, NB, and RF with 99.60, 99.03, and 92.05% accuracy and shows an improvement of 2.27, 26.03, 10.05% in performance compared with existing techniques on BRCA, KIRC, and Alzheimer, respectively.},
  archive      = {J_NCA},
  author       = {Dhillon, Arwinder and Singh, Ashima and Bhalla, Vinod Kumar},
  doi          = {10.1007/s00521-023-09359-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5413-5431},
  shortjournal = {Neural Comput. Appl.},
  title        = {HBS–STACK: Hierarchical biomarker selection and stacked ensemble model for biomarker identification and cancer prediction on multi-omics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CNN-based indian medicinal leaf type identification and
medical use recommendation. <em>NCA</em>, <em>36</em>(10), 5399–5412.
(<a href="https://doi.org/10.1007/s00521-023-09352-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medicinal leaves are playing a vital role in our everyday life. There are an enormous amount of species present in the world. Identification of each type would be a tedious task. Using image processing technology, we can overcome this problem by providing computer vision with the help of a convolution neural network (CNN). The objective of this research is to find out the best CNN model that helps in classifying the plant leaf species and identifying its category. In this research work, the proposed basic CNN model consisting of four convolution layers uses ten different medicinal leaf species each belonging to two categories providing an accuracy of $$96.88\%$$ .},
  archive      = {J_NCA},
  author       = {Praveena, S. and Pavithra, S. M. and Kumar, A. Dalvin Vinoth and Veeresha, P.},
  doi          = {10.1007/s00521-023-09352-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5399-5412},
  shortjournal = {Neural Comput. Appl.},
  title        = {CNN-based indian medicinal leaf type identification and medical use recommendation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Deep noise mitigation and semantic reconstruction hashing
for unsupervised cross-modal retrieval. <em>NCA</em>, <em>36</em>(10),
5383–5397. (<a
href="https://doi.org/10.1007/s00521-023-09331-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing has attracted much attention due to low storage cost and high retrieval efficiency. Compared with the supervised counterparts, the unsupervised cross-modal hashing methods suffer from severe performance degradation without label guidance. Pseudo label-based unsupervised methods have been proved to be an effective way to improve the discriminative ability of hash codes. However, there are varies of noises during the process of creating pseudo labels by clustering algorithms. To mitigate the effects of noise, in this paper, we propose a novel deep noise mitigation and semantic reconstruction hashing (DNMSRH) for unsupervised cross-modal retrieval. Specifically, an unsupervised data balancing strategy is used to search the equivalent training data in each cluster satisfying the distribution of the minimum variance within the class and the maximum variance between classes, which effectively mitigates the data noise caused by the misclassification of outliers. Meanwhile, a joint symmetric multi-metric similarity reconstruction framework is constructed, which cannot only joint the semantic information of heterogeneous modalities, but also preserve and extend the pairwise instance correlation of original features. Furthermore, offline hard and online soft pseudo labels are introduced to mitigate the effects of noisy labels, where soft pseudo labels are generated by the collaborative training of heterogeneous image and text networks. Extensive experiments on three benchmark datasets for unsupervised cross-modal retrieval demonstrate that DNMSRH significantly outperforms the state-of-the-art competitors.},
  archive      = {J_NCA},
  author       = {Zhang, Cheng and Wan, Yuan and Qiang, Haopeng},
  doi          = {10.1007/s00521-023-09331-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5383-5397},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep noise mitigation and semantic reconstruction hashing for unsupervised cross-modal retrieval},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot video object segmentation with prototype evolution.
<em>NCA</em>, <em>36</em>(10), 5367–5382. (<a
href="https://doi.org/10.1007/s00521-023-09325-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a challenging task, few-shot video object segmentation attempts to segment objects of novel categories in the video while providing only a few annotated images. Current methods for this task only explore the relationship between support images and target query video ignoring the rich temporal information in the query video itself. To address this problem, we propose a simple yet effective framework named prototype evolution network (PENet) for few-shot video object segmentation in this paper. PENet first adopts a prototype-based structure which efficiently constructs and exploits the correlation between support images and target query video. Then a prototype evolution module is designed to summarize and propagate temporal information through the evolution process of the video prototype. The feature representation adopted by the module is of fixed size and does not increase memory burden as the video frame moves forward. Along with the category prototype extracted from the support set, the global video prototype provides guidance for the current frame segmentation. Additionally, the approach of utilizing the high-level features is introduced as an optional solution that trades a small amount of speed for higher accuracy. Experimental results on the Youtube-VIS dataset of 2019 version and 2021 version demonstrate that our PENet outperforms the previous methods with a sizable margin, validating the superiority of the proposed model.},
  archive      = {J_NCA},
  author       = {Mao, Binjie and Liu, Xiyan and Shi, Linsu and Yu, Jiazhong and Li, Fei and Xiang, Shiming},
  doi          = {10.1007/s00521-023-09325-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5367-5382},
  shortjournal = {Neural Comput. Appl.},
  title        = {Few-shot video object segmentation with prototype evolution},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 classification based on a deep learning and machine
learning fusion technique using chest CT images. <em>NCA</em>,
<em>36</em>(10), 5347–5365. (<a
href="https://doi.org/10.1007/s00521-023-09346-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease (COVID-19), impacted by SARS-CoV-2, is one of the greatest challenges of the twenty-first century. COVID-19 broke out in the world over the last 2 years and has caused many injuries and killed persons. Computer-aided diagnosis has become a necessary tool to prevent the spreading of this virus. Detecting COVID-19 at an early stage is essential to reduce the mortality risk of patients. Researchers seek to find rapid solutions based on techniques of Machine Learning and Deep Learning. In this paper, we introduced a hybrid model for COVID-19 detection based on machine learning and deep learning models. We used 10 different deep CNN network models to extract features from CT images. We extract features from different layers in each network and find the optimum layer that gives the best-extracted features for each CNN network. Then, for classifying these features, we used five different classifiers based on machine learning. The dataset consists of 2481 CT images divided into COVID-19 and non-COVID-19 categories. Three folds are extracted with a different size between testing and training. Through experiments, we define the best layer for all used CNN networks, the best network, and the best-used classifier. The measured performance shows the superiority of the proposed system over the literature with a highest accuracy of 99.39%. Our models are tested with the three folds that gained maximum average accuracy. The result is 98.69%.},
  archive      = {J_NCA},
  author       = {Salama, Gerges M. and Mohamed, Asmaa and Abd-Ellah, Mahmoud Khaled},
  doi          = {10.1007/s00521-023-09346-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5347-5365},
  shortjournal = {Neural Comput. Appl.},
  title        = {COVID-19 classification based on a deep learning and machine learning fusion technique using chest CT images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight deep neural network model and its applications
based on channel pruning and group vector quantization. <em>NCA</em>,
<em>36</em>(10), 5333–5346. (<a
href="https://doi.org/10.1007/s00521-023-09332-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (DCNNs) contain millions of parameters and require a tremendous amount of computation; therefore, they cannot be well supported by resource-constrained edge devices. We propose a two-stage model compression method to alleviate this restriction: channel pruning and group vector quantization (CP-GVQ). By channel pruning, many channels of the DCNNs layers are pruned to reduce the model size and improve model inference speed. Based on vector quantization (VQ), GVQ is proposed to compress DCNNs, and it uses group codebooks and code matrices to represent the parameters of grouped layers; the model size is reduced greatly. CP-GVQ not only dramatically decreases model size but also improves inference speed. In each stage, it is necessary to fine-tune the model to recover the original accuracy. When applied to the filament indices classification model of microscopic images of activated sludge, the classification accuracy decreased marginally from 0.99 to 0.97, but the model size was decreased by 99% and the inference speed was improved by 42%.},
  archive      = {J_NCA},
  author       = {Huang, Mingzhong and Liu, Yan and Zhao, Lijie and Wang, Guogang},
  doi          = {10.1007/s00521-023-09332-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5333-5346},
  shortjournal = {Neural Comput. Appl.},
  title        = {A lightweight deep neural network model and its applications based on channel pruning and group vector quantization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The non-monopolize search (NO): A novel single-based local
search optimization algorithm. <em>NCA</em>, <em>36</em>(10), 5305–5332.
(<a href="https://doi.org/10.1007/s00521-023-09120-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several optimization-based population search methods have been proposed; they use various operators that permit exploring the search space. These methods typically suffer from local search (LS) problems and are unbalanced between exploration and exploitation. Consequently, recent researchers sought to modify the algorithms to avoid search problems using local search techniques to intensify the exploitation when is necessary. This paper proposes a novel single-based local search optimization algorithm called the non-monopolize search (NO). The NO is a single-solution metaphor-free algorithm, and its operators are designed based to explore and exploit along the iterative process. The NO works only with a candidate solution, and the operators modify the dimension to move the current solution along the search space. The NO is an effective LS method that combines the benefits of exploration with exploitation. Different from other LS, the NO can escape from suboptimal solutions thanks to the randomness incorporated into its operators. This is the main advantage of the NO. Experiments are conducted on standard benchmark functions to validate the performance of the proposed non-monopolize search optimization technique. The results are compared with other well-known methods, and the proposed NO got better results. Moreover, the proposed NO can be considered a powerful alternative to improve the optimization algorithms’ performance and help avoid local search problems. Source codes of NO are publicly available at https://www.mathworks.com/matlabcentral/fileexchange/156154-the-non-monopolize-search-no .},
  archive      = {J_NCA},
  author       = {Abualigah, Laith and Al-qaness, Mohammed A. A. and Abd Elaziz, Mohamed and Ewees, Ahmed A. and Oliva, Diego and Cuong-Le, Thanh},
  doi          = {10.1007/s00521-023-09120-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5305-5332},
  shortjournal = {Neural Comput. Appl.},
  title        = {The non-monopolize search (NO): A novel single-based local search optimization algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight image super-resolution via multi-branch aware
CNN and efficient transformer. <em>NCA</em>, <em>36</em>(10), 5285–5303.
(<a href="https://doi.org/10.1007/s00521-023-09353-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid architecture model of multi-branch aware CNN and efficient transformer (MAET) is proposed and implemented for lightweight image super-resolution (SR). In the model, the multi-branch aware block (MAB) removes the redundant branches when their local spatial features are captured by other branches, while the efficient transformer block (ETB) applies the scaled cosine attention (SCA) to scale up the model capacity by generating mild attentional values from the pixel pairs. By removing the redundant branches and applying SCA to scale up the model capacity, we believe that the model is able to improve the performance while maintaining a low computation complexity. Specifically, MAET consists of a multi-branch aware CNN module (MACM) and an efficient transformer module (ETM). MACM is a lightweight CNN module composed of a serious of MABs to extract hierarchical local features. ETM is composed of ETBs to fully exploit global information by modeling long-term image dependencies to refine the texture details. ETB adopts the feature split strategy, residual post-normalization, and SCA for efficient multi-head attention. Extensive experiments demonstrate that the proposed MAET achieves better accuracy and visual improvements against the state-of-the-art lightweight image SR methods in terms of quantitative and qualitative evaluations.},
  archive      = {J_NCA},
  author       = {Gao, Xiang and Wu, Sining and Zhou, Ying and Wu, Xinrong and Wang, Fan and Hu, Xiaopeng},
  doi          = {10.1007/s00521-023-09353-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5285-5303},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lightweight image super-resolution via multi-branch aware CNN and efficient transformer},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DLP-GAN: Learning to draw modern chinese landscape photos
with generative adversarial network. <em>NCA</em>, <em>36</em>(10),
5267–5284. (<a
href="https://doi.org/10.1007/s00521-023-09345-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese landscape painting has a unique and artistic style, and its drawing technique is highly abstract in both the use of color and the realistic representation of objects. Previous methods focus on transferring from modern photos to ancient ink paintings. However, little attention has been paid to translating landscape paintings into modern photos. To solve such problems, in this paper, we (1) propose DLP-GAN (Draw Modern Chinese Landscape Photos with Generative Adversarial Network), an unsupervised cross-domain image translation framework with a novel asymmetric cycle mapping, and (2) introduce a generator based on a dense-fusion module to match different translation directions. Moreover, a dual-consistency loss is proposed to balance the realism and abstraction of model painting. In this way, our model can draw landscape photos and sketches in the modern sense. Finally, based on our collection of modern landscape and sketch datasets, we compare the images generated by our model with other benchmarks. Extensive experiments including user studies show that our model outperforms state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Gui, Xiangquan and Zhang, Binxuan and Li, Li and Yang, Yi},
  doi          = {10.1007/s00521-023-09345-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5267-5284},
  shortjournal = {Neural Comput. Appl.},
  title        = {DLP-GAN: Learning to draw modern chinese landscape photos with generative adversarial network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention with kernels for EEG-based emotion classification.
<em>NCA</em>, <em>36</em>(10), 5251–5266. (<a
href="https://doi.org/10.1007/s00521-023-09344-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A kernel attention module (KAM) is presented for the task of EEG-based emotion classification using neural network based models. In this study, it is shown that the KAM method can lead to more efficient and accurate models using only a single parameter design. This additional parameter can be leveraged as an interpretable scalar quantity for examining the overall amount of attention needed during deep feature refinement. Extensive experiments are analyzed on both the SEED and DEAP datasets to demonstrate the module’s performance on subject-dependent classification tasks. From these benchmark studies, it is shown that KAM is able to boost the backbone model’s mean prediction accuracy by more than 3% on some subjects and up to more than 1%, on average, across 15 subjects in the SEED dataset for subject dependent tasks. In the DEAP dataset, the improvement is more significant by achieving greater than 3% improvement in the overall mean accuracy versus the no-attention case, and more than 1–2% when benchmarked against various other state-of-the-art attention modules. In addition, the predictive dependencies of KAM with respect to its single parameter is numerically examined up to first order. Accompanying analyzes and visualization techniques are also proposed for interpreting the KAM attention module’s effects, and interaction with the backbone model’s predictive behaviors. These quantitative results can be explored in greater depth to identify correlations with pertinent clinical neuroscientific observations. Finally, a formal mathematical proof of KAM’s permutation equivariance property is included.},
  archive      = {J_NCA},
  author       = {Kuang, Dongyang and Michoski, Craig},
  doi          = {10.1007/s00521-023-09344-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5251-5266},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention with kernels for EEG-based emotion classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special perceptual parsing for chinese landscape painting
scene understanding: A semantic segmentation approach. <em>NCA</em>,
<em>36</em>(10), 5231–5249. (<a
href="https://doi.org/10.1007/s00521-023-09343-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic and precise perceptual parsing of Chinese landscape paintings (CLP) significantly aids in the digitization and recreation of artworks. Manual extraction and analysis of objects in CLPs is challenging, even for expert painters with professional knowledge and sharp discernment. Two main key reasons restricted the development of CLP parsing: (1) a lack of pixel-level labeled data used to supervise model training, and (2) the inherent complexity of CLP images compared to real scenes, characterized by varied scales, diverse textures, and intricate empty spaces. To address these challenges, we first construct a pixel-level annotated CLP segmentation datasets to advance perceptual parsing. Then, a novel CLP Perceptual Parsing (CLPPP) model is designed to fully utilize the intrinsic features of CLP images. To dynamically and adaptively capture context information, we introduced a set of learnable kernels into the CLPPP model based on the multiscale features of objects within CLPs. This enabled the model to learn an appropriate receptive field for context information extraction. Additionally, a positional attention head is devised to effectively eliminate noise from the intergroup and help the kernel gain inter-object position information. This iterative optimization process is helpful to learn powerful feature representations for different textures in CLPs. The experiment results demonstrate that the proposed CLPPP model outperforms state-of-the-art methods with mIoU, aAcc, and mAcc scores of 55.45, 75.08, and 71.15, respectively, achieving a large margin on the CLP dataset under consistent conditions.},
  archive      = {J_NCA},
  author       = {Yang, Rui and Yang, Honghong and Zhao, Min and Jia, Ru and Wu, Xiaojun and Zhang, Yumei},
  doi          = {10.1007/s00521-023-09343-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5231-5249},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special perceptual parsing for chinese landscape painting scene understanding: A semantic segmentation approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based deep supervised hashing for near duplicate
video retrieval. <em>NCA</em>, <em>36</em>(10), 5217–5230. (<a
href="https://doi.org/10.1007/s00521-023-09342-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of video data on the Internet, near duplicate video retrieval (NDVR) has become an important and challenging issue in the field of information retrieval. Hashing is typically employed to tackle this issue owing to its low memory and fast retrieval speed. Most of the existing video hashing methods directly adopt image hashing methods or perform the frame-pooling strategy, failing to fully explore the spatio-temporal information of videos. In this paper, we propose an attention-based deep supervised video hashing (ADVH) network for NDVR. To capture richer perceptions and acquire more comprehensive video representations, we use a residual network as the backbone and incorporate an attention module to extract spatio-temporal features of videos and motion information between adjacent frames. Moreover, we design a novel pairwise constraint utilizing supervised information to learn compact and discriminative video hash codes. The experimental results on three benchmark video datasets demonstrate that our proposed model outperforms other state-of-the-art hashing methods in retrieval precision.},
  archive      = {J_NCA},
  author       = {Shi, Naifei and Fu, Chong and Tie, Ming and Zhang, Wenchao and Wang, Xingwei and Sham, Chiu-Wing},
  doi          = {10.1007/s00521-023-09342-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5217-5230},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention-based deep supervised hashing for near duplicate video retrieval},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LIMFA: Label-irrelevant multi-domain feature alignment-based
fake news detection for unseen domain. <em>NCA</em>, <em>36</em>(10),
5197–5215. (<a
href="https://doi.org/10.1007/s00521-023-09340-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news in social networks causes disastrous effects on the real world yet effectively detecting newly emerged fake news remains difficult. This problem is particularly pronounced when the testing samples (target domain) are derived from different topics, events, platforms or time periods from the training dataset (source domains). Though efforts have focused on learning domain-invariant features (DIF) across multiple source domains to transfer universal knowledge from the source to the target domain, they ignore the complexity that arises when the number of source domains increases, resulting in unreliable DIF. In this paper, we first point out two challenges faced by learning DIF for fake news detection, (1) high intra-domain correlations, caused by the similarity of news samples within the same domain but different categories can be higher than that in different domains but the same categories, and (2) complex inter-domain correlations, stemming from that news samples in different domains are semantically related. To tackle these challenges, we propose two modules, center-aware feature alignment and likelihood gain-based feature disentanglement, to enhance the multiple domains alignment while enforcing two categories separated and disentangle the domain-specific features in an adversarial supervision manner. By combining these modules, we conduct a label-irrelevant multi-domain feature alignment (LIMFA) framework. Our experiments show that LIMFA can be deployed with various base models and it outperforms the state-of-the-art baselines in 4 cross-domain scenarios. Our source codes will be available upon the acceptance of this manuscript.},
  archive      = {J_NCA},
  author       = {Wu, Danke and Tan, Zhenhua and Zhao, Haoran and Jiang, Taotao and Qi, Meilin},
  doi          = {10.1007/s00521-023-09340-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5197-5215},
  shortjournal = {Neural Comput. Appl.},
  title        = {LIMFA: Label-irrelevant multi-domain feature alignment-based fake news detection for unseen domain},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel similarity measure based on new accuracy function on
interval-valued intuitionistic fuzzy number and its application to
multicriteria decision-making problem. <em>NCA</em>, <em>36</em>(10),
5183–5195. (<a
href="https://doi.org/10.1007/s00521-023-09313-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued intuitionistic fuzzy numbers (IVIFNs) are perfect to even more naturally model real-life issues and can be applied to several area like cluster analysis, decision-making, image processing, medical diagnosis, pattern recognition, etc. In particular, the similarity measures defined on IVIFNs take an important role in these fields effectively. Most of the researchers have tried to find a unique method (similarity measure) that may be appropriate for many problems. Apparently, there are several disadvantages to every one of them. First, in this paper, by using general accuracy function defined on IVIFNs, we define a new distance measure and hence a similarity measure for the class of IVIFNs. Second, some properties of these proposed measures are discussed by numerical problems. Third, the drawbacks of existing similarity measures are discussed and compared with the proposed similarity measure in various cases using numerical examples. Finally, the applicability of the proposed method for solving the problem of multicriteria decision making (MCDM) using TOPSIS technique is shown.},
  archive      = {J_NCA},
  author       = {Vishnukumar, P. and Edwin Antony Raj, M. and Sivaraman, Geetha},
  doi          = {10.1007/s00521-023-09313-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5183-5195},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel similarity measure based on new accuracy function on interval-valued intuitionistic fuzzy number and its application to multicriteria decision-making problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TomSevNet: A hybrid CNN model for accurate tomato disease
identification with severity level assessment. <em>NCA</em>,
<em>36</em>(10), 5165–5181. (<a
href="https://doi.org/10.1007/s00521-023-09351-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomato diseases are a major challenge for tomato growers, leading to significant yield losses and reduced quality of produce. Manual diagnosis of tomato diseases can be time-consuming and error-prone, making automated disease diagnosis an attractive solution. In this work, we develop a hybrid convolutional neural network (CNN) model using self-regulated layers and inception layer named as TomSevNet (Tom-Tomato disease Sev-Severity Net-Network) for accurate and efficient diagnosis of tomato diseases with severity levels. Our approach involves training a TomSevNet model on Plant Village dataset of tomato diseases segregated into different categories with their severity levels. The TomSevNet model is trained on a dataset containing 30 different classes belonging to nine tomato diseases of three severity levels, a healthy class, and two negative classes. Negative classes are included in the dataset to avoid misclassification problem. The TomSevNet classifier with Adadelta optimizer has performed extremely well and has attained the highest testing accuracy of 96.91% and the F1-score is 0.97. We also performed a comparison with other bench marked reference models, and the TomSevNet model outperformed them in terms of accuracy as well as F1-score.},
  archive      = {J_NCA},
  author       = {Shruthi, U. and Nagaveni, V.},
  doi          = {10.1007/s00521-023-09351-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5165-5181},
  shortjournal = {Neural Comput. Appl.},
  title        = {TomSevNet: A hybrid CNN model for accurate tomato disease identification with severity level assessment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised discriminative model prediction for visual
tracking. <em>NCA</em>, <em>36</em>(10), 5153–5164. (<a
href="https://doi.org/10.1007/s00521-023-09348-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discriminative model prediction (DiMP) object tracking model is an excellent end-to-end tracking framework and have achieved the best results of its time. However, there are two problems with DiMP in the process of actual use: (1) DiMP is prone to interference from similar objects during the tracking process, and (2) DiMP requires a large amount of labeled data for training. In this paper, we propose two methods to enhance the robustness of interference to similar objects in target tracking: multi-scale region search and Gaussian convolution-based response map processing. Simultaneously, aiming at tackling the issue of requiring a large amount of labeled data for training, we implement self-supervised training based on forward-backward tracking for the DiMP tracking method. Furthermore, a new consistency loss function is designed to better self-supervised training. Extensive experiments show that the enhancements implemented in the DiMP tracking framework can bolster its robustness, and the tracker based on self-supervised training has outstanding tracking performance.},
  archive      = {J_NCA},
  author       = {Yuan, Di and Geng, Gu and Shu, Xiu and Liu, Qiao and Chang, Xiaojun and He, Zhenyu and Shi, Guangming},
  doi          = {10.1007/s00521-023-09348-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5153-5164},
  shortjournal = {Neural Comput. Appl.},
  title        = {Self-supervised discriminative model prediction for visual tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging self-paced learning and deep sparse embedding for
image clustering. <em>NCA</em>, <em>36</em>(10), 5135–5151. (<a
href="https://doi.org/10.1007/s00521-023-09335-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering outperforms traditional methods by incorporating feature learning. However, some existing deep clustering methods overlook the suitability of the learned features for clustering, leading to insufficient feedback received by the clustering model and hampering the accuracy improvement. To tackle these issues, we propose a joint self-paced learning and deep sparse embedding for image clustering. Our method consists of two stages: pretraining and finetuning. In the pretraining stage, the autoencoder learns basic features and constructs the feature space. In the finetuning stage, method performs two tasks: feature learning and cluster assignment. Specifically, we finetune the encoder with both original and augmented data to preserve the local structure in the feature space. Self-paced learning guarantees that the most confident features are used for each iteration and mitigates the influence of boundary samples. Furthermore, sparse embedding ensures that the model encodes only key features in feature learning tasks, thereby avoiding incorrect calculations resulting from redundant features. Finally, we jointly optimize these two tasks to complete the feature learning for clustering. Extensive experiments on various datasets demonstrate that our approach outperforms existing solutions.},
  archive      = {J_NCA},
  author       = {Liu, Yanming and Liu, Jinglei},
  doi          = {10.1007/s00521-023-09335-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5135-5151},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging self-paced learning and deep sparse embedding for image clustering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: A novel qualitative risk assessment using the
interval-valued spherical fuzzy extension of TOPSIS method: A case study
in rail transit systems. <em>NCA</em>, <em>36</em>(10), 5133. (<a
href="https://doi.org/10.1007/s00521-023-09414-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ak, Muhammet Fatih and Demir, Emre},
  doi          = {10.1007/s00521-023-09414-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5133},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: a novel qualitative risk assessment using the interval-valued spherical fuzzy extension of TOPSIS method: a case study in rail transit systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A novel qualitative risk assessment using the
interval-valued spherical fuzzy extension of TOPSIS method: A case study
in rail transit systems. <em>NCA</em>, <em>36</em>(10), 5109–5132. (<a
href="https://doi.org/10.1007/s00521-023-09224-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces an innovative approach for risk assessment in rail transit systems, addressing the limitations of traditional methodologies. Our proposed method combines the modified Fine–Kinney approach with the interval-valued spherical fuzzy extension of the technique for order of preference by similarity to ideal solution (IVSF-TOPSIS). By leveraging interval-valued fuzzy sets and spherical fuzzy sets, we capture nuanced uncertainties more effectively. This study differs from previous risk assessment methods by integrating IVSF sets into Fine–Kinney methodologies. Unlike traditional methods, our approach integrates IVSF sets to enhance the handling of uncertainty, resulting in a more comprehensive risk assessment. The proposed model includes parameters such as cost, preventability, and personal protective use, alongside severity, probability, and frequency. This inclusion, alongside expert opinions, enriches the analysis and ensures a more realistic risk evaluation. Applied to the Antalya rail transit (ANTRAY) system in Turkey, the study demonstrates the method’s applicability through a comprehensive case study. Four experts with extensive field and academic experience in rail transit systems and risk analysis contributed their evaluations, ensuring the thoroughness and accuracy of the results. Limited experts’ input yields consistent and high-correlation findings, enhancing result validity and applicability. Eight most exposed hazard groups, analyzed in this study, aid in producing applicable solutions for risk mitigation. The outcomes provide a prioritized list of risks and actionable insights for managing these risks effectively. By combining quantitative and qualitative data through interval-valued fuzzy sets, our approach bridges the gap between different types of information, resulting in a holistic and reliable risk assessment. Consequently, our novel methodology not only overcomes the limitations of traditional approaches but also offers a practical and comprehensive framework for decision making. By providing a clearer understanding of uncertainties and their impacts, our approach contributes to safer and more efficient rail transit operations.},
  archive      = {J_NCA},
  author       = {Ak, Muhammet Fatih and Demir, Emre},
  doi          = {10.1007/s00521-023-09224-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {5109-5132},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel qualitative risk assessment using the interval-valued spherical fuzzy extension of TOPSIS method: A case study in rail transit systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fall detection on embedded platform using infrared array
sensor for healthcare applications. <em>NCA</em>, <em>36</em>(9),
5093–5108. (<a
href="https://doi.org/10.1007/s00521-023-09334-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous vision-based research has predominantly used common visible light cameras as sensors for detecting falls in home environments. While some studies have explored the use of infrared cameras for this purpose, personal privacy protection and computational capability on an embedded platform remain crucial concerns. To address these challenges and achieve accurate human fall detection on an embedded platform, we propose a new lightweight human fall detection method based on a deep learning network. In the first stage, we designed an image acquisition device based on an infrared array sensor to collect an infrared human fall dataset ( https://github.com/Flier-01/Deeplearning-based-Fall-Detection-Using-Infrared-Array-Dataset ). This dataset consists of 10240 images, including 5216 pictures of falls, 4024 pictures of non-fall walking, and 1000 pictures of other poses. Furthermore, we have included an additional set of 10 videos specifically for testing purposes. These images were captured within living environments with varying ambient temperatures. To address challenges associated with infrared images, such as excessive noise and low definition, we adopted the RetinexNet algorithm to preprocess the collected images. This pre-processing step significantly improves the quality of the infrared images, enabling more accurate analysis and detection. Subsequently, we developed a modified YOLOv5 network that incorporates a comprehensive enhancement strategy by integrating the CBAM and TPH modules. These modules enhance the network’s ability to capture and extract features relevant to fall detection. Furthermore, to optimize the network’s performance, we employed the GhostNet architecture and deployed the resulting model on the Huawei Altas embedded platform. Through video testing, our fall detection system achieved a real-time detection frame rate of 38.61 FPS, surpassing the performance of the original YOLOv5-based fall detector, which attained a frame rate of 34.78 FPS. Notably, our proposed method demonstrated remarkable performance in terms of fall detection accuracy. The average accuracy of our fall detector reached an impressive 96.52%, outperforming the original YOLOv5 fall detector, which achieved an average accuracy of 88.46%. These experimental results affirm the superiority of our approach, exhibiting improved fall detection accuracy and real-time performance compared to the original YOLOv5 algorithm.},
  archive      = {J_NCA},
  author       = {Jiang, Yan and Gong, Tianyi and He, Lingfeng and Yan, Shicheng and Wu, Xiaoping and Liu, Jianyang},
  doi          = {10.1007/s00521-023-09334-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {5093-5108},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fall detection on embedded platform using infrared array sensor for healthcare applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised video-based action recognition using two-stream
generative adversarial network. <em>NCA</em>, <em>36</em>(9), 5077–5091.
(<a href="https://doi.org/10.1007/s00521-023-09333-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based action recognition faces many challenges, such as complex and varied dynamic motion, spatio-temporal similar action factors, and manual labeling of archived videos over large datasets. How to extract discriminative spatio-temporal action features in videos with resisting the effect of similar factors in an unsupervised manner is pivotal. For that, this paper proposes an unsupervised video-based action recognition method, called two-stream generative adversarial network (TS-GAN), which comprehensively learns the static texture and dynamic motion information inherited in videos with taking the detail information and global information into account. Specifically, the extraction of the spatio-temporal information in videos is achieved by a two-stream GAN. Considering that proper attention to detail is capable of alleviating the influence of spatio-temporal similar factors to the network, a global-detailed layer is proposed to resist similar factors via fusing intermediate features (i.e., detailed action information) and high-level semantic features (i.e., global action information). It is worthwhile of mentioning that the proposed TS-GAN does not require complex pretext tasks or the construction of positive and negative sample pairs, compared with recent unsupervised video-based action recognition methods. Extensive experiments conducted on the UCF101 and HMDB51 datasets have demonstrated that the proposed TS-GAN is superior to multiple classical and state-of-the-art unsupervised action recognition methods.},
  archive      = {J_NCA},
  author       = {Lin, Wei and Zeng, Huanqiang and Zhu, Jianqing and Hsia, Chih-Hsien and Hou, Junhui and Ma, Kai-Kuang},
  doi          = {10.1007/s00521-023-09333-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {5077-5091},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised video-based action recognition using two-stream generative adversarial network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A convolutional neural network framework to design power
system stabilizer for damping oscillations in multi-machine power
system. <em>NCA</em>, <em>36</em>(9), 5059–5075. (<a
href="https://doi.org/10.1007/s00521-023-09323-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern power system networks are inherently complex and susceptible to a range of undesirable events, such as line and generator outages, transmission line faults, and power oscillations. These power oscillations arise following disturbances, causing generators to oscillate in relation to one another. Effectively damping these oscillations is crucial for ensuring the reliable operation of the overall system. In light of this, our research employs a convolutional neural network (CNN) approach to fine-tune the parameters of a conventional power system stabilizer (PSS). The goal is to enhance the damping of power oscillations triggered by abrupt disturbances in a multi-machine system. In the process of training the neural network, input vectors are transformed into image vectors and subsequently trained using a CNN architecture. This trained network is then utilized to derive optimized PSS parameters from test data. The proposed CNN-based PSS is rigorously evaluated across a variety of operational scenarios, demonstrating its effectiveness in enhancing power oscillation damping in both single-machine infinite bus and multi-machine systems. Time-domain simulations are conducted to analyze rotor speed and rotor angle deviations within the system equipped with the proposed CNN-based PSS. Comparative assessments are made against systems employing different conventional PSS configurations and systems without PSS. The advantages of CNN-based PSS are its ability to capture complex patterns and relationships in the data, enabling it to effectively learn and adapt to various operating conditions, resulting in improved damping performance. Remarkably, our proposed PSS exhibits superior performance in terms of damping power oscillations, effectively outperforming conventional PSS approaches.},
  archive      = {J_NCA},
  author       = {Sarkar, Devesh Umesh and Prakash, Tapan},
  doi          = {10.1007/s00521-023-09323-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {5059-5075},
  shortjournal = {Neural Comput. Appl.},
  title        = {A convolutional neural network framework to design power system stabilizer for damping oscillations in multi-machine power system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PolyDSS: Computer-aided decision support system for
multiclass polyp segmentation and classification using deep learning.
<em>NCA</em>, <em>36</em>(9), 5031–5057. (<a
href="https://doi.org/10.1007/s00521-023-09358-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) is a malignant condition that affects the colon or rectum, and it is distinguished by abnormal cell growth in these areas. Colon polyps, which are abnormalities, can turn into cancer. To stop the spread of cancer, early polyp detection is essential. The timely removal of polyps without submitting a sample for histology is made possible by computer-assisted polyp classification. In addition to Locally Shared Features (LSF) and ensemble learning majority voting, this paper introduces a computer-aided decision support system named PolyDSS to assist endoscopists in segmenting and classifying various polyp classes using deep learning models like ResUNet and ResUNet++ and transfer learning models like EfficientNet. The PICCOLO dataset is used to train and test the PolyDSS model. To address the issue of class imbalance, data augmentation techniques were used on the dataset. To investigate the impact of each technique on the model, extensive experiments were conducted. While the classification module achieved the highest accuracy of 0.9425 by utilizing the strength of ensemble learning using majority voting, the proposed segmenting module achieved the highest Dice Similarity Coefficient (DSC) of 0.9244 using ResUNet++ and LSF. In conjunction with the Paris classification system, the PolyDSS model, with its significant results, can assist clinicians in identifying polyps early and choosing the best approach to treatment.},
  archive      = {J_NCA},
  author       = {Saad, Abdelrahman I. and Maghraby, Fahima A. and Badawy, Osama M.},
  doi          = {10.1007/s00521-023-09358-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {5031-5057},
  shortjournal = {Neural Comput. Appl.},
  title        = {PolyDSS: Computer-aided decision support system for multiclass polyp segmentation and classification using deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anterior cruciate ligament tear detection based on
convolutional neural network and generative adversarial neural network.
<em>NCA</em>, <em>36</em>(9), 5021–5030. (<a
href="https://doi.org/10.1007/s00521-023-09350-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knee ligament tear injury is frequent in many volleyball, football, basketball, and cricket players. In the past, various deep learning-based ACL tear detection schemes using knee magnetic resonance imaging (MRI) have been presented. It has shown challenges in ACL tear detection performance due to class imbalance issue arising due to uneven training samples and poor feature representation. This paper presents a simple and effective ACL knee ligament tear detection method with a convolutional neural network (ATD-CNN) to lessen the intricacy of the network. Further, the self-attention mechanism is used to improve the feature representation of MRI image information, neglect the irrelevant information in deep features, and enhance the classification accuracy. To diminish the class imbalance issue, generative adversarial network (GAN) is used to construct the synthetic database. The performance of the ATD-CNN with self-attention is assessed on the MRNet database using precision, accuracy, F1-score, and recall. ATD-CNN provides an accuracy of 90.10% for the original and 93.93% and augmented datasets. However, the ATD-CNN without attention mechanism resulted in 89.60% and 92.30% accuracy for original and augmented dataset. The proposed ATD-CNN model indicates that it can be utilized to detect ACL tears automatically and outperforms the existing schemes for tear detection.},
  archive      = {J_NCA},
  author       = {Joshi, Kavita and Suganthi, K.},
  doi          = {10.1007/s00521-023-09350-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {5021-5030},
  shortjournal = {Neural Comput. Appl.},
  title        = {Anterior cruciate ligament tear detection based on convolutional neural network and generative adversarial neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-national CT image-label pairs synthesis for COVID-19
diagnosis via few-shot generative adversarial networks adaptation.
<em>NCA</em>, <em>36</em>(9), 5007–5019. (<a
href="https://doi.org/10.1007/s00521-023-09317-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus disease 2019 (COVID-19) is an ongoing global pandemic that has threatened health worldwide for years, necessitating accurate and rapid diagnostic techniques given its high pathogenicity and transmissibility. Numerous deep learning models have been developed to assist radiologists in chest computed tomography (CT)-based COVID-19 diagnosis. However, existing COVID-19 CT datasets is often characterized by significant geographic and class imbalances, which impede the model’s ability to generalize effectively across varying patient cohorts. With the advancements in generative adversarial networks (GAN), one potential solution to the problem is to synthesize data for the target datasets by leveraging a large-scale source dataset for pre-training (i.e., few-shot GAN adaptation). To calibrate the target GAN during adaptation, we incorporate contrastive learning coupled with LeCam regularization, ensuring that the diversity inherent in the source dataset is preserved. Additionally, overfitting is mitigated through the use of consistency regularization and differentiable augmentation techniques. Also, we incorporate off-the-shelf vision models into the discriminator ensemble, predicated on the linear separability between real and fake samples in the feature space, thereby encouraging the generator to match the real distribution in different, complementary feature spaces. We demonstrate the effectiveness of our approach in improving COVID-19 diagnostic performance by generating realistic and diverse CT image-label pairs for the target datasets and show that it consistently outperforms the state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {Zhang, Jing and Xie, Yingpeng and Sun, Dandan and Huang, Ruidong and Wang, Tianfu and Lei, Baiying and Chen, Kuntao},
  doi          = {10.1007/s00521-023-09317-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {5007-5019},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-national CT image-label pairs synthesis for COVID-19 diagnosis via few-shot generative adversarial networks adaptation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Customer profiling, segmentation, and sales prediction using
AI in direct marketing. <em>NCA</em>, <em>36</em>(9), 4995–5005. (<a
href="https://doi.org/10.1007/s00521-023-09339-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current business environment, where the customer is the primary focus, effective communication between marketing and senior management is vital for success. Effective customer profiling is a cornerstone of strategic decision-making for digital start-ups seeking sustainable growth and customer satisfaction. This research investigates the clustering of customers based on recency, frequency, and monetary (RFM) analysis and employs validation metrics to derive optimal clusters. The K-means clustering algorithm, coupled with the Elbow method, Silhouette coefficient, and Gap Statistics method, facilitates the identification of distinct customer segments. The study unveils three primary clusters with unique characteristics: new customers (Cluster A), best customers (Cluster B), and intermittent customers (Cluster C). For platform-based Edutech start-ups, Cluster A underscores the importance of tailored learning content and support, Cluster B emphasizes personalized incentives, and Cluster C suggests re-engagement strategies. By understanding and addressing the diverse needs of these clusters, digital start-ups can forge enduring connections, optimize customer engagement, and fuel sustainable business growth.},
  archive      = {J_NCA},
  author       = {Kasem, Mahmoud SalahEldin and Hamada, Mohamed and Taj-Eddin, Islam},
  doi          = {10.1007/s00521-023-09339-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4995-5005},
  shortjournal = {Neural Comput. Appl.},
  title        = {Customer profiling, segmentation, and sales prediction using AI in direct marketing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-enabled adaptive markov graph convolution.
<em>NCA</em>, <em>36</em>(9), 4979–4993. (<a
href="https://doi.org/10.1007/s00521-023-09338-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GNNs (Graph Neural Networks) have attracted increasing attention for their strong power on dealing with the graph structures. However, it remains a challenge to design an ideal GNN suitable for various downstream tasks. By revisiting the framework of MPNN (Message Passing Neural Network), we argue that an ideal GNN should satisfy following two conditions. First, the node embedding can absorb the knowledge from a wide range of neighbors while maintaining locality. Second, the first-order information aggregation can adapt to unknown graphs. In this paper, we first extend $$\rm{S}^{2} \rm{GC}$$ to GMGC (Generalized Markov Graph Convolution), which can maintain the node locality regardless the type of the embedded diffusion kernel. Next, we embed the improved self-gating mechanism into the GMGC framework and propose a novel model named AMGC (Attention-enabled Adaptive Markov Graph Convolution), which well satisfies the above conditions. Moreover, the advantages of AMGC can be explained in the frequency domain. First, the frequency of the first-order diffusion kernel is adaptive and no longer limited to low-pass as $$\rm{S}^{2} \rm{GC}$$ . Second, the multi-order diffusion kernel can retain more components around the core frequency compared with FAGCN. To verify the ability of AMGC, extensive experiments are conducted, including graph regression, graph classification and semi-supervised node classification. The results show that AMGC can achieve comparable performance in all graph tasks.},
  archive      = {J_NCA},
  author       = {Wang, Tianfeng and Pan, Zhisong and Hu, Guyu and Hu, Yahao},
  doi          = {10.1007/s00521-023-09338-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4979-4993},
  shortjournal = {Neural Comput. Appl.},
  title        = {Attention-enabled adaptive markov graph convolution},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cucumber diseases diagnosis based on multi-class SVM and
electronic medical record. <em>NCA</em>, <em>36</em>(9), 4959–4978. (<a
href="https://doi.org/10.1007/s00521-023-09337-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cucumber is one of the most popular vegetable varieties, but leaf disease of cucumber is the key factor restricting the increase of yield. Common cucumber diseases include downy mildew, powdery mildew and gray mold. The plant electronic medical records (PEMRs) formed by “plant clinic” are the diagnosis record of the real disease occurrence issued by the plant doctor, which provides a new idea for the cucumber disease diagnosis. The efficient mining of prescription big data to facilitate precise diagnoses of crop pests and diseases represents an emerging challenge. The data mining technology represented by machine learning has attracted wide attention. Therefore, 15 diagnosis models are proposed to deal with this problem. Since SVM has many advantages including implementing the structural risk minimization principle and can effectively deal with the small sample data, five algorithms based on SVM have achieved better diagnosis performance in comparison with others. Moreover, the highest prediction accuracy is beyond 80%. In addition, the prediction performance has been improved after employing the undersampling technology for the imbalanced data. This means they are suitable for this cucumber diseases diagnosis.},
  archive      = {J_NCA},
  author       = {Xu, Chang and Zhang, Lingxian},
  doi          = {10.1007/s00521-023-09337-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4959-4978},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cucumber diseases diagnosis based on multi-class SVM and electronic medical record},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MissBeamNet: Learning missing doppler velocity log beam
measurements. <em>NCA</em>, <em>36</em>(9), 4947–4958. (<a
href="https://doi.org/10.1007/s00521-023-09303-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the primary means of sea exploration is autonomous underwater vehicles (AUVs). To perform these tasks, AUVs must navigate the rough challenging sea environment. AUVs usually employ an inertial navigation system (INS), aided by a Doppler velocity log (DVL), to provide the required navigation accuracy. The DVL transmits four acoustic beams to the seafloor, and by measuring changes in the frequency of the returning beams, the DVL can estimate the AUV velocity vector. However, in practical scenarios, not all the beams are successfully reflected. When only three beams are available, the accuracy of the velocity vector is degraded. When fewer than three beams are reflected, the DVL cannot estimate the AUV velocity vector. For such situations, only model-based approaches have been proposed to estimate missing beams. This paper presents a data-driven approach, MissBeamNet, to regress the missing beams in partial DVL beam measurement cases. To that end, a deep neural network (DNN) model is designed to process the available beams along with past DVL measurements to regress the missing beams. The AUV velocity vector is estimated using the available measured and regressed beams. To validate the proposed approach, sea experiments were made with the &quot;Snapir&quot; AUV, resulting in an 11 h dataset of DVL measurements. Our results show that the proposed system can accurately estimate velocity vectors in situations of missing beam measurements. Our dataset and codebase implementing the described framework is available at: https://github.com/ansfl/MissBeamNet .},
  archive      = {J_NCA},
  author       = {Yona, Mor and Klein, Itzik},
  doi          = {10.1007/s00521-023-09303-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4947-4958},
  shortjournal = {Neural Comput. Appl.},
  title        = {MissBeamNet: Learning missing doppler velocity log beam measurements},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new multi-domain cooperative resource scheduling method
using proximal policy optimization. <em>NCA</em>, <em>36</em>(9),
4931–4945. (<a
href="https://doi.org/10.1007/s00521-023-09326-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the complex environment and massive multi-source data, the capability of multi-domain cooperative resource scheduling has become extremely important. Optimal scheduling can reduce operating costs and time, and MDLS is still the most commonly utilized algorithm in combat task scheduling today, despite of its defects. This research provides a plausible new method for the MDCRS problem, a resource scheduling method based on deep reinforcement learning (DRL), which has proven to be effective for other scheduling problems. Aiming at the resource scheduling problem in the multi-domain cooperative operation, under timing constraints, an MDCRS model is created using the shortest completion time as the objective function. On this premise, this paper presents an MDCRS-MDP model based on Markov decision processes, in which a two-dimensional action space that can simultaneously allocate action and match platform is designed and a dense reward function with strong connections to the criterion for sparse makespan minimization is provided. A resource scheduling approach utilizing DRL is proposed, including task-platform matching and task sequencing, based on the MDCRS-MDP model. Finally, combined with the joint landing operation, the experimental results verify the effectiveness of the proposed method for solving MDCRS and demonstrate the significant advantages over traditional dispatching rules and meta-heuristic optimization algorithms.},
  archive      = {J_NCA},
  author       = {Liu, Haiying and He, Zhaoyi and Wang, Rui and Huang, Kuihua and Cheng, Guangquan},
  doi          = {10.1007/s00521-023-09326-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4931-4945},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new multi-domain cooperative resource scheduling method using proximal policy optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified kernel sparse representation framework for
supervised learning problems. <em>NCA</em>, <em>36</em>(9), 4907–4930.
(<a href="https://doi.org/10.1007/s00521-023-09321-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For supervised learning problems, a unified kernel sparse representation framework is proposed. It is applicable to almost all supervised learners in order to look for kernel representation hypersurface, such as SVM-type or TSVM-type models. Focusing on classification and regression problems in supervised learning, three concrete sparse TSVM-type models are constructed by incorporating specific regularization terms and loss functions. Our methods involve selecting L representative points from the entire training set using the GRPS algorithm. The sparsization parameter L significantly reduces computational complexity by avoiding the need to process all training points. As a result, both the optimization problems and prediction computation costs for new instances are reduced. By comparing our sparse TSVMs with the methods based on the sparse norm regularization terms, our sparsization parameter L is more intuitional than their regularization parameter. Interestingly enough, the numerical experiments on four artificial datasets and 20 benchmark datasets demonstrate that our methods require less prediction time and exhibit better generalization ability when the sparsization parameter L is taken as a small value, i.e., $$L\ll N$$ .},
  archive      = {J_NCA},
  author       = {Ye, Junyou and Yang, Zhixia and Zhu, Yongqi and Zhang, Zheng},
  doi          = {10.1007/s00521-023-09321-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4907-4930},
  shortjournal = {Neural Comput. Appl.},
  title        = {A unified kernel sparse representation framework for supervised learning problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast deep learning with tight frame wavelets. <em>NCA</em>,
<em>36</em>(9), 4885–4905. (<a
href="https://doi.org/10.1007/s00521-023-09260-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cost function gradient vanishing or exploding problem and slow convergence speed are key issues when training deep neural networks (DNNs). In this paper, we investigate the forward and backward propagation processes of DNN training and explore the properties of the activation function and derivative function (ADF) employed. The outputs’ distribution of ADF with near-zero mean is proposed to reduce gradient problems. Additionally, the constant energy transfer of propagating data in the training process is also proposed to speed up convergence further. Based on wavelet frame theory, we derive a novel ADF, i.e., tight frame wavelet activation function (TFWAF) and tight frame wavelet derivative function (TFWDF) of the Mexican hat wavelet, to stabilize and accelerate DNN training. The nonlinearity of wavelet functions can strengthen the learning capacity of DNN models, while the sparse property of wavelets derived can reduce the overfitting problem and enhance the robustness of models. Experiments demonstrate that the proposed method stabilizes the DNN training process and accelerates convergence.},
  archive      = {J_NCA},
  author       = {Cao, Haitao},
  doi          = {10.1007/s00521-023-09260-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4885-4905},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fast deep learning with tight frame wavelets},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predict customer churn using combination deep learning
networks model. <em>NCA</em>, <em>36</em>(9), 4867–4883. (<a
href="https://doi.org/10.1007/s00521-023-09327-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customers churn is an important issue that is always concerned by banks, and is put at the forefront of the bank’s policies. The fact that banks can identify customers who are intending to leave the service can help banks promptly make policies to retain customers. In this paper, we propose a combined deep learning network models to predict customers leaving or staying at the bank. The proposed model consists of two levels, Level 0 consists of three basic models using three Deep Learning Neural Networks, and Level 1 is a logistic regression model. The proposed model has obtained evaluation results with accuracy metrics of 96.60%, precision metrics of 90.26%, recall metrics of 91.91% and F1 score of 91.07% on the dataset “Bank Customer Churn Prediction”.},
  archive      = {J_NCA},
  author       = {Vu, Van-Hieu},
  doi          = {10.1007/s00521-023-09327-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4867-4883},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predict customer churn using combination deep learning networks model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward interpretable credit scoring: Integrating explainable
artificial intelligence with deep learning for credit card default
prediction. <em>NCA</em>, <em>36</em>(9), 4847–4865. (<a
href="https://doi.org/10.1007/s00521-023-09232-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the increasing prevalence of credit card usage has raised concerns about accurately predicting and managing credit card defaults. While machine learning and deep learning methods have shown promising results in default prediction, the black-box nature of these models often limits their interpretability and practical adoption. This study presents a new method for predicting credit card default using a combination of deep learning and explainable artificial intelligence (XAI) techniques. Integrating these methods aims to improve the interpretability of the decision-making process involved in credit card default prediction. The proposed approach is evaluated using a real-world dataset and compared to existing state-of-the-art models. Results show that the proposed approach achieves competitive prediction accuracy while providing meaningful insights into the factors driving credit card default risk. The present investigation adds to the increasing body of literature on explainable artificial intelligence (AI) in the realm of finance. Besides, it provides a pragmatic approach to assessing credit risk, balancing precision and comprehensibility. In conclusion, the model demonstrates strong potential as a credit risk assessment tool, with an accuracy of 0.8350, sensitivity of 0.8823, and specificity of 0.9879. Among the most important features identified by the model are payment delays and outstanding bill amounts. This study is a step toward more interpretable and transparent credit scoring models.},
  archive      = {J_NCA},
  author       = {Talaat, Fatma M. and Aljadani, Abdussalam and Badawy, Mahmoud and Elhosseini, Mostafa},
  doi          = {10.1007/s00521-023-09232-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4847-4865},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward interpretable credit scoring: Integrating explainable artificial intelligence with deep learning for credit card default prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MGCRL: Multi-view graph convolution and multi-agent
reinforcement learning for dialogue state tracking. <em>NCA</em>,
<em>36</em>(9), 4829–4846. (<a
href="https://doi.org/10.1007/s00521-023-09328-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue state tracking (DST) is a significant part of prevalent task-oriented dialogue systems, which monitor the user’s goals based on current and previous dialogues for effective dialogue management. However, most existing approaches train DST on a single domain, ignoring the information across domains, and thus relevant slots in each domain must learn to cooperate. This paper deals this challenge by introducing a multi-view graph convolution and multi-agent reinforcement learning (MGCRL) method to help each domain-specific slot to learn to cooperate. Specifically, first, a multi-view graph is presented to provide more related information to transfer structured features among domain-specific slots across various domains. Compared with a single-view graph, multi-view has better complementarity, incorporating additional graphs for learning multiple types of association, thus improving the cross-domain information-sharing capability of DST models. On this basis, a multi-agent reinforcement learning method is presented to train DST models. Compared to current reinforcement learning methods used in DST models, the proposed multi-agent reinforcement learning utilizing multi-view graph convolutional networks allows each agent to learn to cooperate in multi-agent environments. Experimental results on the widely-used datasets MultiWOZ (Multi-Domain Wizard-of-Oz) 2.0/2.1 demonstrate that the proposed MGCRL method achieves a higher joint goal accuracy than the existing state-of-the-art DST models.},
  archive      = {J_NCA},
  author       = {Huang, Zhenhua and Li, Fancong and Yao, Juanjuan and Chen, Zonggan},
  doi          = {10.1007/s00521-023-09328-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4829-4846},
  shortjournal = {Neural Comput. Appl.},
  title        = {MGCRL: Multi-view graph convolution and multi-agent reinforcement learning for dialogue state tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new super-predefined-time convergence and noise-tolerant
RNN for solving time-variant linear matrix–vector inequality in noisy
environment and its application to robot arm. <em>NCA</em>,
<em>36</em>(9), 4811–4827. (<a
href="https://doi.org/10.1007/s00521-023-09264-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) are excellent solvers for time-variant linear matrix–vector inequality (TVLMVI). However, it is difficult for traditional RNNs to track the theoretical solution of TVLMVI under non-ideal conditions [e.g., noisy environment]. Therefore, by introducing a novel nonlinear activation function (NNAF) and time-variant-gain, a new super-predefined-time convergence and noise-tolerant RNN (SPCNT-RNN) is proposed to acquire an online solution to TVLMVI in noisy environment. The difference between SPCNT-RNN and traditional fixed-parameter RNNs (FP-RNNs) is that the error function equation of SPCNT-RNN has NNAF and time-variant-gain coefficient. Due to this difference, the SPCNT-RNN can achieve super-predefined-time convergence in both noise-free and noisy environments, which is superior to that of existing RNNs. The stability, super-predefined-time convergence, and robustness of SPCNT-RNN are theoretically demonstrated. Moreover, the simulation results between various existing RNNs and SPCNT-RNN verify the feasibility, validity, robustness and rapid convergence effect of the proposed SPCNT-RNN.},
  archive      = {J_NCA},
  author       = {Zheng, Boyu and Yue, Chong and Wang, Qianqian and Li, Chunquan and Zhang, Zhijun and Yu, Junzhi and Liu, Peter X.},
  doi          = {10.1007/s00521-023-09264-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4811-4827},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new super-predefined-time convergence and noise-tolerant RNN for solving time-variant linear matrix–vector inequality in noisy environment and its application to robot arm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CTNet: Convolutional transformer network for diabetic
retinopathy classification. <em>NCA</em>, <em>36</em>(9), 4787–4809. (<a
href="https://doi.org/10.1007/s00521-023-09304-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, diabetic retinopathy diagnosis tools use deep learning and machine learning algorithms for fundus image classification. Deep learning techniques especially convolution neural networks (CNNs) showed outstanding results in the area of lesion detection, segmentation, and diabetic retinopathy classification. Despite high performance, CNNs focus on spatial locality due to strong spatial learning bias and ignore long-range perspectives. To address this issue, the use of transformers is evolving in the computer vision domain. The present work proposes a lightweight diabetic retinopathy classification method—CTNet, using the combination of CNN and Transformers on fundus images to capture both local and global spatial features. Specifically, first, a convolution module is designed with residual connections for extracting local lesion features. Then a transformer module patchifies these features into a sequence of small patches and determines a global long-range perspective focusing on how much focus one lesion places on other lesions of the sequence using self-attention. Finally, pooling is performed on a sequence of patches instead of using memory-inefficient class tokens to generate a single index for classification. The proposed CTNet model requires 823,555 parameters and obtains consistent performance of (0.987 AUC, 0.972 Kappa), and (0.990 AUC, 0.975 Kappa) scores on APTOS and IDRiD datasets, respectively.},
  archive      = {J_NCA},
  author       = {Bala, Ruchika and Sharma, Arun and Goel, Nidhi},
  doi          = {10.1007/s00521-023-09304-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4787-4809},
  shortjournal = {Neural Comput. Appl.},
  title        = {CTNet: Convolutional transformer network for diabetic retinopathy classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SEB-ChOA: An improved chimp optimization algorithm using
spiral exploitation behavior. <em>NCA</em>, <em>36</em>(9), 4763–4786.
(<a href="https://doi.org/10.1007/s00521-023-09236-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The chimp optimization algorithm (ChOA) is a nature-inspired algorithm that imitates chimpanzees’ individual intelligence and hunting behaviors. In this algorithm, the hunting process consists of four steps: driving, blocking, chasing, and attacking. Because of the novelty of ChOA, the steps of the hunting process have been modeled in the simplest possible way, leading to slow and premature convergence similar to other iterative algorithms. This paper proposes six spiral functions and introduces two novel hybrid spiral functions (SEB-ChOA) to rectify the abovementioned deficiencies. The SEB-ChOAs’ performance is evaluated on 23 standard benchmarks, 20 benchmarks of IEEE CEC-2005, 10 cases of IEEE CEC06-2019 test-suite, and 12 constrained real-world engineering problems of IEEE CEC-2020. The SEB-ChOAs are compared with three groups of optimization algorithms, including Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) as the most well-known optimization algorithms, Slime Mould Algorithm (SMA), Marine Predators Algorithm (MPA), Ant Lion Optimization (ALO), Henry Gas Solubility Optimization (HGSO), as almost novel optimization algorithms, and jDE100 and DISHchain1e+12, as winners of IEEE CEC06-2019 competition, and also EBOwithCMAR and CIPDE as superior secondary optimization algorithms. The SEB-ChOAs reached the first rank among almost all benchmarks and demonstrated very competitive results compared to jDE100 and DISHchain1e+12 as the best-performing optimizers. Statistical evidence shows that the SEB-ChOA outperforms the PSO, GA, SMA, MPA, ALO, and HGSO optimizers while producing results comparable to those of the jDE100 and DISHchain1e+12 algorithms.},
  archive      = {J_NCA},
  author       = {Qian, Leren and Khishe, Mohammad and Huang, Yiqian and Mirjalili, Seyedali},
  doi          = {10.1007/s00521-023-09236-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4763-4786},
  shortjournal = {Neural Comput. Appl.},
  title        = {SEB-ChOA: An improved chimp optimization algorithm using spiral exploitation behavior},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seeing both sides: Context-aware heterogeneous graph
matching networks for extracting-related arguments. <em>NCA</em>,
<em>36</em>(9), 4741–4762. (<a
href="https://doi.org/10.1007/s00521-023-09250-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research focuses on extracting exchanged views from dialogical documents through argument pair extraction (APE). The objective of this process is to facilitate comprehension of complex argumentative discourse by finding the related arguments. The APE comprises two stages: argument mining and argument matching. Researchers typically employ sequence labeling models for mining arguments and text matching models to calculate the relationships between them, thereby generating argument pairs. However, these approaches fail to capture long-distance contextual information and struggle to fully comprehend the complex structure of arguments. In our work, we propose the context-aware heterogeneous graph matching (HGMN) model for the APE task. First, we design a graph schema specifically tailored to argumentative texts, along with a heterogeneous graph attention network that effectively captures context information and structural information of arguments. Moreover, the text matching between arguments is converted into a graph matching paradigm and a multi-granularity graph matching model is proposed to handle the intricate relationships between arguments at various levels of granularity. In this way, the semantics of argument are modeled structurally and thus capture the complicated correlations between arguments. Extensive experiments are conducted to evaluate the HGMN model, including comparisons with existing methods and the GPT series of large language models (LLM). The results demonstrate that HGMN outperforms the state-of-the-art method.},
  archive      = {J_NCA},
  author       = {Mao, Tiezheng and Yoshie, Osamu and Fu, Jialing and Mao, Weixin},
  doi          = {10.1007/s00521-023-09250-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4741-4762},
  shortjournal = {Neural Comput. Appl.},
  title        = {Seeing both sides: Context-aware heterogeneous graph matching networks for extracting-related arguments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy control design for time-delay systems under adaptive
event-triggered mechanism. <em>NCA</em>, <em>36</em>(9), 4727–4739. (<a
href="https://doi.org/10.1007/s00521-023-09116-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript studies the fuzzy $${\mathcal {H}}_{\infty }$$ control design problem for nonlinear time-varying delay systems in fuzzy form via adaptive event-triggered mechanism. The fuzzy model and an adaptive event-triggered controller are connected in closed-loop form. A looped-functional is established to conduct stability analysis, and the main feature of this functional can fully reflect the sampling feature of control systems. Thus, the achieved results are less conservative. The Wringter inequality is also used to further relax stability analysis. Finally, sufficient conditions are achieved for the existence of event-triggered fuzzy controller, and the resulting closed-loop system reaches an $${\mathcal {H}}_{\infty }$$ control performance. Two examples verify the efficiency of the presented control strategy.},
  archive      = {J_NCA},
  author       = {Du, Zhenbin and Qu, Zifang and Kao, Yonggui and Wu, Zhaojing},
  doi          = {10.1007/s00521-023-09116-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4727-4739},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy control design for time-delay systems under adaptive event-triggered mechanism},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new semi-supervised fuzzy k-means clustering method with
dynamic adjustment and label discrimination. <em>NCA</em>,
<em>36</em>(9), 4709–4725. (<a
href="https://doi.org/10.1007/s00521-023-09115-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional unsupervised Fuzzy K-means methods (FKM) usually analyze the structure of data solely without considering the influence of label information carried by data, which limits the performance and stability of clustering. How to leverage annotated label information to improve the performance of unsupervised FKM methods is still a challenging research problem. To that end, this paper proposes a new Semi-Supervised Fuzzy K-means method (SSFKM) consisting of dynamic adjustment and label discrimination. Specifically, dynamic adjustment aligns label information and clustering results to distinguish the learning difficulties of labeled data and enable the method to focus on simple but reliable label information. Moreover, a new distance measure is designed to re-evaluate the membership of labeled data with cluster centers, forcing labeled data to be classified into correct cluster for enhancing label discrimination. Comprehensive experiments demonstrate that the SSFKM method achieves the best performance compared with existing state-of-the-art semi-supervised clustering methods. In addition, the results demonstrate that the SSFKM method reduces the impact of data noise effectively during clustering.},
  archive      = {J_NCA},
  author       = {Zhu, Hengdong and Xie, Wenxiu and Mu, Yuanyuan and Xu, Juan and Wang, Fu Lee and Qu, Yingying and Hao, Tianyong},
  doi          = {10.1007/s00521-023-09115-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4709-4725},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new semi-supervised fuzzy K-means clustering method with dynamic adjustment and label discrimination},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative artificial intelligence-enabled dynamic detection
of rat nicotine-related circuits. <em>NCA</em>, <em>36</em>(9),
4693–4707. (<a
href="https://doi.org/10.1007/s00521-023-09307-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nicotine addiction circuits involve integrating specific brain regions that alter to frequent smoking. Detection of these circuits via fMRI contributes to understanding addiction-related mechanisms. Identification of the functional circuits and networks altered by nicotine is essential to improve the treatment of nicotine addiction. However, analyzing fMRI data and detecting functional addiction circuits still have challenges. In this work, we developed a generative AI-enabled framework, rat addiction-related circuits detection platform (RADP), to detect nicotine-related circuits. It has an end-to-end pipeline: functional imaging data acquisition from neurobiological experiments, computational modeling for brain networks, and a novel generative model including spatiotemporal transformer auto-encoder (STA) and dynamic circuits analysis. The proposed spatiotemporal representation contrasting trains the encoder of STA to contrastively capture representations between the addictive and the control groups. Experimental results indicate that the framework can efficiently detect the verified addiction circuits and discover the unknown but significant circuits. Moreover, RADP can be served as a general tool which can be extended to other brain circuits.},
  archive      = {J_NCA},
  author       = {Gong, Changwei and Jing, Changhong and Liu, Xin-an and Wang, Victoria X. and Tang, Cheuk Ying and Kenny, Paul J. and Li, Ye and Chen, Zuxin and Wang, Shuqiang},
  doi          = {10.1007/s00521-023-09307-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4693-4707},
  shortjournal = {Neural Comput. Appl.},
  title        = {Generative artificial intelligence-enabled dynamic detection of rat nicotine-related circuits},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). CLINER: Exploring task-relevant features and label semantic
for few-shot named entity recognition. <em>NCA</em>, <em>36</em>(9),
4679–4691. (<a
href="https://doi.org/10.1007/s00521-023-09285-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot named entity recognition aims at recognizing novel-class named entities in low resources scenarios. Low resource scenarios contain limited data in the support set with sparse labels. Existing methods neglect the relevance of the support set to the task and the semantics of label naming. In this paper, on the basis of contrastive learning, we propose a multi-task learning framework CLINER for Few-Shot NER. We construct a mechanism for joint learning of label semantic information and support set information. For label support set information, we find a view in the support set that is most relevant to the current task, maximizing the utilization of each support set. Momentum encoder, a dynamic queue, is constructed to keep track of positive and negative examples learned from previous support sets, and keep it updated. For label semantic information, it is implied in the label naming and is derived explicitly by pre-trained language encoder. Experiments demonstrate that our model improves the overall performance comparing with recent baseline models, achieves state-of-the-art results on the commonly used standard datasets. The source code of CLINER will be available at: https://github.com/yizumi426/CLINER .},
  archive      = {J_NCA},
  author       = {Li, Xuewei and Li, Xinliang and Zhao, Mankun and Yang, Ming and Yu, Ruiguo and Yu, Mei and Yu, Jian},
  doi          = {10.1007/s00521-023-09285-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4679-4691},
  shortjournal = {Neural Comput. Appl.},
  title        = {CLINER: Exploring task-relevant features and label semantic for few-shot named entity recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Post-capture tracking control with fixed-time convergence
for a free-flying flexible-joint space robot based on adaptive neural
network. <em>NCA</em>, <em>36</em>(9), 4661–4677. (<a
href="https://doi.org/10.1007/s00521-023-09281-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to achieve rapid and precise trajectory tracking for a free-flying flexible-joint space robot (FFSR) when capturing a space target with unknown mass, we developed a nonsingular fixed-time adaptive neural control scheme via backstepping technique. Radial basis function neural networks are employed to deal with the system uncertainties caused by the captured target and external disturbances. Two fixed-time auxiliary systems are designed to attenuate the impact of excessive initial nominal control input and to ensure the control system stability in the presence of physical constraints on the actuators. Moreover, a novel dynamic surface control technique is adopted to handle the complexity explosion generated by multiple derivatives of the virtual control signals. Theoretical analysis demonstrates that the FFSR system is semiglobally fixedtimely uniformly ultimately bounded and the tracking error can converge to a very small bound within fixed time. Finally, the simulation results verify the effectiveness of the proposed controller.},
  archive      = {J_NCA},
  author       = {Liu, Liaoxue and Lu, Yuye and Gu, Xiutao and Wu, Yifei and Guo, Yu},
  doi          = {10.1007/s00521-023-09281-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4661-4677},
  shortjournal = {Neural Comput. Appl.},
  title        = {Post-capture tracking control with fixed-time convergence for a free-flying flexible-joint space robot based on adaptive neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributional offline continuous-time reinforcement
learning with neural physics-informed PDEs (SciPhy RL for DOCTR-l).
<em>NCA</em>, <em>36</em>(9), 4643–4659. (<a
href="https://doi.org/10.1007/s00521-023-09300-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses distributional offline continuous-time reinforcement learning (DOCTR-L) with stochastic policies for high-dimensional optimal control. A soft distributional version of the classical Hamilton–Jacobi–Bellman (HJB) equation is given by a semilinear partial differential equation (PDE). This ‘soft HJB equation’ can be learned from offline data without assuming that the latter correspond to a previous optimal or near-optimal policy. A data-driven solution of the soft HJB equation uses methods of Neural PDEs and Physics-Informed Neural Networks developed in the field of Scientific Machine Learning (SciML). The suggested approach, dubbed ‘SciPhy RL’, thus reduces DOCTR-L to solving neural PDEs from data. Our algorithm called Deep DOCTR-L converts offline high-dimensional data into an optimal policy in one step by reducing it to supervised learning, instead of relying on value iteration or policy iteration methods. The method enables a computable approach to the quality control of obtained policies in terms of both expected returns and uncertainties about their values.},
  archive      = {J_NCA},
  author       = {Halperin, Igor},
  doi          = {10.1007/s00521-023-09300-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4643-4659},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributional offline continuous-time reinforcement learning with neural physics-informed PDEs (SciPhy RL for DOCTR-l)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interval-valued prediction of time series based on fuzzy
cognitive maps and granular computing. <em>NCA</em>, <em>36</em>(9),
4623–4642. (<a
href="https://doi.org/10.1007/s00521-023-09290-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series have yielded impressive results in numerical prediction, yet the presence of noise can significantly affect accuracy. Although interval prediction can minimize noise interference, most methods only predict upper and lower limits separately, resulting in uninterpretable predictions. In this paper, we propose a novel modeling approach for time-series interval prediction that integrates granular computing and fuzzy cognitive maps (FCMs). Granular computing transforms traditional numerical time series into interval time series. Rather than predicting interval values independently, our method mines the fuzzy relationship between information granules to obtain the affiliation matrix. During the prediction stage, an FCM-based model is established to predict the affiliation matrix. We conducted experiments on six publicly available datasets, and results demonstrate that our method reduces the impact of noise while offering improved interpretability for prediction outcomes. More importantly, our approach yields significantly lower interval prediction errors when compared to other advanced methods.},
  archive      = {J_NCA},
  author       = {Yu, Tianming and Li, Qianxin and Wang, Ying and Feng, Guoliang},
  doi          = {10.1007/s00521-023-09290-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4623-4642},
  shortjournal = {Neural Comput. Appl.},
  title        = {Interval-valued prediction of time series based on fuzzy cognitive maps and granular computing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sugar beet farming goes high-tech: A method for automated
weed detection using machine learning and deep learning in precision
agriculture. <em>NCA</em>, <em>36</em>(9), 4603–4622. (<a
href="https://doi.org/10.1007/s00521-023-09320-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this study is to develop a method for the automated detection and classification of weeds and sugar beets. Precision agriculture is an essential area of research that aims to optimize farming practices and reduce the use of harmful chemicals. For this purpose, the Faster RCNN and Federating Learning (FL)-based ensemble models were utilized to classify a specific dataset. In the first stage of the study, feature extraction is performed from the images in the dataset and classified by machine learning algorithms. Then, classification is carried out with the help of FL based deep learning ensemble models. Within the scope of the study, grid search is used for hyperparameter optimization and the results are obtained by a tenfold cross-validation method. Among all tested algorithms, the FL-based ensemble model constructed using the ResNet50 model exhibited the highest accuracy rate of 99%. This system has the potential to significantly reduce the use of herbicides and other chemicals in agricultural practices, promoting a more sustainable form of agriculture.},
  archive      = {J_NCA},
  author       = {Ortatas, Fatma Nur and Ozkaya, Umut and Sahin, Muhammet Emin and Ulutas, Hasan},
  doi          = {10.1007/s00521-023-09320-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4603-4622},
  shortjournal = {Neural Comput. Appl.},
  title        = {Sugar beet farming goes high-tech: A method for automated weed detection using machine learning and deep learning in precision agriculture},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Handling uncertainty issue in software defect prediction
utilizing a hybrid of ANFIS and turbulent flow of water optimization
algorithm. <em>NCA</em>, <em>36</em>(9), 4583–4602. (<a
href="https://doi.org/10.1007/s00521-023-09315-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the development cycle of software projects, numerous defects and challenges have been identified, leading to prolonged project durations and escalated costs. As a result, both product delivery and defect tracking have become increasingly complex, expensive, and time-consuming. Recognizing the challenge of identifying every software defect, it is crucial to foresee potential consequences and strive for the production of high-quality products. The goal of software defect prediction (SDP) is to identify problematic locations within software code. This study presents the first experimental investigation utilizing the turbulent flow of water optimization (TFWO) in conjunction with the adaptive neuro-fuzzy inference system (ANFIS) to enhance SDP. The TFWO_ANFIS model is designed to address the uncertainties present in software features and predict defects with feasible accuracy. Data are divided randomly at the beginning of the model into training and testing sets to avoid the local optima and over-fitting issues. By applying the TFWO approach, it adjusts the ANFIS parameters during the SDP process. The proposed model, TFWO_ANFIS, outperforms other optimization algorithms commonly used in SDP, such as particle swarm optimization (PSO), gray wolf optimization (GWO), differential evolution (DE), ant colony optimization (ACO), standard ANFIS, and genetic algorithm (GA). This superiority is demonstrated through various evaluation metrics for four datasets, including standard deviation (SD) scores (0.3307, 0.2885, 0.3205, and 0.2929), mean square error (MSE) scores (0.1091, 0.0770, 0.1026, and 0.0850), root-mean-square error (RMSE) scores (0.3303, 0.2776, 0.3203, and 0.2926), mean bias error (MBE) scores (0.1281, 0.0860, 0.0931, and 0.2310), and accuracy scores (87.3%, 90.2%, 85.8%, and 89.2%), respectively, for the datasets KC2, PC3, KC1, and PC4. These datasets with different instances and features are obtained from an open platform called OPENML. Additionally, multiple evaluation metrics such as precision, sensitivity, confusion matrices, and specificity are employed to assess the model’s performance.},
  archive      = {J_NCA},
  author       = {Elsabagh, M. A. and Emam, O. E. and Gafar, M. G. and Medhat, T.},
  doi          = {10.1007/s00521-023-09315-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4583-4602},
  shortjournal = {Neural Comput. Appl.},
  title        = {Handling uncertainty issue in software defect prediction utilizing a hybrid of ANFIS and turbulent flow of water optimization algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial deep feature augmentation technique for FER using
genetic algorithm. <em>NCA</em>, <em>36</em>(9), 4563–4581. (<a
href="https://doi.org/10.1007/s00521-023-09245-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of a large human-labelled facial expression dataset is challenging due to ambiguity in labelling the facial expression class, and annotation cost. However, facial expression recognition (FER) systems demand discriminative feature representation, and require many training samples to establish stronger decision boundaries. Recently, FER approaches have used data augmentation techniques to increase the number of training samples for model generation. However, these augmented samples are derived from existing training data, and therefore have limitations for developing an accurate FER system. To achieve meaningful facial expression representations, we introduce an augmentation technique based on deep learning and genetic algorithms for FER. The proposed approach exploits the hypothesis that augmenting the feature-set is better than augmenting the visual data for FER. By evaluating this relationship, we discovered that the genetic evolution of discriminative features for facial expression is significant in developing a robust FER approach. In this approach, facial expression samples are generated from RGB visual data from videos considering human face frames as regions of interest. The face detected frames are further processed to extract key-frames within particular intervals. Later, these key-frames are convolved through a deep convolutional network for feature generation. A genetic algorithm’s fitness function is gauged to select optimal genetically evolved deep facial expression receptive fields to represent virtual facial expressions. The extended facial expression information is evaluated through an extreme learning machine classifier. The proposed technique has been evaluated on five diverse datasets i.e. JAFFE, CK+, FER2013, AffectNet and our application-specific Instructor Facial Expression (IFEV) dataset. Experimentation results and analysis show the promising accuracy and significance of the proposed technique on all these datasets.},
  archive      = {J_NCA},
  author       = {Nida, Nudrat and Yousaf, Muhammad Haroon and Irtaza, Aun and Javed, Sajid and Velastin, Sergio A.},
  doi          = {10.1007/s00521-023-09245-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4563-4581},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spatial deep feature augmentation technique for FER using genetic algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Age transformation based on deep learning: A survey.
<em>NCA</em>, <em>36</em>(9), 4537–4561. (<a
href="https://doi.org/10.1007/s00521-023-09376-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age transformation aims to preserve personalized facial information while altering a given face to appear at a target age. This technique finds extensive applications in fields such as face recognition, movie special effects, and social entertainment, among others. With the advancement of deep learning, particularly Generative Adversarial Networks (GANs), research on age transformation has made significant progress, leading to the emergence of a diverse range of deep learning-based methods. However, a comprehensive and systematic literature review of these methods is currently lacking. In this survey, we provide an all-encompassing review of deep learning methods for facial aging. Firstly, we summarize the key aspects of feature preservation during the age transformation process. Subsequently, we present a comprehensive overview of facial age transformation techniques, categorized according to various deep learning network architectures. Additionally, we conduct an analysis and comparison of commonly used face image datasets, offering recommendations for dataset selection. Furthermore, we consolidate the qualitative and quantitative evaluation metrics commonly employed in age transformation methodologies through experimental assessment. Finally, we address potential areas of future research in age transformation methods, based on the current challenges and limitations.},
  archive      = {J_NCA},
  author       = {Guo, Yingchun and Su, Xin and Yan, Gang and Zhu, Ye and Lv, Xueqi},
  doi          = {10.1007/s00521-023-09376-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4537-4561},
  shortjournal = {Neural Comput. Appl.},
  title        = {Age transformation based on deep learning: A survey},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving productivity in mining operations: A deep
reinforcement learning model for effective material supply and equipment
management. <em>NCA</em>, <em>36</em>(9), 4523–4535. (<a
href="https://doi.org/10.1007/s00521-023-09396-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research study examines the impact of shifts and lunch breaks on mining operations, particularly focusing on delays in hauling equipment used to supply extracted material to crushers. These delays significantly reduce productivity, averaging below 80% during regular working hours and adversely affecting mine profitability. To address this issue, a Q-learning-based deep reinforcement learning model was developed, utilizing real-world data from mining operations. The model aimed to achieve a 90% coverage in material supply to the crushers. A simulation environment, closely resembling the physical mining setting, was created to test the trucks as agents. Various scenarios, including equipment selection, cycle time, queue times, and material types, were considered. Based on the results, a deep learning model was trained to maximize coverage by determining the optimal combination of trucks and crushers. The solution successfully achieved a 90% supply coverage during shift changes and lunch breaks, with average execution times of less than 1 ms, making it suitable for real-time applications. This research demonstrates the effectiveness of the proposed Q-learning deep reinforcement learning model in optimizing material supply and enhancing mining productivity. By addressing delays and improving operational efficiency, this model holds significant potential for improving profitability in mining operations.},
  archive      = {J_NCA},
  author       = {Chiarot Villegas, Teddy V. and Segura Altamirano, S. Francisco and Castro Cárdenas, Diana M. and Sifuentes Montes, Ayax M. and Chaman Cabrera, Lucia I. and Aliaga Zegarra, Antenor S. and Oblitas Vera, Carlos L. and Alban Palacios, José C.},
  doi          = {10.1007/s00521-023-09396-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4523-4535},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving productivity in mining operations: A deep reinforcement learning model for effective material supply and equipment management},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved genetic algorithm approach for coordinating
decision-making in technological disaster management. <em>NCA</em>,
<em>36</em>(9), 4503–4521. (<a
href="https://doi.org/10.1007/s00521-023-09218-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing frequency of technological events has resulted in significant damage to the environment, human health, social stability, and economy, driving ongoing scientific development and interest in emergency management (EM). Traditional EM approaches are often inadequate because of incomplete and imprecise information during crises, making fast and effective decision-making challenging. Computational Intelligence techniques (CI) offer decision-supporting capabilities that can effectively address these challenges. However, there is still a need for deeper integration of emerging computational intelligence techniques to support evidence-based decision-making while also addressing gaps in metrics, standards, and protocols for emergency response and scalability. This study presents a coordinated decision-making system for multiple types of emergency case scenarios for technological disaster management based on CI techniques, including an Improved Genetic Algorithm (IGA), and Multi-objective Particle Swarm Optimization (MOPSO). The IGA enhances emergency performance by optimizing the task assignment for multiple agents involved in emergency response with coordination mechanisms, resulting in an approximately 15% improvement compared to other state-of-the-art methods. Ultimately, this study offers a promising foundation for future research to develop effective strategies for mitigating the impact of technological disasters on society and the environment.},
  archive      = {J_NCA},
  author       = {Guerrero Granados, Bethsy and Quintero M., Christian G. and Núñez, César Viloria},
  doi          = {10.1007/s00521-023-09218-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4503-4521},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved genetic algorithm approach for coordinating decision-making in technological disaster management},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Foodnet: Multi-scale and label dependency learning-based
multi-task network for food and ingredient recognition. <em>NCA</em>,
<em>36</em>(9), 4485–4501. (<a
href="https://doi.org/10.1007/s00521-023-09349-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-based food pattern classification poses challenges of non-fixed spatial distribution and ingredient occlusion for mainstream computer vision algorithms. However, most current approaches classify food and ingredients by directly extracting abstract features of the entire image through a convolutional neural network (CNN), ignoring the relationship between food and ingredients and ingredient occlusion problem. To address these issues mentioned, we propose a FoodNet for both food and ingredient recognition, which uses a multi-task structure with a multi-scale relationship learning module (MSRL) and a label dependency learning module (LDL). As ingredients normally co-occur in an image, we present the LDL to use the dependency of ingredient to alleviate the occlusion problem of ingredient. MSRL aggregates multi-scale information of food and ingredients, then uses two relational matrixs to model the food-ingredient matching relationship to obtain richer feature representation. The experimental results show that FoodNet can achieve good performance on the Vireo Food-172 and UEC Food-100 datasets. It is worth noting that it reaches the most state-of-the-art level in terms of ingredient recognition in the Vireo Food-172 and UECFood-100.The source code will be made available at https://github.com/visipaper/FoodNet .},
  archive      = {J_NCA},
  author       = {Shuang, Feng and Lu, Zhouxian and Li, Yong and Han, Chao and Gu, Xia and Wei, Shidi},
  doi          = {10.1007/s00521-023-09349-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4485-4501},
  shortjournal = {Neural Comput. Appl.},
  title        = {Foodnet: Multi-scale and label dependency learning-based multi-task network for food and ingredient recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-adjusting transformer network for detecting
transmission line defects. <em>NCA</em>, <em>36</em>(9), 4467–4484. (<a
href="https://doi.org/10.1007/s00521-023-09319-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of traditional defect detection methods for power transmission lines, this paper proposes an intelligent defect recognition method based on self-adjusting Transformer. Firstly, a deterministic networking with a large receptive field is used to extract features from the defect images obtained during power transmission line inspections. Subsequently, a DQN is employed to select important regions containing foreground information. Secondly, a bilinear attention mechanism is utilized to project the background region feature vectors, compressing their contribution in the fused feature vectors of the foreground and background regions. Furthermore, the fused feature vectors are input into a Transformer network based on adaptive encoding layers, enabling better focus on the target region. Position-scale constraints are added to the decoding layers of the Transformer to enhance the attention’s emphasis on position-scale information, thereby accelerating the convergence speed of the Transformer. Finally, gate units are introduced in each decoding layer to adaptively adjust the structure of the Transformer decoding layers to accommodate the feature extraction requirements of different inputs. Experimental studies on aerial images of power transmission line defects were conducted, and the proposed method achieved an average detection accuracy of 89.9 $$\%$$ . Compared with other commonly used algorithms, it demonstrated superior detection accuracy and generalization ability.},
  archive      = {J_NCA},
  author       = {Li, Weitao and Tong, Qianqian and Gu, Jiaqin and Li, Junchen and Sun, Wei and Li, Qiyue},
  doi          = {10.1007/s00521-023-09319-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {4467-4484},
  shortjournal = {Neural Comput. Appl.},
  title        = {A self-adjusting transformer network for detecting transmission line defects},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-domain few-shot learning based on feature adaptive
distillation. <em>NCA</em>, <em>36</em>(8), 4451–4465. (<a
href="https://doi.org/10.1007/s00521-023-09318-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, few-shot learning (FSL) has exhibited remarkable performance in computer vision tasks. However, the existing FSL approaches perform poorly when facing data shortages and domain variations between the source and target datasets. This is because the target domain is hidden during training and the strong discriminating ability on the source domain dataset cannot be properly transferred into the good classification precision on the target dataset. To address the optimization problem for cross-domain few-shot image identification, this study proposed the Feature Adaptive Distillation (FAD) method. Specifically, we capture broader variations in feature distributions through a novel Feature Adaptive Distillation method. The two primary components of FAD are the Self-Distillation module (SD) and the Feature Adaptive module (FA). By including additional adaptive parameters for particular tasks in the feature extractor, FA enhances the generalization performance of this method. To enhance it’s ability to recognize features and determine the most effective feature extractor, the feature extractor is further self-distilled using SD. The results indicate that this method can greatly enhance the effectiveness of such kind image recognition.},
  archive      = {J_NCA},
  author       = {Zhang, Dingwei and Yan, Hui and Chen, Yadang and Li, Dichao and Hao, Chuanyan},
  doi          = {10.1007/s00521-023-09318-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4451-4465},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-domain few-shot learning based on feature adaptive distillation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convolutional encoder–decoder network using transfer
learning for topology optimization. <em>NCA</em>, <em>36</em>(8),
4435–4450. (<a
href="https://doi.org/10.1007/s00521-023-09308-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art deep neural networks have achieved great success as an alternative to topology optimization by eliminating the iterative framework of the optimization process. However, models with strong predicting capabilities require massive data, which can be time-consuming, particularly for high-resolution structures. Transfer learning from pre-trained networks has shown promise in enhancing network performance on new tasks with a smaller amount of data. In this study, a U-net-based deep convolutional encoder–decoder network was developed for predicting high-resolution (256 × 256) optimized structures using transfer learning and fine-tuning for topology optimization. Initially, the VGG16 network pre-trained on ImageNet was employed as the encoder for transfer learning. Subsequently, the decoder was constructed from scratch and the network was trained in two steps. Finally, the results of models employing transfer learning and those trained entirely from scratch were compared across various core parameters, including different initial input iterations, fine-tuning epoch numbers, and dataset sizes. Our findings demonstrate that the utilization of transfer learning from the ImageNet pre-trained VGG16 network as the encoder can improve the final predicting performance and alleviate structural discontinuity issues in some cases while reducing training time.},
  archive      = {J_NCA},
  author       = {Ates, Gorkem Can and Gorguluarslan, Recep M.},
  doi          = {10.1007/s00521-023-09308-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4435-4450},
  shortjournal = {Neural Comput. Appl.},
  title        = {Convolutional encoder–decoder network using transfer learning for topology optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network optimal control for discrete-time nonlinear
systems with known internal dynamics. <em>NCA</em>, <em>36</em>(8),
4421–4434. (<a
href="https://doi.org/10.1007/s00521-023-09244-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A neural network (NN) optimal control for discrete-time nonlinear dynamic systems with known internal dynamics is designed. The control is described by an algebraic equation with a variable structure. This algebraic equation is derived analytically. A functional block diagram of the controlled system is given and analyzed. Software and hardware implementation aspects of the controller are discussed. The controller does not need any training and has moderate complexity. The discrete-time state variable trajectories of the controlled system are shown to be globally asymptotically stable and convergent to unique steady states. It is proved that these trajectories converge to steady-state neighborhood in a finite number of steps. Sliding mode analysis of controller operation is fulfilled. A correctness of controller operation in the case of disturbances of its nonlinearities is analyzed. Using the controller for a special case of optimal tracking control is discussed. Results of presented computer simulations of optimal control of discrete-time two-dimensional and three-dimensional affine nonlinear systems and optimal tracking control of permanent-magnet motor of linear type applied for accurate positioning and nonlinear cooling continuous stirred tank reactor confirm theoretical statements of the paper and illustrate a performance of the controller.},
  archive      = {J_NCA},
  author       = {Tymoshchuk, Pavlo},
  doi          = {10.1007/s00521-023-09244-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4421-4434},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural network optimal control for discrete-time nonlinear systems with known internal dynamics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion2language, unsupervised learning of synchronized
semantic motion segmentation. <em>NCA</em>, <em>36</em>(8), 4401–4420.
(<a href="https://doi.org/10.1007/s00521-023-09227-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate building a sequence to sequence architecture for motion-to-language translation and synchronization. The aim is to translate motion capture inputs into English natural-language descriptions, such that the descriptions are generated synchronously with the actions performed, enabling semantic segmentation as a byproduct, but without requiring synchronized training data. We propose a new recurrent formulation of local attention that is suited for synchronous/live text generation, as well as an improved motion encoder architecture better suited to smaller data and for synchronous generation. We evaluate both contributions in individual experiments, using the standard BLEU4 metric, as well as a simple semantic equivalence measure, on the KIT motion-language dataset. In a follow-up experiment, we assess the quality of the synchronization of generated text in our proposed approaches through multiple evaluation metrics. We find that both contributions to the attention mechanism and the encoder architecture additively improve the quality of generated text (BLEU and semantic equivalence), but also of synchronization.},
  archive      = {J_NCA},
  author       = {Radouane, Karim and Tchechmedjiev, Andon and Lagarde, Julien and Ranwez, Sylvie},
  doi          = {10.1007/s00521-023-09227-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4401-4420},
  shortjournal = {Neural Comput. Appl.},
  title        = {Motion2language, unsupervised learning of synchronized semantic motion segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining artificial neural networks and hematological data
to diagnose covid-19 infection in brazilian population. <em>NCA</em>,
<em>36</em>(8), 4387–4399. (<a
href="https://doi.org/10.1007/s00521-023-09312-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate diagnosis of COVID-19 is important to prevent dissemination and disease progression. Artificial Intelligence is known as a universal fitting tool and can be used on the formulation of predictive models for the disease’s diagnosis. Thus, we aimed to obtain a neural network (ANN) to diagnose patients as positive or negative COVID-19 based on patient data and blood tests. Data from 1003 patients followed between June/2020 and October/2020 were used. Covid-19 was confirmed in 777 patients by RT-PCR. The inputs considered were: sex, age, ethinicity, body mass index, tabagism, ex-tabagism, alveolar infiltrate, arterial hypertension, diabetes, heart rate, respiration rate, body temperature, oxygen saturation, D-dimer, activated partial thromboplastin time, prothrombin time, levels of: hemoglobin, platelet, leukocytes, lymphocytes, monocytes, neutrophils, lactate dehydrogenase, C-reactive protein, and creatinine. Blood was collected at the patient’s admission. The ANNs had 25 inputs and the output was the Covid-19 diagnosis. ANNs with one and two hidden layers were proposed. The number of neurons ranged from 5 to 35. The best result was obtained with an ANN containing 15 neurons in the first and second hidden layers, respectively. The model presented accuracy of 83%, and high capacity for the prediction of true positives (precision of 0.90). The results showed that the ANNs are promising to diagnose Covid-19 based on clinical parameters and blood tests. After future refinements and proper validation, this model could be used to diagnose Covid-19 on daily basis.},
  archive      = {J_NCA},
  author       = {Martins, Tiago D. and Martins, Sandra D. and Montalvão, Silmara and Al Bannoud, Mohamad and Ottaiano, Gabriel Y. and Silva, Letícia Q. and Huber, Stephany C. and Diaz, Tassiana S. P. and Wroclawski, Carolina and Filho, Cyrillo Cavalheiro and Maciel-Filho, Rubens and Annichino-Bizzacchi, Joyce M.},
  doi          = {10.1007/s00521-023-09312-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4387-4399},
  shortjournal = {Neural Comput. Appl.},
  title        = {Combining artificial neural networks and hematological data to diagnose covid-19 infection in brazilian population},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using recurrent neural networks to identify
broken-cold-chain fish fillet from spectral profiles. <em>NCA</em>,
<em>36</em>(8), 4377–4386. (<a
href="https://doi.org/10.1007/s00521-023-09311-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last two decades, hyperspectral images have been studied for use in food quality analysis using neural network-based chemometric techniques such as radial basic neural network (RBNN) in classification tasks or multilayer perceptron (MLP) for prediction ones. However, recently, deep learning techniques are receiving special interest as those based on recurrent neural networks (RNN) or gated recurrent units for their feature extraction capacity. A kind of RNN are networks based on long short-term memory (LSTM), which are promising for improving the capabilities of hyperspectral images in food analysis. In this sense, a comparative study on using LSTM-based networks is done, comparing it to RBNN in the discrimination of fish fillets subjected to freeze-thaw cycles. The samples for the study were fresh mackerel fillets subjected to two successive cycles of freezing and thawing. Hyperspectral images of fillets were acquired, both fresh and in each freeze-thaw cycle, and spectral profiles were acquired in the range of 400–1000 nm. Complete spectral profiles were used to generate classification models; these were subsequently optimized using the relevant wavelengths determined by feature selection neighborhood component analysis. The models were trained using a k-cross-fold validation strategy (k = 5), repeating the process thirty times. The models were evaluated, confusion matrices were determined, and their classification metrics were compared. The training process results showed that the LSTM networks had superior potential to the RBNN networks, achieving an average F-measure greater than 0.89 and an accuracy greater than 0.93. This study shows that deep learning techniques can be used to tell the difference between fish fillets that have been frozen and thawed several times. These techniques could also be used to establish systems to control the transport and conservation processes of this type of food.},
  archive      = {J_NCA},
  author       = {Castro, Wilson and Saavedra, Monica and Castro, Jorge and Tech, Adriano Rogério Bruno and Chuquizuta, Tony and Avila-George, Himer},
  doi          = {10.1007/s00521-023-09311-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4377-4386},
  shortjournal = {Neural Comput. Appl.},
  title        = {Using recurrent neural networks to identify broken-cold-chain fish fillet from spectral profiles},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spot-out fruit fly algorithm with simulated annealing
optimized SVM for detecting tomato plant diseases. <em>NCA</em>,
<em>36</em>(8), 4349–4375. (<a
href="https://doi.org/10.1007/s00521-023-09295-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crop diseases are a huge threat to food security, yet timely detection is a difficult task due to the absence of infrastructure in various regions of the world. In agriculture, the detection of disease in plants is complex because farmers must often evaluate whether the crop that are harvesting appears good enough. It is crucial to treat this seriously because it may result to major effects on plants, affecting product characteristics, quantity, or overall productivity. Plant illnesses produce outbreaks of disease on a systematic interval, resulting in large-scale fatalities and a substantial economic impact. Early and precise tools for diagnosing plant diseases are essential for robust plant production and for reducing both qualitative and quantitative losses in crop yield. Cutting-edge and creative data analysis technologies significantly aid in the accurate and precise identification of diseases. Among all the crops, tomato plants are widely grown and required in all parts of the world. Given all the above challenges, this study seeks to recognize tomato plant diseases in an accurate and timely manner. In this paper, a multi-objective hybrid fruit fly optimization algorithm that relies on simulated annealing optimized SVM is proposed to identify tomato plant diseases at an earlier stage in an accurate manner avoiding global optimization problems. The hybridization of simulated annealing with FOA helps in reducing the hyperparameter problems. The proposed methodology was tested and experimented extensively and the results enlightened that the proposed methodology achieved 91.1% accuracy and reliability and the experimental observations also indicated that the suggested method overcomes the drawbacks of the current algorithms. In addition, the operational efficiency of the proposed system was measured on statistical parameters like accuracy (91.1%), sensitivity (96.7%), precision (91.8%), specificity (91.2%), and F1-score (94.5%). Also, a comparison analysis with existing algorithms like DT, RF, KNN, and K-means with SVM was also performed, and overall, it was concluded that proposed methodology is having high methodological approach for diagnosing crop diseases.},
  archive      = {J_NCA},
  author       = {Gangadevi, E. and Rani, R. Shoba and Dhanaraj, Rajesh Kumar and Nayyar, Anand},
  doi          = {10.1007/s00521-023-09295-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4349-4375},
  shortjournal = {Neural Comput. Appl.},
  title        = {Spot-out fruit fly algorithm with simulated annealing optimized SVM for detecting tomato plant diseases},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Medical image fusion based on transfer learning techniques
and coupled neural p systems. <em>NCA</em>, <em>36</em>(8), 4325–4347.
(<a href="https://doi.org/10.1007/s00521-023-09294-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image fusion is an essential task for clinical diagnosis because it allows physicians to make more accurate diagnoses. Up to now, many medical image synthesis algorithms have been proposed, but the obtained images are often of low quality and do not preserve details from the input images. This paper proposes a new algorithm that allows the creation of composite images with advantages in two aspects: good quality and information preservation. Initially, a method for image decomposition is introduced, which separates the image into five distinct components: two highly detailed components (HDCs), two low-detailed components (LDCs), and a base component (BC). This methodology is founded on the utilization of the Gaussian filter (GF) and the rolling guidance filter (RGF). Then, a modified VGG19 (called MVGG-19) network is built by a transfer learning technique for the VGG-19 network to classify four classifications (MRI, CT, PET, and SPECT). The MVGG-19 is utilized to build fusion rules for HDCs and LDCs. Ultimately, a coupled neural P system (CNPS) is utilized to create fusion rules for BCs. In order to evaluate the effectiveness of the proposed algorithm, seven advanced algorithms and eight metrics were employed. The experiments have shown that the composite image generated by the proposed algorithm exhibits a marked improvement in quality and successfully maintains a substantial amount of information from the input image.},
  archive      = {J_NCA},
  author       = {Dinh, Phu-Hung and Giang, Nguyen Long},
  doi          = {10.1007/s00521-023-09294-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4325-4347},
  shortjournal = {Neural Comput. Appl.},
  title        = {Medical image fusion based on transfer learning techniques and coupled neural p systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of skin disease using a novel hybrid flash
butterfly optimization from dermoscopic images. <em>NCA</em>,
<em>36</em>(8), 4311–4324. (<a
href="https://doi.org/10.1007/s00521-023-09011-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The failure of skin disease detection at an early stage leads to causes of well-known cancer known as melanoma, and it is created due to an assortment of dermatological conditions. Based on morphological attributes, design, surface, and shading, they are isolated into different classifications. To minimize the mortality rate, the early and timely prediction and diagnosis model is essential in medical field; so, to perform automatic detection, a novel hybrid flash butterfly optimized convolutional neural network with bidirectional long short-term memory (HFB-CNN-BiLSTM) approach is to accurately predict and classify the category of skin disease captured from dermoscopic images. The images are gathered from Ham10000 datasets that are highly imbalanced, and during training, it degrades classification performance. Therefore, the images are balanced by using preprocessing pipeline like augmentation by increasing the number of training samples to improve the efficiency of classification performance. Then feature extraction and classification processes are performed using HFB-CNN-BiLSTM to extract the relevant image features and classify them accurately based on their lesion characteristics as normal and abnormal (melanoma, benign keratosis, and melanocytic nevus). Moreover, the proposed framework’s viability is examined using MATLAB2018b software, and the performance is validated by comparison with existing approaches for various metrics. As a result, the proposed HFB-CNN-BiLSTM approach is highly superior in terms of all performance metrics compared to other existing approaches. The classification accuracy achieved by the proposed HFB-CNN-BiLSTM model in detecting three kinds of skin diseases is about 96.3%.},
  archive      = {J_NCA},
  author       = {Vidhyalakshmi, A. M. and Kanchana, M.},
  doi          = {10.1007/s00521-023-09011-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4311-4324},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of skin disease using a novel hybrid flash butterfly optimization from dermoscopic images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SleepSmart: An IoT-enabled continual learning algorithm for
intelligent sleep enhancement. <em>NCA</em>, <em>36</em>(8), 4293–4309.
(<a href="https://doi.org/10.1007/s00521-023-09310-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep is an essential physiological process that is crucial for human health and well-being. However, with the rise of technology and increasing work demands, people are experiencing more and more disrupted sleep patterns. Poor sleep quality and quantity can lead to a wide range of negative health outcomes, including obesity, diabetes, and cardiovascular disease. This research paper proposes a smart sleeping enhancement system, named SleepSmart, based on the Internet of Things (IoT) and continual learning using bio-signals. The proposed system utilizes wearable biosensors to collect physiological data during sleep, which is then processed and analyzed by an IoT platform to provide personalized recommendations for sleep optimization. Continual learning techniques are employed to improve the accuracy of the system&#39;s recommendations over time. A pilot study with human subjects was conducted to evaluate the system&#39;s performance, and the results show that SleepSmart can significantly improve sleep quality and reduce sleep disturbance. The proposed system has the potential to provide a practical solution for sleep-related issues and enhance overall health and well-being. With the increasing prevalence of sleep problems, SleepSmart can be an effective tool for individuals to monitor and improve their sleep quality.},
  archive      = {J_NCA},
  author       = {Gamel, Samah A. and Talaat, Fatma M.},
  doi          = {10.1007/s00521-023-09310-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4293-4309},
  shortjournal = {Neural Comput. Appl.},
  title        = {SleepSmart: An IoT-enabled continual learning algorithm for intelligent sleep enhancement},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Film-GAN: Towards realistic analog film photo generation.
<em>NCA</em>, <em>36</em>(8), 4281–4291. (<a
href="https://doi.org/10.1007/s00521-023-09283-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the art of film photography has reemerged as a topic of interest for both researchers and the community. Unlike digital photography, which relies on pixels to capture and store information, film photography employs silver halide to capture the scene. This process imbues film photos with a unique colour and textured graininess not present in digital photography. In this paper, we propose Film-GAN, the first Generative Adversarial Network (GAN)-based method for translating digital images to film. Film-GAN generates a corresponding film transformation of the input image based on the desired reference film style. To improve the realism of the generated images, we introduce the colour-noise-encoding (CNE) network, which extracts the colour and graininess of the reference image separately. Our experimental simulations demonstrate that Film-GAN outperforms other state-of-the-art approaches on multiple datasets. Based on evaluations from both professional photographers and amateur photography enthusiasts, the images generated by Film-GAN also received a higher number of votes, indicating its ability to produce better film-effect images.},
  archive      = {J_NCA},
  author       = {Gong, Haoyan and Su, Jionglong and Seng, Kah Phooi and Nguyen, Anh and Liu, Ao and Liu, Hongbin},
  doi          = {10.1007/s00521-023-09283-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4281-4291},
  shortjournal = {Neural Comput. Appl.},
  title        = {Film-GAN: Towards realistic analog film photo generation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid style transfer with whale optimization algorithm
model for textual adversarial attack. <em>NCA</em>, <em>36</em>(8),
4263–4280. (<a
href="https://doi.org/10.1007/s00521-023-09278-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been widely used in various research fields. However, researchers have discovered that deep learning models are vulnerable to adversarial attacks. Existing word-level attacks can be seen as a combinatorial optimization problem to effectively conduct textual adversarial attacks, but inappropriate search spaces and search methods may affect attack effectiveness. Sentence-level attacks are successfully used in the field of reading comprehension, but the generated examples sometimes lead to semantic deviation. To address these issues, we propose a hybrid textual adversarial attack method that effectively enhances the performance of textual adversarial attacks. To the best of our knowledge, we are the first to conduct textual adversarial attacks by hybridizing Whale Optimization Algorithm (WOA) with style transfer from multiple sentence and word levels. The WOA is improved by incorporating data characteristics and the Metropolis criterion to escape from local optima and by leveraging the mutation operator to increase population diversity. The improved WOA and style transfer algorithm are fused in a parallel and vertical way. Style transfer can increase population diversity and expand the search space, usually without destroying the semantics and syntax of sentences. The parallel combination improves attack performance by attacking from both word-level and sentence-level perspectives. As a black-box attack model, our method can attack without knowing the internal structure of the model. Compared with the state-of-the-art method, our framework can improve the attack success rate by 6.8%. Additionally, further experiments on grammatical error increase rates, semantic consistency, and transferability demonstrate that our model has excellent performance in many respects.},
  archive      = {J_NCA},
  author       = {Kang, Yan and Zhao, Jianjun and Yang, Xuekun and Fan, Baochen and Xie, Wentao},
  doi          = {10.1007/s00521-023-09278-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4263-4280},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid style transfer with whale optimization algorithm model for textual adversarial attack},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective quasi-reflection learning and weight
strategy-based moth flame optimization algorithm. <em>NCA</em>,
<em>36</em>(8), 4229–4261. (<a
href="https://doi.org/10.1007/s00521-023-09234-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the simultaneous optimization of many conflicting objectives, the capability of optimization algorithms must be increased. In this research, a non-dominated sorting (NDS) and crowding distance (CD)-based multi-objective variant of an advanced moth flame optimization (MFO) has been offered. Firstly, a mathematical quasi-reflection-based learning (QRL) strategy and weight strategy (WS) have been added to the classical MFO to alleviate the drawbacks of MFO. Next, this advanced MFO has been extended into multi-objective variant, namely MOQRMFO, with the help of NDS and CD approaches for well-distributed Pareto optimal front. The efficiency of the suggested MOQRMFO algorithm is tested in three phases. In the first phase, five ZDT multi-objective optimization problems (MOOPs) were considered under four performance metrics, namely general distance (GD), inverted general distance (IGD), spacing (S) and spread metric ( $${\Delta }$$ ) and then compared it with competitive multi-objective optimization algorithms. Secondly, six problems from the DTLZ test suite are considered under the above performance metrics to examine the effectiveness of the suggested MOQRMFO algorithm. The MOQRMFO algorithm’s capacity to solve real-world problems has been evaluated by considering four multi-objective real-world engineering design issues in the third phase using several performance metrics. The experimental outcomes show that the MOQRMFO is a better candidate algorithm achieving more than 95% superior results for multi-objective benchmarks and real-life problems in contrast to several other algorithms.},
  archive      = {J_NCA},
  author       = {Sahoo, Saroj Kumar and Premkumar, M. and Saha, Apu Kumar and Houssein, Essam H. and Wanjari, Saurabh and Emam, Marwa M.},
  doi          = {10.1007/s00521-023-09234-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4229-4261},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective quasi-reflection learning and weight strategy-based moth flame optimization algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of punching shear strength in flat slabs:
Ensemble learning models and practical implementation. <em>NCA</em>,
<em>36</em>(8), 4207–4228. (<a
href="https://doi.org/10.1007/s00521-023-09296-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes new models to predict the punching shear strength of flat slabs without transverse reinforcement by harnessing the power of machine learning through ensemble learning models. Leveraging two distinct databases—one with 522 samples with six input variables and another comprising 745 samples with four essential input variables. Six ensemble learning models, including Random Forest, AdaBoost, Light GBM, GBRT, CatBoost, and XGBoost, are evaluated. Through a combination of Bayesian optimisation and tenfold cross-validation technique, the CatBoost model emerges as the standout performer, achieving a coefficient of determination (R2) of 0.97 for both training and testing datasets. Notably, these models exhibit their superior prediction accuracy as compared to existing design codes and empirical equations. To further validate robustness of the models and evaluate the randomness of the databases, Monte Carlo simulations are employed. Additionally, the adaptability of XGBoost, CatBoost, and GBRT was tested using 200 random data points that extended beyond the original database&#39;s range, showcasing their capacity to provide reliable predictions in extended scenarios. Finally, a user-friendly interface application is developed for estimating the punching shear strength of RC flat slabs.},
  archive      = {J_NCA},
  author       = {Nguyen, Khuong Le and Trinh, Hoa Thi and Pham, Thong M.},
  doi          = {10.1007/s00521-023-09296-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4207-4228},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of punching shear strength in flat slabs: Ensemble learning models and practical implementation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neighborhood-enhanced contrast for pre-training graph neural
networks. <em>NCA</em>, <em>36</em>(8), 4195–4205. (<a
href="https://doi.org/10.1007/s00521-023-09274-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training graph neural networks (GNNs) have been proposed to promote graph-related downstream tasks, such as link prediction and node classification. Most existing works employ contrastive learning to explore graph characteristics by enforcing positive sample pairs to be close and negative sample pairs to be distant after performing data augmentation on the input graph. However, these methods apply random operations on input data in data augmentation and sample pairs construction, which leads to neglecting central nodes and the neighbor relationship between nodes. To address the corresponding problem, we propose a novel framework for pre-training GNNs, named Neighborhood-Enhanced Contrast for Pre-Training Graph Neural Networks (NECPT). Specifically, we propose data augmentation strategy based on node centrality to preserve central nodes and corresponding edges, which is used to generate two semantically similar views from input graph. Notably, our NECPT constructs sample pairs by integrating the potential node neighbors in graph structure and semantic space to explore general graph regularities. After generating node representations with GNN encoders and multilayer perceptrons, contrastive sample pairs are selected from different node neighbors, which combines diverse neighborhood relations into contrastive learning. Finally, node representations obtained from the model are used to predict the attributes of nodes and edges, which extracts deep semantic connections between attribute and structure information. Extensive experiments on benchmark datasets in biology and chemistry demonstrate the effectiveness of our proposed approach.},
  archive      = {J_NCA},
  author       = {Li, Yichun and Huang, Jin and Yu, Weihao and Zhang, Tinghua},
  doi          = {10.1007/s00521-023-09274-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4195-4205},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neighborhood-enhanced contrast for pre-training graph neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gorilla troops optimization-based load frequency control in
PV-thermal power system. <em>NCA</em>, <em>36</em>(8), 4179–4193. (<a
href="https://doi.org/10.1007/s00521-023-09273-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mismatch between generated power and load demand often leads to undesirable fluctuations in the frequency and tie-line power change of a power system. To mitigate this problem, the implementation of a control process known as load frequency control (LFC) becomes essential. The objective of this study is to optimize the parameters of the LFC controller for a two-area power system consisting of a reheat thermal generator and a photovoltaic power plant. A proportional–integral (PI) controller is employed to damp the oscillations that occur in the frequency and tie-line power change. A newly developed meta-heuristic optimization technique called gorilla troops optimization (GTO) is used for the first time to optimally tune the parameters of the PI controller and improve its performance. The performance of the GTO optimization technique is analyzed under varying load demands, parameter variations, and nonlinearities. Comparative evaluations with different optimization algorithms are performed. The obtained results demonstrate that the proposed GTO-PI controller outperforms the other optimization techniques in terms of reducing the overshoot values in the system frequency and tie-line power change, as well as achieving faster settling times for these oscillations. This research highlights the effectiveness of the GTO-PI controller in LFC, providing improved performance over alternative algorithms. The results underscore the significance of utilizing meta-heuristic optimization techniques for optimal parameter tuning in power system control applications.},
  archive      = {J_NCA},
  author       = {Can, Ozay and Ayas, Mustafa Sinasi},
  doi          = {10.1007/s00521-023-09273-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4179-4193},
  shortjournal = {Neural Comput. Appl.},
  title        = {Gorilla troops optimization-based load frequency control in PV-thermal power system},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new binary arithmetic optimization algorithm for
uncapacitated facility location problem. <em>NCA</em>, <em>36</em>(8),
4151–4177. (<a
href="https://doi.org/10.1007/s00521-023-09261-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arithmetic Optimization Algorithm (AOA) is a heuristic method developed in recent years. The original version was developed for continuous optimization problems. Its success in binary optimization problems has not yet been sufficiently tested. In this paper, the binary form of AOA (BinAOA) has been proposed. In addition, the candidate solution production scene of BinAOA is developed with the xor logic gate and the BinAOAX method was proposed. Both methods have been tested for success on well-known uncapacitated facility location problems (UFLPs) in the literature. The UFL problem is a binary optimization problem whose optimum results are known. In this study, the success of BinAOA and BinAOAX on UFLP was demonstrated for the first time. The results of BinAOA and BinAOAX methods were compared and discussed according to best, worst, mean, standard deviation, and gap values. The results of BinAOA and BinAOAX on UFLP are compared with binary heuristic methods used in the literature (TSA, JayaX, ISS, BinSSA, etc.). As a second application, the performances of BinAOA and BinAOAX algorithms are also tested on classical benchmark functions. The binary forms of AOA, AOAX, Jaya, Tree Seed Algorithm (TSA), and Gray Wolf Optimization (GWO) algorithms were compared in different candidate generation scenarios. The results showed that the binary form of AOA is successful and can be preferred as an alternative binary heuristic method.},
  archive      = {J_NCA},
  author       = {Baş, Emine and Yildizdan, Gülnur},
  doi          = {10.1007/s00521-023-09261-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4151-4177},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new binary arithmetic optimization algorithm for uncapacitated facility location problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IRNet-RS: Image retargeting network via relative saliency.
<em>NCA</em>, <em>36</em>(8), 4133–4149. (<a
href="https://doi.org/10.1007/s00521-023-09258-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image retargeting (IR) aims to fit different display terminals by changing the image aspect ratio while retaining its important content. The IR methods utilize a saliency map to predict the importance of pixels; however, existing methods assume that multiple objects within the saliency map have the same importance, which does not mimic the human attention mechanism and thus results in inadequate protection of the main content during the retargeting operation. To solve these problems, we propose an image retargeting network via relative saliency (IRNet-RS), which has three key steps: relative saliency detection, edge detection, and IR operation. By using a relative saliency stratified supervision module and saliency rank guidance for the refinement module, IRNet-RS detects the salient objects in an image, allocates different saliency weights to them to obtain a relative saliency map, and then fuses it with the edge detection map to generate an importance map. An adaptive duplicate convolution module is also designed to help the network learn the pixel-by-pixel shift map from the source to the target grid, followed by retargeting the image using pixel shifting. Our experimental results show that the proposed IRNet-RS achieves better performance than alternative methods in terms of saliency rank prediction and retargeting results.},
  archive      = {J_NCA},
  author       = {Guo, Yingchun and Zhang, Meng and Hao, Xiaoke and Yan, Gang},
  doi          = {10.1007/s00521-023-09258-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4133-4149},
  shortjournal = {Neural Comput. Appl.},
  title        = {IRNet-RS: Image retargeting network via relative saliency},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-aware reasoning with self-supervised reinforcement
learning for explainable recommendation in MOOCs. <em>NCA</em>,
<em>36</em>(8), 4115–4132. (<a
href="https://doi.org/10.1007/s00521-023-09257-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable recommendation is important but not yet explored in Massive Open Online Courses (MOOCs). Recently, knowledge graph (KG) has achieved great success in explainable recommendations. However, the e-learning scenario has some unique constraints, such as learners’ knowledge structure and course prerequisite requirements, leading the existing KG-based recommendation methods to work poorly in MOOCs. To address these issues, we propose a novel explainable recommendation model, namely Knowledge-aware Reasoning with self-supervised Reinforcement Learning (KRRL). Specifically, to enhance the semantic representation and relation in the KG, a multi-level representation learning method enriches the perceptual information of semantic interactions. Afterward, a self-supervised reinforcement learning method effectively guides the path reasoning over the KG, to match the unique constraints in the e-learning scenario. We evaluate the KRRL model on two real-world MOOCs datasets. The experimental results show that KRRL evidently outperforms state-of-the-art baselines in terms of the recommendation accuracy and explainability.},
  archive      = {J_NCA},
  author       = {Lin, Yuanguo and Zhang, Wei and Lin, Fan and Zeng, Wenhua and Zhou, Xiuze and Wu, Pengcheng},
  doi          = {10.1007/s00521-023-09257-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4115-4132},
  shortjournal = {Neural Comput. Appl.},
  title        = {Knowledge-aware reasoning with self-supervised reinforcement learning for explainable recommendation in MOOCs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel structure preserving generative adversarial network
for CT to MR modality translation of spine. <em>NCA</em>,
<em>36</em>(8), 4101–4114. (<a
href="https://doi.org/10.1007/s00521-023-09254-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a structure preserving generative adversarial network (S-P GAN) to solve the problem of small structure information loss during the modality translation from computed tomography (CT) to magnetic resonance (MR). A novel generator of the S-P GAN is designed to encode features from CT, where an original CT information branch and its corresponding high-frequency information branch form a dual-branch structure. The small details are highlighted by using a filter in the high-frequency information branch, which offers a complement to the integrity of structural information in CT. Meanwhile, a mixed attention mechanism is introduced to better fuse the dual-branch features for decoding features to MR, where small structure features get more attention in channel and space. Additionally, a new joint loss function is proposed to guide the adversarial training of S-P GAN, which contains structural consistency constrain, pixel translation constrain, and adversarial constrain, so that global similarity and local detail consistency are obtained at the same time. Experimental results show that the results of the S-P GAN are superior to the state-of-the-art models in mean absolute error (MAE), peak signal-to-noise ratio (PSNR), and structural similarity (SSIM). In real clinical situations, the proposed method has shown good performance in the diagnosis of lumbar disk herniation, the new and old degree of compressibility fracture, and the Modic change of cartilage end plate.},
  archive      = {J_NCA},
  author       = {Dai, Guangxin and Su, Junxiao and Zhang, Menghua and Liu, Xinyu and Huang, Weijie},
  doi          = {10.1007/s00521-023-09254-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4101-4114},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel structure preserving generative adversarial network for CT to MR modality translation of spine},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interpretable machine learning model for trajectory
prediction based on nonlinear dynamics mechanism constraints:
Applications for HVs. <em>NCA</em>, <em>36</em>(8), 4083–4100. (<a
href="https://doi.org/10.1007/s00521-023-09249-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging for hypersonic vehicles (HVs) with strong nonlinear dynamics characteristics to achieve high-precision trajectory prediction. The un-interpretability of current prediction models and the difficulty in on-orbit data acquisition, high transmission costs and low data integrity bring huge obstacles to the accuracy and reliability of online prediction results. An interpretable modeling method is proposed by the physical block modeling, attention mechanism and mechanism constraints in the training process. Moreover, the binary encoding and inertial module are introduced to further improve the prediction accuracy and efficiency. The interpretability evaluation index is designed to quantitatively evaluate the degree of coincidence between the interpretable prediction model and the mechanism formulas, which proves the credibility of prediction results. The results show that the interpretable model has a better effect on the incomplete training set in terms of accuracy and efficiency. With an 8% incomplete training set, the interpretable model reduces the mean absolute error by 62.9%. After introducing the inertial module, the mean absolute error and the root-mean-square error are reduced by 40.1% and 46.0%. The developed interpretable model not only ensures the prediction accuracy, but also reduces the dependence on the training data and provides a reliable method for high-precision trajectory prediction.},
  archive      = {J_NCA},
  author       = {Zhou, Dengji and Huang, Dawen and Shen, Yaoxin and Ma, Shixi and Wang, Yulin},
  doi          = {10.1007/s00521-023-09249-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4083-4100},
  shortjournal = {Neural Comput. Appl.},
  title        = {An interpretable machine learning model for trajectory prediction based on nonlinear dynamics mechanism constraints: Applications for HVs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modified deep deterministic policy gradient based on active
disturbance rejection control for hypersonic vehicles. <em>NCA</em>,
<em>36</em>(8), 4071–4081. (<a
href="https://doi.org/10.1007/s00521-023-09302-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the attitude control of hypersonic vehicles, a control scheme based on linear active disturbance rejection (LADRC) and modified deep deterministic policy gradient (MDDPG) is proposed. Firstly, LADRC is used to deal with uncertainty and nonlinear problems in the attitude control process. For the tedious manual parameter tuning process, MDDPG is used to optimize the control gains and bandwidth of LADRC. Secondly, a modified reward function and an early stop criterion are introduced in the MDDPG algorithm to improve the optimization performance. Then, another MDDPG is used as an auxiliary control, which is combined with LADRC for attitude control to improve the robustness and accuracy of the control. The proposed method considers the robustness and rapidity of the control. Finally, the effectiveness of the proposed method is proved by simulation. Compared with traditional LADRC, LADRC based on the Q-learning algorithm, LADRC based on the traditional DDPG algorithm, and LADRC based on MDDPG algorithm, the proposed method has a better control effect and can avoid a lot of manual parameter tuning.},
  archive      = {J_NCA},
  author       = {Xu, Li and Yuehui, Ji and Yu, Song and Junjie, Liu and Qiang, Gao},
  doi          = {10.1007/s00521-023-09302-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4071-4081},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified deep deterministic policy gradient based on active disturbance rejection control for hypersonic vehicles},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic dependency network for lyrics generation from
melody. <em>NCA</em>, <em>36</em>(8), 4059–4069. (<a
href="https://doi.org/10.1007/s00521-023-09282-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melody-conditioned lyrics generation aims to create novel lyrics based on the melodies by learning the relationship between lyrics and melodies, which is an attractive topic in the music field. However, two serious issues, called deficiency of inter-dependency between melody attributes and text degeneration, degrade the quality of the lyrics generation. To solve these issues, this paper proposes a new model called semantic dependency network with two key components: (i) N-gram CNN block is used to compress the information from the single melody attribute and extract the inter-dependency from the multiple melody attributes. (ii) In lyrics, unlikelihood training is exploited to mitigate the syllables mismatching and logic missing and keep the intra-syllable integrity and logic by learning semantic dependency. Extensive evaluation experiments on a large-scale dataset demonstrate that our model can generate higher quality and more harmonic lyrics from the melodies compared with the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Duan, Wei and Yu, Yi and Oyama, Keizo},
  doi          = {10.1007/s00521-023-09282-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4059-4069},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semantic dependency network for lyrics generation from melody},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cardiac arrhythmia classification with rejection of ECG
recordings based on uncertainty estimation from deep neural networks.
<em>NCA</em>, <em>36</em>(8), 4047–4058. (<a
href="https://doi.org/10.1007/s00521-023-09267-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of deep learning-based methods, automated classification of electrocardiograms (ECGs) has recently gained much attention. Although the effectiveness of deep neural networks has been encouraging, the lack of information given by the outputs restricts clinicians’ reexamination. If the uncertainty estimation comes along with the classification results, cardiologists can pay more attention to “uncertain” cases. Our study aims to classify ECGs with rejection based on data uncertainty and model uncertainty. We perform experiments on a real-world 12-lead ECG dataset. First, we estimate uncertainties using the Monte Carlo dropout for each classification prediction, based on our deep neural network. Then, we accept predictions with uncertainty under a given threshold and provide “uncertain&quot; cases for clinicians. Furthermore, we perform a simulation experiment using varying thresholds. Finally, with the help of a clinician, we conduct case studies to explain the results of large uncertainties and incorrect predictions with small uncertainties. The results show that correct predictions are more likely to have smaller uncertainties, and the performance on accepted predictions improves as the accepting ratio decreases (i.e., more rejections). The F1-score on accepted predictions improves by 1.3 $$\sim$$ 30.9% when accepting ratio ranges from 97.3 to 45.3%. Case studies also help explain why rejection can improve the performance. Our study helps neural networks produce more accurate results and provide information on uncertainties to better assist clinicians in the diagnosis process. It can also enable deep learning-based ECG interpretation in clinical implementation.},
  archive      = {J_NCA},
  author       = {Zhang, Wenrui and Di, Xinxin and Wei, Guodong and Geng, Shijia and Fu, Zhaoji and Hong, Shenda},
  doi          = {10.1007/s00521-023-09267-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4047-4058},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cardiac arrhythmia classification with rejection of ECG recordings based on uncertainty estimation from deep neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved KNN classifier based on a novel weighted voting
function and adaptive k-value selection. <em>NCA</em>, <em>36</em>(8),
4027–4045. (<a
href="https://doi.org/10.1007/s00521-023-09272-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a modified KNN classifier (HMAKNN) based on the harmonic mean of the vote and average distance of the neighbors of each class label combined with adaptive k-value selection. Within the scope of this study, two different versions of HMAKNN, regular and weighted, HMAKNN $$ _R $$ and HMAKNN $$ _W $$ , were developed depending on whether there is a weighting mechanism or not. These proposed HMAKNN classifiers were tested eight syntetic and twenty-six real benchmark data sets. In order to reveal the effectiveness and the performance of the proposed methods on classification, they were compared with its constituent KNN and four other well-known distance-weighted KNN methods. Unlike other weighting methods, both HMAKNN classifiers use the synergy between majority voting and average distance together, along with the ability to adaptively adjust the k-value, helping to significantly improve classification accuracy. The results on twenty-six real benchmark data sets suggest that both HMAKNN methods produce more accurate results in terms of average ACC and FScore metrics and statistically outperform all competing methods.},
  archive      = {J_NCA},
  author       = {Açıkkar, Mustafa and Tokgöz, Selçuk},
  doi          = {10.1007/s00521-023-09272-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4027-4045},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved KNN classifier based on a novel weighted voting function and adaptive k-value selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A minimum complexity interaction echo state network.
<em>NCA</em>, <em>36</em>(8), 4013–4026. (<a
href="https://doi.org/10.1007/s00521-023-09271-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simple cycle reservoir is a classic work in reservoir structure design, and has good performance in tasks such as discrete dynamical system prediction and time series classification. However, the overly simple reservoir structure weakens its ability to model the complex systems such as chaotic systems. A minimum complexity interaction echo state network (MCI-ESN) is proposed in this paper to overcome the shortcomings of simple cycle reservoir. MCI-ESN consists of two identical simple cycle reservoirs which are interconnected by only two neurons for reducing the connection redundancy and improve connection efficiency. A sufficient condition is given to guarantee that the MCI-ESN model has the echo state property. Several numerical experiments, including multivariable chaotic time series prediction and time series classification, are used to verify the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Liu, Jianming and Xu, Xu and Li, Eric},
  doi          = {10.1007/s00521-023-09271-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {4013-4026},
  shortjournal = {Neural Comput. Appl.},
  title        = {A minimum complexity interaction echo state network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AR-NET: Lane detection model with feature balance concerns
for autonomous driving. <em>NCA</em>, <em>36</em>(8), 3997–4012. (<a
href="https://doi.org/10.1007/s00521-023-09270-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time accurate lane detection is essential task in autonomous driving systems. We propose a new inference model AR-NET to implement the real-time lane detection task. Compared to the pixel-level lane segmentation approach, the Grid classification method is used in AR-NET to reduce computational consumption. Although the deep feature extraction network can extract features effectively, it does not pay attention to the connection between different feature lanes. In order to effectively fuse the extracted features, we propose an interaction network. The lane information obtained from the encoding layer is sent to the interaction network, which uses interaction to fuse local and global features to achieve a balance of local and global attention. Attention is also used to tune target detail features, which learn contextual information by establishing correlations between the features extracted in convolution and the attention channel. Experiments on a publicly available lane detection benchmark dataset demonstrate that our method achieves excellent performance in terms of speed and accuracy. This method achieves 200 + frames per second(FPS) with an accuracy of 96.11% on TuSimple.},
  archive      = {J_NCA},
  author       = {Tong, Guoxiang and Zu, Chuanye},
  doi          = {10.1007/s00521-023-09270-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3997-4012},
  shortjournal = {Neural Comput. Appl.},
  title        = {AR-NET: Lane detection model with feature balance concerns for autonomous driving},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable empirical risk minimization. <em>NCA</em>,
<em>36</em>(8), 3983–3996. (<a
href="https://doi.org/10.1007/s00521-023-09269-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The successful application of machine learning (ML) methods increasingly depends on their interpretability or explainability. Designing explainable ML (XML) systems is instrumental for ensuring transparency of automated decision-making that targets humans. The explainability of ML methods is also an essential ingredient for trustworthy artificial intelligence. A key challenge in ensuring explainability is its dependence on the specific human end user of an ML system. The users of ML methods might have vastly different background knowledge about ML principles, with some having formal training in the specific field and others having none. We use information-theoretic concepts to develop a novel measure for the subjective explainability of predictions delivered by a ML method. We construct this measure via the conditional entropy of predictions, given the user signal. Our approach allows for a wide range of user signals, ranging from responses to surveys to biophysical measurements. We use this measure of subjective explainability as a regularizer for model training. The resulting explainable empirical risk minimization (EERM) principle strives to balance subjective explainability and risk. The EERM principle is flexible and can be combined with arbitrary ML models. We present several practical implementations of EERM for linear models and decision trees. Numerical experiments demonstrate the application of EERM to weather prediction and detecting inappropriate language in social media.},
  archive      = {J_NCA},
  author       = {Zhang, Linli and Karakasidis, Georgios and Odnoblyudova, Arina and Dogruel, Leyla and Tian, Yu and Jung, Alex},
  doi          = {10.1007/s00521-023-09269-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3983-3996},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable empirical risk minimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Refiner: A general object position refinement algorithm for
visual tracking. <em>NCA</em>, <em>36</em>(8), 3967–3981. (<a
href="https://doi.org/10.1007/s00521-023-09263-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object tracking is an important topic in computer vision. Most existing trackers require an accurate initial position of the target. However, in the real application, the initial location for tracking may not be accurate, which may lead to tracking drift. To solve this problem, we propose a simple deep learning-based method called Refiner that can produce the accurate position of an object given its rough location. Specifically, we propose an end-to-end position refinement network that consists of a backbone network, a feature enhancement module, a feature fusion module, and a shape predictor; the shape predictor includes two branches: a bounding box prediction branch and a mask prediction branch. We improve the spatial robustness of existing trackers by correcting the inaccurate initial position. In addition, the proposed method can also be used in the tracking process to improve the accuracy of the subsequent tracking results. Lots of experiments on the object tracking benchmarks verify its effectiveness and efficiency.},
  archive      = {J_NCA},
  author       = {Wu, Han and Zhao, Bo and Liu, Guizhong},
  doi          = {10.1007/s00521-023-09263-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3967-3981},
  shortjournal = {Neural Comput. Appl.},
  title        = {Refiner: A general object position refinement algorithm for visual tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AutoTGRL: An automatic text-graph representation learning
framework. <em>NCA</em>, <em>36</em>(8), 3941–3965. (<a
href="https://doi.org/10.1007/s00521-023-09226-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-graph representation learning is a critical and important area of research with extensive applications in natural language processing (NLP). Recently, graph learning models based on graph neural networks (GNNs) have been effectively utilized for encoding text-graph representation for various tasks due to their ability to handle complex structures and capture global information. However, existing text-graph representation learning models are heavily based on the manual design of model architectures and fine-tuning hyperparameters, which is time-consuming and relies on expert knowledge. To address this challenge, we propose an automatic text-graph representation learning (AutoTGRL) framework for transductive and inductive learning-based downstream tasks on text graphs. Specifically, the AutoTGRL framework first builds a general text-graph representation learning model (TGRL model) for text-graph transductive and inductive learning. Then, to enable the automatic design of TGRL models, we propose an automated TGRL model search module. In the automated TGRL model search module, we propose an effective and customized search space called text-graph representation learning (TGRL) search space, which consists of three subspaces, including large-scale embedding strategy space, text-graph representation strategy space, and GNN structure and hyperparameter space, to build TGRL models. We propose to use a search algorithm to search for the best combinations to construct TGRL models to fulfill different downstream tasks from the TGRL search space. To demonstrate the effectiveness AutoTGRL framework, we apply it to text classification, aspect-based sentiment analysis (ABSA), and entity and relation extraction tasks. The extensive experiments demonstrate the superiority of AutoTGRL to design the optimal TGRL models, which outperform the state-of-the-art models over multiple datasets.},
  archive      = {J_NCA},
  author       = {Al-Sabri, Raeed and Gao, Jianliang and Chen, Jiamin and Oloulade, Babatounde Moctard and Lyu, Tengfei},
  doi          = {10.1007/s00521-023-09226-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3941-3965},
  shortjournal = {Neural Comput. Appl.},
  title        = {AutoTGRL: An automatic text-graph representation learning framework},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). An improved self-attention for long-sequence time-series
data forecasting with missing values. <em>NCA</em>, <em>36</em>(8),
3921–3940. (<a
href="https://doi.org/10.1007/s00521-023-09347-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-sequence time-series data forecasting based on deep learning has been applied in many practical scenarios. However, the time-series data sequences obtained in the real world inevitably contain missing values due to the failures of sensors or network fluctuations. Current research works dedicate to imputing the incomplete time-series data sequence during the data preprocessing stage, which will lead to the problems of unsynchronized prediction and error accumulation. In this article, we propose an improved multi-headed self-attention mechanism, DecayAttention, which can be applied to the existing X-former models to handle the missing values in the time-series data sequences without decreasing their prediction accuracy. We apply DecayAttention to Transformer and two state-of-the-art X-former models, and the best prediction accuracy improves by 8.2%.},
  archive      = {J_NCA},
  author       = {Zhang, Zhi-cheng and Wang, Yong and Peng, Jian-jian and Duan, Jun-ting},
  doi          = {10.1007/s00521-023-09347-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3921-3940},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved self-attention for long-sequence time-series data forecasting with missing values},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FAformer: Parallel fourier-attention architectures benefits
EEG-based affective computing with enhanced spatial information.
<em>NCA</em>, <em>36</em>(8), 3903–3919. (<a
href="https://doi.org/10.1007/s00521-023-09289-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The balance of brain functional segregation (i.e., the process in specialized local subsystems) and integration (i.e., the process in global cooperation of the subsystems) is crucial for cognition in human beings, and many deep learning models have been used to evaluate the spatial information during EEG-based affective computing. However, acquiring the intrinsic spatial representation in the topology of EEG channels is still challenging. To further address the issue, we propose the FAformer to enhance spatial information in EEG signals with parallel-branch architectures based on a vision transformer (ViT). In the encoder, there is a branch that utilizes Adaptive Neural Fourier Operators (AFNO) to model global spatial patterns using the Fourier transform in the electrode channel dimension. The other branch utilizes multi-head self-attention (MSA) to explore the dependence of emotion on different channels, which is conducive to building key local networks. Additionally, a self-supervised learning (SSL) task of adaptive feature dissociation (AdaptiveFD) is developed to improve the distinctiveness of spatial features generated from the parallel branches and guarantee robustness in different subjects. FAformer achieves superior performance over the competitive models on the DREAMER and DEAP. Moreover, the rationality and hyperparameters analysis are conducted to demonstrate the effectiveness of the FAformer. Finally, the visualization of features reveals the spatial global connections and key local patterns during the deep learning process in FAformer, which benefits EEG-based affective computing.},
  archive      = {J_NCA},
  author       = {Gao, Ziheng and Huang, Jiajin and Chen, Jianhui and Zhou, Haiyan},
  doi          = {10.1007/s00521-023-09289-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3903-3919},
  shortjournal = {Neural Comput. Appl.},
  title        = {FAformer: Parallel fourier-attention architectures benefits EEG-based affective computing with enhanced spatial information},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GTAN: Graph-based tracklet association network for
multi-object tracking. <em>NCA</em>, <em>36</em>(8), 3889–3902. (<a
href="https://doi.org/10.1007/s00521-023-09287-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) is a thriving research field in computer vision. The tracklet-based MOT frameworks are frequently employed to generate long and stable trajectories in work scenes that involve long-term occlusion. However, most of these methods train tracklet feature encoders using complex loss functions, lacking an end-to-end paradigm guided by association results, which ultimately leads to limited MOT performance. To address this issue, a graph-based tracklet association framework that seamlessly integrates tracklet feature learning with tracklet association, thereby achieving tracklet association in an end-to-end manner. Specifically, we perform tracklet-based MOT in the graph domain and transform the tracklet association problem into an edge classification task. A message passing network (MPN) is used to update the tracklet features globally, which enhances the robustness of the tracklet features. Additionally, an attention-based feature update function is proposed to ensure the significance of current object. The effectiveness of the proposed framework is demonstrated using MOT17 and MOT20 benchmark datasets, and the experimental results show that the graph-based tracklet association network is a model-independent and plug-and-play component that could combine with different frame-based trackers to boost the MOT performance significantly.},
  archive      = {J_NCA},
  author       = {Jianfeng, Lv and Zhongliang, Yu and Yifan, Liu and Guanghui, Sun},
  doi          = {10.1007/s00521-023-09287-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3889-3902},
  shortjournal = {Neural Comput. Appl.},
  title        = {GTAN: Graph-based tracklet association network for multi-object tracking},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive evaluation of feature-based AI techniques
for deepfake detection. <em>NCA</em>, <em>36</em>(8), 3859–3887. (<a
href="https://doi.org/10.1007/s00521-023-09288-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the contemporary era, where data and information are the key source in every domain, it becomes imperative to identify, detect and distinguish between fake and authentic content available online. Recent technological innovations in the area of artificial intelligence (AI) and computer vision (CV) have been the key players both in generating and detection of these media (both images and videos). The advancement of techniques for generating, fabricating, and manipulating multimedia materials has resulted in a heightened level of realism, thereby giving rise to numerous security concerns. The adoption of these technologies has resulted in the widespread dissemination of fraudulent images and videos, which are being utilised for various criminal purposes and often featuring misleading information and impersonations of public personalities, which have detrimental consequences on the reputations of those individuals involved. The proliferation of counterfeit images poses a significant threat to national security, as these images can be exploited for the purpose of identity forgery. Therefore, it is imperative to design and develop robust algorithms for detecting counterfeit media, capable of effectively distinguishing between authentic and manipulated content. This study aims to present the generative and detection techniques of visual deep fake media using deep learning (CNN, RNN, LSTM, etc.), machine learning (SVM, KNN, Random Forest, and Decision Tree) and statistical learning (3D Morphable Model). This study also conducted an in-depth analysis of the current state of literature concerning the development and application of deepfake technology, as well as the accessibility of open-source tools for generating manipulated media. The present study provides an extensive review of face manipulation methodologies employed in the development of deep fakes, specifically focusing on Identity swap, Image Synthesis, Face Re-enactment, and Attribute Manipulation. A presented review proposed a novel taxonomy based on spatial, temporal and frequency-based features for the detection of visual Deepfake. This study out passes the existing surveys that have been presented by various other researchers in this field in terms of domain, learning methods, features and manipulation techniques used. In this study, the challenges and research gaps along with the analysis of each of these have also been presented with the intent for prioritising the development of deep fake detection tools.},
  archive      = {J_NCA},
  author       = {Sandotra, Neha and Arora, Bhavna},
  doi          = {10.1007/s00521-023-09288-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3859-3887},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive evaluation of feature-based AI techniques for deepfake detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of inductive knowledge graph completion.
<em>NCA</em>, <em>36</em>(8), 3837–3858. (<a
href="https://doi.org/10.1007/s00521-023-09286-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) can enhance the completeness of the knowledge graph (KG). Traditional transductive KGC assumes that all entities and relations employed during testing have been seen in the training phase. As real-world KGs constantly evolve, it becomes imperative to retrain the KG whenever unseen entities or relations appear. Inductive knowledge graph completion (IKGC) aims to complete missing triples involving unseen entities or relations without retraining and has garnered substantial attention recently. This paper is the first one that provides a comprehensive review of IKGC from both technical and theoretical perspectives. Technically, IKGC is categorized into two groups: structural information-based IKGC and additional information-based IKGC. Theoretically, IKGC is divided into two categories: semi-inductive setting and fully-inductive setting. In particular, each category is further subdivided into distinct granularities, and theoretical scenarios are incorporated into the technical methods to facilitate comparison and analysis. Finally, future research directions are prospected.},
  archive      = {J_NCA},
  author       = {Liang, Xinyu and Si, Guannan and Li, Jianxin and Tian, Pengxin and An, Zhaoliang and Zhou, Fengyu},
  doi          = {10.1007/s00521-023-09286-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {3837-3858},
  shortjournal = {Neural Comput. Appl.},
  title        = {A survey of inductive knowledge graph completion},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Biometric systems for identification and verification
scenarios using spatial footsteps components. <em>NCA</em>,
<em>36</em>(7), 3817–3836. (<a
href="https://doi.org/10.1007/s00521-023-09390-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans are distinguished by their walking patterns; many approaches, including using various types of sensors, have been used to establish walking patterns as biometrics. By studying the distinguishing features of a person&#39;s footsteps, footstep recognition may be utilized in numerous security applications, such as managing access in protected locations or giving an additional layer of biometric verification for secure admittance into restricted regions. We proposed biometric systems for verifying and identifying a person by acquiring spatial foot pressure images from the values obtained from the piezoelectric sensors using the Swansea Foot Biometric Database, which contains 19,980 footstep signals from 127 users and is the most prominent open-source gait database available for footstep recognition. The images acquired are fed into the ConvNeXt model, which was trained using the transfer learning technique, using 16 stride footstep signals in each batch with an Adam optimizer and a learning rate of 0.0001, and using sparse categorical cross-entropy as the loss function. The proposed ConvNeXt model has been adjusted to acquire 512 feature vectors per image, and these feature vectors are used to train the logistic regression models. We propose two biometric systems. The first biometric system is based on training one logistic regression model as a classifier to identify 40 different users using 1600 signals for training, 6697 signals for validation, and 200 signals for evaluation. The second biometric system is based on training 40 logistic regression models, one for each user, to validate the user&#39;s authenticity, with a total number of 2363 training signals, 7077 validation signals, and 500 evaluation signals. Each of the 40 models has a 40-training signal per client and a different number of signals per imposter, a different number of signals for the validation that ranges between 8 and 650 signals, a 5-signal for an authenticated client, and a different number of signals per imposter for evaluation. Independent validation and evaluation sets are used to evaluate our systems. In the biometric identification system, we obtained an equal error rate of 15.30% and 21.72% for the validation and evaluation sets, while in the biometric verification system, we obtained an equal error rate of 6.97% and 10.25% for the validation and evaluation sets.},
  archive      = {J_NCA},
  author       = {Iskandar, Ayman and Alfonse, Marco and Roushdy, Mohamed and El-Horbaty, El-Sayed M.},
  doi          = {10.1007/s00521-023-09390-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3817-3836},
  shortjournal = {Neural Comput. Appl.},
  title        = {Biometric systems for identification and verification scenarios using spatial footsteps components},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MLDC: Multi-lung disease classification using quantum
classifier and artificial neural networks. <em>NCA</em>, <em>36</em>(7),
3803–3816. (<a
href="https://doi.org/10.1007/s00521-023-09207-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung diseases are one of the most common diseases around the world. The risk of these diseases are more in under-developed and developing countries, where millions of people are battling with poverty and living in polluted air. Chest X-Ray images are helpful screening tool for lung disease detection. However, disease diagnosis requires expert medical professionals. Furthermore, in developing and under-developed nations, the doctor-to-patient ratio is comparatively poor. Deep learning algorithms have recently demonstrated promise in the analysis of medical images and the discovery of patterns. In this current work, we have proposed a model MLDC (Multi-Lung Disease Classification) to detect common lung diseases. It introduces a MLDC feature extraction model with two different new classifiers, considering ANN (an artificial neural network) and QC (a quantum classifier). In this proposed model, tests are performed on the LDD (Lung Disease Dataset), which includes COVID-19, pneumonia, tuberculosis, and a healthy person’s lung from chest X-ray images. Our proposed model achieves an accuracy of 95.6% for MLDC-ANN and 97.5% for MLDC-QC at a lower computational cost.},
  archive      = {J_NCA},
  author       = {Arora, Riya and Rao, G. V. Eswara and Banerjea, Shashwati and Rajitha, B.},
  doi          = {10.1007/s00521-023-09207-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3803-3816},
  shortjournal = {Neural Comput. Appl.},
  title        = {MLDC: Multi-lung disease classification using quantum classifier and artificial neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multilayered framework for diagnosis and classification of
alzheimer’s disease using transfer learned alexnet and LSTM.
<em>NCA</em>, <em>36</em>(7), 3777–3801. (<a
href="https://doi.org/10.1007/s00521-023-09301-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease (AD) is the most frequent type of dementia that has no effective cure, except early discovery and treatment that may help patients to include successful years in patient’s lives. Currently, mini-mental state examination (MMSE) score and manual examination of magnetic resource imaging (MRI) scan along with machine learning techniques are used to diagnose the disease; however, they possess certain accuracy limits. Therefore, this paper proposes a deep learning-based multilayered framework for AD classification using transfer learned Alexnet and LSTM for multiclass and binary classification of MR images. However, the deep learning models used in the current study necessitate a large training dataset to produce better outcomes. As a result, this work also utilizes generative adversarial network (GAN) as a data augmentation tool to improve the classification results and further to solve the problem of overfitting. The study uses Alzheimer’s disease neuroimaging initiative (ADNI) dataset of 60 AD, 73 mild cognitive impairment (MCI) and 67 cognitively normal (CN) patients from which 2 D MR image scans are extracted. Furthermore, the proposed method achieved the classification accuracy on AD–CN at 98.13%, AD–MCI at 99.38% and CN–MCI at 99.37%, respectively. Also, the multiclass classification shows the promising accuracy of 96.83% for the proposed framework. Finally, the proposed model&#39;s performance is compared to other state-of-the-art techniques and the experimental results show that the proposed model outperforms in terms of accuracy, sensitivity and hypothesis testing.},
  archive      = {J_NCA},
  author       = {Goyal, Palak and Rani, Rinkle and Singh, Karamjeet},
  doi          = {10.1007/s00521-023-09301-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3777-3801},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multilayered framework for diagnosis and classification of alzheimer&#39;s disease using transfer learned alexnet and LSTM},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memory augmented echo state network for time series
prediction. <em>NCA</em>, <em>36</em>(7), 3761–3776. (<a
href="https://doi.org/10.1007/s00521-023-09276-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo state networks (ESNs), a special class of recurrent neural networks (RNNs), have attracted extensive attention in time series prediction problems. Nevertheless, the memory ability of ESNs is contradictory to nonlinear mapping, which limits the prediction performance of the network on complex time series. To balance the memory ability and the nonlinear mapping, an improved ESN model is proposed, named memory augmented echo state network (MA-ESN). When designing MA-ESN, both linear memory modules and nonlinear mapping modules are introduced into the reservoir in a new way of combination. The linear memory module improves the memory ability, while the nonlinear mapping module retains the nonlinear mapping of the network. Meanwhile, the echo state property of MA-ESN has been analyzed in theory. Finally, we have evaluated the memory ability and prediction performance of the proposed MA-ESN on benchmark time series data sets. The related experimental results demonstrate that the MA-ESN model outperforms some similar ESN models with a special memory mechanism.},
  archive      = {J_NCA},
  author       = {Liu, Qianwen and Li, Fanjun and Wang, Wenting},
  doi          = {10.1007/s00521-023-09276-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3761-3776},
  shortjournal = {Neural Comput. Appl.},
  title        = {Memory augmented echo state network for time series prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view graph representation learning for hyperspectral
image classification with spectral–spatial graph neural networks.
<em>NCA</em>, <em>36</em>(7), 3737–3759. (<a
href="https://doi.org/10.1007/s00521-023-09275-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) classification benefits from effectively handling both spectral and spatial features. However, deep learning (DL) models, like graph convolutional networks (GCN), face challenges in computation time, overfitting, and less informative features. To address these challenges, we propose a novel method called MV-GRL (multi-view graph representation learning) for HSI classification using spectral–spatial graph neural networks. MV-GRL incorporates spectral and spatial features with the extended morphological profile (EMP) and employs a multi-view graph autoencoder (MVGAE) to learn a low-dimensional latent graph representation by fusing two input graphs: spectral features-based graph and spatial-based graph. This fusion enhances the discriminative power of the features. Additionally, we introduce a semi-supervised spectral–spatial GCN using the multi-view latent representation, leveraging labeled and unlabeled samples for improved classification performance. By leveraging both labeled and unlabeled data, our method effectively captures underlying relationships and enhances overall accuracy. Experimental results on the Indian Pines, Salinas, and Pavia University datasets demonstrate its competitive performance, achieving overall accuracy (OA) scores of 96.91%, 97.64%, and 98.88%, respectively, surpassing state-of-the-art (SOTA) models.},
  archive      = {J_NCA},
  author       = {Hanachi, Refka and Sellami, Akrem and Farah, Imed Riadh and Dalla Mura, Mauro},
  doi          = {10.1007/s00521-023-09275-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3737-3759},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-view graph representation learning for hyperspectral image classification with spectral–spatial graph neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the transferability of adversarial examples with
separable positive and negative disturbances. <em>NCA</em>,
<em>36</em>(7), 3725–3736. (<a
href="https://doi.org/10.1007/s00521-023-09259-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples demonstrate the vulnerability of white-box models but exhibit weak transferability to black-box models. In image processing, each adversarial example usually consists of original image and disturbance. The disturbances are essential for the adversarial examples, determining the attack success rate on black-box models. To improve the transferability, we propose a new white-box attack method called separable positive and negative disturbance (SPND). SPND optimizes the positive and negative perturbations instead of the adversarial examples. SPND also smooths the search space by replacing constrained disturbances with unconstrained variables, which improves the success rate of attacking the black-box model. Our method outperforms the other attack methods in the MNIST and CIFAR10 datasets. In the ImageNet dataset, the black-box attack success rate of SPND exceeds the optimal CW method by nearly ten percentage points under the perturbation of $$L_\infty = 0.3$$ .},
  archive      = {J_NCA},
  author       = {Yan, Yuanjie and Bu, Yuxuan and Shen, Furao and Zhao, Jian},
  doi          = {10.1007/s00521-023-09259-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3725-3736},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving the transferability of adversarial examples with separable positive and negative disturbances},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An embedded device-oriented fatigue driving detection method
based on a YOLOv5s. <em>NCA</em>, <em>36</em>(7), 3711–3723. (<a
href="https://doi.org/10.1007/s00521-023-09255-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, most fatigue driving detection methods rely on complex neural networks whose feasibility in hardware implementation needs to be further improved. This paper proposes an embedded device-oriented fatigue driving detection method based on a lightweight YOLOv5s. Firstly, a YOLOv5s face detection network with a parametric-free attention mechanism is designed to enhance the focus on face regions during face detection. Then, a practical facial landmark detector model is improved by integrating multi-scale feature fusion with Ghost module, which can adapt to the variations brought by different scale targets. Next, a fatigue determination approach is investigated by using multiple features of the face. Finally, experiments of the proposed detection model with the public YawDD dataset are implemented on the PC platform and the embedded device, respectively. The experimental results demonstrate that the proposed method achieves a detection accuracy of 95.3% and a processing speed of 22FPS on the PC platform. Meanwhile, the hardware test on an Orange Pi5 embedded device achieves a detection accuracy of 93.3% and a processing speed of 12FPS, which has good prospects for applications.},
  archive      = {J_NCA},
  author       = {Qu, Jiaxiang and Wei, Ziming and Han, Yimin},
  doi          = {10.1007/s00521-023-09255-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3711-3723},
  shortjournal = {Neural Comput. Appl.},
  title        = {An embedded device-oriented fatigue driving detection method based on a YOLOv5s},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TR-BI-RADS: A novel dataset for BI-RADS based mammography
classification. <em>NCA</em>, <em>36</em>(7), 3699–3709. (<a
href="https://doi.org/10.1007/s00521-023-09251-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is still a crucial public health problem worldwide, especially among women. Early diagnosis and treatment can be provided to patients with regular mammography. The BI-RADS system, which is a standard approach used when interpreting mammography results, is widely used worldwide. The number of datasets classified according to the BI-RADS system is mostly limited. Based on this shortcoming, in this study, we introduce a new benchmark dataset, &quot;TR-BI-RADS&quot;, for mammogram classification based on BI-RADS standardization. A convolution neural network (CNN) is evaluated on this dataset. In addition to the newly defined (TR-BI-RADS) dataset, experiments are also carried out on the other dataset (INbreast Dataset), available in the literature and consists of BI-RADS categories. We believe that the TR-BI-RADS dataset will be beneficial for detecting breast cancer in the future studies.},
  archive      = {J_NCA},
  author       = {Ülgü, Mustafa Mahir and Zalluhoglu, Cemil and Birinci, Suayip and Yarbay, Yasin and Sezer, Ebru Akcapinar},
  doi          = {10.1007/s00521-023-09251-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3699-3709},
  shortjournal = {Neural Comput. Appl.},
  title        = {TR-BI-RADS: A novel dataset for BI-RADS based mammography classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-level contrastive graph learning for academic
abnormality prediction. <em>NCA</em>, <em>36</em>(7), 3681–3698. (<a
href="https://doi.org/10.1007/s00521-023-09268-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic Abnormality Prediction aims to predict whether students have academic abnormalities through their historical academic scores. However, existing research methods still have the following challenges: (1) Student behavior. Only the students’ historical academic performance is considered, ignoring the impact of student behavior in student status. (2) Data imbalance. The number of academically abnormal students is much less than that of ordinary students, resulting in a data imbalance problem. Therefore, in response to the above challenges, this paper proposes a Multi-level Contrastive Graph learning for academic abnormality prediction (MCG). Specifically, firstly, we capture student behavior and fuse it with student historical achievement data based on a Graph Neural Network (GNN), Thereafter, we construct an embedding space for sample interpolation, which generates virtual nodes of abnormal students, thereby alleviating the data imbalance problem. Moreover, we introduce a multi-level contrastive learning module to precisely learn node representations and maximize the consistency between different views of the same node in the target and online networks for data augmentation. Experiments on real datasets show that the abnormality prediction performance of MCG outperforms the existing state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Ouyang, Yong and Wang, Yuanlin and Gao, Rong and Zeng, Yawen and Liu, Jinhang and Ye, Zhiwei},
  doi          = {10.1007/s00521-023-09268-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3681-3698},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-level contrastive graph learning for academic abnormality prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Similar question retrieval with incorporation of
multi-dimensional quality analysis for community question answering.
<em>NCA</em>, <em>36</em>(7), 3663–3679. (<a
href="https://doi.org/10.1007/s00521-023-09266-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The semantic-based method for question retrieval is an important method for searching similar questions in community question answering (CQA). The major challenges in question retrieval lie in polysemy and lexical gaps between questions, and the quality of retrieved similar questions by semantic retrieval model might not be high enough to effectively solve one’s doubts. In order to address these challenges, a high-quality and multi-level semantic analysis-based similar question retrieval framework named HQML-QR is proposed, which consists of semantic representation from tag-level and sentence-level semantics for question retrieval (TS-QR) and multi-dimensional quality analysis (MDQQ). Firstly, TS-QR extracts multi-level semantic features of the question contents, where graph embedding model is utilized to learn coarse-grained semantics of questions from the scope of the tag. Meanwhile, in order to effectively identify polysemy and extract fine-grained sentence semantic of questions, TS-QR integrates the pre-trained language model based on self-attention mechanism to ensure the accuracy of question retrieval. Secondly, based on the quality factors in CQA (i.e., popularity, question, answer and user), MDQQ constructs a multi-dimensional quality evaluation model to provide a reasonable quality measurement standard for questions. Under the guidance of the quality of questions, the similarity score obtained by semantic vector matching is updated to retrieve high-quality and semantically similar questions. Finally, experiments are executed on CQADupStack dataset from Stack Overflow and the experimental results show that the P@N of HQML-QR has an average increase of 5.65%, 4.44% and 4.34% compared with LDA-VSM-SEM, WET-QR, RCM-QR, respectively.},
  archive      = {J_NCA},
  author       = {Liu, Yue and Tang, Weize and Liu, Zitu and Tang, Aihua and Zhang, Lipeng},
  doi          = {10.1007/s00521-023-09266-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3663-3679},
  shortjournal = {Neural Comput. Appl.},
  title        = {Similar question retrieval with incorporation of multi-dimensional quality analysis for community question answering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fault-attri-attention: A method for fault identification
based on seismic attributes attention. <em>NCA</em>, <em>36</em>(7),
3645–3661. (<a
href="https://doi.org/10.1007/s00521-023-09265-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imaging principle of seismic images is different from natural images, which results in very limited resolution, complex reflection features and strong uncertainty of seismic images. The fault interpretation methods based on seismic attribute analysis have been widely applied in the industry. However, the seismic attribute has inherent limitations and strong multiplicity. In order to overcome the limitations and multiplicity, a method for fault identification based on seismic attributes attention is proposed to enhance the expression ability of seismic multi-attributes fusion in fault identification tasks. Specifically, the fault identification model is proposed to achieve multi-objective joint prediction by fusing seismic multi-attributes. The seismic attributes attention mechanism named Fault-Attri-Attention is proposed to adaptively extract seismic attributes attention according to the difference in contributions of seismic attributes to fault identification tasks, which can obtain the optimal seismic multi-attributes fusion output. The multi-scales TransBlock module is proposed to enhance the feature expression of seismic attributes with different scales. Experimental results show that the fault identification method based on seismic attributes attention can achieve complementary multi-scales features information, which ensures the independence of seismic attributes and the integrity of multivariate information.},
  archive      = {J_NCA},
  author       = {Li, Xiao and Li, Kewen},
  doi          = {10.1007/s00521-023-09265-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3645-3661},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fault-attri-attention: A method for fault identification based on seismic attributes attention},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-domain object detection by local to global
object-aware feature alignment. <em>NCA</em>, <em>36</em>(7), 3631–3644.
(<a href="https://doi.org/10.1007/s00521-023-09248-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain object detection has attracted more and more attention recently. It reduces the gap between the two domains, where the source domain is labeled and the target domain is label-agnostic. The feature alignment is a fundamental step for cross-domain object detection. However, the complex background information may lead to an unreliable feature alignment and even negative transfer. It has been found that paying more attention to the object instances is more conducive to the feature alignment. Therefore, this paper proposes a local to global object-aware feature alignment (OFA) method for cross-domain object detection. The proposed network consists of three components: (1) local object-aware feature alignment (LOFA) module, which utilizes the classification map to enhance the local object representation and achieve the local object feature alignment. (2) cross-scale attention feature alignment (CAFA) module, which employs the local cross-channel interactive attention to highlight the foreground features and aligns the features of global cross-scale fusion in the multi-scale level. (3) memory-category guided alignment (MCGA) module, which records all category features from the source domain, and then uses the memory-category features to guide the category learning of target domain. By the proposed OFA, the enhanced object information can lead to better feature alignment. The proposed method is demonstrated by the cross-domain detection in different scenarios and shows state-of-the-art performance.},
  archive      = {J_NCA},
  author       = {Song, Yiguo and Liu, Zhenyu and Tang, Ruining and Duan, Guifang and Tan, Jianrong},
  doi          = {10.1007/s00521-023-09248-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3631-3644},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-domain object detection by local to global object-aware feature alignment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An entity-guided text summarization framework with
relational heterogeneous graph neural network. <em>NCA</em>,
<em>36</em>(7), 3613–3630. (<a
href="https://doi.org/10.1007/s00521-023-09247-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two of the most crucial issues for text summarization to generate faithful summaries are to make use of knowledge beyond text and to make use of cross-sentence relations in text. Intuitive ways for the two issues are knowledge graph (KG) and graph neural network (GNN), respectively. Entities are semantic units in text and in KG. This paper focuses on both issues by leveraging entities mentioned in text to connect GNN and KG for summarization. Firstly, entities are leveraged to construct a sentence-entity graph with weighted multi-type edges to model sentence relations, and a relational heterogeneous GNN for summarization is proposed to calculate node encodings. Secondly, entities are leveraged to link the graph to KG to collect knowledge. Thirdly, entities guide a two-step summarization framework defining a multitask selector to select salient sentences and entities, and using an entity-focused abstractor to compress the sentences. GNN is connected with KG by constructing sentence-entity graphs where entity–entity edges are built based on KG, initializing entity embeddings on KG, and training entity embeddings using entity–entity edges. The relational heterogeneous GNN utilizes both edge weights and edge types in GNN to calculate graphs with weighted multi-type edges. Experiments show the proposed method outperforms extractive baselines including the HGNN-based HGNNSum and abstractive baselines including the entity-driven SENECA on CNN/DM, and outperforms most baselines on NYT50. Experiments on sub-datasets show the density of sentence-entity edges greatly influences the performance of the proposed method. The greater the density, the better the performance. Ablations show effectiveness of the method.},
  archive      = {J_NCA},
  author       = {Chen, Jingqiang},
  doi          = {10.1007/s00521-023-09247-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3613-3630},
  shortjournal = {Neural Comput. Appl.},
  title        = {An entity-guided text summarization framework with relational heterogeneous graph neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A train dispatching model in case of segment blockages by
integrating the prediction of delay propagation. <em>NCA</em>,
<em>36</em>(7), 3595–3611. (<a
href="https://doi.org/10.1007/s00521-023-09243-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the high-speed railway system, trains’ original timetable is often disturbed by some emergencies including geological disasters and equipment failures, which brings great influence to passengers. This paper proposes a real-time high-speed train dispatching model in case of segment blockages, where a railway network is considered. The model includes the following two parts. First, if the trains are not cancelled or decelerated after a blockage occurs, the scope of the affected trains and stations is roughly estimated via the prediction of delay propagation model. Second, with the overall delay as the objective function, this paper constructs a mixed integer nonlinear programming (MINLP) model by considering the following three adjustment strategies: cancellation, delayed departure and deceleration, where the safe headway of the train operation is guaranteed by the moving blocking principle. Furthermore, to reduce the computation complexity, the solution of the model is only considered within the scope obtained in the first stage. The model is verified by using a small railway network with Nanjing as the hub station, which shows that the model is useful for reducing the effect of a disruption on original timetable, especially in comparison with the First Scheduled First Served (FSFS) rule used in practice.},
  archive      = {J_NCA},
  author       = {Yang, Han and Hu, Wenfeng and Ma, Shan and Peng, Tao},
  doi          = {10.1007/s00521-023-09243-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3595-3611},
  shortjournal = {Neural Comput. Appl.},
  title        = {A train dispatching model in case of segment blockages by integrating the prediction of delay propagation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning approach to satellite image time series
coregistration through alignment of road networks. <em>NCA</em>,
<em>36</em>(7), 3583–3593. (<a
href="https://doi.org/10.1007/s00521-023-09242-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adverse effects of thawing permafrost on transportation infrastructure in northern regions are exacerbated by climate change. To address this issue, remote sensing techniques can be employed to track deformations in these structures over time. This will allow us to identify regions that are most vulnerable to permafrost degradation, and implement climate adaptation strategies accordingly. The Sentinel-2 mission provides highly suitable data for multitemporal analysis due to its high temporal resolution and multispectral coverage. However, the geometrical misalignment of Sentinel-2 imagery presents a significant challenge for such analysis. In this study, we propose an automatic sub-pixel coregistration algorithm for satellite image time series, specifically focusing on estimating the deformation of linear infrastructure in northern Canada. Our approach involves utilizing a deep learning model to generate binary masks of roads, which are then used to match and align the images. We demonstrate the feasibility of achieving sub-pixel coregistration through road alignment on a small dataset of high-resolution Sentinel-2 images from the town of Gillam in northern Canada. This represents an initial step toward training a road deformation prediction model, which can ultimately contribute to improved infrastructure resilience and adaptation to changing climatic conditions.},
  archive      = {J_NCA},
  author       = {Pérez, Andres F. and Maghoul, Pooneh and Ashraf, Ahmed},
  doi          = {10.1007/s00521-023-09242-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3583-3593},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning approach to satellite image time series coregistration through alignment of road networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time adaptive fuzzy control of nonlinear systems with
actuator faults and input saturation. <em>NCA</em>, <em>36</em>(7),
3569–3581. (<a
href="https://doi.org/10.1007/s00521-023-09222-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the finite-time control problem of a class of uncertain nonlinear systems subject to input saturation and actuator faults. To approximate the unknown system states, a fuzzy state observer is established where fuzzy logic systems are utilized to estimate the unknown nonlinearities. A nonlinear disturbance observer to estimate the external disturbance of the system. A new finite-time adaptive fuzzy controller is constructed together with the proposed disturbance and state observers, which can guarantee the tracking error into a small neighborhood around zero within finite time. To avoid the tedious and arithmetic problems brought by the traditional backstepping control, the dynamic surface technique is applied, which can effectively reduce the computation burden. It can be proved that not only the boundedness of the closed-loop system states can be guaranteed but also the tracking error is regulated into a small range near the equilibrium in finite time, despite unknown actuator faults and input saturation. Finally, the simulations of two-stage chemical reactor nonlinear system are conducted to demonstrate the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Li, Jiafeng and Ji, Ruihang and Liang, Xiaoling and Yan, Hao and Ge, Shuzhi Sam},
  doi          = {10.1007/s00521-023-09222-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3569-3581},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time adaptive fuzzy control of nonlinear systems with actuator faults and input saturation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-delayed impulsive stability for stochastic multi-link
complex networks with time-varying coupling structure. <em>NCA</em>,
<em>36</em>(7), 3555–3568. (<a
href="https://doi.org/10.1007/s00521-023-09170-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studied the exponential stability of stochastic functional differential systems based on directed networks, utilizing impulsive control with multiple delays. The impulsive control considered in this article is related to multi-past states since the impact of input delay for stability. It is worth mentioning that multi-link networks are constructed as extensions of single-link or double-link networks. The time-varying coupling strength is considered, which is generally but rarely considered in network stability. Several criteria, which are related to the network topology, input delays, and involved impulsive control schemes, are obtained based on Lyapunov-Razumikhin method and graph theory. Subsequently, the stability of multi-link stochastic time-varying networks with time delays is studied using delayed impulsive control. Finally, the theoretical results are applied to the oscillator system, and some numerical simulations are given.},
  archive      = {J_NCA},
  author       = {Yang, Ni and Chen, Jiakun and Su, Huan},
  doi          = {10.1007/s00521-023-09170-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3555-3568},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-delayed impulsive stability for stochastic multi-link complex networks with time-varying coupling structure},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fine-tuning deep learning with multi-objective-based
feature selection approach for the classification of text. <em>NCA</em>,
<em>36</em>(7), 3525–3553. (<a
href="https://doi.org/10.1007/s00521-023-09225-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document classification is becoming increasingly essential for the vast number of documents available in digital libraries, emails, the Internet, etc. Textual records frequently contain non-discriminative (noisy and irrelevant) terms that are also high-dimensional, resulting in higher computing costs and poorer learning performance in Text Classification (TC). Feature selection (FS), which tries to discover discriminate terms or features from the textual data, is one of the most effective tasks for this issue. This paper introduces a novel multi-stage term-weighting scheme-based FS model designed for the single-label TC system to obtain the optimal set of features. We have also developed a hybrid deep learning fine-tuning network based on Bidirectional Long Short-Term Memory (BiLSTM) and Convolutional Neural Network (CNN) for the classification stage. The FS approach is worked on two-stage criteria. The filter model is used in the first stage, and the multi-objective wrapper model, an upgraded version of the Whale Optimization Algorithm (WOA) with Particle Swarm Optimization (PSO), is used in the second stage. The objective function in the above wrapper model is based on a tri-objective principle. It uses the Pareto front technique to discover the optimal set of features. Here in the wrapper model, a novel selection strategy has been introduced to select the whale instead of the random whale. The proposed work is evaluated on four popular benchmark text corpora, of which two are binary class, and two are multi-class. The suggested FS technique is compared against classic Machine Learning (ML) and deep learning classifiers. The results of the experiments reveal that the recommended FS technique is more effective in obtaining better results than the other results.},
  archive      = {J_NCA},
  author       = {Dhal, Pradip and Azad, Chandrashekhar},
  doi          = {10.1007/s00521-023-09225-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3525-3553},
  shortjournal = {Neural Comput. Appl.},
  title        = {A fine-tuning deep learning with multi-objective-based feature selection approach for the classification of text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel adaptive neural network-based laplacian of gaussian
(AnLoG) classification algorithm for detecting diabetic retinopathy with
colour retinal fundus images. <em>NCA</em>, <em>36</em>(7), 3513–3524.
(<a href="https://doi.org/10.1007/s00521-023-09324-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a human eye disease in which the eye’s retina is damaged in diabetics. Diabetic retinopathy can be diagnosed by manually interpreting retinal fundus images, even though that takes longer to diagnose. Among these, the most challenging task in diagnosing the DR disease is edge detection in retinal fundus images to identify the region of infection and its severity. This paper aims to use the adaptive neural network-based Laplacian of Gaussian (AnLoG) classification algorithm on features extracted from diverse retinal fundus images to improve DR disease diagnostic accuracy and reduce training time. Based on the retinal fundus image in the Messidor dataset, the consequence of the proposed AnLoG classification algorithm for detecting diabetic retinopathy is compared to traditional supervised BPN machine learning algorithms and other contemporary techniques. AnLoG has proved its supremacy in terms of accuracy (97.29%), recall (94.64%), precision (93.13%), and F-Score (93.80%). Simulation results show that the proposed technique performs well compared to the existing approach.},
  archive      = {J_NCA},
  author       = {Ramasamy, Manjula Devi and Periasamy, Keerthika and Periasamy, Suresh and Muthusamy, Suresh and Ramamoorthi, Ponarun and Thangavel, Gunasekaran and Sekaran, Sreejith and Sadasivuni, Kishor Kumar and Geetha, Mithra},
  doi          = {10.1007/s00521-023-09324-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3513-3524},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel adaptive neural network-based laplacian of gaussian (AnLoG) classification algorithm for detecting diabetic retinopathy with colour retinal fundus images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WalkFormer: 3D mesh analysis via transformer on random walk.
<em>NCA</em>, <em>36</em>(7), 3499–3511. (<a
href="https://doi.org/10.1007/s00521-023-09279-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A 3D mesh is a popular representation of 3D shapes. For mesh analysis tasks, one typical method is to map 3D mesh data into 1D sequence data with random walk sampling. However, existing random walk-based approaches cannot make full use of attentive regions, which limits the capability of 3D shape analysis. In addition, existing methods process the random walk as sequence data in the discovery order, which results in computational overhead. In this paper, we propose a novel neural framework named WalkFormer, which applies a transformer to a random walk to fully exploit semantic information in a 3D mesh. First, we propose a novel transformer-based framework to learn semantic information from a random walk of a 3D mesh. Second, to capture the attentive regions of the random walk, our approach extends the multi-head self-attention mechanism to specific 3D mesh analysis tasks. To establish the long-range interactions between vertices in the random walk, our approach adopts a novel relative position encoding module. Thus, the local–global information in the random walk can be obtained and learned in our approach. Third, we discover that for 3D mesh analysis, the sequential operations for the random walk sequence are redundant. Different from previous random walk methods, our approach can be executed in a parallelized manner, which greatly improves computational efficiency. Numerous experiments demonstrate the effectiveness of the proposed method on typical 3D shape analysis tasks.},
  archive      = {J_NCA},
  author       = {Guo, Qing and He, Fazhi and Fan, Bo and Song, Yupeng and Dai, Jicheng and Fan, Linkun},
  doi          = {10.1007/s00521-023-09279-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3499-3511},
  shortjournal = {Neural Comput. Appl.},
  title        = {WalkFormer: 3D mesh analysis via transformer on random walk},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three intelligent computational models to predict the
high-performance concrete mixture. <em>NCA</em>, <em>36</em>(7),
3479–3498. (<a
href="https://doi.org/10.1007/s00521-023-09233-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual calculation of the compressive strength of concrete (CSC) is an expensive and time-consuming process. Soft computing methods outperform the statistical methods used to resolve these problems. Nonetheless, complicated prediction models are still incomplete and require more exploration. Artificial neural networks (ANNs) provide a better and faster technique featuring solitary hidden layers and have improved the generalization capacity. The present paper presents three ANN-based (shuffled complex evolution, evaporation rate based water cycle algorithm (ERWCA), and Cuckoo optimization algorithm) prediction models to anticipate the compressive strength of concrete efficiently. An available database from the UCI repository is employed to develop and access the model performance. A comparison is made between the prediction accuracies of the above three techniques. Using all models, a comparative investigation has been conducted to predict the compressive strength of concrete at the curing ages of 91, 56, and 28 days. The experimental findings obtained from the ERWCA-MLP method indicate its capability of robust CSC prediction. On average, this method achieves the minimum RMSE of 0.55314 and 0.43329 and R2 of 0.99803 and 0.99824. The statistical significance test and the comparative analysis of simulation results indicate the superiority of ERWCA-MLP in predicting the compressive strength of concrete.},
  archive      = {J_NCA},
  author       = {Moayedi, Hossein and Foong, Loke Kok and Le, Binh Nguyen},
  doi          = {10.1007/s00521-023-09233-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3479-3498},
  shortjournal = {Neural Comput. Appl.},
  title        = {Three intelligent computational models to predict the high-performance concrete mixture},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Panini: A transformer-based grammatical error correction
method for bangla. <em>NCA</em>, <em>36</em>(7), 3463–3477. (<a
href="https://doi.org/10.1007/s00521-023-09211-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the Bangla grammatical error correction task is to spontaneously identify and correct syntactic, morphological, semantic, and punctuation mistakes in written Bangla text using computational models, ultimately enhancing language precision and eloquence. The significance of the task encompasses bolstering linguistic acumen, fostering efficacious communication, and ensuring utmost lucidity and meticulousness in written expression, thereby mitigating the potential for obfuscation or dissemination of fallacious connotations. Prior endeavors have centered around surmounting the constraints inherent in rule-based and statistical methods through the exploration of machine learning and deep learning methods, aiming to enhance accuracy by apprehending intricate linguistic patterns, comprehending contextual cues, and discerning semantic nuances. In this study, we address the absence of a baseline for the task by developing a large-scale parallel corpus comprising 7.7M source-target pairs and exploring the untapped potential of transformers. Alongside the corpus, we introduce a Vaswani-style efficient monolingual transformer-based method named Bangla grammatical error corrector, Panini by leveraging transfer learning, which has become the state-of-the-art method for the task by surpassing the performance of both BanglaT5 and T5-Small by 18.81% and 23.8% of accuracy scores, and 11.5 and 15.6 of SacreBLEU scores, respectively. The empirical findings of the method substantiate its superiority over other approaches when it comes to capturing intricate linguistic rules and patterns. Moreover, the efficacy of our proposed method has been compared with the Bangla paraphrase task, showcasing its superior capability by outperforming the previous state-of-the-art method for the task as well. The BanglaGEC corpus and Panini, along with the baselines of BGEC and the Bangla paraphrase task, have been made publicly accessible at https://tinyurl.com/BanglaGEC .},
  archive      = {J_NCA},
  author       = {Hossain, Nahid and Bijoy, Mehedi Hasan and Islam, Salekul and Shatabda, Swakkhar},
  doi          = {10.1007/s00521-023-09211-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3463-3477},
  shortjournal = {Neural Comput. Appl.},
  title        = {Panini: A transformer-based grammatical error correction method for bangla},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised object detection based on single-stage
detector for thighbone fracture localization. <em>NCA</em>,
<em>36</em>(7), 3447–3461. (<a
href="https://doi.org/10.1007/s00521-023-09277-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The thighbone is the largest bone supporting the lower body. If the thighbone fracture is not treated in time, it will lead to lifelong inability to walk. Correct diagnosis of thighbone disease is very important in orthopedic medicine. Deep learning is promoting the development of fracture detection technology. However, the existing computer-aided diagnosis methods rely on a large number of manually labeled data, and labeling these data costs a lot of time and energy. Therefore, we develop an object detection method with limited labeled image quantity and apply it to the thighbone fracture localization. In this work, we build a semi-supervised object detection framework based on single-stage detector, which includes three modules: adaptive difficult sample oriented (ADSO) module, Fusion Box and deformable expand encoder (Dex encoder). ADSO module takes the classification score as the label reliability evaluation criterion by weighting, Fusion Box is designed to merge similar pseudo boxes into a reliable box for box regression and Dex encoder is proposed to enhance the adaptability of image augmentation. The experiment is conducted on the thighbone fracture dataset, which includes 3484 training thighbone fracture images and 358 testing thighbone fracture images. The experimental results show that the proposed method achieves the state-of-the-art AP in thighbone fracture detection at different labeled data rates, i.e., 1%, 5% and 10%. Besides, we use full data to achieve knowledge distillation, our method achieves 86.2% AP50 and 52.6% AP75. Finally, the effectiveness of our method has also been evaluated using the publicly available datasets COCO and VOC.},
  archive      = {J_NCA},
  author       = {Wei, Jinman and Yao, Jinkun and Zhang, Guoshan and Guan, Bin and Zhang, Yueming and Wang, Shaoquan},
  doi          = {10.1007/s00521-023-09277-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3447-3461},
  shortjournal = {Neural Comput. Appl.},
  title        = {Semi-supervised object detection based on single-stage detector for thighbone fracture localization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic interactive refinement network for camouflaged
object detection. <em>NCA</em>, <em>36</em>(7), 3433–3446. (<a
href="https://doi.org/10.1007/s00521-023-09262-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically identifying objects similar to the surroundings is a complex and difficult task in real-world scenarios. In addition to the high intrinsic similarity between camouflaged objects and their backgrounds, these objects are usually diverse in scale and blurred in appearance. And the deceptive nature of the camouflaged objects introduces lots of noise into the features and generates inaccurate segmentation map extracted by deep learning model. We tackle these problems by proposing a novel dynamic interactive refinement network (DIRNet), which aims to make the features exploit effective details and semantics together as well as discard interference information. Specifically, we utilize bilateral interaction module (BIM) to interact with foreground and background information to conduct contextual exploration, which can capture more meaningful details and refine the confusion. Additionally, in the purpose of retaining the appropriate information and erasing noise, we design an adjacent aggregation interaction module (AAIM) to integrate the adjacent multi-level features with attention coefficients for each layer. The final results are obtained through the dynamic refinement of the BIM and AAIM. Extensive quantitative and qualitative experiments on four public benchmark datasets demonstrate that our proposed DIRNet is an effective COD framework and outperforms 14 state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Sun, Yaoqi and Ma, Lidong and Shou, Peiyao and Wen, Hongfa and Gao, YuHan and Liu, Yixiu and Yan, Chenggang and Yin, Haibing},
  doi          = {10.1007/s00521-023-09262-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3433-3446},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic interactive refinement network for camouflaged object detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-objective QoS-aware IoT service placement mechanism
using teaching learning-based optimization in the fog computing
environment. <em>NCA</em>, <em>36</em>(7), 3415–3432. (<a
href="https://doi.org/10.1007/s00521-023-09246-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The huge amount and diversity of data generated by Internet of Things (IoT) devices and the need to store and process this data led to the development of fog computing alongside cloud computing. Fog computing is a new paradigm for providing service at the edge of the network and close to end users, so that it can support real-time IoT applications. Because fog involves heterogeneous and distributed infrastructure with limited resources, so efficient resource allocation to satisfy Quality of Service (QoS) is challenging. IoT application placement mechanisms have been developed to address these issues, in which the subordinate services of these applications are mapped to fog nodes. Despite extensive research to solve the Service Placement Problem (SPP) in fog computing, efforts are still ongoing due to the importance of the issue. Hence, this paper proposes an efficient and autonomous mechanism for solving SPP using Teaching Learning-Based Optimization (TLBO) called SPP-TLBO. SPP-TLBO is a multi-objective QoS-aware algorithm that manages resources on distributed and localized fog domains. In addition to the above, we improve the performance of TLBO by configuring the evolution process with a shared parallel architecture. Besides, SPP-TLBO can save more resources to handle future requests by considering application deadlines and extracting the dynamic distribution of resources required over time. The proposed algorithm is evaluated by simulation on a synthetic fog environment. The simulation results show that SPP-TLBO improves system performance and is between 8 and 19% better efficiency compared to some advanced methods such as CSA-FSPP, FSP-ODMA and, WOA-FSP.},
  archive      = {J_NCA},
  author       = {Sha, Yan and Wang, Hui and Wang, Dan and Ghobaei-Arani, Mostafa},
  doi          = {10.1007/s00521-023-09246-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3415-3432},
  shortjournal = {Neural Comput. Appl.},
  title        = {A multi-objective QoS-aware IoT service placement mechanism using teaching learning-based optimization in the fog computing environment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancement of GWO for solving numerical functions and
engineering problems. <em>NCA</em>, <em>36</em>(7), 3405–3413. (<a
href="https://doi.org/10.1007/s00521-023-09292-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to using nature-inspired metaheuristic algorithms to solve real-world applications in different fields, this area has become very popular among researchers because of the flexibility of using optimization algorithms. Therefore, these algorithms can be measured based on their operator, diversity of populations, and balancing between the exploration and exploitation phases. The Grey Wolf Optimization algorithm is one of the competitive metaheuristic algorithms that was proposed in 2014. It mimics the hunting mechanism of wolves. It uses three types of wolves: alpha, beta, and delta for searching in the search space. Despite having competitive performance, GWO has problems regarding local optima and has low exploration. Therefore, enhancement GWO (EGWO) is proposed in this paper in order to solve these problems. EGWO used different methods to improve the performance of GWO: using gamma, z-position, and golden ratio. MGWO is evaluated using CEC2019 ten benchmark functions. Statistical results proved that EGWO outperforms well in six functions out of ten compared to GWO, fitness-dependent optimizer (FDO), cat swarm optimizer, and FOX optimizer. It is also used to solve two real-world applications such as pressure vessel design and 10-bar truss design problems. Results showed that EGWO is very competitive against GWO, FDO, and FOX.},
  archive      = {J_NCA},
  author       = {Mohammed, Hardi and Abdul, Zrar and Hamad, Zana},
  doi          = {10.1007/s00521-023-09292-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3405-3413},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancement of GWO for solving numerical functions and engineering problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speeding up pattern matching in streaming time-series via
block vector and multilevel lower bound. <em>NCA</em>, <em>36</em>(7),
3389–3403. (<a
href="https://doi.org/10.1007/s00521-023-09291-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pattern matching is one of the essential tasks in streaming time-series data mining. Its purpose is to identify all sliding windows in streaming time-series whose Euclidean Distances with predefined patterns are smaller than a threshold pre-determined. The pattern can be high-dimensional data and the streaming time-series is frequently updated. Thus, the brute-force method, which involves calculating Euclidean Distances between each sliding window and all patterns, is not effective in practical applications. This paper develops a lower bound-basedmethod that can perform pattern matching in less time while guaranteeing the same results as brute-force method. The proposed method achieves speedup without any sacrifice in matching accuracy. The block vector is utilized to calculate the lower bound of Euclidean Distance. Our proposal can safely eliminate many expensive Euclidean Distance calculations between patterns and sliding window; thus, the efficiency of pattern matching can be improved. Besides, we present an approach that can obtain the block vectors on-the-fly in the streaming scenarios to improve efficiency further. The experimental study in synthetic and real-life data sets verifies the efficiency and advantage of the proposals over the state-of-the-art.},
  archive      = {J_NCA},
  author       = {Zhang, Haowen and Li, Jing},
  doi          = {10.1007/s00521-023-09291-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3389-3403},
  shortjournal = {Neural Comput. Appl.},
  title        = {Speeding up pattern matching in streaming time-series via block vector and multilevel lower bound},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). One-class graph moderating attention neural network in
quality assessment of creative ideas. <em>NCA</em>, <em>36</em>(7),
3369–3388. (<a
href="https://doi.org/10.1007/s00521-023-09256-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification and implementation of high-quality ideas have been hindered in the open innovation community due to information overload. Most existing studies tended to utilize the factors that influence the quality of ideas to construct the methods to assess the quality of ideas, which ignores the deeper information contained in the community system environment where the creative idea is located. This paper regards a community as a complex social system formed by user sharing and interaction from a systemic perspective. A one-class graph moderating attention neural network model (OCGMAT) is constructed to map this social network system and mine the in-depth information of the system’s impact on ideas quality, especially the moderating effect of interactive emotion. The OCGMAT model includes five layers, a mapping layer to map the network information of the social system to graph-structured data, a multi-head moderating attention layer to calculate the attention coefficient between the two neighboring nodes under the moderating effect of interactive emotion, two convolutional layers to extract the deep representation of features, a fully connected layer to classify the quality of creative ideas. The experiments for OCGMAT, GAT, GNN, and other classification-based models have been conducted on the creative ideas dataset from the Meizu open innovation community, which shows that the OCGMAT model outperforms other methods with high accuracy of 93.22%. Finally, according to the predictions, we take measures to manage creative ideas and improve innovation effectiveness.},
  archive      = {J_NCA},
  author       = {Yang, Yang},
  doi          = {10.1007/s00521-023-09256-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3369-3388},
  shortjournal = {Neural Comput. Appl.},
  title        = {One-class graph moderating attention neural network in quality assessment of creative ideas},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluate student achievement by classifying brain structure
and its functionality with novel hybrid method. <em>NCA</em>,
<em>36</em>(7), 3357–3368. (<a
href="https://doi.org/10.1007/s00521-023-09031-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a labor market that demands a workforce well-trained in science, technology, engineering, and mathematics (STEM) subjects, it is required of children to successfully develop their mathematical skills in order to become highly productive adults. Recent developments in computer vision, artificial intelligence, machine learning, and medical imaging techniques give us new opportunities for building intelligent support tools to help us learn more about the neural underpinnings of how children learn math and how that knowledge relates to individual differences in skill. This study examines the brain activities of students during problem-solving by checking brain structure and its functionality. By using powerful techniques in the light of machine learning and image processing, the relationship between success and the background of a child was researched. The aim is to make a solid prediction of the possible future success of the children by observing their brain activities. The children we investigated were asked different questions to get information about their intelligence. In our study, we have tried to find how those questions and answers may affect the future success of a child. For this purpose, a novel hybrid classification model that utilizes cluster analysis, Random Forest, Logistic Regression, and ensemble learning is intended for classification tasks. Our study includes two main stages. Firstly, the image processing techniques were applied to create unique features of brain images. Then, machine learning tecnniques were used to select a set of features, and for getting prediction results our hybrid classification model was applied. In the end, we obtained useful results indicating that there is a complicated connection between the success rate and the history of a child. This novel approach to classification, which combines multiple methods by using a hybrid model, has the potential to be implemented in computational tools for strategic decision support systems.},
  archive      = {J_NCA},
  author       = {Ataş, Pınar Karadayı},
  doi          = {10.1007/s00521-023-09031-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3357-3368},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evaluate student achievement by classifying brain structure and its functionality with novel hybrid method},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DAttNet: Monocular depth estimation network based on
attention mechanisms. <em>NCA</em>, <em>36</em>(7), 3347–3356. (<a
href="https://doi.org/10.1007/s00521-023-09210-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As autonomous vehicles get closer to our daily lives, the need for architectures that function as redundant pipelines is becoming increasingly critical. To address this issue without compromising the budget, researchers aim to avoid duplicating high-cost sensors such as LiDARs. In this work, we propose using monocular cameras, which are already essential for some modules of the autonomous platform, for 3D scene understanding. While many methods for depth estimation using single images have been proposed in the literature, they usually rely on complex neural network ensembles that extract dense feature maps, resulting in a high computational cost. Instead, we propose a novel and inherently efficient method for obtaining depth images that replace tangled neural architectures with attention mechanisms applied to basic encoder–decoder models. We evaluate our method on the KITTI public dataset and in real-world experiments on our automated vehicle. The obtained results prove the viability of our approach, which can compete with intricate state-of-the-art methods while outperforming most alternatives based on attention mechanisms.},
  archive      = {J_NCA},
  author       = {Astudillo, Armando and Barrera, Alejandro and Guindel, Carlos and Al-Kaff, Abdulla and García, Fernando},
  doi          = {10.1007/s00521-023-09210-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3347-3356},
  shortjournal = {Neural Comput. Appl.},
  title        = {DAttNet: Monocular depth estimation network based on attention mechanisms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A state-of-the-art survey of u-net in microscopic image
analysis: From simple usage to structure mortification. <em>NCA</em>,
<em>36</em>(7), 3317–3346. (<a
href="https://doi.org/10.1007/s00521-023-09284-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microscopic image analysis technology helps solve the inadvertences of artificial traditional methods in disease, wastewater treatment, and environmental change monitoring analysis. Convolutional neural network (CNN) play an important role in microscopic image analysis. Image segmentation, in which U-Net is increasingly applied in microscopic image segmentation, is a crucial step in detection, tracking, monitoring, feature extraction, modelling, and analysis. This paper comprehensively reviews the development history of U-Net, analyses several research results of various segmentation methods since the emergence of U-Net, and conducts a comprehensive review of related papers. This paper summarised the improved methods of U-Net and then listed the existing significance of image segmentation techniques and their improvements introduced over the years. Finally, focusing on the different improvement strategies of U-Net in different papers, the related work of each application target is reviewed according to detailed technical categories to facilitate future research. Researchers can see the dynamics of the transmission of technological development and keep up with future trends in this interdisciplinary field.},
  archive      = {J_NCA},
  author       = {Wu, Jian and Liu, Wanli and Li, Chen and Jiang, Tao and Shariful, Islam Mohammad and Yao, Yudong and Sun, Hongzan and Li, Xiaoqi and Li, Xintong and Huang, Xinyu and Grzegorzek, Marcin},
  doi          = {10.1007/s00521-023-09284-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3317-3346},
  shortjournal = {Neural Comput. Appl.},
  title        = {A state-of-the-art survey of U-net in microscopic image analysis: From simple usage to structure mortification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision-language navigation: A survey and taxonomy.
<em>NCA</em>, <em>36</em>(7), 3291–3316. (<a
href="https://doi.org/10.1007/s00521-023-09217-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language navigation (VLN) tasks require an agent to follow language instructions from a human guide to navigate in previously unseen environments using visual observations. This challenging field, involving problems in natural language processing (NLP), computer vision (CV), robotics, etc., has spawned many excellent works focusing on various VLN tasks. This paper provides a comprehensive survey and an insightful taxonomy of these tasks based on the different characteristics of language instructions. Depending on whether navigation instructions are given once or multiple times, we divide the tasks into two categories, i.e., single-turn and multiturn tasks. We subdivide single-turn tasks into goal-oriented and route-oriented tasks based on whether the instructions designate a single goal location or specify a sequence of multiple locations. We subdivide multiturn tasks into interactive and passive tasks based on whether the agent is allowed to ask questions. These tasks require different agent capabilities and entail various model designs. We identify the progress made on these tasks and examine the limitations of the existing VLN models and task settings. Hopefully, a well-designed taxonomy of the task family enables comparisons among different approaches across papers concerning the same tasks and clarifies the advances made in these tasks. Furthermore, we discuss several open issues in this field and some promising directions for future research, including the incorporation of knowledge into VLN models and transferring them to the real physical world.},
  archive      = {J_NCA},
  author       = {Wu, Wansen and Chang, Tao and Li, Xinmeng and Yin, Quanjun and Hu, Yue},
  doi          = {10.1007/s00521-023-09217-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3291-3316},
  shortjournal = {Neural Comput. Appl.},
  title        = {Vision-language navigation: A survey and taxonomy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Metaverse token price forecasting using artificial neural
networks (ANNs) and adaptive neural fuzzy inference system (ANFIS).
<em>NCA</em>, <em>36</em>(7), 3267–3290. (<a
href="https://doi.org/10.1007/s00521-023-09228-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study is about the metaverse environment which has recently heard a lot in life. Although many individuals and institutions are interested in metaverse, it is an imaginary future space, and the conceptual framework is not fully drawn. The metaverse is a mix of augmented, virtual, and mixed reality technologies that are predicted to affect our lives over the next decade including our money, possessions, and ownership. So, we examined to forecast metaverse token price using ANN and ANFIS methods. The market value of the five metaverse token firms: opening price, highest value, lowest value, closing price, volume value, and variables, is evaluated between October 17, 2017, and December 15, 2022, by YSA and ANFIS. The ANN method training was carried out using ten hidden layers and the Levenberg–Marquardt algorithm. In the ANFIS method, training was carried out with 100 iterations in a triple mesh structure. At the end of the method training, the training performed with the ANN method was 99.3% successful, and the ANFIS method was 99.1% successful. It is concluded that the model fitness of the R2 values of ANN and ANFIS methods is appropriate at 99.3 and 98.7%, respectively. As a result, ANN and ANFIS methods can be used for the prediction of metaverse token prices for the estimation of financial instruments. ANN and ANFIS are advanced tools for predicting metaverse token prices, with ANFIS having unique features like fuzzy logic. However, using only basic price data is not enough for precise predictions. While the EMA and SMA have less impact, gold (XAU), BTC, ETH, US dollar (USD), Chinese Yuan (CNY), and Brent oil (BRT) are observed to have a moderate impact on determining the market values of metaverse prices. The use of XAU and ETH prices in both ANN and ANFIS methods gives successful results. Especially, we have achieved favorable outcomes when employing the ANN method for analyzing EMA and BTC values. Additionally, we have obtained valuable and successful results by utilizing the ANFIS method for analyzing BRT. Using only opening, highest, lowest, closing prices, and volume values and USD, CNY, BRT, and SMA prices has not demonstrated usefulness in attaining favorable results. The findings of this research indicate that the utilization of the metaverse world has the potential to enhance learning capabilities and motivation, as well as make significant contributions to industrial production and the field of health. However, it is important to note that the existing body of research on the metaverse world remains limited in scope and depth. Users often hold preconceived notions and biases regarding ethical concerns associated with the metaverse world. Additionally, there are significant obstacles that need to be addressed in terms of fulfilling hardware requirements for its implementation.},
  archive      = {J_NCA},
  author       = {Özkal, İbrahim and Özkan, İlker Ali and Başçiftçi, Fatih},
  doi          = {10.1007/s00521-023-09228-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3267-3290},
  shortjournal = {Neural Comput. Appl.},
  title        = {Metaverse token price forecasting using artificial neural networks (ANNs) and adaptive neural fuzzy inference system (ANFIS)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing gas formation theory assessment in power
transformers by using decision tree transparency and new guess into
decomposition temperatures of insulating mineral oil. <em>NCA</em>,
<em>36</em>(7), 3259–3266. (<a
href="https://doi.org/10.1007/s00521-023-09216-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of gases dissolved in oil is the main technique used to predict possible failures in power transformers. Currently, there are some assessment algorithms for the predictive analysis, but all of them have in common the fact that they are based on the classical gas formation theory. This work aims to analyze the use of decision trees (DTs) for the analysis of gases dissolved in mineral oil, also establishing a relationship associated with decision making during the formation of trees and the formation of gases. In this way, some important aspects involving the insulating mineral oil can be better understood and quantified. For this purpose, one dataset containing 201 samples is used in the study. The results provided by the tree are arranged in a Cartesian plane, and the gases are analyzed based on the ratios used by Doernenburg. DT is discussed in detail to validate the algorithm performance based on the classical gas formation theory.},
  archive      = {J_NCA},
  author       = {Araujo, Mateus M. and Almeida, Otacilio M. and Barbosa, Fabio R. and Menezes, Abraão G. C.},
  doi          = {10.1007/s00521-023-09216-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {3259-3266},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing gas formation theory assessment in power transformers by using decision tree transparency and new guess into decomposition temperatures of insulating mineral oil},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing anomaly-based attack detection using
classification machine learning. <em>NCA</em>, <em>36</em>(6),
3239–3257. (<a
href="https://doi.org/10.1007/s00521-023-09309-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the significant aspects of our digital world is that data are literally everywhere, and it is increasing. On the other hand, the number of cyberattacks aiming to seize this data and use it illegally is increasing at an exponential rate, and this is the challenge. Therefore, intrusion detection systems (IDS) have attracted considerable interest from researchers and industries. In this regard, machine learning (ML) techniques are playing a pivotal role as they put the responsibility of analyzing enormous amounts of data, finding patterns, classifying intrusions, and solving issues on computers instead of humans. This paper implements two separate classification layers of ML-based algorithms with the recently published NF-UQ-NIDS-v2 dataset, preprocessing two volumes of sample records (100 k and 10 million), utilizing MinMaxScaler, LabelEncoder, selecting superlative features by recursive feature elimination, normalizing the data, and optimizing hyper-parameters for classical algorithms and neural networks. With a small dataset volume, the results of the classical algorithms layer show high detection accuracy rates for support vector (98.26%), decision tree (98.78%), random forest (99.07%), K-nearest neighbors (98.16%), CatBoost (99.04%), and gradient boosting (98.80%). In addition, the layer of neural network algorithms has proven to be a very powerful technology when using deep learning, particularly due to its unique ability to effectively handle enormous amounts of data and detect hidden correlations and patterns; it showed high detection results, which were (98.87%) for long short-term memory and (98.56%) for convolutional neural networks.},
  archive      = {J_NCA},
  author       = {Gouda, Hany Abdelghany and Ahmed, Mohamed Abdelslam and Roushdy, Mohamed Ismail},
  doi          = {10.1007/s00521-023-09309-y},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3239-3257},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing anomaly-based attack detection using classification machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic-efficient fine-tuning with layer pruning on
multimodal covid-19 medical imaging. <em>NCA</em>, <em>36</em>(6),
3215–3237. (<a
href="https://doi.org/10.1007/s00521-023-09194-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image analysis using multiple modalities refers to the process of analyzing and extracting information from more than one type of image in order to gain a comprehensive understanding of a given subject. To maximize the potential of multimodal data in improving and enhancing our understanding of the disease, sophisticated classification techniques must be developed as part of the integration process to classify meaningful information from different types of data. A pre-trained model, such as those trained on large datasets such as ImageNet, has learned rich representations that can be used for various downstream tasks. Fine-tuning a pre-trained model refers to the process of further developing the model using the knowledge and representations gained from a pre-existing dataset. In comparison to training a model from scratch, fine-tuning allows knowledge to be transferred from the pre-trained model to the target task, thus improving performance and efficiency. In evolutionary search, the genetic algorithm (GA) is an algorithm that emulates the process of natural selection and genetics. In this context, a population of candidate solutions is generated, fitness is evaluated and new candidate solutions are generated by applying genetic operations such as mutation and crossover. Considering the above characteristics, the present study presents an efficient architecture called Selective-COVIDNet for analyzing COVID-19 cases using a novel selective layer-pruning algorithm. To detect COVID-19 from multimodal data, the current study will use a genetic algorithm to fine-tune the performance of pre-trained models by adjusting specific layers selectively. Furthermore, the proposed approach provides flexibility in the depth of two deep learning architectures, VGG-16 and MobileNet-V2. The impact of freezing specific layers on fine-tuning performance was assessed using five different strategies, namely Random, Odd, Even, Half, and Full Freezing. Therefore, existing pre-trained models can be enhanced for Covid-19 tasks while minimizing their computational burden. For evaluating the effectiveness of the proposed framework, two multi-modal standard datasets are used, including CT-scan images and electrocardiogram (ECG) recordings of individuals with COVID-19. From the conducted experiments, it is found that the proposed framework can detect Covid-19 effectively with accuracy of 98.48% for MobileNet-V2 and 99.65% for VGG-16.},
  archive      = {J_NCA},
  author       = {Ismail, Walaa N. and Alsalamah, Hessah A. and Mohamed, Ebtsam A.},
  doi          = {10.1007/s00521-023-09194-5},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3215-3237},
  shortjournal = {Neural Comput. Appl.},
  title        = {Genetic-efficient fine-tuning with layer pruning on multimodal covid-19 medical imaging},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of calcareous algae under noisy labels.
<em>NCA</em>, <em>36</em>(6), 3197–3214. (<a
href="https://doi.org/10.1007/s00521-023-09235-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calcareous algae are an important marine ecosystem that is under threat due to global warming and local stressors like oil and gas offshore. Under this condition, an important Brazilian oil and gas company started to monitor that environment. To carry out this monitoring, a deep learning classifier was proposed. However, the elaborated dataset presented noisy labels. Noisy labels mean that some dataset samples are mislabeled, and it degenerates the robustness of the model. State-of-the-art models to deal with it use small loss technique. This technique excludes from the training set noisy labels and keeps the cleans. The state-of-the-art models apply different techniques on the set of clean samples to improve their performance. We introduce in this work a novel framework to deal with noise, that can improve “small loss” models’ performance, named retrieving discard samples (RDS), that under ideal conditions is equivalent to training without any noise. The main idea of this method is to retrieve the discarded samples, add a pseudo-label to the excluded samples and return them to the training stage. This paper demonstrates the adaptability of the framework RDS to other models utilizing the small loss approach. Furthermore, two novel models are proposed to effectively handle noisy labels. Results show that RDS significantly improves the accuracy of both models, achieving superior results than the state-of-the-art approaches. We also developed a deep learning model for calcareous algae environmental monitoring based in RDS approach that improved the performance of F’-Score in 4.2% when compared to standard deep learning classifiers.},
  archive      = {J_NCA},
  author       = {Bento, Vitor and Kohler, Manoela and Pacheco, Marco Aurelio},
  doi          = {10.1007/s00521-023-09235-z},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3197-3214},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of calcareous algae under noisy labels},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SwinDTI: Swin transformer-based generalized fast estimation
of diffusion tensor parameters from sparse data. <em>NCA</em>,
<em>36</em>(6), 3179–3196. (<a
href="https://doi.org/10.1007/s00521-023-09206-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion tensor imaging (DTI) is a non-invasive technique for analyzing the movement of water in the brain. However, the precision of measurements required for tracking white matter pathways can lead to long scan times, which can be challenging for some patient populations such as pediatric patients. To address this issue, researchers have been experimenting with deep learning techniques for faster estimation of DTI parameters, which are helpful in neurological diagnosis, of diffusion-weighted images. Our proposed solution is a transformer neural network-based approach for fast estimation of diffusion tensor parameters using sparse measurements. While there have been attempts to address this problem, our proposed model handles both scalable and generalized estimation of DTI parameters using multiple sparse measurements. Through experimentation on the Human Connectome Project (HCP) Young Adult benchmark dataset, our proposed model demonstrated state-of-the-art results in terms of fractional anisotropy (FA), axial diffusivity (AD), and mean diffusivity (MD) when compared to traditional linear least square (LLS) fitting and 3D U-Net model with $$16 \times 16 \times 16$$ input size (3D U-Net16).},
  archive      = {J_NCA},
  author       = {Tiwari, Abhishek and Singh, Rajeev Kumar and Shigwan, Saurabh J.},
  doi          = {10.1007/s00521-023-09206-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3179-3196},
  shortjournal = {Neural Comput. Appl.},
  title        = {SwinDTI: Swin transformer-based generalized fast estimation of diffusion tensor parameters from sparse data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HFE-net: Hierarchical feature extraction and coordinate
conversion of point cloud for object 6D pose estimation. <em>NCA</em>,
<em>36</em>(6), 3167–3178. (<a
href="https://doi.org/10.1007/s00521-023-09241-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current challenging problems of learning a robust 6D pose lie in noise in RGB/RGBD images, sparsity of point cloud and severe occlusion. To tackle the problems, object geometric information is critical. In this work, we present a novel pipeline for 6DoF object pose estimation. Unlike previous methods that directly regressing pose parameters and predicting keypoints, we tackle this challenging task with a point-pair based approach and leverage geometric information as much as possible. Specifically, at the representation learning stage, we build a point cloud network locally modeling CNN to encode point cloud, which is able to extract effective geometric features while the point cloud is projected into a high-dimensional space. Moreover, we design a coordinate conversion network to regress point cloud in the object coordinate system in a decoded way. Then, the pose could be calculated through point pairs matching algorithm. Experimental results show that our method achieves state-of-the-art performance on several datasets.},
  archive      = {J_NCA},
  author       = {Shen, Ze and Chu, Hao and Wang, Fei and Guo, Yi and Liu, Shangdong and Han, Shuai},
  doi          = {10.1007/s00521-023-09241-1},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3167-3178},
  shortjournal = {Neural Comput. Appl.},
  title        = {HFE-net: Hierarchical feature extraction and coordinate conversion of point cloud for object 6D pose estimation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved tasmanian devil optimization algorithm for
parameter identification of electric transformers. <em>NCA</em>,
<em>36</em>(6), 3141–3166. (<a
href="https://doi.org/10.1007/s00521-023-09240-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tasmanian devil optimization (TDO) algorithm represents one of the most recent optimization algorithms that were introduced based on the nature behavior of Tasmanian devil behavior. However, as a recent optimizer, its performance may provide inadequate balance among the exploitation and exploration abilities, especially when dealing with the multimodal and high-dimensional natures of optimization tasks. To overcome this shortage, a novel variant of the TDO, called improved Tasmanian devil optimization (ITDO), is introduced in this paper. In ITDO, two competitive strategies are embedded into TDO to enrich the scope of the searching capability with the aim of improving the diversification and identification of the algorithm. The effectiveness of the ITDO algorithm is examined by validating its performance on CEC 2020 benchmark functions with different landscape natures. The recorded results proved that the ITDO is very competitive with other counterparts. After ITDO exhibited a sufficient performance, then, it was applied to estimate the parameters of the 1 kVA, 230/230 V, single-phase transformer. Some assessment metrics along with convergence analysis are conducted to affirm the performance of the proposed algorithm. The recorded results confirm the competitive performance of the proposed method in comparison with the other optimization methods for the benchmark functions and can identify the accurate parameters for the single-phase transformer as the estimated parameters by ITDO are highly coincident with the experimental parameters.},
  archive      = {J_NCA},
  author       = {Rizk-Allah, Rizk M. and El-Sehiemy, Ragab A. and Abdelwanis, Mohamed I.},
  doi          = {10.1007/s00521-023-09240-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3141-3166},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improved tasmanian devil optimization algorithm for parameter identification of electric transformers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural networks as an approximator for a family of
optimization algorithm solutions for online applications. <em>NCA</em>,
<em>36</em>(6), 3125–3140. (<a
href="https://doi.org/10.1007/s00521-023-09203-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a sufficient condition at which a neural network can approximate a set of optimization algorithm solutions; we establish under which conditions a neural network can replace an optimization algorithm to solve a problem with the objective of safely deploying that network in a system where online solutions are necessary to simplify the hardware or allowing the processor to solve the optimization problem on time. To that end, first, we define the family of optimization problems to be addressed; then, we construct a vector with the parameters on which the solution depends, in order to propose a function based on the first-order Karush–Kuhn–Tucker conditions to find conditions under which the inverse of the proposed function maps the problem minimizer with respect to the constructed vector, we provide the sufficiency proof of, both, existence and feasibility of approximation by a neural network regarding the inverse function. Two case studies are proposed, one numerical case showing how a neural network can solve an optimization problem faster than popular solvers to illustrate how it can be implemented in applications where the computation time is tight, and the other case is a Model Predictive Control implementation with the optimization problem solver replaced by a neural network which allows a hardware downgrade; both cases are presented with time statistics comparisons.},
  archive      = {J_NCA},
  author       = {López-Rojas, Arturo D. and Cruz-Villar, Carlos A.},
  doi          = {10.1007/s00521-023-09203-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3125-3140},
  shortjournal = {Neural Comput. Appl.},
  title        = {Neural networks as an approximator for a family of optimization algorithm solutions for online applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence-based camel face identification
system for sustainable livestock farming. <em>NCA</em>, <em>36</em>(6),
3107–3124. (<a
href="https://doi.org/10.1007/s00521-023-09238-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence and machine learning have recently been applied to improve agricultural and livestock applications. The precise estimation, recommendations, and performances are the main justifications for using technology. The knowledge that can be gained from animal detection and tracking in videos is useful for monitoring body condition, calving processes, behavior analysis, and individual identification. Accurate animal identification is necessary for monitoring animal welfare, disease prevention, vaccination administration, production supply, and ownership management. In this study, a deep learning-based camera tracking system has been built for businesses where animal welfare is a priority. For this purpose, images of camels in their natural habitat were taken in order to create a dataset. The dataset was split into three categories: training, validation, and testing. It contains 19,081 records from 18 different camels. To identify specific camel faces, this study used deep learning algorithms. The EfficientNetV2B0 algorithm had the highest test accuracy, scoring 98.85% with a validation accuracy of 98.53%. The AI for the camel face recognition task has been validated. The usability of AI on the camel face recognition task was successful in terms of recognition accuracy, and it can be used in place of conventional methods.},
  archive      = {J_NCA},
  author       = {Gerdan Koc, Dilara and Koc, Caner and Polat, Havva Eylem and Koc, Atakan},
  doi          = {10.1007/s00521-023-09238-w},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3107-3124},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial intelligence-based camel face identification system for sustainable livestock farming},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence tools and a diagrammatic scale for
evaluating the quality of coating in treated soybean seeds.
<em>NCA</em>, <em>36</em>(6), 3101–3106. (<a
href="https://doi.org/10.1007/s00521-023-09182-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image analysis combined with artificial intelligence has enabled efficient evaluation of the quality of seed lots during the production process. In the treatment stage, the evaluation of seed coverage is performed by visual analysis, which is considered subjective and of low standard. With the aim of helping producers and those responsible for treatment in classifying the coating of soybean seeds, the objective of this research was to investigate the efficiency of artificial intelligence tools for analyzing the quality of coating of soybean seeds submitted to chemical treatment and develop a diagrammatic scale for the standardization of the evaluation for this characteristic. To obtain the different levels of coating, excellent, good, medium and poor, images were captured and processed using the GroundEye® system, version S800, of samples of industrially treated soybean seeds (TSI) and treated on the farm (on-farm). The quantification of seed coverage was performed by adding the percentages of the red and pink color dominance characteristics detected in the seeds. Subsequently, artificial intelligence tools, classifiers and a decision network were used to help classify the coating quality. From the results obtained and considering the maximum and minimum values of quantification of the coating observed in the image bank obtained from the samples, a diagrammatic scale was established for the visual evaluation of the quantity and quality of the coating of the seeds with the chemical treatment. The use of artificial intelligence tools was efficient for evaluating the quality of soybean seed coatings.},
  archive      = {J_NCA},
  author       = {de Andrade, Dayliane Bernardes and Carvalho, Everson Reis and Pires, Raquel Maria de Oliveira and Rocha, Debora Kelli and Pereira, Wilson Vicente Souza and Von Pinho, Édila Vilela de Resende},
  doi          = {10.1007/s00521-023-09182-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3101-3106},
  shortjournal = {Neural Comput. Appl.},
  title        = {Artificial intelligence tools and a diagrammatic scale for evaluating the quality of coating in treated soybean seeds},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Passion-net: A robust precise and explainable predictor for
hate speech detection in roman urdu text. <em>NCA</em>, <em>36</em>(6),
3077–3100. (<a
href="https://doi.org/10.1007/s00521-023-09169-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an aim to eliminate or reduce the spread of hate content across social media platforms, the development of artificial intelligence supported computational predictors is an active area of research. However, diversity of languages hinders development of generic predictors that can precisely identify hate content. Several language-specific hate speech detection predictors have been developed for most common languages including English, Chinese and German. Specifically, for Urdu language a few predictors have been developed and these predictors lack in predictive performance. The paper in hand presents a precise and explainable deep learning predictor which makes use of advanced language modelling strategies for the extraction of semantic and discriminative patterns. Extracted patterns are utilized to train an attention-based novel classifier that is competent in precisely identifying hate content. Over coarse-grained benchmark dataset, the proposed predictor significantly outperforms state-of-the-art predictor by 8.7% in terms of accuracy, precision and F1-score. Similarly, over fine-grained dataset, in comparison with state-of-the-art predictor, it achieves performance gain of 10.6%, 17.6%, 18.6% and 17.6% in terms of accuracy, precision, recall and F1-score.},
  archive      = {J_NCA},
  author       = {Mehmood, Faiza and Ghafoor, Hina and Asim, Muhammad Nabeel and Ghani, Muhammad Usman and Mahmood, Waqar and Dengel, Andreas},
  doi          = {10.1007/s00521-023-09169-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3077-3100},
  shortjournal = {Neural Comput. Appl.},
  title        = {Passion-net: A robust precise and explainable predictor for hate speech detection in roman urdu text},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speaker age and gender recognition using 1D and 2D
convolutional neural networks. <em>NCA</em>, <em>36</em>(6), 3065–3075.
(<a href="https://doi.org/10.1007/s00521-023-09153-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The speech signal is one of the most effective data sources used in human–computer interaction and is widely used in many applications such as speech/speaker recognition, emotion recognition, language recognition, and age and gender recognition. In this study, two convolutional neural networks, 1D and 2D, are designed to recognize the age and gender class of the speaker. These models are created by stacking four feature learning blocks (FLBs) and one classification block. Two different feature vectors are used in their inputs, which are formed with mel-frequency cepstrum coefficients. Each FLB consists of a convolution layer, a batch normalization layer, a ReLU layer, a max pooling layer, and a dropout layer, while the classification block consists of a flatten layer, two fully connected layers, and a softmax layer. In the study, besides the parameter optimization made by manual search method, model optimization is also carried out by trying different combinations of the basic components that make up the FLBs. In the experiments with the Common Voice Turkish dataset, the highest validation accuracy is obtained as 66.26% for the 1D model and 94.40% for the 2D model. These results reveal the effectiveness of the proposed 2D model in age and gender recognition.},
  archive      = {J_NCA},
  author       = {Yücesoy, Ergün},
  doi          = {10.1007/s00521-023-09153-0},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3065-3075},
  shortjournal = {Neural Comput. Appl.},
  title        = {Speaker age and gender recognition using 1D and 2D convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). N-IoU: Better IoU-based bounding box regression loss for
object detection. <em>NCA</em>, <em>36</em>(6), 3049–3063. (<a
href="https://doi.org/10.1007/s00521-023-09133-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is one of the core tasks of computer vision, and bounding box (bbox) regression is one of the basic tasks of object detection. In recent years of related research, bbox regression is often used in the Intersection over Union (IoU) loss and its improved version. In this paper, for the first time, we introduce the Dice coefficient into the regression loss calculation and propose a new measure which is superior to and can replace the IoU. We define three properties of the new measure and prove the theory by mathematical reasoning and analysis of the existing work. This paper also proposes the N-IoU regression loss family. And the superiority of the N-IoU regression loss family is proved by designing simulation experiments and comparative experiments. The main results of this paper are: (1) The proposed new measure is better than IoU which can be used to evaluate bounding box regression, and the three properties of the new measure can be used as a broad criterion for the design of regression loss functions; and (2) we propose N-IoU loss. The parameter n of N-IOU can be debugged, which can be widely adapted to different application scenarios with higher flexibility, and the regression performance is better.},
  archive      = {J_NCA},
  author       = {Su, Keke and Cao, Lihua and Zhao, Botong and Li, Ning and Wu, Di and Han, Xiyu},
  doi          = {10.1007/s00521-023-09133-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3049-3063},
  shortjournal = {Neural Comput. Appl.},
  title        = {N-IoU: Better IoU-based bounding box regression loss for object detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predefined-time fuzzy adaptive output feedback control for
non-strict feedback stochastic nonlinear systems with state constraints.
<em>NCA</em>, <em>36</em>(6), 3037–3048. (<a
href="https://doi.org/10.1007/s00521-023-09123-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predefined-time fuzzy adaptive output feedback control problem is considered for non-strict feedback stochastic nonlinear systems with state constraints. Since the controlled plant contains unknown nonlinear dynamics and unmeasured states, the unknown nonlinear dynamics are handled by using fuzzy approximation technique, and a fuzzy state observer is established to estimate unmeasured states. Then, under the frameworks of a predefined-time stability theory and backstepping control design technique, a new fuzzy adaptive output feedback control method is proposed. It is proved that the controlled system is semi-global practically predefined-time stable in probability by constructing suitable barrier Lyapunov functions. Finally, the spring–mass–damper system is given to confirm the effectiveness of the presented control method.},
  archive      = {J_NCA},
  author       = {Cui, Mengyuan and Tong, Shaocheng},
  doi          = {10.1007/s00521-023-09123-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3037-3048},
  shortjournal = {Neural Comput. Appl.},
  title        = {Predefined-time fuzzy adaptive output feedback control for non-strict feedback stochastic nonlinear systems with state constraints},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic detection of breast cancer for mastectomy based on
MRI images using mask r-CNN and detectron2 models. <em>NCA</em>,
<em>36</em>(6), 3017–3035. (<a
href="https://doi.org/10.1007/s00521-023-09237-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast tumor diagnosis has seen widespread use of computer-aided techniques. Machine learning techniques can benefit doctors in making diagnosis decisions. One of the most important treatments for breast cancer is neoadjuvant chemotherapy (NAC). The reason is that NAC before surgery can downstage breast cancer and reduce local surgery. The problem of MRI, in brief, is how to distinguish between the types of pre-NAC and post-NAC, especially between the kinds of post-NAC. This study presents creating a system that goes through five stages: the input dataset, comparing normal and abnormal using EfficientNetV2L, determining the difference between malignant (pre- or post-NAC) and benign by utilizing a mask region-based convolutional neural network (R-CNN), comparing the types of post-NAC by using Detectron2, and finally the multidisciplinary team (MDT). Thus, it is decided if the breast needs a mastectomy or wide local excision (WLE) using Detectron2 with Faster R-CNN. The results showed that EfficientNetV2L achieved high accuracy, about 98%. The models successfully compared the types of post-NAC by using Detectron2 with Mask R-CNN. The study concludes that Detectron2 with Mask and Faster R-CNN is a reasonable model for detecting the type of MRI image and classifying whether the image is normal or abnormal.},
  archive      = {J_NCA},
  author       = {Salh, Chiman Haydar and Ali, Abbas M.},
  doi          = {10.1007/s00521-023-09237-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {3017-3035},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic detection of breast cancer for mastectomy based on MRI images using mask R-CNN and detectron2 models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating graph embedding and neural models for improving
transition-based dependency parsing. <em>NCA</em>, <em>36</em>(6),
2999–3016. (<a
href="https://doi.org/10.1007/s00521-023-09223-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an effective method for improving dependency parsing which is based on a graph embedding model. The model helps extract local and global connectivity patterns between tokens. This method allows neural network models to perform better on dependency parsing benchmarks. We propose to incorporate node embeddings trained by a graph embedding algorithm into a bidirectional recurrent neural network scheme. The new model outperforms a baseline reference using a state-of-the-art method on three dependency treebanks for both low-resource and high-resource natural languages, namely Indonesian, Vietnamese and English. We also show that the popular pretraining technique of BERT would not pick up on the same kind of signal as graph embeddings. The new parser together with all trained models is made available under an open-source license, facilitating community engagement and advancement of natural language processing research for two low-resource languages with around 300 million users worldwide in total.},
  archive      = {J_NCA},
  author       = {Le-Hong, Phuong and Cambria, Erik},
  doi          = {10.1007/s00521-023-09223-3},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2999-3016},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrating graph embedding and neural models for improving transition-based dependency parsing},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating bias through random activation function
selection. <em>NCA</em>, <em>36</em>(6), 2983–2998. (<a
href="https://doi.org/10.1007/s00521-023-09178-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have evolved into strong and dependable machine learning systems. However, training these systems requires human intervention in selecting neural network parameters and evaluating results. This human intervention exposes the training of a neural network to human bias. One key task in neural network learning success is selecting optimal activation functions for the hidden and output layers. Activation functions are hyperparameters that cannot be adjusted during learning. By programming a neural network to repeatedly monitor the loss function to sense learning decline, an underperforming activation function can be discarded at an appropriate point in favor of another one until convergence, thus minimizing human intervention and potential bias. The results of this study indicate that parameterizing activation functions can improve neural network accuracy while achieving convergence. Swapping activation functions during training offer solutions to both the user bias problem and the risk of suboptimal learning.},
  archive      = {J_NCA},
  author       = {Locke, James M. and Paradice, David and Rainer, R. Kelly},
  doi          = {10.1007/s00521-023-09178-5},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2983-2998},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mitigating bias through random activation function selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Prediction of performance degradation in aircraft engines
with fuel flow parameter. <em>NCA</em>, <em>36</em>(6), 2973–2982. (<a
href="https://doi.org/10.1007/s00521-023-09174-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planned maintenance is required by licensed maintenance organizations to detect and prevent performance degradation in aircraft engines. In the literature, engine performance is evaluated with parameters that show engine performance. Fuel flow parameter is one of the important parameters that shows engine performance. In the models developed earlier, no engine performance evaluation was made with the fuel flow parameter at all stages from the take-off to the landing of the aircraft. In this study, fuel flow parameter is estimated with over 99.9% accuracy by using artificial neural network in MATLAB® software. In order to detect the engine performance deterioration of the aircraft, the fuel flow values obtained from the artificial neural network and confidence intervals with 99% confidence level were established. Each value taken from the fuel flow sensor is evaluated by the model in all flight phases. In the model, engine performance is considered normal if the fuel flow value is within the confidence interval, and abnormal (anomaly) if it is outside the confidence interval. An accuracy of over 99.9% was achieved and results of this study showed that fuel flow rate of the engine of interest was within the confidence interval (no performance deterioration).},
  archive      = {J_NCA},
  author       = {Kurt, Bulent},
  doi          = {10.1007/s00521-023-09174-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2973-2982},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of performance degradation in aircraft engines with fuel flow parameter},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VolPAM: Volumetric phenotype-activation-map for data-driven
discovery of 3D imaging phenotypes and interpretability. <em>NCA</em>,
<em>36</em>(6), 2961–2972. (<a
href="https://doi.org/10.1007/s00521-023-09172-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge about the subtypes of a disease critically affects clinical decisions ranging from the choice of therapeutic options to patient management. If the understanding of a disease is partial and the subtypes of the disease are not yet known, a traditional supervised approach becomes untenable for disease subtype classification. In these contexts, unsupervised methods for subtype discovery are essential. There has been very little prior work on the discovery of phenotypic subtypes based on imaging. Moreover, within that limited body of work, the discovered phenotypes often lack interpretability. In this paper, we present a data-driven approach to discovering interpretable imaging phenotypes in 3D image volumes. In particular, the phenotypes are discovered in a latent space learned through a 3D autoencoder. To interpret the discovered phenotypes, we learn a convolutional neural network to classify the phenotype label and present VolPAM (Volumetric Phenotype-Activation-Map) to interpret the latent phenotypes in terms of their imaging footprints. We present results and visualizations on datasets of Computed Tomography images as an example 3D imaging modality. The proposed methods can become a useful aid to further the understanding of the condition in question through phenotype discovery and interpretability in terms of distinct aspects of the discovered phenotypes.},
  archive      = {J_NCA},
  author       = {Norouzi, Mahboobeh and Khan, Shehroz S. and Ashraf, Ahmed},
  doi          = {10.1007/s00521-023-09172-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2961-2972},
  shortjournal = {Neural Comput. Appl.},
  title        = {VolPAM: Volumetric phenotype-activation-map for data-driven discovery of 3D imaging phenotypes and interpretability},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ubiquitous multi-occupant detection in smart environments.
<em>NCA</em>, <em>36</em>(6), 2941–2960. (<a
href="https://doi.org/10.1007/s00521-023-09162-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in ubiquitous computing have emphasized the need for privacy-preserving occupancy detection in smart environments to enhance security. This work presents a novel occupancy detection solution utilizing privacy-aware sensing technologies. The solution analyzes time-series data to detect not only occupancy as a binary problem, but also determines whether one or multiple individuals are present in an indoor environment. On three real-world datasets, our models outperformed various state-of-the-art algorithms, achieving F1-scores up to 94.91% in single-occupancy detection and a macro F1-score of 91.55% in multi-occupancy detection. This makes our approach a promising solution for improving security in smart environments.},
  archive      = {J_NCA},
  author       = {Fährmann, Daniel and Boutros, Fadi and Kubon, Philipp and Kirchbuchner, Florian and Kuijper, Arjan and Damer, Naser},
  doi          = {10.1007/s00521-023-09162-z},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2941-2960},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ubiquitous multi-occupant detection in smart environments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybridization of rough set–wrapper method with regularized
combinational LSTM for seasonal air quality index prediction.
<em>NCA</em>, <em>36</em>(6), 2921–2940. (<a
href="https://doi.org/10.1007/s00521-023-09220-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to survive, mankind needs air. The quality of life depends on the purity of the air we breathe in. Hazardous pollutants are stirred up in our environment by various activities everyday. In a developing country like India, which has huge population, protecting public health is important. In general, air quality is measured using the air quality index, which records the pollutants level in the air. These recordings are to be mentioned across various places, to know about the air quality level. The advancement of the recent artificial intelligence can be replaced by the human efforts and to automate the system in flowless manner. Hence, an effort has been taken in this paper, by proposing a framework of predicting the air quality seasonally using regularized combinational LSTM (REG-CLSTM). For an efficient air quality level prediction with an improved error rate, time, and accuracy, the study has implemented Reg-CLSTM with a large amount of real-time dataset. To improvise the comprehensiveness and the potentiality of the proposed model, the significant feature is extracted by the rough set-wrapper method. The significant challenge is to provide a seasonal limit range for each considered pollutant in place of a generalized range partition. Aiming at this problem, the proposed model is able to identify the highest concerning pollutants occurrence in individual seasons. Through this study, pyramid learning-based hybridized deep learning framework is developed which can play a crucial role in warning the policy maker to reduce the activities that instigate air pollution.},
  archive      = {J_NCA},
  author       = {Manna, Tishya and Anitha, A.},
  doi          = {10.1007/s00521-023-09220-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2921-2940},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybridization of rough set–wrapper method with regularized combinational LSTM for seasonal air quality index prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ant colony optimization for chinese postman problem.
<em>NCA</em>, <em>36</em>(6), 2901–2920. (<a
href="https://doi.org/10.1007/s00521-023-09195-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to solve the Chinese Postman Problem (CPP) using an Ant Colony Optimization (ACO) algorithm. In graph theory, the CPP looks for the shortest closed path that visits every edge of a connected undirected graph. This problem has many applications, including route optimization, interactive system analysis, and flow design. Although numerous algorithms aimed at solving CPP are present in the literature, very few meta-heuristic algorithms are proposed, and no ACO applications have been proposed to solve them. This paper tries to fill this gap by presenting an ACO algorithm that solves CPP (ACO-CPP). To prove its consistency and effectiveness, ACO-CPP is compared with a Genetic Algorithm (GA) and a recursive algorithm throughout three experiments: (1) recursive-ACO-GA comparisons over randomly generated graphs for the attainment of the global optimum; (2) ACO-GA statistical comparisons over specifically generated graphs; (3) recursive-ACO-GA comparisons by changing ACO hyperparameters over randomly generated graphs for the attainment of the global optimum. The experiments prove that the ACO-CPP algorithm is efficient and exhibits a consistency similar to GA when the number of possible solutions to explore is relatively low. However, when that number greatly exceeds those explored, ACO outperforms GA. This suggests that ACO is more suitable for solving problems with a CPP structure.},
  archive      = {J_NCA},
  author       = {Sgarro, Giacinto Angelo and Grilli, Luca},
  doi          = {10.1007/s00521-023-09195-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2901-2920},
  shortjournal = {Neural Comput. Appl.},
  title        = {Ant colony optimization for chinese postman problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VGAN-BL: Imbalanced data classification based on generative
adversarial network and biased loss. <em>NCA</em>, <em>36</em>(6),
2883–2899. (<a
href="https://doi.org/10.1007/s00521-023-09180-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of imbalanced data classification is to solve the problem of unfair learning caused by the large difference in data distribution. Traditional classifiers are designed on the basis of balanced data, but the performance of imbalanced data will decline sharply. Therefore, balancing the majority class and minority class samples before classification is a popular strategy for solving imbalanced learning. Current methods for data balance mainly include oversampling and undersampling. However, the existing undersampling will face the problem of losing important sample information, while oversampling cannot effectively fit the global distribution and generate noise. In recent years, generative adversarial network (GAN) has shown great potential in fitting real sample distributions. Based on this, this paper proposes an improved GAN and biased loss combined model, namely VGAN-BL, to solve the learning problem under imbalanced conditions. In the improvement based on GAN, VAE is used to generate latent vectors with posterior distribution as the input of GAN, and KL similarity measurement loss is introduced into the generator to improve the quality of minority samples generated by GAN. In addition, we propose a biased loss definition method based on the discriminator to improve the performance of classifier. Experiments on 20 real datasets show that the classification performance of the proposed method is significantly improved compared with other advanced methods. The source code can be found here: https://github.com/universuen/VGAN-BL .},
  archive      = {J_NCA},
  author       = {Ding, Hongwei and Sun, Yu and Huang, Nana and Cui, Xiaohui},
  doi          = {10.1007/s00521-023-09180-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2883-2899},
  shortjournal = {Neural Comput. Appl.},
  title        = {VGAN-BL: Imbalanced data classification based on generative adversarial network and biased loss},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual regenerative fusion network for pest recognition.
<em>NCA</em>, <em>36</em>(6), 2867–2882. (<a
href="https://doi.org/10.1007/s00521-023-09173-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic pest detection from agricultural crops is a challenging agricultural application. It has been observed that many farmers lose crop yields mainly due to pests that spread rapidly. An intelligent pest recognition system (IPRS) is an innovative application that assists farmers in increasing agricultural productivity by accurately detecting pests that may cause crop damage. It allows one to identify the type of pest and apply the appropriate pesticides in a timely manner. There is a large deviation in deep neural network (DNN) performance on clean images and naturally degraded images. This article proposes a novel data augmentation techniques and feature fusion techniques to improve the accuracy as well as the desired robustness. The proposed visual regenerative fusion network (VRFNet) fuses the multiscale features from global feature extraction (GFE) network and the visual regeneration (VR) network to capture the semantic details for identifying pests from the distorted images which improves the accuracy. The proposed patch-based augmentation approach can effectively simulate the environment in which the leaves can partially conceal the insects and helps in improving the robustness. The proposed model achieves an accuracy of 99.12 and 68.34 on the publicly available D0 and IP102 datasets, respectively. These results clearly demonstrate that the proposed fusion method achieved a high success rate for distorted and occluded images captured from the agriculture farms.},
  archive      = {J_NCA},
  author       = {Nandhini, C. and Brindha, M.},
  doi          = {10.1007/s00521-023-09173-w},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2867-2882},
  shortjournal = {Neural Comput. Appl.},
  title        = {Visual regenerative fusion network for pest recognition},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed asynchronous non-smooth optimization with
coupled equality and bounded constraints. <em>NCA</em>, <em>36</em>(6),
2853–2866. (<a
href="https://doi.org/10.1007/s00521-023-09205-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a distributed convex optimization problem with a linearly coupled equality constraint and non-smooth objective function, in which heterogeneous time delays exist over the communication network. Based on the passivity of primal–dual dynamics, a distributed asynchronous algorithm that is robust to heterogeneous time delays over the network is proposed. By transforming the output information using the scattering variables and transmitting the scattering variables across the network, convergence to the optimal solution can be guaranteed with a distributed asynchronous method. Moreover, the convergence condition, which is irrelative to the heterogeneous delay parameters, is obtained through Lyapunov analysis. This means the proposed algorithm can achieve convergence to the optimal solution without the heterogeneous delay information.},
  archive      = {J_NCA},
  author       = {Lin, Wen-Ting and Li, Chaojie},
  doi          = {10.1007/s00521-023-09205-5},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2853-2866},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distributed asynchronous non-smooth optimization with coupled equality and bounded constraints},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing epileptic seizure recognition performance with
feature scaling and dropout layers. <em>NCA</em>, <em>36</em>(6),
2835–2852. (<a
href="https://doi.org/10.1007/s00521-023-09204-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a widespread neurological disorder characterized by recurring seizures that have a significant impact on individuals&#39; lives. Accurately recognizing epileptic seizures is crucial for proper diagnosis and treatment. Deep learning models have shown promise in improving seizure recognition accuracy. However, optimizing their performance for this task remains challenging. This study presents a new approach to optimize epileptic seizure recognition using deep learning models. The study employed a dataset of Electroencephalography (EEG) recordings from multiple subjects and trained nine deep learning architectures with different preprocessing techniques. By combining a 1D convolutional neural network (Conv1D) with a Long Short-Term Memory (LSTM) network, we developed the Conv1D + LSTM architecture. This architecture, augmented with dropout layers, achieved an effective test accuracy of 0.993. The LSTM architecture alone achieved a slightly lower accuracy of 0.986. Additionally, the Bidirectional LSTM (BiLSTM) and Gated Recurrent Unit (GRU) architectures performed exceptionally well, with accuracies of 0.983 and 0.984, respectively. Notably, standard scaling proved to be advantageous, significantly improving the accuracy of both BiLSTM and GRU compared to MinMax scaling. These models consistently achieved high test accuracies across different percentages of Principal Component Analysis (PCA), with the best results obtained when retaining 50% and 90% of the features. Chi-square feature selection also enhanced the classification performance of BiLSTM and GRU models. The study reveals that different deep learning architectures respond differently to feature scaling, PCA, and feature selection methods. Understanding these nuances can lead to optimized models for epileptic seizure recognition, ultimately improving patient outcomes and quality of life.},
  archive      = {J_NCA},
  author       = {Omar, Ahmed and Abd El-Hafeez, Tarek},
  doi          = {10.1007/s00521-023-09204-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2835-2852},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing epileptic seizure recognition performance with feature scaling and dropout layers},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new binary coati optimization algorithm for binary
optimization problems. <em>NCA</em>, <em>36</em>(6), 2797–2834. (<a
href="https://doi.org/10.1007/s00521-023-09200-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coati optimization algorithm (COA) is a recently proposed heuristic algorithm. The COA algorithm, which solved the continuous optimization problems in its original paper, has been converted to a binary optimization solution by using transfer functions in this paper. Thus, binary COA (BinCOA) is proposed for the first time in this study. In this study, twenty transfer functions are used (four S-shaped, four V-shaped, four Z-shaped, four U-shaped, and four taper-shaped transfer functions). Thus, twenty variations of BinCOA are obtained, and the effect of each transfer function on BinCOA is examined in detail. The knapsack problem (KP) and uncapacitated facility location problem (UFLP), which are popular binary optimization problems in the literature, are chosen to test the success of BinCOA. In this study, small-, middle-, and large-scale KP and UFLP datasets are selected. Real-world problems are not always low-dimensional. Although a binary algorithm sometimes shows superior success in low dimensions, it cannot maintain the same success in large dimensions. Therefore, the success of BinCOA has been tested and demonstrated not only in low-dimensional binary optimization problems, but also in large-scale optimization problems. The most successful transfer function is T3 for KPs and T20 for UFLPs. This showed that S-shaped and taper-shaped transfer functions obtained better results than others. After determining the most successful transfer function for each problem, the enhanced BinCOA (EBinCOA) is proposed to increase the success of BinCOA. Two methods are used in the development of BinCOA. These are the repair method and the XOR gate method. The repair method repairs unsuitable solutions in the population in a way that competes with other solutions. The XOR gate is one of the most preferred methods in the literature when producing binary solutions and supports diversity. In tests, EBinCOA has achieved better results than BinCOA. The added methods have proven successful on BinCOA. In recent years, the newly proposed evolutionary mating algorithm, fire hawk optimizer, honey badger algorithm, mountain gazelle optimizer, and aquila optimizer have been converted to binary using the most successful transfer function selected for KP and UFLP. BinCOA and EBinCOA have been compared with these binary heuristic algorithms and literature. In this way, their success has been demonstrated. According to the results, it has been seen that EBinCOA is a successful and preferable algorithm for binary optimization problems.},
  archive      = {J_NCA},
  author       = {Yildizdan, Gülnur and Bas, Emine},
  doi          = {10.1007/s00521-023-09200-w},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2797-2834},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new binary coati optimization algorithm for binary optimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). QvQ-IL: Quantity versus quality in incremental learning.
<em>NCA</em>, <em>36</em>(6), 2767–2796. (<a
href="https://doi.org/10.1007/s00521-023-09129-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The catastrophic forgetting problem is one of the hotspots in the field of deep learning. At present, there is no doubt that storing samples of previous tasks in fixed-size memory is the best way to solve this problem. However, the number of samples stored in fixed-size memory is limited. With the increase in tasks, the number of samples stored in memory for a single task will decrease sharply. It is also difficult to balance the memory capacity and number of samples. To solve this problem, some methods use a fixed size of memory to store dimensionality reduction images. However, this will create new problems. 1) The quality of dimensionality reduction images is poor, and they are significantly different from original images. 2) How to choose the dimensionality reduction method of images. To address these problem, we put forward a new method. Firstly, we employ a simple and reliable scheme to solve the domain difference between dimensionality reduction images and original images. And we theoretically analyzed which image dimensionality reduction method is better. Secondly, to increase the generalization ability of our method and further mitigate the catastrophic forgetting phenomenon, we utilize a self-supervised image augmentation method and the output features similarity loss. Thirdly, we make use of the neural kernel mapping support vector machine theory to improve the interpretability of our method. Experimental results demonstrated that the top-1 average accuracy of our method is much higher than other methods when using the same size of memory.},
  archive      = {J_NCA},
  author       = {Han, Jidong and Zhang, Ting and Liu, Zhaoying and Li, Yujian},
  doi          = {10.1007/s00521-023-09129-0},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2767-2796},
  shortjournal = {Neural Comput. Appl.},
  title        = {QvQ-IL: Quantity versus quality in incremental learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ensemble of CNNs with self-attention mechanism for
DeepFake video detection. <em>NCA</em>, <em>36</em>(6), 2749–2765. (<a
href="https://doi.org/10.1007/s00521-023-09196-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of large-scale facial datasets with the rapid progress of deep learning techniques, such as Generative Adversarial Networks, has enabled anyone to create realistic fake videos. These fake videos can potentially become harmful when used for fake news, hoaxes, and identity fraud. We propose a deep learning bagging ensemble classifier to detect manipulated faces in videos. The proposed bagging classifier uses the convolution and self-attention network (CoAtNet) model as a base learner. CoAtNet model is vertically stacking depthwise convolution layers and self-attention layers in such a way that generalization, capacity, and efficiency are improved. Depthwise convolution captures local features from faces extracted from video then pass these features to the attention layers to extract global information and efficiently capture long-range dependencies of spatial details. Each learner is trained on a different subset randomly taken of training data with a replacement then models’ predictions are combined to classify the video either as real or fake. We also use CutMix data augmentation on the extracted faces to enhance the generalization and localization performance of the base learner model. Our experimental results show that our proposed method achieves higher efficiency compared to state-of-the-art methods with AUC values of 99.70%, 97.49%, 98.90%, and 87.62% on the different manipulation techniques of the FaceForensics++ dataset (DeepFakes (DF), Face2Face (F2F), FaceSwap (FS), and NeuralTextures (NT)), respectively, and 99.74% on the Celeb-DF dataset.},
  archive      = {J_NCA},
  author       = {Omar, Karima and Sakr, Rasha H. and Alrahmawy, Mohammed F.},
  doi          = {10.1007/s00521-023-09196-3},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2749-2765},
  shortjournal = {Neural Comput. Appl.},
  title        = {An ensemble of CNNs with self-attention mechanism for DeepFake video detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive prescribed performance control for state
constrained stochastic nonlinear systems with unknown control direction:
A novel network-based approach. <em>NCA</em>, <em>36</em>(6), 2737–2748.
(<a href="https://doi.org/10.1007/s00521-023-09125-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the tracking control problem of the state constrained stochastic nonlinear systems with unknown control direction is studied, and a novel adaptive prescribed performance control (PPC) approach is developed with the help of the multi-dimensional Taylor network (MTN). Firstly, a performance function is introduced into the first step of backstepping to ensure transient performance under state constraints. Secondly, the tangent time-varying barrier Lyapunov functions (tan-TVBLFs) are constructed to prevent all states from violating the given time-varying boundary. Thirdly, the MTNs are employed to estimate the unknown nonlinearity in the process of controller design, and a new adaptive PPC strategy is designed. Then, the Lyapunov stability theorem is used to prove that the closed-loop system is semi-global uniformly ultimately bounded (SGUUB) in probability, and the tracking error can be kept in an adjustable small neighborhood of the origin. Finally, the effectiveness of the proposed scheme is verified by the simulation of a numerical example and an actual control system.},
  archive      = {J_NCA},
  author       = {Han, Yu-Qun and Li, Na and Wang, Dong-Mei and Zhou, Ya-Feng and Zhu, Shan-Liang},
  doi          = {10.1007/s00521-023-09125-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2737-2748},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive prescribed performance control for state constrained stochastic nonlinear systems with unknown control direction: A novel network-based approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Review of the grey wolf optimization algorithm: Variants and
applications. <em>NCA</em>, <em>36</em>(6), 2713–2735. (<a
href="https://doi.org/10.1007/s00521-023-09202-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most widely referenced Swarm Intelligence (SI) algorithms is the Grey Wolf Optimizer (GWO), which is based on the pack hunting and natural leadership organization of grey wolves. The GWO algorithm offers several significant benefits, including simple implementation, rapid convergence, and superior convergence outcomes, leading to its effective application in diverse fields for solving optimization issues. Consequently, the GWO has rapidly garnered substantial research interest and a broad audience across numerous areas. To better understand the literature on this algorithm, this review paper aims to consolidate and summarize research publications that utilized the GWO. The paper begins with a concise introduction to the GWO, providing insight into its natural establishment and conceptual framework for optimization. It then lays out the theoretical foundation and key procedures involved in the GWO, following which it comprehensively examines the most recent iterations of the algorithm and categorizes them into parallel, modified, and hybridized variations. Subsequently, the primary applications of the GWO are thoroughly explored, spanning various fields such as computer science, engineering, energy, physics and astronomy, materials science, environmental science, and chemical engineering, among others. This review paper concludes by summarizing the key arguments in favour of GWO and outlining potential lines of inquiry in the future research.},
  archive      = {J_NCA},
  author       = {Liu, Yunyun and As’arry, Azizan and Hassan, Mohd Khair and Hairuddin, Abdul Aziz and Mohamad, Hesham},
  doi          = {10.1007/s00521-023-09202-8},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2713-2735},
  shortjournal = {Neural Comput. Appl.},
  title        = {Review of the grey wolf optimization algorithm: Variants and applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HDUD-net: Heterogeneous decoupling unsupervised dehaze
network. <em>NCA</em>, <em>36</em>(6), 2695–2711. (<a
href="https://doi.org/10.1007/s00521-023-09199-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haze reduces the imaging effectiveness of outdoor vision systems, significantly degrading the quality of images; hence, reducing haze has been a focus of many studies. In recent years, decoupled representation learning has been applied in image processing; however, existing decoupled networks lack a specific design for information with different characteristics to achieve satisfactory results in dehazing tasks. This study proposes a heterogeneous decoupling unsupervised dehazing network (HDUD-Net). Heterogeneous modules are used to learn the content and haze information of images individually to separate them effectively. To address the problem of information loss when extracting the content from hazy images with complex noise, this study proposes a bi-branch multi-hierarchical feature fusion module. Additionally, it proposes a style feature contrast learning method to generate positive and negative sample queues and construct contrast loss for enhancing decoupling performance. Numerous experiments confirm that the proposed algorithm achieves higher performance according to objective metrics and a more realistic visual effect when compared with state-of-the-art single-image dehazing algorithms.},
  archive      = {J_NCA},
  author       = {Li, Jiafeng and Kuang, Lingyan and Jin, Jiaqi and Zhuo, Li and Zhang, Jing},
  doi          = {10.1007/s00521-023-09199-0},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2695-2711},
  shortjournal = {Neural Comput. Appl.},
  title        = {HDUD-net: Heterogeneous decoupling unsupervised dehaze network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AnIO: Anchored input–output learning for time-series
forecasting. <em>NCA</em>, <em>36</em>(6), 2683–2693. (<a
href="https://doi.org/10.1007/s00521-023-09175-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the short-term electric load demand forecasting problem is addressed, proposing a method inspired by the use of anchors in object detection methods. Specifically, a method named Anchored Input–Output Learning (AnIO) is proposed. AnIO proposes to define and use an anchor, reformulating the problem into offset prediction instead of actual load value prediction. Additionally, the use of anchor-encoded input features to match the encoded output is proposed. Extensive experiments were conducted, considering different anchors and model architectures on different datasets. Considering the Greek energy market, AnIO improves the performance from 2.914 to 2.251% in terms of MAPE. In conclusion, AnIO method achieves to improve the performance, considering time-series forecasting tasks.},
  archive      = {J_NCA},
  author       = {Stentoumi, Ourania and Nousi, Paraskevi and Tzelepi, Maria and Tefas, Anastasios},
  doi          = {10.1007/s00521-023-09175-8},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2683-2693},
  shortjournal = {Neural Comput. Appl.},
  title        = {AnIO: Anchored input–output learning for time-series forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DECACNN: Differential evolution-based approach to compress
and accelerate the convolution neural network model. <em>NCA</em>,
<em>36</em>(6), 2665–2681. (<a
href="https://doi.org/10.1007/s00521-023-09166-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research work, a differential evolution-based method has been used to compress the deep neural network architectures. The compression is achieved by selecting the most dominant filters/nodes during the training of the model. The usefulness of filters is established by the test accuracy of the model. The experimental results demonstrate that the performance of proposed model compares fairly well with other state of art model compression techniques. Moreover, the compression achieved with VGG16 on MNIST, CIFAR-10 and CIFAR-100 datasets was 98.32, 98.5 and 93.54%, respectively. The corresponding compression achieved on ResNet50 was 85.24, 85.38 and 79.37%, while SqueezeNet which is already compressed model could also be compressed by 72.94, 73.77 and 44.59%, respectively. MobileNet, which is already a compact model developed for mobile applications, could also be compressed by 93.04, 93.74 and 76.37% on MNIST, CIFAR-10 and CIFAR-100 datasets. The loss in accuracy in compressed models turns out to be less than 2%. Further, the compressed models report acceleration in inference time being 80.79% on VGG16, 74.14% on ResNet50, 42.96% on MobileNet and 11.79% on SqueezeNet.},
  archive      = {J_NCA},
  author       = {Agarwal, Mohit and Gupta, Suneet K. and Biswas, K. K.},
  doi          = {10.1007/s00521-023-09166-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2665-2681},
  shortjournal = {Neural Comput. Appl.},
  title        = {DECACNN: Differential evolution-based approach to compress and accelerate the convolution neural network model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dementia classification from magnetic resonance images by
machine learning. <em>NCA</em>, <em>36</em>(6), 2653–2664. (<a
href="https://doi.org/10.1007/s00521-023-09163-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dementia is a threatening condition that affects communication, thinking, and memory skills, being Alzheimer its most common type. The early detection of this disease allows for better care of the patient. Recently, Machine Learning (ML) methods have been developed to support the finding and forecast of Alzheimer’s disease through the analysis of Magnetic Resonance Images (MRI). Existing ML methods present some limitations: (i) require an expert to extract relevant features from MRI, (ii) depend on multistep image preprocessing, or (iii) need complex architectures and several images to train them. To surpass these limitations, in the present work, we analyze different Convolutional Neural Networks (CNNs) for Alzheimer’s classification, formulated to learn from a set of representative MRI sagittal images available in the Open Access Series of Imaging Studies (OASIS-2, 72 non-demented and 64 demented subjects, with ages from 60 to 96 years) and the Alzheimer’s Disease Neuroimaging Initiative (ADNI, 200 early Alzheimer and 200 control patients, with ages from 55 to 90 years) datasets. All CNNs were compared with state-of-the-art ML methods, being the VGG-16 variant the best performed architecture with an average validation accuracy of 56% ± 4%, evaluated with a bootstrapping strategy to measure the variability on independent runs. This result confirms the best performance reported so far (&lt; 60%) with different ML methods. The low accuracy evidences the hardness of the problem and contrasts with the higher accuracy levels (up to 97%) reached with preprocessed and well-characterized MRI axial images from the OASIS-1 or ADNI-2 datasets. Thus, opening an interesting discussion about what MRI plane should be considered when training CNNs for Alzheimer’s classification, and leaving a wide room for improvement on the performance of CNNs trained with sagittal MRI images. The resulting model implemented in software and experimental data are publicly available.},
  archive      = {J_NCA},
  author       = {Waldo-Benítez, Georgina and Padierna, Luis Carlos and Ceron, Pablo and Sosa, Modesto A.},
  doi          = {10.1007/s00521-023-09163-y},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2653-2664},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dementia classification from magnetic resonance images by machine learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel hybrid search strategy for evolutionary fuzzy
optimization approach. <em>NCA</em>, <em>36</em>(6), 2633–2652. (<a
href="https://doi.org/10.1007/s00521-023-09161-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybridization of metaheuristic algorithms has recently been introduced to increase the search capabilities of a traditional metaheuristic algorithms. The fuzzy optimization approach (FOA) is a metaheuristic algorithm that implements fuzzy logic systems to incorporate the knowledge and experience of an expert metaheuristic designer. This integration enables the FOA to guide the search strategy throughout the optimization process. It has been widely applied in high-dimensional problems due to its robustness. However, it presents some issues, such as a slow convergence rate, low exploration and exploitation mechanisms, and high computational effort. In this paper, hybrid search mechanisms are implemented to the original structure of FOA to increase its performance in terms of search capabilities over the limits of the fitness functions. The proposed method called ODM-FOA combines the advantages of Metropolis Hasting (MH) initialization, opposition-based learning (OBL), and Diversity measures to correctly identify and register prominent areas within the search space by approximating the fitness function and improving the exploration and exploitation of the search space. A comparison between ODM-FOA and the original FOA is implemented. Additionally, to evaluate the performance of the developed scheme, it is compared among six well-known metaheuristic algorithms on a set of benchmark functions. Experimental results demonstrate the effectiveness and robustness of the proposed approach against the other original FOA and the other methodologies in terms of solution quality, dimensionality, similarity, and convergence criteria.},
  archive      = {J_NCA},
  author       = {Escobar-Cuevas, Héctor and Cuevas, Erik and Gálvez, Jorge and Avila, Karla},
  doi          = {10.1007/s00521-023-09161-0},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {6},
  pages        = {2633-2652},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel hybrid search strategy for evolutionary fuzzy optimization approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective variational auto-encoder-based model for
traffic flow imputation. <em>NCA</em>, <em>36</em>(5), 2617–2631. (<a
href="https://doi.org/10.1007/s00521-023-09127-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow imputation is crucial in modern intelligent transportation systems, due to frequent data missing caused by the failure of detectors or the influence of hostile external environment (e.g., signal strength). However, this work can be challenging for mainly three reasons: firstly, how to impute traffic flow that shows both universal complex spatio-temporal regularity and individual random authenticity is non-trivial. Secondly, though there are so many algorithms for traffic flow imputation, most of them either ignore different periodic dependencies or just deal with them independently. Lastly, the effectiveness of most deep learning models (etc., CNN, RNN) may be influenced by data missing in model training phase. To solve the problems above, an effective model traffic flow imputation variational auto-encoder (TFI-VAE) considering robust joint-periodic spatio-temporal features is proposed, which can impute missing value not only accurately but also realistically by introducing Gaussian mixture distribution enhanced VAE and normalization flows. Moreover, spatial missing oriented block and temporal missing oriented block are utilized in TFI-VAE to learn the spatial and temporal features of traffic flow data with ability to resist the negative effects of missing data. The experiments conducted on three real-world traffic flow datasets demonstrate that our TFI-VAE outperforms other classical imputation models from all aspects.},
  archive      = {J_NCA},
  author       = {Zhang, Shuo and Hu, Xingbang and Chen, Jinyi and Zhang, Wenbo and Huang, Hejiao},
  doi          = {10.1007/s00521-023-09127-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2617-2631},
  shortjournal = {Neural Comput. Appl.},
  title        = {An effective variational auto-encoder-based model for traffic flow imputation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Addressing the data bottleneck in medical deep learning
models using a human-in-the-loop machine learning approach.
<em>NCA</em>, <em>36</em>(5), 2597–2616. (<a
href="https://doi.org/10.1007/s00521-023-09197-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any machine learning (ML) model is highly dependent on the data it uses for learning, and this is even more important in the case of deep learning models. The problem is a data bottleneck, i.e. the difficulty in obtaining an adequate number of cases and quality data. Another issue is improving the learning process, which can be done by actively introducing experts into the learning loop, in what is known as human-in-the-loop (HITL) ML. We describe an ML model based on a neural network in which HITL techniques were used to resolve the data bottleneck problem for the treatment of pancreatic cancer. We first augmented the dataset using synthetic cases created by a generative adversarial network. We then launched an active learning (AL) process involving human experts as oracles to label both new cases and cases by the network found to be suspect. This AL process was carried out simultaneously with an interactive ML process in which feedback was obtained from humans in order to develop better synthetic cases for each iteration of training. We discuss the challenges involved in including humans in the learning process, especially in relation to human–computer interaction, which is acquiring great importance in building ML models and can condition the success of a HITL approach. This paper also discusses the methodological approach adopted to address these challenges.},
  archive      = {J_NCA},
  author       = {Mosqueira-Rey, Eduardo and Hernández-Pereira, Elena and Bobes-Bascarán, José and Alonso-Ríos, David and Pérez-Sánchez, Alberto and Fernández-Leal, Ángel and Moret-Bonillo, Vicente and Vidal-Ínsua, Yolanda and Vázquez-Rivera, Francisca},
  doi          = {10.1007/s00521-023-09197-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2597-2616},
  shortjournal = {Neural Comput. Appl.},
  title        = {Addressing the data bottleneck in medical deep learning models using a human-in-the-loop machine learning approach},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MBVS: A modified binary vortex search algorithm for solving
uncapacitated facility location problem. <em>NCA</em>, <em>36</em>(5),
2573–2595. (<a
href="https://doi.org/10.1007/s00521-023-09190-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vortex search (VS) algorithm is a recently proposed swarm intelligence or evolutionary algorithm for solving continuous optimization problems inspired by the behavior of whirlpool. In this study, an approach based on VS algorithm is proposed to deal with uncapacitated facility location problem (UFLP) which is a pure problem in binary domain. The update mechanism of VS algorithm is not sufficiently useful for solving the binary optimization problems; therefore, a binary form of VS method called modified binary vortex search (for short MBVS) is proposed for solving UFLPs. Three important changes have been carried out on basic VS algorithm such as (1) converting continuous values to binary values; (2) using genetic mutation operators for enhancing the exploration ability and (3) a local search mechanism for extending the exploitation ability. Based on these changes, MBVS has been tested on fifteen different UFLP instances. The UFLPs dealt with in this study is one of the famous binary optimization problems. It is widely used for comparing the performance of superior algorithms. Once an analysis of 10 different transfer functions, a genetic mutation operator, a local search parameter and population size have been made on proposed method; then, it has been compared with some binary metaheuristic methods and their variants: genetic algorithm (GA)-based approaches such as GA-SP, GA-TP and GA-UP; binary particle swarm optimization algorithm (BPSO); binary versions of artificial bee colony (ABC) algorithm such as binABC, DisABC and ABCbin; binary versions of differential evolution (DE) algorithm such as DisDe/rand and binDE and binary variants of the artificial algae algorithm (AAA) such as AAA-Tanh, AAA-Sig and binAAA methods. The experimental results and comparisons reveal that MBVS algorithm is highly competitive and robust optimizer for the problem addressed in this study.},
  archive      = {J_NCA},
  author       = {Aslan, Murat and Pavone, Mario},
  doi          = {10.1007/s00521-023-09190-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2573-2595},
  shortjournal = {Neural Comput. Appl.},
  title        = {MBVS: A modified binary vortex search algorithm for solving uncapacitated facility location problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Optimizing and interpreting the latent space of the
conditional text-to-image GANs. <em>NCA</em>, <em>36</em>(5), 2549–2572.
(<a href="https://doi.org/10.1007/s00521-023-09185-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image generation intends to automatically produce a photo-realistic image, conditioned on a textual description. To facilitate the real-world applications of text-to-image synthesis, we focus on studying the following three issues: (1) How to ensure that generated samples are believable, realistic or natural? (2) How to exploit the latent space of the generator to edit a synthesized image? (3) How to improve the explainability of a text-to-image generation framework? We introduce two new data sets for benchmarking, i.e., the Good &amp; Bad, bird and face, data sets consisting of successful as well as unsuccessful generated samples. This data set can be used to effectively and efficiently acquire high-quality images by increasing the probability of generating Good latent codes with a separate, new classifier. Additionally, we present a novel algorithm which identifies semantically understandable directions in the latent space of a conditional text-to-image GAN architecture by performing independent component analysis on the pre-trained weight values of the generator. Furthermore, we develop a background-flattening loss (BFL), to improve the background appearance in the generated images. Subsequently, we introduce linear-interpolation analysis between pairs of text keywords. This is extended into a similar triangular ‘linguistic’ interpolation. The visual array of interpolation results gives users a deep look into what the text-to-image synthesis model has learned within the linguistic embeddings. Experimental results on the recent DiverGAN generator, pre-trained on three common benchmark data sets demonstrate that our classifier achieves a better than 98% accuracy in predicting Good/Bad classes for synthetic samples and our proposed approach is able to derive various interpretable semantic properties for the text-to-image GAN model.},
  archive      = {J_NCA},
  author       = {Zhang, Zhenxing and Schomaker, Lambert},
  doi          = {10.1007/s00521-023-09185-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2549-2572},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing and interpreting the latent space of the conditional text-to-image GANs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IDP: ML-driven diabetes prediction framework using
deep-ensemble modeling. <em>NCA</em>, <em>36</em>(5), 2525–2548. (<a
href="https://doi.org/10.1007/s00521-023-09184-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an intelligent healthcare framework by incorporating modern computing technologies like machine learning and deep learning. The sole motivation of this paper is to predict diabetes status intelligently so that patients can be made aware of their diabetes status regularly. A novel ensemble machine learning-based diabetes prediction framework, namely “iDP”, has been proposed in this paper. Six different machine learning approaches have been used for the iDP framework, namely random forest, decision tree, neural network, AdaBoost, support vector machine, and XGBoost. Training and testing of ensemble modeling have been performed based on these learning techniques. A comprehensive preliminary data analysis and screening of statistical analysis have been systematically demonstrated in this paper. The recursive feature elimination and fivefold cross-validation methods have been used to select the best model. All experiments have been performed using R-Studio 1.2.5 with the help of the Rattle library 5.4.0. The preliminary data analytic and Pearson correlation coefficient values have been computed to verify the linearity relationship among the data. Results have been reported in eight performance metrics, including accuracy, specificity, sensitivity, area under curve, area under convex hull, minimum error rate, minimum weighted loss, and precision. The proposed iDP framework improves the results on different aspects in order to compare them with individual learning approaches. Despite this, a comparative performance analysis of the iDP framework has also been performed with state-of-the-art prevailing models. As per experiment, the iDP framework gives better results in most cases, like accuracy: 95.26%, AUC: 91.15%, sensitivity: 96.81%, specificity: 97.72% and precision: 90.72%.},
  archive      = {J_NCA},
  author       = {Kumar, Ajay and Bawa, Seema and Kumar, Neeraj},
  doi          = {10.1007/s00521-023-09184-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2525-2548},
  shortjournal = {Neural Comput. Appl.},
  title        = {IDP: ML-driven diabetes prediction framework using deep-ensemble modeling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LeukoCapsNet: A resource-efficient modified CapsNet model to
identify leukemia from blood smear images. <em>NCA</em>, <em>36</em>(5),
2507–2524. (<a
href="https://doi.org/10.1007/s00521-023-09157-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leukemia is one of the deadly cancers which spreads itself at an exponential rate and has a detrimental impact on leukocytes in the human blood. To automate the process of leukemia detection, researchers have utilized deep learning networks to analyze blood smear images. In our research, we have proposed the usage of networks that mimic the human brain’s real working. These models are fed features from numerous convolution layers, each having its own set of additional skip connections. It is then stored and processed as vectors, making them rotationally invariant as well, a characteristic not found in other deep learning networks, specifically convolutional neural networks (CNNs). The network is then pruned by 20% to make it more deployable in resource-constrained environments. This research also compares the model’s performance by four ablation experiments and concludes that the proposed model is optimal. It has also been tested on three different types of datasets to highlight its robustness. The average values of all three datasets correspond to specificity: 96.97%, sensitivity: 96.81%, precision: 96.79% and accuracy: 97.44%. In a nutshell, the outcomes of the proposed model, i.e., PrunedResCapsNet make it more dynamic and effective compared with other existing methods.},
  archive      = {J_NCA},
  author       = {Dhalla, Sabrina and Mittal, Ajay and Gupta, Savita},
  doi          = {10.1007/s00521-023-09157-w},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2507-2524},
  shortjournal = {Neural Comput. Appl.},
  title        = {LeukoCapsNet: A resource-efficient modified CapsNet model to identify leukemia from blood smear images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic algorithm with normal boundary intersection for
multi-objective early/tardy scheduling problem with carbon-emission
consideration: A pareto-optimum solution. <em>NCA</em>, <em>36</em>(5),
2493–2506. (<a
href="https://doi.org/10.1007/s00521-023-09146-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green manufacturing has become an important research topic owing to the dominant role of the manufacturing industry in environmental conservation, global energy consumption, and carbon emissions. Job scheduling is an active research area that supports industrial development and transformation as a part of industrial manufacturing management. Scheduling and just-in-time (JIT) production are complementary concepts that can help organizations optimize their production processes and achieve their goals more efficiently. The objective of these concepts is to reduce waste by focusing on the timely delivery of products or services to meet customer demand without holding excess inventory or wasting resources. Early/tardy job scheduling aligns with the primary goals of JIT production. This study jointly considers the early/tardy scheduling problem and carbon-emission optimization. A speed-scaling strategy is applied, where a machine has the ability to process jobs at discrete machining speeds. A heuristic method based on a genetic algorithm is proposed to solve the above problem. The proposed algorithm integrates a normal boundary intersection to reinforce the generation of a Pareto optimal solution. Numerical experiments show that the proposed approach provides an optimal and satisfactory Pareto solution within a relatively short computational time.},
  archive      = {J_NCA},
  author       = {Hudaifah, Hudaifah and Andriansyah, Andriansyah and Al-Shareef, Khaled and Darghouth, M. N. and Saleh, Haitham},
  doi          = {10.1007/s00521-023-09146-z},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2493-2506},
  shortjournal = {Neural Comput. Appl.},
  title        = {Genetic algorithm with normal boundary intersection for multi-objective early/tardy scheduling problem with carbon-emission consideration: A pareto-optimum solution},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subconcept perturbation-based classifier for within-class
multimodal data. <em>NCA</em>, <em>36</em>(5), 2479–2491. (<a
href="https://doi.org/10.1007/s00521-023-09144-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification, it is generally assumed that data from one class consist of one pure compact data cluster. However, in many cases, this cluster might consist of multiple subclusters, in other words, within-class multimodality. In such a scenario, it may be difficult or even impossible for a single classifier to find a suitable model using limited data. So, training a model using smaller chunks of data is an alternative that helps avoid complex models and reduces the task’s complexity. This paper proposes the subconcept Perturbation-based Classifier (sPerC) that finds the best clusters per class using cluster validation measures, and one meta-classifier is trained per subcluster. This way, each class is represented by a set of meta-classifiers instead of one classifier. Such a design diminishes the complexity of the task, and using a divide-to-conquer strategy favors the precision of each meta-classifier. Through a set of comprehensive experiments on 30 datasets, the sPerC results compared favorably to other classifiers in multi-class classification tasks, showing that creating specialized classifiers per class in different regions of the feature space can be advantageous.},
  archive      = {J_NCA},
  author       = {Cavalcanti, George D. C. and Soares, Rodolfo J. O. and Araújo, Edson L.},
  doi          = {10.1007/s00521-023-09144-1},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2479-2491},
  shortjournal = {Neural Comput. Appl.},
  title        = {Subconcept perturbation-based classifier for within-class multimodal data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lung cancer detection from thoracic CT scans using an
ensemble of deep learning models. <em>NCA</em>, <em>36</em>(5),
2459–2477. (<a
href="https://doi.org/10.1007/s00521-023-09130-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer remains a prevalent and deadly disease, claiming numerous lives annually. Early detection plays a pivotal role in significantly improving survival rates, by up to 50–70%. Therefore, developing a robust lung cancer detection system holds immense potential to positively impact human survival. Computed tomography (CT) scan images offer invaluable information about lung nodules, and the emergence of machine learning and deep learning techniques has empowered radiologists in their diagnostic tasks. In this study, we propose a new ensemble of deep learning models to accurately classify the severity of lung nodules. Our approach leverages deep transfer learning and adopts an ensemble learning approach. Specifically, three state-of-the-art convolutional neural networks (CNN) models, namely ResNet-152, DenseNet-169, and EfficientNet-B7, are employed. To enhance the ensemble method’s performance, we introduce a novel scheme for selecting and assigning weights to each base model. Unlike conventional methods that often rely on manual experimentation to set weights, our approach fuses the scores of two standard assessment metrics, ROC-AUC score and F1-score, for a more accurate weight vector determination. To evaluate the effectiveness of our method, we conduct extensive testing using the publicly available CT scan dataset, LIDC-IDRI. Our proposed ensemble achieves an accuracy of 97.23%, surpassing various recent methods and outperforming commonly used ensemble techniques. Furthermore, our novel weight optimization strategy significantly reduces false negatives, leading to a sensitivity of 98.6%. The codes for the proposed work are available at https://github.com/iabh1shekbasu/LungCancerDetectionEnsemble .},
  archive      = {J_NCA},
  author       = {Gautam, Nandita and Basu, Abhishek and Sarkar, Ram},
  doi          = {10.1007/s00521-023-09130-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2459-2477},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lung cancer detection from thoracic CT scans using an ensemble of deep learning models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive-based YOLOv7 for personal protective equipment
detection. <em>NCA</em>, <em>36</em>(5), 2445–2457. (<a
href="https://doi.org/10.1007/s00521-023-09212-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {You only look once (YOLO) is a state-of-the-art object detection model which has a novel architecture that balances model complexity with the inference time. Among YOLO versions, YOLOv7 has a lightweight backbone network called E-ELAN that allows it to learn more efficiently without affecting the gradient path. However, YOLOv7 models face classification difficulties when dealing with classes that have a similar shape and texture like personal protective equipment (PPE). In other words, the Glass versus NoGlass PPE objects almost appear similar when the image is captured at a distance. To mitigate this issue and further improve the classification performance of YOLOv7, a modified version called the contrastive-based model is introduced in this work. The basic concept is that a contrast loss branch function has been added, which assists the YOLOv7 model in differentiating and pushing instances from different classes in the embedding space. To validate the effectiveness of the implemented contrastive-based YOLO, it has been evaluated on two different datasets which are CHV and our own indoor collected dataset named JRCAI. The dataset contains 12 different types of PPE classes. Notably, we have annotated both datasets for the studied 12 PPE objects. The experimental results showed that the proposed model outperforms the standard YOLOv7 model by 2% in mAP@0.5 measure. Furthermore, the proposed model outperformed other YOLO variants as well as cutting-edge object detection models such as YOLOv8, Faster-RCNN, and DAB-DETR.},
  archive      = {J_NCA},
  author       = {Samma, Hussein and Al-Azani, Sadam and Luqman, Hamzah and Alfarraj, Motaz},
  doi          = {10.1007/s00521-023-09212-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2445-2457},
  shortjournal = {Neural Comput. Appl.},
  title        = {Contrastive-based YOLOv7 for personal protective equipment detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Type-2 diabetes identification from toe-photoplethysmography
using fourier decomposition method. <em>NCA</em>, <em>36</em>(5),
2429–2443. (<a
href="https://doi.org/10.1007/s00521-023-09208-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Type-2 diabetes mellitus (DM-2) is a complicated endocrine and metabolism condition recognized as the most major non-communicable disease in the world. The complications associated with DM-2 involve cardiovascular disease, diabetic retinopathy and neuropathy. This article proposes the Fourier decomposition method for non-invasive automated type-2 diabetes detection using photoplethysmography (PPG) signals. The proposed research work comprises three major phases. In the first phase, the 5-min duration of the toe PPG signal is split into 10-s segments and decomposed into frequency subbands known as Fourier intrinsic band functions (FIBFs). Two features from each FIBF are extracted in the second phase, including kurtosis and log energy entropy. The last stage involves passing the features on to various machine learning techniques. The least-square support vector machine (radial basis function) algorithm yielded better classification results with an accuracy of 98.61%, a sensitivity of 98.96%, and a selectivity of 98.26%.},
  archive      = {J_NCA},
  author       = {Mishra, Bhanupriya and Nirala, Neelamshobha and Singh, Bikesh Kumar},
  doi          = {10.1007/s00521-023-09208-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2429-2443},
  shortjournal = {Neural Comput. Appl.},
  title        = {Type-2 diabetes identification from toe-photoplethysmography using fourier decomposition method},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable offline automatic signature verifier to support
forensic handwriting examiners. <em>NCA</em>, <em>36</em>(5), 2411–2427.
(<a href="https://doi.org/10.1007/s00521-023-09192-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signature verification is a critical task in many applications, including forensic science, legal judgments, and financial markets. However, current signature verification systems are often difficult to explain, which can limit their acceptance in these applications. In this paper, we propose a novel explainable offline automatic signature verifier (ASV) to support forensic handwriting examiners. Our ASV is based on a universal background model (UBM) constructed from offline signature images. It allows us to assign a questioned signature to the UBM and to a reference set of known signatures using simple distance measures. This makes it possible to explain the verifier’s decision in a way that is understandable to non-experts. We evaluated our ASV on publicly available databases and found that it achieves competitive performance with state-of-the-art ASVs, even when challenging 1 versus 1 comparisons are considered. Our results demonstrate that it is possible to develop an explainable ASV that is also competitive in terms of performance. We believe that our ASV has the potential to improve the acceptance of signature verification in critical applications such as forensic science and legal judgments.},
  archive      = {J_NCA},
  author       = {Diaz, Moises and Ferrer, Miguel A. and Vessio, Gennaro},
  doi          = {10.1007/s00521-023-09192-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2411-2427},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable offline automatic signature verifier to support forensic handwriting examiners},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed attractivity region selection for recurrent
neural networks based on deep reinforcement learning. <em>NCA</em>,
<em>36</em>(5), 2399–2409. (<a
href="https://doi.org/10.1007/s00521-023-09191-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks’ (RNNs’) outputs are the same when network states converge to the same saturation region. Strong external inputs can cause the neural network to converge to a prescribed saturation region. Different from previous works, this paper employs deep reinforcement learning to obtain external inputs to make network states converge to the desired saturation region. Firstly, for five-dimensional neural networks, the deep Q learning (DQN) algorithm is used to compute the optimal external inputs that make the network state converge to the specified saturation region. When scaling to n-dimensional RNNs, the problem of dimensional disaster is encountered. Then, it proposes a batch computation of the external inputs to cope with the curse of dimensionality. At last, the proposed method is validated by numerical examples, and compared with existing methods, it shows that less conservative external inputs conditions can be obtained.},
  archive      = {J_NCA},
  author       = {Bao, Gang and Song, Zhenyan and Xu, Rui},
  doi          = {10.1007/s00521-023-09191-8},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2399-2409},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prescribed attractivity region selection for recurrent neural networks based on deep reinforcement learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A term extraction algorithm based on machine learning and
comprehensive feature strategy. <em>NCA</em>, <em>36</em>(5), 2385–2398.
(<a href="https://doi.org/10.1007/s00521-023-08960-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual term extraction is similar to literal meaning: A translator browses text, classifies words, and prepares for translation. Terminology, as a centralized carrier of expertise, creation, popularization, and disappearance, dynamically reflects the development and evolution of an industry. The automatic extraction of terminology is a key technology for creating a professional terminology database, and it is also a key topic in the field of natural language processing. The purpose of this paper is to study how to analyse a term extraction algorithm based on machine learning and a comprehensive feature strategy. Focusing on the problems of poor generality and single statistical features of current term extraction algorithms, this paper proposes an improved domain ontology term extraction algorithm based on a comprehensive feature strategy. Moreover, automatic term extraction experiments based on a word-based maximum entropy model and a conditional random field model based on machine learning are conducted in this paper. Its word-based conditional random field model outperforms the maximum entropy model. The experimental results show that the algorithm based on the comprehensive feature strategy improves the accuracy by 8.6% compared with the TF-IDF algorithm and the C-value term extraction algorithm. This algorithm can be used to effectively extract the terms in a text and has good generality.},
  archive      = {J_NCA},
  author       = {Gong, Xiuliang and Cheng, Bo and Hu, Xiaomei and Bo, Wen},
  doi          = {10.1007/s00521-023-08960-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2385-2398},
  shortjournal = {Neural Comput. Appl.},
  title        = {A term extraction algorithm based on machine learning and comprehensive feature strategy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent speech recognition algorithm in multimedia
visual interaction via BiLSTM and attention mechanism. <em>NCA</em>,
<em>36</em>(5), 2371–2383. (<a
href="https://doi.org/10.1007/s00521-023-08959-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology in modern society, the application of multimedia integration platform is more and more extensive. Speech recognition has become an important subject in the process of multimedia visual interaction. The accuracy of speech recognition is dependent on a number of elements, two of which are the acoustic characteristics of speech and the speech recognition model. Speech data is complex and changeable. Most methods only extract a single type of feature of the signal to represent the speech signal. This single feature cannot express the hidden information. And, the excellent speech recognition model can also better learn the characteristic speech information to improve performance. This work proposes a new method for speech recognition in multimedia visual interaction. First of all, this work considers the problem that a single feature cannot fully represent complex speech information. This paper proposes three kinds of feature fusion structures to extract speech information from different angles. This extracts three different fusion features based on the low-level features and higher-level sparse representation. Secondly, this work relies on the strong learning ability of neural network and the weight distribution mechanism of attention model. In this paper, the fusion feature is combined with the bidirectional long and short memory network with attention. The extracted fusion features contain more speech information with strong discrimination. When the weight increases, it can further improve the influence of features on the predicted value and improve the performance. Finally, this paper has carried out systematic experiments on the proposed method, and the results verify the feasibility.},
  archive      = {J_NCA},
  author       = {Feng, Yican},
  doi          = {10.1007/s00521-023-08959-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2371-2383},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent speech recognition algorithm in multimedia visual interaction via BiLSTM and attention mechanism},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application status of qualitative comparative analysis
methods in the international ISLS field based on social network
analysis. <em>NCA</em>, <em>36</em>(5), 2353–2369. (<a
href="https://doi.org/10.1007/s00521-023-08808-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the knowledge network structure of foreign research literature by applying the qualitative comparative analysis (QCA) method to the field of information science and library science (ISLS) from the perspective of the cocitation of social network actors such as authors, institutions, countries, and literature, and it further reveals the future application trends of this method. [Method/process] Based on 86 journals in the ISLS field that were downloaded from the Web of Science using the QCA method, the social network analysis (SNA) method and the visual analysis tool Gephi are used to analyse the author cooperation network, the research institution cooperation network, the national cooperation network, the cocitation network, the cutting-edge trends, etc., of journal papers. The analysis shows that the QCA method covers a wide range within the field of ISLS, but the research topics involved in this field are not concentrated, and the author cooperation network has scale-free characteristics. The application of the QCA method is still dominant in European and American countries, and China, the USA, and Italy all play key roles in the national cooperation network. Finally, the institutional cooperation network has certain small group attributes.},
  archive      = {J_NCA},
  author       = {Chen, Zeyin and Lu, Xinyuan and Zhang, Heng},
  doi          = {10.1007/s00521-023-08808-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2353-2369},
  shortjournal = {Neural Comput. Appl.},
  title        = {Application status of qualitative comparative analysis methods in the international ISLS field based on social network analysis},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and accurate detection of herd pigs based on
ghost-YOLOv7-SIoU. <em>NCA</em>, <em>36</em>(5), 2339–2352. (<a
href="https://doi.org/10.1007/s00521-023-09093-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision methods for non-contact detection of herd pigs could help detect early disease and reduce mortality rates by analyzing pig behavior. Due to the limitation of breeding space and cost, the unit breeding area is relatively dense, making it difficult to detect all pigs for a long time without interruption. In order to improve the detection performance, this paper proposes an end-to-end efficient and accurate herd pig detection framework based on YOLOv7 target detection model, which is named Ghost-YOLOv7-SIoU. In this framework, the feature extraction backbone network consists of a series of directly connected efficient layer aggregation networks (ELAN) and downsampling modules. The neck network contains a feature pyramid network and path aggregation network. Ghost convolution is adopted to replace the $$3 \times 3$$ standard convolution of the ELAN module in backbone network and the scaled-up ELAN module in neck network to obtain rich features while reducing the parameter number and computational effort. Furthermore, to speed up the model convergence and improve the model robustness and accuracy, SIoU loss is used for bounding box regression in the training stage. On the VOC2012 dataset, the number of parameters and floating-point operations decreased by 13.4% and 15.7% compared to YOLOv7, with comparable detection accuracy. Additionally, the number of parameters and floating-point operations decreased by 13.7% and 16.1% on our pig dataset. Ghost-YOLOv7-SIoU is superior to YOLOV4-CSP and YOLOR-CSP in accuracy. Experimental results demonstrate the effectiveness of the proposed method in improving the efficiency of model detection while ensuring detection accuracy.},
  archive      = {J_NCA},
  author       = {Sun, Donglai and Zhang, Lijuan and Wang, Jianqiang and Liu, Xintong and Wang, Zhengbo and Hui, Zhenqiao and Wang, Jichao},
  doi          = {10.1007/s00521-023-09093-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2339-2352},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient and accurate detection of herd pigs based on ghost-YOLOv7-SIoU},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Fine-grained image recognition method for
digital media based on feature enhancement strategy. <em>NCA</em>,
<em>36</em>(5), 2337. (<a
href="https://doi.org/10.1007/s00521-023-09221-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhou, Tieyu and Gao, Linyi and Hua, Ranjun and Zhou, Junhong and Li, Jinao and Guo, Yawen and Zhang, Yan},
  doi          = {10.1007/s00521-023-09221-5},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2337},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Fine-grained image recognition method for digital media based on feature enhancement strategy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Fine-grained image recognition method for digital media
based on feature enhancement strategy. <em>NCA</em>, <em>36</em>(5),
2323–2335. (<a
href="https://doi.org/10.1007/s00521-023-08968-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of digital media has changed the way people live and learn. In the context of the new era, digital media is gradually integrating into people’s life and learning. Digital media contains massive images, and fine-grained image recognition for digital media has become an important topic. The challenge of fine-grained image recognition is that the difference between different categories is small, and the difference between the same categories is sometimes large. This work designs a fine-grained image recognition based on feature enhancement (FIRFE). This extracts as much information as possible from fine-grained images under weak supervision to improve the recognition accuracy. When the existing methods extract image features, the feature extraction other than the most significant local feature is not enough. This deals with local features alone and ignores the relationship between features. First, this paper designs a feature enhancement and suppression module to process image features. Secondly, this paper designs pyramid residual convolution. This uses different scale convolution kernels to capture different levels of features in the scene. Thirdly, this paper uses the softpool method to rationally allocate the information weight in the pooling process. Fourth, this paper uses feature focus module to mine more features. This focuses on obtaining similar information in multiple local features as discriminant features to further improve the recognition. Fifthly, this paper carried out systematic experiments on the designed method. The proposed method achieves 94.3%/95.7% accuracy, 92.9%/94.1% recall, and 91.4%/92.2% F1 score on different datasets. This verified the superiority of this method for fine-grained image recognition of digital media.},
  archive      = {J_NCA},
  author       = {Zhou, Tieyu and Gao, Linyi and Hua, Ranjun and Zhou, Junhong and Li, Jinao and Guo, Yawen and Zhang, Yan},
  doi          = {10.1007/s00521-023-08968-1},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2323-2335},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fine-grained image recognition method for digital media based on feature enhancement strategy},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy identification of nonuniformly sampled nonlinear
systems based on forwards recursive input–output clustering.
<em>NCA</em>, <em>36</em>(5), 2315–2322. (<a
href="https://doi.org/10.1007/s00521-023-08722-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on forwards recursive input–output data clustering, a recursive least squares (RLS) algorithm is proposed to estimate nonuniformly sampled nonlinear systems. The relationship of linear and nonlinear systems is studied under nonuniform sampling, and a fuzzy model is constructed for the global system. Forwards recursive input–output data clustering based on k-means clustering is used to identify the fuzzy rule number and the antecedent parameters. Based on the membership function, the consequent parameters are identified by an RLS algorithm. A practical application verified the efficiency of the method.},
  archive      = {J_NCA},
  author       = {Liu, Ranran and Zheng, Enxing and Li, Feng and Guo, Wei and Jiang, Yifeng},
  doi          = {10.1007/s00521-023-08722-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2315-2322},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fuzzy identification of nonuniformly sampled nonlinear systems based on forwards recursive input–output clustering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantization to speedup approximate nearest neighbor search.
<em>NCA</em>, <em>36</em>(5), 2303–2313. (<a
href="https://doi.org/10.1007/s00521-023-08920-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantization-based approaches not only are the effective methods for solving the problems of approximate nearest neighbor search, but also effectively reduce storage space. However, many quantization-based approaches usually employ fixed nprobes to the search process for each query. This will lead to extra query consumption. Additionally, we observed that as the number of points in each cluster center of product quantization increases, the query cost also increases. To address this issue, we propose an acceleration strategy based on the IVF-HNSW framework to further speed up the query process. This strategy involves introducing an adaptive termination condition for queries and reducing the number of data points accessed by building HNSW results. Through extensive experiments, we have shown that our proposed method significantly accelerates the nearest neighbor search process.},
  archive      = {J_NCA},
  author       = {Peng, Hao},
  doi          = {10.1007/s00521-023-08920-3},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2303-2313},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quantization to speedup approximate nearest neighbor search},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of online CSR message authenticity on consumer
purchase intention in social media on internet platform via PSO-1DCNN
algorithm. <em>NCA</em>, <em>36</em>(5), 2289–2302. (<a
href="https://doi.org/10.1007/s00521-023-08739-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the deepening of the research on corporate social responsibility (CSR), CSR has become increasingly important to enterprises. It can affect consumers’ willingness to purchase enterprise products. Corporate social responsibility activities are used by many multinational corporations as a competitive business strategy to build a favorable corporate image in the eyes of consumers. Social media, made possible by developments in web and mobile technology, ushered in a new era of advertising on digital platforms. In this context, it has become an important topic to study the relationship between the authenticity of online CSR communication messages and consumers’ purchase intentions. This work proposes an algorithm based on PSO-1DCNN joint optimization to analyze the impact of online CSR information authenticity on consumers’ purchase intention in social media on the Internet platform. First, this work uses one-dimensional convolutional neural network (1DCNN) to model the relationship between the two. This model uses multichannel convolution feature, BN and Dropout strategy to promote performance for the model. Secondly, this work designs optimization measures from inertia weight and learning factor to build an improved particle swarm optimization algorithm (IPSO). Third, this work uses IPSO to optimize the initial network parameters of 1DCNN to build IPSO-1DCNN. The model has stronger convergence ability and convergence speed, in addition, it also has stronger global optimization ability. Fourthly, systematic experiments are carried out for the IPSO-1DCNN designed in this work, and the experimental data verify the superiority of this method.},
  archive      = {J_NCA},
  author       = {Li, Man and Liu, Fang and Abdullah, Zulhamri},
  doi          = {10.1007/s00521-023-08739-y},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2289-2302},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analysis of online CSR message authenticity on consumer purchase intention in social media on internet platform via PSO-1DCNN algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of children’s sub-health treatment effect based on
multi-scale feature fusion network from the perspective of medical
informatization. <em>NCA</em>, <em>36</em>(5), 2277–2288. (<a
href="https://doi.org/10.1007/s00521-023-08918-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sub-health state is a state of health and low quality between disease and health. The theoretical basis of children&#39;s sub-health is to start from the whole. The common clinical sub-health conditions cannot be explained by modern detection methods, and it can be screened and analyzed with the help of big data in medical informatization. The combination of &quot;Internet + &quot; and the health care model is an innovation in the construction of medical informatization. It can provide many considerate services to the masses in time and alleviate the anxiety of illness. Therefore, it is very necessary to carry out the efficacy evaluation of children&#39;s sub-health from the perspective of medical information. Therefore, this paper completes the following work with the help of AI neural network: (1) This paper proposes an improved AlexNet network evaluation method based on attention mechanism. In this study, attention mechanism is added to the original AlexNet model to weight each channel of the feature layer. At the same time, we improve the large convolution kernel of the previous layers of the original AlexNet network and use batch normalization instead of the local response normalization (LRN) layer in the original model. (2) This paper proposes an evaluation method based on improved residual network, which improves the original residual block of the residual model and widens the residual block. The residual block can effectively reduce the amount of network parameters and improve the efficiency of network training. (3) This paper proposes an evaluation method of multi-scale feature fusion (MSFF). The features extracted from the improved AlexNet and residual network are fused and then evaluated. At this time, the training time is greatly shortened, and the accuracy is higher than that of single model.},
  archive      = {J_NCA},
  author       = {Ma, Lingli and Hou, Jianghong and Gui, Lingqin},
  doi          = {10.1007/s00521-023-08918-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2277-2288},
  shortjournal = {Neural Comput. Appl.},
  title        = {Analysis of children&#39;s sub-health treatment effect based on multi-scale feature fusion network from the perspective of medical informatization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparative study of policy shock response effects based
on the data algorithm of the DSGE model. <em>NCA</em>, <em>36</em>(5),
2261–2275. (<a
href="https://doi.org/10.1007/s00521-023-08710-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degree to which the banking sector opens up will immediately impact the structure of the national financial system, which will then directly influence the transmission mechanism and effect of monetary policy because it is the fundamental link in the financial system. This study describes the DSGE model of two nations with heterogeneous banks in light of the disparities in global capital flows and loan restrictions between Chinese and foreign banks. DSGE stands for Dynamic Stochastic General Equilibrium. The results show that (1) foreign banks can lessen the net worth shocks of local banks when they are subject to negative shocks to their net worth by injecting international capital flows. (2) The buffer mechanism of foreign banks will obstruct the transmission of monetary policy and partially offset its policy effects. (3) The buffer mechanism of foreign banks has a more pronounced interference effect on monetary policy when facing negative shocks to their net worth. The management of foreign banks is increasingly loosening as China’s financial opening up quickens. The findings of this paper have policy implications for how to seize the dividends brought by financial openness and control the interference with monetary policy beyond the advantages of foreign banks in stabilizing economic fluctuations.},
  archive      = {J_NCA},
  author       = {Bai, Jiangtao and Deng, Ziyao},
  doi          = {10.1007/s00521-023-08710-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2261-2275},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comparative study of policy shock response effects based on the data algorithm of the DSGE model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Robot knowledge analysis based on cognitive computing and
modular neural network feature combination. <em>NCA</em>,
<em>36</em>(5), 2245–2260. (<a
href="https://doi.org/10.1007/s00521-023-08675-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ongoing integration of information technology and industrialization, strategic emerging industries are becoming an increasingly important force in guiding future economic and social development. As one of the strategic emerging industries&#39; development priorities and a replacement for scarce labor resources, industrial robots will be widely used in labor-intensive industries. It is a contentious topic how to evaluate and improve robot knowledge education. There are modular features introduced in this paper, which builds a modular network for the evaluation of robot knowledge education quality and enhances the cognitive computing ability of artificial neural networks and their ability to process complex information. A modular neural network-based model of feature combination robot knowledge education quality evaluation is developed based on the three aspects of module division method, subnet structure selection, and feature combination output. The following are some of the paper&#39;s most important contributions: K-OD algorithm of density clustering optimized by K-means is proposed. Because of its high level of modularized partition simulating, this method has an excellent clustering effect, and it identifies the core points, boundary points, as well as outliers. Using K-OD algorithm, the calculation of density radius and threshold is optimized by using density clustering, which reduces the overall computational complexity. Find out how SOM neural networks learn from competition. SOM network&#39;s competition layer neuron weights are prone to falling into local optimal solutions, so an SASOM neural network with weight adjustment simulated by an annealing algorithm is proposed to address this issue. It is more accurate in terms of prediction and error, and it is better at identifying sample attribute features. This work builds a modular neural network for evaluating robot knowledge education quality using K-OD clustering algorithm and SASOM neural network, which introduces the simulated annealing mechanism.},
  archive      = {J_NCA},
  author       = {Xu, Zhenliang and Wang, Zhen and Chen, Xi},
  doi          = {10.1007/s00521-023-08675-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2245-2260},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robot knowledge analysis based on cognitive computing and modular neural network feature combination},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State estimation of hydraulic quadruped robots using
invariant-EKF and kinematics with neural networks. <em>NCA</em>,
<em>36</em>(5), 2231–2244. (<a
href="https://doi.org/10.1007/s00521-023-08755-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on state estimation for quadruped robots is critical. Its result passed to motion controller makes the robot navigate autonomously and adjust the gait to a more stable motion. The current research depends on a multi-sensor fusion of cameras, lidars or other proprioceptive sensors, such as Inertial Measurement Unit (IMU) and encoders. The high-frequency data are generally derived from body sensors, which is to be fused with data from external sensors directly, or preprocessed with EKF first. Due to its unguaranteed convergence and robustness of tracking state mutations, EKF is insufficient. Therefore, we study state estimation for hydraulic quadruped robot based on the fusion of IMU measurement and leg odometry in this paper, and Invariant Extended Kalman Filter (IEKF) is successfully applied to quadruped robots by using this method. Besides, neural networks are utilized to train the weight functions of foot force and the state of leg odometry, and our trained functions improve the accuracy of observation compared with common weight average methods. Finally, our experiments of accuracy show that the root mean square error of our method is significantly reduced and the absolute trajectory error is reduced by 30% compared to traditional IEKF. The algorithm achieves the drift per distance travelled below 4 cm/m. Moreover, it has good robustness.},
  archive      = {J_NCA},
  author       = {Yang, Shangru and Yang, Qingjun and Zhu, Rui and Zhang, Zhenyang and Li, Congfei and Liu, Hu},
  doi          = {10.1007/s00521-023-08755-y},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2231-2244},
  shortjournal = {Neural Comput. Appl.},
  title        = {State estimation of hydraulic quadruped robots using invariant-EKF and kinematics with neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Slime mold optimization with hybrid deep learning enabled
crowd-counting approach in video surveillance. <em>NCA</em>,
<em>36</em>(5), 2215–2229. (<a
href="https://doi.org/10.1007/s00521-023-09083-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting (CC) and density estimation are crucial for ensuring public safety and security in surveillance videos with large audiences. As computer vision-based scene interpretation advances, automatic analysis of crowd situations is becoming increasingly prevalent. However, existing crowd analysis algorithms may not accurately interpret the video footage. To address this challenge, we propose a new approach called SMOHDL-CCA. This approach combines a Slime Mold Optimization algorithm with a Hybrid Deep Learning Enabled CC Approach. Our system uses the SMO algorithm with an optimized neural network search network (NASNet) model as the front-end to take advantage of transfer learning and flexible characteristics. The back-end model employs Dilated Convolutional Neural Networks, and the hyperparameter tuning process is done using the Chicken Swarm Optimization algorithm. Given a crowded video input frame, our SMOHDL-CCA model estimates the density map of the image. Each pixel value indicates the crowd density at the corresponding location in the picture. The final crowd count is obtained by summing all the values in the density map. We evaluated our proposed approach using three standard datasets. Furthermore, the state-of-the-art combining the proposed SMOHDL-CCA model achieves comparable performance such as improved precision is 96.97%, recall is 96.94%, and F1 score is 96.61%, reduced mean squared error of 61.15 values for the NWPU-crowd, UCF_QNRF, and World Expo datasets.},
  archive      = {J_NCA},
  author       = {Xu, Zheng and Jain, Deepak Kumar and Shamsolmoali, Pourya and Goli, Alireza and Neelakandan, Subramani and Jain, Amar},
  doi          = {10.1007/s00521-023-09083-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2215-2229},
  shortjournal = {Neural Comput. Appl.},
  title        = {Slime mold optimization with hybrid deep learning enabled crowd-counting approach in video surveillance},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploration of intelligent housing price forecasting based
on the anchoring effect. <em>NCA</em>, <em>36</em>(5), 2201–2214. (<a
href="https://doi.org/10.1007/s00521-023-08823-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The investigation of how to accurately predict the sale price of houses is the main objective of our work. Accurate secondhand housing price appraisal is critical in secondhand housing deals, mortgages, and risk assessment. Due to the complex composition of real estate prices, the difficulty of obtaining data and the lack of effective algorithms, the accurate appraisal of housing prices is still a challenge. Based on the hedonic model, the anchoring effect is added to the structure and location characteristics in this work. The 2SFCA algorithm is introduced into the location feature index to filter the influence of the accessibility index. Our model was trained using a variety of machine learning models, such as linear regression and random forest, and the results were evaluated to determine a suitable algorithm for building a secondhand housing transaction price forecasting model. The results showed that the prediction accuracy of the price prediction model could be improved by adding the facility accessibility index, and when the anchoring effect is added to the price prediction model, the prediction accuracy of the model could increase to 0.89. In comparing the results of various machine learning algorithms, we found that the ETR, RFR, and GBR models had better prediction results, and the accuracy rate could reach 0.9. In the end, a case study in Shenzhen was utilized to show that our proposed framework for predicting the price of secondhand houses, which integrated behavioral economics, hedonic price theory, and machine learning algorithms, was practical and efficient and can effectively improve the efficiency and accuracy of the evaluation.},
  archive      = {J_NCA},
  author       = {Song, Yi and Ma, Xiaomeng},
  doi          = {10.1007/s00521-023-08823-3},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2201-2214},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploration of intelligent housing price forecasting based on the anchoring effect},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pricing strategies for remanufacturing with government
incentives. <em>NCA</em>, <em>36</em>(5), 2187–2200. (<a
href="https://doi.org/10.1007/s00521-023-08804-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Government incentives play an important role in the development of the remanufacturing industry. It remains a challenge to determine an optimal policy (subsidy and/or tax refund) and how firms (manufacturers and retailers) can integrate it into their pricing decisions. We analyze the impacts of government financial incentives on manufacturers’ and retailers’ pricing decisions in terms of corporate profits and social welfare under different scenarios. We find that government incentives increase the recycling price and availability of used products, while the wholesale and retail prices of new products remain unchanged. Government incentives also significantly increase the manufacturer’s profits and enhance social welfare.},
  archive      = {J_NCA},
  author       = {Hao, Hui and Ran, Gang and Liu, Hui-min and Han, Henry and Gu, Qiannong},
  doi          = {10.1007/s00521-023-08804-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2187-2200},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pricing strategies for remanufacturing with government incentives},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain-enabled q&amp;a communities: The impact of task
technology matching on willingness to share knowledge. <em>NCA</em>,
<em>36</em>(5), 2171–2186. (<a
href="https://doi.org/10.1007/s00521-023-08618-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Q&amp;A communities provide Internet users with an online platform for knowledge dissemination, communication and sharing. The characteristics of blockchain technology, such as untampered, traceability, and data up-chaining, can help solve the problems of knowledge privacy protection, affirming knowledge Ownership, and trust deficit faced by users when sharing knowledge in traditional online Q&amp;A communities, and enhance users’ willingness to share knowledge on the platform. Studying users’ perceived characteristics and usage attitudes toward blockchain embedded in online platforms is important for enhancing users’ willingness to share knowledge and exploring the management mechanism of blockchain technology on online platforms. Based on the task-technology matching theory and technology acceptance model, this paper explores the impact of task-technology matching on users’ perceived characteristics and digs deeper into how users’ perceived characteristics of blockchain technology affect users’ usage attitudes and thus stimulate users’ willingness to share knowledge. Task-technology matching also positively influences users’ willingness to share knowledge by positively affecting perceived characteristics and users’ attitudes toward using. The findings of the study provide inspiration and guidance on how platforms can use new technologies to enhance users’ willingness to share knowledge.},
  archive      = {J_NCA},
  author       = {Zhang, Shengtai and Shi, Wenjuan and Zhang, Mengtao},
  doi          = {10.1007/s00521-023-08618-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2171-2186},
  shortjournal = {Neural Comput. Appl.},
  title        = {Blockchain-enabled Q&amp;A communities: The impact of task technology matching on willingness to share knowledge},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine reading comprehension model based on query
reconstruction technology and deep learning. <em>NCA</em>,
<em>36</em>(5), 2155–2170. (<a
href="https://doi.org/10.1007/s00521-023-08698-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine reading comprehension is introduced to improve machines’ readability and understandability of human languages. This sophisticated version of natural language processing is used for testing and improving the machine’s efficiency for reading and responding to the input texts for appropriate queries. In this article, a persistent comprehensive model using query reconstruction is introduced to address the “Cloze Style” issue in text reading. This issue results in multiple output delivery that serves as irrelevant for different input queries. Therefore, the query reconstruction using the possible combination, reducing the aforementioned issue, is introduced in this model. The possible query keywords are replaced using the maximum individual combinations. The combinations are swapped using deep learning through keyword training and substitution processes. This process is persistent until the maximum text output (answer/ response) is obtained from the machine. The output is used for analyzing the understandability of the machine based on which the training intensity is tuned for successive iterations. Therefore, the proposed model scrutinizes output accuracy by reducing errors under controlled combination time.},
  archive      = {J_NCA},
  author       = {Wang, Pengming and Kamruzzaman, M. M. and Chen, Qing},
  doi          = {10.1007/s00521-023-08698-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2155-2170},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine reading comprehension model based on query reconstruction technology and deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the distributed learning on federated learning and
cluster computing via convolutional neural networks. <em>NCA</em>,
<em>36</em>(5), 2141–2153. (<a
href="https://doi.org/10.1007/s00521-023-09160-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed learning has led to the development of federated learning and cluster computing; however, the two methods are very different. Therefore, this study uses a deep learning approach to investigate the distinction between federated learning and cluster computing. Specifically, the LeNet convolutional neural network model is used. Three frameworks were tested, including Spark on Hadoop with four nodes, PySyft with four nodes, and native PyTorch with a single node. The results show that Spark on Hadoop can accelerate performance and facilitate applications that have large memory requirements. In addition, PySyft can protect data privacy but is slower than Spark on Hadoop and native PyTorch. The three frameworks performed comparable accuracy for IID distributions, while PySyft had the worst for non-IID data. Therefore, if excluding sensitive data does not significantly affect training results, the results suggest that cluster computing, Spark on Hadoop, is recommended. However, federated learning, PySyft, is recommended in cases where sensitive data is required for training or positively affects training results, and time constraints are not an issue.},
  archive      = {J_NCA},
  author       = {Chang, Jia-Wei and Hung, Jason C. and Chu, Ting-Hong},
  doi          = {10.1007/s00521-023-09160-1},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2141-2153},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exploring the distributed learning on federated learning and cluster computing via convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method with constraints embedded into a cuckoo
search for steelmaking–continuous casting scheduling. <em>NCA</em>,
<em>36</em>(5), 2131–2140. (<a
href="https://doi.org/10.1007/s00521-023-08973-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Featured by multi-charge, multi-process integration, multi-constraint, steelmaking and continuous casting (SCC) scheduling is a complex and industrial synthesis process. Generally, it is solved by the two-stage or multistage approach. To reduce time consumption, we propose a “one-stage” optimization method that integrates the constraints into the cuckoo search algorithm (CICSA). To obtain the minimum total waiting time (TWT), we built an SCC scheduling optimization model. Firstly, we integrate machine uniqueness constraints and the process sequence into the coding of the nests. Then, non-conflict constraints and casting on time constraints are converted into the fitness values of the cuckoo search algorithm (CSA). Thus, the solutions obtained in the population after iteration meet the process constraints. The non-conflict optimal nest is taken as the optimal solution. Simulations are conducted using the actual industrial data. Comparisons among the proposed algorithm, the two-stage algorithm, and the original CSA are presented. The result shows the proposed approach achieves better performance.},
  archive      = {J_NCA},
  author       = {Wang, Haihong and Feng, Hui and Ren, Zhikao and Ye, Chen and Zhao, Tongtong and Sun, Yue and Wang, Xiuying},
  doi          = {10.1007/s00521-023-08973-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2131-2140},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel method with constraints embedded into a cuckoo search for steelmaking–continuous casting scheduling},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prototype selection for multi-label data based on label
correlation. <em>NCA</em>, <em>36</em>(5), 2121–2130. (<a
href="https://doi.org/10.1007/s00521-023-08617-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, the training data is typically large-scale and contains numerous noisy and redundant instances. Directly inducing a classifier with raw data can result in higher memory overhead and lower classification performance. One effective method to alleviate these problems is prototype selection, which reduces the number of instances. However, most existing multi-label prototype selection algorithms transform the multi-label data set into a single-label one using problem transformation methods, which may ignore the label correlation and lead to suboptimal prototype selection. To overcome this limitation, we propose a new method called CO-GCNN, i.e., multi-label prototype selection with Co-Occurrence and Generalized Condensed Nearest Neighbor. The CO-GCNN represents label correlation by calculating the co-occurrence rate of pairwise labels and dividing the original data into positive and negative classes. Then, the prototype selection process is performed using the generalized condensed nearest neighbor rule to obtain a reduced set of instances. Experiments on six multi-label benchmark datasets show that the classifier derived from the reduced set outperforms the classifier derived from the original data, confirming the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Li, Haikun and Fang, Min and Li, Hang and Wang, Peng},
  doi          = {10.1007/s00521-023-08617-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2121-2130},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prototype selection for multi-label data based on label correlation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue on machine learning and big data analytics for
IoT security and privacy (SPIoT2022). <em>NCA</em>, <em>36</em>(5),
2119–2120. (<a
href="https://doi.org/10.1007/s00521-023-09357-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhao, Jinghua},
  doi          = {10.1007/s00521-023-09357-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {5},
  pages        = {2119-2120},
  shortjournal = {Neural Comput. Appl.},
  title        = {Special issue on machine learning and big data analytics for IoT security and privacy (SPIoT2022)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Breast lesion classification from mammograms using deep
neural network and test-time augmentation. <em>NCA</em>, <em>36</em>(4),
2101–2117. (<a
href="https://doi.org/10.1007/s00521-023-09165-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to effectively aid in the automatic classification of the breast cancer suspicious region, a new deep-learning (DL) model built on the transfer-learning (TL) technique is proposed in this work. Pretrained convolutional neural networks (CNN) architectures, such as VGG-16, ResNet-50, Inception-V3, and Efficientnet-B7 are used in the proposed model to extract the features from the MIAS and CBIS-DDSM datasets. Three scenarios are used to evaluate the performance of each network under consideration: TL for the original dataset, TL for the pre-processed dataset, and a novel approach of TL with test time augmentation (TTA). Concerning limited training datasets, the proposed approach showed that pre-trained classification networks with test time augmentation are much more effective and efficient, making them more acceptable for medical imaging. With accuracy (99.97%), specificity (99.24%), sensitivity (98.50%), and F1-score (98.74%), the proposed test time augmentation strategy with transfer learning outperforms other state-of-the-art methods on the MIAS dataset. The proposed model could also do well on the CBIS-DDSM dataset with accuracy (99.8%), specificity (95.44%), sensitivity (96.57%), and F1-score (97.22%). Additionally, on the mammography predictions provided by our algorithm, we also sought the advice of a radiology professional. The model’s predictions and the expert’s assessment are almost in sync.},
  archive      = {J_NCA},
  author       = {Oza, Parita and Sharma, Paawan and Patel, Samir},
  doi          = {10.1007/s00521-023-09165-w},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {2101-2117},
  shortjournal = {Neural Comput. Appl.},
  title        = {Breast lesion classification from mammograms using deep neural network and test-time augmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated convolutional neural network with attention
guidance for improved performance of medical image classification.
<em>NCA</em>, <em>36</em>(4), 2067–2099. (<a
href="https://doi.org/10.1007/s00521-023-09164-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, it becomes essential to develop computer vision algorithms that are both highly effective and cost-effective for supporting physicians&#39; decisions. Convolutional Neural Network (CNN) is a deep learning architecture that enables learning relevant imaging features by simultaneously optimizing feature extraction and classification phases and has a high potential to meet this need. On the other hand, the lack of low- and high-level local details in a CNN is an issue that can reduce the task performance and prevent the network from focusing on the region of interest. To tackle this issue, we propose an attention-guided CNN architecture, which combines three lightweight encoders (the ensembled encoder) at the feature level to consolidate the feature maps with local details in this study. The proposed model is validated on the publicly available data sets for two commonly studied classification tasks, i.e., the brain tumor and COVID-19 disease classification. Performance improvements of 2.21% and 1.32%, respectively, achieved for brain tumor and COVID-19 classification tasks confirm our assumption that combining encoders recovers local details missed in a deeper encoder. In addition, the attention mechanism used after the ensembled encoder further improves performance by 2.29% for the brain tumor and 6.13% for the COVID-19 classification tasks. Besides that, our ensembled encoder with the attention mechanism enhances the focus on the region of interest by 4.4% in terms of the IoU score. Competitive performance scores accomplished for each classification task against state-of-the-art methods indicate that the proposed model can be an effective tool for medical image classification.},
  archive      = {J_NCA},
  author       = {Öksüz, Coşku and Urhan, Oğuzhan and Güllü, Mehmet Kemal},
  doi          = {10.1007/s00521-023-09164-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {2067-2099},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated convolutional neural network with attention guidance for improved performance of medical image classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discriminative latent subspace learning with adaptive metric
learning. <em>NCA</em>, <em>36</em>(4), 2049–2066. (<a
href="https://doi.org/10.1007/s00521-023-09159-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Least squares regression (LSR) has been widely used in the field of pattern recognition. However, LSR-based classifier still suffers from the following issues. One is that it focuses only on the dependency between the input data and the output targets, while overlooking the local structure of instances. Another one is that using binary labels as the regression targets is too strict to fully exploit the discriminative information of the data. To address these issues, we propose a novel multiclass classification method called discriminative latent subspace learning with adaptive metric learning (DLSAML). Specifically, DLSAML adaptively learns a metric matrix for the residuals between inputs and outputs, driving smaller distances between instances of the same class and larger distances between instances of different classes in the output space. To solve the second problem, latent representations are learnt guided by the pairwise label relations as the regression targets, allowing for more flexible use of discriminative information in the data. As a combination of these two techniques, the interactive optimization of the projection matrix and metric matrix allows DLSAML to fully exploit the structural and supervised information of the data to obtain a more discriminative latent subspace for multiclass classification. Extensive experiments on several benchmark datasets have demonstrated the effectiveness of the proposed method.},
  archive      = {J_NCA},
  author       = {Ma, Jiajun and Tang, Yuan Yan and Shang, Zhaowei},
  doi          = {10.1007/s00521-023-09159-8},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {2049-2066},
  shortjournal = {Neural Comput. Appl.},
  title        = {Discriminative latent subspace learning with adaptive metric learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intelligent machine learning-enabled cattle reclining
risk mitigation technique using surveillance videos. <em>NCA</em>,
<em>36</em>(4), 2029–2047. (<a
href="https://doi.org/10.1007/s00521-023-09143-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public highways are, in reality, the cornerstone of the country&#39;s transportation system. Accidents are unavoidable with this mode of transportation. Collisions involving resting livestock on national highways occur in most countries around the world. It endangers both the drivers and the animals. This paper proposes a method for mitigating the risk of accidents caused by deceased animals, notably cattle that are generating traffic and congestion on national highways and may constitute a safety risk. We have proposed an Internet of Things (IoT) fog-based framework for reclining livestock identification techniques for roadways, data are collected using the IoT-enabled video recording surveillance cameras. We use feature extraction, characteristic expression, assessment criteria, and an unrestricted approach for detecting deceased livestock (such as cows or buffalos), as well as recommendations on whether their placement is harmful to highway traffic. In this study, you only look once (YOLO) image recognition algorithm is implemented for reclining cattle on roadways using the fog layer for training and evaluating datasets. The performance parameters of the proposed framework, such as accuracy, recall, precision, mean average precision (mAP), and interference time, have been measured, and a comparison with existing state-of-the-art techniques has been presented. The obtained findings indicate that the suggested framework surpasses the present approaches, with a higher accuracy of 98% and an interference time of 4.68 ms. Artificially intelligent surveillance system can spot reclined livestock utilizing surveillance videos on roadways. This will ensure passenger safety as well as the safety of roadside cattle.},
  archive      = {J_NCA},
  author       = {Saini, Munish and Singh, Harpreet and Sengupta, Eshan and Aggarwal, Ashutosh and Singh, Harnoor and Kumar, Neeraj},
  doi          = {10.1007/s00521-023-09143-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {2029-2047},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intelligent machine learning-enabled cattle reclining risk mitigation technique using surveillance videos},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning from constraints and focal entity
shifting in conversational KGQA. <em>NCA</em>, <em>36</em>(4),
2015–2028. (<a
href="https://doi.org/10.1007/s00521-023-09138-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The actual needs of users for information are often hidden in multiple question answering (QA) on the same topic. In order to generate answers to users’ current questions, a conversational QA system relies on getting external information from a knowledge graph (KG) and combining it with conversation history. Therefore, how to make full use of the information of KG and combining it with the conversation environment is the top priority. In a conversational knowledge graph question answering (KGQA) scenario, the follow-up questions are often incomplete and may contain a shift of focal entity. Considering and processing the constrained information which plays the key role in solving complex conversational KGQA is very important. In this paper, we propose a reinforcement learning (RL) model, which uses a dynamically maintained context entity set to capture the shift of the focal entity in the process of conversation. We then use the bidirectional encoder representations from transformers (BERT) pre-training model to obtain the semantic information from context questions and KG paths. Our model learns from not only the 1-hop path but also 2-hop path constraint of the KG at the same time and gives reward rules based on precision and certain rules, respectively. Compared with state-of-the-art methods on ConvQuestions, our model improves mean reciprocal rank (MRR) and precision at 1 (P@1) by a margin of 4.7 $$\%$$ and 4.3 $$\%$$ , respectively. Experimental results on two datasets demonstrate the effectiveness of our proposed approach.},
  archive      = {J_NCA},
  author       = {Xu, Xirong and Xu, Tao and Wang, Ziming and Li, Haochen and Zhu, Li and Wei, Xiaopeng},
  doi          = {10.1007/s00521-023-09138-z},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {2015-2028},
  shortjournal = {Neural Comput. Appl.},
  title        = {Reinforcement learning from constraints and focal entity shifting in conversational KGQA},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of gender recognition system using quantum-based deep
learning. <em>NCA</em>, <em>36</em>(4), 1997–2014. (<a
href="https://doi.org/10.1007/s00521-023-09213-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric authentication systems identify or verify a person from a digital image taken by security cameras or fingerprint readers. Digital images are used for authentication wherever a security system exists, such as in airports and banks. Although biometric data authentication boosts security, it has several practical challenges and is a difficult problem in computer vision. Another application classifies biometric data according to certain characteristics such as age, gender, or race. One of the biometric data frequently used for this purpose and has become very important is face images. Deep learning systems can learn rich, compact representations of faces from very big face datasets, allowing people to surpass their facial analysis talents. The Convolutional Neural Network (CNN) has recently obtained very promising face analysis results among these methods. Although CNN has the beneficial use of the data’s correlation information, it has trouble learning efficiently when the supplied amount of the data or model is too huge. Quantum Convolutional Neural Network (QCNN) provides a new solution to a CNN-related problem using a quantum computing environment. In this study, gender recognition is performed with CNN and QCNN algorithms, and the results are compared in terms of time and accuracy. The purpose of the study is to show the comparative evaluation of QCNN and its classical counterpart CNN algorithms with detailed applications under the same conditions. 92% accuracy for QCNN and 90% accuracy for CNN are obtained. The total processing time is 128.85 s for QCNN and 832.30 s for CNN.},
  archive      = {J_NCA},
  author       = {Çavşi Zaim, Hande and Yılmaz, Metin and Yolaçan, Esra Nergis},
  doi          = {10.1007/s00521-023-09213-5},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1997-2014},
  shortjournal = {Neural Comput. Appl.},
  title        = {Design of gender recognition system using quantum-based deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning modelling of dew point pressure in gas
condensate reservoirs: Application of decision tree-based models.
<em>NCA</em>, <em>36</em>(4), 1973–1995. (<a
href="https://doi.org/10.1007/s00521-023-09201-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In gas condensate reservoirs, the dew point pressure (PDew) plays a significant role in gas and liquid assessment, reservoir characterisation, surface facility design, and reservoir simulation. Although field and laboratory measurements of PDew give accurate results, both approaches are time-consuming and resource-intensive; hence, a fast and accurate determination of PDew is very important. Equation of states (EoS) and empirical correlations are other alternative methods that are used for PDew determination. However, these methods are unable to fully capture the non-linear and complex relationships between fluid composition and PDew. Machine Learning (ML) methods, as reliable tools, have emerged in different aspects of engineering. In this study, for the first time, the application of different decision tree-based methods for the prediction of PDew is investigated. A comprehensive database, containing 681 samples (almost all the available experimental data set of pure and impure samples published from 1942 to 2018), is collected from open literature and different decision tree-based methods namely Decision Tree (DT), Random Forest (RF), Gradient Boosting (GB), and Extremely Randomised Tree (ET) are used for modelling. The statistical analysis of developed models&#39; performance showed that the ET method yields the best predictions by Root Mean Squared Error (RMSE) and R2 values of 441 psi and 0.9227, respectively for the testing dataset. Moreover, the results show that the novel ET model has a better performance compared with existing models in the literature and EoSs for the prediction of PDew of gas condensate reservoirs.},
  archive      = {J_NCA},
  author       = {Esmaeili-Jaghdan, Zohre and Tatar, Afshin and Shokrollahi, Amin and Bon, Jan and Zeinijahromi, Abbas},
  doi          = {10.1007/s00521-023-09201-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1973-1995},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning modelling of dew point pressure in gas condensate reservoirs: Application of decision tree-based models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A WSFA-based adaptive feature extraction method for
multivariate time series prediction. <em>NCA</em>, <em>36</em>(4),
1959–1972. (<a
href="https://doi.org/10.1007/s00521-023-09198-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial neural networks (ANNs) have been successfully and widely used in multivariate time series prediction, but the accuracy of the prediction is significantly affected by the ANNs’ input. In order to determine the appropriate input for more accurate prediction, a weighted slow feature analysis-based adaptive feature extraction (WSFA-AFE) method is proposed for multivariate time series prediction. Firstly, the weighted SFA (WSFA) algorithm is developed to extract slow features weighted by their contributions. Then, an improved adaptive sliding window algorithm is designed to self-determine the historical information of slow features for input. Finally, the out-of-model performance of the WSFA-AFE method is verified by applying it to different ANN models with several benchmark data sets as well as a practical dataset in wastewater treatment process. The results indicate that a better modeling performance of ANNs for multivariate time series prediction can be obtained by the WSFA-AFE method, which can adaptively extract feature variables from the multivariate time series. Besides, the robustness of the proposed method is demonstrated as well.},
  archive      = {J_NCA},
  author       = {Yang, Shuang and Li, Wenjing and Qiao, Junfei},
  doi          = {10.1007/s00521-023-09198-1},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1959-1972},
  shortjournal = {Neural Comput. Appl.},
  title        = {A WSFA-based adaptive feature extraction method for multivariate time series prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 1D-convolutional transformer for parkinson disease diagnosis
from gait. <em>NCA</em>, <em>36</em>(4), 1947–1957. (<a
href="https://doi.org/10.1007/s00521-023-09193-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an efficient deep neural network model for diagnosing Parkinson’s disease from gait. More specifically, we introduce a hybrid ConvNet-Transformer architecture to accurately diagnose the disease by detecting the severity stage. The proposed architecture exploits the strengths of both convolutional neural networks and Transformers in a single end-to-end model, where the former is able to extract relevant local features from Vertical Ground Reaction Force (VGRF) signal, while the latter allows to capture long-term spatio-temporal dependencies in data. In this manner, our hybrid architecture achieves an improved performance compared to using either models individually. Our experimental results show that our approach is effective for detecting the different stages of Parkinson’s disease from gait data, with a final accuracy of 88%, outperforming other state-of-the-art AI methods on the Physionet gait dataset. Moreover, our method can be generalized and adapted for other classification problems to jointly address the feature relevance and spatio-temporal dependency problems in 1D signals. Our source code and pre-trained models are publicly available at https://github.com/SafwenNaimi .},
  archive      = {J_NCA},
  author       = {Naimi, Safwen and Bouachir, Wassim and Bilodeau, Guillaume-Alexandre},
  doi          = {10.1007/s00521-023-09193-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1947-1957},
  shortjournal = {Neural Comput. Appl.},
  title        = {1D-convolutional transformer for parkinson disease diagnosis from gait},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight transformer and multi-head prediction network
for no-reference image quality assessment. <em>NCA</em>, <em>36</em>(4),
1931–1946. (<a
href="https://doi.org/10.1007/s00521-023-09188-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No-reference (NR) image quality assessment (IQA) is an important task of computer vision. Most NR-IQA methods via deep neural networks do not reach desirable IQA performance and have bulky models which make them difficult to be used in the practical scenarios. This paper proposes a lightweight transformer and multi-head prediction network for NR-IQA. The proposed method consists of two lightweight modules: feature extraction and multi-head prediction. The module of feature extraction exploits lightweight transformer blocks to learn features at different scales for measuring different image distortions. The module of multi-head prediction uses three weighted prediction blocks and an FC layer to aggregate the learned features for predicting image quality score. The weighted prediction block can measure the importance of different elements of input feature at the same scale. Since the importance of feature elements at the same scale and the importance of the features at different scales are both considered, the module of multi-head prediction can provide more accurate prediction results. Extensive experiments on the standard IQA datasets are conducted. The results show that the proposed method outperforms some baseline NR-IQA methods in IQA performance on the large image datasets. For the model complexity, the proposed method is also superior to several recent NR-IQA methods.},
  archive      = {J_NCA},
  author       = {Tang, Zhenjun and Chen, Yihua and Chen, Zhiyuan and Liang, Xiaoping and Zhang, Xianquan},
  doi          = {10.1007/s00521-023-09188-3},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1931-1946},
  shortjournal = {Neural Comput. Appl.},
  title        = {Lightweight transformer and multi-head prediction network for no-reference image quality assessment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multilingual mixture attention interaction framework with
adversarial training for cross-lingual SLU. <em>NCA</em>,
<em>36</em>(4), 1915–1930. (<a
href="https://doi.org/10.1007/s00521-023-09132-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual spoken language understanding (cross-lingual SLU), as a key component of task-oriented dialogue systems, is widely used in various industrial and real-world scenarios, such as multilingual customer support systems, cross-border communication platforms, and international language learning tools. However, obtaining large-scale and high-quality datasets for SLU is challenging due to the high cost of dialogue collection and manual annotation, particularly for minority languages. As a result, there is increasing interest in leveraging high-resource language data for cross-lingual transfer learning. Existing approaches for zero-shot cross-lingual SLU primarily focus on the relationship between the source language sentence and the single generated cross-lingual sentence, disregarding the shared information among multiple languages. This limitation weakens the robustness of multilingual word embedding representations and hampers the scalability of the model. In this paper, we propose the multilingual mixture attention interaction framework with adversarial training to alleviate the above problems. Specifically, we leverage the source language sentence to generate multiple multilingual hybrid sentences, in which words can adaptively capture unambiguous representations from the aligned multilingual words during the encoding phase, and adversarial training is introduced to enhance the scalability of the model. Then, we incorporate the symmetric kernel self-attention module with positional embedding to learn contextual information within a sentence, and employ the multi-relation graph convolutional networks to learn different granularity information between two highly correlated intent detection and slot filling tasks. Experimental results on the public dataset MultiATIS++ demonstrate that our proposed model achieves state-of-the-art performance, and comprehensive analysis validates the effectiveness of each component.},
  archive      = {J_NCA},
  author       = {Zhang, Qichen and Wang, Shuai and Li, Jingmei},
  doi          = {10.1007/s00521-023-09132-5},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1915-1930},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multilingual mixture attention interaction framework with adversarial training for cross-lingual SLU},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning approach for early detection of drought
stress in maize using proximal scale digital images. <em>NCA</em>,
<em>36</em>(4), 1899–1913. (<a
href="https://doi.org/10.1007/s00521-023-09219-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural computing methods pose an edge over conventional methods for drought stress identification because of their ease of implementation, accuracy, non-invasive approach, cost-effectiveness, and ability to predict in real time. To ensure proper irrigation scheduling and prevent major yield losses, the objective was to develop a deep learning (DL)-based custom convolutional neural network (CNN) framework for in situ identification and classification of drought stress in maize crops. An original image dataset was created by acquiring 2703 RGB images of maize crops under natural daylight conditions to incorporate noise and varied backgrounds. The dataset was augmented and divided in a ratio of 7:2:1 for the training, validation, and test sets. A custom-CNN model was built using feature blocks, fully connected layers, and dense layers, and compared with five state-of-the-art CNN architectures, i.e. InceptionV3, Xception, ResNet50, DenseNet121 and EfficientNetB1. The results revealed that the custom CNN model achieved accuracies of 98.71% and 98.53% on the training and test sets, respectively. In comparison, the ResNet50 and EfficientNetB1 transfer-learned CNN architectures achieved an equivalent accuracy of 99.26% each, followed by DenseNet121 with a 98.90% accuracy on the test set. The Xception model performed the worst, with the highest accuracy of 91.91% on the test set. The results demonstrate that the developed custom CNN model should be adopted for real-time implementation on resource-constrained edge devices because of the lower number of parameters (0.65 million parameters) compared to other state-of-the-art architectures.},
  archive      = {J_NCA},
  author       = {Goyal, Pooja and Sharda, Rakesh and Saini, Mukesh and Siag, Mukesh},
  doi          = {10.1007/s00521-023-09219-z},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1899-1913},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning approach for early detection of drought stress in maize using proximal scale digital images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A network analysis-based framework to understand the
representation dynamics of graph neural networks. <em>NCA</em>,
<em>36</em>(4), 1875–1897. (<a
href="https://doi.org/10.1007/s00521-023-09181-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a framework that uses the theory and techniques of (Social) Network Analysis to investigate the learned representations of a Graph Neural Network (GNN, for short). Our framework receives a graph as input and passes it to the GNN to be investigated, which returns suitable node embeddings. These are used to derive insights on the behavior of the GNN through the application of (Social) Network Analysis theory and techniques. The insights thus obtained are employed to define a new training loss function, which takes into account the differences between the graph received as input by the GNN and the one reconstructed from the node embeddings returned by it. This measure is finally used to improve the performance of the GNN. In addition to describe the framework in detail and compare it with related literature, we present an extensive experimental campaign that we conducted to validate the quality of the results obtained.},
  archive      = {J_NCA},
  author       = {Bonifazi, Gianluca and Cauteruccio, Francesco and Corradini, Enrico and Marchetti, Michele and Ursino, Domenico and Virgili, Luca},
  doi          = {10.1007/s00521-023-09181-w},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1875-1897},
  shortjournal = {Neural Comput. Appl.},
  title        = {A network analysis-based framework to understand the representation dynamics of graph neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SMP-DL: A novel stock market prediction approach based on
deep learning for effective trend forecasting. <em>NCA</em>,
<em>36</em>(4), 1849–1873. (<a
href="https://doi.org/10.1007/s00521-023-09179-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the economy has grown rapidly in recent years, more and more people have begun putting their money into the stock market. Thus, predicting trends in the stock market is regarded as a crucial endeavor, and one that has proven to be more fruitful than others. Profitable investments will result in rising stock prices. Investors face significant difficulties making stock market-related predictions due to the lack of movement and noise in the data. In this paper, a new system for predicting stock market prices is introduced, namely stock market prediction based on deep leaning (SMP-DL). SMP-DL splits into two stages, which are (i) data preprocessing (DP) and (ii) stock price’s prediction (SP2). In the first stage, data are preprocessed to obtain cleaned ones through several stages which are detect and reject missing value, feature selection, and data normalization. Then, in the second stage (e.g., SP2), the cleaned data will pass through the used predicted model. In SP2, long short-term memory (LSTM) combined with bidirectional gated recurrent unit (BiGRU) to predict the closing price of stock market. The obtained results showed that the proposed system perform well when compared to other existing methods. As RMSE, MSE, MAE, and R2 values are 0.2883, 0.0831, 0.2099, and 0.9948. Moreover, the proposed method was applied using different datasets and it performs well.},
  archive      = {J_NCA},
  author       = {Shaban, Warda M. and Ashraf, Eman and Slama, Ahmed Elsaid},
  doi          = {10.1007/s00521-023-09179-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1849-1873},
  shortjournal = {Neural Comput. Appl.},
  title        = {SMP-DL: A novel stock market prediction approach based on deep learning for effective trend forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new approach to multi-objective optimization of a tapered
matrix distributed amplifier for UWB applications. <em>NCA</em>,
<em>36</em>(4), 1833–1847. (<a
href="https://doi.org/10.1007/s00521-023-09167-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using of ultra-wideband (UWB) technology in radio transceiver systems has increased in recent years due to high-speed data transmission, low power dissipation, low cost, and low complexity. In particular, distributed amplifier (DA) is a critical component of transceiver in UWB technology. However, designing an ultra-wideband DA with high performance becomes challenging. The DA design suffers from the tight trade-offs between the amplifier parameters such as gain, noise, linearity, input/output impedance matching, and power dissipation. In this paper, a new approach for multi-objective optimization of the DA is introduced. In the proposed approach, the meta-heuristic optimization techniques are applied over the entire bandwidth of the UWB, while the most recent optimization approaches for amplifiers are performed at the center frequency and they can’t achieve the proper design specifications for wideband amplifiers. The simultaneous optimization of power gain (S21), noise figure (NF), input and output return loss (S11 and S22) are conducted over the wide bandwidth using three multi-objective optimization algorithms including Multi-Objective Inclined Planes System Optimization (MOIPO), Non-dominated Sorting Genetic Algorithm II (NSGA-II), and Multi-Objective Particle Swarm Optimization (MOPSO). The obtained results demonstrate the tapered matrix DA optimized by MOIPO exhibits better performance than others. The circuit simulations are performed in 0.18 µm TSMC RF-CMOS technology. Simulation results show that the optimized tapered matrix DA by MOIPO, compared to NSGA-II and MOPSO, exhibits a good performance over the frequency band of 0.1–28 GHz with maximum S21 of 12.9 dB, NF less than 5.9 dB, S11 and S22 below than  − 10 dB over the whole frequency band. The DC power dissipation is 25 mW from a 1.5 V supply.},
  archive      = {J_NCA},
  author       = {Bijari, Abolfazl and Zandian, Salman and Soruri, Mohammad and Abbasi Avval, Somayye and Harifi-Mood, Mehrdad},
  doi          = {10.1007/s00521-023-09167-8},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1833-1847},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new approach to multi-objective optimization of a tapered matrix distributed amplifier for UWB applications},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SSR-TA: Sequence-to-sequence-based expert recurrent
recommendation for ticket automation. <em>NCA</em>, <em>36</em>(4),
1815–1832. (<a
href="https://doi.org/10.1007/s00521-023-09152-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ticket automation plays a crucial role in ensuring the normal operation of IT software systems. One of the key tasks of ticket automation is to assign experts to resolve incoming tickets. However, when facing a large number of tickets, inappropriate expert assignments can result in frequent ticket transfers between experts, leading to time delays and wasted resources. Therefore, it is essential to find an appropriate expert efficiently and effectively with minimal steps. To address this challenge, we propose a sequence-to-sequence-based translation model that is combined with a recurrent recommendation network to recommend suitable experts for tickets. The sequence-to-sequence model transforms the ticket description into the corresponding resolution for capturing the potential and useful features of representing tickets. The recurrent recommendation network recommends the appropriate expert based on the assumption that the previous expert in the recommendation sequence cannot solve the ticket. To evaluate the performance of our proposed model, we conducted experiments on two real-world datasets and compared SSR-TA with several baselines. The experimental results demonstrate that our proposed model outperforms the baselines.},
  archive      = {J_NCA},
  author       = {Cao, Chenhan and Fang, Xiaoyu and Luo, Bingqing and Xia, Bin},
  doi          = {10.1007/s00521-023-09152-1},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1815-1832},
  shortjournal = {Neural Comput. Appl.},
  title        = {SSR-TA: Sequence-to-sequence-based expert recurrent recommendation for ticket automation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster and efficient tetrahedral mesh generation using
generator neural networks for 2D and 3D geometries. <em>NCA</em>,
<em>36</em>(4), 1805–1813. (<a
href="https://doi.org/10.1007/s00521-023-09119-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulations are crucial for validating the design of engineering systems and their components. However, before simulations can be performed, the geometry of the component must undergo meshing, which involves dividing it into small elements to solve the Partial Differential Equations that describe the phenomenon being simulated. This process can be computationally expensive, so we propose a meshing algorithm that uses Generator Neural Networks to generate refined meshes. Our algorithm is based on a generator used in a Conditional Generative Adversarial Network, which was trained on reference meshes generated by conventional meshing codes. The proposed scheme generated mesh nodal coordinates for both 2D and 3D geometries, and the difference between the element quality of our meshes and the reference meshes used as training data was only 1%. Our algorithm was also 75% faster than the algorithm used to generate the training data meshes. We demonstrate that refined meshes can be generated without relying on computationally expensive solvers.},
  archive      = {J_NCA},
  author       = {Soman, Sumedh and Mehendale, Ninad},
  doi          = {10.1007/s00521-023-09119-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1805-1813},
  shortjournal = {Neural Comput. Appl.},
  title        = {Faster and efficient tetrahedral mesh generation using generator neural networks for 2D and 3D geometries},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid deep convolutional neural network model for
improved diagnosis of pneumonia. <em>NCA</em>, <em>36</em>(4),
1791–1804. (<a
href="https://doi.org/10.1007/s00521-023-09147-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumonia is an infection that inflames the air sacs in lungs and is one of the prime causes of deaths under the age of five, all over the world. Moreover, sometimes it became quite difficult to detect and diagnose pneumonia by just looking at the chest plain X-ray images. Therefore, we propose a hybrid deep convolutional neural network model (HDCNN) for improved diagnosis of pneumonia, to simplify the detection for medical practitioners and specialists. In this proposed model, image preprocessing is performed using Student&#39;s t distribution, a compact probability density function (cPDF), for better sampling and segregation between the healthy and infected part of lungs, to improve the predictions. Further, a hybrid deep convolutional neural network model is built to extract image features by fine-tuning the pretrained models, viz. Resnet-50, EfficientNet, VGG-16, MobileNetV2 and DenseNet to achieve better results of diagnosis. The proposed hybrid model is analyzed using Grad-CAM visualization, which produces a course localization map, highlighting the infected region in the image used for prediction. The proposed hybrid model is evaluated based on governing parameters, viz. precision, recall, F1-score and accuracy. The results show our proposed model achieves precision of 97.47%, recall 98.09%, F1-score of 97.77% and overall accuracy of 97.69% as compared to other existing models.},
  archive      = {J_NCA},
  author       = {Mann, Palvinder Singh and Panchal, Shailesh D. and Singh, Satvir and Saggu, Guramritpal Singh and Gupta, Keshav},
  doi          = {10.1007/s00521-023-09147-y},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1791-1804},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid deep convolutional neural network model for improved diagnosis of pneumonia},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impact of datasets on the effectiveness of MobileNet for
beans leaf disease detection. <em>NCA</em>, <em>36</em>(4), 1773–1789.
(<a href="https://doi.org/10.1007/s00521-023-09187-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bean is a widely cultivated crop worldwide; however, it is susceptible to various diseases that can adversely affect the quality of beans, including rust and angular leaf spot diseases. These diseases can cause significant damage by wiping out hectares of crops, emphasizing the need for early detection. Deep learning algorithms have shown remarkable performance in image detection tasks, achieving high accuracy on many datasets. This study used a deep learning technique, specifically the MobileNet architecture, to detect bean leaf disease. We evaluated the effectiveness of the approach by testing the model on three different bean leaf image datasets with varying difficulty. MobileNet was chosen due to its ability to achieve high performance with a reduced number of parameters and faster execution time. Additionally, we examined the impact of the datasets on the model’s performance and presented a comparative analysis of the three datasets, and then we applied the GradCAM technique to the model’s predictions. Experimental results showed that the proposed approach achieved remarkable accuracy, with over 92% accuracy on all three datasets. The study provides a valuable contribution to the field of plant disease detection and highlights the potential of deep learning techniques in detecting bean leaf disease.},
  archive      = {J_NCA},
  author       = {Elfatimi, Elhoucine and Eryiğit, Recep and Shehu, Harisu Abdullahi},
  doi          = {10.1007/s00521-023-09187-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1773-1789},
  shortjournal = {Neural Comput. Appl.},
  title        = {Impact of datasets on the effectiveness of MobileNet for beans leaf disease detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Genetic algorithm optimized a deep learning method with
attention mechanism for soil moisture prediction. <em>NCA</em>,
<em>36</em>(4), 1761–1772. (<a
href="https://doi.org/10.1007/s00521-023-09168-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and effective soil moisture prediction has gradually attracted attention due to the management of agricultural activities and the practical usage of water resources. Therefore, this research presents an integrated deep learning-based framework for soil moisture prediction, where long short-term memory (LSTM) layers, an attention mechanism, and fully connected layers are combined. In this framework, LSTM layers are applied to extract the complicated, long- and short-term dependencies from the time series soil moisture data. Besides, the attention mechanism is employed to learn the discriminative information from the extracted features. The genetic algorithm (GA), which aims to enhance the prediction accuracy, is applied to simultaneously determine the hyperparameters of the proposed network, called the GA-LSTM-ATT, consisting of the LSTM layer count, the hidden units in layers, the rate of dropout, and the learning rate. The experimental consequences have indicated that the GA-LSTM-ATT method outperforms the benchmark approaches in different evaluation indices.},
  archive      = {J_NCA},
  author       = {Kara, Ahmet and Pekel, Engin and Ozcetin, Erdener and Yıldız, Gazi Bilal},
  doi          = {10.1007/s00521-023-09168-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1761-1772},
  shortjournal = {Neural Comput. Appl.},
  title        = {Genetic algorithm optimized a deep learning method with attention mechanism for soil moisture prediction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fault distance estimation for transmission lines with
dynamic regressor selection. <em>NCA</em>, <em>36</em>(4), 1741–1759.
(<a href="https://doi.org/10.1007/s00521-023-09155-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transmission line is one of the most crucial electric power system components, demanding special attention since they are subject to failures that can cause disruptions in energy supply. In this scenario, the fault location emerges as a fundamental task, providing an approximate position where the failure occurred in the line. This paper presents a method for fault location using a novel dynamic regressor selection (DRS) framework, in which we introduce embedded normalization, incorporating the data scaling process inside the framework. The DRS aims to select the most accurate models from a pool of regressors to predict the fault distance. Moreover, since there is a lack of a public dataset, this paper presents and makes a new fault dataset available to the scientific community with several features extracted from current and voltage signals of representative failure events. In our experiments, we demonstrate the importance of this embedded normalization as well as the significance in the variation of critical hyperparameters of the DRS strategy, such as the distance metric used to define the region of competence and the criterion to select the best regressors from the pool of predictors. This work also presents the definition of the oracle concept in DRS, which represents the ideal predictor selection scheme. The results demonstrate the effectiveness of the proposed method with a mean error of 0.7086 km ± 0.0068 km, representing 0.1712% ± 0.0016% of the transmission line extension (414 km).},
  archive      = {J_NCA},
  author       = {Ensina, Leandro A. and Oliveira, Luiz E. S. de and Cruz, Rafael M. O. and Cavalcanti, George D. C.},
  doi          = {10.1007/s00521-023-09155-y},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1741-1759},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fault distance estimation for transmission lines with dynamic regressor selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robot arm damage detection using vibration data and deep
learning. <em>NCA</em>, <em>36</em>(4), 1727–1739. (<a
href="https://doi.org/10.1007/s00521-023-09150-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During robot operation, robot components like links and joints may experience collisions or excess loads that can lead to structural damages or cracks. A crack in a structural component can degrade the overall performance of the structure. This study examines the influence of cracks on the vibration characteristics of a baseline robot link. The approach uses the finite element method to simulate the dynamics of planar robot link models with and without artificial cracks with different sizes, locations, and orientations in the ABAQUS software. The robot link models include one intact model and five defective models with cracks. A rectangular crack with a fixed length of 1 mm and a varying width from 0.001 to 0.1 mm is applied to a specific location along the robot link. Finite element analysis and machine learning are used to simulate and characterize the vibration of each robot link with one fixed end and one free end. The vibration responses are measured at the free end. The measured vibration data are then transformed into two-dimensional (2D) image data using the Gramian Angular Summation Field method. A convolutional neural network is then trained with the image data for crack detection and analysis. The results indicate that the proposed method demonstrates 98.25% accuracy on the data generated by the simulation experiments.},
  archive      = {J_NCA},
  author       = {Ambaye, Getachew and Boldsaikhan, Enkhsaikhan and Krishnan, Krishna},
  doi          = {10.1007/s00521-023-09150-3},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1727-1739},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robot arm damage detection using vibration data and deep learning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A syntactic multi-level interaction network for rumor
detection. <em>NCA</em>, <em>36</em>(4), 1713–1726. (<a
href="https://doi.org/10.1007/s00521-023-09140-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online rumors could have a great impact on public order, stock prices and even the presidential election. Therefore, the detection of online rumors is imperative. Despite the satisfactory performance achieved by the current methods, there are still some issues that need to be addressed. First, most of the current methods have not taken into account imposing attentional constraints on important related words in the sentences, resulting in inaccurate attention being paid to some irrelevant words. Second, most of the current methods for detecting rumors fail to effectively incorporate contextual information from words or sentences. In this paper, we propose a syntactic multi-level interaction network model which incorporates syntactic dependency relationships and multi-level interaction network for rumor detection. First, the SMNet model uses a syntactic dependency parser to extract the corresponding syntactic sentence structures and incorporates the extracted syntactic dependency relationships into the attention mechanism for language-driven word representation. Then, the multi-level interaction network is applied to obtain a richer semantic representation. After that, the global relation encoding capture the rich structural information and the rumor classification is performed to generate the verification result. We have conducted experiments on Weibo, Twitter15 and Twitter16 datasets for performance evaluation. Our SMNet model has achieved an accuracy of 95.9% on the Weibo dataset. In addition, our SMNet model has achieved an accuracy of 91.7% and 93.5% on Twitter 15 and Twitter 16, respectively. The experimental results show that our proposed SMNet model outperforms the baseline models and achieves the state-of-the-art performance for rumor detection.},
  archive      = {J_NCA},
  author       = {Chen, Zhendong and Zhuang, Fuzhen and Liao, Lejian and Jia, Meihuizi and Li, Jiaqi and Huang, Heyan},
  doi          = {10.1007/s00521-023-09140-5},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1713-1726},
  shortjournal = {Neural Comput. Appl.},
  title        = {A syntactic multi-level interaction network for rumor detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigate the scale imbalance via multi-scale information
interaction in small object detection. <em>NCA</em>, <em>36</em>(4),
1699–1712. (<a
href="https://doi.org/10.1007/s00521-023-09122-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scale imbalance of the backbone and the neck is the main reason for the inferior accuracy of small object detection when using the general object detector. The general object detector usually contains a complex backbone and a lightweight neck, in which the complex backbone always costs large computational resource and the lightweight neck is hard to interact with deep semantic and shallow spatial information. Thus, the general object detector has severe scale imbalance in detecting small objects. Based on these, in this paper, we propose a novel detector named IUDet which includes a lightweight backbone and a complex neck. A novel sampling strategy is proposed, named pixel-spanning merge (PSM), in the lightweight backbone to save computational cost. In other side, it can transfer features of the scale dimension to the spatial dimension, thus enhancing information interaction. Moreover, the neck is designed with the element-wise sum of multi-scale features and an inverted U-shaped skip connection to improve the small object’s feature representation. The experimental results show that our IUDet outperforms the most popular detectors on MS COCO 2017 and VisDrone DET2019, in small object detection.},
  archive      = {J_NCA},
  author       = {Chai, Enhui and Chen, Li and Hao, Xingxing and Zhou, Wei},
  doi          = {10.1007/s00521-023-09122-7},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1699-1712},
  shortjournal = {Neural Comput. Appl.},
  title        = {Mitigate the scale imbalance via multi-scale information interaction in small object detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybridized intelligent multi-class classifiers for rockburst
risk assessment in deep underground mines. <em>NCA</em>, <em>36</em>(4),
1681–1698. (<a
href="https://doi.org/10.1007/s00521-023-09189-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rockburst hazard induced by the extreme release of the stress concentrated in rock mass in deep underground mines poses a significant threat to the safety and economy of the mining projects. Therefore, properly managing this hazard is critical for ensuring rock engineering projects’ sustainability. This study proposes comprehensible and practical classifiers for rockburst risk level appraisal by hybridizing K-means clustering with gene expression programming, GEP, logistic regression, LR, and classification and regression tree, CART (i.e., K-mean-GEP-LR and K-means-CART classifiers). A database containing 246 rockburst events with four risk levels of none, light, moderate, and severe was compiled from previous practices. Preliminary statistical analyses were conducted to detect the extreme outliers and determine the critical rockburst indicators. The K-means clustering analysis was performed to identify the main clusters within the database and relabel the rockburst events. The GEP algorithm was then utilized to develop binary models for predicting the occurrence of each class. Then, the likelihood of each class occurrence was determined using LR. Furthermore, the K-means clustering was combined with the CART algorithm to provide another visual tree structure model. The classifiers’ performance evaluation showed 96% and 95% accuracy values in the training and testing stages, respectively, for the K-means-GEP-LR model, while the accuracy values of 98.8% and 93.0% were obtained for the foregoing stages for the K-means-CART classifier. The results showed the robustness and high classification capability of both models. MatLab codes were also provided for the K-means-GEP-LR model, which assists other researchers/engineers in implementing the model in practice.},
  archive      = {J_NCA},
  author       = {Shirani Faradonbeh, Roohollah and Vaisey, Will and Sharifzadeh, Mostafa and Zhou, Jian},
  doi          = {10.1007/s00521-023-09189-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1681-1698},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hybridized intelligent multi-class classifiers for rockburst risk assessment in deep underground mines},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new framework for early diagnosis of breast cancer using
mammography images. <em>NCA</em>, <em>36</em>(4), 1665–1680. (<a
href="https://doi.org/10.1007/s00521-023-09156-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most common types of cancer in women. This type of cancer can be detected and treated at an early stage, and the quality of life of sick individuals can significantly improve. In addition to radiology specialists, tools that can help these specialists are also needed in early diagnosis. The proposed study includes a tool with a new framework that can help diagnose with maximum accuracy. This study uses a multi-class MIAS data set of benign, malignant, and normal mammography images. First, only the breast region is determined from the images in this data set with the help of morphological operations. The bicubic interpolation-based super-resolution method enhances the details of the detected areas. In addition, the success of classification methods is directly related to the diversity of the data set. Therefore, the images in the data set are enriched with different transformations. Another vital point for classification methods is the extraction of the feature vector. A unique feature vector consisting of 11 features is obtained in the created framework. Then, these feature vectors are separated into three classes separately by seven different classifiers tested in the created framework: KNN, SVM, NB, LDA, DT, ANN, and CNN. The optimal parameters of these classifiers are obtained by the Grid Search method. Finally, the classification results are evaluated using accuracy, precision, sensitivity, specificity, F-score, and time metrics. The evaluation results prove that the created framework is a successful aid in diagnosing breast cancer.},
  archive      = {J_NCA},
  author       = {Aymaz, Samet},
  doi          = {10.1007/s00521-023-09156-x},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1665-1680},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new framework for early diagnosis of breast cancer using mammography images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Proposed methodology for gait recognition using generative
adversarial network with different feature selectors. <em>NCA</em>,
<em>36</em>(4), 1641–1663. (<a
href="https://doi.org/10.1007/s00521-023-09154-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, investigating gait recognition as a biometric technology has become necessary, especially after the COVID-19 pandemic broke out in the world. This paper proposes a deep structure procedure for precise human identification from the walking manner quickly, as each human has a unique way of walking. The proposed generative adversarial network (GAN) generates gait images from pedestrians of the CASIA and OU-ISIR gait datasets for normalizing the number of frames in each class in both datasets. Then, we extract the gait features from the normalized datasets by the pretrained convolutional neural network (CNN) models; AlexNet, Inception, VGG16, VGG19, ResNet, and Xception, and balance them using the synthetic minority oversampling technique (SMOTE) to enhance the recognition results. Several feature selectors are selecting the best features, including particle swarm optimization (PSO), grey wolf optimization (GWO), Chi-square, and genetic models. Finally, the proposed deep neural network recognizes the gait images precisely. Several performance assessment measures were generated to assess the model&#39;s quality, including accuracy, precision, sensitivity, specificity, false negative rate (FNR), intersection of union (IoU), and time. Experimental results showed that the inception model with genetic feature selector performed better in all used datasets than the current studies and was more robust against any change, achieving 99.3%, 99.1%, and 99.09% accuracy in identifying CASIA-B, CASIA-A, and OU-ISIR datasets, respectively in low time.},
  archive      = {J_NCA},
  author       = {Yousef, Reem N. and Khalil, Abeer T. and Samra, Ahmed S. and Ata, Mohamed Maher},
  doi          = {10.1007/s00521-023-09154-z},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1641-1663},
  shortjournal = {Neural Comput. Appl.},
  title        = {Proposed methodology for gait recognition using generative adversarial network with different feature selectors},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A classification study for turkish folk music makam
recognition using machine learning with data augmentation techniques.
<em>NCA</em>, <em>36</em>(4), 1621–1639. (<a
href="https://doi.org/10.1007/s00521-023-09177-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Makam is defined as melodies that are described with typical the agâz(beginning), seyir (the orientation style), and karar (ending) features in a certain perde düzen (tone/fret tunings). For this reason, determining the makam is the basic step in understanding the melodic progression, as in musical keys. Machine learning, an artificial intelligence discipline, offers stable solutions for estimating different situations based on known data. In this study, classifications for makam recognition in Turkish folk music were carried out using different machine learning methods on the original dataset. The success of the different methods used was compared, and also data augmentation was performed by using SMOTE, KMeansSMOTE, ADASYN, and SVMSMOTE oversampling techniques, which are widely used in the literature to increase the prediction success of the classifiers. For each of eight different machine learning techniques, namely light gradient boosting machine, eXtreme gradient boosting, naive Bayes, decision tree, support vector machine, K-nearest neighbor, random forest, and logistic regression, in addition to classification without data augmentation, a total of 40 classification processes were carried out using four different data augmentation techniques. The results of the classification processes are reported with four different parameters: accuracy, precision, recall, and F1-score. The highest accuracy value of 99.17% was obtained when the light gradient boosting machine classifier was used together with the SMOTE data augmentation technique. It was observed that the measurements obtained in the study were higher than the results obtained in similar studies conducted in the literature in recent years.},
  archive      = {J_NCA},
  author       = {Börekci, Alper and Sevli, Onur},
  doi          = {10.1007/s00521-023-09177-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1621-1639},
  shortjournal = {Neural Comput. Appl.},
  title        = {A classification study for turkish folk music makam recognition using machine learning with data augmentation techniques},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of microscopic peripheral blood cell images
using multibranch lightweight CNN-based model. <em>NCA</em>,
<em>36</em>(4), 1599–1620. (<a
href="https://doi.org/10.1007/s00521-023-09158-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {White blood cells (WBC), which are human peripheral blood cells, are the most significant part of the immune system that defends the body against microorganisms. Modifications in the morphological structure and number of subtypes of WBC play an major role in the diagnosis of serious diseases such as anemia and leukemia. Therefore, accurate WBC classification is clinically quite significant in the diagnosis of the disease. In last years, deep learning, especially CNN, has been used frequently in the field of medicine because of its strong self-learning capabilities and it can extract deeper features in images with stronger semantic information. In this study, a new CNN-based method is proposed for WBC classification. The proposed method (PM) is a hybrid method consisting of Inception module, pyramid pooling module (PPM) and depthwise squeeze-and-excitation block (DSEB). Inception module increases classification accuracy of CNNs by performing multiple parallel convolutions at different scales. PPM captures multi-scale contextual information from the input image by pooling features at multiple different scales. DSEB offers a structure where the network can selectively learn about informative features and remove useless ones. For the analysis of the classification results of the PM, experiments were carried out on three different datasets consisting of four classes (BCCD dataset), five classes (Raabin WBC dataset) and eight classes. As a result of the experimental studies, classification accuracy was obtained 99.96% in the BCCD dataset containing 4 classes, 99.22% in the Raabin WBC dataset containing 5 classes and 99.72% in the PBC dataset containing 8 classes. Compared with the state-of-the-art studies in the literature, the PM achieved the best accuracy in three datasets.},
  archive      = {J_NCA},
  author       = {Fırat, Hüseyin},
  doi          = {10.1007/s00521-023-09158-9},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1599-1620},
  shortjournal = {Neural Comput. Appl.},
  title        = {Classification of microscopic peripheral blood cell images using multibranch lightweight CNN-based model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bladder cancer gene expression prediction with explainable
algorithms. <em>NCA</em>, <em>36</em>(4), 1585–1597. (<a
href="https://doi.org/10.1007/s00521-023-09142-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we aimed to classify bladder cancer patients using tumoral and non-tumoral gene expression data. In this way, we aimed to determine which genes are effective on tumoral and normal tissues. In addition, for this purpose, we planned to perform this classification using interpretable methods (The aim of this study was to classify bladder cancer patients using gene expression data from tumoral and non-tumoral tissues. By doing so, we wanted to determine which genes were effective on both tumoral and normal tissues. Moreover, for this purpose, we planned to use interpretable methods for this classification.). Analyses using permutation feature importance (PFI), SHapley Additive exPlanations (SHAP), local interpretable model-agnostic explanations (LIME), and Anchor methods on data from Gene Expression Omnibus (GEO) and Curated Microarray Database we did (We performed analyses using permutation feature importance (PFI), SHapley Additive exPlanations (SHAP), local interpretable model-agnostic explanations (LIME), and Anchor methods on data from Gene Expression Omnibus (GEO) and Curated Microarray Database.). These are eXplainable methods used to determine the importance of genes in classification. According to the results of our study, the most important genes were determined as LINC00161, ACACB, and CBARP according to the PFI method, HSPA6, STON2, and RFC2 according to the SHAP method, PRUNE2 and ABCC13 according to the LIME method, and TMEM74, KLHL10, and GAMT according to the Anchor method. This study shows that genes involved in other cancer types are also effective in bladder cancer. In addition, it has been observed that using explainable methods in cancer data can support prognosis and treatment in the clinic.},
  archive      = {J_NCA},
  author       = {Kırboğa, Kevser Kübra},
  doi          = {10.1007/s00521-023-09142-3},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1585-1597},
  shortjournal = {Neural Comput. Appl.},
  title        = {Bladder cancer gene expression prediction with explainable algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised character recognition with graphene memristive
synapses. <em>NCA</em>, <em>36</em>(4), 1569–1584. (<a
href="https://doi.org/10.1007/s00521-023-09135-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristive devices being applied in neuromorphic computing are envisioned to significantly improve the power consumption and speed of future computing platforms. The materials used to fabricate such devices will play a significant role in their viability. Graphene is a promising material, with superb electrical properties and the ability to be produced in large volumes. In this paper, we demonstrate that a graphene-based memristive device could potentially be used as synapses within spiking neural networks (SNNs) to realise spike timing-dependant plasticity for unsupervised learning in an efficient manner. Specifically, we verify the operation of two SNN architectures tasked for single-digit (0–9) classification: (i) a single layer network, where inputs are presented in $$5\times 5$$ pixel resolution, and (ii) a larger network capable of classifying the dataset. Our work presents the first investigation and large-scale simulation of the use of graphene memristive devices to perform a complex pattern classification task. In favour of reproducible research, we will make our code and data publicly available. This can pave the way for future research in using graphene devices with memristive capabilities in neuromorphic computing architectures.},
  archive      = {J_NCA},
  author       = {Walters, Ben and Lammie, Corey and Yang, Shuangming and Jacob, Mohan V and Rahimi Azghadi, Mostafa},
  doi          = {10.1007/s00521-023-09135-2},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1569-1584},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised character recognition with graphene memristive synapses},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerated fuzzy min–max neural network and arithmetic
optimization algorithm for optimizing hyper-boxes and feature selection.
<em>NCA</em>, <em>36</em>(4), 1553–1568. (<a
href="https://doi.org/10.1007/s00521-023-09131-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy min–max (FMM) neural network effectively solves classification problems. Despite its success, it has been observed recently that FMM has overlapping between hyper-boxes in some datasets which certainly the overall classification performance, as well as FMM has a high compactional complexity, especially when dealing with high-dimensional datasets. a hybrid model combining Arithmetic Optimization Algorithm (AOA) and Accelerated fuzzy min–max (AFMM) neural network is proposed to produce an AFMM-AOA model, where AFMM is used to speed up the hyper-boxes contraction process and to reduce the number of hyper-boxes, then AOA is employed for selecting the optimal feature set in each hyper-box, which results in lowering the compactional complexity and overcoming the overlapping problem. Furthermore, the AOA algorithm has been modified (MAOA) to enhance the exploiting ability of the original AOA algorithm for handling the high dimensionality in hyper-box representation by introducing both random and neighbor search methods. The performance of the proposed methods is evaluated using twelve datasets, as a result, the neighbor search method shows better performance than the random search. In addition, both methods showed superior performance compared with the original AOA and some state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Alzaqebah, Malek and Ahmed, Eman A. E.},
  doi          = {10.1007/s00521-023-09131-6},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1553-1568},
  shortjournal = {Neural Comput. Appl.},
  title        = {Accelerated fuzzy min–max neural network and arithmetic optimization algorithm for optimizing hyper-boxes and feature selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction and classification of minerals using deep
residual neural network. <em>NCA</em>, <em>36</em>(4), 1539–1551. (<a
href="https://doi.org/10.1007/s00521-023-09141-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minerals are in great demand because of their pervasive application in atomic energy and their use as raw materials for other industries. Despite this, it is challenging to identify and classify the minerals due to the deposit&#39;s broadness, mineral composition, particle size, and geography. In the proposed study, a deep computer vision technology supported by a deep residual neural network model is developed to establish a system for classifying and identifying minerals. Convolutional feature selection is used in this model to apply the filters and extract the mineral characteristics from the mineral images. This model offers a better and more effective model while minimizing reliance on mineral images with high resolution. Additionally, VGG with a depth of 16 and residual neural networks with depths of 101, 34, and 18 are developed by combining various pooling algorithms for mineral identification. The proposed model&#39;s performance has been thoroughly investigated and evaluated using the confusion matrix, sensitivity, classification accuracy, and specificity scores. The proposed model classified numerous minerals with an accuracy of 91%.},
  archive      = {J_NCA},
  author       = {Theerthagiri, Prasannavenkatesan and Ruby, A. Usha and George Chellin Chandran, J.},
  doi          = {10.1007/s00521-023-09141-4},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1539-1551},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction and classification of minerals using deep residual neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperparameter optimization of pre-trained convolutional
neural networks using adolescent identity search algorithm.
<em>NCA</em>, <em>36</em>(4), 1523–1537. (<a
href="https://doi.org/10.1007/s00521-023-09121-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are widely used deep learning (DL) models for image classification. The selected hyperparameters for training convolutional neural network (CNN) models have a significant effect on the performance. Therefore, hyperparameter optimization (HPO) is an important process to design optimal CNN models. In this study, Adolescent Identity Search Algorithm (AISA) and Bayesian Optimization (BO) methods were applied for HPO of pre-trained CNN models to improve their classification performance. Diabetic retinopathy (DR) classification was chosen as the application problem of the study and Kaggle Diabetic Retinopathy Detection dataset was used. We used pre-trained CNN models named AlexNet, MobileNetV2, ResNet18, and GoogLeNet. To the best of our knowledge, this study represents the first use of AISA-based HPO for DR classification. The results show that hybrid models incorporating AISA-based HPO achieve better accuracy with fewer iterations than BO-based HPO hybridized models.},
  archive      = {J_NCA},
  author       = {Akkuş, Ebubekir and Bal, Ufuk and Koçoğlu, Fatma Önay and Beyhan, Selami},
  doi          = {10.1007/s00521-023-09121-8},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1523-1537},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hyperparameter optimization of pre-trained convolutional neural networks using adolescent identity search algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multidimensional relational knowledge embedding for
coreference resolution. <em>NCA</em>, <em>36</em>(4), 1507–1521. (<a
href="https://doi.org/10.1007/s00521-023-09128-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the co-reference resolution model using a knowledge base mainly faces two problems: first, the knowledge is complex and diverse, and it is difficult to add appropriate knowledge to complement the conceptual relationships between entities; second, it is difficult to integrate the obtained external knowledge into the model. In this paper, we propose a multidimensional relational knowledge model (MDR) for co-reference resolution, which extends in both high-dimensional and low-dimensional directions according to the antecedent words to be parsed, abstracts upwards to high-dimensional concepts to represent the essential relations of things, and diffuses downwards to find intra-sentence words to make the knowledge closer to the sentence meaning, providing the model with more generalised multidimensional relational knowledge and higher sentence relevance. At the same time, in order for the model to make full use of the knowledge, the attention mechanism is adjusted to use external knowledge to guide the intra-sentence relationship changes and adjust the degree of knowledge dominance according to the back-propagation of the neural network. The knowledge noise reduction module is designed based on a multiplexed hybrid approach, using a hybrid approach to dilute the proportion of knowledge in the total information and reduce noise generation. The multidimensional relational knowledge model is evaluated on the Definite Pronoun Resolution Dataset and Winograd Schema Challenge datasets, showing its cross-sectional comparison with existing models in experiments and ablation experiments, and the role of knowledge is analyzed for experimental cases to demonstrate that the multidimensional relational knowledge is helpful for model co-reference resolution ability.},
  archive      = {J_NCA},
  author       = {Li, Kai and Zhang, Shuquan and Zhao, Zhenlei},
  doi          = {10.1007/s00521-023-09128-1},
  journal      = {Neural Computing and Applications},
  month        = {2},
  number       = {4},
  pages        = {1507-1521},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multidimensional relational knowledge embedding for coreference resolution},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comment to “a projective general linear group-based
algorithm for the construction of substitution box for block ciphers.”
<em>NCA</em>, <em>36</em>(3), 1495–1505. (<a
href="https://doi.org/10.1007/s00521-023-09082-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This letter identifies a fundamental mistake in the published paper titled “A projective general linear group-based algorithm for the construction of substitution box for block ciphers.” The projective general linear group-based algorithm is designed to provide high nonlinearity, low differential uniformity, and good resistance against linear and differential attacks. The projective general linear group-based algorithm uses the linear fractional transformation defined over finite field $$\mathrm{GF}\left({2}^{8}\right)$$ . The authors of the paper claimed that the irreducible polynomial of degree 8 is used for the construction of a finite field $$\mathrm{GF}\left({2}^{8}\right)$$ . We have observed that the projective general linear group-based algorithm uses a reducible polynomial of degree 8. Thus, the inverse of each element does not exist in the finite field $$\mathrm{GF}\left({2}^{8}\right)$$ . We have also shown that the values of the S-Box given in the paper are also incorrect.},
  archive      = {J_NCA},
  author       = {Arshad, Razi and Jalil, Mudassar},
  doi          = {10.1007/s00521-023-09082-y},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1495-1505},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comment to “A projective general linear group-based algorithm for the construction of substitution box for block ciphers”},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pmir: An efficient privacy-preserving medical images search
in cloud-assisted scenario. <em>NCA</em>, <em>36</em>(3), 1477–1493. (<a
href="https://doi.org/10.1007/s00521-023-09118-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of content-based medical image retrieval (CBMIR) technology which is used as a convenient assistant for medical diagnosis. However, the potential risk of privacy disclosure in CBMIR remains a concern due to the involvement of patients’ sensitive information in medical images. To address this issue, we have proposed an efficient scheme to achieve privacy-preserving medical image retrieval, named PMIR. The primary objective of PMIR is to enhance the accuracy of medical image retrieval while ensuring privacy protection. In PMIR, medical institutions with large repositories of medical images can securely upload to the cloud server with their image data and encryption indexes. Subsequently, users who successfully registered from medical institutions are able to enjoy convenient image retrieval services without revealing their sensitive information and query attributes to the cloud server. The proposed approach emphasizes a privacy-preserving policy mechanism, which empowers users with the right to choose rather than relying solely on service providers. Through rigorous security analysis, it is demonstrated that PMIR can effectively withstand various known security threats. Additionally, experimental results highlight the substantial reduction in communication overhead achieved by PMIR, ultimately providing a seamless and secure search experience for users.},
  archive      = {J_NCA},
  author       = {Li, Dong and Wu, Yanling and Lü, Qingguo and Zhang, Keke and Wang, Zheng and Wu, Jiahui},
  doi          = {10.1007/s00521-023-09118-3},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1477-1493},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pmir: An efficient privacy-preserving medical images search in cloud-assisted scenario},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving interpretable neural modularity in free-form
multilayer perceptrons through connection costs. <em>NCA</em>,
<em>36</em>(3), 1459–1476. (<a
href="https://doi.org/10.1007/s00521-023-09117-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability fosters trust when humans and artificial intelligence (AI) systems interact, and its value for neural networks in particular cannot be overstated. In this paper, we analyse the emergence and value of neural modularity as it relates to interpretability. We compare the modularity evolved through connectivity constraints in terms of network Q-scores and examine the interpretable qualities of the resultant networks with functional subset regression. The connectivity constraints compared here include those proposed by previous research as well as several novel variations formulated to express neuron input competition and connections per neuron variance. Networks were evolved using HyperNEAT on a free-form substrate. The results indicate that the connection costs successfully promote the evolution of neural modularity across a variety of tasks and show that the novel connection cost variations are competitive with previously explored connection costs. The interpretability assessment shows that while the evolved networks’ interpretable qualities are task dependent, two of the compared connection costs deliver statistically different functional module overlap distributions. However, recovered subnetwork module accuracies remain low, highlighting the key points for future research.},
  archive      = {J_NCA},
  author       = {van der Merwe, Andreas Werle and Vandenheever, David},
  doi          = {10.1007/s00521-023-09117-4},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1459-1476},
  shortjournal = {Neural Comput. Appl.},
  title        = {Evolving interpretable neural modularity in free-form multilayer perceptrons through connection costs},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State estimation in coupled neural networks with delays via
changeable pinning control. <em>NCA</em>, <em>36</em>(3), 1449–1458. (<a
href="https://doi.org/10.1007/s00521-023-09114-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the state estimation problem in a network of diffusively coupled neural networks (NNs), where each NN has delayed dynamics, and the designer can only measure the states of a portion of NNs. In light of the master–slave synchronization framework, an estimator network of NNs incorporating pinning control is constructed, and the control gain is assumed to be changeable. Some sufficient criteria are established for successful state estimation, which reveal the influence of NNs’ dynamics, network topology, and time delays. Moreover, some corollaries are also derived to cater several specified cases. Besides, a criterion independent on the exact topological information is also given to tackle scenarios with topological uncertainties. Finally, some numerical examples are provided to demonstrate the validity of theoretical results and the feasibility of control schemes.},
  archive      = {J_NCA},
  author       = {Jia, Qiang and Fang, Chengyu and Gao, Yingchao and Yang, Cuili},
  doi          = {10.1007/s00521-023-09114-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1449-1458},
  shortjournal = {Neural Comput. Appl.},
  title        = {State estimation in coupled neural networks with delays via changeable pinning control},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DRL-dEWMA: A composite framework for run-to-run control in
the semiconductor manufacturing process. <em>NCA</em>, <em>36</em>(3),
1429–1447. (<a
href="https://doi.org/10.1007/s00521-023-09112-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to develop a weight-adjustment scheme for a double exponentially weighted moving average (dEWMA) controller using deep reinforcement learning (DRL) techniques. Under the run-to-run control framework, the weight adjustment of the dEWMA is formulated as a Markovian decision process in which the candidate weights are viewed as the DRL agent’s decision action. Accordingly, a composite control strategy integrating DRL and dEWMA is proposed. Specifically, a well-trained DRL agent serves as an auxiliary controller that produces the preferred weights of the dEWMA. The optimized dEWMA serves as a master controller to provide a suitable recipe for the manufacturing process. Furthermore, two classical deterministic policy-gradient algorithms are leveraged for automatic weight tuning. The simulation results show that the proposed scheme outperforms existing RtR controllers in terms of disturbance rejection and target tracking. The proposed scheme has significant practical application prospects in smart semiconductor manufacturing.},
  archive      = {J_NCA},
  author       = {Ma, Zhu and Pan, Tianhong},
  doi          = {10.1007/s00521-023-09112-9},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1429-1447},
  shortjournal = {Neural Comput. Appl.},
  title        = {DRL-dEWMA: A composite framework for run-to-run control in the semiconductor manufacturing process},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative magnitude pruning-based light-version of AlexNet
for skin cancer classification. <em>NCA</em>, <em>36</em>(3), 1413–1428.
(<a href="https://doi.org/10.1007/s00521-023-09111-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNN) with different architectures have shown promising results in skin cancer diagnosis. However, CNN has a high computational cost, which makes the need for a light version of CNN a desirable step. This version can be used on small devices, such as mobile phones or tablets. A light version can be created using pruning techniques. In this study, iterative magnitude pruning (IMP) is utilized. This method depends on pruning the network iteratively. The IMP method is applied on AlexNet with transfer learning (TL) and data augmentation. The proposed IMP AlexNet with TL is applied on three different skin cancer datasets which are PAD-UFES-20, MED-NODE, and PH2 dataset. The datasets used are a combination of smartphone, dermoscopic, and non-dermoscopic images. Different CNN versions are applied on the same datasets for comparison with IMP AlexNet. The CNNs used are VGG-16, ShuffleNet, SqueezNet, DarkNet-19, DarkNet-53, and Inception-v3. The proposed IMP AlexNet achieved accuracies of 97.62%, 96.79%, and 96.75%, with accuracy losses of 1.53%, 2.3%, and 2.2%, respectively, compared to the original AlexNet. In addition, the proposed IMP AlexNet requires less running time and memory usage than the traditional AlexNet. The average running time for IMP AlexNet is 0.45 min, 0.28 min, and 0.3 min, for PAD-UFES-20, MED-NODE, and PH2 datasets, respectively. The average RAM usage with IMP AlexNet is 1.8 GB, 1.6 GB, and 1.7 GB, respectively. IMP AlexNet accelerates the average running time by approximately 15 times that of the traditional AlexNet and reduces the average RAM used by 40%.},
  archive      = {J_NCA},
  author       = {Medhat, Sara and Abdel-Galil, Hala and Aboutabl, Amal Elsayed and Saleh, Hassan},
  doi          = {10.1007/s00521-023-09111-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1413-1428},
  shortjournal = {Neural Comput. Appl.},
  title        = {Iterative magnitude pruning-based light-version of AlexNet for skin cancer classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal multi-objective optimization via determinantal
point process-assisted evolutionary algorithm. <em>NCA</em>,
<em>36</em>(3), 1381–1411. (<a
href="https://doi.org/10.1007/s00521-023-09110-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problems (MMOPs) are widely present in real life. Due to the need of balancing between convergence and diversity in multi-objective optimization, as well as the need of balancing between diversities in objective and decision spaces, exploring the Pareto optimal front and Pareto optimal solution set becomes rather difficult in solving MMOPs. Recently, some multimodal multi-objective optimization algorithms have emerged. However, most of them are convergence-first, which may result in poor diversity of the solution set in decision space. To remedy this defect, in this paper, a determinantal point process (DPP)-assisted evolutionary algorithm is proposed to effectively solve MMOPs. In the proposed method, i) the DPPs are used to select subsets to consider convergence and diversity in both objective and decision spaces; ii) a kernel matrix is designed to retain solutions with poor convergence but good diversity in the decision space to explore the equivalent Pareto optimal solution sets; and iii) we propose a framework that combines the population and archive to better solve MMOPs. The results show that the proposed algorithm achieves the best performance in 18 of the 28 benchmark problems compared to six state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Cheng, Xinyu and Gong, Wenyin and Ming, Fei and Zhu, Xiaofang},
  doi          = {10.1007/s00521-023-09110-x},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1381-1411},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal multi-objective optimization via determinantal point process-assisted evolutionary algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of scour depth around bridge abutments using
ensemble machine learning models. <em>NCA</em>, <em>36</em>(3),
1369–1380. (<a
href="https://doi.org/10.1007/s00521-023-09109-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abutments are the structures that support the ends of a bridge deck. Scouring of streambed is a significant problem and ultimately results in the failure of the bridge when the abutments are exposed to flowing water over the long term. Abutment scour is influenced by the type of abutment, shape, and size of the abutments. In the current study, machine learning (ML) models have been utilized for predicting the scour depth around abutments making use of experimental data. The scour depth was modeled around three types of abutments: a vertical wall, a semicircular wall, and a 45° wing wall. Five input parameters, namely, the length of the abutment (L), breadth of the abutment (B), sediment size (d50), approaching flow depth (h) and average approaching flow velocity (U), were used in this study. For predicting the abutment scour depth, ML models such as Adaptive Neuro-Fuzzy Inference System (ANFIS), Gradient Tree Boosting (GTB), Group Method of Data Handling (GMDH), and Multivariate Adaptive Regression Splines (MARS) were applied. Statistical metrics such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Relative RMSE (RRMSE), Normalized Nash–Sutcliffe Efficiency (NNSE), Kling-Gupta Efficiency (KGE), and Willmott Index (WI) have been employed to evaluate the performance of each model. It was found that the GTB model provided relatively accurate predictions of the scour depth around the semicircular and 45° wing wall abutments with good metrics. Similarly, the MARS model outperformed all other models in terms of predicting vertical wall abutment scour depth.},
  archive      = {J_NCA},
  author       = {Marulasiddappa, Sreedhara B. and Patil, Amit Prakash and Kuntoji, Geetha and Praveen, K. M. and Naganna, Sujay Raghavendra},
  doi          = {10.1007/s00521-023-09109-4},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1369-1380},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of scour depth around bridge abutments using ensemble machine learning models},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Whole image average pooling-based convolution neural network
approach for brain tumour classification. <em>NCA</em>, <em>36</em>(3),
1351–1367. (<a
href="https://doi.org/10.1007/s00521-023-09108-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network has been proven to be a robust recognition and diagnosis model for modelling diseases. In general, a convolutional neural network consists of feature learning which is considered a vital process in terms of feature extraction and classifier algorithms used for decision-making. In recent years, various pooling operations considered the spine of the feature learning layer have been developed in the literature; unfortunately, few of them can be spread to tackle the overfitting problem. In this paper, a novel pooling approach termed whole image average pooling is proposed to hold over the most significant feature information on the learning layer. The proposed method consists of two main stages: in the first stage, the average of all the values of the input image is calculated, in the second stage, the input image is divided into regions that represent the feature set of the input image, and then, the values of the regions are calculated. While obtaining the values of these features, the average of all values of the input image is taken into account. The proposed whole image average pooling approach addresses the overfitting problem by processing all pixel values in the image data and is used to get the important feature information from the medical datasets. To evaluate the performance of the proposed whole image average pooling, four clinically applicable tumour datasets as medical datasets have been trained and tested on seven convolutional neural network models AlexNet, VGG16, ResNet18, GoogleNet, ResNet50, R-CNN, and Faster R-CNN. The experimental outcomes demonstrate that the proposed whole image average pooling consistently outperformed the state-of-the-art pooling operation in terms of accuracy, sensitivity, specificity, positive predictive value, false-positive rate, and F1-measure evaluation criteria in three datasets.},
  archive      = {J_NCA},
  author       = {Karaaltun, Muhammed},
  doi          = {10.1007/s00521-023-09108-5},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1351-1367},
  shortjournal = {Neural Comput. Appl.},
  title        = {Whole image average pooling-based convolution neural network approach for brain tumour classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fundamental period estimation of RC buildings by considering
structural and non-structural damage distributions through neural
network. <em>NCA</em>, <em>36</em>(3), 1329–1350. (<a
href="https://doi.org/10.1007/s00521-023-09107-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to develop a machine learning network to estimate the fundamental vibration period values of existing reinforced concrete (RC) buildings with damaged structural and non-structural elements. By considering the proposed machine learning network, changes in the fundamental vibration period of RC buildings due to potential damage states on structural members and infill walls are estimated. In this context, first of all, the level of reduction in stiffness caused by different damage levels in different types of structural elements is determined. Afterwards, an extensive database composed of 16,000 different building simulations with varying geometrical and mechanical properties is generated. 3D numerical models of these simulations are formed, and the fundamental vibration period values of the generated numerical models are determined. For each numerical model, a variant model at a certain damage state is also created by assigning predefined damage parameters to both structural and non-structural components. To this end, damage factor coefficients are used in stiffness matrices. An artificial neural network model is developed, and the created database is used in training and testing the artificial neural network model. The performance of the proposed artificial neural network (ANN) is determined using ambient vibration tests conducted on both undamaged buildings from the literature and damaged buildings during the Samos earthquake (2020) in the scope of this study. As a result, it has been shown that the proposed ANN is quite successful and can be used as an alternative method for determining the period values of undamaged—damaged RC buildings without the need to generate complex 3D numerical models.},
  archive      = {J_NCA},
  author       = {Cinar, Omer Faruk and Aldemir, Alper and Zervent, Altan and Yucel, Omer Burak and Erberik, Murat Altug and Anil, Ozgur and Sahmaran, Mustafa and Kockar, Mustafa Kerem and Askan, Aysegul},
  doi          = {10.1007/s00521-023-09107-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1329-1350},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fundamental period estimation of RC buildings by considering structural and non-structural damage distributions through neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel hybrid model for freight volume prediction based on
the baidu search index and emergency. <em>NCA</em>, <em>36</em>(3),
1313–1328. (<a
href="https://doi.org/10.1007/s00521-023-09106-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate freight volume forecasts play a crucial role in supporting regional economies and transportation systems. Nevertheless, the majority of previous studies rely on historical data, which poses challenges in promptly capturing the influence of market changes and emergency situations. To address this challenge, a novel prediction model based on the Baidu search index (BSI) and emergency is proposed, which comprises four distinct stages. In the first stage, we gathered the Baidu search index data and the COVID-19 index to furnish comprehensive, interactive, and timely information for the primary freight volume dataset. In the second stage, seasonal-trend decomposition procedures based on loess (STL) and empirical mode decomposition (EMD) are used to reduce data complexity. Additionally, we utilized boxplot to identify outliers in the remainder component. In the third stage, we employed seasonal naive prediction to forecast the seasonal component, while utilizing a genetic algorithm optimized backpropagation neural network (GABP) to predict other sub-sequences. To improve the prediction accuracy, we applied BPNN for error correction. Finally, to evaluate the performance of the proposed model, China’s freight volume is selected as the subject of the study. The results demonstrate that the model incorporating BSI and COVID-19 information can effectively establish a dynamic forecasting system for freight volume. Furthermore, the data preprocessing techniques employed in this study successfully reduce data complexity and enhance the accuracy of prediction. In comparative experiments, the proposed model has been demonstrated to outperform all the contrasted models in terms of forecasting accuracy.},
  archive      = {J_NCA},
  author       = {Liu, Jinpei and Chu, Na and Wang, Piao and Zhou, Ligang and Chen, Huayou},
  doi          = {10.1007/s00521-023-09106-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1313-1328},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel hybrid model for freight volume prediction based on the baidu search index and emergency},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distribution system state estimation with
transformer-bi-LSTM-based imputation model for missing measurements.
<em>NCA</em>, <em>36</em>(3), 1295–1312. (<a
href="https://doi.org/10.1007/s00521-023-09097-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution of the distribution system state estimation (DSSE) relies on the presence of physical measurements in real time. Sometimes, these measurements may not reach the control center due to the defects in meter functionality, the large communication time delays, and denial-of-service (DoS) attacks on communication channels. Addressing this issue, a novel deep learning (DL) approach is proposed by using a transformer model with the integration of bi-directional long short-term memory (Bi-LSTM) layer. The proposed model can be leveraged to forecast the unavailable measurement data, which maintains the observability of the system to obtain an accurate solution from DSSE. The superiority of the proposed model is probed by comparing it with other forecasting-based DL models at various percentages of missing measurement data. Further, the effectiveness of the proposed model is evaluated for forecasting the power injections of residential, commercial, and industrial loads as well as renewable energy sources. Finally, the solution of the DSSE is tested with forecasted data and compared with the results of the DSSE for the original measurement data. The simulations are performed on modified IEEE 13-node and IEEE 37-node test systems, and their corresponding results highlighted the superiority of the proposed model in the forecasting of the incomplete data.},
  archive      = {J_NCA},
  author       = {Raghuvamsi, Y. and Teeparthi, Kiran},
  doi          = {10.1007/s00521-023-09097-5},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1295-1312},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distribution system state estimation with transformer-bi-LSTM-based imputation model for missing measurements},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel algorithm based on DNA coding for substitution box
generation problem. <em>NCA</em>, <em>36</em>(3), 1283–1294. (<a
href="https://doi.org/10.1007/s00521-023-09095-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substitution boxes are very important for cryptographic structures. But getting an 8-bit strong s-box is a difficult problem. To address this problem, a new approach is proposed in this study. DNA chains are used in the proposed approach. First of all, a weak s-box is obtained with the help of a chaotic map. Then, a DNA chain is formed with the same chaotic map. In this study, 2000-long DNA chains were produced. Then, two random values consisting of four components are determined from these DNA chains, and these values are addressed to the s-box structure. By changing the places of these values, the s-box structure is improved up to a certain iteration. In this study, 10,000 iterations were examined, and three different strong s-boxes were obtained by using three different DNA chains. The nonlinearity values of these s-box structures were observed as 110.25, 110.5, and 110.75, respectively. The proposed study has proven to work effectively with effective results in three different chains. In addition, it has been proven as a result of the analysis that the proposed s-box structures also have other cryptographic features. The proposed algorithm has surpassed many s-box generation philosophies in the literature. In addition, the proposed algorithm will provide serious gains to cryptographic structures that will be developed in the future.},
  archive      = {J_NCA},
  author       = {Artuğer, Fırat},
  doi          = {10.1007/s00521-023-09095-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1283-1294},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel algorithm based on DNA coding for substitution box generation problem},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An analysis of precision: Occlusion and perspective
geometry’s role in 6D pose estimation. <em>NCA</em>, <em>36</em>(3),
1261–1281. (<a
href="https://doi.org/10.1007/s00521-023-09094-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving precise 6 degrees of freedom (6D) pose estimation of rigid objects from color images is a critical challenge with wide-ranging applications in robotics and close-contact aircraft operations. This study investigates key techniques in the application of YOLOv5 object detection convolutional neural network (CNN) for 6D pose localization of aircraft using only color imagery. Traditional object detection labeling methods suffer from inaccuracies due to perspective geometry and being limited to visible key points. This research demonstrates that with precise labeling, a CNN can predict object features with near-pixel accuracy, effectively learning the distinct appearance of the object due to perspective distortion with a pinhole camera. Additionally, we highlight the crucial role of knowledge about occluded features. Training the CNN with such knowledge slightly reduces pixel precision, but enables the prediction of 3 times more features, including those that are not initially visible, resulting in an overall better performing 6D system. Notably, we reveal that the data augmentation technique of scale can interfere with pixel precision when used during training. These findings are crucial for the entire system, which leverages the Solve Perspective-N-Point (Solve-PnP) algorithm, achieving 6D pose accuracy within 1 $$^\circ$$ and 7 cm at distances ranging from 7.5 to 35 m from the camera. Moreover, this solution operates in real-time, achieving sub-10ms processing times on a desktop PC.},
  archive      = {J_NCA},
  author       = {Choate, Jeffrey and Worth, Derek and Nykl, Scott and Taylor, Clark and Borghetti, Brett and Schubert Kabban, Christine},
  doi          = {10.1007/s00521-023-09094-8},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1261-1281},
  shortjournal = {Neural Comput. Appl.},
  title        = {An analysis of precision: Occlusion and perspective geometry’s role in 6D pose estimation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DSHFS: A new hybrid approach that detects structures with
their spatial location from large volume satellite images using CNN,
GeoServer and TileCache. <em>NCA</em>, <em>36</em>(3), 1237–1259. (<a
href="https://doi.org/10.1007/s00521-023-09092-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite images, widely used in recent years and entered the field of remote sensing technology, continuously record image data in databases worldwide. These image data, which are continually obtained, changing, and have a large volume, fall into the big data category. On the other hand, CNN-based techniques, a sub-branch of artificial intelligence, have been widely used to classify and segment image data in recent years. The scope of this study, firstly, it was tried to determine spatial positions and building objects from large-volume satellite images with classical CNN methods. However, classical CNN models could not process the data even in ECW format, one of the most compressed satellite imagery forms. To overcome these problems, a new approach called DSHFS has been proposed. It uses hybrid CNN, GeoServer, and TileCache techniques related to different disciplines to detect structures from large-volume satellite images and their spatial locations. In the proposed DSHFS approach, large-volume satellite imagery is first published in WMS format with GeoServer, which has an open-source strategy. Then, the data are converted into small images containing coordinate information with the TileCache system in size $$256 \times 256$$ . Finally, the building objects in these images are detected by CNN models. In the proposed DSHFS approach, the actual locations of the detected structures on the earth are calculated using the location information of the image presented as input to the CNN model. In order to examine the performance of the proposed DSHFS approach, satellite imagery covering 12.5 GB in the computer system in ECW format, which corresponds to an area of approximately 17.200 $$\hbox {km}^{2}$$ of Kayseri province, was used. In the proposed DSHFS approach, Faster R-CNN, MobileNet, and YOLO models are used as the CNN model. When the proposed DSHFS approach is examined according to the F1 score, DSHFS Faster R-CNN, MobileNet, and YOLO obtain F1 scores of 0.961, 0.964, and 0.910, respectively. When evaluating the computational efficiency of the proposed approaches, it was found that DSHFS Faster R-CNN, MobileNet, and YOLO took 512.72, 188.20, and 99.35 s, respectively, to identify the structures and their locations in the image. DSHFS YOLO approach detected approximately 2 times faster than MobileNet and approximately 5 times faster than Faster R-CNN. When the proposed DSHFS approach is generally examined, it detects the building objects from the satellite image and their actual positions on the earth in approximately 0.13 s.},
  archive      = {J_NCA},
  author       = {Taşyürek, Murat and Türkdamar, Mehmet Uğur and Öztürk, Celal},
  doi          = {10.1007/s00521-023-09092-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1237-1259},
  shortjournal = {Neural Comput. Appl.},
  title        = {DSHFS: A new hybrid approach that detects structures with their spatial location from large volume satellite images using CNN, GeoServer and TileCache},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective generation scheduling of integrated energy
system using hybrid optimization technique. <em>NCA</em>,
<em>36</em>(3), 1215–1236. (<a
href="https://doi.org/10.1007/s00521-023-09091-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates multi-objective (MO) generation scheduling problem of an integrated energy system (IES). The integrated energy system comprises combined heat and power (CHP), hydroelectric, thermal and heat units. The interdependency of heat and power in CHP units, water transport delay among various multi-chain hydroelectric units and valve point loading effect of thermal units makes the generation scheduling problem a complex, constrained, discontinuous, non-differentiable and multimodal optimization problem. The main motive of this research work is to concurrently reduce the overall generation cost and pollutant emissions emitted by various generating units. The generation scheduling problem is treated as a MO problem owing to the contradictory nature of these objectives. Thus, a very proficient hybrid optimization approach, i.e., quantum-based cuckoo search algorithm (QCSA) with mutation operators, is proposed for searching for the optimal generation schedule of the MO-integrated energy system generation scheduling (IESGS) problem. The proposed technique significantly improves the solutions obtained by QCSA by utilizing three mutation operators, i.e., Cauchy, Gaussian, and opposition-based mutation. The proposed strategy has been implemented to MO-hydroelectric-thermal (HT) generation scheduling and MO-IESGS problems to demonstrate the efficacy of the proposed method. The cardinal priority method is utilized for finding the most suitable non-dominated solution for both problems. The obtained results are comparatively better than the published results. The proposed approach’s robustness compared to the QCSA has been further verified using the t-test. Based on comparisons and statistical analysis, the proposed technique is a promising approach for handling complex, multi-dimensional and non-convex generation scheduling optimization problems.},
  archive      = {J_NCA},
  author       = {Kaur, Arunpreet and Narang, Nitin},
  doi          = {10.1007/s00521-023-09091-x},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1215-1236},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective generation scheduling of integrated energy system using hybrid optimization technique},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient space learning based on kernel trick and dimension
reduction technique for multichannel motor imagery EEG signals
classification. <em>NCA</em>, <em>36</em>(3), 1199–1214. (<a
href="https://doi.org/10.1007/s00521-023-09090-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) signals show the electrical activity of the brain, which are one of the inputs of the brain–computer interface (BCI). The BCI provides the communication path between the brain and the computer. One of the critical applications of BCI is Motor imagery (MI). MI is a mental process that a person practices or simulates a particular movement without physically acting. BCI allows the person to communicate with their environment independently of peripheral muscles and nerves, using EEG brain signals by assistive devices such as wheelchairs, robotic arms, and computers. In this paper, a space learning concept is proposed for EEG motor imagery signal classification. Our innovation in the proposed method is to increase and then, reduce the data dimensions, which has led to learning the efficient space for signals classification. It is based on two techniques: Multi-Kernel Learning (MKL) and dimension reduction. The composite kernel is made of a combination of four kernels by The Heuristic MKL Algorithm. This algorithm uses heuristic rules to estimate the weight of kernels with high accuracy and very little computational complexity. The weight associated with each base kernel and its parameters is calculated by the Equilibrium Optimizer. Dimensions of data are reduced to avoid the curse of dimensions. In this step, the number of dimensions of reduced space and the mapping matrix are learned to reduce the dimensions of data linearly. We selected ELM, KNN, and SVM classifiers for classification. The BCI Competition dataset was used for evaluation, which consists of five subsets aa, al, ay, aw, av, and two classes of the right hand and right foot. The proposed method with the ELM was improved the average classification accuracy and standard deviation by 3.9% and 2.28, respectively, and achieved 91.4% accuracy. The lower standard deviation than other methods shows that our method is more robust than all other methods to subject variety. The proposed method is compared with twelve state-of-the-art methods and has shown higher accuracy than other methods such as the deep convolutional neural networks. The results show the superiority of the proposed method over other methods in the Wilcoxon signed test.},
  archive      = {J_NCA},
  author       = {Amiri, Youkabed and Omranpour, Hesam},
  doi          = {10.1007/s00521-023-09090-y},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1199-1214},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient space learning based on kernel trick and dimension reduction technique for multichannel motor imagery EEG signals classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NSOFS: A non-dominated sorting-based online feature
selection algorithm. <em>NCA</em>, <em>36</em>(3), 1181–1197. (<a
href="https://doi.org/10.1007/s00521-023-09089-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online streaming feature selection (OSFS) methods are used to dynamically update the feature space as well as remove irrelevant and redundant features from the data. Since most Big Data in real-world applications are generated in the form of data streams, effective methods should be developed in this area. Further, methods with low computational complexity are required to make online decisions. In this paper, the OSFS process is modeled as a multi-objective optimization problem. To the best of our knowledge, this is the first time that the concept of Pareto dominance has been applied to find the optimal subset of features in OSFS. When a new feature arrives, it is evaluated in the multi-objective space. The non-dominated features are the optimal subset for each timestamp. We proposed an efficient and effective method which enhances the classification accuracy in OSFS by minimizing the number of features within a short time. In addition, the proposed method is insensitive to the feature streams. Experiments are conducted using two classifiers and seven OSFS methods, including OSFSMI, K-OFSD, OFS-A3M, OFS-Density, Alpha-Investing, SAOLA, and OFSS-FI.},
  archive      = {J_NCA},
  author       = {Hashemi, Amin and Pajoohan, Mohammad-Reza and Dowlatshahi, Mohammad Bagher},
  doi          = {10.1007/s00521-023-09089-5},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1181-1197},
  shortjournal = {Neural Comput. Appl.},
  title        = {NSOFS: A non-dominated sorting-based online feature selection algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SCCRNet: A framework for source camera identification on
digital images. <em>NCA</em>, <em>36</em>(3), 1167–1179. (<a
href="https://doi.org/10.1007/s00521-023-09088-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the source of digital images is a critical task in digital image forensics. A novel architecture is proposed using a combination of Convolutional layers and residual blocks to distinguish source cameras. The network architecture comprises convolutional layers, residual blocks, batch normalization layers, a fully connected layer and a softmax layer. Architecture aids in learning and extracting the features for identifying the model and sensor level patterns for source camera identification. Multiple patches are taken from each image to increase the sample space size. The experiments on the MICHE-I dataset show an accuracy of 99.47% for model level source camera identification and 96.03% for sensor level identification. Thus, the proposed method is more accurate than the state-of-the-art methods on the MICHE-1 dataset. The proposed architecture yields comparable results on Dresden and VISION datasets also. Moreover, a technique is also proposed to identify the images of unknown camera models by setting a threshold value for the output prediction score.},
  archive      = {J_NCA},
  author       = {Sychandran, C. S. and Shreelekshmi, R.},
  doi          = {10.1007/s00521-023-09088-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1167-1179},
  shortjournal = {Neural Comput. Appl.},
  title        = {SCCRNet: A framework for source camera identification on digital images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid transformer–sequencer approach for age and gender
classification from in-wild facial images. <em>NCA</em>, <em>36</em>(3),
1149–1165. (<a
href="https://doi.org/10.1007/s00521-023-09087-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancements in computer vision and image processing techniques have led to emergence of new application in the domain of visual surveillance, targeted advertisement, content-based searching, human–computer interaction, etc. Out of the various techniques in computer vision, face analysis, in particular, has gained much attention. Several previous studies have tried to explore different applications of facial feature processing for a variety of tasks, including age and gender classification. However, despite several previous studies having explored the problem, the age and gender classification of in-wild human faces is still far from achieving the desired levels of accuracy required for real-world applications. This paper, therefore, attempts to bridge this gap by proposing a hybrid model that combines self-attention and BiLSTM approaches for age and gender classification problems. The proposed model’s performance is compared with several state-of-the-art models proposed so far. An improvement of approximately 10% and 6% over the state-of-the-art implementations for age and gender classification, respectively, is noted for the proposed model. The proposed model is thus found to achieve superior performance and is found to provide a more generalized learning. The model can, therefore, be applied as a core classification component in various image processing and computer vision problems.},
  archive      = {J_NCA},
  author       = {Singh, Aakash and Singh, Vivek Kumar},
  doi          = {10.1007/s00521-023-09087-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1149-1165},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid transformer–sequencer approach for age and gender classification from in-wild facial images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intuitionistic fuzzy hypersoft expert set-based robust
decision-support framework for human resource management integrated with
modified TOPSIS and correlation coefficient. <em>NCA</em>,
<em>36</em>(3), 1123–1147. (<a
href="https://doi.org/10.1007/s00521-023-09085-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human resource management is the process of making a company’s human resources decisions. In general, these decisions include hiring, firing, training, and developing people according to their positions and the needs of the organization. It includes a variety of policies and strategies designed to recognize the contribution that people make to an organization. The core goal of this article is to depict a novel fuzzy multi-criteria decision-making methodology for selecting employees. The purpose behind selecting employees is to identify and hire individuals who possess the required skills, qualifications, and attributes that align with the organization’s goals and job requirements. To reflect an inadequate assessment, ambiguity, and anxiety in making choices, the intuitionistic fuzzy hypersoft expert set is an extension of the intuitionistic fuzzy soft expert and hypersoft sets. It is a novel approach to decisions and intelligent computing in the face of uncertainty. The intuitionistic fuzzy hypersoft expert set has a better ability to handle ambiguous and unclear data. In the research that follows, the ideas and characteristics of the correlation coefficient and the weighted correlation coefficient of the intuitionistic fuzzy hypersoft expert sets are proposed. Under the aegis of intuitionistic fuzzy hypersoft expert sets, a TOPSIS based on correlation coefficients and weighted correlation coefficients is introduced. Aside from that, we also covered aggregation operators, including intuitionistic fuzzy hypersoft weighted geometric operators. The decision-making process is suggested in an intuitionistic fuzzy hypersoft expert environment to resolve uncertain and ambiguous information, relying on the well-established TOPSIS approach and aggregation operators. An illustration of decision-making challenges shows how the suggested algorithm can be used. The efficacy of this strategy is lastly demonstrated by comparing its benefits, effectiveness, flexibility, and numerous current studies.},
  archive      = {J_NCA},
  author       = {Ihsan, Muhammad and Saeed, Muhammad and Rahman, Atiqe Ur},
  doi          = {10.1007/s00521-023-09085-9},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1123-1147},
  shortjournal = {Neural Comput. Appl.},
  title        = {An intuitionistic fuzzy hypersoft expert set-based robust decision-support framework for human resource management integrated with modified TOPSIS and correlation coefficient},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust and novel attention guided MultiResUnet model for 3D
ground reaction force and moment prediction from foot kinematics.
<em>NCA</em>, <em>36</em>(3), 1105–1121. (<a
href="https://doi.org/10.1007/s00521-023-09081-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ground reaction force and moment (GRF&amp;M) measurements are vital for biomechanical analysis and significantly impact the clinical domain for early abnormality detection for different neurodegenerative diseases. Force platforms have become the de facto standard for measuring GRF&amp;M signals in recent years. Although the signal quality achieved from these devices is unparalleled, they are expensive and require laboratory setup, making them unsuitable for many clinical applications. For these reasons, predicting GRF&amp;M from cheaper and more feasible alternatives has become a topic of interest. Several works have been done on predicting GRF&amp;M from kinematic data captured from the subject’s body with the help of motion capture cameras. The problem with these solutions is that they rely on markers placed on the whole body to capture the movements, which can be very infeasible in many practical scenarios. This paper proposes a novel deep learning-based approach to predict 3D GRF&amp;M from only 5 markers placed on the shoe. The proposed network “Attention Guided MultiResUNet” can predict the force and moment signals accurately and reliably compared to the techniques relying on full-body markers. The proposed deep learning model is tested on two publicly available datasets containing data from 66 healthy subjects to validate the approach. The framework has achieved an average correlation coefficient of 0.96 for 3D ground reaction force prediction and 0.86 for 3D ground reaction momentum prediction in cross-dataset validation. The framework can provide a cheaper and more feasible alternative for predicting GRF&amp;M in many practical applications.},
  archive      = {J_NCA},
  author       = {Faisal, Md. Ahasan Atick and Mahmud, Sakib and Chowdhury, Muhammad E. H. and Khandakar, Amith and Ahmed, Mosabber Uddin and Alqahtani, Abdulrahman and Alhatou, Mohammed},
  doi          = {10.1007/s00521-023-09081-z},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1105-1121},
  shortjournal = {Neural Comput. Appl.},
  title        = {Robust and novel attention guided MultiResUnet model for 3D ground reaction force and moment prediction from foot kinematics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised fabric defect detection with local spectra
refinement (LSR). <em>NCA</em>, <em>36</em>(3), 1091–1103. (<a
href="https://doi.org/10.1007/s00521-023-09080-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inspection of fabric defects is of great importance, as undetected and uncorrected defects entail poor production quality and expensive compensation. Due to the variety of defect types and sizes, it is a very tedious task to perform inspection manually. There are numerous automated systems in the literature; however, most of them require a training scheme where clean and defective fabric samples are manually fed to the system. Because of the diversity of fabric patterns and defect classes, supervised systems reduce convenience and ease of use in real practice. In this study, we propose an unsupervised, robust fabric defect detection method using spectral domain analysis. The proposed algorithm has a very simple flow and can run without any prior training scheme. First, the algorithm splits the input textile image into smaller patches and computes a generic spectral representation of the fabric pattern. Then, the method detects defective regions by measuring dissimilarities between the spectral representation and all local patches of the input fabric. We also introduce a textile fabric dataset, i.e., Ten Fabrics Dataset, which consists of ten different types of fabrics with 27 of the most common textile defects. According to the extensive set of experiments on two different datasets, the proposed method outperforms the state-of-the-art by achieving up to 94% accuracy.},
  archive      = {J_NCA},
  author       = {Shakir, Sahar and Topal, Cihan},
  doi          = {10.1007/s00521-023-09080-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1091-1103},
  shortjournal = {Neural Comput. Appl.},
  title        = {Unsupervised fabric defect detection with local spectra refinement (LSR)},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). End-to-end acceleration of the YOLO object detection
framework on FPGA-only devices. <em>NCA</em>, <em>36</em>(3), 1067–1089.
(<a href="https://doi.org/10.1007/s00521-023-09078-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection has been revolutionized by convolutional neural networks (CNNs), but their high computational complexity and heavy data access requirements make implementing these algorithms on edge devices challenging. To address this issue, we propose an efficient object detection accelerator for YOLO series algorithm. Our architecture utilizes multiple dimensions of parallelism to accelerate the convolution computation. We employ line-buffer-based parallel data caches and dedicated data access units to minimize off-chip bandwidth pressure. Additionally, our proposed design not only accelerates the convolutional computation, but also control-intensive post-processing to achieve low detection latency. We evaluate the final design on Xilinx V7-690t FPGA device, achieving a throughput of 525 GOP/s for a batch size of 1 and 914 GOP/s for a batch size equal to 2. Compared with state-of-the-art YOLOv2 and YOLOv3 implementations, our proposed accelerator offers up to 9 $$\times$$ throughput improvement and 5 $$\times$$ shorter latency.},
  archive      = {J_NCA},
  author       = {Zhang, Dezheng and Wang, Aibin and Mo, Ruchan and Wang, Dong},
  doi          = {10.1007/s00521-023-09078-8},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1067-1089},
  shortjournal = {Neural Comput. Appl.},
  title        = {End-to-end acceleration of the YOLO object detection framework on FPGA-only devices},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The effect of rebalancing techniques on the classification
performance in cyberbullying datasets. <em>NCA</em>, <em>36</em>(3),
1049–1065. (<a
href="https://doi.org/10.1007/s00521-023-09084-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberbullying detection systems rely increasingly on machine learning techniques. However, class imbalance in cyberbullying datasets, where the percentage of normal labeled classes is higher than that of abnormal labeled ones, presents a significant challenge for classification algorithms. This issue is particularly problematic in two-class datasets, where conventional machine learning methods tend to perform poorly on minority class samples due to the influence of the majority class. To address this problem, researchers have proposed various oversampling and undersampling techniques. In this paper, we investigate the effectiveness of such techniques in addressing class imbalance in cyberbullying datasets. We conduct an experimental study that involves a preprocessing step to enhance machine learning algorithm performance. We then examine the impact of imbalanced data on classification performance for four cyberbullying datasets. To study the classification performance on balanced cyberbullying datasets, we employ four resampling techniques, namely random undersampling, random oversampling, SMOTE, and SMOTE + TOMEK. We evaluate the impact of each rebalancing technique on classification performance using eight well-known classification algorithms. Our findings demonstrate that the performance of resampling techniques depends on the dataset size, imbalance ratio, and classifier used. The conducted experiments proved that there are no techniques that will always perform better the others.},
  archive      = {J_NCA},
  author       = {Khairy, Marwa and Mahmoud, Tarek M. and Abd-El-Hafeez, Tarek},
  doi          = {10.1007/s00521-023-09084-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {3},
  pages        = {1049-1065},
  shortjournal = {Neural Comput. Appl.},
  title        = {The effect of rebalancing techniques on the classification performance in cyberbullying datasets},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Neural networks as building blocks for the
design of efficient learned indexes. <em>NCA</em>, <em>36</em>(2), 1047.
(<a href="https://doi.org/10.1007/s00521-023-09079-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Amato, Domenico and Lo Bosco, Giosué and Giancarlo, Raffaele},
  doi          = {10.1007/s00521-023-09079-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {1047},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Neural networks as building blocks for the design of efficient learned indexes},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Fractional-order chaotic oscillator-based
aquila optimization algorithm for maximization of the chaotic with
lorentz oscillator. <em>NCA</em>, <em>36</em>(2), 1045. (<a
href="https://doi.org/10.1007/s00521-023-09077-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Cavlak, Yakup and Ateş, Abdullah and Abualigah, Laith and Elaziz, Mohammed Abd},
  doi          = {10.1007/s00521-023-09077-9},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {1045},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Fractional-order chaotic oscillator-based aquila optimization algorithm for maximization of the chaotic with lorentz oscillator},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards efficient image-based representation of tabular
data. <em>NCA</em>, <em>36</em>(2), 1023–1043. (<a
href="https://doi.org/10.1007/s00521-023-09074-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been widely used in image classification tasks and have achieved remarkable results compared with traditional methods. Their main advantage is the ability to extract hidden features automatically using local connectivity and spatial locality. However, CNN cannot be applied to tabular data, mainly due to the unsuitability of the tabular data structure to the CNN input. In this paper, we propose a new generic method for the representation of multidimensional tabular data as color-encoded images that can be used both for data visualization and classification with CNN. Our approach, named FC-Viz (Feature Clustering-Visualization), is based on user-oriented data visualization ideas, such as pixel-oriented techniques, feature clustering, and feature interactions. The proposed approach includes a transformation of each instance of the tabular data into a 2D pixel-based representation, where pixels representing features with strong correlation and interaction are adjacent to each other. We applied FC-Viz to ten multidimensional tabular datasets with dozens to thousands of features and compared its classification and visualization performance with a state-of-the-art tabular data transformation method. The evaluation experiments show that our approach is as accurate as the state-of-the-art, but with much smaller images resulting in much more compact and faster CNN models.},
  archive      = {J_NCA},
  author       = {Damri, Amit and Last, Mark and Cohen, Niv},
  doi          = {10.1007/s00521-023-09074-y},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {1023-1043},
  shortjournal = {Neural Comput. Appl.},
  title        = {Towards efficient image-based representation of tabular data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explored seeds generation for weakly supervised semantic
segmentation. <em>NCA</em>, <em>36</em>(2), 1007–1022. (<a
href="https://doi.org/10.1007/s00521-023-09073-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation with only image-level labels is an essential application since it reduces the considerable human effort to fully annotate image. Most state-of-the-art methods take into account discriminative regions or prior knowledge (called seeds) by applying the recent Classification Activation Maps (CAM) methods. As seeds used in the CAM methods could be considered as segmentation knowledge, increasing seeds will naturally improve the performance of the CAM methods. We treat such task as a seed exploration with clustering learning, which is different from the current methods in which region mining or seeds learning are performed in an end-to-end learning manner. In this paper, we propose a progressive framework containing autoencoders to explore numerous and accurate seeds to further improve the performance of CAM methods. Our explored seeds can replace the initial seeds, and thus, they can be integrated with current weakly supervised semantic segmentation methods for performance improvement. We show experimentally that our provided seeds lead to better model training. As a result, we obtain performance improvement from corresponding counterparts to reach 68.1 and 69.2% mIoU on PASCAL VOC 2012 validation and test dataset, respectively.},
  archive      = {J_NCA},
  author       = {Chow, Terence and Deng, Haojin and Yang, Yimin and Lin, Zhiping and Zhuang, Huiping and Du, Shan},
  doi          = {10.1007/s00521-023-09073-z},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {1007-1022},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explored seeds generation for weakly supervised semantic segmentation},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Denoising matrix factorization for high-dimensional time
series forecasting. <em>NCA</em>, <em>36</em>(2), 993–1005. (<a
href="https://doi.org/10.1007/s00521-023-09072-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The matrix factorization method (MF) has gained widespread popularity in recent years as an effective technique for handling high-dimensional time series data. By converting large-scale data sets into low-rank representations, MF-based methods have proven to be successful. However, these methods continue to face challenges in managing long-term dependencies, primarily due to the presence of noise and a lack of prior knowledge regarding the underlying matrix. To overcome this issue, we propose a novel approach that incorporates a latent bias effect and a denoising model, which enables the model to recover the underlying matrix more effectively and improves the precision of the model. By focusing only on relevant components, our proposed model constructs the underlying matrix more precisely through denoising operations. Our experiments conducted on four benchmark datasets demonstrate that our proposed model outperforms existing methods in terms of accuracy and robustness.},
  archive      = {J_NCA},
  author       = {Chen, Bo and Fang, Min and Li, Xiao},
  doi          = {10.1007/s00521-023-09072-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {993-1005},
  shortjournal = {Neural Comput. Appl.},
  title        = {Denoising matrix factorization for high-dimensional time series forecasting},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty-guided robust labels refinement for unsupervised
person re-identification. <em>NCA</em>, <em>36</em>(2), 977–991. (<a
href="https://doi.org/10.1007/s00521-023-09071-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing state-of-the-art unsupervised person re-identification (Re-ID) methods rely on clustering to generate pseudo labels for training. The reliability of pseudo labels directly affects the performance of these methods. Due to unsatisfactory feature embedding and imperfect clustering, pseudo labels are not always reliable that significantly hinder the representation learning of person. To address this issue, an Uncertainty-guided Robust labels refinement method is proposed. It employs uncertainty as guidance to selects and optimizes unreliable pseudo labels, which alleviates the impact of incorrect pseudo labels. Specially, an uncertainty estimation module is constructed, which identifies the samples with low reliability applies base on consistency between the ideal distribution and the predicted distribution. To mitigate the impact of unreliable samples, the labels refinement module is designed, which rebuilds labels for low reliability samples by measuring similarity from the closest centroid. Thanks to the reliability of pseudo labels provided by uncertain estimation module, the proposed method enhances robustness to noisy labels and learns discriminative representations of person. Extensive experiments demonstrate that the proposed method is effective and achieves advanced performance for unsupervised person Re-ID.},
  archive      = {J_NCA},
  author       = {Wang, Chengjun and Peng, Jinjia and Tao, Zeze and Wang, Huibing},
  doi          = {10.1007/s00521-023-09071-1},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {977-991},
  shortjournal = {Neural Comput. Appl.},
  title        = {Uncertainty-guided robust labels refinement for unsupervised person re-identification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variational gaussian topic model with invertible neural
projections. <em>NCA</em>, <em>36</em>(2), 961–975. (<a
href="https://doi.org/10.1007/s00521-023-09070-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural topic models have triggered a surge of interest in extracting topics from text automatically since they avoid the sophisticated derivations in conventional topic models. However, most of these models only utilize word count information, which will result in low coherent topics. To address this issue, we explore the way to incorporate word relatedness in word embeddings into the topic modeling process and propose the novel Variational Gaussian Topic Model (VaGTM). Based on the variational auto-encoder, the proposed VaGTM models each topic with a multivariate Gaussian in the decoder to group the semantically similar words together and obtains more coherent topics. Moreover, to address the limitation that pre-trained word embedding of topic-associated words does not exactly follows Gaussian, we extend the VaGTM and propose the Variational Gaussian Topic Model with Invertible neural Projections (VaGTM-IP). Extensive experiments have been conducted on three benchmark text corpora, and the experimental results show that VaGTM and VaGTM-IP outperform several competitive baselines in terms of four topic coherence metrics. Besides, the proposed approaches could also mine topic correlations between extracted topics with topic-associated Gaussian distributions.},
  archive      = {J_NCA},
  author       = {Wang, Rui and Zhou, Deyu and Xiong, Yuxuan and Huang, Haiping},
  doi          = {10.1007/s00521-023-09070-2},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {961-975},
  shortjournal = {Neural Comput. Appl.},
  title        = {Variational gaussian topic model with invertible neural projections},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Action recognition based on adaptive region perception.
<em>NCA</em>, <em>36</em>(2), 943–959. (<a
href="https://doi.org/10.1007/s00521-023-09069-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal modelling is still challenging for action recognition in video. To alleviate this problem, this paper proposes a new video architecture, called Adaptive Region Aware (ARP) network. The network focuses on combining short-range temporal information with long-range temporal information to perform effective action recognition. The core of our ARP is the Movement and Spatial-Temporal module (MST), which is made up of two modules, movement information and Spatial-Temporal information. MST uses the idea of difference for short-range temporal information extraction and adaptive region sensing and temporal convolution for long-range temporal information extraction. To extract temporal information for the entire video, our MST module contains two branches. Specifically, for local temporal information, we use the difference in motion between successive frames to extract a fine-grained representation of the motion, thus obtaining short-range temporal information. For the global temporal information, we use adaptive region awareness for feature extraction of the whole video to enhance the representation of the model in the spatio-temporal domain, and use temporal convolution for modelling to obtain our long-range temporal information. We insert the MST module into ResNet-50 to build our ARP network and experiment on the Something V1, Something V2 and Kinetics-400 datasets with optimal performance.},
  archive      = {J_NCA},
  author       = {Lu, Tongwei and Yang, Qi and Min, Feng and Zhang, Yanduo},
  doi          = {10.1007/s00521-023-09069-9},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {943-959},
  shortjournal = {Neural Comput. Appl.},
  title        = {Action recognition based on adaptive region perception},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Auto-encoding score distribution regression for action
quality assessment. <em>NCA</em>, <em>36</em>(2), 929–942. (<a
href="https://doi.org/10.1007/s00521-023-09068-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the quality of actions in videos is a challenging vision task, as the relationship between videos and action scores can be difficult to model. Consequently, extensive research has been conducted on action quality assessment (AQA) in the literature. Traditional AQA methods treat the problem as a regression task to learn the underlying mappings between videos and action scores. However, previous approaches overlook the presence of data uncertainty in AQA datasets. To address aleatoric uncertainty, we have developed a plug-and-play module called distribution auto-encoder (DAE). DAE encodes videos into distributions and utilizes the reparameterization trick to sample scores, which enables a more accurate mapping between videos and scores. Additionally, we use a likelihood loss to learn the uncertainty parameters. We have evaluated our approach on publicly available datasets, and extensive experiments demonstrate that DAE achieves state-of-the-art performance with the Spearman’s correlation metric of 82.58%, 92.32%, and 76.00% on the AQA-7, MTL-AQA, and JIGSAWSS datasets, respectively. Furthermore, plug-and-play experiments also demonstrate the extensibility of DAE. Our code is available at https://github.com/InfoX-SEU/DAE-AQA .},
  archive      = {J_NCA},
  author       = {Zhang, Boyu and Chen, Jiayuan and Xu, Yinfei and Zhang, Hui and Yang, Xu and Geng, Xin},
  doi          = {10.1007/s00521-023-09068-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {929-942},
  shortjournal = {Neural Comput. Appl.},
  title        = {Auto-encoding score distribution regression for action quality assessment},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A projected decentralized variance-reduction algorithm for
constrained optimization problems. <em>NCA</em>, <em>36</em>(2),
913–928. (<a href="https://doi.org/10.1007/s00521-023-09067-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving constrained optimization problems that require processing large-scale data is of significant value in practical applications, and such problems can be described as the minimization of a finite-sum of local convex functions. Many existing works addressing constrained optimization problems have achieved a linear convergence rate to the exact optimal solution if the constant step-size was sufficiently small. However, they still suffer from low computational efficiency because of the computation of the local batch gradients at each iteration. Considering high computational efficiency to resolve the constrained optimization problems, we introduce the projection operator and variance-reduction technique to propose a novel projected decentralized variance-reduction algorithm, namely P-DVR, to tackle the constrained optimization problem subject to a closed convex set. Theoretical analysis shows that if the local function is strongly convex and smooth, the P-DVR algorithm can converge to the exact optimal solution at a linear convergence rate $${\mathcal {O}} ( {\hat{\lambda }}^{k} )$$ with a sufficiently small step-size, where $$0&lt; {\hat{\lambda }} &lt; 1$$ . Finally, we experimentally validate the effectiveness of the algorithm, i.e., the algorithm possesses high computational efficiency and exact convergence.},
  archive      = {J_NCA},
  author       = {Deng, Shaojiang and Gao, Shanfu and Lü, Qingguo and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s00521-023-09067-x},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {913-928},
  shortjournal = {Neural Comput. Appl.},
  title        = {A projected decentralized variance-reduction algorithm for constrained optimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Community detection in attributed networks via adaptive deep
nonnegative matrix factorization. <em>NCA</em>, <em>36</em>(2), 897–912.
(<a href="https://doi.org/10.1007/s00521-023-09066-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection plays an important role in analyzing attributed networks. It attempts to find the optimal cluster structures to identify valuable information. Although deep nonnegative matrix factorization (DNMF) is widely used in community detection, it cannot be used to analyze attributed networks since only topology information is considered. Recent researches have taken attribute information into account, but we still need to face the following challenges. First, it is difficult to deal with topology noise and attribute noise in attributed networks at one stroke. Second, we need to balance the coupling between topology and node attributes with hyperparameters in most methods. However, with inappropriate hyperparameters, it is easy to cause interference and compromise between them. For the above challenges, in this paper, we propose a novel method, namely adaptive deep nonnegative matrix factorization. Specifically, we handle the inherent noise of attributed networks via dual-DNMF with autoencoder. And then, we use the attention mechanism to adaptively integrate topology information and attribute information without adjusting hyperparameters manually. Overall, our method not only handles the inherent noise in attributed networks, but also resolves the interference and compromise between topology and attributes in a generalized way. The results of comprehensive experiments support our conclusions and demonstrate that our method outperforms the state-of-the-art methods in most datasets.},
  archive      = {J_NCA},
  author       = {Cheng, Junwei and Tang, Yong and He, Chaobo and Han, Kunlin and Li, Ying and Wei, Jinhui},
  doi          = {10.1007/s00521-023-09066-y},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {897-912},
  shortjournal = {Neural Comput. Appl.},
  title        = {Community detection in attributed networks via adaptive deep nonnegative matrix factorization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient lightweight network for video super-resolution.
<em>NCA</em>, <em>36</em>(2), 883–896. (<a
href="https://doi.org/10.1007/s00521-023-09065-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, video super-resolution has achieved an outstanding performance. However, many existing methods to solve video super-resolution usually make use of complex strategies, such as explicit optical flow, deformable convolution, which increase complexity and computation. In this paper, we propose a lightweight network for video super-resolution, namely Efficient Lightweight Network for Video Super-Resolution (ELNVSR). We design a Multi-group Block extracting long-distance spatial information to construct a lightweight Bidirection Alignment Module which is implicitly capable of fusing and propagating spatial-temporal information in a bidirectional way. Meanwhile, a Multi-scale Pyramid Block is built as a lightweight reconstruction module to extract different levels of information layer by layer. Comprehensive experiments are conducted on public benchmarks. The results demonstrate a promising performance with fewer parameters.},
  archive      = {J_NCA},
  author       = {Luo, Laigan and Yi, Benshun and Wang, Zhongyuan and Yi, Peng and He, Zheng},
  doi          = {10.1007/s00521-023-09065-z},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {883-896},
  shortjournal = {Neural Comput. Appl.},
  title        = {Efficient lightweight network for video super-resolution},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new robust modified capuchin search algorithm for the
optimum amalgamation of DSTATCOM in power distribution networks.
<em>NCA</em>, <em>36</em>(2), 843–881. (<a
href="https://doi.org/10.1007/s00521-023-09064-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Very sensitive loads require the safe operation of electrical distribution networks, including hospitals, nuclear and radiation installations, industries used by divers, etc. To address this issue, the provided paper suggests an innovative method for evaluating the appropriate allocation of Distribution STATic COMpensator (DSTATCOM) to alleviate total power losses, relieve voltage deviation, and lessen capital annual price in power distribution grids (PDGs). An innovative approach, known as the modified capuchin search algorithm (mCapSA), has been introduced for the first time, which is capable of addressing several issues regarding optimal DSTATCOM allocation. Furthermore, the analytic hierarchy process method approach is suggested to generate the most suitable weighting factors for the objective function. In order to verify the feasibility of the proposed mCapSA methodology and the performance of DSTATCOM, it has been tested on two standard buses, the 33-bus PDG and the 118-bus PDG, with a load modeling case study based on real measurements and analysis of the middle Egyptian power distribution grid. The proposed mCapSA technique&#39;s accuracy is evaluated by comparing it to other 7 recent optimization algorithms including the original CapSA. Furthermore, the Wilcoxon sign rank test is used to assess the significance of the results. Based on the simulation results, it has been demonstrated that optimal DSTATCOM allocation contributes greatly to the reduction of power loss, augmentation of the voltage profile, and reduction of total annual costs. As a result of optimized DSTATCOM allocation in PDGs, distribution-level uncertainties can also be reduced.},
  archive      = {J_NCA},
  author       = {Tolba, Mohamed A. and Houssein, Essam H. and Ali, Mohammed Hamouda and Hashim, Fatma A.},
  doi          = {10.1007/s00521-023-09064-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {843-881},
  shortjournal = {Neural Comput. Appl.},
  title        = {A new robust modified capuchin search algorithm for the optimum amalgamation of DSTATCOM in power distribution networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel modified delphi-based spherical fuzzy AHP integrated
spherical fuzzy CODAS methodology for vending machine location selection
problem: A real-life case study in i̇stanbul. <em>NCA</em>,
<em>36</em>(2), 823–842. (<a
href="https://doi.org/10.1007/s00521-023-09063-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely delivery of products to customers is the great importance for retailers in supply chain management. Vending machines are one of the most effective retail tools for consumers to get the product they want at any time. With the developing technology, retailers tend to establish distribution with vending machines to provide faster service to the consumer. At this point, one of the primary objectives is to make the location selection decisions for these vending machines. The most suitable location selection decision includes the evaluation of each alternative under the specified criteria in a problem where there are multiple alternative locations. The present paper proposes a novel modified Delphi-based spherical fuzzy analytical hierarchy process (SFAHP) integrated spherical fuzzy combinative distance-based assessment (SFCODAS) methodology to the vending machine location selection (VMLS) problem. After determining the main and sub-criteria hierarchically, the Modified Delphi method is used to consolidate the opinions of the experts regarding the criteria and integrate them into the study. The main and sub-criteria weights are provided by the SFAHP method. And the most suitable location is determined by the SFCODAS method by ranking among the alternative locations according to these weighted criteria. The case study of VMLS is presented for a retail firm in Istanbul. Sensitivity analysis is performed to measure the flexibility of the proposed methodology. To validate the applicability of the proposed methodology, comparison analysis is presented with the results of the spherical fuzzy weighted aggregated sum-product assessment (SFWASPAS) method. Finally, the conclusions and future directions are discussed in the study.},
  archive      = {J_NCA},
  author       = {Yildiz, Aslihan and Ozkan, Coskun},
  doi          = {10.1007/s00521-023-09063-1},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {823-842},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel modified delphi-based spherical fuzzy AHP integrated spherical fuzzy CODAS methodology for vending machine location selection problem: A real-life case study in İstanbul},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep multi-scale convolutional neural networks for automated
classification of multi-class leaf diseases in tomatoes. <em>NCA</em>,
<em>36</em>(2), 803–822. (<a
href="https://doi.org/10.1007/s00521-023-09062-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques have gained immense popularity recently because of their remarkable capacity to learn complex patterns and features from large datasets. These techniques have revolutionized many fields by achieving advanced performance in various tasks. The availability of large datasets and the advancement of computing resources have enabled deep learning models to perform well in solving challenging problems. As a result, they have become an essential tool in many industries, including agriculture. The application of deep learning in agriculture has great potential for increasing productivity, reducing costs, and improving sustainability by aiding in the early identification and prevention of plant leaf diseases, optimizing crop yields, and facilitating precision agriculture. This paper suggests using a novel approach to automatically classify multi-class leaf diseases in tomatoes using a deep multi-scale convolutional neural network (DMCNN). The proposed DMCNN architecture consists of parallel streams of convolutional neural networks at different scales, which get merged at the end to form a single output. The images of tomato leaves are preprocessed using data augmentation techniques and fed into the DMCNN model to classify disease. The proposed approach is evaluated on a dataset of tomato plant images containing 10 distinct classes of diseases and compared with different existing models. The research results reveal that the suggested DMCNN model performs better than other models in terms of accuracy, precision, recall, and F1 score. Furthermore, the proposed model reported an overall accuracy of 99.1%, which is higher than the accuracy of existing models tested on the same dataset. The study demonstrates the potential of deep learning techniques for automated disease classification in agriculture, which can aid in early disease detection and prevent crop loss.},
  archive      = {J_NCA},
  author       = {Elfatimi, Elhoucine and Eryiğit, Recep and Elfatimi, Lahcen},
  doi          = {10.1007/s00521-023-09062-2},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {803-822},
  shortjournal = {Neural Comput. Appl.},
  title        = {Deep multi-scale convolutional neural networks for automated classification of multi-class leaf diseases in tomatoes},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-based features and bi-LSTM neural network for
EEG-based music and voice classification. <em>NCA</em>, <em>36</em>(2),
791–802. (<a href="https://doi.org/10.1007/s00521-023-09061-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain receives stimuli in multiple ways; among them, audio constitutes an important source of relevant stimuli for the brain regarding communication, amusement, warning, etc. In this context, the aim of this manuscript is to advance in the classification of brain responses to music of diverse genres and to sounds of different nature: speech and music. For this purpose, two different experiments have been designed to acquire EEG signals from subjects listening to songs of different musical genres and sentences in various languages. With this, a novel scheme is proposed to characterize brain signals for their classification; this scheme is based on the construction of a feature matrix built on relations between energy measured at the different EEG channels and the usage of a bi-LSTM neural network. With the data obtained, evaluations regarding EEG-based classification between speech and music, different musical genres, and whether the subject likes the song listened to or not are carried out. The experiments unveil satisfactory performance to the proposed scheme. The results obtained for binary audio type classification attain 98.66% of success. In multi-class classification between 4 musical genres, the accuracy attained is 61.59%, and results for binary classification of musical taste rise to 96.96%.},
  archive      = {J_NCA},
  author       = {Ariza, Isaac and Barbancho, Ana M. and Tardón, Lorenzo J. and Barbancho, Isabel},
  doi          = {10.1007/s00521-023-09061-3},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {791-802},
  shortjournal = {Neural Comput. Appl.},
  title        = {Energy-based features and bi-LSTM neural network for EEG-based music and voice classification},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). LRB-t: Local reasoning back-projection transformer for the
removal of bad weather effects in images. <em>NCA</em>, <em>36</em>(2),
773–789. (<a href="https://doi.org/10.1007/s00521-023-09059-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer vision, transformers have shown increasing effectiveness for high-level vision tasks. To further cope with low-level vision tasks, we propose a general framework, namely local reasoning back-projection transformer (LRB-T) for removing multiple types of bad weather (rain, haze, rain fog, raindrop, et al.) affecting images. Specifically, this paper first integrates the back-projection mechanism into the transformer architecture, where iterative up- and down-projection modules effectively feed and correct the feature reconstruction errors for spatial information preservation, and reduce computational costs since nearly half of the feature maps participate in the back-projection using half resolution. Besides, the proposed adaptive local reasoning block captures important neighborhood information through multiple local reasoning schemes. It can aggregate adjacent tokens to produce spatial-specific involution kernels, attention weights and dynamic positional encodings for local structure updating, and provide implicit spatial feature transform to achieve spatial-wise feature modulation. A pyramid scale guidance module is also established to enable arbitrary size generation consistent with the input, and generate scale-dependent trainable parameters to enhance skip connections. Extensive experiments on four types of well-known bad weather datasets show that the proposed LRB-T improves the image deraining, dehazing, de-rain fog and de-raindrop performance in terms of PSNR and SSIM effectively and outperforms state-of-the-art task-specific bad weather removal methods.},
  archive      = {J_NCA},
  author       = {Wang, Pengyu and Zhu, Hongqing and Zhang, Huaqi and Yang, Suyi},
  doi          = {10.1007/s00521-023-09059-x},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {773-789},
  shortjournal = {Neural Comput. Appl.},
  title        = {LRB-T: Local reasoning back-projection transformer for the removal of bad weather effects in images},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Capsule network-based disease classification for vitis
vinifera leaves. <em>NCA</em>, <em>36</em>(2), 757–772. (<a
href="https://doi.org/10.1007/s00521-023-09058-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary source of food is extracted from the plant. Take care of and maintain the plants in real-time to enhance human survival. Diseases in plants can directly lead to a reduction in the industrial economy. Automatic detection of plant diseases is crucial for effective disease control. Vitis vinifera (Grapes) is an essential crop with rich vitamin C nutrients. This paper targets to classify the major diseases in Vitis vinifera leaves using Capsule Network (CapsNet), that prevails over the significant CNN limitations by discarding the pooling layers and adding capsule layers. Dynamic routing techniques of CapsNet make are more robust for the affine transformation of the leaves dataset. It is capable of learning large datasets effectively with vital image transformations such as rotations and transitions. Implementing CapsNet for Vitis vinifera leaf disease classification, which utilizes dynamic routing between capsules, is a novel method. The proposed CapsNet for disease classification is trained with augmented and non-augmented datasets. The performance metrics highlight that the proposed method can effectively classify the Vitis vinifera plant leaves with 98.7% of validation accuracy. The results highlight that the proposed model performs well in detecting and classifying the diseases of Vitis vinifera plant leaves on two benchmark datasets.},
  archive      = {J_NCA},
  author       = {Andrushia, A. Diana and Neebha, T. Mary and Patricia, A. Trephena and Sagayam, K. Martin and Pramanik, Sabyasachi},
  doi          = {10.1007/s00521-023-09058-y},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {757-772},
  shortjournal = {Neural Comput. Appl.},
  title        = {Capsule network-based disease classification for vitis vinifera leaves},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pathological brain classification using multiple
kernel-based deep convolutional neural network. <em>NCA</em>,
<em>36</em>(2), 747–756. (<a
href="https://doi.org/10.1007/s00521-023-09057-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventionally, fine-tuning or transfer learning using a pre-trained convolutional network is adopted to design a classifier. However, when the dataset is small this can deteriorate the classifier generalization performance due to negative transfer or overfitting issues. In this paper, we suggest a flexible and high-capacity multiple kernel-based convolutional neural network (MK-CNN) to automate the pathological brain classification task. The proposed network employed different stacks of convolution with various kernels to obtain multi-scale features from the input image. The smaller kernel size provides specific information about the local features whereas the larger kernel size provides the global spatial information. Hence, the network takes into account both regional specifics and global spatial consistency thanks to this multi-scale methodology. Only the output layer is shared between each network stack. This makes it possible to specifically tweak the CNN’s weights and biases for each convolution stack and associated kernel size. The results reported on real patient data from the Harvard Whole Brain Atlas reveal that our method outperforms state-of-the-art techniques. The suggested approach may be used to help experts carry out the clinical follow-up study.},
  archive      = {J_NCA},
  author       = {Dora, Lingraj and Agrawal, Sanjay and Panda, Rutuparna and Pachori, Ram Bilas},
  doi          = {10.1007/s00521-023-09057-z},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {747-756},
  shortjournal = {Neural Comput. Appl.},
  title        = {Pathological brain classification using multiple kernel-based deep convolutional neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning applied to evaluation of reservoir
connectivity. <em>NCA</em>, <em>36</em>(2), 731–746. (<a
href="https://doi.org/10.1007/s00521-023-09056-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mature reservoirs, there are hundreds or thousands of producing and injecting wells operating simultaneously, so it is important to understand the impact of injection wells on producers to maintain pressure and control water production. In this work, we propose a workflow with two strategies, reduced-physics and data-driven modeling, to monitoring producer and injector wells based on interwell connectivity. The monitoring the wells allows to increase oil production, reducing water rate, and avoiding possible fracturing or fault reactivations. Both strategies use production history data only. The inputs in both strategies are injection rates, while output are liquid production rates. The first one, the reduced-physics modeling strategy, is based on the capacitance-resistance modeling for producers (CRMP), which calculates the liquid flowrate of the producing well based on the injection rate, productivity index of producers, time constant, and the connectivity between injectors and producers. The parameters of the CRMP model are obtained by minimizing the error between the observed and calculated liquid flowrates. The optimization algorithm that minimizes the error is the Sequential Quadratic Programming (SQP) and the gradient is obtained by finite differences. The second one, the data-driven modeling strategy is based on artificial neural networks (ANNs), which only use input and output data. The parameters of the artificial neural network, weights, and biases, are adjusted during the training process. Three architectures are proposed to match the outputs based on the inputs: single-layer perceptron, deep learning with multiple layers, and convolutional neural networks. The backpropagation algorithm is used to adjust the weights and biases of the architectures during training. In this study, we propose three alternatives for calculating the connectivities based on the trained model. The first one is based on the optimal weights. The second one is based on the average error after training and shuffling the input data, and the last one is based on the gradient importance. Two synthetic models, Two-phases, and Brush Canyon Outcrop, are used to validate the proposed workflow. The results show that the connectivities calculated by the gradient importance approach are closer to the connectivities obtained by the capacitance-resistance model. On the other hand, the connectivities obtained through the optimal weights and average error strategies show differences of 4% and 5%, respectively.},
  archive      = {J_NCA},
  author       = {Ramalho, Leticia Agra Mendes and Tueros, Juan Alberto Rojas and Horowitz, Bernardo},
  doi          = {10.1007/s00521-023-09056-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {731-746},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning applied to evaluation of reservoir connectivity},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consider high-order consistency for multi-view clustering.
<em>NCA</em>, <em>36</em>(2), 717–729. (<a
href="https://doi.org/10.1007/s00521-023-09054-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor-based multi-view clustering has attracted intensive attention due to the effectiveness of exploiting multi-view data information. However, most existing methods purely aim to explore the consistency of different views while neglecting the inherent difference between views, which may lead to incomplete modeling and affect the final clustering performance. To handle this problem, in this paper, we unify the consistency and specificity to model the multi-view data in a tensor manner. Specifically, we learn multiple candidate graphs corresponding to all views through self-expressiveness learning. Then these candidate graphs are decomposed into two sets of graphs, i.e., consistent graphs and specific graphs, respectively. After that, these consistent graphs are stacked into a tensor to exploit the high-order structure information while the specific graphs are used to capture the inherent difference in each view, such that a refined consensus affinity graph can be obtained for spectral clustering. The established model is dubbed Consider High-Order Consistency for Multi-View Clustering (CHOC-MVC), and its optimal problem can be efficiently solved by the alternating direction method of multipliers (ADMM). The experimental results demonstrate the effectiveness of our proposed method. The source code is available at https://github.com/haoranli50/CHOC-MVSC .},
  archive      = {J_NCA},
  author       = {You, Xiaojian and Li, Haoran and You, Jiali and Ren, Zhenwen},
  doi          = {10.1007/s00521-023-09054-2},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {717-729},
  shortjournal = {Neural Comput. Appl.},
  title        = {Consider high-order consistency for multi-view clustering},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Re-evaluation of machine learning models for predicting
ultimate bearing capacity of piles through SHAP and joint shapley
methods. <em>NCA</em>, <em>36</em>(2), 697–715. (<a
href="https://doi.org/10.1007/s00521-023-09053-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the prediction of the load-bearing capacity of closed and open-ended piles using machine learning (ML) methods. Full-scale load test results and CPT data are used to gather two comprehensive databases for such piles. ML models are developed employing input features associated with pile geometry and CPT resistances along with the ultimate bearing capacity being the only output feature. Following the training/testing sequences, the interpretability of ML predictions is examined through the Shapley and Joint Shapley value methods. Shapley values for multiple feature combinations allow ML models to decide the number of features necessary to make the most accurate predictions. Using updated input features, the models are rebuilt and predictions are repeated with the new input feature set; hence, the re-evaluation of ML models is focused on at this point. These features are twofold: One has two geometric features attributed to piles: cross-section area and length, and the other is a single feature attributed to soil, the average CPT tip resistance, which are overall sufficient in predicting the load capacity of both closed and open-ended piles. To the best of our knowledge, this study is one of the pioneers of its kind for pile foundations. The results show that the predictions of ML methods aided with strong interpretability techniques prove to be necessary in providing accurate results. As a result, Shapley is determined to be a useful tool for other geotechnical engineering applications as well.},
  archive      = {J_NCA},
  author       = {Karakaş, S. and Taşkın, G. and Ülker, M. B. C.},
  doi          = {10.1007/s00521-023-09053-3},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {697-715},
  shortjournal = {Neural Comput. Appl.},
  title        = {Re-evaluation of machine learning models for predicting ultimate bearing capacity of piles through SHAP and joint shapley methods},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local features-based evidence glossary for generic
recognition of handwritten characters. <em>NCA</em>, <em>36</em>(2),
685–695. (<a href="https://doi.org/10.1007/s00521-023-09051-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of handwritten characters has been a challenging task so far. There exist thousands of official languages across the globe which are used to communicate through documentation. Optical character recognition (OCR) being the challenging domain in such context where images of such documents are to be recognized either offline or online. Online and offline recognition of documents refer to the approaches whereby the basic operation of character recognition is performed during documentation itself and recognizing characters from stored documents, respectively. Numerous applications from a range of fields like medical transcription, digitization of ancient manuscripts, language translations, etc. are solely dependent on the task of OCR. In this work, an efficient framework is presented for the purpose of handwritten character recognition that can be well utilized for both offline and online processes. The proposed work takes the handwritten character images as input. It applies set of pre-processing such that the samples become suitable for the feature extraction task. The novelty lies in the process of feature extraction whereby three distinct types of feature are considered based on the shape primitives of the images. These features are global to the sample. Subsequently, local shape features are further extracted out of this shape features after suitable quantization process. These local features are the evidences which can be generically used to recognize test samples. These local feature vectors are dubbed as evidences and are preserved into a glossary dubbed as evidence glossary. The efficiency of the proposed scheme is well justified as it utilizes only a fraction of the feature vector and still it can recognize the characters. Other advantages of the proposed work are scale invariance and rotations invariance. Suitable datasets from two distinct languages, namely Odia and English are utilized for evaluating the efficiency of the framework. Comparison of the performance of the framework with six distinct state-of-the-art machine learning models is conducted whereby it outclass the competent in terms of several performance metrics.},
  archive      = {J_NCA},
  author       = {Mishra, Tusar Kanti and Kolhar, Manjur and Mishra, Soumya Ranjan and Mohapatra, Hitesh and Al-Turjman, Fadi and Rath, Amiya Kumar},
  doi          = {10.1007/s00521-023-09051-5},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {685-695},
  shortjournal = {Neural Comput. Appl.},
  title        = {Local features-based evidence glossary for generic recognition of handwritten characters},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-media web video event mining based on multiple
semantic-paths embedding. <em>NCA</em>, <em>36</em>(2), 667–683. (<a
href="https://doi.org/10.1007/s00521-023-09050-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web video event mining based on cross-media fusion has become a research hotspot. However, each video is only described by a dozen noisy words, resulting in extremely unstable textual features. Moreover, different people might describe the same video with completely different words. Thus, the semantic association between textual and visual information would be much sparse, which brings great challenges to web video event mining based on cross-media associations. To address this issue, this paper proposes a novel framework to enrich the associations between near duplicate keyframes (NDK) and terms based on multiple semantic-paths embedding. After data preprocessing, we build a heterogeneous information network to establish associations among NDKs, terms and videos. Then, semantic-path walk strategy is designed to generate meaningful semantic-node sequences for embedding. Next, an embedding fusion method is proposed to predict the distribution characteristics of each term in NDKs. Finally, multiple correspondence analysis is used to mine web video events. Experiments on web videos from YouTube show that our proposed method performs better than several state-of-the-art baseline models, with an average F1 score improvement of 19–50%.},
  archive      = {J_NCA},
  author       = {Xiao, Xia and Du, Mingyue and Xu, Shuyu and Liu, Guoying and Zhang, Chengde},
  doi          = {10.1007/s00521-023-09050-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {667-683},
  shortjournal = {Neural Comput. Appl.},
  title        = {Cross-media web video event mining based on multiple semantic-paths embedding},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DVC-net: A new dual-view context-aware network for emotion
recognition in the wild. <em>NCA</em>, <em>36</em>(2), 653–665. (<a
href="https://doi.org/10.1007/s00521-023-09040-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition in the wild (ERW) is a challenging task due to unknown and the unconstrained scenes in the wild environment. Different from previous approaches that use facial expression or posture for ERW, a growing number of researches are beginning to utilize contextual information to improve the performance of emotion recognition. In this paper, we propose a new dual-view context-aware network (DVC-Net) to fully explore the usage of contextual information from global and local views, and balance the individual features and context features by introducing the attention mechanism. The proposed DVC-Net consists of three parallel modules: (1) the body-aware stream to suppress the uncertainties of body gesture feature representation, (2) the global context-aware stream based on salient context to capture the global-level effective context, and (3) the local context-aware stream based on graph convolutional network to find the local discriminative features with emotional cues. Quantitative evaluations have been carried out on two in-the-wild emotion recognition datasets. The experimental results demonstrated that the proposed DVC-Net outperforms the state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Qing, Linbo and Wen, Hongqian and Chen, Honggang and Jin, Rulong and Cheng, Yongqiang and Peng, Yonghong},
  doi          = {10.1007/s00521-023-09040-8},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {653-665},
  shortjournal = {Neural Comput. Appl.},
  title        = {DVC-net: A new dual-view context-aware network for emotion recognition in the wild},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revolutionizing neural network efficiency: Introducing FPAC
for filter pruning via attention consistency. <em>NCA</em>,
<em>36</em>(2), 639–652. (<a
href="https://doi.org/10.1007/s00521-023-09037-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of feature mapping is used to represent features on a map with their corresponding properties. The features are displayed visually and their associated information is made available. Various abstraction approaches, including alignment approaches, are introduced to reduce the computational complexity. However, previous works based on standard treatments of feature maps often suffer from the negative effects of noise and background details. To solve this problem, we present a simple and effective implementation approach for Filter Pruning via Attention Consistency (FPAC), which determines a revolutionary filter pruning mechanism. Feature maps that concentrate on a single layer are inconsistent, which can affect the spatial dimension. The feature map with minimum consistency is less significant and is experimentally demonstrated. This study presents a novel layer-wise pruning technique using the Aphid Ant Mutualism (AAM) algorithm, which considers the sensitivity of various convolutional network layers to model inference and sets the optimal pruning ratio. The accuracy of the compressed model is enhanced by eliminating high redundancy through pruning correlated filters. The performance of FPAC is confirmed through the Caltech 256 image dataset. With VGG-16 on the Caltech 256 image dataset, the classification accuracy is enhanced from 93.96 to 94.03%. With ResNet-50 on the Caltech 256 image dataset, 45% FLOPs are achieved with an accuracy loss of only 0.53%.},
  archive      = {J_NCA},
  author       = {Mana, Suja Cherukullapurath and Rajesh, Sudha and Governor, Kalaiarasi and Chandrasekaran, Hemalatha and Murugesan, Kanipriya},
  doi          = {10.1007/s00521-023-09037-3},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {639-652},
  shortjournal = {Neural Comput. Appl.},
  title        = {Revolutionizing neural network efficiency: Introducing FPAC for filter pruning via attention consistency},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective reward generalization: Improving performance
of deep reinforcement learning for applications in single-asset trading.
<em>NCA</em>, <em>36</em>(2), 619–637. (<a
href="https://doi.org/10.1007/s00521-023-09033-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the potential of Multi-Objective, Deep Reinforcement Learning for stock and cryptocurrency single-asset trading: in particular, we consider a Multi-Objective algorithm which generalizes the reward functions and discount factor (i.e., these components are not specified a priori, but incorporated in the learning process). Firstly, using several important assets (BTCUSD, ETHUSDT, XRPUSDT, AAPL, SPY, NIFTY50), we verify the reward generalization property of the proposed Multi-Objective algorithm, and provide preliminary statistical evidence showing increased predictive stability over the corresponding Single-Objective strategy. Secondly, we show that the Multi-Objective algorithm has a clear edge over the corresponding Single-Objective strategy when the reward mechanism is sparse (i.e., when non-null feedback is infrequent over time). Finally, we discuss the generalization properties with respect to the discount factor. The entirety of our code is provided in open-source format.},
  archive      = {J_NCA},
  author       = {Cornalba, Federico and Disselkamp, Constantin and Scassola, Davide and Helf, Christopher},
  doi          = {10.1007/s00521-023-09033-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {619-637},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-objective reward generalization: Improving performance of deep reinforcement learning for applications in single-asset trading},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved hybrid ICA-SA metaheuristic for order acceptance
and scheduling with time windows and sequence-dependent setup times.
<em>NCA</em>, <em>36</em>(2), 599–617. (<a
href="https://doi.org/10.1007/s00521-023-09030-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Order acceptance and scheduling (OAS) is a critical part of production planning in manufacturing units. In real-world problems, where the manufacturing units are required to meet capacity limitations and delivery time obligations, OAS problem arises. In this study, a hybrid population-based heuristic of imperialists competitive algorithm (ICA) and well-known simulated annealing (SA) has been applied to deal with the variant of OAS with time windows and sequence-dependent setup time. As part of ICA, a specific representation has been proposed to capture all of the characteristics of an OAS solution. The neighborhood functions have been developed based on this specific representation. In order to improve conventional ICA, a roulette wheel is used for selecting these functions, which is periodically updated based on their prior effectiveness. As an additional approach to avoid being confined to a local optimum point, an escape strategy is employed. This part of the study utilizes eight local search functions that are different from those in the ICA in order to further diversify the population. The proposed algorithm has been implemented on benchmark instances, and results have been analyzed. The results of our experiments demonstrated that ICA-SA shows improvement over well-known existing methods both in terms of quality and speed. In addition, we found in 32 out of 1500 cases, ICA-SA yielded a better result than the upper bound generated by MILP. This improvement in optimal solutions was made possible due to the allowance of scheduling tasks with zero revenue in this study. Therefore by relaxing one of the constraints of MILP, better upper bounds can be achieved.},
  archive      = {J_NCA},
  author       = {Mahmoudinazlou, Sasan and Alizadeh, Arash and Noble, James and Eslamdoust, Sina},
  doi          = {10.1007/s00521-023-09030-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {599-617},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved hybrid ICA-SA metaheuristic for order acceptance and scheduling with time windows and sequence-dependent setup times},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Offline reinforcement learning in high-dimensional
stochastic environments. <em>NCA</em>, <em>36</em>(2), 585–598. (<a
href="https://doi.org/10.1007/s00521-023-09029-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (RL) has emerged as a promising paradigm for real-world applications since it aims to train policies directly from datasets of past interactions with the environment. The past few years, algorithms have been introduced to learn from high-dimensional observational states in offline settings. The general idea of these methods is to encode the environment into a latent space and train policies on top of this smaller representation. In this paper, we extend this general method to stochastic environments (i.e., where the reward function is stochastic) and consider a risk measure instead of the classical expected return. First, we show that, under some assumptions, it is equivalent to minimizing a risk measure in the latent space and in the natural space. Based on this result, we present Latent Offline Distributional Actor-Critic (LODAC), an algorithm which is able to train policies in high-dimensional stochastic and offline settings to minimize a given risk measure. Empirically, we show that using LODAC to minimize Conditional Value-at-Risk (CVaR) outperforms previous methods in terms of CVaR and return on stochastic environments.},
  archive      = {J_NCA},
  author       = {Hêche, Félicien and Barakat, Oussama and Desmettre, Thibaut and Marx, Tania and Robert-Nicoud, Stephan},
  doi          = {10.1007/s00521-023-09029-3},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {585-598},
  shortjournal = {Neural Comput. Appl.},
  title        = {Offline reinforcement learning in high-dimensional stochastic environments},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FGNet: Fixation guidance network for salient object
detection. <em>NCA</em>, <em>36</em>(2), 569–584. (<a
href="https://doi.org/10.1007/s00521-023-09028-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In challenging scenarios (e.g., small objects and cluttered backgrounds), most existing algorithms suffer from inconsistent results with human visual attention. Since fixation prediction can better model the human visual attention mechanism and has a strong correlation with salient objects. Inspired by this, we proposed a fixation guidance network (FGNet) for salient object detection, which innovatively used fixation prediction to guide both salient object detection and edge detection. Firstly, a multi-branch network structure was designed to achieve multi-task detection. Each branch unit significantly learned the extracted features to accomplish the correct prediction. Secondly, given the strong correlation between the fixation and salient objects, a fixation guidance module was employed to guide salient object detection and edge detection for obtaining more accurate detection results. Finally, to  full use the complementary relationship between salient features and edge features, we proposed a multi-resolution feature interaction module to achieve mutual optimization within the same feature and between the different features for suppressing noise and enhancing their representations. The experimental results show that our proposed method performed better in challenging scenes and outperformed existing state-of-the-art algorithms in several metrics on four public benchmark datasets.},
  archive      = {J_NCA},
  author       = {Yuan, Junbin and Xiao, Lifang and Wattanachote, Kanoksak and Xu, Qingzhen and Luo, Xiaonan and Gong, Yongyi},
  doi          = {10.1007/s00521-023-09028-4},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {569-584},
  shortjournal = {Neural Comput. Appl.},
  title        = {FGNet: Fixation guidance network for salient object detection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel reinforcement learning-based reptile search
algorithm for solving optimization problems. <em>NCA</em>,
<em>36</em>(2), 533–568. (<a
href="https://doi.org/10.1007/s00521-023-09023-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel reptile search algorithm (RSA) to solve optimization problems called reinforcement reptile search algorithm (RLRSA). The basic RSA performs exploitation through highly walking in the first half of searching process while the exploration phase is executed through the hunting phase in the second half. Therefore, the algorithm is not able to balance exploration and exploitation and this behavior results in trapping in local optima. A novel learning method based on reinforcement learning and Q-learning model is proposed to balance the exploitation and exploration phases when the solution starts deteriorating. Furthermore, the random opposite-based learning (ROBL) is introduced to increase the diversity of the population and so enhance the obtained solutions. Twenty-three typical benchmark functions, including unimodal, multimodal and fixed-dimension multimodal functions, were employed to assess the performance of RLRSA. According to the findings, the RLRSA method surpasses the standard RSA approach in the majority of benchmark functions evaluated, specifically in 12 out of 13 unimodal functions, 9 out of 13 multimodal functions, and 8 out of 10 fixed multimodal functions. Furthermore, the RLRSA is applied to vessel solve pressure and tension/compression spring design problems. The results show that RLRSA significantly found the solution with minimum cost. The experimental results reveal the superiority of the RLRSA compared to RSA and other optimization methods in the literature.},
  archive      = {J_NCA},
  author       = {Ghetas, Mohamed and Issa, Mohamed},
  doi          = {10.1007/s00521-023-09023-9},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {533-568},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel reinforcement learning-based reptile search algorithm for solving optimization problems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel adaptive fuzzy prescribed performance congestion
control for network systems with predefined settling time. <em>NCA</em>,
<em>36</em>(2), 523–532. (<a
href="https://doi.org/10.1007/s00521-023-09022-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adaptive predefined settling time performance tracking control for a class of uncertain nonlinear network systems with fast time-varying or even abrupt reference signals is studied. In this paper, an improved performance function with time-varying boundary (following the change of reference signal) is designed to overcome the problem that the traditional prescribed performance control (PPC) can only converge to a constant in steady state. Compared with the existing adaptive finite time prescribed performance congestion control for tracking fixed value reference signals, an adaptive predefined settling time prescribed performance congestion control strategy is proposed by means of some new recursive construction (introducing nonautonomous differential equations (NDE)) and analysis innovation. In addition, the network system considered in this paper is more general. Under the framework of backstepping, NDE is used iteratively to control the approximation error with boundary inequality. It is proved theoretically that all signals of the closed-loop system are predefined settling time bounded. Finally, the effectiveness of the proposed control strategy is verified by simulations.},
  archive      = {J_NCA},
  author       = {Qi, Xuelei and Li, Chen and Ni, Wei and Ma, Hongjun},
  doi          = {10.1007/s00521-023-09022-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {2},
  pages        = {523-532},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel adaptive fuzzy prescribed performance congestion control for network systems with predefined settling time},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Nonlinear feature selection using
sparsity-promoted centroid-encoder. <em>NCA</em>, <em>36</em>(1), 521.
(<a href="https://doi.org/10.1007/s00521-023-09076-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ghosh, Tomojit and Kirby, Michael},
  doi          = {10.1007/s00521-023-09076-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {521},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Nonlinear feature selection using sparsity-promoted centroid-encoder},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Novel neural adaptive terminal sliding mode
control for TCP network systems with arbitrary convergence time.
<em>NCA</em>, <em>36</em>(1), 519. (<a
href="https://doi.org/10.1007/s00521-023-09048-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Qi, Xuelei and Li, Chen and Chen, Bao and Ni, Wei and Ma, Hongjun},
  doi          = {10.1007/s00521-023-09048-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {519},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Novel neural adaptive terminal sliding mode control for TCP network systems with arbitrary convergence time},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Scarce data driven deep learning of drones
via generalized data distribution space. <em>NCA</em>, <em>36</em>(1),
517. (<a href="https://doi.org/10.1007/s00521-023-09006-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Li, Chen and Sun, Schyler C. and Wei, Zhuangkun and Tsourdos, Antonios and Guo, Weisi},
  doi          = {10.1007/s00521-023-09006-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {517},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction to: Scarce data driven deep learning of drones via generalized data distribution space},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing explanations in RL. <em>NCA</em>, <em>36</em>(1),
505–516. (<a href="https://doi.org/10.1007/s00521-023-08696-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep reinforcement learning (RL)’s capabilities surpass traditional reinforcement learning, the community is working to make these black boxes less opaque. Explanations about algorithms’ choices and strategies serve this purpose. However, information about RL algorithms’ operations is not easily accessible. Our research aimed to extract such information, use it to build explanations, and test those explanations with users. For our user study, eight RL agents were trained using OpenAI baselines. Then, the HIGHLIGHTS-VIS algorithm was created by altering previous HIGHLIGHTS algorithms to collect data about the agents’ interactions with the environment. The data were used to create explanations that were compared to previous works’ video-based summaries in a user study. The between-subjects user study had participants answer questions about different agents. Participants were measured using both self-reported trust and performance on downstream tasks. Downstream tasks are tasks that a participant is more likely to do correctly with the information contained in the explanation. Collecting data about both trust and the utility of explanations allowed comparison and analysis of the explanations’ effectiveness. Results showed that the alternative explanations built from the collected data led to more correct answers about the agents and their strategies. Additionally, explanations’ utility depended on the context. Finally, users’ reported trust in an explanation did not directly correlate to performance. These results suggest trust and effectiveness may need to be measured and calibrated separately in future examinations of explanations.},
  archive      = {J_NCA},
  author       = {Pierson, Britt Davis and Arendt, Dustin and Miller, John and Taylor, Matthew E.},
  doi          = {10.1007/s00521-023-08696-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {505-516},
  shortjournal = {Neural Comput. Appl.},
  title        = {Comparing explanations in RL},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time and pinning synchronization of multi-weighted
delayed coupled cohen–grossberg neural networks. <em>NCA</em>,
<em>36</em>(1), 483–504. (<a
href="https://doi.org/10.1007/s00521-023-09019-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synchronization of multi-weighted delayed coupled Cohen–Grossberg neural networks (CCGNNs) is considered in this paper. On the one hand, by designing a general controller and an aperiodically intermittent controller, respectively, several adequate conditions for reaching finite-time synchronization of the considered network are obtained, and the settling time is given. On the other hand, the pinning synchronization of the delayed CCGNNs with multiple weights is considered, and some corresponding criteria of pinning synchronization are derived by a general adaptive control scheme and an adaptive aperiodically intermittent control scheme, respectively. Finally, two illustrative examples including numerical simulations are presented to show the correctness of our results.},
  archive      = {J_NCA},
  author       = {Huang, Yanli and Hao, Qing},
  doi          = {10.1007/s00521-023-09019-5},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {483-504},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time and pinning synchronization of multi-weighted delayed coupled Cohen–Grossberg neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal multi-objective optimization based on local
optimal neighborhood crowding distance differential evolution algorithm.
<em>NCA</em>, <em>36</em>(1), 461–481. (<a
href="https://doi.org/10.1007/s00521-023-09018-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, the optimal solutions of multi-objective optimization are not unique. Some problems exist different Pareto Sets (PSs) in the decision space mapped to the same Pareto Front (PF) in the objective space, which are called multimodal multi-objective problems (MMOPs). To tackle this issue, this paper proposes a multimodal multi-objective optimization based on a local optimal neighborhood crowding distance differential evolution algorithm. First, an adaptive partitioning strategy in the initialization phase is proposed by using the characteristics of the heuristic stochastic search. That ensures the local optimal solution is quickly found among multiple PSs. Second, opposition-based learning is combined with differential mutation to generate vectors, which accelerate the convergence of the population to the optimal solution. Finally, a method for neighborhood crowding distances on different Pareto ranks is designed. The distance is computed by a weighted sum of Euclidean distances for the nearest neighbors. While reducing computational complexity, this strategy reflects realistic crowding degree. With these methods, balances the diversity performance of the decision and the objective space, while improving the search capability. Multiple PSs reveal the problem’s potential characteristics and meet the needs of the decision-maker. The practical significance is verified by the application of actual distance minimization problem. According to experimental results, the proposed method can achieve a high level of comprehensive performance.},
  archive      = {J_NCA},
  author       = {Gu, Qinghua and Peng, Yifan and Wang, Qian and Jiang, Song},
  doi          = {10.1007/s00521-023-09018-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {461-481},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multimodal multi-objective optimization based on local optimal neighborhood crowding distance differential evolution algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Fixed-time convergent RNNs with logarithmic settling time
for time-variant quadratic programming solving with application to
repetitive motion planning. <em>NCA</em>, <em>36</em>(1), 445–460. (<a
href="https://doi.org/10.1007/s00521-023-09016-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, fixed-time convergent RNNs with logarithmic settling time are proposed for solving time-variant quadratic programming (QP), where the domain of attraction of the RNN models can be reasonably estimated a priori. Two novel activation functions are designed, and the exact expressions of the settling time functions for each given initial condition are given; and upper bounds of the settling times for any given initial condition can be obtained. In addition, the generic activation functions are constructed and analyzed to achieve logarithmic fixed-time settling. The RNNs based on the generic activation function are designed, which have a faster convergence rate and a fixed-time convergence property. By estimating the bound of the settling time function under given initial conditions in the bounded region, the semi-global fixed-time convergence of the RNN model is in turn established. It is shown that the predefined-time convergence of modified RNN models can be assured by adopting the inverse of the bound. Simulation results verify effectiveness of the proposed computing schemes for the time-variant QP problem solving and the repetitive motion planning of a redundant manipulator.},
  archive      = {J_NCA},
  author       = {Li, Xing and Wang, Liming and Zhong, Guomin and Sun, Mingxuan},
  doi          = {10.1007/s00521-023-09016-8},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {445-460},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fixed-time convergent RNNs with logarithmic settling time for time-variant quadratic programming solving with application to repetitive motion planning},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Projection neural networks with finite-time and fixed-time
convergence for sparse signal reconstruction. <em>NCA</em>,
<em>36</em>(1), 425–443. (<a
href="https://doi.org/10.1007/s00521-023-09015-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the $$L_1$$ -minimization problem for sparse signal and image reconstruction by using projection neural networks (PNNs). Firstly, a new finite-time converging projection neural network (FtPNN) is presented. Building upon FtPNN, a new fixed-time converging PNN (FxtPNN) is designed. Under the condition that the projection matrix satisfies the Restricted Isometry Property (RIP), the stability in the sense of Lyapunov and the finite-time convergence property of the proposed FtPNN are proved; then, it is proven that the proposed FxtPNN is stable and converges to the optimum solution regardless of the initial values in fixed time. Finally, simulation examples with signal and image reconstruction are carried out to show the effectiveness of our proposed two neural networks, namely FtPNN and FxtPNN.},
  archive      = {J_NCA},
  author       = {Xu, Jing and Li, Chuandong and He, Xing and Zhang, Xiaoyu},
  doi          = {10.1007/s00521-023-09015-9},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {425-443},
  shortjournal = {Neural Comput. Appl.},
  title        = {Projection neural networks with finite-time and fixed-time convergence for sparse signal reconstruction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing aerial robots performance through robust hybrid
control and metaheuristic optimization of controller parameters.
<em>NCA</em>, <em>36</em>(1), 413–424. (<a
href="https://doi.org/10.1007/s00521-023-09014-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous flying robots (AFRs) have captured significant interest owing to their agile maneuverability, adaptability, and economical viability. However, the pursuit of enhancing their trajectory tracking performance presents an ongoing challenge. In light of this, our work introduces an innovative strategy that integrates optimization metaheuristic algorithms with a robust hybrid control framework for AFRs, resulting in an optimized and robust controller tailored for autonomous quadrotor robots. By optimizing the controller parameters, we aim to minimize the tracking error and improve the overall performance of AFRs. To evaluate our approach, this study comprehensively analyzes four metaheuristic algorithms in addition to the Improved Grey Wolf Optimization (I-GWO) which outperforms others in quality, convergence rate, and robustness. The proposed I-GWO integration yields a tracking error of 23.25, surpassing Grey Wolf Optimizer (GWO) (24.36), Artificial Bee Colony (ABC) (29.63), and Sine Cosine Algorithm (SCA) (2481.56). The I-GWO has also achieved its minimum objective value within less than 20 iterations compared to other algorithms. Extensive simulations show that our framework achieves optimal and accurate trajectory tracking, critical for safe and efficient AFR operations in various applications. This study emphasizes the importance of choosing suitable optimization algorithms and provides a systematic method for tuning controller gains applicable to different AFR types and control problems. Our contributions could advance more reliable and advanced AFR development in areas such as agriculture, inspection, monitoring, and search and rescue operations. A supplemental animated simulation of this work is available at https://youtu.be/aJMq8ROW51g .},
  archive      = {J_NCA},
  author       = {Alqudsi, Yunes Sh. and Saleh, Radhwan A. A. and Makaraci, Murat and Ertunç, H. Metin},
  doi          = {10.1007/s00521-023-09014-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {413-424},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing aerial robots performance through robust hybrid control and metaheuristic optimization of controller parameters},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing quality of pose-varied face restoration with local
weak feature sensing and GAN prior. <em>NCA</em>, <em>36</em>(1),
399–412. (<a href="https://doi.org/10.1007/s00521-023-09013-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial semantic guidance (including facial landmarks, facial heatmaps, and facial parsing maps) and facial generative adversarial networks (GAN) prior have been widely used in blind face restoration (BFR) in recent years. Although existing BFR methods have achieved good performance in ordinary cases, these solutions have limited resilience when applied to face images with serious degradation and pose-varied (e.g., looking right, looking left, laughing, etc.) in real-world scenarios. In this work, we propose a well-designed blind face restoration network with generative facial prior. The proposed network is mainly comprised of an asymmetric codec and a StyleGAN2 prior network. In the asymmetric codec, we adopt a mixed multi-path residual block (MMRB) to gradually extract weak texture features of input images, which can better preserve the original facial features and avoid excessive fantasy. The MMRB can also be plug-and-play in other networks. Furthermore, thanks to the affluent and diverse facial priors of the StyleGAN2 model, we adopt it as the primary generator network in our proposed method and specially design a novel self-supervised training strategy to fit the distribution closer to the target and flexibly restore natural and realistic facial details. Extensive experiments on synthetic and real-world datasets demonstrate that our model performs superior to the prior art for face restoration and face super-resolution tasks.},
  archive      = {J_NCA},
  author       = {Hu, Kai and Liu, Yu and Liu, Renhe and Lu, Wei and Yu, Gang and Fu, Bin},
  doi          = {10.1007/s00521-023-09013-x},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {399-412},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing quality of pose-varied face restoration with local weak feature sensing and GAN prior},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An approach for classifying ceramic tile defects based on a
two-dimensional genetic CNN algorithm. <em>NCA</em>, <em>36</em>(1),
385–397. (<a href="https://doi.org/10.1007/s00521-023-09012-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ceramic tile industry is facing significant challenges in the industrial revolution 4.0. Most of the ceramic tile factories are under backward technologies, especially in the developing countries. Due to their complicated process and current technologies, there are many surface defects occurring on the final products. Classifying and grading the product still relies on humans which has caused many problems. Hence, developing an optimal model to deal with this surface defect detection and classification automatically is necessary for these companies. This study aims to propose a two-dimensional genetic algorithm-based convolutional neural network (2DG-CNN) which can automatically generate an optimal convolutional neural network (CNN) for detecting and classifying the defect products. In particular, a general CNN structure is firstly determined including the number of convolution layers, pooling layers, and fully connected layers. A two-dimensional chromosome is designed to represent a CNN model efficiently. In addition, a novel matrix crossover is developed to create more diversified offspring. A database of ceramic tile surface images is constructed to validate the proposed approach. The 2DG-CNN was compared with the other well-known algorithms. The results have shown the efficiency of the proposed approach.},
  archive      = {J_NCA},
  author       = {Huynh, Nhat-To},
  doi          = {10.1007/s00521-023-09012-y},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {385-397},
  shortjournal = {Neural Comput. Appl.},
  title        = {An approach for classifying ceramic tile defects based on a two-dimensional genetic CNN algorithm},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of daily average seawater temperature using
data-driven and deep learning algorithms. <em>NCA</em>, <em>36</em>(1),
365–383. (<a href="https://doi.org/10.1007/s00521-023-09010-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large amounts of cooling water are required for the cooling process in coal-fired or nuclear power plants. Because the primary use of water in a power plant is to condense steam and remove waste heat as part of a Rankine cycle, seawater temperature (SWT) is of critical importance for electrical output in power plant applications installed at the seaside. Moreover, the analysis of SWT is an important criterion for researching sea life and global climate, and it also serves as an important indicator of climate change. In this paper, multilayer perceptron, which is in the class of a feed-forward artificial neural network, deep learning approach based on long short-term memory and bidirectional long short-term memory neural networks and data-driven methods, such as adaptive neuro-fuzzy inference system (ANFIS) accompanied by fuzzy c-means, ANFIS with grid partition and ANFIS with subtractive clustering methods were applied to make 1-day ahead SWT predictions. Analyses were conducted using 5-year daily mean SWTs measured by the Turkish State Meteorological Service for Antalya province between 2014 and 2018. The models were evaluated using mean absolute error (MAE), root-mean-square error (RMSE), and correlation coefficient (R). According to the daily SWT prediction, the best MAE, RMSE, and R values were obtained with the ANFIS-SC model, which were 0.1877 °C, 0.2683 °C, and 0.99814, respectively.},
  archive      = {J_NCA},
  author       = {Ozbek, Arif},
  doi          = {10.1007/s00521-023-09010-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {365-383},
  shortjournal = {Neural Comput. Appl.},
  title        = {Prediction of daily average seawater temperature using data-driven and deep learning algorithms},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive recurrent neural network intelligent sliding mode
control of permanent magnet linear synchronous motor. <em>NCA</em>,
<em>36</em>(1), 349–363. (<a
href="https://doi.org/10.1007/s00521-023-09009-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In permanent magnet linear synchronous motor systems, the nonlinear system functions in the dynamic model are difficult to obtain accurately, which leads to the reduction of system control performance. In this paper, an adaptive recurrent neural network intelligent sliding mode control (ARNISMC) strategy is proposed. The sliding mode controller is designed to improve the robustness of the system. Secondly, considering the nonlinear system function in the dynamic model of linear motor, it is approximated by recursive radial basis function neural network (RRBFNN). Then, the weight of RRBFNN is learned online by the adaptive algorithm and the approximation error of the nonlinear function is robustly compensated. The stability and convergence of the closed-loop system are proved based on the Lyapunov theory. Finally, the experimental results verify that the proposed ARNISMC not only achieves strong robustness, but also has better control accuracy than the original sliding mode control and radial basis function neural network sliding mode control method. In addition, it also shows the advantages of intelligent control.},
  archive      = {J_NCA},
  author       = {Fang, Xin and Wang, Limei and Zhang, Kang},
  doi          = {10.1007/s00521-023-09009-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {349-363},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive recurrent neural network intelligent sliding mode control of permanent magnet linear synchronous motor},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Handwritten bangla character recognition using convolutional
neural networks: A comparative study and new lightweight model.
<em>NCA</em>, <em>36</em>(1), 337–348. (<a
href="https://doi.org/10.1007/s00521-023-09008-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwriting is a crucial way to enhance character recognition and learn new words. However, the Bangla characters consist of very complex shapes and similar patterns. Deep learning (DL) techniques have become a prominent solution for handwritten Bangla character recognition (HBCR) due to their ability to extract high-level features from complex data. Several DL techniques have been proposed for HBCR, but they are computationally expensive and large in model size and thus not suitable for use in resource-constrained devices such as smartphones. In this study, we have evaluated the state-of-the-art DL models for HBCR. For this, we have used four existing datasets and created a merged dataset (by combining the four) for cross-dataset evaluation. We have provided a comparative performance analysis of the state-of-the-art DL models for HBCR. Additionally, we have proposed a new lightweight DL model for HBCR and evaluated its performance. The proposed DL model consists of 74 layers, including sub-layers, and its architecture is divided into five similar blocks. It includes the convolutional layers of (3, 3) and (5, 5) kernels, (1,1) stride, and the maximum pool layer of the (2, 2) pool size. The proposed model achieved accuracy, model size, loading and testing times of 96.87%, 13 MB, 9.11 s, and 7.95 s, respectively. The experimental results show that our model outperformed state-of-the-art models in terms of efficiency (loading and testing time) and model size with competitive accuracy.},
  archive      = {J_NCA},
  author       = {Opu, Md. Nahidul Islam and Hossain, Md. Ekramul and Kabir, Muhammad Ashad},
  doi          = {10.1007/s00521-023-09008-8},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {337-348},
  shortjournal = {Neural Comput. Appl.},
  title        = {Handwritten bangla character recognition using convolutional neural networks: A comparative study and new lightweight model},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Hierarchical reinforcement learning for kinematic control
tasks with parameterized action spaces. <em>NCA</em>, <em>36</em>(1),
323–336. (<a href="https://doi.org/10.1007/s00521-023-08991-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing reinforcement learning (RL) algorithms are solely applied to scenarios with pure discrete action space or pure continuous action space. However, in certain real-world kinematic control tasks that involve robot control based on kinematic properties, the action space is parameterized, wherein actions are represented by a fusion of discrete actions and continuous parameters. In this paper, we propose a hierarchical RL architecture designed specifically for handling parameterized action spaces. Our architecture consists of two levels, the higher level (discrete actor network) selects the discrete action and the lower level (continuous actor networks) determines the corresponding continuous parameters. These components work in tandem to generate an action-parameters vector to interact with the environment. Both the higher and lower levels share the rewards of environmental feedback and the critic networks to update the network weights. The soft actor critic and deep deterministic policy gradient algorithms are adopted to update higher-level and lower-level policies, respectively. Through simulation experiments conducted on different kinematic control tasks with parameterized action spaces, we demonstrate the effectiveness of our proposed algorithm.},
  archive      = {J_NCA},
  author       = {Cao, Jingyu and Dong, Lu and Sun, Changyin},
  doi          = {10.1007/s00521-023-08991-2},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {323-336},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical reinforcement learning for kinematic control tasks with parameterized action spaces},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Document-level multi-task learning approach based on
coreference-aware dynamic heterogeneous graph network for event
extraction. <em>NCA</em>, <em>36</em>(1), 303–321. (<a
href="https://doi.org/10.1007/s00521-023-08977-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level event extraction aims to extract event-related information from an unstructured document composed of multiple sentences. Existing approaches are not effective due to the challenge of event arguments that are scattered across multi-sentences and they pay more attention to the coreference relationship between entity mentions. However, it is an extremely common phenomenon that there are a large number of crossing sentences pronouns that referring to entity mentions. These pronouns also contain rich semantic information related to events in the document. Therefore, there is still a challenge that how to effectively construct the mention–pronoun coreference relationship and better learn the rich semantic entities representations for DEE. Aiming at the above problems, we propose a novel document-level multi-task learning approach based on coreference-aware dynamic heterogeneous graph network for event extraction, named DMCGEE. Specifically, first, an information enhancement extractor module is constructed to effectively capture multi-types of semantic association information for mentions representations. Second, a mention–pronoun coreference resolution method is proposed to capture mention–pronoun coreference resolution pairs, and a coreference-aware dynamic heterogeneous graph network is constructed to help sentences and mentions representations to focus on the effective global related information, thereby improving the performance of DMCGEE. Experiments show that DMCGEE outperforms the state-of-the-art.},
  archive      = {J_NCA},
  author       = {Chen, Ze and Ji, Wanting and Ding, Linlin and Song, Baoyan},
  doi          = {10.1007/s00521-023-08977-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {303-321},
  shortjournal = {Neural Comput. Appl.},
  title        = {Document-level multi-task learning approach based on coreference-aware dynamic heterogeneous graph network for event extraction},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Defense against adversarial attacks via textual embeddings
based on semantic associative field. <em>NCA</em>, <em>36</em>(1),
289–301. (<a href="https://doi.org/10.1007/s00521-023-08946-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are known to be vulnerable to various types of adversarial attacks, especially word-level attacks, in the field of natural language processing. In recent years, various defense methods are proposed against word-level attacks; however, most of those defense methods only focus on synonyms substitution-based attacks, while word-level attacks are not based on synonym substitution. In this paper, we propose a textual adversarial defense method against word-level adversarial attacks via textual embedding based on the semantic associative field. More specifically, we analyze the reasons why humans can read and understand textual adversarial examples and observe two crucial points: (1) There must be a relation between the original word and the perturbed word or token. (2) Such a kind of relation enables humans to infer original words, while humans have the ability to associations. Motivated by this, we introduce the concept of semantic associative field and propose a new defense method by building a robust word embedding, that is, we calculate the word vector by exerting the related word vector to it with potential function and weighted embedding sampling for simulating the semantic influence between words in same semantic field. We conduct comprehensive experiments and demonstrate that the models using the proposed method can achieve higher accuracy than the baseline defense methods under various adversarial attacks or original testing sets. Moreover, the proposed method is more universal, while it is irrelevant to model structure and will not affect the efficiency of training.},
  archive      = {J_NCA},
  author       = {Huang, Jiacheng and Chen, Long},
  doi          = {10.1007/s00521-023-08946-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {289-301},
  shortjournal = {Neural Comput. Appl.},
  title        = {Defense against adversarial attacks via textual embeddings based on semantic associative field},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical multi-agent reinforcement learning for
cooperative tasks with sparse rewards in continuous domain.
<em>NCA</em>, <em>36</em>(1), 273–287. (<a
href="https://doi.org/10.1007/s00521-023-08882-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sparse reward problem has long been one of the most challenging topics in the application of reinforcement learning (RL), especially in complex multi-agent systems. In this paper, a hierarchical multi-agent RL architecture is developed to address the sparse reward problem of cooperative tasks in continuous domain. The proposed architecture is divided into two levels: the higher-level meta-agent implements state transitions on a larger time scale to alleviate the sparse reward problem, which receives global observation as spatial information and formulates sub-goals for the lower-level agents; the lower-level agent receives local observation and sub-goal and completes the cooperative tasks. In addition, to improve the stability of the higher-level policy, a channel is built to transmit the lower-level policy to the meta-agent as temporal information, and then a two-stream structure is adopted in the actor-critic networks of the meta-agent to process spatial and temporal information. Simulation experiments on different tasks demonstrate that the proposed algorithm effectively alleviates the sparse reward problem, so as to learn desired cooperative policies.},
  archive      = {J_NCA},
  author       = {Cao, Jingyu and Dong, Lu and Yuan, Xin and Wang, Yuanda and Sun, Changyin},
  doi          = {10.1007/s00521-023-08882-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {273-287},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hierarchical multi-agent reinforcement learning for cooperative tasks with sparse rewards in continuous domain},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient confusing choices decoupling framework for
multi-choice tasks over texts. <em>NCA</em>, <em>36</em>(1), 259–271.
(<a href="https://doi.org/10.1007/s00521-023-08795-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the multi-choice tasks, which aim to select the correct choice for a given query by reasoning over texts, such as sentences and passages. Benefiting from the provided knowledge in these tasks, the reasoning of multi-choice models becomes well-founded. However, besides the evidence of the correct choice, the text usually contains some content related to other choices as well, which causes multi-choice models vulnerable to being confused by candidate choices, and we denote it as choice confusion problem. To alleviate this challenge, we propose two auxiliary mechanisms to distinguish the confusing choices. Specifically, a query-guided attention (QGA) mechanism is designed to automatically filter the text contents causing confusion by measuring the syntactic relevance between different contents and the query. Meanwhile, a confusion-aware training (CAT) mechanism is designed to learn the correct and easily confused choices asynchronously and perform a pushing-away operation between their selection processes. We conduct experiments on multi-choice tasks based on sentences and passages. The results show that our framework improves the choice selection accuracy compared to strong baselines. Furthermore, the ablation test and case study verify the effectiveness of our proposed QGA and CAT, especially in addressing the choice confusion problem.},
  archive      = {J_NCA},
  author       = {Wang, Yingyao and Bao, Junwei and Duan, Chaoqun and Wu, Youzheng and He, Xiaodong and Zhu, Conghui and Zhao, Tiejun},
  doi          = {10.1007/s00521-023-08795-4},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {259-271},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient confusing choices decoupling framework for multi-choice tasks over texts},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FC-SEEDA: Fog computing-based secure and energy efficient
data aggregation scheme for internet of healthcare things. <em>NCA</em>,
<em>36</em>(1), 241–257. (<a
href="https://doi.org/10.1007/s00521-023-08270-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT is used in healthcare to monitor patients via wearable sensors to measure different physiological information. This collected information can be stored, processed, and made available to doctors to give a consultation at any time, which improves the efficiency of the traditional medical systems. Secure data collection and transfer to centralized servers in healthcare applications employing IoT is quite challenging to protect against several attacks for illegal data access. Furthermore, the bulk of IoT devices have physical limitations in processing and storage. Securing and effectively aggregating sensitive patient information on the Internet of Healthcare Things remains difficult. This research article proposes FC-SEEDA: Fog Computing-based Secure and Energy-Efficient Data Aggregation scheme for Internet of healthcare Things. By leveraging the distributed nature and other extended capabilities of Fog Computing, the main objective of this proposed scheme is to decrease the communication overhead and energy consumption while maintaining safe and secure aggregation of the healthcare data between medical sensors and cloud servers. The proposed system is experimentally developed using the E-health sensor shield V2.0 platform. Security analysis demonstrates that the proposed aggregation protocol achieves desirable security properties. Performance comparisons show that our newly proposed protocol significantly reduces computing overhead compared to the latest protocols in the field.},
  archive      = {J_NCA},
  author       = {Chakraborty, Chinmay and Othman, Soufiene Ben and Almalki, Faris A. and Sakli, Hedi},
  doi          = {10.1007/s00521-023-08270-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {241-257},
  shortjournal = {Neural Comput. Appl.},
  title        = {FC-SEEDA: Fog computing-based secure and energy efficient data aggregation scheme for internet of healthcare things},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Utilization of big data classification models in digitally
enhanced optical coherence tomography for medical diagnostics.
<em>NCA</em>, <em>36</em>(1), 225–239. (<a
href="https://doi.org/10.1007/s00521-022-07973-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement in modern imaging techniques like CT scan, MRI, PET scan etc., a vast amount of data is generated every day in the field of healthcare. Big data contains hidden information, which necessitates the development of intelligent systems to analyze it and extract relevant information, allowing for accurate and cost-effective decisions in the medical field. By utilizing the untapped potential of the big data available in the medical field, very precise models can be developed for the medical diagnosis of retinal diseases. Optical coherence tomography (OCT) is a non-invasive imaging test that captures different, distinctive layers of the retina and optic nerve in a living eye to map and measure their thickness, that helps diagnose various retinal disorders. With the advancement of the application of deep learning-based techniques in the field of medical sciences, the use of convolutional neural network (CNN) based approaches for disease detection is gaining popularity. While the manual examination of 3D OCT images for the diagnosis of retinal disorders requires extensive time and expert intervention, the use of CNNs provides an effective automated option that provides results with higher accuracy while also reducing the time involved in the overall process. In this paper, we have implemented the aforementioned idea by proposing OCT-CNN, a CNN architecture, that automatically classifies retinal OCT images and identifies potential disorders in a living eye. Several techniques have been employed to enhance the performance of the proposed approach, including digital enhancement of the images, dropout regularization, adaptive learning rates, and early stopping of training to attain optimal performance. The performance of the proposed OCT-CNN is evaluated on the UCSD dataset against several popular deep CNN architectures and existing state-of-the-art approaches to automatic retinal OCT classification. The proposed OCT-CNN attains the best performance on all evaluated metrics, pushing the classification accuracies to 99.28% on CNV, 99.9% on DME, 99.38% on DRUSEN, and 100% on NORMAL images, indicating its superiority over existing state-of-the-art techniques.},
  archive      = {J_NCA},
  author       = {Bansal, Priti and Harjai, Nipun and Saif, Mohammad and Mugloo, Saahil Hussain and Kaur, Preeti},
  doi          = {10.1007/s00521-022-07973-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {225-239},
  shortjournal = {Neural Comput. Appl.},
  title        = {Utilization of big data classification models in digitally enhanced optical coherence tomography for medical diagnostics},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motor imagery classification using sparse nonnegative matrix
factorization and convolutional neural networks. <em>NCA</em>,
<em>36</em>(1), 213–223. (<a
href="https://doi.org/10.1007/s00521-022-07861-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motor movement performed by different body parts affects the synaptic potential at different brain cortices, which can be observed by the electroencephalogram (EEG) signal. The recorded EEG signals can be used to decode the imagined motor task. The EEG signals are non-stationary and transient and contain time, frequency, and space information. Extracting this information and processing them with the latest machine learning and deep learning algorithms can be useful for brain–computer interfacing and other human–machine interaction techniques. EEG signal contains negative values. Hence, nonnegative matrix factorization can be used to provide a meaningful explanation of information within EEG signals. Sparseness in feature vectors is another essential factor to consider while identifying the structures in an input signal. In this work, we propose a novel motor imagery classification model that extracts the weights for predefined motor imagery features from EEG signals and classifies them using a convolution neural network (CNN). Sparse nonnegative matrix factorization is used to extract the fundamental feature vectors for different motor imagery events, which are further used to extract the combined weight matrix of unknown motor imagery events. The designed CNN classifies the extracted weight matrix in the corresponding classes. The acquired EEG signals from all the channels are processed simultaneously using the CNN, which helps extract spatial information from the signals. BCI Competition IV dataset IIa and BCI Competition III dataset IVa are used to validate the proposed method. The proposed method has been compared with existing methods and validates their superiority in terms of average accuracy. The classification accuracy for two types and four types of motor imagery signals is 99.53% and 94.58%, respectively. Empirical results show that EEG signals’ sparseness characteristics can be considered an effective feature for motor imagery classification.},
  archive      = {J_NCA},
  author       = {Chaudhary, Poonam and Varshney, Yash Vardhan and Srivastava, Gautam and Bhatia, Surbhi},
  doi          = {10.1007/s00521-022-07861-7},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {213-223},
  shortjournal = {Neural Comput. Appl.},
  title        = {Motor imagery classification using sparse nonnegative matrix factorization and convolutional neural networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MethEvo: An accurate evolutionary information-based
methylation site predictor. <em>NCA</em>, <em>36</em>(1), 201–212. (<a
href="https://doi.org/10.1007/s00521-022-07738-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post Translational Modification (PTM) plays an essential role in the biological and molecular mechanisms. They are also considered as a vital element in cell signaling and networking pathways. Among different PTMs, Methylation is regarded as one of the most important types. Methylation plays a crucial role in maintaining the dynamic balance, stability, and remodeling of chromatins. Methylation also leads to different abnormalities in cells and is responsible for many serious diseases. Methylation can be detected by experimental approaches such as methylation-specific antibodies, mass spectrometry, or characterizing methylation sites using the radioactive labeling method. However, these approaches are time-consuming and costly. Therefore, there is a demand for fast and accurate computational techniques to solve these issues. This study proposes a novel machine learning approach called MethEvo to predict methylation sites in proteins. To build this model, we use an evolutionary-based bi-gram profile approach to extract features. We also use SVM as our classification technique to build MethEvo. Our results demonstrate that MethEvo achieves 98.7%, 98.8%, 98.4%, and 0.974 in terms of accuracy, specificity, sensitivity, and Matthews Correlation Coefficient (MCC). MethEvo and its source code are publicly available at: https://github.com/islamsadia88/MethEvo .},
  archive      = {J_NCA},
  author       = {Islam, Sadia and Mugdha, Shafayat Bin Shabbir and Dipta, Shubhashis Roy and Arafat, MD. Easin and Shatabda, Swakkhar and Alinejad-Rokny, Hamid and Dehzangi, Iman},
  doi          = {10.1007/s00521-022-07738-9},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {201-212},
  shortjournal = {Neural Comput. Appl.},
  title        = {MethEvo: An accurate evolutionary information-based methylation site predictor},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Machine learning techniques for CT imaging diagnosis of
novel coronavirus pneumonia: A review. <em>NCA</em>, <em>36</em>(1),
181–199. (<a href="https://doi.org/10.1007/s00521-022-07709-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 2020, novel coronavirus pneumonia has been spreading rapidly around the world, bringing tremendous pressure on medical diagnosis and treatment for hospitals. Medical imaging methods, such as computed tomography (CT), play a crucial role in diagnosing and treating COVID-19. A large number of CT images (with large volume) are produced during the CT-based medical diagnosis. In such a situation, the diagnostic judgement by human eyes on the thousands of CT images is inefficient and time-consuming. Recently, in order to improve diagnostic efficiency, the machine learning technology is being widely used in computer-aided diagnosis and treatment systems (i.e., CT Imaging) to help doctors perform accurate analysis and provide them with effective diagnostic decision support. In this paper, we comprehensively review these frequently used machine learning methods applied in the CT Imaging Diagnosis for the COVID-19, discuss the machine learning-based applications from the various kinds of aspects including the image acquisition and pre-processing, image segmentation, quantitative analysis and diagnosis, and disease follow-up and prognosis. Moreover, we also discuss the limitations of the up-to-date machine learning technology in the context of CT imaging computer-aided diagnosis.},
  archive      = {J_NCA},
  author       = {Chen, Jingjing and Li, Yixiao and Guo, Lingling and Zhou, Xiaokang and Zhu, Yihan and He, Qingfeng and Han, Haijun and Feng, Qilong},
  doi          = {10.1007/s00521-022-07709-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {181-199},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning techniques for CT imaging diagnosis of novel coronavirus pneumonia: A review},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG signal classification using improved intuitionistic
fuzzy twin support vector machines. <em>NCA</em>, <em>36</em>(1),
163–179. (<a href="https://doi.org/10.1007/s00521-022-07655-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support-vector machines (SVMs) have been successfully employed to diagnose neurological disorders like epilepsy and sleep disorders via electroencephalogram (EEG) signal classification. However, EEG signals are susceptible to noise and outliers while recording. Thus, classification of EEG signals require efficient methods that is robust to noise and outliers. SVMs suffer in the presence of noise and outliers as it treats each sample to be of equal importance. Fuzzy membership function has been successful in dealing with noise and outliers. Fuzzy support vector machine uses fuzzy membership to give the appropriate weight to each sample for reducing the effect of noise and outliers. To reduce the effect of noise and outliers, intuitionistic fuzzy twin support vector machines (IFTWSVM) uses both membership and non-membership weights to subsidise the effect of outliers. Moreover, IFTWSVM solves smaller size quadratic programming problems which makes it comparatively efficient than fuzzy support vector machines. However, IFTWSVM suffers as (i) it involves the computation of matrix inverses which makes it intractable as the size of the data increases. (ii) it solves different problems for linear and nonlinear cases, and nonlinear case with linear kernel does not reduce to the linear case. Thus, it can only solve the approximate formulation not the exact formulation. To overcome these issues, we propose improved intuitionistic fuzzy twin support vector machine (IIFTWSVM). The proposed IIFTWSVM introduces different Lagrangian functions to avoid the computation of matrix inverses. Also, in nonlinear case, kernel trick is applied directly and hence, the exact formulation is solved. We employed the proposed IIFTWSVM for the classification of EEG signals. The experimental results and statistical analysis show that the proposed IIFTWSVM model is better compared to the given baseline models. Also, we evaluate the performance of the models on KEEL datasets to check the robustness of the proposed IIFTWSVM model.},
  archive      = {J_NCA},
  author       = {Ganaie, M. A. and Kumari, Anuradha and Malik, A. K. and Tanveer, M.},
  doi          = {10.1007/s00521-022-07655-x},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {163-179},
  shortjournal = {Neural Comput. Appl.},
  title        = {EEG signal classification using improved intuitionistic fuzzy twin support vector machines},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tear film breakup time-based dry eye disease detection using
convolutional neural network. <em>NCA</em>, <em>36</em>(1), 143–161. (<a
href="https://doi.org/10.1007/s00521-022-07652-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dry eye disease (DED) is a chronic eye disease and a common complication among the world&#39;s population. Evaporation of moisture from tear film or a decrease in tear production leads to an unstable tear film which causes DED. The tear film breakup time (TBUT) test is a common clinical test used to diagnose DED. In this test, DED is diagnosed by measuring the time at which the first breakup pattern appears on the tear film. TBUT test is subjective, labour-intensive and time-consuming. These weaknesses make a computer-aided diagnosis of DED highly desirable. The existing computer-aided DED detection techniques use expensive instruments for image acquisition which may not be available in all eye clinics. Moreover, among these techniques, TBUT-based DED detection techniques are limited to finding only tear film breakup area/time and do not identify the severity of DED, which can essentially be helpful to ophthalmologists in prescribing the right treatment. Additionally, a few challenges in developing a DED detection approach are less illuminated video, constant blinking of eyes in the videos, blurred video, and lack of public datasets. This paper presents a novel TBUT-based DED detection approach that detects the presence/absence of DED from TBUT video. In addition, the proposed approach accurately identifies the severity level of DED and further categorizes it as normal, moderate or severe based on the TBUT. The proposed approach exhibits high performance in classifying TBUT frames, detecting DED, and severity grading of TBUT video with an accuracy of 83%. Also, the correlation computed between the proposed approach and the Ophthalmologist&#39;s opinion is 90%, which reflects the noteworthy contribution of our proposed approach.},
  archive      = {J_NCA},
  author       = {Vyas, Aditi Haresh and Mehta, Mayuri A. and Kotecha, Ketan and Pandya, Sharnil and Alazab, Mamoun and Gadekallu, Thippa Reddy},
  doi          = {10.1007/s00521-022-07652-0},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {143-161},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tear film breakup time-based dry eye disease detection using convolutional neural network},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An algorithm for overlapping chromosome segmentation based
on region selection. <em>NCA</em>, <em>36</em>(1), 133–142. (<a
href="https://doi.org/10.1007/s00521-022-07317-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chromosome images are commonly used in karyotype analysis to diagnose chromosomal diseases. However, there are often chromosome adhesion and overlaps in chromosome images, so effective chromosome segmentation is conducive to smooth karyotype analysis. To date, some progress has been made in automatic chromosome segmentation, and existing methods can be used to segment overlapping chromosomes in most cases. However, when two or more overlapping regions are too close to each other in the image of overlapping chromosomes, the existing segmentation methods adjust the non-overlapping regions that do not belong to the overlapping region, resulting in incomplete segmentation of chromatids. Therefore, we use a heuristic algorithm to solve this problem from the point of view of mathematics and geometry to improve the segmentation of overlapping chromosomes. Starting from chromosome images, the existing problems and solutions are explained and displayed in the way of visualized interpretable image features, which helps to better understand the algorithm. Our method achieves 92.86% splicing accuracy and 90.44% overall segmentation accuracy on open datasets. The experimental results show that our method can effectively improve the problem of incorrect chromosome segmentation when two or more overlapping parts of overlapping chromosomes are too close to each other. It can accelerate the development of artificial intelligence in computational pathology and provide patients with more accurate medical services.},
  archive      = {J_NCA},
  author       = {Liu, Xiangbin and Wang, Sisi and Lin, Jerry Chun-Wei and Liu, Shuai},
  doi          = {10.1007/s00521-022-07317-y},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {133-142},
  shortjournal = {Neural Comput. Appl.},
  title        = {An algorithm for overlapping chromosome segmentation based on region selection},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tuberculosis detection in chest radiograph using
convolutional neural network architecture and explainable artificial
intelligence. <em>NCA</em>, <em>36</em>(1), 111–131. (<a
href="https://doi.org/10.1007/s00521-022-07258-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most regions of the world, tuberculosis (TB) is classified as a malignant infectious disease that can be fatal. Using advanced tools and technology, automatic analysis and classification of chest X-rays (CXRs) into TB and non-TB can be a reliable alternative to the subjective assessment performed by healthcare professionals. Thus, in the study, we propose an automatic TB detection system using advanced deep learning (DL) models. A significant portion of a CXR image is dark, providing no information for diagnosis and potentially confusing DL models. Therefore, in the proposed system, we use sophisticated segmentation networks to extract the region of interest from multimedia CXRs. Then, segmented images are fed into the DL models. For the subjective assessment, we use explainable artificial intelligence to visualize TB-infected parts of the lung. We use different convolutional neural network (CNN) models in our experiments and compare their classification performance using three publicly available CXR datasets. EfficientNetB3, one of the CNN models, achieves the highest accuracy of 99.1%, with a receiver operating characteristic of 99.9%, and an average accuracy of 98.7%. Experiment results confirm that using segmented lung CXR images produces better performance than does using raw lung CXR images.},
  archive      = {J_NCA},
  author       = {Nafisah, Saad I. and Muhammad, Ghulam},
  doi          = {10.1007/s00521-022-07258-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {111-131},
  shortjournal = {Neural Comput. Appl.},
  title        = {Tuberculosis detection in chest radiograph using convolutional neural network architecture and explainable artificial intelligence},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). M3BTCNet: Multi model brain tumor classification using
metaheuristic deep neural network features optimization. <em>NCA</em>,
<em>36</em>(1), 95–110. (<a
href="https://doi.org/10.1007/s00521-022-07204-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor is an active research topic in the area of medical imaging due to only 36% survival rate. The malignant tumor is a more dangerous type of tumor. The recent facts and figures show that 700,000 American are living in brain tumor and from them, 30.25% tumors are malignant. The diagnosis at the initial stage can help to minimize the human mortality rate due to brain tumor. Several researchers of computer vision proposed computer-aided diagnosis systems for this purpose but they faced several issues such as low accuracy and higher computational time. In this work, an end-to-end optimized deep learning system for multimodal brain tumor classification is proposed. The BRATS datasets are utilized for evaluation. The contrast is enhanced at the very first step by using hybrid division histogram equalization along ant colony optimization approach and train a newly design nine-layered CNN model. The features are extracted from second fully connected layer and optimized through differential evolution and mouth flame optimization. The output of both methods is fused using matrix length approach and passed in multi-class support vector machine (MC-SVM). In the experimental process, suggested method achieved an accuracy of 99.06, 98.76, 98.18 and 94.6%, on BRATS 2013, BRATS 2015, BRATS 2017 and BRATS 2018, respectively. Comparing results with existing techniques shows the superiority of proposed technique.},
  archive      = {J_NCA},
  author       = {Sharif, Muhammad Irfan and Li, Jian Ping and Khan, Muhammad Attique and Kadry, Seifedine and Tariq, Usman},
  doi          = {10.1007/s00521-022-07204-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {95-110},
  shortjournal = {Neural Comput. Appl.},
  title        = {M3BTCNet: Multi model brain tumor classification using metaheuristic deep neural network features optimization},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An FCN-LSTM model for neurological status detection from
non-invasive multivariate sensor data. <em>NCA</em>, <em>36</em>(1),
77–93. (<a href="https://doi.org/10.1007/s00521-022-07117-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A continuous monitoring of neurological status can help in reporting the physical and mental health of a person. This can be capitalized for building a healthcare tracking system using a wearable device and a handheld mobile device. In this paper, we have used the non-EEG physiological biosignals dataset which gives practicability among subjects for acquiring data easily from wearable device sensors linearly and comfortably rather than the way of putting the subjects in a cumbersome setup laboratory. This paper proposes a custom fully convolutional-LSTM (FCN-LSTM) network to identify the neurological status of a subject using multivariate time series physiological sensor data. The proposed architecture uses parallel stacks of the convolutional layers and LSTM cells. This combination of different network types is significant for the selected problem as the fully convolutional section of the model extracts the local spatial features in the data, while the LSTM network handles the high-level features and temporal dependencies. The proposed FCN-LSTM model yielded a high accuracy of 98.6% and a precision of 98% on the non-EEG dataset from UT-Dallas. The average accuracy of single-subject results of the dataset using the proposed model was observed to be 99.26%. The results from the proposed model are significantly improved when compared with various state-of-the-art works on this problem. These results strongly suggest that this model, when put on a wearable device, can be effectively used to detect the neurological status or stress that the subject may be going through in real time.},
  archive      = {J_NCA},
  author       = {Masood, Sarfaraz and Khan, Rafiuddin and Abd El-Latif, Ahmed A. and Ahmad, Musheer},
  doi          = {10.1007/s00521-022-07117-4},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {77-93},
  shortjournal = {Neural Comput. Appl.},
  title        = {An FCN-LSTM model for neurological status detection from non-invasive multivariate sensor data},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective machine learning-based model for the prediction
of protein–protein interaction sites in health systems. <em>NCA</em>,
<em>36</em>(1), 65–75. (<a
href="https://doi.org/10.1007/s00521-022-07024-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein is a vital biomolecule that accomplishes distinct biological activities by interacting with other proteins in complex biological systems. The protein–protein interaction (PPI) sites hot spot characterization holds preliminary importance in drug discovery as well as in the comprehension of the cellular signaling phenomenon. Looking at the significance of PPIs, an intelligent prediction system based on the notion of fuzzy logic “PPIs-FuzzyKNN” is developed for PPI sites identification. Here, protein sequences are transformed into an equal length of numerical descriptors by using physicochemical properties of amino acids and a position-specific scoring matrix. Here, we have utilized conventional machine learning algorithms as well as fuzzy k-nearest neighbors. The results of the model are assessed via a tenfold cross-validation test. The proposed model PPIs-FuzzyKNN obtained 91.20, 92.65, and 93.50% of accuracy on the three different datasets, namely Dtestset72, PDBtestset164, and Dset186, respectively. The results exhibited that the outcomes of the proposed model are outstanding and persistent in all datasets, so far, compared to the literature. Consequently, it will not only play a leading role in the accurate identification of PPI sites but also becomes a rudimentary tool for the research community.},
  archive      = {J_NCA},
  author       = {Tahir, Muhammad and Khan, Fazlullah and Hayat, Maqsood and Alshehri, Mohammad Dahman},
  doi          = {10.1007/s00521-022-07024-8},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {65-75},
  shortjournal = {Neural Comput. Appl.},
  title        = {An effective machine learning-based model for the prediction of protein–protein interaction sites in health systems},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brain age prediction using improved twin SVR. <em>NCA</em>,
<em>36</em>(1), 53–63. (<a
href="https://doi.org/10.1007/s00521-021-06518-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twin support vector regression (TSVR) has been widely applied in regression problems. TSVR seeks a pair of $$\varepsilon $$ -insensitive proximal planes by solving two support vector machine type problems. TSVR assumes that the matrices appearing in the dual formulation are positive definite. However, in real-world scenarios, such an assumption may not be fulfilled and, hence, leads to suboptimal performance. $$\varepsilon $$ -Twin support vector regression ( $$\varepsilon $$ -TSVR) improved the TSVR by introducing the regularisation term to avoid the singularity issues. Most of the twin support vector machine models involve the computation of matrix inverses. Also, TSVR implements the empirical risk minimization principle. In this paper, we propose an improved twin support vector regression (ITSVR) for brain age estimation by introducing different Lagrangian functions for the primal problems of the TSVR. The proposed ITSVR implements the structural risk minimization principle and avoids the computation of the matrix inverses. To solve the optimization problem more efficiently, we used successive overrelaxation (SOR) technique. We evaluated the proposed ITSVR on cognitively healthy subjects, mild cognitive impairment subjects and Alzheimer’s disease subjects. The experimental results demonstrate that the proposed ITSVR has superior performance compared to the baseline models for brain age estimation.},
  archive      = {J_NCA},
  author       = {Ganaie, M. A. and Tanveer, M. and Beheshti, Iman},
  doi          = {10.1007/s00521-021-06518-1},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {53-63},
  shortjournal = {Neural Comput. Appl.},
  title        = {Brain age prediction using improved twin SVR},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent fusion-assisted skin lesion localization and
classification for smart healthcare. <em>NCA</em>, <em>36</em>(1),
37–52. (<a href="https://doi.org/10.1007/s00521-021-06490-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology, the conception of smart healthcare has progressively come to the fore. Smart healthcare utilizes next-generation technologies, such as artificial intelligence, the Internet of Things (IoT), big data and cloud computing to transform intelligently the existing medical system-making it more efficient, more reliable, and personalized. In this work, skin data are collected using dedicated hardware from mobile health units-working as nodes. The collected samples are uploaded to the cloud for further processing using a novel multi-modal information fusion framework, which performs skin lesion segmentation, followed by classification. The proposed framework has two main functional blocks: Segmentation and classification. In each block, we have a performance booster, which works on the principle of information fusion. For lesion segmentation, a hybrid framework is proposed, which utilizes the complementary strengths of two convolutional neural network (CNN) architectures to generate the segmented images. The resultant binary images are later fused using joint probability distribution and marginal distribution function. For lesion classification, a 30-layered CNN architecture is designed, which is trained on the HAM10000 dataset. A novel summation discriminant correlation analysis technique is used to fuse the extracted features from two fully connected layers. To avoid feature redundancy, a feature selection method “Regular Falsi” is developed, which down samples the extracted features into the lower dimensions. The selected features are finally classified using an extreme learning machine classifier. Five skin benchmark datasets (ISBI2016, ISIC2017, ISBI2018, ISIC2019, and HAM10000) are used to evaluate both segmentation and classification frameworks using average accuracy, false-negative rate, sensitivity, and computational time, whose results are impressive compared to state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Khan, Muhammad Attique and Muhammad, Khan and Sharif, Muhammad and Akram, Tallha and Kadry, Seifedine},
  doi          = {10.1007/s00521-021-06490-w},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {37-52},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent fusion-assisted skin lesion localization and classification for smart healthcare},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A threat intelligence framework for protecting smart
satellite-based healthcare networks. <em>NCA</em>, <em>36</em>(1),
15–35. (<a href="https://doi.org/10.1007/s00521-021-06441-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-to-machine (H2M) communication is an important evolution in the industrial internet of health things (IIoHT), where many H2M interfaces are remotely interacting with industrial and medical assets. Lightweight protocols, such as constrained application protocol (CoAP), have been widely utilised in transferring sensing data of medical devices to end-users in smart satellite-based healthcare IIoT networks (SmartSat-IIoHT). However, such protocols are extensively deployed without appropriate security configurations, making attackers’ mission easier for abusing these protocols to launch advanced cyber threats. This paper, therefore, presents a new threat intelligence framework to examine and model CoAP protocol’s attacks in these systems. We present a ransom denial of service (RDoS) as a new threat that would exploit this protocol’s vulnerabilities. We propose many RDoS attack’s techniques to understand the attack indicators and analyse their behaviour on systems. Moreover, we present a real-time discovery of attacks’ network behaviours using deep learning. The experiment results demonstrate that this proposed discovery model obtains a better performance in revealing RDoS than other conventional machine learning algorithms and accomplishing high fidelity of protecting SmartSat-IIoHT networks.},
  archive      = {J_NCA},
  author       = {Al-Hawawreh, Muna and Moustafa, Nour and Slay, Jill},
  doi          = {10.1007/s00521-021-06441-5},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {15-35},
  shortjournal = {Neural Comput. Appl.},
  title        = {A threat intelligence framework for protecting smart satellite-based healthcare networks},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A statistical approach to secure health care services from
DDoS attacks during COVID-19 pandemic. <em>NCA</em>, <em>36</em>(1),
1–14. (<a href="https://doi.org/10.1007/s00521-021-06389-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the course of this year, more than a billion people have been afflicted by the COVID-19 outbreak. As long as individuals maintain their social distance, they should all be secure at this period. Because of this, there has been a rise in the usage of different online technologies, but at the same time, there has also been a rise in the likelihood of different cyber-attacks. A DDoS assault, the most prevalent and deadly of them all, impairs an online resource for its users. Thus, in this paper, we have proposed a filtering approach that can work efficiently in the COVID-19 scenario and detect the DDoS attack. We base our proposed approach on statistical methods like packet score and entropy variation for the identification of DDoS attack traffic. We have implemented our proposed approach on Omnet++ and for testing its efficiency we have checked it with different test cases. Our proposed approach detects the DDoS attack traffic with 96% accuracy and can also clearly have differentiated the DDoS attack traffic from the flash crowd.},
  archive      = {J_NCA},
  author       = {Zhou, Zhili and Gaurav, Akshat and Gupta, B. B. and Hamdi, Hedi and Nedjah, Nadia},
  doi          = {10.1007/s00521-021-06389-6},
  journal      = {Neural Computing and Applications},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Neural Comput. Appl.},
  title        = {A statistical approach to secure health care services from DDoS attacks during COVID-19 pandemic},
  volume       = {36},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
