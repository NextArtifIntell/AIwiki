<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mp---144">MP - 144</h2>
<ul>
<li><details>
<summary>
(2024). Deciding whether a lattice has an orthonormal basis is in
co-NP. <em>MP</em>, <em>208</em>(1), 763–775. (<a
href="https://doi.org/10.1007/s10107-023-02052-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the problem of deciding whether a given Euclidean lattice L has an orthonormal basis is in NP and co-NP. Since this is equivalent to saying that L is isomorphic to the standard integer lattice, this problem is a special form of the lattice isomorphism problem, which is known to be in the complexity class SZK. We achieve this by deploying a result on characteristic vectors by Elkies that gained attention in the context of 4-manifolds and Seiberg-Witten equations, but seems rather unnoticed in the algorithmic lattice community. On the way, we also show that for a given Gram matrix $$G \in \mathbb {Q}^{n \times n}$$ , we can efficiently find a rational lattice that is embedded in at most four times the initial dimension n, i.e. a rational matrix $$B \in \mathbb {Q}^{4n \times n}$$ such that $$B^\intercal B = G$$ .},
  archive      = {J_MP},
  author       = {Hunkenschröder, Christoph},
  doi          = {10.1007/s10107-023-02052-1},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {763-775},
  shortjournal = {Math. Program.},
  title        = {Deciding whether a lattice has an orthonormal basis is in co-NP},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Frank–wolfe-type methods for a class of nonconvex
inequality-constrained problems. <em>MP</em>, <em>208</em>(1), 717–761.
(<a href="https://doi.org/10.1007/s10107-023-02055-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Frank–Wolfe (FW) method, which implements efficient linear oracles that minimize linear approximations of the objective function over a fixed compact convex set, has recently received much attention in the optimization and machine learning literature. In this paper, we propose a new FW-type method for minimizing a smooth function over a compact set defined as the level set of a single difference-of-convex function, based on new generalized linear-optimization oracles (LO). We show that these LOs can be computed efficiently with closed-form solutions in some important optimization models that arise in compressed sensing and machine learning. In addition, under a mild strict feasibility condition, we establish the subsequential convergence of our nonconvex FW-type method. Since the feasible region of our generalized LO typically changes from iteration to iteration, our convergence analysis is completely different from those existing works in the literature on FW-type methods that deal with fixed feasible regions among subproblems. Finally, motivated by the away steps for accelerating FW-type methods for convex problems, we further design an away-step oracle to supplement our nonconvex FW-type method, and establish subsequential convergence of this variant. Numerical results on the matrix completion problem with standard datasets are presented to demonstrate the efficiency of the proposed FW-type method and its away-step variant.},
  archive      = {J_MP},
  author       = {Zeng, Liaoyuan and Zhang, Yongle and Li, Guoyin and Pong, Ting Kei and Wang, Xiaozhou},
  doi          = {10.1007/s10107-023-02055-y},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {717-761},
  shortjournal = {Math. Program.},
  title        = {Frank–Wolfe-type methods for a class of nonconvex inequality-constrained problems},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Designing tractable piecewise affine policies for
multi-stage adjustable robust optimization. <em>MP</em>,
<em>208</em>(1), 661–716. (<a
href="https://doi.org/10.1007/s10107-023-02053-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study piecewise affine policies for multi-stage adjustable robust optimization (ARO) problems with non-negative right-hand side uncertainty. First, we construct new dominating uncertainty sets and show how a multi-stage ARO problem can be solved efficiently with a linear program when uncertainty is replaced by these new sets. We then demonstrate how solutions for this alternative problem can be transformed into solutions for the original problem. By carefully choosing the dominating sets, we prove strong approximation bounds for our policies and extend many previously best-known bounds for the two-staged problem variant to its multi-stage counterpart. Moreover, the new bounds are—to the best of our knowledge—the first bounds shown for the general multi-stage ARO problem considered. We extensively compare our policies to other policies from the literature and prove relative performance guarantees. In two numerical experiments, we identify beneficial and disadvantageous properties for different policies and present effective adjustments to tackle the most critical disadvantages of our policies. Overall, the experiments show that our piecewise affine policies can be computed by orders of magnitude faster than affine policies, while often yielding comparable or even better results.},
  archive      = {J_MP},
  author       = {Thomä, Simon and Walther, Grit and Schiffer, Maximilian},
  doi          = {10.1007/s10107-023-02053-0},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {661-716},
  shortjournal = {Math. Program.},
  title        = {Designing tractable piecewise affine policies for multi-stage adjustable robust optimization},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semiglobal exponential stability of the discrete-time
arrow-hurwicz-uzawa primal-dual algorithm for constrained optimization.
<em>MP</em>, <em>208</em>(1), 629–660. (<a
href="https://doi.org/10.1007/s10107-023-02051-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the discrete-time Arrow-Hurwicz-Uzawa primal-dual algorithm, also known as the first-order Lagrangian method, for constrained optimization problems involving a smooth strongly convex cost and smooth convex constraints. We prove that, for every given compact set of initial conditions, there always exists a sufficiently small stepsize guaranteeing exponential stability of the optimal primal-dual solution of the problem with a domain of attraction including the initialization set. Inspired by the analysis of nonlinear oscillators, the stability proof is based on a non-quadratic Lyapunov function including a nonlinear cross term.},
  archive      = {J_MP},
  author       = {Bin, Michelangelo and Notarnicola, Ivano and Parisini, Thomas},
  doi          = {10.1007/s10107-023-02051-2},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {629-660},
  shortjournal = {Math. Program.},
  title        = {Semiglobal exponential stability of the discrete-time arrow-hurwicz-uzawa primal-dual algorithm for constrained optimization},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adjustability in robust linear optimization. <em>MP</em>,
<em>208</em>(1), 581–628. (<a
href="https://doi.org/10.1007/s10107-023-02049-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the concept of adjustability—the difference in objective values between two types of dynamic robust optimization formulations: one where (static) decisions are made before uncertainty realization, and one where uncertainty is resolved before (adjustable) decisions. This difference reflects the value of information and decision timing in optimization under uncertainty, and is related to several other concepts such as the optimality of decision rules in robust optimization. We develop a theoretical framework to quantify adjustability based on the input data of a robust optimization problem with a linear objective, linear constraints, and fixed recourse. We make very few additional assumptions. In particular, we do not assume constraint-wise separability or parameter nonnegativity that are commonly imposed in the literature for the study of adjustability. This allows us to study important but previously under-investigated problems, such as formulations with equality constraints and problems with both upper and lower bound constraints. Based on the discovery of an interesting connection between the reformulations of the static and fully adjustable problems, our analysis gives a necessary and sufficient condition—in the form of a theorem-of-the-alternatives—for adjustability to be zero when the uncertainty set is polyhedral. Based on this sharp characterization, we provide two efficient mixed-integer optimization formulations to verify zero adjustability. Then, we develop a constructive approach to quantify adjustability when the uncertainty set is general, which results in an efficient and tight poly-time algorithm to bound adjustability. We demonstrate the efficiency and tightness via both theoretical and numerical analyses.},
  archive      = {J_MP},
  author       = {Wei, Ningji and Zhang, Peter},
  doi          = {10.1007/s10107-023-02049-w},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {581-628},
  shortjournal = {Math. Program.},
  title        = {Adjustability in robust linear optimization},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constrained optimization of rank-one functions with
indicator variables. <em>MP</em>, <em>208</em>(1), 533–579. (<a
href="https://doi.org/10.1007/s10107-023-02047-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization problems involving minimization of a rank-one convex function over constraints modeling restrictions on the support of the decision variables emerge in various machine learning applications. These problems are often modeled with indicator variables for identifying the support of the continuous variables. In this paper we investigate compact extended formulations for such problems through perspective reformulation techniques. In contrast to the majority of previous work that relies on support function arguments and disjunctive programming techniques to provide convex hull results, we propose a constructive approach that exploits a hidden conic structure induced by perspective functions. To this end, we first establish a convex hull result for a general conic mixed-binary set in which each conic constraint involves a linear function of independent continuous variables and a set of binary variables. We then demonstrate that extended representations of sets associated with epigraphs of rank-one convex functions over constraints modeling indicator relations naturally admit such a conic representation. This enables us to systematically give perspective formulations for the convex hull descriptions of these sets with nonlinear separable or non-separable objective functions, sign constraints on continuous variables, and combinatorial constraints on indicator variables. We illustrate the efficacy of our results on sparse nonnegative logistic regression problems.},
  archive      = {J_MP},
  author       = {Shafiee, Soroosh and Kılınç-Karzan, Fatma},
  doi          = {10.1007/s10107-023-02047-y},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {533-579},
  shortjournal = {Math. Program.},
  title        = {Constrained optimization of rank-one functions with indicator variables},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Characterization of matrices with bounded graver bases and
depth parameters and applications to integer programming. <em>MP</em>,
<em>208</em>(1), 497–531. (<a
href="https://doi.org/10.1007/s10107-023-02048-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intensive line of research on fixed parameter tractability of integer programming is focused on exploiting the relation between the sparsity of a constraint matrix A and the norm of the elements of its Graver basis. In particular, integer programming is fixed parameter tractable when parameterized by the primal tree-depth and the entry complexity of A, and when parameterized by the dual tree-depth and the entry complexity of A; both these parameterization imply that A is sparse, in particular, the number of its non-zero entries is linear in the number of columns or rows, respectively. We study preconditioners transforming a given matrix to a row-equivalent sparse matrix if it exists and provide structural results characterizing the existence of a sparse row-equivalent matrix in terms of the structural properties of the associated column matroid. In particular, our results imply that the $$\ell _1$$ -norm of the Graver basis is bounded by a function of the maximum $$\ell _1$$ -norm of a circuit of A. We use our results to design a parameterized algorithm that constructs a matrix row-equivalent to an input matrix A that has small primal/dual tree-depth and entry complexity if such a row-equivalent matrix exists. Our results yield parameterized algorithms for integer programming when parameterized by the $$\ell _1$$ -norm of the Graver basis of the constraint matrix, when parameterized by the $$\ell _1$$ -norm of the circuits of the constraint matrix, when parameterized by the smallest primal tree-depth and entry complexity of a matrix row-equivalent to the constraint matrix, and when parameterized by the smallest dual tree-depth and entry complexity of a matrix row-equivalent to the constraint matrix.},
  archive      = {J_MP},
  author       = {Briański, Marcin and Koutecký, Martin and Král’, Daniel and Pekárková, Kristýna and Schröder, Felix},
  doi          = {10.1007/s10107-023-02048-x},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {497-531},
  shortjournal = {Math. Program.},
  title        = {Characterization of matrices with bounded graver bases and depth parameters and applications to integer programming},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FPT algorithms for a special block-structured integer
program with applications in scheduling. <em>MP</em>, <em>208</em>(1),
463–496. (<a href="https://doi.org/10.1007/s10107-023-02046-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a special case of the generalized 4-block n-fold IPs is investigated, where $$B_i=B$$ and B has a rank at most 1. Such IPs, called almost combinatorial 4-block n-fold IPs, include the generalized n-fold IPs as a subcase. We are interested in fixed parameter tractable (FPT) algorithms by taking as parameters the dimensions of the blocks and the largest coefficient. For almost combinatorial 4-block n-fold IPs, we first show that there exists some $$\lambda \le g(\gamma )$$ such that for any nonzero kernel element $${\textbf{g}}$$ , $$\lambda {\textbf{g}}$$ can always be decomposed into kernel elements in the same orthant whose $$\ell _{\infty }$$ -norm is bounded by $$g(\gamma )$$ (while $${\textbf{g}}$$ itself might not admit such a decomposition), where g is a computable function and $$\gamma $$ is an upper bound on the dimensions of the blocks and the largest coefficient. Based on this, we are able to bound the $$\ell _{\infty }$$ -norm of Graver basis elements by $${\mathcal {O}}(g(\gamma )n)$$ and develop an $${\mathcal {O}}(g(\gamma )n^{3+o(1)}\hat{L}^2)$$ -time algorithm (here $$\hat{L}$$ denotes the logarithm of the largest absolute value occurring in the input). Additionally, we show that the $$\ell _{\infty }$$ -norm of Graver basis elements is $$\varOmega (n)$$ . As applications, almost combinatorial 4-block n-fold IPs can be used to model generalizations of classical problems, including scheduling with rejection, bi-criteria scheduling, and a generalized delivery problem. Therefore, our FPT algorithm establishes a general framework to settle these problems.},
  archive      = {J_MP},
  author       = {Chen, Hua and Chen, Lin and Zhang, Guochuan},
  doi          = {10.1007/s10107-023-02046-z},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {463-496},
  shortjournal = {Math. Program.},
  title        = {FPT algorithms for a special block-structured integer program with applications in scheduling},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymmetry in the complexity of the multi-commodity network
pricing problem. <em>MP</em>, <em>208</em>(1), 425–461. (<a
href="https://doi.org/10.1007/s10107-023-02043-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network pricing problem (NPP) is a bilevel problem, where the leader optimizes its revenue by deciding on the prices of certain arcs in a graph, while expecting the followers (also known as the commodities) to choose a shortest path based on those prices. In this paper, we investigate the complexity of the NPP with respect to two parameters: the number of tolled arcs, and the number of commodities. We devise a simple algorithm showing that if the number of tolled arcs is fixed, then the problem can be solved in polynomial time with respect to the number of commodities. In contrast, even if there is only one commodity, once the number of tolled arcs is not fixed, the problem becomes NP-hard. We characterize this asymmetry in the complexity with a novel property named strong bilevel feasibility. Finally, we describe an algorithm to generate valid inequalities to the NPP based on this property, whose numerical results illustrate its potential for effectively solving the NPP with a high number of commodities.},
  archive      = {J_MP},
  author       = {Bui, Quang Minh and Carvalho, Margarida and Neto, José},
  doi          = {10.1007/s10107-023-02043-2},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {425-461},
  shortjournal = {Math. Program.},
  title        = {Asymmetry in the complexity of the multi-commodity network pricing problem},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterexample and an additional revealing poll step for a
result of “analysis of direct searches for discontinuous functions.”
<em>MP</em>, <em>208</em>(1), 411–424. (<a
href="https://doi.org/10.1007/s10107-023-02042-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note provides a counterexample to a theorem announced in the last part of the paper (Vicente and Custódio Math Program 133:299–325, 2012). The counterexample involves an objective function $$f: \mathbb {R}\rightarrow \mathbb {R}$$ which satisfies all the assumptions required by the theorem but contradicts some of its conclusions. A corollary of this theorem is also affected by this counterexample. The main flaw revealed by the counterexample is the possibility that a directional direct search method (dDSM) generates a sequence of trial points $$(x_k)_{k \in \mathbb {N}}$$ converging to a point $$x_*$$ where f is discontinuous, lower semicontinuous and whose objective function value $$f(x_*)$$ is strictly less than $$\lim _{k\rightarrow \infty } f(x_k)$$ . Moreover the dDSM generates trial points in only one of the continuity sets of f near $$x_*$$ . This note also investigates the proof of the theorem to highlight the inexact statements in the original paper. Finally this work introduces a modification of the dDSM that allows, in usual cases, to recover the properties broken by the counterexample.},
  archive      = {J_MP},
  author       = {Audet, Charles and Bouchet, Pierre-Yves and Bourdin, Loïc},
  doi          = {10.1007/s10107-023-02042-3},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {411-424},
  shortjournal = {Math. Program.},
  title        = {Counterexample and an additional revealing poll step for a result of “analysis of direct searches for discontinuous functions”},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: High-order methods beyond the classical
complexity bounds: Inexact high-order proximal-point methods.
<em>MP</em>, <em>208</em>(1), 409–410. (<a
href="https://doi.org/10.1007/s10107-024-02067-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Ahookhosh, Masoud and Nesterov, Yurii},
  doi          = {10.1007/s10107-024-02067-2},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {409-410},
  shortjournal = {Math. Program.},
  title        = {Correction: high-order methods beyond the classical complexity bounds: inexact high-order proximal-point methods},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). High-order methods beyond the classical complexity bounds:
Inexact high-order proximal-point methods. <em>MP</em>, <em>208</em>(1),
365–407. (<a href="https://doi.org/10.1007/s10107-023-02041-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a Bi-level OPTimization (BiOPT) framework for minimizing the sum of two convex functions, where one of them is smooth enough. The BiOPT framework offers three levels of freedom: (i) choosing the order p of the proximal term; (ii) designing an inexact pth-order proximal-point method in the upper level; (iii) solving the auxiliary problem with a lower-level non-Euclidean method in the lower level. We here regularize the objective by a $$(p+1)$$ th-order proximal term (for arbitrary integer $$p\ge 1$$ ) and then develop the generic inexact high-order proximal-point scheme and its acceleration using the standard estimating sequence technique at the upper level. This follows at the lower level with solving the corresponding pth-order proximal auxiliary problem inexactly either by one iteration of the pth-order tensor method or by a lower-order non-Euclidean composite gradient scheme. Ultimately, it is shown that applying the accelerated inexact pth-order proximal-point method at the upper level and handling the auxiliary problem by the non-Euclidean composite gradient scheme lead to a 2q-order method with the convergence rate $${\mathcal {O}}(k^{-(p+1)})$$ (for $$q=\lfloor p/2\rfloor $$ and the iteration counter k), which can result to a superfast method for some specific class of problems.},
  archive      = {J_MP},
  author       = {Ahookhosh, Masoud and Nesterov, Yurii},
  doi          = {10.1007/s10107-023-02041-4},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {365-407},
  shortjournal = {Math. Program.},
  title        = {High-order methods beyond the classical complexity bounds: Inexact high-order proximal-point methods},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complementary composite minimization, small gradients in
general norms, and applications. <em>MP</em>, <em>208</em>(1), 319–363.
(<a href="https://doi.org/10.1007/s10107-023-02040-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composite minimization is a powerful framework in large-scale convex optimization, based on decoupling of the objective function into terms with structurally different properties and allowing for more flexible algorithmic design. We introduce a new algorithmic framework for complementary composite minimization, where the objective function decouples into a (weakly) smooth and a uniformly convex term. This particular form of decoupling is pervasive in statistics and machine learning, due to its link to regularization. The main contributions of our work are summarized as follows. First, we introduce the problem of complementary composite minimization in general normed spaces; second, we provide a unified accelerated algorithmic framework to address broad classes of complementary composite minimization problems; and third, we prove that the algorithms resulting from our framework are near-optimal in most of the standard optimization settings. Additionally, we show that our algorithmic framework can be used to address the problem of making the gradients small in general normed spaces. As a concrete example, we obtain a nearly-optimal method for the standard $$\ell _1$$ setup (small gradients in the $$\ell _\infty $$ norm), essentially matching the bound of Nesterov (Optima Math Optim Soc Newsl 88:10–11, 2012) that was previously known only for the Euclidean setup. Finally, we show that our composite methods are broadly applicable to a number of regression and other classes of optimization problems, where regularization plays a key role. Our methods lead to complexity bounds that are either new or match the best existing ones.},
  archive      = {J_MP},
  author       = {Diakonikolas, Jelena and Guzmán, Cristóbal},
  doi          = {10.1007/s10107-023-02040-5},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {319-363},
  shortjournal = {Math. Program.},
  title        = {Complementary composite minimization, small gradients in general norms, and applications},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hardness and approximation of submodular minimum linear
ordering problems. <em>MP</em>, <em>208</em>(1), 277–318. (<a
href="https://doi.org/10.1007/s10107-023-02038-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum linear ordering problem (MLOP) generalizes well-known combinatorial optimization problems such as minimum linear arrangement and minimum sum set cover. MLOP seeks to minimize an aggregated cost $$f(\cdot )$$ due to an ordering $$\sigma $$ of the items (say [n]), i.e., $$\min _{\sigma } \sum _{i\in [n]} f(E_{i,\sigma })$$ , where $$E_{i,\sigma }$$ is the set of items mapped by $$\sigma $$ to indices [i]. Despite an extensive literature on MLOP variants and approximations for these, it was unclear whether the graphic matroid MLOP was NP-hard. We settle this question through non-trivial reductions from mininimum latency vertex cover and minimum sum vertex cover problems. We further propose a new combinatorial algorithm for approximating monotone submodular MLOP, using the theory of principal partitions. This is in contrast to the rounding algorithm by Iwata et al. (in: APPROX, 2012), using Lovász extension of submodular functions. We show a $$(2-\frac{1+\ell _{f}}{1+|E|})$$ -approximation for monotone submodular MLOP where $$\ell _{f}=\frac{f(E)}{\max _{x\in E}f(\{x\})}$$ satisfies $$1 \le \ell _f \le |E|$$ . Our theory provides new approximation bounds for special cases of the problem, in particular a $$(2-\frac{1+r(E)}{1+|E|})$$ -approximation for the matroid MLOP, where $$f = r$$ is the rank function of a matroid. We further show that minimum latency vertex cover is $$\frac{4}{3}$$ -approximable, by which we also lower bound the integrality gap of its natural LP relaxation, which might be of independent interest.},
  archive      = {J_MP},
  author       = {Farhadi, Majid and Gupta, Swati and Sun, Shengding and Tetali, Prasad and Wigal, Michael C.},
  doi          = {10.1007/s10107-023-02038-z},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {277-318},
  shortjournal = {Math. Program.},
  title        = {Hardness and approximation of submodular minimum linear ordering problems},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The exact worst-case convergence rate of the alternating
direction method of multipliers. <em>MP</em>, <em>208</em>(1), 243–276.
(<a href="https://doi.org/10.1007/s10107-023-02037-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, semidefinite programming performance estimation has been employed as a strong tool for the worst-case performance analysis of first order methods. In this paper, we derive new non-ergodic convergence rates for the alternating direction method of multipliers (ADMM) by using performance estimation. We give some examples which show the exactness of the given bounds. We also study the linear and R-linear convergence of ADMM in terms of dual objective. We establish that ADMM enjoys a global linear convergence rate if and only if the dual objective satisfies the Polyak–Łojasiewicz (PŁ) inequality in the presence of strong convexity. In addition, we give an explicit formula for the linear convergence rate factor. Moreover, we study the R-linear convergence of ADMM under two scenarios.},
  archive      = {J_MP},
  author       = {Zamani, Moslem and Abbaszadehpeivasti, Hadi and de Klerk, Etienne},
  doi          = {10.1007/s10107-023-02037-0},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {243-276},
  shortjournal = {Math. Program.},
  title        = {The exact worst-case convergence rate of the alternating direction method of multipliers},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). First order asymptotics of the sample average approximation
method to solve risk averse stochastic programs. <em>MP</em>,
<em>208</em>(1), 209–242. (<a
href="https://doi.org/10.1007/s10107-023-02036-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate statistical properties of the optimal value of the Sample Average Approximation of stochastic programs, continuing the study (Krätschmer in Nonasymptotic upper estimates for errors of the sample average approximation method to solve risk averse stochastic programs, 2023. Forthcoming in SIAM J. Optim.). Central Limit Theorem type results are derived for the optimal value. As a crucial point the investigations are based on a new type of conditions from the theory of empirical processes which do not rely on pathwise analytical properties of the goal functions. In particular, continuity or convexity in the parameter is not imposed in advance as usual in the literature on the Sample Average Approximation method. It is also shown that the new condition is satisfied if the paths of the goal functions are Hölder continuous so that the main results carry over in this case. Moreover, the main results are applied to goal functions whose paths are piecewise Hölder continuous as e.g. in two stage mixed-integer programs. The main results are shown for classical risk neutral stochastic programs, but we also demonstrate how to apply them to the Sample Average Approximation of risk averse stochastic programs. In this respect we consider stochastic programs expressed in terms of absolute semideviations and divergence risk measures.},
  archive      = {J_MP},
  author       = {Krätschmer, Volker},
  doi          = {10.1007/s10107-023-02036-1},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {209-242},
  shortjournal = {Math. Program.},
  title        = {First order asymptotics of the sample average approximation method to solve risk averse stochastic programs},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A single cut proximal bundle method for stochastic convex
composite optimization. <em>MP</em>, <em>208</em>(1), 173–208. (<a
href="https://doi.org/10.1007/s10107-023-02035-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers optimization problems where the objective is the sum of a function given by an expectation and a closed convex function, and proposes stochastic composite proximal bundle (SCPB) methods for solving it. Complexity guarantees are established for them without requiring knowledge of parameters associated with the problem instance. Moreover, it is shown that they have optimal complexity when these problem parameters are known. To the best of our knowledge, this is the first proximal bundle method for stochastic programming able to deal with continuous distributions. Finally, we present computational results showing that SCPB substantially outperforms the robust stochastic approximation method in all instances considered.},
  archive      = {J_MP},
  author       = {Liang, Jiaming and Guigues, Vincent and Monteiro, Renato D. C.},
  doi          = {10.1007/s10107-023-02035-2},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {173-208},
  shortjournal = {Math. Program.},
  title        = {A single cut proximal bundle method for stochastic convex composite optimization},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quasi-polynomial time approximation schemes for assortment
optimization under mallows-based rankings. <em>MP</em>, <em>208</em>(1),
111–171. (<a href="https://doi.org/10.1007/s10107-023-02033-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spite of its widespread applicability in learning theory, probability, combinatorics, and in various other fields, the Mallows model has only recently been examined from revenue management perspectives. To our knowledge, the only provably-good approaches for assortment optimization under the Mallows model have recently been proposed by Désir et al. (Oper Res 69(4):1206–1227, 2021), who devised three approximation schemes that operate in very specific circumstances. Unfortunately, these algorithmic results suffer from two major limitations, either crucially relying on strong structural assumptions, or incurring running times that exponentially scale either with the ratio between the extremal prices or with the Mallows concentration parameter. The main contribution of this paper consists in devising a quasi-polynomial-time approximation scheme for the assortment optimization problem under the Mallows model in its utmost generality. In other words, for any accuracy level $$\epsilon &gt; 0$$ , our algorithm identifies an assortment whose expected revenue is within factor $$1 - \epsilon $$ of optimal, without resorting to any structural or parametric assumption whatsoever. Our work sheds light on newly-gained structural insights surrounding near-optimal Mallows-based assortments and fleshes out some of their unexpected algorithmic consequences.},
  archive      = {J_MP},
  author       = {Rieger, Alon and Segev, Danny},
  doi          = {10.1007/s10107-023-02033-4},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {111-171},
  shortjournal = {Math. Program.},
  title        = {Quasi-polynomial time approximation schemes for assortment optimization under mallows-based rankings},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general framework for multi-marginal optimal transport.
<em>MP</em>, <em>208</em>(1), 75–110. (<a
href="https://doi.org/10.1007/s10107-023-02032-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish a general condition on the cost function to obtain uniqueness and Monge solutions in the multi-marginal optimal transport problem, under the assumption that a given collection of the marginals are absolutely continuous with respect to local coordinates. When only the first marginal is assumed to be absolutely continuous, our condition is equivalent to the twist on splitting sets condition found in Kim and Pass (SIAM J Math Anal 46:1538–1550, 2014; SIAM J Math Anal 46:1538–1550, 2014). In addition, it is satisfied by the special cost functions in our earlier work (Pass and Vargas-Jiménez in SIAM J Math Anal 53:4386–4400, 2021; Monge solutions and uniqueness in multi-marginal optimal transport via graph theory. arXiv:2104.09488 , 2021), when absolute continuity is imposed on certain other collections of marginals. We also present several new examples of cost functions which violate the twist on splitting sets condition but satisfy the new condition introduced here, including a class of examples arising in robust risk management problems; we therefore obtain Monge solution and uniqueness results for these cost functions, under regularity conditions on an appropriate subset of the marginals.},
  archive      = {J_MP},
  author       = {Pass, Brendan and Vargas-Jiménez, Adolfo},
  doi          = {10.1007/s10107-023-02032-5},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {75-110},
  shortjournal = {Math. Program.},
  title        = {A general framework for multi-marginal optimal transport},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). No dimension-free deterministic algorithm computes
approximate stationarities of lipschitzians. <em>MP</em>,
<em>208</em>(1), 51–74. (<a
href="https://doi.org/10.1007/s10107-023-02031-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the oracle complexity of computing an approximate stationary point of a Lipschitz function. When the function is smooth, it is well known that the simple deterministic gradient method has finite dimension-free oracle complexity. However, when the function can be nonsmooth, it is only recently that a randomized algorithm with finite dimension-free oracle complexity has been developed. In this paper, we show that no deterministic algorithm can do the same. Moreover, even without the dimension-free requirement, we show that any finite-time deterministic method cannot be general zero-respecting. In particular, this implies that a natural derandomization of the aforementioned randomized algorithm cannot have finite-time complexity. Our results reveal a fundamental hurdle in modern large-scale nonconvex nonsmooth optimization.},
  archive      = {J_MP},
  author       = {Tian, Lai and So, Anthony Man-Cho},
  doi          = {10.1007/s10107-023-02031-6},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {51-74},
  shortjournal = {Math. Program.},
  title        = {No dimension-free deterministic algorithm computes approximate stationarities of lipschitzians},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond symmetry: Best submatrix selection for the sparse
truncated SVD. <em>MP</em>, <em>208</em>(1), 1–50. (<a
href="https://doi.org/10.1007/s10107-023-02030-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The truncated singular value decomposition (SVD), also known as the best low-rank matrix approximation with minimum error measured by a unitarily invariant norm, has been applied to many domains such as biology, healthcare, among others, where high-dimensional datasets are prevalent. To extract interpretable information from the high-dimensional data, sparse truncated SVD (SSVD) has been used to select a handful of rows and columns of the original matrix along with the best low-rank approximation. Different from the literature on SSVD focusing on the top singular value or compromising the sparsity for the seek of computational efficiency, this paper presents a novel SSVD formulation that can select the best submatrix precisely up to a given size to maximize its truncated Ky Fan norm. The fact that the proposed SSVD problem is NP-hard motivates us to study effective algorithms with provable performance guarantees. To do so, we first reformulate SSVD as a mixed-integer semidefinite program, which can be solved exactly for small- or medium-sized instances within a branch-and-cut algorithm framework with closed-form cuts and is extremely useful for evaluating the solution quality of approximation algorithms. We next develop three selection algorithms based on different selection criteria and two searching algorithms, greedy and local search. We prove the approximation ratios for all the approximation algorithms and show that all the ratios are tight when the number of rows or columns of the selected submatrix is no larger than half of the data matrix, i.e., our derived approximation ratios are unimprovable. Our numerical study demonstrates the high solution quality and computational efficiency of the proposed algorithms. Finally, all our analysis can be extended to row-sparse PCA.},
  archive      = {J_MP},
  author       = {Li, Yongchun and Xie, Weijun},
  doi          = {10.1007/s10107-023-02030-7},
  journal      = {Mathematical Programming},
  month        = {11},
  number       = {1},
  pages        = {1-50},
  shortjournal = {Math. Program.},
  title        = {Beyond symmetry: Best submatrix selection for the sparse truncated SVD},
  volume       = {208},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Short-step methods are not strongly polynomial-time.
<em>MP</em>, <em>207</em>(1), 733–746. (<a
href="https://doi.org/10.1007/s10107-023-02002-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-step methods are an important class of algorithms for solving convex constrained optimization problems. In this short paper, we show that under very mild assumptions on the self-concordant barrier and the width of the $$\ell _2$$ -neighbourhood, any short-step interior-point method is not strongly polynomial-time.},
  archive      = {J_MP},
  author       = {Zong, Manru and Lee, Yin Tat and Yue, Man-Chung},
  doi          = {10.1007/s10107-023-02002-x},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {733-746},
  shortjournal = {Math. Program.},
  title        = {Short-step methods are not strongly polynomial-time},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A polynomial time algorithm for finding a minimum
4-partition of a submodular function. <em>MP</em>, <em>207</em>(1),
717–732. (<a href="https://doi.org/10.1007/s10107-023-02029-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the minimum k-partition problem of submodular functions, i.e., given a finite set V and a submodular function $$f:2^V\rightarrow \mathbb {R}$$ , computing a k-partition $$ \{ V_1, \ldots , V_k \}$$ of V with minimum $$\sum _{i=1}^k f(V_i)$$ . The problem is a natural generalization of the minimum k-cut problem in graphs and hypergraphs. It is known that the problem is NP-hard for general k, and solvable in polynomial time for fixed $$k \le 3$$ . In this paper, we construct the first polynomial-time algorithm for the minimum 4-partition problem.},
  archive      = {J_MP},
  author       = {Hirayama, Tsuyoshi and Liu, Yuhao and Makino, Kazuhisa and Shi, Ke and Xu, Chao},
  doi          = {10.1007/s10107-023-02029-0},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {717-732},
  shortjournal = {Math. Program.},
  title        = {A polynomial time algorithm for finding a minimum 4-partition of a submodular function},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New lower bounds on crossing numbers of <span
class="math display"><em>K</em><sub><em>m</em>, <em>n</em></sub></span>
from semidefinite programming. <em>MP</em>, <em>207</em>(1), 693–715.
(<a href="https://doi.org/10.1007/s10107-023-02028-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we use semidefinite programming and representation theory to compute new lower bounds on the crossing number of the complete bipartite graph $$K_{m,n}$$ , extending a method from de Klerk et al. (SIAM J Discrete Math 20:189–202, 2006) and the subsequent reduction by De Klerk, Pasechnik and Schrijver (Math Prog Ser A and B 109:613–624, 2007). We exploit the full symmetry of the problem using a novel decomposition technique. This results in a full block-diagonalization of the underlying matrix algebra, which we use to improve bounds on several concrete instances. Our results imply that $$\mathop {\textrm{cr}}\limits (K_{10,n}) \ge 4.87057 n^2 - 10n$$ , $$\mathop {\textrm{cr}}\limits (K_{11,n}) \ge 5.99939 n^2-12.5n$$ , $$ \mathop {\textrm{cr}}\limits (K_{12,n}) \ge 7.25579 n^2 - 15n$$ , $$\mathop {\textrm{cr}}\limits (K_{13,n}) \ge 8.65675 n^2-18n$$ for all n. The latter three bounds are computed using a new and well-performing relaxation of the original semidefinite programming bound. This new relaxation is obtained by only requiring one small matrix block to be positive semidefinite.},
  archive      = {J_MP},
  author       = {Brosch, Daniel and C. Polak, Sven},
  doi          = {10.1007/s10107-023-02028-1},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {693-715},
  shortjournal = {Math. Program.},
  title        = {New lower bounds on crossing numbers of $$K_{m,n}$$ from semidefinite programming},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State polynomials: Positivity, optimization and nonlinear
bell inequalities. <em>MP</em>, <em>207</em>(1), 645–691. (<a
href="https://doi.org/10.1007/s10107-023-02024-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces state polynomials, i.e., polynomials in noncommuting variables and formal states of their products. A state analog of Artin’s solution to Hilbert’s 17th problem is proved showing that state polynomials, positive over all matrices and matricial states, are sums of squares with denominators. Somewhat surprisingly, it is also established that a Krivine–Stengle Positivstellensatz fails to hold in the state polynomial setting. Further, archimedean Positivstellensätze in the spirit of Putinar and Helton–McCullough are presented leading to a hierarchy of semidefinite relaxations converging monotonically to the optimum of a state polynomial subject to state constraints. This hierarchy can be seen as a state analog of the Lasserre hierarchy for optimization of polynomials, and the Navascués–Pironio–Acín scheme for optimization of noncommutative polynomials. The motivation behind this theory arises from the study of correlations in quantum networks. Determining the maximal quantum violation of a polynomial Bell inequality for an arbitrary network is reformulated as a state polynomial optimization problem. Several examples of quadratic Bell inequalities in the bipartite and the bilocal tripartite scenario are analyzed. To reduce the size of the constructed SDPs, sparsity, sign symmetry and conditional expectation of the observables’ group structure are exploited. To obtain the above-mentioned results, techniques from noncommutative algebra, real algebraic geometry, operator theory, and convex optimization are employed.},
  archive      = {J_MP},
  author       = {Klep, Igor and Magron, Victor and Volčič, Jurij and Wang, Jie},
  doi          = {10.1007/s10107-023-02024-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {645-691},
  shortjournal = {Math. Program.},
  title        = {State polynomials: Positivity, optimization and nonlinear bell inequalities},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Efficient kirszbraun extension with
applications to regression. <em>MP</em>, <em>207</em>(1), 643. (<a
href="https://doi.org/10.1007/s10107-024-02056-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Zaichyk, Hananel and Biess, Armin and Kontorovich, Aryeh and Makarychev, Yury},
  doi          = {10.1007/s10107-024-02056-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {643},
  shortjournal = {Math. Program.},
  title        = {Correction: Efficient kirszbraun extension with applications to regression},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Efficient kirszbraun extension with applications to
regression. <em>MP</em>, <em>207</em>(1), 617–642. (<a
href="https://doi.org/10.1007/s10107-023-02023-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a framework for performing vector-valued regression in finite-dimensional Hilbert spaces. Using Lipschitz smoothness as our regularizer, we leverage Kirszbraun’s extension theorem for off-data prediction. We analyze the statistical and computational aspects of this method—to our knowledge, its first application to supervised learning. We decompose this task into two stages: training (which corresponds operationally to smoothing/regularization) and prediction (which is achieved via Kirszbraun extension). Both are solved algorithmically via a novel multiplicative weight updates (MWU) scheme, which, for our problem formulation, achieves significant runtime speedups over generic interior point methods. Our empirical results indicate a dramatic advantage over standard off-the-shelf solvers in our regression setting.},
  archive      = {J_MP},
  author       = {Zaichyk, Hananel and Biess, Armin and Kontorovich, Aryeh and Makarychev, Yury},
  doi          = {10.1007/s10107-023-02023-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {617-642},
  shortjournal = {Math. Program.},
  title        = {Efficient kirszbraun extension with applications to regression},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relaxations and duality for multiobjective integer
programming. <em>MP</em>, <em>207</em>(1), 577–616. (<a
href="https://doi.org/10.1007/s10107-023-02022-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective integer programs (MOIPs) simultaneously optimize multiple objective functions over a set of linear constraints and integer variables. In this paper, we present continuous, convex hull and Lagrangian relaxations for MOIPs and examine the relationship among them. The convex hull relaxation is tight at supported solutions, i.e., those that can be derived via a weighted-sum scalarization of the MOIP. At unsupported solutions, the convex hull relaxation is not tight and a Lagrangian relaxation may provide a tighter bound. Using the Lagrangian relaxation, we define a Lagrangian dual of an MOIP that satisfies weak duality and is strong at supported solutions under certain conditions on the primal feasible region. We include a numerical experiment to illustrate that bound sets obtained via Lagrangian duality may yield tighter bounds than those from a convex hull relaxation. Subsequently, we generalize the integer programming value function to MOIPs and use its properties to motivate a set-valued superadditive dual that is strong at supported solutions. We also define a simpler vector-valued superadditive dual that exhibits weak duality but is strongly dual if and only if the primal has a unique nondominated point.},
  archive      = {J_MP},
  author       = {Dunbar, Alex and Sinha, Saumya and Schaefer, Andrew J.},
  doi          = {10.1007/s10107-023-02022-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {577-616},
  shortjournal = {Math. Program.},
  title        = {Relaxations and duality for multiobjective integer programming},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global stability of first-order methods for coercive tame
functions. <em>MP</em>, <em>207</em>(1), 551–576. (<a
href="https://doi.org/10.1007/s10107-023-02020-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider first-order methods with constant step size for minimizing locally Lipschitz coercive functions that are tame in an o-minimal structure on the real field. We prove that if the method is approximated by subgradient trajectories, then the iterates eventually remain in a neighborhood of a connected component of the set of critical points. Under suitable method-dependent regularity assumptions, this result applies to the subgradient method with momentum, the stochastic subgradient method with random reshuffling and momentum, and the random-permutations cyclic coordinate descent method.},
  archive      = {J_MP},
  author       = {Josz, Cédric and Lai, Lexiao},
  doi          = {10.1007/s10107-023-02020-9},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {551-576},
  shortjournal = {Math. Program.},
  title        = {Global stability of first-order methods for coercive tame functions},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Better-than- <span
class="math display">$$\frac{4}{3}$$</span> -approximations for
leaf-to-leaf tree and connectivity augmentation. <em>MP</em>,
<em>207</em>(1), 515–549. (<a
href="https://doi.org/10.1007/s10107-023-02018-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Connectivity Augmentation Problem (CAP) together with a well-known special case thereof known as the Tree Augmentation Problem (TAP) are among the most basic Network Design problems. There has been a surge of interest recently to find approximation algorithms with guarantees below 2 for both TAP and CAP, culminating in the currently best approximation factor for both problems of 1.393 through quite sophisticated techniques. We present a new and arguably simple matching-based method for the well-known special case of leaf-to-leaf instances. Combining our work with prior techniques, we readily obtain a $$(4/3+\varepsilon )$$ -approximation for Leaf-to-Leaf CAP by returning the better of our solution and one of an existing method. Prior to our work, a $$4/3$$ -guarantee was only known for Leaf-to-Leaf TAP instances on trees of height 2. Moreover, when combining our technique with a recently introduced stack analysis approach, which is part of the above-mentioned 1.393-approximation, we can further improve the approximation factor to 1.29, obtaining for the first time a factor below $$\frac{4}{3}$$ for a nontrivial class of TAP/CAP instances.},
  archive      = {J_MP},
  author       = {Cecchetto, Federica and Traub, Vera and Zenklusen, Rico},
  doi          = {10.1007/s10107-023-02018-3},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {515-549},
  shortjournal = {Math. Program.},
  title        = {Better-than- $$\frac{4}{3}$$ -approximations for leaf-to-leaf tree and connectivity augmentation},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Homotopic policy mirror descent: Policy convergence,
algorithmic regularization, and improved sample complexity. <em>MP</em>,
<em>207</em>(1), 457–513. (<a
href="https://doi.org/10.1007/s10107-023-02017-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a new variant of policy gradient method, named homotopic policy mirror descent (HPMD), for solving discounted, infinite horizon MDPs with finite state and action spaces. HPMD performs a mirror descent type policy update with an additional diminishing regularization term, and possesses several computational properties that seem to be new in the literature. When instantiated with Kullback–Leibler divergence, we establish the global linear convergence of HPMD applied to any MDP instance, for both the optimality gap, and a weighted distance to the set of optimal policies. We then unveil a phase transition, where both quantities exhibit local acceleration, and converge at a superlinear rate after the optimality gap falls below certain instance-dependent threshold. With local acceleration and diminishing regularization, we establish the first result among policy gradient methods on certifying and characterizing the limiting policy, by showing, with a non-asymptotic characterization, that the last-iterate policy converges to the unique optimal policy with the maximal entropy. We then extend all the aforementioned results to HPMD instantiated with a broad class of decomposable Bregman divergences, demonstrating the generality of the these computational properties. As a byproduct, we discover the finite-time exact convergence for some commonly used Bregman divergences, implying the continuing convergence of HPMD to the limiting policy even if the current policy is already optimal. Finally, we develop a stochastic version of HPMD and establish similar convergence properties. By exploiting the local acceleration, we show that when a generative model is available for policy evaluation, with a small enough $$\epsilon _0$$ , for any target precision $$\epsilon \le \epsilon _0$$ , an $$\epsilon $$ -optimal policy can be learned with $$\widetilde{\mathcal {O}}(|{\mathcal {S}} | |\mathcal {A} | / \epsilon _0^2)$$ samples with probability $$1 - \mathcal {O}(\epsilon _0^{\scriptscriptstyle 1/3})$$ .},
  archive      = {J_MP},
  author       = {Li, Yan and Lan, Guanghui and Zhao, Tuo},
  doi          = {10.1007/s10107-023-02017-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {457-513},
  shortjournal = {Math. Program.},
  title        = {Homotopic policy mirror descent: Policy convergence, algorithmic regularization, and improved sample complexity},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiplicative updates for symmetric-cone factorizations.
<em>MP</em>, <em>207</em>(1), 427–456. (<a
href="https://doi.org/10.1007/s10107-023-02015-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a matrix $$X\in \mathbb {R}^{m\times n}_+$$ with non-negative entries, the cone factorization problem concerns computing $$\{ {a}_1,\ldots , {a}_{m} \} \subseteq \mathcal {K}$$ belonging to a convex cone $$\mathcal {K}\subseteq \mathbb {R}^k$$ , and $$\{ {b}_1,\ldots , {b}_{n} \} \subseteq ~\mathcal {K}^*$$ belonging to its dual so that $$X_{ij} = \langle {a}_i, {b}_j \rangle $$ for all $$i\in [m], j\in [n]$$ . Cone factorizations are fundamental to mathematical optimization as they allow us to express convex bodies as feasible regions of linear conic programs. In this paper, we introduce the symmetric-cone multiplicative update (SCMU) algorithm for computing cone factorizations in settings where $$\mathcal {K}$$ is symmetric; i.e., the cone is self-dual and homogeneous. Our proposed SCMU algorithm is multiplicative in the sense that each iterate is updated by applying a suitably chosen automorphism of the cone, which is is obtained via a generalization of the geometric mean to symmetric cones. In particular, the SCMU update ensures that iterates remain in the interior of the cone by design. When applied to direct sums of simpler symmetric cones, the SCMU algorithm preserves the direct sum structure, and hence specifies an algorithm for computing cone factorizations over such cones. By using an extension of the Lieb’s concavity theorem to symmetric cones, we show that the squared-loss objective is non-decreasing under the SCMU algorithm. When specialized to the nonnegative orthant, the SCMU algorithm recovers the seminal multiplicative update algorithm for computing Non-negative Matrix Factorizations developed by Lee and Seung. Last, we apply the SCMU algorithm to investigate hybrid lifts (combining SDP- and SOCP-based descriptions) of regular polygons from a numerical perspective.},
  archive      = {J_MP},
  author       = {Soh, Yong Sheng and Varvitsiotis, Antonios},
  doi          = {10.1007/s10107-023-02015-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {427-456},
  shortjournal = {Math. Program.},
  title        = {Multiplicative updates for symmetric-cone factorizations},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Residuals-based distributionally robust optimization with
covariate information. <em>MP</em>, <em>207</em>(1), 369–425. (<a
href="https://doi.org/10.1007/s10107-023-02014-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider data-driven approaches that integrate a machine learning prediction model within distributionally robust optimization (DRO) given limited joint observations of uncertain parameters and covariates. Our framework is flexible in the sense that it can accommodate a variety of regression setups and DRO ambiguity sets. We investigate asymptotic and finite sample properties of solutions obtained using Wasserstein, sample robust optimization, and phi-divergence-based ambiguity sets within our DRO formulations, and explore cross-validation approaches for sizing these ambiguity sets. Through numerical experiments, we validate our theoretical results, study the effectiveness of our approaches for sizing ambiguity sets, and illustrate the benefits of our DRO formulations in the limited data regime even when the prediction model is misspecified.},
  archive      = {J_MP},
  author       = {Kannan, Rohit and Bayraksan, Güzin and Luedtke, James R.},
  doi          = {10.1007/s10107-023-02014-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {369-425},
  shortjournal = {Math. Program.},
  title        = {Residuals-based distributionally robust optimization with covariate information},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deterministic enumeration of all minimum cut-sets and
k-cut-sets in hypergraphs for fixed k. <em>MP</em>, <em>207</em>(1),
329–367. (<a href="https://doi.org/10.1007/s10107-023-02013-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of deterministically enumerating all minimum k-cut-sets in a given hypergraph for fixed constant k. The input here is a hypergraph $$G=(V,E)$$ with non-negative hyperedge costs. A subset $$F\subseteq E$$ of hyperedges is a k-cut-set if the number of connected components in $$G-F$$ is at least k and it is a minimum k-cut-set if it has the least cost among all k-cut-sets. For fixed k, we call the problem of finding a minimum k-cut-set as Hypergraph- $$k$$ -Cut and the problem of enumerating all minimum k-cut-sets as Enum-Hypergraph- $$k$$ -Cut. The special cases of Hypergraph- $$k$$ -Cut and Enum-Hypergraph- $$k$$ -Cut restricted to graph inputs are well-known to be solvable in (randomized as well as deterministic) polynomial time (Goldschmidt and Hochbaum in Math Oper Res 19(1):24–37, 1994; Karger and Stein in J ACM 43(4):601–640, 1996; Kamidoi et al. in SIAM J Comput 36(5):1329–1341, 2007; Thorup, in: Proceedings of the 40th annual ACM symposium on theory of computing, STOC, 2008). In contrast, it is only recently that polynomial-time algorithms for Hypergraph- $$k$$ -Cut were developed (Chandrasekaran et al. in Math Program 186:85–113, 2019; Fox et al., in: Proceedings of the 30th annual ACM-SIAM symposium on discrete algorithms, SODA, 2019; Chandrasekaran and Chekuri in Math Oper Res 47:3380–3399, 2022). The randomized polynomial-time algorithm for Hypergraph- $$k$$ -Cut that was designed in 2018 (Chandrasekaran et al. 2019) showed that the number of minimum k-cut-sets in a hypergraph is $$O(n^{2k-2})$$ , where n is the number of vertices in the input hypergraph, and that they can all be enumerated in randomized polynomial time, thus resolving Enum-Hypergraph- $$k$$ -Cut in randomized polynomial time. A deterministic polynomial-time algorithm for Hypergraph- $$k$$ -Cut was subsequently designed in 2020 (Chandrasekaran and Chekuri 2022), but it is not guaranteed to enumerate all minimum k-cut-sets. In this work, we give the first deterministic polynomial-time algorithm to solve Enum-Hypergraph- $$k$$ -Cut (this is non-trivial even for $$k=2$$ ). Our algorithm is based on new structural results that allow for efficient recovery of all minimum k-cut-sets by solving minimum (S, T)-terminal cuts. Our techniques give new structural insights even for minimum cut-sets (i.e., minimum 2-cut-sets) in hypergraphs—we give a new proof showing that the number of minimum cut-sets in a n-vertex hypergraph is at most $$\left( {\begin{array}{c}n\\ 2\end{array}}\right) $$ and they can all be enumerated in deterministic polynomial time for a given hypergraph.},
  archive      = {J_MP},
  author       = {Beideman, Calvin and Chandrasekaran, Karthekeyan and Wang, Weihang},
  doi          = {10.1007/s10107-023-02013-8},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {329-367},
  shortjournal = {Math. Program.},
  title        = {Deterministic enumeration of all minimum cut-sets and k-cut-sets in hypergraphs for fixed k},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The density of planar sets avoiding unit distances.
<em>MP</em>, <em>207</em>(1), 303–327. (<a
href="https://doi.org/10.1007/s10107-023-02012-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By improving upon previous estimates on a problem posed by L. Moser, we prove a conjecture of Erdős that the density of any measurable planar set avoiding unit distances is less than 1/4. Our argument implies the upper bound of 0.2470.},
  archive      = {J_MP},
  author       = {Ambrus, Gergely and Csiszárik, Adrián and Matolcsi, Máté and Varga, Dániel and Zsámboki, Pál},
  doi          = {10.1007/s10107-023-02012-9},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {303-327},
  shortjournal = {Math. Program.},
  title        = {The density of planar sets avoiding unit distances},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A polynomial-size extended formulation for the multilinear
polytope of beta-acyclic hypergraphs. <em>MP</em>, <em>207</em>(1),
269–301. (<a href="https://doi.org/10.1007/s10107-023-02009-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the multilinear polytope defined as the convex hull of the set of binary points z, satisfying a collection of equations of the form $$z_e = \prod _{v \in e} z_v$$ for all $$e \in E$$ . The complexity of the facial structure of the multilinear polytope is closely related to the acyclicity degree of the underlying hypergraph. We obtain a polynomial-size extended formulation for the multilinear polytope of $$\beta $$ -acyclic hypergraphs, hence characterizing the acyclic hypergraphs for which such a formulation can be constructed.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Khajavirad, Aida},
  doi          = {10.1007/s10107-023-02009-4},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {269-301},
  shortjournal = {Math. Program.},
  title        = {A polynomial-size extended formulation for the multilinear polytope of beta-acyclic hypergraphs},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new complexity metric for nonconvex rank-one generalized
matrix completion. <em>MP</em>, <em>207</em>(1), 227–268. (<a
href="https://doi.org/10.1007/s10107-023-02008-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a new complexity metric for an important class of low-rank matrix optimization problems in both symmetric and asymmetric cases, where the metric aims to quantify the complexity of the nonconvex optimization landscape of each problem and the success of local search methods in solving the problem. The existing literature has focused on two recovery guarantees. The RIP constant is commonly used to characterize the complexity of matrix sensing problems. On the other hand, the incoherence and the sampling rate are used when analyzing matrix completion problems. The proposed complexity metric has the potential to generalize these two notions and also applies to a much larger class of problems. To mathematically study the properties of this metric, we focus on the rank-1 generalized matrix completion problem and illustrate the usefulness of the new complexity metric on three types of instances, namely, instances with the RIP condition, instances obeying the Bernoulli sampling model, and a synthetic example. We show that the complexity metric exhibits a consistent behavior in the three cases, even when other existing conditions fail to provide theoretical guarantees. These observations provide a strong implication that the new complexity metric has the potential to generalize various conditions of optimization complexity proposed for different applications. Furthermore, we establish theoretical results to provide sufficient conditions and necessary conditions for the existence of spurious solutions in terms of the proposed complexity metric. This contrasts with the RIP and incoherence conditions that fail to provide any necessary condition.},
  archive      = {J_MP},
  author       = {Zhang, Haixiang and Yalcin, Baturalp and Lavaei, Javad and Sojoudi, Somayeh},
  doi          = {10.1007/s10107-023-02008-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {227-268},
  shortjournal = {Math. Program.},
  title        = {A new complexity metric for nonconvex rank-one generalized matrix completion},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable adaptive cubic regularization methods. <em>MP</em>,
<em>207</em>(1), 191–225. (<a
href="https://doi.org/10.1007/s10107-023-02007-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive cubic regularization (ARC) methods for unconstrained optimization compute steps from linear systems involving a shifted Hessian in the spirit of the Levenberg-Marquardt and trust-region methods. The standard approach consists in performing an iterative search for the shift akin to solving the secular equation in trust-region methods. Such search requires computing the Cholesky factorization of a tentative shifted Hessian at each iteration, which limits the size of problems that can be reasonably considered. We propose a scalable implementation of ARC named ARC $$_q$$ K in which we solve a set of shifted systems concurrently by way of an appropriate modification of the Lanczos formulation of the conjugate gradient (CG) method. At each iteration of ARC $$_q$$ K to solve a problem with $$n$$ variables, a range of $$m \ll n$$ shift parameters is selected. The computational overhead in CG beyond the Lanczos process is thirteen scalar operations to update five vectors of length $$m$$ , and two $$n$$ -vector updates for each value of the shift. The CG variant only requires one Hessian-vector product and one dot product per iteration, independently of $$m$$ . Solves corresponding to inadequate shift parameters are interrupted early. All shifted systems are solved inexactly. Such modest cost makes our implementation scalable and appropriate for large-scale problems. We provide a new analysis of the inexact ARC method including its worst case evaluation complexity, global and asymptotic convergence. We describe our implementation and report numerical experience that confirms that our implementation of ARC $$_q$$ K outperforms a classic Steihaug-Toint trust-region method, and the ARC method of the GALAHAD library. The latter solves the subproblem in nested Krylov subspaces by a Lanczos-based method, which requires the storage of a dense matrix that can be comparable to or larger than the two dense arrays required by our approach if the problem is large or requires many Lanczos iterations. Finally, we generalize our convergence results to inexact Hessians and nonlinear least-squares problems.},
  archive      = {J_MP},
  author       = {Dussault, Jean-Pierre and Migot, Tangi and Orban, Dominique},
  doi          = {10.1007/s10107-023-02007-6},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {191-225},
  shortjournal = {Math. Program.},
  title        = {Scalable adaptive cubic regularization methods},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic algorithms with geometric step decay converge
linearly on sharp functions. <em>MP</em>, <em>207</em>(1), 145–190. (<a
href="https://doi.org/10.1007/s10107-023-02003-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic (sub)gradient methods require step size schedule tuning to perform well in practice. Classical tuning strategies decay the step size polynomially and lead to optimal sublinear rates on (strongly) convex problems. An alternative schedule, popular in nonconvex optimization, is called geometric step decay and proceeds by halving the step size after every few epochs. In recent work, geometric step decay was shown to improve exponentially upon classical sublinear rates for the class of sharp convex functions. In this work, we ask whether geometric step decay similarly improves stochastic algorithms for the class of sharp weakly convex problems. Such losses feature in modern statistical recovery problems and lead to a new challenge not present in the convex setting: the region of convergence is local, so one must bound the probability of escape. Our main result shows that for a large class of stochastic, sharp, nonsmooth, and nonconvex problems a geometric step decay schedule endows well-known algorithms with a local linear (or nearly linear) rate of convergence to global minimizers. This guarantee applies to the stochastic projected subgradient, proximal point, and prox-linear algorithms. As an application of our main result, we analyze two statistical recovery tasks—phase retrieval and blind deconvolution—and match the best known guarantees under Gaussian measurement models and establish new guarantees under heavy-tailed distributions.},
  archive      = {J_MP},
  author       = {Davis, Damek and Drusvyatskiy, Dmitriy and Charisopoulos, Vasileios},
  doi          = {10.1007/s10107-023-02003-w},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {145-190},
  shortjournal = {Math. Program.},
  title        = {Stochastic algorithms with geometric step decay converge linearly on sharp functions},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complexity of a projected newton-CG method for optimization
with bounds. <em>MP</em>, <em>207</em>(1), 107–144. (<a
href="https://doi.org/10.1007/s10107-023-02000-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a method for solving smooth nonconvex minimization problems subject to bound constraints with good worst-case complexity guarantees and practical performance. The method contains elements of two existing methods: the classical gradient projection approach for bound-constrained optimization and a recently proposed Newton-conjugate gradient algorithm for unconstrained nonconvex optimization. Using a new definition of approximate second-order optimality parametrized by some tolerance $$\epsilon $$ (which is compared with related definitions from previous works), we derive complexity bounds in terms of $$\epsilon $$ for both the number of iterations required and the total amount of computation. The latter is measured by the number of gradient evaluations or Hessian-vector products. We also describe illustrative computational results on several test problems from low-rank matrix optimization.},
  archive      = {J_MP},
  author       = {Xie, Yue and Wright, Stephen J.},
  doi          = {10.1007/s10107-023-02000-z},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {107-144},
  shortjournal = {Math. Program.},
  title        = {Complexity of a projected newton-CG method for optimization with bounds},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). First- and second-order high probability complexity bounds
for trust-region methods with noisy oracles. <em>MP</em>,
<em>207</em>(1), 55–106. (<a
href="https://doi.org/10.1007/s10107-023-01999-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present convergence guarantees for a modified trust-region method designed for minimizing objective functions whose value and gradient and Hessian estimates are computed with noise. These estimates are produced by generic stochastic oracles, which are not assumed to be unbiased or consistent. We introduce these oracles and show that they are more general and have more relaxed assumptions than the stochastic oracles used in prior literature on stochastic trust-region methods. Our method utilizes a relaxed step acceptance criterion and a cautious trust-region radius updating strategy which allows us to derive exponentially decaying tail bounds on the iteration complexity for convergence to points that satisfy approximate first- and second-order optimality conditions. Finally, we present two sets of numerical results. We first explore the tightness of our theoretical results on an example with adversarial zeroth- and first-order oracles. We then investigate the performance of the modified trust-region algorithm on standard noisy derivative-free optimization problems.},
  archive      = {J_MP},
  author       = {Cao, Liyuan and Berahas, Albert S. and Scheinberg, Katya},
  doi          = {10.1007/s10107-023-01999-5},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {55-106},
  shortjournal = {Math. Program.},
  title        = {First- and second-order high probability complexity bounds for trust-region methods with noisy oracles},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal gradient tracking for decentralized optimization.
<em>MP</em>, <em>207</em>(1), 1–53. (<a
href="https://doi.org/10.1007/s10107-023-01997-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on solving the decentralized optimization problem of minimizing the sum of n objective functions over a multi-agent network. The agents are embedded in an undirected graph where they can only send/receive information directly to/from their immediate neighbors. Assuming smooth and strongly convex objective functions, we propose an Optimal Gradient Tracking (OGT) method that achieves the optimal gradient computation complexity $$O\left( \sqrt{\kappa }\log \frac{1}{\epsilon } \right) $$ and the optimal communication complexity $$O\left( \sqrt{\frac{\kappa }{\theta }}\log \frac{1}{\epsilon } \right) $$ simultaneously, where $$\kappa $$ and $$\frac{1}{\theta }$$ denote the condition numbers related to the objective functions and the communication graph, respectively. To our best knowledge, $$\textsc {OGT}$$ is the first single-loop decentralized gradient-type method that is optimal in both gradient computation and communication complexities. The development of $$\textsc {OGT}$$ involves two building blocks that are also of independent interest. The first one is another new decentralized gradient tracking method termed “Snapshot” Gradient Tracking (SS-GT), which achieves the gradient computation and communication complexities of $$O\left( \sqrt{\kappa }\log \frac{1}{\epsilon } \right) $$ and $$O\left( \frac{\sqrt{\kappa }}{\theta }\log \frac{1}{\epsilon } \right) $$ , respectively. $$\textsc {SS-GT}$$ can be potentially extended to more general settings compared to OGT. The second one is a technique termed Loopless Chebyshev Acceleration (LCA), which can be implemented “looplessly” but achieves a similar effect by adding multiple inner loops of Chebyshev acceleration in the algorithm. In addition to $$\textsc {SS-GT}$$ , this LCA technique can accelerate many other gradient tracking based methods with respect to the graph condition number $$\frac{1}{\theta }$$ .},
  archive      = {J_MP},
  author       = {Song, Zhuoqing and Shi, Lei and Pu, Shi and Yan, Ming},
  doi          = {10.1007/s10107-023-01997-7},
  journal      = {Mathematical Programming},
  month        = {9},
  number       = {1},
  pages        = {1-53},
  shortjournal = {Math. Program.},
  title        = {Optimal gradient tracking for decentralized optimization},
  volume       = {207},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On circuit diameter bounds via circuit imbalances.
<em>MP</em>, <em>206</em>(1), 631–662. (<a
href="https://doi.org/10.1007/s10107-024-02107-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the circuit diameter of polyhedra, introduced by Borgwardt, Finhold, and Hemmecke (SIAM J. Discrete Math. 29(1), 113–121 (2015)) as a relaxation of the combinatorial diameter. We show that the circuit diameter of a system $$\{x\in \mathbb {R}^n:\, Ax=b,\, \mathbb {0}\le x\le u\}$$ for $$A\in \mathbb {R}^{m\times n}$$ is bounded by $$O(m\min \{m, n - m\}\log (m+\kappa _A)+n\log n)$$ , where $$\kappa _A$$ is the circuit imbalance measure of the constraint matrix. This yields a strongly polynomial circuit diameter bound if e.g., all entries of A have polynomially bounded encoding length in n. Further, we present circuit augmentation algorithms for LPs using the minimum-ratio circuit cancelling rule. Even though the standard minimum-ratio circuit cancelling algorithm is not finite in general, our variant can solve an LP in $$O(mn^2\log (n+\kappa _A))$$ augmentation steps.},
  archive      = {J_MP},
  author       = {Dadush, Daniel and Koh, Zhuan Khye and Natura, Bento and Végh, László A.},
  doi          = {10.1007/s10107-024-02107-x},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {631-662},
  shortjournal = {Math. Program.},
  title        = {On circuit diameter bounds via circuit imbalances},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A PTAS for the horizontal rectangle stabbing problem.
<em>MP</em>, <em>206</em>(1), 607–630. (<a
href="https://doi.org/10.1007/s10107-024-02106-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study rectangle stabbing problems in which we are given n axis-aligned rectangles in the plane that we want to stab, that is, we want to select line segments such that for each given rectangle there is a line segment that intersects two opposite edges of it. In the horizontal rectangle stabbing problem (Stabbing), the goal is to find a set of horizontal line segments of minimum total length such that all rectangles are stabbed. In the horizontal–vertical stabbing problem (HV-Stabbing), the goal is to find a set of rectilinear (that is, either vertical or horizontal) line segments of minimum total length such that all rectangles are stabbed. Both variants are NP-hard. Chan et al. (ISAAC, 2018) initiated the study of these problems by providing constant approximation algorithms. Recently, Eisenbrand et al. (A QPTAS for stabbing rectangles, 2021) have presented a QPTAS and a polynomial-time 8-approximation algorithm for Stabbing, but it was open whether the problem admits a PTAS. In this paper, we obtain a PTAS for Stabbing, settling this question. For HV-Stabbing, we obtain a $$(2+\varepsilon )$$ -approximation. We also obtain PTASs for special cases of HV-Stabbing: (i) when all rectangles are squares, (ii) when each rectangle’s width is at most its height, and (iii) when all rectangles are $$\delta $$ -large, that is, have at least one edge whose length is at least $$\delta $$ , while all edge lengths are at most 1. Our result also implies improved approximations for other problems such as generalized minimum Manhattan network.},
  archive      = {J_MP},
  author       = {Khan, Arindam and Subramanian, Aditya and Wiese, Andreas},
  doi          = {10.1007/s10107-024-02106-y},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {607-630},
  shortjournal = {Math. Program.},
  title        = {A PTAS for the horizontal rectangle stabbing problem},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph coloring and semidefinite rank. <em>MP</em>,
<em>206</em>(1), 577–605. (<a
href="https://doi.org/10.1007/s10107-024-02085-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the interplay between semidefinite programming, matrix rank, and graph coloring. Karger et al. (J ACM 45(2):246–265, 1998) give a vector program in which a coloring of a graph can be encoded as a semidefinite matrix of low rank. By complementary slackness conditions of semidefinite programming, if an optimal dual solution has high rank, any optimal primal solution must have low rank. We attempt to characterize graphs for which we can show that the corresponding dual optimal solution must have rank high enough that the primal solution encodes a coloring. In the case of the original Karger, Motwani, and Sudan vector program, we show that any graph which is a k-tree has sufficiently high dual rank, and we can extract the coloring from the corresponding low-rank primal solution. We can also show that if a graph is not uniquely colorable, then no sufficiently high rank dual optimal solution can exist. This allows us to completely characterize the planar graphs for which dual optimal solutions have sufficiently high dual rank, since it is known that the uniquely colorable planar graphs are precisely the planar 3-trees. We then modify the semidefinite program to have an objective function with costs, and explore when we can create an objective function such that the optimal dual solution has sufficiently high rank. We show that it is always possible to construct such an objective function given the graph coloring. The construction of the objective function gives rise to heuristics for 4-coloring planar graphs. We enumerated all maximal planar graphs with an induced $$K_4$$ of up to 14 vertices; the heuristics successfully found a 4-coloring for 99.75% of them. Our research was motivated by trying to use semidefinite programming to prove the four-color theorem, which states that every planar graph can be colored with four colors. There is an intriguing connection of the Karger–Motwani–Sudan semidefinite program with the Colin de Verdière graph invariant (J Combin. Theory Ser B 50:11-21, 1990) (and a corresponding conjecture of Colin de Verdière), in which matrices that have some similarities to the dual feasible matrices of the semidefinite program must have high rank in the case that graphs are of a certain type; for instance, planar graphs have rank that would imply that the primal solution of the semidefinite program encodes a 4-coloring.},
  archive      = {J_MP},
  author       = {Mirka, Renee and Smedira, Devin and Williamson, David P.},
  doi          = {10.1007/s10107-024-02085-0},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {577-605},
  shortjournal = {Math. Program.},
  title        = {Graph coloring and semidefinite rank},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matroid-based TSP rounding for half-integral solutions.
<em>MP</em>, <em>206</em>(1), 541–576. (<a
href="https://doi.org/10.1007/s10107-024-02065-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how to round any half-integral solution to the subtour-elimination relaxation for the TSP, while losing a less-than $$-$$ 1.5 factor. Such a rounding algorithm was recently given by Karlin, Klein, and Oveis Gharan based on sampling from max-entropy distributions. We build on an approach of Haddadan and Newman to show how sampling from the matroid intersection polytope, combined with a novel use of max-entropy sampling, can give better guarantees.},
  archive      = {J_MP},
  author       = {Gupta, Anupam and Lee, Euiwoong and Li, Jason and Mucha, Marcin and Newman, Heather and Sarkar, Sherry},
  doi          = {10.1007/s10107-024-02065-4},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {541-576},
  shortjournal = {Math. Program.},
  title        = {Matroid-based TSP rounding for half-integral solutions},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A constant-factor approximation for generalized malleable
scheduling under <span
class="math display"><em>M</em><sup>♮</sup></span> -concave processing
speeds. <em>MP</em>, <em>206</em>(1), 515–539. (<a
href="https://doi.org/10.1007/s10107-023-02054-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In generalized malleable scheduling, jobs can be allocated and processed simultaneously on multiple machines so as to reduce the overall makespan of the schedule. The required processing time for each job is determined by the joint processing speed of the allocated machines. We study the case that processing speeds are job-dependent $$M ^{\natural }$$ -concave functions and provide a constant-factor approximation for this setting, significantly expanding the realm of functions for which such an approximation is possible. Further, we explore the connection between malleable scheduling and the problem of fairly allocating items to a set of agents with distinct utility functions, devising a black-box reduction that allows to obtain resource-augmented approximation algorithms for the latter.},
  archive      = {J_MP},
  author       = {Fotakis, Dimitris and Matuschke, Jannik and Papadigenopoulos, Orestis},
  doi          = {10.1007/s10107-023-02054-z},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {515-539},
  shortjournal = {Math. Program.},
  title        = {A constant-factor approximation for generalized malleable scheduling under $$M ^{\natural }$$ -concave processing speeds},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A competitive algorithm for throughput maximization on
identical machines. <em>MP</em>, <em>206</em>(1), 497–514. (<a
href="https://doi.org/10.1007/s10107-023-02045-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the basic problem of scheduling jobs online with preemption to maximize the number of jobs completed by their deadline on m identical machines. The main result is an O(1) competitive deterministic algorithm for any number of machines $$m &gt;1$$ .},
  archive      = {J_MP},
  author       = {Moseley, Benjamin and Pruhs, Kirk and Stein, Clifford and Zhou, Rudy},
  doi          = {10.1007/s10107-023-02045-0},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {497-514},
  shortjournal = {Math. Program.},
  title        = {A competitive algorithm for throughput maximization on identical machines},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A 2-approximation for the bounded treewidth sparsest cut
problem in <span class="math display">FPT</span> time. <em>MP</em>,
<em>206</em>(1), 479–495. (<a
href="https://doi.org/10.1007/s10107-023-02044-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the non-uniform sparsest cut problem, we are given a supply graph G and a demand graph D, both with the same set of nodes V. The goal is to find a cut of V that minimizes the ratio of the total capacity on the edges of G crossing the cut over the total demand of the crossing edges of D. In this work, we study the non-uniform sparsest cut problem for supply graphs with bounded treewidth k. For this case, Gupta et al. (ACM STOC, 2013) obtained a 2-approximation with polynomial running time for fixed k, and it remained open the question of whether there exists a c-approximation algorithm for a constant c independent of k, that runs in $$\textsf{FPT}$$ time. We answer this question in the affirmative. We design a 2-approximation algorithm for the non-uniform sparsest cut with bounded treewidth supply graphs that runs in $$\textsf{FPT}$$ time, when parameterized by the treewidth. Our algorithm is based on rounding the optimal solution of a linear programming relaxation inspired by the Sherali-Adams hierarchy. In contrast to the classic Sherali-Adams approach, we construct a relaxation driven by a tree decomposition of the supply graph by including a carefully chosen set of lifting variables and constraints to encode information of subsets of nodes with super-constant size, and at the same time we have a sufficiently small linear program that can be solved in $$\textsf{FPT}$$ time.},
  archive      = {J_MP},
  author       = {Cohen-Addad, Vincent and Mömke, Tobias and Verdugo, Victor},
  doi          = {10.1007/s10107-023-02044-1},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {479-495},
  shortjournal = {Math. Program.},
  title        = {A 2-approximation for the bounded treewidth sparsest cut problem in $$\textsf{FPT}$$ time},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intersecting and dense restrictions of clutters in
polynomial time. <em>MP</em>, <em>206</em>(1), 461–477. (<a
href="https://doi.org/10.1007/s10107-023-02034-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A clutter is a family of sets, called members, such that no member contains another. It is called intersecting if every two members intersect, but not all members have a common element. Dense clutters additionally do not have a fractional packing of value 2. We are looking at certain substructures of clutters, namely minors and restrictions. For a family of clutters we introduce a general sufficient condition such that for every clutter we can decide whether the clutter has a restriction in that set in polynomial time. It is known that the sets of intersecting and dense clutters satisfy this condition. For intersecting clutters we generalize the statement to k-wise intersecting clutters using a much simpler proof. We also give a simplified proof that a dense clutter with no proper dense minor is either a delta or the blocker of an extended odd hole. This simplification reduces the running time of the algorithm for finding a delta or the blocker of an extended odd hole minor from previously $${\mathscr {O}}(n^4)$$ to $${\mathscr {O}}(n^3)$$ filter oracle calls.},
  archive      = {J_MP},
  author       = {Drees, Martin},
  doi          = {10.1007/s10107-023-02034-3},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {461-477},
  shortjournal = {Math. Program.},
  title        = {Intersecting and dense restrictions of clutters in polynomial time},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal item pricing in online combinatorial auctions.
<em>MP</em>, <em>206</em>(1), 429–460. (<a
href="https://doi.org/10.1007/s10107-023-02027-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a fundamental pricing problem in combinatorial auctions. We are given a set of indivisible items and a set of buyers with randomly drawn monotone valuations over subsets of items. A decision-maker sets item prices and then the buyers make sequential purchasing decisions, taking their favorite set among the remaining items. We parametrize an instance by d, the size of the largest set a buyer may want. Our main result asserts that there exist prices such that the expected (over the random valuations) welfare of the allocation they induce is at least a factor $$1/(d+1)$$ times the expected optimal welfare in hindsight. Moreover, we prove that this bound is tight. Thus, our result not only improves upon the $$1/(4d-2)$$ bound of Dütting et al., but also settles the approximation that can be achieved by using item prices. The existence of these prices follows from the existence of a fixed point of a related mapping, and therefore, it is non-constructive. However, we show how to compute such a fixed point in polynomial time, even if we only have sample access to the valuation distributions. We provide additional results for the special case when buyers’ valuations are known (but a posted-price mechanism is still desired), and an improved impossibility result for the special case of prophet inequalities for bipartite matching.},
  archive      = {J_MP},
  author       = {Correa, José and Cristi, Andrés and Fielbaum, Andrés and Pollner, Tristan and Weinberg, S. Matthew},
  doi          = {10.1007/s10107-023-02027-2},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {429-460},
  shortjournal = {Math. Program.},
  title        = {Optimal item pricing in online combinatorial auctions},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The limits of local search for weighted k-set packing.
<em>MP</em>, <em>206</em>(1), 389–427. (<a
href="https://doi.org/10.1007/s10107-023-02026-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the weighted k-set packing problem, where, given a collection $${\mathcal {S}}$$ of sets, each of cardinality at most k, and a positive weight function $$w:{\mathcal {S}}\rightarrow {\mathbb {Q}}_{&gt;0}$$ , the task is to find a sub-collection of $${\mathcal {S}}$$ consisting of pairwise disjoint sets of maximum total weight. As this problem does not permit a polynomial-time $$o(\frac{k}{\log k})$$ -approximation unless $$P=NP$$ (Hazan et al. in Comput Complex 15:20–39, 2006. https://doi.org/10.1007/s00037-006-0205-6 ), most previous approaches rely on local search. For twenty years, Berman’s algorithm SquareImp (Berman, in: Scandinavian workshop on algorithm theory, Springer, 2000. https://doi.org/10.1007/3-540-44985-X_19 ), which yields a polynomial-time $$\frac{k+1}{2}+\epsilon $$ -approximation for any fixed $$\epsilon &gt;0$$ , has remained unchallenged. Only recently, it could be improved to $$\frac{k+1}{2}-\frac{1}{63,700,993}$$ by Neuwohner (38th International symposium on theoretical aspects of computer science (STACS 2021), Leibniz international proceedings in informatics (LIPIcs), 2021. https://doi.org/10.4230/LIPIcs.STACS.2021.53 ). In her paper, she showed that instances for which the analysis of SquareImp is almost tight are “close to unweighted” in a certain sense. But for the unit weight variant, the best known approximation guarantee is $$\frac{k+1}{3}+\epsilon $$ (Fürer and Yu in International symposium on combinatorial optimization, Springer, 2014. https://doi.org/10.1007/978-3-319-09174-7_35 ). Using this observation as a starting point, we conduct a more in-depth analysis of close-to-tight instances of SquareImp. This finally allows us to generalize techniques used in the unweighted case to the weighted setting. In doing so, we obtain approximation guarantees of $$\frac{k+\epsilon _k}{2}$$ , where $$\lim _{k\rightarrow \infty } \epsilon _k = 0$$ . On the other hand, we prove that this is asymptotically best possible in that local improvements of logarithmically bounded size cannot produce an approximation ratio below $$\frac{k}{2}$$ .},
  archive      = {J_MP},
  author       = {Neuwohner, Meike},
  doi          = {10.1007/s10107-023-02026-3},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {389-427},
  shortjournal = {Math. Program.},
  title        = {The limits of local search for weighted k-set packing},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse multi-term disjunctive cuts for the epigraph of a
function of binary variables. <em>MP</em>, <em>206</em>(1), 357–388. (<a
href="https://doi.org/10.1007/s10107-023-02019-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for separating valid inequalities for the epigraph of a function of binary variables. The proposed inequalities are disjunctive cuts defined by disjunctive terms obtained by enumerating a subset I of the binary variables. We show that by restricting the support of the cut to the same set of variables I, a cut can be obtained by solving a linear program with $$2^{|I|}$$ constraints. While this limits the size of the set I used to define the multi-term disjunction, the procedure enables generation of multi-term disjunctive cuts using far more terms than existing approaches. We present two approaches for choosing the subset of variables. Experience on three MILP problems with block diagonal structure using |I| up to size 10 indicates the sparse cuts can often close nearly as much gap as the multi-term disjunctive cuts without this restriction and in a fraction of the time. We also find that including these cuts within a cut-and-branch solution method for these MILP problems leads to significant reductions in solution time or ending optimality gap for instances that were not solved within the time limit. Finally, we describe how the proposed approach can be adapted to optimally “tilt” a given valid inequality by modifying the coefficients of a sparse subset of the variables.},
  archive      = {J_MP},
  author       = {Chen, Rui and Luedtke, James},
  doi          = {10.1007/s10107-023-02019-2},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {357-388},
  shortjournal = {Math. Program.},
  title        = {Sparse multi-term disjunctive cuts for the epigraph of a function of binary variables},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural networks with linear threshold activations: Structure
and algorithms. <em>MP</em>, <em>206</em>(1), 333–356. (<a
href="https://doi.org/10.1007/s10107-023-02016-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we present new results on neural networks with linear threshold activation functions $$x \mapsto \mathbb {1}_{\{ x &gt; 0\}}$$ . We precisely characterize the class of functions that are representable by such neural networks and show that 2 hidden layers are necessary and sufficient to represent any function representable in the class. This is a surprising result in the light of recent exact representability investigations for neural networks using other popular activation functions like rectified linear units (ReLU). We also give upper and lower bounds on the sizes of the neural networks required to represent any function in the class. Finally, we design an algorithm to solve the empirical risk minimization (ERM) problem to global optimality for these neural networks with a fixed architecture. The algorithm’s running time is polynomial in the size of the data sample, if the input dimension and the size of the network architecture are considered fixed constants. The algorithm is unique in the sense that it works for any architecture with any number of layers, whereas previous polynomial time globally optimal algorithms work only for restricted classes of architectures. Using these insights, we propose a new class of neural networks that we call shortcut linear threshold neural networks. To the best of our knowledge, this way of designing neural networks has not been explored before in the literature. We show that these neural networks have several desirable theoretical properties.},
  archive      = {J_MP},
  author       = {Khalife, Sammy and Cheng, Hongyu and Basu, Amitabh},
  doi          = {10.1007/s10107-023-02016-5},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {333-356},
  shortjournal = {Math. Program.},
  title        = {Neural networks with linear threshold activations: Structure and algorithms},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The simultaneous semi-random model for TSP. <em>MP</em>,
<em>206</em>(1), 305–332. (<a
href="https://doi.org/10.1007/s10107-023-02011-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Worst-case analysis is a performance measure that is often too pessimistic to indicate which algorithms we should use in practice. A classical example is in the context of the Euclidean Traveling Salesman Problem (TSP) in the plane, where local search performs very well in practice even though it only achieves an $$\Omega (\frac{\log n}{\log \log n})$$ worst-case approximation ratio. In such cases, a natural alternative approach to worst-case analysis is to analyze the performance of algorithms in semi-random models. In this paper, we propose and investigate a novel semi-random model for the Euclidean TSP. In this model, called the simultaneous semi-random model, an instance over n points consists of the union of an adversarial instance over $$(1-\alpha )n$$ points and a random instance over $$\alpha n$$ points, for some $$\alpha \in [0, 1]$$ . As with smoothed analysis, the semi-random model interpolates between distributional (random) analysis when $$\alpha = 1$$ and worst-case analysis when $$\alpha = 0$$ . In contrast to smoothed analysis, this model trades off allowing some completely random points in order to have other points that exhibit a fully arbitrary structure. We show that with only an $$\alpha = \frac{1}{\log n}$$ fraction of the points being random, local search achieves an $$\mathcal {O}(\log \log n)$$ approximation in the simultaneous semi-random model for Euclidean TSP in fixed dimensions. On the other hand, we show that at least a polynomial number of random points are required to obtain an asymptotic improvement in the approximation ratio of local search compared to its worst-case approximation, even in two dimensions.},
  archive      = {J_MP},
  author       = {Balkanski, Eric and Faenza, Yuri and Kubik, Mathieu},
  doi          = {10.1007/s10107-023-02011-w},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {305-332},
  shortjournal = {Math. Program.},
  title        = {The simultaneous semi-random model for TSP},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simple method for convex optimization in the oracle model.
<em>MP</em>, <em>206</em>(1), 283–304. (<a
href="https://doi.org/10.1007/s10107-023-02005-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a simple and natural method for computing approximately optimal solutions for minimizing a convex function f over a convex set K given by a separation oracle. Our method utilizes the Frank–Wolfe algorithm over the cone of valid inequalities of K and subgradients of f. Under the assumption that f is L-Lipschitz and that K contains a ball of radius r and is contained inside the origin centered ball of radius R, using $$O\left( \frac{(RL)^2}{\varepsilon ^2} \cdot \frac{R^2}{r^2}\right) $$ iterations and calls to the oracle, our main method outputs a point $$x \in K$$ satisfying $$f(x) \le \varepsilon + \min _{z \in K} f(z)$$ . Our algorithm is easy to implement, and we believe it can serve as a useful alternative to existing cutting plane methods. As evidence towards this, we show that it compares favorably in terms of iteration counts to the standard LP based cutting plane method and the analytic center cutting plane method, on a testbed of combinatorial, semidefinite and machine learning instances.},
  archive      = {J_MP},
  author       = {Dadush, Daniel and Hojny, Christopher and Huiberts, Sophie and Weltge, Stefan},
  doi          = {10.1007/s10107-023-02005-8},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {283-304},
  shortjournal = {Math. Program.},
  title        = {A simple method for convex optimization in the oracle model},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LP-based approximations for disjoint bilinear and two-stage
adjustable robust optimization. <em>MP</em>, <em>206</em>(1), 239–281.
(<a href="https://doi.org/10.1007/s10107-023-02004-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the class of disjoint bilinear programs $$ \max \, \{ {\textbf{x}}^T{\textbf{y}} \mid {\textbf{x}} \in {\mathcal {X}}, \;{\textbf{y}} \in {\mathcal {Y}}\}$$ where $${\mathcal {X}}$$ and $${\mathcal {Y}}$$ are packing polytopes. We present an $$O(\frac{\log \log m_1}{\log m_1} \frac{\log \log m_2}{\log m_2})$$ -approximation algorithm for this problem where $$m_1$$ and $$m_2$$ are the number of packing constraints in $${\mathcal {X}}$$ and $${\mathcal {Y}}$$ respectively. In particular, we show that there exists a near-optimal solution $$(\tilde{{\textbf{x}}}, \tilde{{\textbf{y}}})$$ such that $$\tilde{{\textbf{x}}}$$ and $$\tilde{{\textbf{y}}}$$ are “near-integral&quot;. We give an LP relaxation of the problem from which we obtain the near-optimal near-integral solution via randomized rounding. We show that our relaxation is tightly related to the widely used reformulation linearization technique. As an application of our techniques, we present a tight approximation for the two-stage adjustable robust optimization problem with covering constraints and right-hand side uncertainty where the separation problem is a bilinear optimization problem. In particular, based on the ideas above, we give an LP restriction of the two-stage problem that is an $$O(\frac{\log n}{\log \log n} \frac{\log L}{\log \log L})$$ -approximation where L is the number of constraints in the uncertainty set. This significantly improves over state-of-the-art approximation bounds known for this problem. Furthermore, we show that our LP restriction gives a feasible affine policy for the two-stage robust problem with the same (or better) objective value. As a consequence, affine policies give an $$O(\frac{\log n}{\log \log n} \frac{\log L}{\log \log L})$$ -approximation of the two-stage problem, significantly generalizing the previously known bounds on their performance.},
  archive      = {J_MP},
  author       = {El Housni, Omar and Foussoul, Ayoub and Goyal, Vineet},
  doi          = {10.1007/s10107-023-02004-9},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {239-281},
  shortjournal = {Math. Program.},
  title        = {LP-based approximations for disjoint bilinear and two-stage adjustable robust optimization},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simple odd <span class="math display"><em>β</em></span>
-cycle inequalities for binary polynomial optimization. <em>MP</em>,
<em>206</em>(1), 203–238. (<a
href="https://doi.org/10.1007/s10107-023-01992-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the multilinear polytope which arises naturally in binary polynomial optimization. Del Pia and Di Gregorio introduced the class of odd $$\beta $$ -cycle inequalities valid for this polytope, showed that these generally have Chvátal rank 2 with respect to the standard relaxation and that, together with flower inequalities, they yield a perfect formulation for cycle hypergraph instances. Moreover, they describe a separation algorithm in case the instance is a cycle hypergraph. We introduce a weaker version, called simple odd $$\beta $$ -cycle inequalities, for which we establish a strongly polynomial-time separation algorithm for arbitrary instances. These inequalities still have Chvátal rank 2 in general and still suffice to describe the multilinear polytope for cycle hypergraphs. Finally, we report about computational results of our prototype implementation. The simple odd $$\beta $$ -cycle inequalities sometimes help to close more of the integrality gap in the experiments; however, the preliminary implementation has substantial computational cost, suggesting room for improvement in the separation algorithm.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Walter, Matthias},
  doi          = {10.1007/s10107-023-01992-y},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {203-238},
  shortjournal = {Math. Program.},
  title        = {Simple odd $$\beta $$ -cycle inequalities for binary polynomial optimization},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An abstract model for branch and cut. <em>MP</em>,
<em>206</em>(1), 175–202. (<a
href="https://doi.org/10.1007/s10107-023-01991-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Branch and cut is the dominant paradigm for solving a wide range of mathematical programming problems—linear or nonlinear—combining efficient search (via branch and bound) and relaxation-tightening procedures (via cutting planes, or cuts). While there is a wealth of computational experience behind existing cutting strategies, there is simultaneously a relative lack of theoretical explanations for these choices, and for the tradeoffs involved therein. Recent papers have explored abstract models for branching and for comparing cuts with branch and bound. However, to model practice, it is crucial to understand the impact of jointly considering branching and cutting decisions. In this paper, we provide a framework for analyzing how cuts affect the size of branch-and-cut trees, as well as their impact on solution time. Our abstract model captures some of the key characteristics of real-world phenomena in branch-and-cut experiments, regarding whether to generate cuts only at the root or throughout the tree, how many rounds of cuts to add before starting to branch, and why cuts seem to exhibit nonmonotonic effects on the solution process.},
  archive      = {J_MP},
  author       = {Kazachkov, Aleksandr M. and Le Bodic, Pierre and Sankaranarayanan, Sriram},
  doi          = {10.1007/s10107-023-01991-z},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {175-202},
  shortjournal = {Math. Program.},
  title        = {An abstract model for branch and cut},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On computing small variable disjunction branch-and-bound
trees. <em>MP</em>, <em>206</em>(1), 145–173. (<a
href="https://doi.org/10.1007/s10107-023-01968-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates smallest branch-and-bound trees and their computation. We first revisit the notion of hiding sets to deduce lower bounds on the size of branch-and-bound trees for certain binary programs, using both variable disjunctions and general disjunctions. We then provide exponential lower bounds for variable disjunctions by a disjoint composition of smaller binary programs. Moreover, we investigate the complexity of finding small branch-and-bound trees using variable disjunctions: We show that it is not possible to approximate the size of a smallest branch-and-bound tree within a factor of $$\smash {2^{\frac{1}{5}n}}$$ in time $$O(2^{\delta n})$$ with $$\delta 0$$ , no polynomial time $$\smash {2^{(\frac{1}{2} - \varepsilon )n}}$$ -approximation is possible, unless $$\text {P} = \text {NP} $$ . We also show that computing the size of a smallest branch-and-bound tree exactly is $${\#P} $$ -hard. Similar results hold for estimating the size of the tree produced by branching rules like most-infeasible branching. Finally, we discuss that finding small branch-and-bound trees generalizes finding short treelike resolution refutations, and thus non-automatizability results transfer from this setting.},
  archive      = {J_MP},
  author       = {Gläser, Max and Pfetsch, Marc E.},
  doi          = {10.1007/s10107-023-01968-y},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {145-173},
  shortjournal = {Math. Program.},
  title        = {On computing small variable disjunction branch-and-bound trees},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Total dual dyadicness and dyadic generating sets.
<em>MP</em>, <em>206</em>(1), 125–143. (<a
href="https://doi.org/10.1007/s10107-023-01967-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vector is dyadic if each of its entries is a dyadic rational number, i.e. of the form $$\frac{a}{2^k}$$ for some integers a, k with $$k\ge 0$$ . A linear system $$Ax\le b$$ with integral data is totally dual dyadic if whenever $$\min \{b^\top y:A^\top y=w,y\ge \textbf{0}\}$$ for w integral, has an optimal solution, it has a dyadic optimal solution. In this paper, we study total dual dyadicness, and give a co-NP characterization of it in terms of dyadic generating sets for cones and subspaces, the former being the dyadic analogue of Hilbert bases, and the latter a polynomial-time recognizable relaxation of the former. Along the way, we see some surprising turn of events when compared to total dual integrality, primarily led by the density of the dyadic rationals. Our study ultimately leads to a better understanding of total dual integrality and polyhedral integrality. We see examples from dyadic matroids, T-joins, cycles, and perfect matchings of a graph.},
  archive      = {J_MP},
  author       = {Abdi, Ahmad and Cornuéjols, Gérard and Guenin, Bertrand and Tunçel, Levent},
  doi          = {10.1007/s10107-023-01967-z},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {125-143},
  shortjournal = {Math. Program.},
  title        = {Total dual dyadicness and dyadic generating sets},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On SOCP-based disjunctive cuts for solving a class of
integer bilevel nonlinear programs. <em>MP</em>, <em>206</em>(1),
91–124. (<a href="https://doi.org/10.1007/s10107-023-01965-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of integer bilevel programs with second-order cone constraints at the upper-level and a convex-quadratic objective function and linear constraints at the lower-level. We develop disjunctive cuts (DCs) to separate bilevel-infeasible solutions using a second-order-cone-based cut-generating procedure. We propose DC separation strategies and consider several approaches for removing redundant disjunctions and normalization. Using these DCs, we propose a branch-and-cut algorithm for the problem class we study, and a cutting-plane method for the problem variant with only binary variables. We present an extensive computational study on a diverse set of instances, including instances with binary and with integer variables, and instances with a single and with multiple linking constraints. Our computational study demonstrates that the proposed enhancements of our solution approaches are effective for improving the performance. Moreover, both of our approaches outperform a state-of-the-art generic solver for mixed-integer bilevel linear programs that is able to solve a linearized version of our binary instances.},
  archive      = {J_MP},
  author       = {Gaar, Elisabeth and Lee, Jon and Ljubić, Ivana and Sinnl, Markus and Tanınmış, Kübra},
  doi          = {10.1007/s10107-023-01965-1},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {91-124},
  shortjournal = {Math. Program.},
  title        = {On SOCP-based disjunctive cuts for solving a class of integer bilevel nonlinear programs},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the maximal number of columns of a <span
class="math display"><em>Δ</em></span> -modular integer matrix: Bounds
and computations. <em>MP</em>, <em>206</em>(1), 61–89. (<a
href="https://doi.org/10.1007/s10107-023-01964-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the maximal number of pairwise distinct columns in a $$\varDelta $$ -modular integer matrix with m rows. Recent results by Lee et al. provide an asymptotically tight upper bound of $$\mathcal {O}\left( m^2\right) $$ for fixed $$\varDelta $$ . We complement this and obtain an upper bound of the form $$\mathcal {O}(\varDelta )$$ for fixed m, and with the implied constant depending polynomially on m.},
  archive      = {J_MP},
  author       = {Averkov, Gennadiy and Schymura, Matthias},
  doi          = {10.1007/s10107-023-01964-2},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {61-89},
  shortjournal = {Math. Program.},
  title        = {On the maximal number of columns of a $$\Delta $$ -modular integer matrix: Bounds and computations},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the complexity of separating cutting planes for the
knapsack polytope. <em>MP</em>, <em>206</em>(1), 33–59. (<a
href="https://doi.org/10.1007/s10107-023-01963-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We close three open problems on the separation complexity of valid inequalities for the knapsack polytope. Specifically, we establish that the separation problems for extended cover inequalities, (1, k)-configuration inequalities, and weight inequalities are all $$\mathcal{N}\mathcal{P}$$ -complete. We also show that, when the number of constraints of the LP relaxation is constant and its optimal solution is an extreme point, then the separation problems of both extended cover inequalities and weight inequalities can be solved in polynomial time. Moreover, we provide a natural generalization of (1, k)-configuration inequality which is easier to separate and contains the original (1, k)-configuration inequality as a strict sub-family.},
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Linderoth, Jeff and Zhu, Haoran},
  doi          = {10.1007/s10107-023-01963-3},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {33-59},
  shortjournal = {Math. Program.},
  title        = {On the complexity of separating cutting planes for the knapsack polytope},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster goal-oriented shortest path search for bulk and
incremental detailed routing. <em>MP</em>, <em>206</em>(1), 3–32. (<a
href="https://doi.org/10.1007/s10107-023-01962-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop new algorithmic techniques for VLSI detailed routing. First, we improve the goal-oriented version of Dijkstra’s algorithm to find shortest paths in huge incomplete grid graphs with edge costs depending on the direction and the layer, and possibly on rectangular regions. We devise estimates of the distance to the targets that offer better trade-offs between running time and quality than previously known methods, leading to an overall speed-up. Second, we combine the advantages of the two classical detailed routing approaches—global shortest path search and track assignment with local corrections—by treating input wires (such as the output of track assignment) as reservations that can be used at a discount by the respective net. We show how to implement this new approach efficiently.},
  archive      = {J_MP},
  author       = {Ahrens, Markus and Henke, Dorothee and Rabenstein, Stefan and Vygen, Jens},
  doi          = {10.1007/s10107-023-01962-4},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {3-32},
  shortjournal = {Math. Program.},
  title        = {Faster goal-oriented shortest path search for bulk and incremental detailed routing},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue: Integer programming and combinatorial
optimization (IPCO) 2022. <em>MP</em>, <em>206</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s10107-024-02115-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Aardal, Karen and Sanità, Laura},
  doi          = {10.1007/s10107-024-02115-x},
  journal      = {Mathematical Programming},
  month        = {7},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Math. Program.},
  title        = {Special issue: Integer programming and combinatorial optimization (IPCO) 2022},
  volume       = {206},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: The ancestral benders’ cutting-plane
algorithm with multi-term disjunctions for mixed-integer recourse
decisions in stochastic programming. <em>MP</em>, <em>205</em>(1),
841–845. (<a href="https://doi.org/10.1007/s10107-023-02039-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Qi, Yunwei and Sen, Suvrajeet},
  doi          = {10.1007/s10107-023-02039-y},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {841-845},
  shortjournal = {Math. Program.},
  title        = {Correction to: The ancestral benders’ cutting-plane algorithm with multi-term disjunctions for mixed-integer recourse decisions in stochastic programming},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tropical medians by transportation. <em>MP</em>,
<em>205</em>(1), 813–839. (<a
href="https://doi.org/10.1007/s10107-023-01996-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fermat–Weber points with respect to an asymmetric tropical distance function are studied. It turns out that they correspond to the optimal solutions of a transportation problem. The results are applied to obtain a new method for computing consensus trees in phylogenetics. This method has several desirable properties; e.g., it is Pareto and co-Pareto on rooted triplets.},
  archive      = {J_MP},
  author       = {Comăneci, Andrei and Joswig, Michael},
  doi          = {10.1007/s10107-023-01996-8},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {813-839},
  shortjournal = {Math. Program.},
  title        = {Tropical medians by transportation},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new extension of chubanov’s method to symmetric cones.
<em>MP</em>, <em>205</em>(1), 773–812. (<a
href="https://doi.org/10.1007/s10107-023-01995-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new variant of Chubanov’s method for solving the feasibility problem over the symmetric cone by extending Roos’s method (Optim Methods Softw 33(1):26–44, 2018) of solving the feasibility problem over the nonnegative orthant. The proposed method considers a feasibility problem associated with a norm induced by the maximum eigenvalue of an element and uses a rescaling focusing on the upper bound for the sum of eigenvalues of any feasible solution to the problem. Its computational bound is (1) equivalent to that of Roos’s original method (2018) and superior to that of Lourenço et al.’s method (Math Program 173(1–2):117–149, 2019) when the symmetric cone is the nonnegative orthant, (2) superior to that of Lourenço et al.’s method (2019) when the symmetric cone is a Cartesian product of second-order cones, (3) equivalent to that of Lourenço et al.’s method (2019) when the symmetric cone is the simple positive semidefinite cone, and (4) superior to that of Pena and Soheili’s method (Math Program 166(1–2):87–111, 2017) for any simple symmetric cones under the feasibility assumption of the problem imposed in Pena and Soheili’s method (2017). We also conduct numerical experiments that compare the performance of our method with existing methods by generating strongly (but ill-conditioned) feasible instances. For any of these instances, the proposed method is rather more efficient than the existing methods in terms of accuracy and execution time.},
  archive      = {J_MP},
  author       = {Kanoh, Shin-ichi and Yoshise, Akiko},
  doi          = {10.1007/s10107-023-01995-9},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {773-812},
  shortjournal = {Math. Program.},
  title        = {A new extension of chubanov’s method to symmetric cones},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of rationality in integer-programming relaxations.
<em>MP</em>, <em>205</em>(1), 745–771. (<a
href="https://doi.org/10.1007/s10107-023-01994-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a finite set $$X \subset \mathbb {Z}^d$$ that can be represented as $$X = Q \cap \mathbb {Z}^d$$ for some polyhedron Q, we call Q a relaxation of X and define the relaxation complexity $${\text {rc}}(X)$$ of X as the least number of facets among all possible relaxations Q of X. The rational relaxation complexity $${\text {rc}}_\mathbb {Q}(X)$$ restricts the definition of $${\text {rc}}(X)$$ to rational polyhedra Q. In this article, we focus on $$X = \Delta _d$$ , the vertex set of the standard simplex, which consists of the null vector and the standard unit vectors in $$\mathbb {R}^d$$ . We show that $${\text {rc}}(\Delta _d) \le d$$ for every $$d \ge 5$$ . That is, since $${\text {rc}}_\mathbb {Q}(\Delta _d)=d+1$$ , irrationality can reduce the minimal size of relaxations. This answers an open question posed by Kaibel and Weltge (Math Program 154(1):407–425, 2015). Moreover, we prove the asymptotic statement $${\text {rc}}(\Delta _d) \in O(\nicefrac {d}{\sqrt{\log (d)}})$$ , which shows that the ratio $$\nicefrac {{\text {rc}}(\Delta _d)}{{\text {rc}}_\mathbb {Q}(\Delta _d)}$$ goes to 0, as $$d \rightarrow \infty $$ .},
  archive      = {J_MP},
  author       = {Aprile, Manuel and Averkov, Gennadiy and Di Summa, Marco and Hojny, Christopher},
  doi          = {10.1007/s10107-023-01994-w},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {745-771},
  shortjournal = {Math. Program.},
  title        = {The role of rationality in integer-programming relaxations},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting ideal-sparsity in the generalized moment problem
with application to matrix factorization ranks. <em>MP</em>,
<em>205</em>(1), 703–744. (<a
href="https://doi.org/10.1007/s10107-023-01993-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore a new type of sparsity for the generalized moment problem (GMP) that we call ideal-sparsity. In this setting, one optimizes over a measure restricted to be supported on the variety of an ideal generated by quadratic bilinear monomials. We show that this restriction enables an equivalent sparse reformulation of the GMP, where the single (high dimensional) measure variable is replaced by several (lower dimensional) measure variables supported on the maximal cliques of the graph corresponding to the quadratic bilinear constraints. We explore the resulting hierarchies of moment-based relaxations for the original dense formulation of GMP and this new, equivalent ideal-sparse reformulation, when applied to the problem of bounding nonnegative- and completely positive matrix factorization ranks. We show that the ideal-sparse hierarchies provide bounds that are at least as good (and often tighter) as those obtained from the dense hierarchy. This is in sharp contrast to the situation when exploiting correlative sparsity, as is most common in the literature, where the resulting bounds are weaker than the dense bounds. Moreover, while correlative sparsity requires the underlying graph to be chordal, no such assumption is needed for ideal-sparsity. Numerical results show that the ideal-sparse bounds are often tighter and much faster to compute than their dense analogs.},
  archive      = {J_MP},
  author       = {Korda, Milan and Laurent, Monique and Magron, Victor and Steenkamp, Andries},
  doi          = {10.1007/s10107-023-01993-x},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {703-744},
  shortjournal = {Math. Program.},
  title        = {Exploiting ideal-sparsity in the generalized moment problem with application to matrix factorization ranks},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Swarm gradient dynamics for global optimization: The
mean-field limit case. <em>MP</em>, <em>205</em>(1), 661–701. (<a
href="https://doi.org/10.1007/s10107-023-01988-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using jointly geometric and stochastic reformulations of nonconvex problems and exploiting a Monge–Kantorovich (or Wasserstein) gradient system formulation with vanishing forces, we formally extend the simulated annealing method to a wide range of global optimization methods. Due to the built-in combination of a gradient-like strategy and particle interactions, we call them swarm gradient dynamics. As in the original paper by Holley–Kusuoka–Stroock, a functional inequality is the key to the existence of a schedule that ensures convergence to a global minimizer. One of our central theoretical contributions is proving such an inequality for one-dimensional compact manifolds. We conjecture that the inequality holds true in a much broader setting. Additionally, we describe a general method for global optimization that highlights the essential role of functional inequalities la Łojasiewicz.},
  archive      = {J_MP},
  author       = {Bolte, Jérôme and Miclo, Laurent and Villeneuve, Stéphane},
  doi          = {10.1007/s10107-023-01988-8},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {661-701},
  shortjournal = {Math. Program.},
  title        = {Swarm gradient dynamics for global optimization: The mean-field limit case},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph isomorphism: Physical resources, optimization models,
and algebraic characterizations. <em>MP</em>, <em>205</em>(1), 617–660.
(<a href="https://doi.org/10.1007/s10107-023-01989-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the (G, H)-isomorphism game, a verifier interacts with two non-communicating players (called provers), by privately sending each of them a random vertex from either G or H. The goal of the players is to convince the verifier that the graphs G and H are isomorphic. In recent work along with Atserias et al. (J Comb Theory Ser B 136:89–328, 2019) we showed that a verifier can be convinced that two non-isomorphic graphs are isomorphic, if the provers are allowed to share quantum resources. In this paper we model classical and quantum graph isomorphism by linear constraints over certain complicated convex cones, which we then relax to a pair of tractable convex models (semidefinite programs). Our main result is a complete algebraic characterization of the corresponding equivalence relations on graphs in terms of appropriate matrix algebras. Our techniques are an interesting mix of algebra, combinatorics, optimization, and quantum information.},
  archive      = {J_MP},
  author       = {Mančinska, Laura and Roberson, David E. and Varvitsiotis, Antonios},
  doi          = {10.1007/s10107-023-01989-7},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {617-660},
  shortjournal = {Math. Program.},
  title        = {Graph isomorphism: Physical resources, optimization models, and algebraic characterizations},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A preconditioned iterative interior point approach to the
conic bundle subproblem. <em>MP</em>, <em>205</em>(1), 559–615. (<a
href="https://doi.org/10.1007/s10107-023-01986-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conic bundle implementation of the spectral bundle method for large scale semidefinite programming solves in each iteration a semidefinite quadratic subproblem by an interior point approach. For larger cutting model sizes the limiting operation is collecting and factorizing a Schur complement of the primal-dual KKT system. We explore possibilities to improve on this by an iterative approach that exploits structural low rank properties. Two preconditioning approaches are proposed and analyzed. Both might be of interest for rank structured positive definite systems in general. The first employs projections onto random subspaces, the second projects onto a subspace that is chosen deterministically based on structural interior point properties. For both approaches theoretic bounds are derived for the associated condition number. In the instances tested the deterministic preconditioner provides surprisingly efficient control on the actual condition number. The results suggest that for large scale instances the iterative solver is usually the better choice if precision requirements are moderate or if the size of the Schur complemented system clearly exceeds the active dimension within the subspace giving rise to the cutting model of the bundle method.},
  archive      = {J_MP},
  author       = {Helmberg, Christoph},
  doi          = {10.1007/s10107-023-01986-w},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {559-615},
  shortjournal = {Math. Program.},
  title        = {A preconditioned iterative interior point approach to the conic bundle subproblem},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convex hull results on quadratic programs with
non-intersecting constraints. <em>MP</em>, <em>205</em>(1), 539–558. (<a
href="https://doi.org/10.1007/s10107-023-01985-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $${\mathcal {F}}\subseteq \mathbb {R}^n$$ be a nonempty closed set. Understanding the structure of the closed convex hull $${\overline{{\mathcal {C}}}}({\mathcal {F}}):= {\overline{{{\,\textrm{conv}\,}}}} \{ (x, xx^T) | x \in {\mathcal {F}}\}$$ in the lifted space is crucial for solving quadratic programs related to $${\mathcal {F}}$$ . This paper discusses the relationship between $${\overline{{\mathcal {C}}}}({\mathcal {F}})$$ and $${\overline{{\mathcal {C}}}}({\mathcal {G}})$$ , where $${\mathcal {G}}$$ results by adding non-intersecting quadratic constraints to $${\mathcal {F}}$$ . We prove that $${\overline{{\mathcal {C}}}}({\mathcal {G}})$$ can be represented as the intersection of $${\overline{{\mathcal {C}}}}({\mathcal {F}})$$ and half spaces defined by the added constraints. The proof relies on a complete description of the asymptotic cones of sets defined by a single quadratic equality and a partial characterization of the recession cone of $${\overline{{\mathcal {C}}}}({\mathcal {G}})$$ . Our proof generalizes an existing result for bounded quadratically defined $${\mathcal {F}}$$ with non-intersecting hollows and several results on $${\overline{{\mathcal {C}}}}({\mathcal {G}})$$ for $${\mathcal {G}}$$ defined by non-intersecting quadratic constraints. The result also implies a sufficient condition for when the lifted closed convex hull of an intersection equals the intersection of the lifted closed convex hulls.},
  archive      = {J_MP},
  author       = {Joyce, Alexander and Yang, Boshi},
  doi          = {10.1007/s10107-023-01985-x},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {539-558},
  shortjournal = {Math. Program.},
  title        = {Convex hull results on quadratic programs with non-intersecting constraints},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pareto adaptive robust optimality via a fourier–motzkin
elimination lens. <em>MP</em>, <em>205</em>(1), 485–538. (<a
href="https://doi.org/10.1007/s10107-023-01983-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formalize the concept of Pareto Adaptive Robust Optimality (PARO) for linear two-stage Adaptive Robust Optimization (ARO) problems, with fixed continuous recourse. A worst-case optimal solution pair of here-and-now decisions and wait-and-see decisions is PARO if it cannot be Pareto dominated by another solution, i.e., there does not exist another worst-case optimal pair that performs at least as good in all scenarios in the uncertainty set and strictly better in at least one scenario. We argue that, unlike PARO, extant solution approaches—including those that adopt Pareto Robust Optimality from static robust optimization—could fail in ARO and yield solutions that can be Pareto dominated. The latter could lead to inefficiencies and suboptimal performance in practice. We prove the existence of PARO solutions, and present approaches for finding and approximating such solutions. Amongst others, we present a constraint &amp; column generation method that produces a PARO solution for the considered two-stage ARO problems by iteratively improving upon a worst-case optimal solution. We present numerical results for a facility location problem that demonstrate the practical value of PARO solutions. Our analysis of PARO relies on an application of Fourier–Motzkin Elimination as a proof technique. We demonstrate how this technique can be valuable in the analysis of ARO problems, besides PARO. In particular, we employ it to devise more concise and more insightful proofs of known results on (worst-case) optimality of decision rule structures.},
  archive      = {J_MP},
  author       = {Bertsimas, Dimitris and ten Eikelder, Stefan C. M. and den Hertog, Dick and Trichakis, Nikolaos},
  doi          = {10.1007/s10107-023-01983-z},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {485-538},
  shortjournal = {Math. Program.},
  title        = {Pareto adaptive robust optimality via a Fourier–Motzkin elimination lens},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Worst-case complexity of an SQP method for nonlinear
equality constrained stochastic optimization. <em>MP</em>,
<em>205</em>(1), 431–483. (<a
href="https://doi.org/10.1007/s10107-023-01981-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A worst-case complexity bound is proved for a sequential quadratic optimization (commonly known as SQP) algorithm that has been designed for solving optimization problems involving a stochastic objective function and deterministic nonlinear equality constraints. Barring additional terms that arise due to the adaptivity of the monotonically nonincreasing merit parameter sequence, the proved complexity bound is comparable to that known for the stochastic gradient algorithm for unconstrained nonconvex optimization. The overall complexity bound, which accounts for the adaptivity of the merit parameter sequence, shows that a result comparable to the unconstrained setting (with additional logarithmic factors) holds with high probability.},
  archive      = {J_MP},
  author       = {Curtis, Frank E. and O’Neill, Michael J. and Robinson, Daniel P.},
  doi          = {10.1007/s10107-023-01981-1},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {431-483},
  shortjournal = {Math. Program.},
  title        = {Worst-case complexity of an SQP method for nonlinear equality constrained stochastic optimization},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Globally convergent coderivative-based generalized newton
methods in nonsmooth optimization. <em>MP</em>, <em>205</em>(1),
373–429. (<a href="https://doi.org/10.1007/s10107-023-01980-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes and justifies two globally convergent Newton-type methods to solve unconstrained and constrained problems of nonsmooth optimization by using tools of variational analysis and generalized differentiation. Both methods are coderivative-based and employ generalized Hessians (coderivatives of subgradient mappings) associated with objective functions, which are either of class $${{\mathcal {C}}}^{1,1}$$ , or are represented in the form of convex composite optimization, where one of the terms may be extended-real-valued. The proposed globally convergent algorithms are of two types. The first one extends the damped Newton method and requires positive-definiteness of the generalized Hessians for its well-posedness and efficient performance, while the other algorithm is of the regularized Newton-type being well-defined when the generalized Hessians are merely positive-semidefinite. The obtained convergence rates for both methods are at least linear, but become superlinear under the semismooth $$^*$$ property of subgradient mappings. Problems of convex composite optimization are investigated with and without the strong convexity assumption on smooth parts of objective functions by implementing the machinery of forward–backward envelopes. Numerical experiments are conducted for Lasso problems and for box constrained quadratic programs with providing performance comparisons of the new algorithms and some other first-order and second-order methods that are highly recognized in nonsmooth optimization.},
  archive      = {J_MP},
  author       = {Khanh, Pham Duy and Mordukhovich, Boris S. and Phat, Vo Thanh and Tran, Dat Ba},
  doi          = {10.1007/s10107-023-01980-2},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {373-429},
  shortjournal = {Math. Program.},
  title        = {Globally convergent coderivative-based generalized newton methods in nonsmooth optimization},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the centralization of the circumcentered-reflection
method. <em>MP</em>, <em>205</em>(1), 337–371. (<a
href="https://doi.org/10.1007/s10107-023-01978-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to deriving the first circumcenter iteration scheme that does not employ a product space reformulation for finding a point in the intersection of two closed convex sets. We introduce a so-called centralized version of the circumcentered-reflection method (CRM). Developed with the aim of accelerating classical projection algorithms, CRM is successful for tracking a common point of a finite number of affine sets. In the case of general convex sets, CRM was shown to possibly diverge if Pierra’s product space reformulation is not used. In this work, we prove that there exists an easily reachable region consisting of what we refer to as centralized points, where pure circumcenter steps possess properties yielding convergence. The resulting algorithm is called centralized CRM (cCRM). In addition to having global convergence, cCRM converges linearly under an error bound condition, and superlinearly if the two target sets are so that their intersection have nonempty interior and their boundaries are locally differentiable manifolds. We also run numerical experiments with successful results.},
  archive      = {J_MP},
  author       = {Behling, Roger and Bello-Cruz, Yunier and Iusem, Alfredo N. and Santos, Luiz-Rafael},
  doi          = {10.1007/s10107-023-01978-w},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {337-371},
  shortjournal = {Math. Program.},
  title        = {On the centralization of the circumcentered-reflection method},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A theoretical and computational analysis of full
strong-branching. <em>MP</em>, <em>205</em>(1), 303–336. (<a
href="https://doi.org/10.1007/s10107-023-01977-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Full strong-branching (henceforth referred to as strong-branching) is a well-known variable selection rule that is known experimentally to produce significantly smaller branch-and-bound trees in comparison to all other known variable selection rules. In this paper, we attempt an analysis of the performance of the strong-branching rule both from a theoretical and a computational perspective. On the positive side for strong-branching, we identify vertex cover as a class of instances where this rule provably works well. In particular, for vertex cover we present: (1) an upper bound on the size of the branch-and-bound tree using strong-branching as a function of the additive integrality gap; (2) show how the Nemhauser-Trotter property of persistency, which can be used as a pre-solve technique for vertex cover, is being recursively and consistently used throughout the strong-branching tree; (3) and finally provide an example of a vertex cover instance where not using strong-branching leads to a tree that has at least exponentially more nodes than the branch-and-bound tree based on strong-branching. On the negative side for strong-branching, we identify another class of instances where the strong-branching tree is exponentially larger than another branch-and-bound tree for solving these instances. On the computational side, we conduct experiments on various types of instances, like the lot-sizing problem and its variants, packing integer programs (IP), covering IPs, chance constrained IPs, vertex cover, etc., to understand how much larger is the size of the strong-branching based branch-and-bound tree in comparison to the optimal branch-and-bound tree. The main take-away from these experiments (on small instances) is that for all these instances the size of the strong-branching tree is within a factor of two of the size of the optimal branch-and-bound tree.},
  archive      = {J_MP},
  author       = {Dey, Santanu S. and Dubey, Yatharth and Molinaro, Marco and Shah, Prachi},
  doi          = {10.1007/s10107-023-01977-x},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {303-336},
  shortjournal = {Math. Program.},
  title        = {A theoretical and computational analysis of full strong-branching},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A solution algorithm for chance-constrained problems with
integer second-stage recourse decisions. <em>MP</em>, <em>205</em>(1),
269–301. (<a href="https://doi.org/10.1007/s10107-023-01984-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of chance-constrained two-stage stochastic optimization problems where the second-stage recourse decisions belong to mixed-integer convex sets. Due to the nonconvexity of the second-stage feasible sets, standard decomposition approaches cannot be applied. We develop a provably convergent branch-and-cut scheme that iteratively generates valid inequalities for the convex hull of the second-stage feasible sets, resorting to spatial branching when cutting no longer suffices. We show that this algorithm attains an approximate notion of convergence, whereby the feasible sets are relaxed by some positive tolerance $$\epsilon $$ . Computational results on chance-constrained resource planning problems indicate that our implementation of the proposed algorithm is highly effective in solving this class of problems, compared to a state-of-the-art MIP solver and to a naive decomposition scheme.},
  archive      = {J_MP},
  author       = {Lodi, Andrea and Malaguti, Enrico and Monaci, Michele and Nannicini, Giacomo and Paronuzzi, Paolo},
  doi          = {10.1007/s10107-023-01984-y},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {269-301},
  shortjournal = {Math. Program.},
  title        = {A solution algorithm for chance-constrained problems with integer second-stage recourse decisions},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). No-regret dynamics in the fenchel game: A unified framework
for algorithmic convex optimization. <em>MP</em>, <em>205</em>(1),
203–268. (<a href="https://doi.org/10.1007/s10107-023-01976-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an algorithmic framework for solving convex optimization problems using no-regret game dynamics. By converting the problem of minimizing a convex function into an auxiliary problem of solving a min–max game in a sequential fashion, we can consider a range of strategies for each of the two-players who must select their actions one after the other. A common choice for these strategies are so-called no-regret learning algorithms, and we describe a number of such and prove bounds on their regret. We then show that many classical first-order methods for convex optimization—including average-iterate gradient descent, the Frank–Wolfe algorithm, Nesterov’s acceleration methods, the accelerated proximal method—can be interpreted as special cases of our framework as long as each player makes the correct choice of no-regret strategy. Proving convergence rates in this framework becomes very straightforward, as they follow from plugging in the appropriate known regret bounds. Our framework also gives rise to a number of new first-order methods for special cases of convex optimization that were not previously known.},
  archive      = {J_MP},
  author       = {Wang, Jun-Kun and Abernethy, Jacob and Levy, Kfir Y.},
  doi          = {10.1007/s10107-023-01976-y},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {203-268},
  shortjournal = {Math. Program.},
  title        = {No-regret dynamics in the fenchel game: A unified framework for algorithmic convex optimization},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymptotic linear convergence of fully-corrective
generalized conditional gradient methods. <em>MP</em>, <em>205</em>(1),
135–202. (<a href="https://doi.org/10.1007/s10107-023-01975-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a fully-corrective generalized conditional gradient method (FC-GCG) for the minimization of the sum of a smooth, convex loss function and a convex one-homogeneous regularizer over a Banach space. The algorithm relies on the mutual update of a finite set $$\mathcal {A}_k$$ of extremal points of the unit ball of the regularizer and of an iterate $$u_k \in {\text {cone}}(\mathcal {A}_k)$$ . Each iteration requires the solution of one linear problem to update $$\mathcal {A}_k$$ and of one finite dimensional convex minimization problem to update the iterate. Under standard hypotheses on the minimization problem we show that the algorithm converges sublinearly to a solution. Subsequently, imposing additional assumptions on the associated dual variables, this is improved to a linear rate of convergence. The proof of both results relies on two key observations: First, we prove the equivalence of the considered problem to the minimization of a lifted functional over a particular space of Radon measures using Choquet’s theorem. Second, the FC-GCG algorithm is connected to a Primal-Dual-Active-Point method on the lifted problem for which we finally derive the desired convergence rates.},
  archive      = {J_MP},
  author       = {Bredies, Kristian and Carioni, Marcello and Fanzon, Silvio and Walter, Daniel},
  doi          = {10.1007/s10107-023-01975-z},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {135-202},
  shortjournal = {Math. Program.},
  title        = {Asymptotic linear convergence of fully-corrective generalized conditional gradient methods},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the stationarity for nonlinear optimization problems with
polyhedral constraints. <em>MP</em>, <em>205</em>(1), 107–134. (<a
href="https://doi.org/10.1007/s10107-023-01979-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For polyhedral constrained optimization problems and a feasible point $$\textbf{x}$$ , it is shown that the projection of the negative gradient on the tangent cone, denoted $$\nabla _\varOmega f(\textbf{x})$$ , has an orthogonal decomposition of the form $$\varvec{\beta }(\textbf{x}) + \varvec{\varphi }(\textbf{x})$$ . At a stationary point, $$\nabla _\varOmega f(\textbf{x}) = \textbf{0}$$ so $$\Vert \nabla _\varOmega f(\textbf{x})\Vert $$ reflects the distance to a stationary point. Away from a stationary point, $$\Vert \varvec{\beta }(\textbf{x})\Vert $$ and $$\Vert \varvec{\varphi }(\textbf{x})\Vert $$ measure different aspects of optimality since $$\varvec{\beta }(\textbf{x})$$ only vanishes when the KKT multipliers at $$\textbf{x}$$ have the correct sign, while $$\varvec{\varphi }(\textbf{x})$$ only vanishes when $$\textbf{x}$$ is a stationary point in the active manifold. As an application of the theory, an active set algorithm is developed for convex quadratic programs which adapts the flow of the algorithm based on a comparison between $$\Vert \varvec{\beta }(\textbf{x})\Vert $$ and $$\Vert \varvec{\varphi }(\textbf{x})\Vert $$ .},
  archive      = {J_MP},
  author       = {di Serafino, Daniela and Hager, William W. and Toraldo, Gerardo and Viola, Marco},
  doi          = {10.1007/s10107-023-01979-9},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {107-134},
  shortjournal = {Math. Program.},
  title        = {On the stationarity for nonlinear optimization problems with polyhedral constraints},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Radial duality part II: Applications and algorithms.
<em>MP</em>, <em>205</em>(1), 69–105. (<a
href="https://doi.org/10.1007/s10107-023-01974-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The first part of this work established the foundations of a radial duality between nonnegative optimization problems, inspired by the work of Renegar (SIAM J Optim 26(4): 2649-2676, 2016). Here we utilize our radial duality theory to design and analyze projection-free optimization algorithms that operate by solving a radially dual problem. In particular, we consider radial subgradient, smoothing, and accelerated methods that are capable of solving a range of constrained convex and nonconvex optimization problems and that can scale-up more efficiently than their classic counterparts. These algorithms enjoy the same benefits as their predecessors, avoiding Lipschitz continuity assumptions and costly orthogonal projections, in our newfound, broader context. Our radial duality further allows us to understand the effects and benefits of smoothness and growth conditions on the radial dual and consequently on our radial algorithms.},
  archive      = {J_MP},
  author       = {Grimmer, Benjamin},
  doi          = {10.1007/s10107-023-01974-0},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {69-105},
  shortjournal = {Math. Program.},
  title        = {Radial duality part II: Applications and algorithms},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Radial duality part i: foundations. <em>MP</em>,
<em>205</em>(1), 33–68. (<a
href="https://doi.org/10.1007/s10107-023-02006-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renegar (SIAM J Optim 26(4):2649–2676, https://doi.org/10.1137/15M1027371 2016) introduced a novel approach to transforming generic conic optimization problems into unconstrained, uniformly Lipschitz continuous minimization. We introduce radial transformations generalizing these ideas, equipped with an entirely new motivation and development that avoids any reliance on convex cones or functions. Of practical importance, this facilitates the development of new families of projection-free first-order methods applicable even in the presence of nonconvex objectives and constraint sets. Our generalized construction of this radial transformation uncovers that it is dual (i.e., self-inverse) for a wide range of functions including all concave objectives. This gives a new duality relating optimization problems to their radially dual problem. For a broad class of functions, we characterize continuity, differentiability, and convexity under the radial transformation as well as develop a calculus for it. This radial duality provides a foundation for designing projection-free radial optimization algorithms, which is carried out in the second part of this work.},
  archive      = {J_MP},
  author       = {Grimmer, Benjamin},
  doi          = {10.1007/s10107-023-02006-7},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {33-68},
  shortjournal = {Math. Program.},
  title        = {Radial duality part i: Foundations},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weak notions of nondegeneracy in nonlinear semidefinite
programming. <em>MP</em>, <em>205</em>(1), 1–32. (<a
href="https://doi.org/10.1007/s10107-023-01970-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constraint nondegeneracy condition is one of the most relevant and useful constraint qualifications in nonlinear semidefinite programming. It can be characterized in terms of any fixed orthonormal basis of the, let us say, $$\ell $$ -dimensional kernel of the constraint matrix, by the linear independence of a set of $$\ell (\ell +1)/2$$ derivative vectors. We show that this linear independence requirement can be equivalently formulated in a smaller set, of $$\ell $$ derivative vectors, by considering all orthonormal bases of the kernel instead. This allows us to identify that not all bases are relevant for a constraint qualification to be defined, giving rise to a strictly weaker variant of nondegeneracy related to the global convergence of an external penalty method. We use some of these ideas to revisit an approach of Forsgren (Math Program 88, 105–128, 2000) for exploiting the sparsity structure of a transformation of the constraints to define a constraint qualification, which led us to develop another relaxed notion of nondegeneracy using a simpler transformation. If the zeros of the derivatives of the constraint function at a given point are considered, instead of the zeros of the function itself in a neighborhood of that point, we obtain an even weaker constraint qualification that connects Forsgren’s condition and ours.},
  archive      = {J_MP},
  author       = {Andreani, Roberto and Haeser, Gabriel and Mito, Leonardo M. and Ramírez, Héctor},
  doi          = {10.1007/s10107-023-01970-4},
  journal      = {Mathematical Programming},
  month        = {5},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Math. Program.},
  title        = {Weak notions of nondegeneracy in nonlinear semidefinite programming},
  volume       = {205},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperbolicity cones are amenable. <em>MP</em>,
<em>204</em>(1), 753–764. (<a
href="https://doi.org/10.1007/s10107-023-01958-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amenability is a notion of facial exposedness for convex cones that is stronger than being facially dual complete (or ‘nice’) which is, in turn, stronger than merely being facially exposed. Hyperbolicity cones are a family of algebraically structured closed convex cones that contain all spectrahedral cones (linear sections of positive semidefinite cones) as special cases. It is known that all spectrahedral cones are amenable. We establish that all hyperbolicity cones are amenable. As part of the argument, we show that any face of a hyperbolicity cone is a hyperbolicity cone. As a corollary, we show that the intersection of two hyperbolicity cones, not necessarily sharing a common relative interior point, is a hyperbolicity cone.},
  archive      = {J_MP},
  author       = {Lourenço, Bruno F. and Roshchina, Vera and Saunderson, James},
  doi          = {10.1007/s10107-023-01958-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {753-764},
  shortjournal = {Math. Program.},
  title        = {Hyperbolicity cones are amenable},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shapes and recession cones in mixed-integer convex
representability. <em>MP</em>, <em>204</em>(1), 739–752. (<a
href="https://doi.org/10.1007/s10107-023-01946-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed-integer convex representable (MICP-R) sets are those sets that can be represented exactly through a mixed-integer convex programming formulation. Following up on recent work by Lubin et al. (in: Eisenbrand (ed) Integer Programming and Combinatorial Optimization - 19th International Conference, Springer, Waterloo), (Math. Oper. Res. 47:720-749, 2022) we investigate structural geometric properties of MICP-R sets, which strongly differentiate them from the class of mixed-integer linear representable (MILP-R) sets. First, we provide an example of an MICP-R set which is the countably infinite union of convex sets with countably infinitely many different recession cones. This is in sharp contrast with MILP-R sets which are (countable) unions of polyhedra that share the same recession cone. Second, we provide an example of an MICP-R set which is the countably infinite union of polytopes all of which have different shapes (no pair is combinatorially equivalent, which implies they are not affine transformations of each other). Again, this is in sharp contrast with MILP-R sets which are (countable) unions of polyhedra that are all translations of a finite subset of themselves.},
  archive      = {J_MP},
  author       = {Zadik, Ilias and Lubin, Miles and Vielma, Juan Pablo},
  doi          = {10.1007/s10107-023-01946-4},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {739-752},
  shortjournal = {Math. Program.},
  title        = {Shapes and recession cones in mixed-integer convex representability},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the convex hull of convex quadratic optimization problems
with indicators. <em>MP</em>, <em>204</em>(1), 703–737. (<a
href="https://doi.org/10.1007/s10107-023-01982-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the convex quadratic optimization problem in $$\mathbb {R}^{n}$$ with indicator variables and arbitrary constraints on the indicators. We show that a convex hull description of the associated mixed-integer set in an extended space with a quadratic number of additional variables consists of an $$(n+1) \times (n+1)$$ positive semidefinite constraint (explicitly stated) and linear constraints. In particular, convexification of this class of problems reduces to describing a polyhedral set in an extended formulation. While the vertex representation of this polyhedral set is exponential and an explicit linear inequality description may not be readily available in general, we derive a compact mixed-integer linear formulation whose solutions coincide with the vertices of the polyhedral set. We also give descriptions in the original space of variables: we provide a description based on an infinite number of conic-quadratic inequalities, which are “finitely generated.” In particular, it is possible to characterize whether a given inequality is necessary to describe the convex hull. The new theory presented here unifies several previously established results, and paves the way toward utilizing polyhedral methods to analyze the convex hull of mixed-integer nonlinear sets.},
  archive      = {J_MP},
  author       = {Wei, Linchuan and Atamtürk, Alper and Gómez, Andrés and Küçükyavuz, Simge},
  doi          = {10.1007/s10107-023-01982-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {703-737},
  shortjournal = {Math. Program.},
  title        = {On the convex hull of convex quadratic optimization problems with indicators},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A colorful steinitz lemma with application to
block-structured integer programs. <em>MP</em>, <em>204</em>(1),
677–702. (<a href="https://doi.org/10.1007/s10107-023-01971-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Steinitz constant in dimension d is the smallest value c(d) such that for any norm on $$\mathbb {R}^{ d}$$ and for any finite zero-sum sequence in the unit ball, the sequence can be permuted such that the norm of each partial sum is bounded by c(d). Grinberg and Sevastyanov prove that $$c(d) \le d$$ and that the bound of d is best possible for arbitrary norms; we refer to their result as the Steinitz Lemma. We present a variation of the Steinitz Lemma that permutes multiple sequences at one time. Our result, which we term a colorful Steinitz Lemma, demonstrates upper bounds that are independent of the number of sequences. Many results in the theory of integer programming are proved by permuting vectors of bounded norm; this includes proximity results, Graver basis algorithms, and dynamic programs. Due to a recent paper of Eisenbrand and Weismantel, there has been a surge of research on how the Steinitz Lemma can be used to improve integer programming results. As an application we prove a proximity result for block-structured integer programs.},
  archive      = {J_MP},
  author       = {Oertel, Timm and Paat, Joseph and Weismantel, Robert},
  doi          = {10.1007/s10107-023-01971-3},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {677-702},
  shortjournal = {Math. Program.},
  title        = {A colorful steinitz lemma with application to block-structured integer programs},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The maximum measure of non-trivial 3-wise intersecting
families. <em>MP</em>, <em>204</em>(1), 643–676. (<a
href="https://doi.org/10.1007/s10107-023-01969-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $$\mathcal G$$ be a family of subsets of an n-element set. The family $$\mathcal G$$ is called non-trivial 3-wise intersecting if the intersection of any three subsets in $$\mathcal G$$ is non-empty, but the intersection of all subsets is empty. For a real number $$p\in (0,1)$$ we define the measure of the family by the sum of $$p^{|G|}(1-p)^{n-|G|}$$ over all $$G\in \mathcal G$$ . We determine the maximum measure of non-trivial 3-wise intersecting families. We also discuss the uniqueness and stability of the corresponding optimal structure. These results are obtained by solving linear programming problems.},
  archive      = {J_MP},
  author       = {Tokushige, Norihide},
  doi          = {10.1007/s10107-023-01969-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {643-676},
  shortjournal = {Math. Program.},
  title        = {The maximum measure of non-trivial 3-wise intersecting families},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Publisher correction: Branch-and-bound performance
estimation programming: A unified methodology for constructing optimal
optimization methods. <em>MP</em>, <em>204</em>(1), 641. (<a
href="https://doi.org/10.1007/s10107-023-01998-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Das Gupta, Shuvomoy and Van Parys, Bart P. G. and Ryu, Ernest K.},
  doi          = {10.1007/s10107-023-01998-6},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {641},
  shortjournal = {Math. Program.},
  title        = {Publisher correction: branch-and-bound performance estimation programming: a unified methodology for constructing optimal optimization methods},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Branch-and-bound performance estimation programming: A
unified methodology for constructing optimal optimization methods.
<em>MP</em>, <em>204</em>(1), 567–639. (<a
href="https://doi.org/10.1007/s10107-023-01973-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the Branch-and-Bound Performance Estimation Programming (BnB-PEP), a unified methodology for constructing optimal first-order methods for convex and nonconvex optimization. BnB-PEP poses the problem of finding the optimal optimization method as a nonconvex but practically tractable quadratically constrained quadratic optimization problem and solves it to certifiable global optimality using a customized branch-and-bound algorithm. By directly confronting the nonconvexity, BnB-PEP offers significantly more flexibility and removes the many limitations of the prior methodologies. Our customized branch-and-bound algorithm, through exploiting specific problem structures, outperforms the latest off-the-shelf implementations by orders of magnitude, accelerating the solution time from hours to seconds and weeks to minutes. We apply BnB-PEP to several setups for which the prior methodologies do not apply and obtain methods with bounds that improve upon prior state-of-the-art results. Finally, we use the BnB-PEP methodology to find proofs with potential function structures, thereby systematically generating analytical convergence proofs.},
  archive      = {J_MP},
  author       = {Das Gupta, Shuvomoy and Van Parys, Bart P. G. and Ryu, Ernest K.},
  doi          = {10.1007/s10107-023-01973-1},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {567-639},
  shortjournal = {Math. Program.},
  title        = {Branch-and-bound performance estimation programming: A unified methodology for constructing optimal optimization methods},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparing solution paths of sparse quadratic minimization
with a stieltjes matrix. <em>MP</em>, <em>204</em>(1), 517–566. (<a
href="https://doi.org/10.1007/s10107-023-01966-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies several solution paths of sparse quadratic minimization problems as a function of the weighing parameter of the bi-objective of estimation loss versus solution sparsity. Three such paths are considered: the “ $$\ell _0$$ -path” where the discontinuous $$\ell _0$$ -function provides the exact sparsity count; the “ $$\ell _1$$ -path” where the $$\ell _1$$ -function provides a convex surrogate of sparsity count; and the “capped $$\ell _1$$ -path” where the nonconvex nondifferentiable capped $$\ell _1$$ -function aims to enhance the $$\ell _1$$ -approximation. Serving different purposes, each of these three formulations is different from each other, both analytically and computationally. Our results deepen the understanding of (old and new) properties of the associated paths, highlight the pros, cons, and tradeoffs of these sparse optimization models, and provide numerical evidence to support the practical superiority of the capped $$\ell _1$$ -path. Our study of the capped $$\ell _1$$ -path is interesting in its own right as the path pertains to computable directionally stationary (= strongly locally minimizing in this context, as opposed to globally optimal) solutions of a parametric nonconvex nondifferentiable optimization problem. Motivated by classical parametric quadratic programming theory and reinforced by modern statistical learning studies, both casting an exponential perspective in fully describing such solution paths, we also aim to address the question of whether some of them can be fully traced in strongly polynomial time in the problem dimensions. A major conclusion of this paper is that a path of directional stationary solutions of the capped $$\ell _1$$ -regularized problem offers interesting theoretical properties and practical compromise between the $$\ell _0$$ -path and the $$\ell _1$$ -path. Indeed, while the $$\ell _0$$ -path is computationally prohibitive and greatly handicapped by the repeated solution of mixed-integer nonlinear programs, the quality of $$\ell _1$$ -path, in terms of the two criteria—loss and sparsity—in the estimation objective, is inferior to the capped $$\ell _1$$ -path; the latter can be obtained efficiently by a combination of a parametric pivoting-like scheme supplemented by an algorithm that takes advantage of the Z-matrix structure of the loss function.},
  archive      = {J_MP},
  author       = {He, Ziyu and Han, Shaoning and Gómez, Andrés and Cui, Ying and Pang, Jong-Shi},
  doi          = {10.1007/s10107-023-01966-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {517-566},
  shortjournal = {Math. Program.},
  title        = {Comparing solution paths of sparse quadratic minimization with a stieltjes matrix},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation algorithms for flexible graph connectivity.
<em>MP</em>, <em>204</em>(1), 493–516. (<a
href="https://doi.org/10.1007/s10107-023-01961-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present approximation algorithms for several network design problems in the model of flexible graph connectivity (Adjiashvili et al., in: IPCO, pp 13–26, 2020, Math Program 1–33, 2021). Let $$k\ge 1$$ , $$p\ge 1$$ and $$q\ge 0$$ be integers. In an instance of the (p, q)-Flexible Graph Connectivity problem, denoted $$(p,q)\text {-FGC}$$ , we have an undirected connected graph $$G = (V,E)$$ , a partition of E into a set of safe edges $${\mathscr {S}}$$ and a set of unsafe edges $${\mathscr {U}}$$ , and nonnegative costs $$c: E\rightarrow {\mathbb {R}}_{\ge 0}$$ on the edges. A subset $$F \subseteq E$$ of edges is feasible for the $$(p,q)\text {-FGC}$$ problem if for any set $$F&#39;\subseteq {\mathscr {U}}$$ with $$|F&#39;|\le q$$ , the subgraph $$(V, F {\setminus } F&#39;)$$ is p-edge connected. The algorithmic goal is to find a feasible solution F that minimizes $$c(F) = \sum _{e \in F} c_e$$ . We present a simple 2-approximation algorithm for the $$(1,1)\text {-FGC}$$ problem via a reduction to the minimum-cost rooted 2-arborescence problem. This improves on the 2.527-approximation algorithm of Adjiashvili et al. Our 2-approximation algorithm for the $$(1,1)\text {-FGC}$$ problem extends to a $$(k+1)$$ -approximation algorithm for the $$(1,k)\text {-FGC}$$ problem. We present a 4-approximation algorithm for the $$(k,1)\text {-FGC}$$ problem, and an $$O(q\log |V|)$$ -approximation algorithm for the $$(p,q)\text {-FGC}$$ problem. Finally, we improve on the result of Adjiashvili et al. for the unweighted $$(1,1)\text {-FGC}$$ problem by presenting a 16/11-approximation algorithm. The $$(p,q)\text {-FGC}$$ problem is related to the well-known Capacitated k-Connected Subgraph problem (denoted $$\text {Cap-}k\text {-ECSS}$$ ) that arises in the area of Capacitated Network Design. We give a $$\min (k,2 {u}_{\textrm{max}})$$ -approximation algorithm for the $$\text {Cap-}k\text {-ECSS}$$ problem, where $${u}_{\textrm{max}}$$ denotes the maximum capacity of an edge.},
  archive      = {J_MP},
  author       = {Boyd, Sylvia and Cheriyan, Joseph and Haddadan, Arash and Ibrahimpur, Sharat},
  doi          = {10.1007/s10107-023-01961-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {493-516},
  shortjournal = {Math. Program.},
  title        = {Approximation algorithms for flexible graph connectivity},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FISTA is an automatic geometrically optimized algorithm for
strongly convex functions. <em>MP</em>, <em>204</em>(1), 449–491. (<a
href="https://doi.org/10.1007/s10107-023-01960-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we are interested in the famous FISTA algorithm. We show that FISTA is an automatic geometrically optimized algorithm for functions satisfying a quadratic growth assumption. This explains why FISTA works better than the standard Forward-Backward algorithm (FB) in such a case, although FISTA is known to have a polynomial asymptotic convergence rate while FB is exponential. We provide a simple rule to tune the $$\alpha $$ parameter within the FISTA algorithm to reach an $$\varepsilon $$ -solution with an optimal number of iterations. These new results highlight the efficiency of FISTA algorithms, and they rely on new non asymptotic bounds for FISTA.},
  archive      = {J_MP},
  author       = {Aujol, J.-F. and Dossal, Ch. and Rondepierre, A.},
  doi          = {10.1007/s10107-023-01960-6},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {449-491},
  shortjournal = {Math. Program.},
  title        = {FISTA is an automatic geometrically optimized algorithm for strongly convex functions},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diverse collections in matroids and graphs. <em>MP</em>,
<em>204</em>(1), 415–447. (<a
href="https://doi.org/10.1007/s10107-023-01959-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the parameterized complexity of finding diverse sets of solutions to three fundamental combinatorial problems. The input to the Weighted Diverse Bases problem consists of a matroid $$M$$ , a weight function $$\omega :E(M)\rightarrow \mathbb {N} $$ , and integers $$k\ge 1, d\ge 1$$ . The task is to decide if there is a collection of $$k$$ bases $$B_{1}, \dotsc , B_{k}$$ of $$M$$ such that the weight of the symmetric difference of any pair of these bases is at least $$d$$ . The input to the Weighted Diverse Common Independent Sets problem consists of two matroids $$M_{1},M_{2}$$ defined on the same ground set $$E$$ , a weight function $$\omega :E\rightarrow \mathbb {N} $$ , and integers $$k\ge 1, d\ge 1$$ . The task is to decide if there is a collection of $$k$$ common independent sets $$I_{1}, \dotsc , I_{k}$$ of $$M_{1}$$ and $$M_{2}$$ such that the weight of the symmetric difference of any pair of these sets is at least $$d$$ . The input to the Diverse Perfect Matchings problem consists of a graph $$G$$ and integers $$k\ge 1, d\ge 1$$ . The task is to decide if $$G$$ contains $$k$$ perfect matchings $$M_{1},\dotsc ,M_{k}$$ such that the symmetric difference of any two of these matchings is at least $$d$$ . We show that none of these problems can be solved in polynomial time unless $${{\,\mathrm{\textsf{P}}\,}} ={{\,\mathrm{\textsf{NP}}\,}} $$ . We derive fixed-parameter tractable ( $${{\,\mathrm{\textsf{FPT}}\,}}$$ ) algorithms for all three problems with $$(k,d)$$ as the parameter, and present a $$poly(k,d)$$ -sized kernel for Weighted Diverse Bases.},
  archive      = {J_MP},
  author       = {Fomin, Fedor V. and Golovach, Petr A. and Panolan, Fahad and Philip, Geevarghese and Saurabh, Saket},
  doi          = {10.1007/s10107-023-01959-z},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {415-447},
  shortjournal = {Math. Program.},
  title        = {Diverse collections in matroids and graphs},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling combinatorial disjunctive constraints via junction
trees. <em>MP</em>, <em>204</em>(1), 385–413. (<a
href="https://doi.org/10.1007/s10107-023-01955-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce techniques to build small ideal mixed-integer programming (MIP) formulations of combinatorial disjunctive constraints (CDCs) via the independent branching scheme. We present a novel pairwise IB-representable class of CDCs, CDCs admitting junction trees, and provide a combinatorial procedure to build MIP formulations for those constraints. Generalized special ordered sets ( $${\text {SOS}}k$$ ) can be modeled by CDCs admitting junction trees and we also obtain MIP formulations of $${\text {SOS}}k$$ . Furthermore, we provide a novel ideal extended formulation of any combinatorial disjunctive constraints with fewer auxiliary binary variables with an application in planar obstacle avoidance.},
  archive      = {J_MP},
  author       = {Lyu, Bochuan and Hicks, Illya V. and Huchette, Joey},
  doi          = {10.1007/s10107-023-01955-3},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {385-413},
  shortjournal = {Math. Program.},
  title        = {Modeling combinatorial disjunctive constraints via junction trees},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Geometry of vectorial martingale optimal transportations and
duality. <em>MP</em>, <em>204</em>(1), 349–383. (<a
href="https://doi.org/10.1007/s10107-023-01954-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of Optimal Transport and Martingale Optimal Transport (MOT) were inspired by problems in economics and finance and have flourished over the past decades, making significant advances in theory and practice. MOT considers the problem of pricing and hedging of a financial instrument, referred to as an option, assuming its payoff depends on a single asset price. In this paper we introduce Vectorial Martingale Optimal Transport (VMOT) problem, which considers the more general and realistic situation in which the option payoff depends on multiple asset prices. We address this problem of pricing and hedging given market information—described by vectorial marginal distributions of underlying asset prices—which is an intimately relevant setup in the robust financial framework. We establish that the VMOT problem, as an infinite-dimensional linear programming, admits an optimizer for its dual program. Such existence result of dual optimizers is significant for several reasons: the dual optimizers describe how a person who is liable for an option payoff can formulate optimal hedging portfolios, and more importantly, they can provide crucial information on the geometry of primal optimizers, i.e. the VMOTs. As an illustration, we show that multiple martingales given marginals must exhibit an extremal conditional correlation structure whenever they jointly optimize the expectation of distance-type cost functions.},
  archive      = {J_MP},
  author       = {Lim, Tongseok},
  doi          = {10.1007/s10107-023-01954-4},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {349-383},
  shortjournal = {Math. Program.},
  title        = {Geometry of vectorial martingale optimal transportations and duality},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving graph equipartition SDPs on an algebraic variety.
<em>MP</em>, <em>204</em>(1), 299–347. (<a
href="https://doi.org/10.1007/s10107-023-01952-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on using the low-rank factorization approach to solve the SDP relaxation of a graph equipartition problem, which involves an additional spectral upper bound over the traditional linear SDP. We discuss the equivalence between the decomposed problem and the original SDP problem. We also derive a sufficient condition, under which a second order stationary point of the non-convex problem is also a global minimum. Moreover, the constraints of the non-convex problem involve an algebraic variety with conducive geometric properties which we analyse. We also develop a method to escape from a non-optimal singular point on this variety. This allows us to use Riemannian optimization techniques to solve the SDP problem very efficiently with certified global optimality.},
  archive      = {J_MP},
  author       = {Tang, Tianyun and Toh, Kim-Chuan},
  doi          = {10.1007/s10107-023-01952-6},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {299-347},
  shortjournal = {Math. Program.},
  title        = {Solving graph equipartition SDPs on an algebraic variety},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal algorithms for differentially private stochastic
monotone variational inequalities and saddle-point problems.
<em>MP</em>, <em>204</em>(1), 255–297. (<a
href="https://doi.org/10.1007/s10107-023-01953-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we conduct the first systematic study of stochastic variational inequality (SVI) and stochastic saddle point (SSP) problems under the constraint of differential privacy (DP). We propose two algorithms: Noisy Stochastic Extragradient (NSEG) and Noisy Inexact Stochastic Proximal Point (NISPP). We show that a stochastic approximation variant of these algorithms attains risk bounds vanishing as a function of the dataset size, with respect to the strong gap function; and a sampling with replacement variant achieves optimal risk bounds with respect to a weak gap function. We also show lower bounds of the same order on weak gap function. Hence, our algorithms are optimal. Key to our analysis is the investigation of algorithmic stability bounds, both of which are new even in the nonprivate case. The dependence of the running time of the sampling with replacement algorithms, with respect to the dataset size n, is $$n^2$$ for NSEG and $${\widetilde{O}}(n^{3/2})$$ for NISPP.},
  archive      = {J_MP},
  author       = {Boob, Digvijay and Guzmán, Cristóbal},
  doi          = {10.1007/s10107-023-01953-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {255-297},
  shortjournal = {Math. Program.},
  title        = {Optimal algorithms for differentially private stochastic monotone variational inequalities and saddle-point problems},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A j-symmetric quasi-newton method for minimax problems.
<em>MP</em>, <em>204</em>(1), 207–254. (<a
href="https://doi.org/10.1007/s10107-023-01957-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimax problems have gained tremendous attentions across the optimization and machine learning community recently. In this paper, we introduce a new quasi-Newton method for the minimax problems, which we call J-symmetric quasi-Newton method. The method is obtained by exploiting the J-symmetric structure of the second-order derivative of the objective function in minimax problem. We show that the Hessian estimation (as well as its inverse) can be updated by a rank-2 operation, and it turns out that the update rule is a natural generalization of the classic Powell symmetric Broyden method from minimization problems to minimax problems. In theory, we show that our proposed quasi-Newton algorithm enjoys local Q-superlinear convergence to a desirable solution under standard regularity conditions. Furthermore, we introduce a trust-region variant of the algorithm that enjoys global R-superlinear convergence. Finally, we present numerical experiments that verify our theory and show the effectiveness of our proposed algorithms compared to Broyden’s method and the extragradient method on three classes of minimax problems.},
  archive      = {J_MP},
  author       = {Asl, Azam and Lu, Haihao and Yang, Jinwen},
  doi          = {10.1007/s10107-023-01957-1},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {207-254},
  shortjournal = {Math. Program.},
  title        = {A J-symmetric quasi-newton method for minimax problems},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scaling-invariant algorithm for linear programming whose
running time depends only on the constraint matrix. <em>MP</em>,
<em>204</em>(1), 135–206. (<a
href="https://doi.org/10.1007/s10107-023-01956-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the breakthrough work of Tardos (Oper Res 34:250–256, 1986) in the bit-complexity model, Vavasis and Ye (Math Program 74(1):79–120, 1996) gave the first exact algorithm for linear programming in the real model of computation with running time depending only on the constraint matrix. For solving a linear program (LP) $$\max \, c^\top x,\, Ax = b,\, x \ge 0,\, A \in \mathbb {R}^{m \times n}$$ , Vavasis and Ye developed a primal-dual interior point method using a ‘layered least squares’ (LLS) step, and showed that $$O(n^{3.5} \log (\bar{\chi }_A+n))$$ iterations suffice to solve (LP) exactly, where $$\bar{\chi }_A$$ is a condition measure controlling the size of solutions to linear systems related to A. Monteiro and Tsuchiya (SIAM J Optim 13(4):1054–1079, 2003), noting that the central path is invariant under rescalings of the columns of A and c, asked whether there exists an LP algorithm depending instead on the measure $$\bar{\chi }^*_A$$ , defined as the minimum $$\bar{\chi }_{AD}$$ value achievable by a column rescaling AD of A, and gave strong evidence that this should be the case. We resolve this open question affirmatively. Our first main contribution is an $$O(m^2 n^2 + n^3)$$ time algorithm which works on the linear matroid of A to compute a nearly optimal diagonal rescaling D satisfying $$\bar{\chi }_{AD} \le n(\bar{\chi }_A^*)^3$$ . This algorithm also allows us to approximate the value of $$\bar{\chi }_A$$ up to a factor $$n (\bar{\chi }_A^*)^2$$ . This result is in surprising contrast to that of Tunçel (Math Program 86(1):219–223, 1999), who showed NP-hardness for approximating $$\bar{\chi }_A$$ to within $$2^{\textrm{poly}(\textrm{rank}(A))}$$ . The key insight for our algorithm is to work with ratios $$g_i/g_j$$ of circuits of A—i.e., minimal linear dependencies $$Ag=0$$ —which allow us to approximate the value of $$\bar{\chi }_A^*$$ by a maximum geometric mean cycle computation in what we call the ‘circuit ratio digraph’ of A. While this resolves Monteiro and Tsuchiya’s question by appropriate preprocessing, it falls short of providing either a truly scaling invariant algorithm or an improvement upon the base LLS analysis. In this vein, as our second main contribution we develop a scaling invariant LLS algorithm, which uses and dynamically maintains improving estimates of the circuit ratio digraph, together with a refined potential function based analysis for LLS algorithms in general. With this analysis, we derive an improved $$O(n^{2.5} \log (n)\log (\bar{\chi }^*_A+n))$$ iteration bound for optimally solving (LP) using our algorithm. The same argument also yields a factor $$n/\log n$$ improvement on the iteration complexity bound of the original Vavasis–Ye algorithm.},
  archive      = {J_MP},
  author       = {Dadush, Daniel and Huiberts, Sophie and Natura, Bento and Végh, László A.},
  doi          = {10.1007/s10107-023-01956-2},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {135-206},
  shortjournal = {Math. Program.},
  title        = {A scaling-invariant algorithm for linear programming whose running time depends only on the constraint matrix},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Recognizing pinch-graphic matroids. <em>MP</em>,
<em>204</em>(1), 113–134. (<a
href="https://doi.org/10.1007/s10107-023-01951-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even-cycle matroids are elementary lifts of graphic matroids. An even-cycle matroid is pinch-graphic if it has a signed-graph representation with a blocking pair. We present a polynomial algorithm to check if an internally 4-connected binary matroid is pinch-graphic. Combining this with a result in Guenin and Heo (Small separations in pinch-graphic matroids. Math Program (2023). https://doi.org/10.1007/s10107-023-01950-8) this allows us to check, in polynomial time, if an arbitrary binary matroid is pinch-graphic.},
  archive      = {J_MP},
  author       = {Guenin, Bertrand and Heo, Cheolwon},
  doi          = {10.1007/s10107-023-01951-7},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {113-134},
  shortjournal = {Math. Program.},
  title        = {Recognizing pinch-graphic matroids},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Small separations in pinch-graphic matroids. <em>MP</em>,
<em>204</em>(1), 81–111. (<a
href="https://doi.org/10.1007/s10107-023-01950-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even-cycle matroids are elementary lifts of graphic matroids. Pinch-graphic matroids are even-cycle matroids that are also elementary projections of graphic matroids. In this paper we analyze the structure of 1-, 2-, and 3-separations in these matroids. As a corollary we obtain a polynomial-time algorithm that reduces the problem of recognizing pinch-graphic matroids to internally 4-connected matroids. Combining this with earlier results (Guenin and Heo in Recognizing even-cycle and even-cut matroids manuscript, 2020; Guenin and Heo in Recognizing pinch-graphic matroids manuscript, 2020) we obtain a polynomial-time algorithm for recognizing even-cycle matroids and we obtain a polynomial-time algorithm for recognizing even-cut matroids.},
  archive      = {J_MP},
  author       = {Guenin, Bertrand and Heo, Cheolwon},
  doi          = {10.1007/s10107-023-01950-8},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {81-111},
  shortjournal = {Math. Program.},
  title        = {Small separations in pinch-graphic matroids},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A combinatorial algorithm for computing the entire sequence
of the maximum degree of minors of a generic partitioned polynomial
matrix with <span class="math display">2 × 2</span> submatrices.
<em>MP</em>, <em>204</em>(1), 27–79. (<a
href="https://doi.org/10.1007/s10107-023-01949-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of computing the entire sequence of the maximum degree of minors of a block-structured symbolic matrix (a generic partitioned polynomial matrix) $$A = (A_{\alpha \beta } x_{\alpha \beta } t^{d_{\alpha \beta }})$$ , where $$A_{\alpha \beta }$$ is a $$2 \times 2$$ matrix over a field $$\textbf{F}$$ , $$x_{\alpha \beta }$$ is an indeterminate, and $$d_{\alpha \beta }$$ is an integer for $$\alpha = 1,2,\dots , \mu $$ and $$\beta = 1,2,\dots ,\nu $$ , and t is an additional indeterminate. This problem can be viewed as an algebraic generalization of the maximum weight bipartite matching problem. The main result of this paper is a combinatorial -time algorithm for computing the entire sequence of the maximum degree of minors of a $$(2 \times 2)$$ -type generic partitioned polynomial matrix of size $$2\mu \times 2\nu $$ . We also present a minimax theorem, which can be used as a good characterization (NP $$\cap $$ co-NP characterization) for the computation of the maximum degree of minors of order k. Our results generalize the classical primal-dual algorithm (the Hungarian method) and minimax formula (Egerváry’s theorem) for the maximum weight bipartite matching problem.},
  archive      = {J_MP},
  author       = {Iwamasa, Yuni},
  doi          = {10.1007/s10107-023-01949-1},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {27-79},
  shortjournal = {Math. Program.},
  title        = {A combinatorial algorithm for computing the entire sequence of the maximum degree of minors of a generic partitioned polynomial matrix with $$2 \times 2$$ submatrices},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient regularization of newton method with bregman
distances. <em>MP</em>, <em>204</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10107-023-01943-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a first second-order scheme based on arbitrary non-Euclidean norms, incorporated by Bregman distances. They are introduced directly in the Newton iterate with regularization parameter proportional to the square root of the norm of the current gradient. For the basic scheme, as applied to the composite convex optimization problem, we establish the global convergence rate of the order $$O(k^{-2})$$ both in terms of the functional residual and in the norm of subgradients. Our main assumption on the smooth part of the objective is Lipschitz continuity of its Hessian. For uniformly convex functions of degree three, we justify global linear rate, and for strongly convex function we prove the local superlinear rate of convergence. Our approach can be seen as a relaxation of the Cubic Regularization of the Newton method (Nesterov and Polyak in Math Program 108(1):177–205, 2006) for convex minimization problems. This relaxation preserves the convergence properties and global complexities of the Cubic Newton in convex case, while the auxiliary subproblem at each iteration is simpler. We equip our method with adaptive search procedure for choosing the regularization parameter. We propose also an accelerated scheme with convergence rate $$O(k^{-3})$$ , where k is the iteration counter.},
  archive      = {J_MP},
  author       = {Doikov, Nikita and Nesterov, Yurii},
  doi          = {10.1007/s10107-023-01943-7},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Math. Program.},
  title        = {Gradient regularization of newton method with bregman distances},
  volume       = {204},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair division of graphs and of tangled cakes. <em>MP</em>,
<em>203</em>(1), 931–975. (<a
href="https://doi.org/10.1007/s10107-023-01945-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fair division has been studied in both continuous and discrete contexts. One strand of the continuous literature seeks to award each agent with a single connected piece—a subinterval. The analogue for the discrete case corresponds to the fair division of a graph, where allocations must be contiguous so that each bundle of vertices is required to induce a connected subgraph. With envy-freeness up to one item (EF1) as the fairness criterion, however, positive results for three or more agents have mostly been limited to traceable graphs. We introduce tangles as a new context for fair division. A tangle is a more complicated cake—a connected topological space constructed by gluing together several copies of the unit interval [0, 1]—and each single tangle $$\mathcal {T}$$ corresponds in a natural way to an infinite topological class $$\mathcal {G}(\mathcal {T})$$ of graphs, linking envy-free fair division of tangles to EFk fair division of graphs. In addition to the unit interval itself, we show that only five other stringable tangles guarantee the existence of envy-free and connected allocations for arbitrarily many agents, with the corresponding topological classes containing only traceable graphs. Any other tangle $$\mathcal {T}$$ has a bound r on the number of agents for which such allocations necessarily exist, and our Negative Transfer Principle then applies to the graphs in $$\mathcal {T}$$ ’s class; for any integer $$k \ge 1$$ , almost all graphs in this class are non-traceable and fail to guarantee EFk contiguous allocations for $$r + 1$$ or more agents, even when very strict requirements are placed on the valuation functions for the agents. With bounds on the number of agents, however, we obtain positive results for some non-stringable classes. An elaboration of Stromquist’s moving knife procedure shows that the non-stringable lips tangle $$\mathcal {L}$$ guarantees envy-free allocations of connected shares for three agents. We then modify the discrete version of Stromquist’s procedure in Bilò et al. (Games Econ Behav 131:197–221, 2022) to show that all graphs in the topological class $$\mathcal {G}(\mathcal {L})$$ (most of which are non-traceable) guarantee EF1 allocations for three agents.},
  archive      = {J_MP},
  author       = {Igarashi, Ayumi and Zwicker, William S.},
  doi          = {10.1007/s10107-023-01945-5},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {931-975},
  shortjournal = {Math. Program.},
  title        = {Fair division of graphs and of tangled cakes},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Truthful facility assignment with resource augmentation: An
exact analysis of serial dictatorship. <em>MP</em>, <em>203</em>(1),
901–930. (<a href="https://doi.org/10.1007/s10107-022-01902-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the truthful facility assignment problem, where a set of agents with private most-preferred points on a metric space have to be assigned to facilities that lie on the metric space, under capacity constraints on the facilities. The goal is to produce such an assignment that minimizes the social cost, i.e., the total distance between the most-preferred points of the agents and their corresponding facilities in the assignment, under the constraint of truthfulness, which ensures that agents do not misreport their most-preferred points. We propose a resource augmentation framework, where a truthful mechanism is evaluated by its worst-case performance on an instance with enhanced facility capacities against the optimal mechanism on the same instance with the original capacities. We study a well-known mechanism, Serial Dictatorship, and provide an exact analysis of its performance. Among other results, we prove that Serial Dictatorship has approximation ratio $$g/(g-2)$$ when the capacities are multiplied by any integer $$g \ge 3$$ . Our results suggest that with a limited augmentation of the resources we can achieve exponential improvements on the performance of the mechanism and in particular, the approximation ratio goes to 1 as the augmentation factor becomes large. We complement our results with bounds on the approximation ratio of Random Serial Dictatorship, the randomized version of Serial Dictatorship, when there is no resource augmentation.},
  archive      = {J_MP},
  author       = {Caragiannis, Ioannis and Filos-Ratsikas, Aris and Frederiksen, Søren Kristoffer Stiil and Hansen, Kristoffer Arnsfelt and Tan, Zihan},
  doi          = {10.1007/s10107-022-01902-8},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {901-930},
  shortjournal = {Math. Program.},
  title        = {Truthful facility assignment with resource augmentation: An exact analysis of serial dictatorship},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Truthful ownership transfer with expert advice. <em>MP</em>,
<em>203</em>(1), 871–900. (<a
href="https://doi.org/10.1007/s10107-022-01834-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a company undergoes a merger or transfers its ownership, the existing governing body has an opinion on which buyer should take over as the new owner. Similar situations occur while assigning the host of big sports tournaments, like the World Cup or the Olympics. In all these settings, the values of the external bidders are as important as the opinions of the internal experts. Motivated by such scenarios, we consider a social welfare maximizing approach to design and analyze truthful mechanisms in hybrid social choice settings, where payments can be imposed to the bidders, but not to the experts. Since this problem is a combination of mechanism design with and without monetary transfers, classical solutions like VCG cannot be applied, making this a novel mechanism design problem. We consider the simple but fundamental scenario with one expert and two bidders, and provide tight approximation guarantees of the optimal social welfare. We distinguish between mechanisms that use ordinal and cardinal information, as well as between mechanisms that base their decisions on one of the two sides (either the bidders or the expert) or both. Our analysis shows that the cardinal setting is quite rich and admits several non-trivial randomized truthful mechanisms, and also allows for closer-to-optimal welfare guarantees.},
  archive      = {J_MP},
  author       = {Caragiannis, Ioannis and Filos-Ratsikas, Aris and Nath, Swaprava and Voudouris, Alexandros A.},
  doi          = {10.1007/s10107-022-01834-3},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {871-900},
  shortjournal = {Math. Program.},
  title        = {Truthful ownership transfer with expert advice},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistent queueing rules. <em>MP</em>, <em>203</em>(1),
857–869. (<a href="https://doi.org/10.1007/s10107-022-01905-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a “queueing problem”, a group of agents are waiting for a service. Each agent incurs a cost of waiting that is proportional to the time they wait. Monetary transfers can take place. We study the subsolutions of the no-envy solution that are anonymous, consistent, conversely consistent, and continuous. We show that there are infinitely many proper consistent subsolutions from the no-envy solution and characterize a class of these solutions on the basis of basic requirements of continuity, anonymity, monotonicity with respect to the budget available, consistency, and the converse of consistency.},
  archive      = {J_MP},
  author       = {Thomson, William and Velez, Rodrigo A.},
  doi          = {10.1007/s10107-022-01905-5},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {857-869},
  shortjournal = {Math. Program.},
  title        = {Consistent queueing rules},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the resolution of cross-liabilities. <em>MP</em>,
<em>203</em>(1), 827–856. (<a
href="https://doi.org/10.1007/s10107-023-01928-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a variety of systems, in particular in a financial system, entities hold liabilities on each other. The reimbursement abilities are intertwined, thereby potentially generating coordination failures and cascades of defaults calling for orderly resolution. With a single indebted firm, a bankruptcy law organizes such an orderly resolution. With cross-liabilities, a resolution rule should be defined at the system level to account for all those affected, directly or indirectly. This paper investigates such rules assuming their primary goal is to avoid defaults on creditors external to the system, say banks’ defaults on customers’ deposits. I define and characterize the constrained-proportional rule building on two approaches: the minimization of an inequality measure on the reimbursements (made and received) and the axiomatization through desirable properties.},
  archive      = {J_MP},
  author       = {Demange, Gabrielle},
  doi          = {10.1007/s10107-023-01928-6},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {827-856},
  shortjournal = {Math. Program.},
  title        = {On the resolution of cross-liabilities},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Characterization of TU games with stable cores by nested
balancedness. <em>MP</em>, <em>203</em>(1), 801–826. (<a
href="https://doi.org/10.1007/s10107-021-01716-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A balanced transferable utility game (N, v) has a stable core if its core is externally stable, that is, if each imputation that is not in the core is dominated by some core element. Given two payoff allocations x and y, we say that x outvotes y via some coalition S of a feasible set if x dominates y via S and x allocates at least v(T) to any feasible T that is not contained in S. It turns out that outvoting is transitive and the set M of maximal elements with respect to outvoting coincides with the core if and only if the game has a stable core. By applying the duality theorem of linear programming twice, it is shown that M coincides with the core if and only if a certain nested balancedness condition holds. Thus, it can be checked in finitely many steps whether a balanced game has a stable core. We say that the game has a super-stable core if each payoff vector that allocates less than v(S) to some coalition S is dominated by some core element and prove that core super-stability is equivalent to vital extendability, requiring that each vital coalition is extendable.},
  archive      = {J_MP},
  author       = {Grabisch, Michel and Sudhölter, Peter},
  doi          = {10.1007/s10107-021-01716-0},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {801-826},
  shortjournal = {Math. Program.},
  title        = {Characterization of TU games with stable cores by nested balancedness},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stackelberg pricing games with congestion effects.
<em>MP</em>, <em>203</em>(1), 763–799. (<a
href="https://doi.org/10.1007/s10107-021-01672-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a Stackelberg game with multiple leaders and a continuum of followers that are coupled via congestion effects. The followers’ problem constitutes a nonatomic congestion game, where a population of infinitesimal players is given and each player chooses a resource. Each resource has a linear cost function which depends on the congestion of this resource. The leaders of the Stackelberg game each control a resource and determine a price per unit as well as a service capacity for the resource influencing the slope of the linear congestion cost function. As our main result, we establish existence of pure-strategy Nash–Stackelberg equilibria for this multi-leader Stackelberg game. The existence result requires a completely new proof approach compared to previous approaches, since the leaders’ objective functions are discontinuous in our game. As a consequence, best responses of leaders do not always exist, and thus standard fixed-point arguments á la Kakutani (Duke Math J 8(3):457–458, 1941) are not directly applicable. We show that the game is C-secure (a concept introduced by Reny (Econometrica 67(5):1029–1056, 1999) and refined by McLennan et al. (Econometrica 79(5):1643–1664, 2011), which leads to the existence of an equilibrium. We furthermore show that the equilibrium is essentially unique, and analyze its efficiency compared to a social optimum. We prove that the worst-case quality is unbounded. For identical leaders, we derive a closed-form expression for the efficiency of the equilibrium.},
  archive      = {J_MP},
  author       = {Harks, Tobias and Schedel, Anja},
  doi          = {10.1007/s10107-021-01672-9},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {763-799},
  shortjournal = {Math. Program.},
  title        = {Stackelberg pricing games with congestion effects},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Absorption paths and equilibria in quitting games.
<em>MP</em>, <em>203</em>(1), 735–762. (<a
href="https://doi.org/10.1007/s10107-022-01807-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study quitting games and introduce an alternative notion of strategy profiles—absorption paths. An absorption path is parametrized by the total probability of absorption in past play rather than by time, and it accommodates both discrete-time aspects and continuous-time aspects. We then define the concept of sequentially 0-perfect absorption paths, which are shown to be limits of $$\varepsilon $$ -equilibrium strategy profiles as $$\varepsilon $$ goes to 0. We establish that all quitting games that do not have simple equilibria (that is, an equilibrium where the game terminates in the first period or one where the game never terminates) have a sequentially 0-perfect absorption path. Finally, we prove the existence of sequentially 0-perfect absorption paths in a new class of quitting games.},
  archive      = {J_MP},
  author       = {Ashkenazi-Golan, Galit and Krasikov, Ilia and Rainer, Catherine and Solan, Eilon},
  doi          = {10.1007/s10107-022-01807-6},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {735-762},
  shortjournal = {Math. Program.},
  title        = {Absorption paths and equilibria in quitting games},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A finite characterization of perfect equilibria.
<em>MP</em>, <em>203</em>(1), 727–734. (<a
href="https://doi.org/10.1007/s10107-021-01746-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Govindan and Klumpp [7] provided a characterization of perfect equilibria using Lexicographic Probability Systems (LPSs). Their characterization was essentially finite in that they showed that there exists a finite bound on the number of levels in the LPS, but they did not compute it explicitly. In this note, we draw on two recent developments in Real Algebraic Geometry to obtain a formula for this bound.},
  archive      = {J_MP},
  author       = {Callejas, Ivonne and Govindan, Srihari and Pahl, Lucas},
  doi          = {10.1007/s10107-021-01746-8},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {727-734},
  shortjournal = {Math. Program.},
  title        = {A finite characterization of perfect equilibria},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Utility/privacy trade-off as regularized optimal transport.
<em>MP</em>, <em>203</em>(1), 703–726. (<a
href="https://doi.org/10.1007/s10107-022-01811-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic information is valuable either by remaining private (for instance if it is sensitive) or, on the other hand, by being used publicly to increase some utility. These two objectives are antagonistic and leaking this information by taking full advantage of it might be more rewarding than concealing it. Unlike classical solutions that focus on the first point, we consider instead agents that optimize a natural trade-off between both objectives. We formalize this as an optimization problem where the objective mapping is regularized by the amount of information revealed to the adversary (measured as a divergence between the prior and posterior on the private knowledge). Quite surprisingly, when combined with the entropic regularization, the Sinkhorn loss naturally emerges in the optimization objective, making it efficiently solvable via better adapted optimization schemes. We empirically compare these different techniques on a toy example and apply them to preserve some privacy in online repeated auctions.},
  archive      = {J_MP},
  author       = {Boursier, Etienne and Perchet, Vianney},
  doi          = {10.1007/s10107-022-01811-w},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {703-726},
  shortjournal = {Math. Program.},
  title        = {Utility/privacy trade-off as regularized optimal transport},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The core of a transferable utility game as the solution to a
public good market demand problem. <em>MP</em>, <em>203</em>(1),
687–702. (<a href="https://doi.org/10.1007/s10107-021-01729-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core of a monotonic transferable utility (TU) game is shown to be the set of prices that incentivize each individual to demand the grand coalition in a market demand problem in which the goods being demanded are coalitions viewed as excluable public goods. It is also shown that the core is the intersection of superdifferentials evaluated at the grand coalition of the covers of person-specific TU games derived from the original game. These characterizations of the core demonstrate how a market demand approach to coalition formation in the spirit of Baldwin and Klemperer (Tropical geometry to analyze demand, University of Oxford, 2014; Econometrica, 87: 867–932, 2019) is related to the approach to the core using the cover of a TU game and it superdifferential at the grand coalition developed by Shapley and Shubik (J Econ Theory, 1: 9–25, 1969), Aubin (Math Oper Res, 6:1–13, 1981), and Danilov and Koshevoy (J Math Anal Appl, 247: 1–14, 2000).},
  archive      = {J_MP},
  author       = {Edelman, Paul H. and Van der Linden, Martin and Weymark, John A.},
  doi          = {10.1007/s10107-021-01729-9},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {687-702},
  shortjournal = {Math. Program.},
  title        = {The core of a transferable utility game as the solution to a public good market demand problem},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). No-regret algorithms in on-line learning, games and convex
optimization. <em>MP</em>, <em>203</em>(1), 645–686. (<a
href="https://doi.org/10.1007/s10107-023-01927-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this article is to underline the links between some no-regret algorithms used in on-line learning, games and convex optimization and to compare the continuous and discrete time versions.},
  archive      = {J_MP},
  author       = {Sorin, Sylvain},
  doi          = {10.1007/s10107-023-01927-7},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {645-686},
  shortjournal = {Math. Program.},
  title        = {No-regret algorithms in on-line learning, games and convex optimization},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Strong substitutes: Structural properties, and a new
algorithm for competitive equilibrium prices. <em>MP</em>,
<em>203</em>(1), 611–643. (<a
href="https://doi.org/10.1007/s10107-022-01792-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show the strong substitutes product-mix auction bidding language provides an intuitive and geometric interpretation of strong substitutes as Minkowski differences between sets that are easy to identify. We prove that competitive equilibrium prices for agents with strong substitutes preferences can be computed by minimizing the difference between two linear programs for the positive and the negative bids with suitably relaxed resource constraints. This also leads to a new algorithm for computing competitive equilibrium prices which is competitive with standard steepest descent algorithms in extensive experiments.},
  archive      = {J_MP},
  author       = {Baldwin, Elizabeth and Bichler, Martin and Fichtl, Maximilian and Klemperer, Paul},
  doi          = {10.1007/s10107-022-01792-w},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {611-643},
  shortjournal = {Math. Program.},
  title        = {Strong substitutes: Structural properties, and a new algorithm for competitive equilibrium prices},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified stochastic approximation framework for learning in
games. <em>MP</em>, <em>203</em>(1), 559–609. (<a
href="https://doi.org/10.1007/s10107-023-02001-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a flexible stochastic approximation framework for analyzing the long-run behavior of learning in games (both continuous and finite). The proposed analysis template incorporates a wide array of popular learning algorithms, including gradient-based methods, the exponential/multiplicative weights algorithm for learning in finite games, optimistic and bandit variants of the above, etc. In addition to providing an integrated view of these algorithms, our framework further allows us to obtain several new convergence results, both asymptotic and in finite time, in both continuous and finite games. Specifically, we provide a range of criteria for identifying classes of Nash equilibria and sets of action profiles that are attracting with high probability, and we also introduce the notion of coherence, a game-theoretic property that includes strict and sharp equilibria, and which leads to convergence in finite time. Importantly, our analysis applies to both oracle-based and bandit, payoff-based methods—that is, when players only observe their realized payoffs.},
  archive      = {J_MP},
  author       = {Mertikopoulos, Panayotis and Hsieh, Ya-Ping and Cevher, Volkan},
  doi          = {10.1007/s10107-023-02001-y},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {559-609},
  shortjournal = {Math. Program.},
  title        = {A unified stochastic approximation framework for learning in games},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The price of anarchy in routing games as a function of the
demand. <em>MP</em>, <em>203</em>(1), 531–558. (<a
href="https://doi.org/10.1007/s10107-021-01701-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The price of anarchy has become a standard measure of the efficiency of equilibria in games. Most of the literature in this area has focused on establishing worst-case bounds for specific classes of games, such as routing games or more general congestion games. Recently, the price of anarchy in routing games has been studied as a function of the traffic demand, providing asymptotic results in light and heavy traffic. The aim of this paper is to study the price of anarchy in nonatomic routing games in the intermediate region of the demand. To achieve this goal, we begin by establishing some smoothness properties of Wardrop equilibria and social optima for general smooth costs. In the case of affine costs we show that the equilibrium is piecewise linear, with break points at the demand levels at which the set of active paths changes. We prove that the number of such break points is finite, although it can be exponential in the size of the network. Exploiting a scaling law between the equilibrium and the social optimum, we derive a similar behavior for the optimal flows. We then prove that in any interval between break points the price of anarchy is smooth and it is either monotone (decreasing or increasing) over the full interval, or it decreases up to a certain minimum point in the interior of the interval and increases afterwards. We deduce that for affine costs the maximum of the price of anarchy can only occur at the break points. For general costs we provide counterexamples showing that the set of break points is not always finite.},
  archive      = {J_MP},
  author       = {Cominetti, Roberto and Dose, Valerio and Scarsini, Marco},
  doi          = {10.1007/s10107-021-01701-7},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {531-558},
  shortjournal = {Math. Program.},
  title        = {The price of anarchy in routing games as a function of the demand},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The price of anarchy in series-parallel network congestion
games. <em>MP</em>, <em>203</em>(1), 499–529. (<a
href="https://doi.org/10.1007/s10107-022-01803-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the inefficiency of pure Nash equilibria in symmetric network congestion games defined over series-parallel networks with affine edge delays. For arbitrary networks, Correa (Math Oper Res 44(4):1286–1303, 2019) proved a tight upper bound of 5/2 on the PoA. On the other hand, for extension-parallel networks, a subclass of series-parallel networks, Fotakis (Theory Comput Syst 47:113–136, 2010) proved that the PoA is 4/3. He also showed that this bound is not valid for series-parallel networks by providing a simple construction with PoA 15/11. Our main result is that for series-parallel networks the PoA cannot be larger than 2, which improves on the bound of 5/2 valid for arbitrary networks. We also construct a class of instances with a lower bound on the PoA that asymptotically approaches 27/19, which improves on the lower bound of 15/11.},
  archive      = {J_MP},
  author       = {Hao, Bainian and Michini, Carla},
  doi          = {10.1007/s10107-022-01803-w},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {499-529},
  shortjournal = {Math. Program.},
  title        = {The price of anarchy in series-parallel network congestion games},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Splitting games over finite sets. <em>MP</em>,
<em>203</em>(1), 477–498. (<a
href="https://doi.org/10.1007/s10107-022-01806-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies zero-sum splitting games with finite sets of states. Players dynamically choose a pair of martingales $$\{p_t,q_t\}_t$$ , in order to control a terminal payoff $$u(p_\infty ,q_\infty )$$ . A first part introduces the notion of “Mertens–Zamir transform&quot; of a real-valued matrix and use it to approximate the solution of the Mertens–Zamir system for continuous functions on the square $$[0,1]^2$$ . A second part considers the general case of finite splitting games with arbitrary correspondences containing the Dirac mass on the current state: building on Laraki and Renault (Math Oper Res 45:1237–1257, 2020), we show that the value exists by constructing non Markovian $$\varepsilon $$ -optimal strategies and we characterize it as the unique concave-convex function satisfying two new conditions.},
  archive      = {J_MP},
  author       = {Koessler, Frédéric and Laclau, Marie and Renault, Jérôme and Tomala, Tristan},
  doi          = {10.1007/s10107-022-01806-7},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {477-498},
  shortjournal = {Math. Program.},
  title        = {Splitting games over finite sets},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: The computation of pairwise stable networks.
<em>MP</em>, <em>203</em>(1), 475–476. (<a
href="https://doi.org/10.1007/s10107-022-01814-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Herings, P. Jean-Jacques and Zhan, Yang},
  doi          = {10.1007/s10107-022-01814-7},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {475-476},
  shortjournal = {Math. Program.},
  title        = {Correction to: The computation of pairwise stable networks},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). The computation of pairwise stable networks. <em>MP</em>,
<em>203</em>(1), 443–473. (<a
href="https://doi.org/10.1007/s10107-022-01791-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important stability concepts for network formation is pairwise stability. We develop a homotopy algorithm that is effective in computing pairwise stable networks for a generic network formation problem. To do so, we reformulate the concept of pairwise stability as a Nash equilibrium of a non-cooperative game played by the links in the network and adapt the linear tracing procedure for non-cooperative games to the network formation problem. As a by-product of our main result, we obtain that the number of pairwise stable networks is generically odd. We apply the algorithm to the connections model and obtain a number of novel insights.},
  archive      = {J_MP},
  author       = {Herings, P. Jean-Jacques and Zhan, Yang},
  doi          = {10.1007/s10107-022-01791-x},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {443-473},
  shortjournal = {Math. Program.},
  title        = {The computation of pairwise stable networks},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the minimum <span
class="math display"><em>s</em> − <em>t</em></span> cut problem with
budget constraints. <em>MP</em>, <em>203</em>(1), 421–442. (<a
href="https://doi.org/10.1007/s10107-023-01987-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider in this paper the budgeted minimum $$s-t$$ cut problem. Suppose that we are given a directed graph $$G=(V,A)$$ with two distinguished nodes s and t, k non-negative cost functions $$c^1,\ldots ,c^k:A \rightarrow \mathbb {Z}_+$$ , and $$k-1$$ budget bounds $$b_1, \ldots ,b_{k-1}$$ . The goal is to find a $$s-t$$ cut C satisfying the budget constraints $$c^h(C) \leqslant b_h$$ , for $$h = 1,\ldots ,k-1$$ , and whose cost $$c^k(C)$$ is minimum. In this paper we discuss the linear relaxation of the problem and introduce a strict partial ordering on its solutions. We give a necessary and sufficient condition for which it has an integral optimal minimal (with respect to this ordering) basic solution. We also show that recognizing whether this is the case is NP-hard.},
  archive      = {J_MP},
  author       = {Aissi, Hassene and Mahjoub, A. Ridha},
  doi          = {10.1007/s10107-023-01987-9},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {421-442},
  shortjournal = {Math. Program.},
  title        = {On the minimum $$s-t$$ cut problem with budget constraints},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graphs with <span
class="math display"><em>G</em><sup><em>p</em></sup></span> -connected
medians. <em>MP</em>, <em>203</em>(1), 369–420. (<a
href="https://doi.org/10.1007/s10107-023-01939-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The median of a graph G with weighted vertices is the set of all vertices x minimizing the sum of weighted distances from x to the vertices of G. For any integer $$p\ge 2$$ , we characterize the graphs in which, with respect to any non-negative weights, median sets always induce connected subgraphs in the pth power $$G^p$$ of G. This extends some characterizations of graphs with connected medians (case $$p=1$$ ) provided by Bandelt and Chepoi (SIAM J Discrete Math 15(2):268–282, 2002. https://doi.org/10.1137/S089548019936360X ). The characteristic conditions can be tested in polynomial time for any p. We also show that several important classes of graphs in metric graph theory, including bridged graphs (and thus chordal graphs), graphs with convex balls, bucolic graphs, and bipartite absolute retracts, have $$G^2$$ -connected medians. Extending the result of Bandelt and Chepoi that basis graphs of matroids are graphs with connected medians, we characterize the isometric subgraphs of Johnson graphs and of halved-cubes with connected medians.},
  archive      = {J_MP},
  author       = {Bénéteau, Laurine and Chalopin, Jérémie and Chepoi, Victor and Vaxès, Yann},
  doi          = {10.1007/s10107-023-01939-3},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {369-420},
  shortjournal = {Math. Program.},
  title        = {Graphs with $$G^p$$ -connected medians},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying optimal strategies in kidney exchange games is
<span
class="math display"><em>𝛴</em><sub>2</sub><sup><em>p</em></sup></span>
-complete. <em>MP</em>, <em>203</em>(1), 347–368. (<a
href="https://doi.org/10.1007/s10107-021-01748-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Kidney Exchange Games, agents (e.g. hospitals or national organizations) have control over a number of incompatible recipient-donor pairs whose recipients are in need of a transplant. Each agent has the opportunity to join a collaborative effort which aims to maximize the total number of transplants that can be realized. However, the individual agent is only interested in maximizing the number of transplants within the set of recipients under its control. Then, the question becomes: which recipient-donor pairs to submit to the collaborative effort? We model this situation by introducing the Stackelberg Kidney Exchange Game, a game where an agent, having perfect information, needs to identify a strategy, i.e., to decide which recipient-donor pairs to submit. We show that even in this simplified setting, identifying an optimal strategy is $$\varSigma _2^p$$ -complete, whenever we allow exchanges involving at most a fixed number $$K \ge 3$$ pairs. However, when we restrict ourselves to pairwise exchanges only, the problem becomes solvable in polynomial time.},
  archive      = {J_MP},
  author       = {Smeulders, B. and Blom, D. A. M. P. and Spieksma, F. C. R.},
  doi          = {10.1007/s10107-021-01748-6},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {347-368},
  shortjournal = {Math. Program.},
  title        = {Identifying optimal strategies in kidney exchange games is $$\varSigma _2^p$$ -complete},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate and strategyproof maximin share allocation of
chores with ordinal preferences. <em>MP</em>, <em>203</em>(1), 319–345.
(<a href="https://doi.org/10.1007/s10107-022-01855-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the work on maximin share (MMS) fair allocation of m indivisible chores to n agents using only their ordinal preferences, from both algorithmic and mechanism design perspectives. The previous best-known approximation ratio using ordinal preferences is $$2-1/n$$ by Aziz et al. [AAAI 2017]. We improve this result by giving a deterministic 5/3-approximation algorithm that determines an allocation sequence of agents, according to which items are allocated one by one. By a tighter analysis, we show that for $$n=2$$ and 3, our algorithm achieves better approximation ratios, and is actually optimal. We also consider the setting with strategic agents, where agents may misreport their preferences to manipulate the outcome. We first provide a strategyproof $$O(\log (m/n))$$ -approximation consecutive picking algorithm, and then improve the approximation ratio to $$O(\sqrt{\log n})$$ by a randomized algorithm. Both algorithms only use the ordinal preferences of agents. Our results uncover some interesting contrasts between the approximation ratios achieved for chores versus goods.},
  archive      = {J_MP},
  author       = {Aziz, Haris and Li, Bo and Wu, Xiaowei},
  doi          = {10.1007/s10107-022-01855-y},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {319-345},
  shortjournal = {Math. Program.},
  title        = {Approximate and strategyproof maximin share allocation of chores with ordinal preferences},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness over time in dynamic resource allocation with an
application in healthcare. <em>MP</em>, <em>203</em>(1), 285–318. (<a
href="https://doi.org/10.1007/s10107-022-01904-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision making problems are typically concerned with maximizing efficiency. In contrast, we address problems where there are multiple stakeholders and a centralized decision maker who is obliged to decide in a fair manner. Different decisions give different utility to each stakeholder. In cases where these decisions are made repeatedly, we provide efficient mathematical programming formulations to identify both the maximum fairness possible and the decisions that improve fairness over time, for reasonable metrics of fairness. We apply this framework to the problem of ambulance allocation, where decisions in consecutive rounds are constrained. With this additional complexity, we prove structural results on identifying fair feasible allocation policies and provide a hybrid algorithm with column generation and constraint programming-based solution techniques for this class of problems. Computational experiments show that our method can solve these problems orders of magnitude faster than a naive approach.},
  archive      = {J_MP},
  author       = {Lodi, Andrea and Olivier, Philippe and Pesant, Gilles and Sankaranarayanan, Sriram},
  doi          = {10.1007/s10107-022-01904-6},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {285-318},
  shortjournal = {Math. Program.},
  title        = {Fairness over time in dynamic resource allocation with an application in healthcare},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How many matchings cover the nodes of a graph? <em>MP</em>,
<em>203</em>(1), 271–284. (<a
href="https://doi.org/10.1007/s10107-022-01804-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected graph, are there k matchings whose union covers all of its nodes, that is, a matching-k-cover? When $$k=1$$ , the problem is equivalent to the existence of a perfect matching for which Tutte’s celebrated matching theorem (J. Lon. Math. Soc., 1947) provides a ‘good’ characterization. We prove here, when k is greater than one, a ‘good’ characterization à la Kőnig: for $$k\ge 2$$ , there exist k matchings covering every node if and only if for every stable set S, we have $$|S|\le k\cdot |N(S)|$$ . Moreover, somewhat surprisingly, we use only techniques from bipartite matching in the proof, through a simple, polynomial algorithm. A different approach to matching-k-covers has been previously suggested by Wang et al. (Math. Prog., 2014), relying on general matching and using matroid union for matching-matroids, or the Edmonds-Gallai structure theorem. Our approach provides a simpler polynomial algorithm together with an elegant certificate of non-existence when appropriate. Further results, generalizations and interconnections between several problems are then deduced as consequences of the new minimax theorem, with surprisingly simple proofs (again using only the level of difficulty of bipartite matchings). One of the equivalent formulations leads to a solution of weighted minimization for non-negative edge-weights, while the edge-cardinality maximization of matching-2-covers turns out to be already NP-hard. We have arrived at this problem as the line graph special case of a model arising for manufacturing integrated circuits with the technology called ‘Directed Self Assembly’.},
  archive      = {J_MP},
  author       = {Ferhat, Dehia Ait and Király, Zoltán and Sebő, András and Stauffer, Gautier},
  doi          = {10.1007/s10107-022-01804-9},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {271-284},
  shortjournal = {Math. Program.},
  title        = {How many matchings cover the nodes of a graph?},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cutoff stability under distributional constraints with an
application to summer internship matching. <em>MP</em>, <em>203</em>(1),
247–269. (<a href="https://doi.org/10.1007/s10107-022-01917-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new two-sided stable matching problem that describes the summer internship matching practice of an Australian university. The model is a case between two models of Kamada and Kojima on matchings with distributional constraints. We study three solution concepts, the strong and weak stability concepts proposed by Kamada and Kojima, and a new one in between the two, called cutoff stability. Kamada and Kojima showed that a strongly stable matching may not exist in their most restricted model with disjoint regional quotas. Our first result is that checking its existence is NP-hard. We then show that a cutoff stable matching exists not just for the summer internship problem but also for the general matching model with arbitrary heredity constraints. We present an algorithm to compute a cutoff stable matching and show that it runs in polynomial time in our special case of summer internship model. However, we also show that finding a maximum size cutoff stable matching is NP-hard, but we provide a Mixed Integer Linear Program formulation for this optimisation problem.},
  archive      = {J_MP},
  author       = {Aziz, Haris and Baychkov, Anton and Biró, Péter},
  doi          = {10.1007/s10107-022-01917-1},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {247-269},
  shortjournal = {Math. Program.},
  title        = {Cutoff stability under distributional constraints with an application to summer internship matching},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Why webster? <em>MP</em>, <em>203</em>(1), 239–246. (<a
href="https://doi.org/10.1007/s10107-021-01637-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several different arguments support the use of Webster’s method when seats in a parliament are to be apportioned proportionally according to populations. This note—instigated by a new property—summarizes the reasons.},
  archive      = {J_MP},
  author       = {Balinski, Michel and Ramírez, Victoriano},
  doi          = {10.1007/s10107-021-01637-y},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {239-246},
  shortjournal = {Math. Program.},
  title        = {Why webster?},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New characterizations of strategy-proofness under
single-peakedness. <em>MP</em>, <em>203</em>(1), 207–238. (<a
href="https://doi.org/10.1007/s10107-023-02010-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide novel representations of strategy-proof voting rules applicable when voters have uni-dimensional single-peaked preferences. In particular, we introduce a ‘grading curve’ representation which is particularly useful when introducing variable electorates. Our analysis recovers, links and unifies existing results in the literature, and provides new characterizations when strategy-proofness is combined with other desirable properties such as ordinality, participation, consistency, and proportionality. Finally, the new representations are used to compute the strategy-proof methods that maximize the ex-ante social welfare for the $$L_2$$ -norm and a uniform prior. The resulting strategy-proof welfare maximizer is the linear median (or ‘uniform median’), that we also characterize as the unique proportional strategy-proof voting rule.},
  archive      = {J_MP},
  author       = {Jennings, Andrew B. and Laraki, Rida and Puppe, Clemens and Varloot, Estelle M.},
  doi          = {10.1007/s10107-023-02010-x},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {207-238},
  shortjournal = {Math. Program.},
  title        = {New characterizations of strategy-proofness under single-peakedness},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simple and fast linear-time algorithm for divisor methods
of apportionment. <em>MP</em>, <em>203</em>(1), 187–205. (<a
href="https://doi.org/10.1007/s10107-023-01929-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proportional apportionment is the problem of assigning seats to states (resp. parties) according to their relative share of the population (resp. votes), a field heavily influenced by the early work of Michel Balinski, not least his influential 1982 book with Peyton Young (Fair representation, 2nd edn. Brookings Institution Press, Washington, D.C., 2001). In this article, we consider the computational cost of divisor methods (also known as highest averages methods), the de-facto standard solution that is used in many countries. We show that a simple linear-time algorithm can exactly simulate all instances of the family of divisor methods of apportionment by reducing the problem to a single call to a selection algorithm. All previously published solutions were iterative methods that either offer no linear-time guarantee in the worst case or require a complex update step that suffers from numerical instability.},
  archive      = {J_MP},
  author       = {Reitzig, Raphael and Wild, Sebastian},
  doi          = {10.1007/s10107-023-01929-5},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {187-205},
  shortjournal = {Math. Program.},
  title        = {A simple and fast linear-time algorithm for divisor methods of apportionment},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Note on axiomatic properties of apportionment methods for
proportional representation systems. <em>MP</em>, <em>203</em>(1),
169–185. (<a href="https://doi.org/10.1007/s10107-022-01835-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Apportionment methods are used in proportional representation systems for the apportionment of parliamentary seats among political parties proportionately to their vote counts, or for the allocation of parliamentary seats between geographical districts proportionately to their population figures. From an axiomatic viewpoint apportionment methods ought to satisfy six basic principles: anonymity, balancedness, concordance, decency, exactness, and fairness. It is well-known that the first two principles are implied by the last four. In this note it is shown that the last four principles are logically independent of each other.},
  archive      = {J_MP},
  author       = {Palomares, Antonio and Pukelsheim, Friedrich and Ramírez, Victoriano},
  doi          = {10.1007/s10107-022-01835-2},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {169-185},
  shortjournal = {Math. Program.},
  title        = {Note on axiomatic properties of apportionment methods for proportional representation systems},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Apportionment with parity constraints. <em>MP</em>,
<em>203</em>(1), 135–168. (<a
href="https://doi.org/10.1007/s10107-022-01918-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the classic apportionment problem, the goal is to decide how many seats of a parliament should be allocated to each party as a result of an election. The divisor methods solve this problem by defining a notion of proportionality guided by some rounding rule. Motivated by recent challenges in the context of electoral apportionment, we consider the question of how to allocate the seats of a parliament under parity constraints between candidate types (e.g., an equal number of men and women elected) while at the same time satisfying party proportionality. We study two different approaches to solve this question. We first provide a theoretical analysis of a recently devised mechanism based on a greedy approach. We then propose and analyze a mechanism that follows the idea of biproportionality introduced by Balinski and Demange. In contrast with the classic biproportional method by Balinski and Demange, this mechanism is ruled by two levels of proportionality: Proportionality is satisfied at the level of parties by means of a divisor method, and then biproportionality is used to decide the number of candidates allocated to each type and party. A typical benchmark used in the context of two-dimensional apportionment is the fair share (a.k.a matrix scaling), which corresponds to an ideal fractional biproportional solution. We provide lower bounds on the distance between these two types of solutions, and we explore their consequences in the context of two-dimensional apportionment.},
  archive      = {J_MP},
  author       = {Mathieu, Claire and Verdugo, Victor},
  doi          = {10.1007/s10107-022-01918-0},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {135-168},
  shortjournal = {Math. Program.},
  title        = {Apportionment with parity constraints},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The maximin support method: An extension of the d’hondt
method to approval-based multiwinner elections. <em>MP</em>,
<em>203</em>(1), 107–134. (<a
href="https://doi.org/10.1007/s10107-022-01805-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the maximin support method, a novel extension of the D’Hondt apportionment method to approval-based multiwinner elections. The maximin support method is a sequential procedure that aims to maximize the voter support of the least supported elected candidate. It can be computed efficiently and satisfies (adjusted versions of) the main properties of the original D’Hondt method: house monotonicity, population monotonicity, and proportional representation. We also establish a close relationship between the maximin support method and alternative D’Hondt extensions due to Phragmén.},
  archive      = {J_MP},
  author       = {Sánchez-Fernández, Luis and Fernández-García, Norberto and Fisteus, Jesús A. and Brill, Markus},
  doi          = {10.1007/s10107-022-01805-8},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {107-134},
  shortjournal = {Math. Program.},
  title        = {The maximin support method: An extension of the D’Hondt method to approval-based multiwinner elections},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approval-based apportionment. <em>MP</em>, <em>203</em>(1),
77–105. (<a href="https://doi.org/10.1007/s10107-022-01852-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the apportionment problem, a fixed number of seats must be distributed among parties in proportion to the number of voters supporting each party. We study a generalization of this setting, in which voters can support multiple parties by casting approval ballots. This approval-based apportionment setting generalizes traditional apportionment and is a natural restriction of approval-based multiwinner elections, where approval ballots range over individual candidates instead of parties. Using techniques from both apportionment and multiwinner elections, we identify rules that generalize the D’Hondt apportionment method and that satisfy strong axioms which are generalizations of properties commonly studied in the apportionment literature. In fact, the rules we discuss provide representation guarantees that are currently out of reach in the general setting of multiwinner elections: First, we show that core-stable committees are guaranteed to exist and can be found in polynomial time. Second, we demonstrate that extended justified representation is compatible with committee monotonicity (also known as house monotonicity).},
  archive      = {J_MP},
  author       = {Brill, Markus and Gölz, Paul and Peters, Dominik and Schmidt-Kraepelin, Ulrike and Wilker, Kai},
  doi          = {10.1007/s10107-022-01852-1},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {77-105},
  shortjournal = {Math. Program.},
  title        = {Approval-based apportionment},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Phragmén’s voting methods and justified representation.
<em>MP</em>, <em>203</em>(1), 47–76. (<a
href="https://doi.org/10.1007/s10107-023-01926-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the late 19th century, Swedish mathematician Edvard Phragmén proposed a load-balancing approach for selecting committees based on approval ballots. We consider three committee voting rules resulting from this approach: two optimization variants—one minimizing the maximum load and one minimizing the variance of loads—and a sequential variant. We study Phragmén ’s methods from an axiomatic point of view, focusing on properties capturing proportional representation. We show that the sequential variant satisfies proportional justified representation, which is a rare property for committee monotonic methods. Moreover, we show that the optimization variants satisfy perfect representation. We also analyze the computational complexity of Phragmén ’s methods and provide mixed-integer programming based algorithms for computing them.},
  archive      = {J_MP},
  author       = {Brill, Markus and Freeman, Rupert and Janson, Svante and Lackner, Martin},
  doi          = {10.1007/s10107-023-01926-8},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {47-76},
  shortjournal = {Math. Program.},
  title        = {Phragmén’s voting methods and justified representation},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimality and fairness of partisan gerrymandering.
<em>MP</em>, <em>203</em>(1), 9–45. (<a
href="https://doi.org/10.1007/s10107-021-01731-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimal partisan gerrymandering: a legislator in charge of redrawing the boundaries of equal-sized congressional districts wants to ensure the best electoral outcome for his own party. The so-called gerrymanderer faces two issues: the number of districts is finite and there is uncertainty at the level of each district. Solutions to this problem consists in cracking favorable voters in as many districts as possible to get tight majorities, and in packing unfavorable voters in the remaining districts. The optimal payoff of the gerrymanderer tends to increase as the uncertainty decreases and the number of districts is large. With an infinite number of districts, this problem boils down to concavifying a function, similarly to the optimal Bayesian persuasion problem. We introduce a measure of fairness and show that optimal gerrymandering is accordingly closer to uniform districting (full cracking), which is most unfair, than to community districting (full packing), which is very fair.},
  archive      = {J_MP},
  author       = {Lagarde, Antoine and Tomala, Tristan},
  doi          = {10.1007/s10107-021-01731-1},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {9-45},
  shortjournal = {Math. Program.},
  title        = {Optimality and fairness of partisan gerrymandering},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical optimization for fair social decisions: A
tribute to michel balinski. <em>MP</em>, <em>203</em>(1), 1–7. (<a
href="https://doi.org/10.1007/s10107-023-02050-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Baïou, Mourad and Correa, José and Laraki, Rida},
  doi          = {10.1007/s10107-023-02050-3},
  journal      = {Mathematical Programming},
  month        = {1},
  number       = {1},
  pages        = {1-7},
  shortjournal = {Math. Program.},
  title        = {Mathematical optimization for fair social decisions: A tribute to michel balinski},
  volume       = {203},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
