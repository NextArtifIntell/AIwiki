<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cc---212">CC - 212</h2>
<ul>
<li><details>
<summary>
(2024). Cognitive-inspired deep learning models for aspect-based
sentiment analysis: A retrospective overview and bibliometric analysis.
<em>CC</em>, <em>16</em>(6), 3518–3556. (<a
href="https://doi.org/10.1007/s12559-024-10331-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As cognitive-inspired computation approaches, deep neural networks or deep learning (DL) models have played important roles in allowing machines to reach human-like performances in various complex cognitive tasks such as cognitive computation and sentiment analysis. This paper offers a thorough examination of the rapidly developing topic of DL-assisted aspect-based sentiment analysis (DL-ABSA), focusing on its increasing importance and implications for practice and research advancement. Leveraging bibliometric indicators, social network analysis, and topic modeling techniques, the study investigates four research questions: publication and citation trends, scientific collaborations, major themes and topics, and prospective research directions. The analysis reveals significant growth in DL-ABSA research output and impact, with notable contributions from diverse publication sources, institutions, and countries/regions. Collaborative networks between countries/regions, particularly between the USA and China, underscore global engagement in DL-ABSA research. Major themes such as syntax and structure analysis, neural networks for sequence modeling, and specific aspects and modalities in sentiment analysis emerge from the analysis, guiding future research endeavors. The study identifies prospective avenues for practitioners, emphasizing the strategic importance of syntax analysis, neural network methodologies, and domain-specific applications. Overall, this study contributes to the understanding of DL-ABSA research dynamics, providing a roadmap for practitioners and researchers to navigate the evolving landscape and drive innovations in DL-ABSA methodologies and applications.},
  archive      = {J_CC},
  author       = {Chen, Xieling and Xie, Haoran and Qin, S. Joe and Chai, Yaping and Tao, Xiaohui and Wang, Fu Lee},
  doi          = {10.1007/s12559-024-10331-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3518-3556},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive-inspired deep learning models for aspect-based sentiment analysis: A retrospective overview and bibliometric analysis},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view cooperative learning with invariant rationale for
document-level relation extraction. <em>CC</em>, <em>16</em>(6),
3505–3517. (<a
href="https://doi.org/10.1007/s12559-024-10322-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (RE) is a complex and significant natural language processing task, as the massive entity pairs exist in the document and are across sentences in reality. However, the existing relation extraction methods (deep learning) often use single-view information (e.g., entity-level or sentence-level) to learn the relational information but ignore the multi-view information, and the explanations of deep learning are difficult to be reflected, although it achieves good results. To extract high-quality relational information from the document and improve the explanations of the model, we propose a multi-view cooperative learning with invariant rationale (MCLIR) framework. Firstly, we design the multi-view cooperative learning to find latent relational information from the various views. Secondly, we utilize invariant rationale to encourage the model to focus on crucial information, which can empower the performance and explanations of the model. We conduct the experiment on two public datasets, and the results of the experiment demonstrate the effectiveness of MCLIR.},
  archive      = {J_CC},
  author       = {Lin, Rui and Fan, Jing and He, Yinglong and Yang, Yehui and Li, Jia and Guo, Cunhan},
  doi          = {10.1007/s12559-024-10322-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3505-3517},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-view cooperative learning with invariant rationale for document-level relation extraction},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probing fundamental visual comprehend capabilities on vision
language models via visual phrases from structural data. <em>CC</em>,
<em>16</em>(6), 3484–3504. (<a
href="https://doi.org/10.1007/s12559-024-10351-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Does the model demonstrate exceptional proficiency in “item counting,” “color recognition,” or other Fundamental Visual Comprehension Capability (FVCC)? There have been remarkable advancements in the field of multimodal, the pretrained general Vision Language Models exhibit strong performance across a range of intricate Visual Language (VL) tasks and Multimodal Large Language Models (MLLMs) emerge novel visual reasoning abilities from several examples. But models tend to encounter difficulties when confronted with texts supplemented with specific details by simple visual phrases. Moreover, there is a scarcity of datasets in sufficient quantity, variety, and composability to enable the evaluation of each FVCC using statistical metrics. Accordingly, we decomposed the complete VL task into 9 M simple Visual Phrase Triplets (VPTs) across 16 categories representing 16 distinct FVCCs from the structural scene graph. Then, we reconstructed a Multilevel Scene Graph (MLSG) for each image and introduced our unbiased, balanced, and binary Visual Phrase Entailment benchmark with 20 times the data volume of SNLI-VE. The benchmark consisted of three exams and evaluated the performance of 8 widely used VLM and 10 MLLMs respectively. The results demonstrate the performance of each model across 16 classes in FVCC, as well as their lower and upper limits under conditions of increased text complexity or unnoised image input. Finally, we enhanced the efficiency of MLLM and evoked their In-Context Learning characteristics by appending multiple VPT generated QA pairs of identical types to the conversation history without tuning. The proposed structural VPTs and MLSG data hold promise for facilitating future explorations on FVCC.},
  archive      = {J_CC},
  author       = {Xie, Peijin and Liu, Bingquan},
  doi          = {10.1007/s12559-024-10351-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3484-3504},
  shortjournal = {Cogn. Comput.},
  title        = {Probing fundamental visual comprehend capabilities on vision language models via visual phrases from structural data},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing pre-trained deep learning model with self-adaptive
reflection. <em>CC</em>, <em>16</em>(6), 3468–3483. (<a
href="https://doi.org/10.1007/s12559-024-10348-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the text mining area, prevalent deep learning models primarily focus on mapping input features to result of predicted outputs, which exhibit a deficiency in self-dialectical thinking process. Inspired by self-reflective mechanisms in human cognition, we propose a hypothesis that existing models emulate decision-making processes and automatically rectify erroneous predictions. The Self-adaptive Reflection Enhanced pre-trained deep learning Model (S-REM) is introduced to validate our hypotheses and to determine the types of knowledge that warrant reproduction. Based on the pretrained-model, S-REM introduces the local explanation for pseudo-label and the global explanation for all labels as the explanation knowledge. The keyword knowledge from TF-IDF model is also integrated to form a reflection knowledge. Based on the key explanation features, the pretrained-model reflects on the initial decision by two reflection methods and optimizes the prediction of deep learning models. Experiments with local and global reflection variants of S-REM on two text mining tasks across four datasets, encompassing three public and one private dataset were conducted. The outcomes demonstrate the efficacy of our method in improving the accuracy of state-of-the-art deep learning models. Furthermore, the method can serve as a foundational step towards developing explainable through integration with various deep learning models.},
  archive      = {J_CC},
  author       = {Wang, Xinzhi and Li, Mengyue and Yu, Hang and Wang, Chenyang and Sugumaran, Vijayan and Zhang, Hui},
  doi          = {10.1007/s12559-024-10348-3},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3468-3483},
  shortjournal = {Cogn. Comput.},
  title        = {Enhancing pre-trained deep learning model with self-adaptive reflection},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PDD: Pruning neural networks during knowledge distillation.
<em>CC</em>, <em>16</em>(6), 3457–3467. (<a
href="https://doi.org/10.1007/s12559-024-10350-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep neural networks have developed at a high level, the large computational requirement limits the deployment in end devices. To this end, a variety of model compression and acceleration techniques have been developed. Among these, knowledge distillation has emerged as a popular approach that involves training a small student model to mimic the performance of a larger teacher model. However, the student architectures used in existing knowledge distillation are not optimal and always have redundancy, which raises questions about the validity of this assumption in practice. This study aims to investigate this assumption and empirically demonstrate that student models could contain redundancy, which can be removed through pruning without significant performance degradation. Therefore, we propose a novel pruning method to eliminate redundancy in student models. Instead of using traditional post-training pruning methods, we perform pruning during knowledge distillation (PDD) to prevent any loss of important information from the teacher models to the student models. This is achieved by designing a differentiable mask for each convolutional layer, which can dynamically adjust the channels to be pruned based on the loss. Experimental results show that with ResNet20 as the student model and ResNet56 as the teacher model, a 39.53%-FLOPs reduction was achieved by removing 32.77% of parameters, while the top-1 accuracy on CIFAR10 increased by 0.17%. With VGG11 as the student model and VGG16 as the teacher model, a 74.96%-FLOPs reduction was achieved by removing 76.43% of parameters, with only a loss of 1.34% in the top-1 accuracy on CIFAR10. Our code is available at https://github.com/YihangZhou0424/PDD-Pruning-during-distillation .},
  archive      = {J_CC},
  author       = {Dan, Xi and Yang, Wenjie and Zhang, Fuyan and Zhou, Yihang and Yu, Zhuojun and Qiu, Zhen and Zhao, Boyuan and Dong, Zeyu and Huang, Libo and Yang, Chuanguang},
  doi          = {10.1007/s12559-024-10350-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3457-3467},
  shortjournal = {Cogn. Comput.},
  title        = {PDD: Pruning neural networks during knowledge distillation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PrimeNet: A framework for commonsense knowledge
representation and reasoning based on conceptual primitives.
<em>CC</em>, <em>16</em>(6), 3429–3456. (<a
href="https://doi.org/10.1007/s12559-024-10345-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge acquisition and representation is a core topic in artificial intelligence (AI), which is crucial for building more sophisticated and human-like AI systems. However, existing commonsense knowledge bases organize facts in an isolated manner like bag of facts, lacking the cognitive-level connections that humans commonly possess. People have the ability to efficiently organize vast amounts of knowledge by linking or generalizing concepts using a limited set of conceptual primitives that serve as the fundamental building blocks of reasoning. These conceptual primitives are basic, foundational elements of thought that humans use to make sense of the world. By combining and recombining these primitives, people can construct complex ideas, solve problems, and understand new concepts. To emulate this cognitive mechanism, we design a new commonsense knowledge base, termed PrimeNet, organized in a three-layer structure: a small core of conceptual primitives (e.g., FOOD), a bigger set of concepts that connect to such primitives (e.g., fruit), and an even larger layer of entities connecting to the concepts (e.g., banana). First, we collect commonsense knowledge and employ a gradual expansion strategy for knowledge integration. After refinement, PrimeNet contains 6 million edges between 2 million nodes, with 34 different types of relations. Then, we design a new conceptualization method by leveraging a probabilistic taxonomy, to build the concept layer of PrimeNet. Finally, we conduct primitive detection to build the primitive layer, where a lexical substitution task is used to identify related concepts, and large language models are employed to generate a rational primitive to label each concept cluster as well as verify the primitive detection process.},
  archive      = {J_CC},
  author       = {Liu, Qian and Han, Sooji and Cambria, Erik and Li, Yang and Kwok, Kenneth},
  doi          = {10.1007/s12559-024-10345-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3429-3456},
  shortjournal = {Cogn. Comput.},
  title        = {PrimeNet: A framework for commonsense knowledge representation and reasoning based on conceptual primitives},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prompt learning for multimodal intent recognition with modal
alignment perception. <em>CC</em>, <em>16</em>(6), 3417–3428. (<a
href="https://doi.org/10.1007/s12559-024-10328-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal intent recognition analysis is a crucial task in understanding user intent through speech, body movements, tone, and other modalities in real-world multimodal environments. However, due to the hidden nature of intent within and across modalities, most existing methods still have limitations in excavating and integrating multimodal intent information. This paper introduces a prompt learning with modal alignment perception (PMAP) approach to address these challenges. First, for excavating deep-level semantic information, the intent templates are constructed for prompt learning to enhance text representations. Then, cross-modal alignment perception is leveraged to eliminate modality discrepancies while excavating consistent hidden intent information from non-text modalities. Through multimodal semantic interaction, the position of text in the semantic space is fine-tuned, which effectively aggregates intent details from multiple modalities. Extensive experiments demonstrate that our method achieves significant improvements.},
  archive      = {J_CC},
  author       = {Chen, Yuzhao and Zhu, Wenhua and Yu, Weilun and Xue, Hongfei and Fu, Hao and Lin, Jiali and Jiang, Dazhi},
  doi          = {10.1007/s12559-024-10328-7},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3417-3428},
  shortjournal = {Cogn. Comput.},
  title        = {Prompt learning for multimodal intent recognition with modal alignment perception},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Barrier function to skin elasticity in talking head.
<em>CC</em>, <em>16</em>(6), 3405–3416. (<a
href="https://doi.org/10.1007/s12559-024-10344-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we target the problem of generating facial expressions from a piece of audio. This is challenging since both audio and video have inherent characteristics that are distinct from the other. Some words may have identical lip movements, and speech impediments may prevent lip-reading in some individuals. Previous approaches to generating such a talking head suffered from stiff expressions. This is because they focused only on lip movements and the facial landmarks did not contain the information flow from the audio. Hence, in this work, we employ spatio-temporal independent component analysis to accurately sync the audio with the corresponding face video. Proper word formation also requires control over the face muscles that can be captured using a barrier function. We first validated the approach on the diffusion of salt water in coastal areas using a synthetic finite element simulation. Next, we applied it to 3D facial expressions in toddlers for which training data is difficult to capture. Prior knowledge in the form of rules is specified using Fuzzy logic, and multi-objective optimization is used to collectively learn a set of rules. We observed significantly higher F-measure on three real-world problems.},
  archive      = {J_CC},
  author       = {Chaturvedi, Iti and Pandelea, Vlad and Cambria, Erik and Welsch, Roy and Datta, Bithin},
  doi          = {10.1007/s12559-024-10344-7},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3405-3416},
  shortjournal = {Cogn. Comput.},
  title        = {Barrier function to skin elasticity in talking head},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disentangling user cognitive intent with causal reasoning
for knowledge-enhanced recommendation. <em>CC</em>, <em>16</em>(6),
3391–3404. (<a
href="https://doi.org/10.1007/s12559-024-10321-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of an effective recommender system is to provide accurate, varied, and personalized recommendations that align with the user’s cognitive intents. Given their ability to represent structural and semantic information effectively, knowledge graphs (KGs) are increasingly being utilized to capture auxiliary information for recommendation systems. This trend is supported by the recent advancements in graph neural network (GNN)-based models for KG-aware recommendations. However, these models often struggle with issues such as insufficient user-item interactions and the misalignment of user intent weights during information propagation. Additionally, they face a popularity bias, which is exacerbated by the disproportionate influence of a small number of highly active users and the limited auxiliary information about items. This bias significantly curtails the effectiveness of the recommendations. To address this issue, we propose a Knowledge-Enhanced User Cognitive Intent Network (KeCAIN), which incorporates item category information to capture user intents with information aggregation and eliminate popularity bias based on causal reasoning in recommendation systems. Experiments on three real-world datasets show that KeCAIN outperforms state-of-the-art baselines.},
  archive      = {J_CC},
  author       = {xu, Hongcai and Bao, Junpeng and Lin, Qika and Hou, Lifang and Chen, Feng},
  doi          = {10.1007/s12559-024-10321-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3391-3404},
  shortjournal = {Cogn. Comput.},
  title        = {Disentangling user cognitive intent with causal reasoning for knowledge-enhanced recommendation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitive tracing data trails: Auditing data provenance in
discriminative language models using accumulated discrepancy score.
<em>CC</em>, <em>16</em>(6), 3379–3390. (<a
href="https://doi.org/10.1007/s12559-024-10315-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The burgeoning practice of unauthorized acquisition and utilization of personal textual data (e.g., social media comments and search histories) by certain entities has become a discernible trend. To uphold data protection regulations such as the Asia–Pacific Privacy Initiative (APPI) and to identify instances of unpermitted exploitation of personal data, we propose a novel and efficient audit framework that helps users conduct cognitive analysis to determine if their textual data was used for data augmentation. and training a discriminative model. In particular, we focus on auditing models that use BERT as the backbone for discriminating text and are at the core of popular online services. We first propose an accumulated discrepancy score, which involves not only the response of the target model to the auditing sample but also the responses between pre-trained and finetuned models, to identify membership. We implement two types of audit methods (i.e., sample-level and user-level) according to our framework and conduct comprehensive experiments on two downstream applications to evaluate the performance. The experimental results demonstrate that our sample-level auditing achieves an AUC of 89.7% and an accuracy of 83%, whereas the user-level method can audit membership with an AUC of 89.7% and an accuracy of 88%. Additionally, we undertake an analysis of how augmentation methods impact auditing performance and expound upon the underlying reasons for these observations.},
  archive      = {J_CC},
  author       = {Zeng, Zhirui and He, Jialing and Xiang, Tao and Wang, Ning and Chen, Biwen and Guo, Shangwei},
  doi          = {10.1007/s12559-024-10315-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3379-3390},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive tracing data trails: Auditing data provenance in discriminative language models using accumulated discrepancy score},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diagnostic potential of eye movements in alzheimer’s disease
via a multiclass machine learning model. <em>CC</em>, <em>16</em>(6),
3364–3378. (<a
href="https://doi.org/10.1007/s12559-024-10346-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis plays a crucial role in controlling Alzheimer’s disease (AD) progression and delaying cognitive decline. Traditional diagnostic tools present great challenges to clinical practice due to their invasiveness, high cost, and time-consuming administration. This study was designed to construct a non-invasive and cost-effective classification model based on eye movement parameters to distinguish dementia due to AD (ADD), mild cognitive impairment (MCI), and normal cognition. Eye movement data were collected from 258 subjects, comprising 111 patients with ADD, 81 patients with MCI, and 66 individuals with normal cognition. The fixation, smooth pursuit, prosaccade, and anti-saccade tasks were performed. Machine learning methods were used to screen eye movement parameters and build diagnostic models. Pearson’s correlation analysis was used to assess the correlations between the five most important eye movement indicators in the optimal model and neuropsychological scales. The gradient boosting classifier model demonstrated the best classification performance, achieving 68.2% of accuracy and 66.32% of F1-score in multiclass classification of AD. Moreover, the correlation analysis indicated that the eye movement parameters were associated with various cognitive functions, including general cognitive status, attention, visuospatial ability, episodic memory, short-term memory, and language and instrumental activities of daily life. Eye movement parameters in conjunction with machine learning methods achieve satisfactory overall accuracy, making it an effective and less time-consuming method to assist clinical diagnosis of AD.},
  archive      = {J_CC},
  author       = {Song, Jiaqi and Huang, Haodong and Liu, Jiarui and Wu, Jiani and Chen, Yingxi and Wang, Lisong and Zhong, Fuxin and Wang, Xiaoqin and Lin, Zihan and Yan, Mengyu and Zhang, Wenbo and Liu, Xintong and Tang, Xinyi and Lü, Yang and Yu, Weihua},
  doi          = {10.1007/s12559-024-10346-5},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3364-3378},
  shortjournal = {Cogn. Comput.},
  title        = {Diagnostic potential of eye movements in alzheimer’s disease via a multiclass machine learning model},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A consensus model with non-cooperative behavior adaptive
management based on cognitive psychological state computation in
large-scale group decision. <em>CC</em>, <em>16</em>(6), 3344–3363. (<a
href="https://doi.org/10.1007/s12559-024-10330-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social cognition proposed that individual cognitive psychology was closely related to decision-making behavior. The heterogeneity of individual cognitive psychology has been ignored in large-scale decision-making. This research proposes a novel consensus decision model based on cognitive psychological state computation. Effective trust, cognitive trust, and opinion similarity are integrated to construct a fusion relationship network, and Louvain algorithm is used to divide communities. On this basis, non-cooperative individuals are identified. We quantify and classify individual cognitive psychological states by introducing attitude-belief factors. In this process, the cognitive trust and cognitive expression involved have fuzziness and uncertainty, which are quantified and computed by intuitionistic fuzzy set theory. Considering the difference in cognitive dissonance among non-cooperative individuals with different cognitive states, an adaptive feedback mechanism and trust renewal rule are proposed. The simulation results show that, on the one hand, the consensus model in this paper has a high timeliness. On the other hand, among the four types of cognitive psychological state, the non-cooperative individual with higher attitude factor and lower belief factor had higher management efficiency and consensus-reaching speed.},
  archive      = {J_CC},
  author       = {Chen, Yuetong and Zhou, Mingrui and Liu, Fengming},
  doi          = {10.1007/s12559-024-10330-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3344-3363},
  shortjournal = {Cogn. Comput.},
  title        = {A consensus model with non-cooperative behavior adaptive management based on cognitive psychological state computation in large-scale group decision},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From pixels to prepositions: Linking visual perception with
spatial prepositions far and near. <em>CC</em>, <em>16</em>(6),
3319–3343. (<a
href="https://doi.org/10.1007/s12559-024-10329-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human language is influenced by sensory-motor experiences. Sensory experiences gathered in a spatiotemporal world are used as raw material to create more abstract concepts. In language, one way to encode spatial relationships is through spatial prepositions. Spatial prepositions that specify the proximity of objects in space, like far and near or their variants, are found in most languages. The mechanism for determining the proximity of another entity to itself is a useful evolutionary trait. From the taxic behavior in unicellular organisms like bacteria to the tropism in the plant kingdom, this behavior can be found in almost all organisms. In humans, vision plays a critical role in spatial localization and navigation. This computational study analyzes the relationship between vision and spatial prepositions using an artificial neural network. For this study, a synthetic image dataset was created, with each image featuring a 2D projection of an object placed in 3D space. The objects can be of various shapes, sizes, and colors. A convolutional neural network is trained to classify the object in the images as far or near based on a set threshold. The study mainly explores two visual scenarios: objects confined to a plane (grounded) and objects not confined to a plane (ungrounded), while also analyzing the influence of camera placement. The classification performance is high for the grounded case, demonstrating that the problem of far/near classification is well-defined for grounded objects, given that the camera is at a sufficient height. The network performance showed that depth can be determined in grounded cases only from monocular cues with high accuracy, given the camera is at an adequate height. The difference in the network’s performance between grounded and ungrounded cases can be explained using the physical properties of the retinal imaging system. The task of determining the distance of an object from individual images in the dataset is challenging as they lack any background cues. Still, the network performance shows the influence of spatial constraints placed on the image generation process in determining depth. The results show that monocular cues significantly contribute to depth perception when all the objects are confined to a single plane. A set of sensory inputs (images) and a specific task (far/near classification) allowed us to obtain the aforementioned results. The visual task, along with reaching and motion, may enable humans to carve the space into various spatial prepositional categories like far and near. The network’s performance and how it learns to classify between far and near provided insights into certain visual illusions that involve size constancy.},
  archive      = {J_CC},
  author       = {Raj S R, Krishna and Chakravarthy V, Srinivasa and Sahoo, Anindita},
  doi          = {10.1007/s12559-024-10329-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3319-3343},
  shortjournal = {Cogn. Comput.},
  title        = {From pixels to prepositions: Linking visual perception with spatial prepositions far and near},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial: Cognitive analysis for humans and AI.
<em>CC</em>, <em>16</em>(6), 3316–3318. (<a
href="https://doi.org/10.1007/s12559-024-10352-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Mao, Rui and Liu, Qian and Li, Xiao and Cambria, Erik and Hussain, Amir},
  doi          = {10.1007/s12559-024-10352-7},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3316-3318},
  shortjournal = {Cogn. Comput.},
  title        = {Guest editorial: Cognitive analysis for humans and AI},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive survey on generative AI for metaverse:
Enabling immersive experience. <em>CC</em>, <em>16</em>(6), 3286–3315.
(<a href="https://doi.org/10.1007/s12559-024-10342-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Artificial Intelligence models are Artificial Intelligence models that generate new content based on a prompt or input. The output content can be in various forms, including text, images, and video. Metaverse refers to a virtual world where users can interact with each other, objects and events in an immersive, realistic, and dynamic manner. A critical and foremost step in realizing the Metaverse is content creation for its different realms. Given Metaverse’s need for enormous content, Generative AI is a perfect technology for content creation. This paper explores how Generative AI models can help fulfil the potential of the Metaverse by assisting in the design and production of various aspects of the Metaverse and attracting users not just by creating dynamic, interactive, and personalised content at scale but also by producing various revenue-generating opportunities for users and organisations in the Metaverse. The paper analyses the Generative AI models by grouping them according to the type of content they generate, namely text, image, video, 3D visual, audio, and gaming. Various use cases in the Metaverse are explored and listed according to each type of AI Generated Content (AIGC). This paper also presents several applications and scenarios where the mixture of different Generative AI (GAI) models benefits the Metaverse. Further, this paper also enumerates the limitations and challenges of Generative AI models and the areas of future work. Despite the obstacles, Generative AI can realise the potential of the Metaverse by making it much more functional and interactive owing to the vast use cases of different types of AIGC in the Metaverse, and the age of virtual reality may not be too distant.},
  archive      = {J_CC},
  author       = {Chamola, Vinay and Sai, Siva and Bhargava, Animesh and Sahu, Ashis and Jiang, Wenchao and Xiong, Zehui and Niyato, Dusit and Hussain, Amir},
  doi          = {10.1007/s12559-024-10342-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3286-3315},
  shortjournal = {Cogn. Comput.},
  title        = {A comprehensive survey on generative AI for metaverse: Enabling immersive experience},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel cognitive rough approach for severity analysis of
autistic children using spherical fuzzy bipolar soft sets. <em>CC</em>,
<em>16</em>(6), 3260–3285. (<a
href="https://doi.org/10.1007/s12559-024-10349-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorders (ASDs) pose complex challenges, characterized by atypical behaviors, sensory sensitivities, and difficulties in social interaction. Despite extensive research, their exact causes remain elusive, indicating a multifactorial interplay of genetic, environmental, and neurological factors. This complexity calls for innovative approaches to ASD understanding and management. Motivated by the need to address the nuanced and uncertain nature of ASD-related data, in this study, we introduce a novel hybrid model called rough spherical fuzzy bipolar soft sets (RSFBSSs) by integrating rough sets, spherical fuzzy sets, and bipolar soft sets, which accommodates imprecision inherent in clinical assessments. We build upon foundational concepts of RSFBSS theory, developing a comprehensive algorithm for uncertain multiple attribute decision-making (MADM). Leveraging this framework, we aim to assess ASD symptom severity in pediatric populations, considering diverse contributing factors to ASD pathogenesis. The RSFBSSs offer advantages over existing methodologies, providing a robust framework for handling complex ASD data. The algorithmic framework facilitates accurate and individualized assessments of ASD symptomatology. To validate our model’s efficacy, we conduct a comparative analysis with preexisting hybrid models, employing quantitative metrics and qualitative evaluations. Through this comprehensive evaluation, we demonstrate the superior performance and versatility of RSFBSSs, offering promising avenues for advancing ASD management.},
  archive      = {J_CC},
  author       = {Ali, Ghous and Lateef, Nimra and Zia, Muhammad Usman and Abbas, Tehseen},
  doi          = {10.1007/s12559-024-10349-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3260-3285},
  shortjournal = {Cogn. Comput.},
  title        = {A novel cognitive rough approach for severity analysis of autistic children using spherical fuzzy bipolar soft sets},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A joint network for low-light image enhancement based on
retinex. <em>CC</em>, <em>16</em>(6), 3241–3259. (<a
href="https://doi.org/10.1007/s12559-024-10347-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods based on the physical Retinex model are effective in enhancing low-light images, adeptly handling the challenges posed by low signal-to-noise ratios and high noise in images captured under weak lighting conditions. However, traditional models based on manually designed Retinex priors do not adapt well to complex and varying degradation environments. DEANet (Jiang et al., Tsinghua Sci Technol. 2023;28(4):743–53 2023) combines frequency and Retinex to address the interference of high-frequency noise in low-light image restoration. Nonetheless, low-frequency noise still significantly impacts the restoration of low-light images. To overcome this issue, this paper integrates the physical Retinex model with deep learning to propose a joint network model, DEANet++, for enhancing low-light images. The model is divided into three modules: decomposition, enhancement, and adjustment. The decomposition module employs a data-driven approach based on Retinex theory to split the image; the enhancement module restores degradation and adjusts brightness in the decomposed images; and the adjustment module restores details and adjusts complex features in the enhanced images. Trained on the publicly available LOL dataset, DEANet++ not only surpasses the control group in both visual and quantitative aspects but also achieves superior results compared to other Retinex-based enhancement methods. Ablation studies and additional experiments highlight the importance of each component in this method.},
  archive      = {J_CC},
  author       = {Jiang, Yonglong and Zhu, Jiahe and Li, Liangliang and Ma, Hongbing},
  doi          = {10.1007/s12559-024-10347-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3241-3259},
  shortjournal = {Cogn. Comput.},
  title        = {A joint network for low-light image enhancement based on retinex},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incorporating template-based contrastive learning into
cognitively inspired, low-resource relation extraction. <em>CC</em>,
<em>16</em>(6), 3228–3240. (<a
href="https://doi.org/10.1007/s12559-024-10343-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From an unstructured text, relation extraction (RE) predicts semantic relationships between pairs of entities. The process of labeling tokens and phrases can be very expensive and require a great deal of time and effort. The low-resource relation extraction (LRE) problem comes into being and is challenging since there are only a limited number of annotated sentences available. Recent research has focused on minimizing the cross-entropy loss between pseudo labels and ground truth or on using external knowledge to make annotations for unlabeled data. Existing methods, however, fail to take into account the semantics of relation types and the information hidden within different relation groups. By drawing inspiration from the process of human interpretation of unstructured documents, we introduce a Template-based Contrastive Learning ( TempCL ). Through the use of template, we limit the model’s attention to the semantic information that is contained in a relation. Then, we employ a contrastive learning strategy using both group-wise and instance-wise perspectives to leverage shared semantic information within the same relation type to achieve a more coherent semantic representation. Particularly, the proposed group-wise contrastive learning minimizes the discrepancy between the template and original sentences in the same label group and maximizes the difference between those from separate label groups under limited annotation settings. Our experiment results on two public datasets show that our model TempCL achieves state-of-the-art results for low-resource relation extraction in comparison to baselines. The relative error reductions range from 0.68 to 1.32%. Our model encourages the feature to be aligned with both the original and template sentences. Using two contrastive losses, we exploit shared semantic information underlying sentences (both original and template) that have the same relation type. We demonstrate that our method reduces the noise caused by tokens that are unrelated and constrains the model’s attention to the tokens that are related.},
  archive      = {J_CC},
  author       = {Zheng, Yandan and Tuan, Luu Anh},
  doi          = {10.1007/s12559-024-10343-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3228-3240},
  shortjournal = {Cogn. Comput.},
  title        = {Incorporating template-based contrastive learning into cognitively inspired, low-resource relation extraction},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitively inspired three-way decision making and bi-level
evolutionary optimization for mobile cybersecurity threats detection: A
case study on android malware. <em>CC</em>, <em>16</em>(6), 3200–3227.
(<a href="https://doi.org/10.1007/s12559-024-10337-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious apps use a variety of methods to spread infections, take over computers and/or IoT devices, and steal sensitive data. Several detection techniques have been proposed to counter these attacks. Despite the promising results of recent malware detection strategies, particularly those addressing evolving threats, inefficiencies persist due to potential inconsistency in both the generated malicious malware and the pre-specified detection rules, as well as their crisp decision-making process. In this paper, we propose to address these issues by (i) considering the detection rules generation process as a Bi-Level Optimization Problem, where a competition between two levels (an upper level and a lower one) produces a set of effective detection rules capable of detecting new variants of existing and even unseen malware patterns. This bi-level strategy is subtly inspired by natural evolutionary processes, where organisms adapt and evolve through continuous interaction and competition within their environments. Furthermore, (ii) we leverage the fundamentals of Rough Set Theory, which reflects cognitive decision-making processes, to assess the true nature of artificially generated malicious patterns. This involves retaining only the consistent malicious patterns and detection rules and categorizing these rules into a three-way decision framework comprising accept, abstain, and reject options. Our novel malware detection technique outperforms several state-of-the-art methods on various Android malware datasets, accurately predicting new apps with a 96.76% accuracy rate. Moreover, our approach is versatile and effective in detecting patterns applicable to a variety of cybersecurity threats.},
  archive      = {J_CC},
  author       = {Jerbi, Manel and Chelly Dagdia, Zaineb and Bechikh, Slim and Said, Lamjed Ben},
  doi          = {10.1007/s12559-024-10337-6},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3200-3227},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitively inspired three-way decision making and bi-level evolutionary optimization for mobile cybersecurity threats detection: A case study on android malware},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Brain age estimation using universum learning-based kernel
random vector functional link regression network. <em>CC</em>,
<em>16</em>(6), 3186–3199. (<a
href="https://doi.org/10.1007/s12559-024-10326-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain age serves as a vital biomarker for detecting neurological ailments like Alzheimer’s disease (AD) and Parkinson’s disease (PD). Magnetic resonance imaging (MRI) has been extensively explored with deep neural networks to estimate brain age. The discrepancy between the predicted age and chronological age (real age) can be instrumental in identifying brain-related issues and assessing overall brain health. In this study, we have developed a brain age estimation framework utilizing a ResNet-50 deep neural network and a universum learning-based kernel random vector functional link (UKRVFL) network based on MRI images. A novel formulation of universum-KRVFL is introduced for regression tasks that capitalizes on prior knowledge through supplementary data samples. The universum data samples originate from the same domain as training samples but have different distributions. The proposed work efficacy is substantiated by conducting experiments on publicly available datasets. The model performance is quantified through metrics such as the mean absolute error (MAE), root mean square error (RMSE), and the coefficient of determination ( $$R^2$$ ), where lower MAE and RMSE values and a higher $$R^2$$ indicate greater accuracy in age prediction. The proposed age prediction model achieved an MAE of 2.68 years and 3.53 years of RMSE on healthy control (HC) test subjects. To further assess the significance of the brain age gap (BAG) as a biomarker for brain health, studies are conducted on mild cognitive impairment (MCI), PD, and AD groups. For MCI, PD, and AD groups, age estimation model yielded an RMSE of 4.13, 4.86, and 6.60 years, respectively. The experimental results demonstrate that the brain age gap in brain function is notably wider within AD group, indicating an acceleration of brain aging among those with neurodegeneration.},
  archive      = {J_CC},
  author       = {Pilli, Raveendra and Goel, Tripti and Murugan, R. and Tanveer, M.},
  doi          = {10.1007/s12559-024-10326-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3186-3199},
  shortjournal = {Cogn. Comput.},
  title        = {Brain age estimation using universum learning-based kernel random vector functional link regression network},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing emotional trends from x platform using SenticNet:
A comparative analysis with cryptocurrency price. <em>CC</em>,
<em>16</em>(6), 3168–3185. (<a
href="https://doi.org/10.1007/s12559-024-10335-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the relationship between emotional trends derived from X platform data and the market dynamics of prominent cryptocurrencies—Cardano, Binance, Fantom, Matic, and Ripple—during the period from October 2022 to March 2023. Utilizing SenticNet, key emotions such as fear and anxiety, rage and anger, grief and sadness, delight and pleasantness, enthusiasm and eagerness, and delight and joy were identified. The emotional data and cryptocurrency price data, sourced bi-weekly, were analyzed to uncover significant correlations. The findings reveal that emotions such as delight and pleasantness and delight and joy have the strongest positive correlations with Fantom’s price, while delight and pleasantness exhibit the strongest negative correlations with Cardano and Binance. The study highlights the nuanced impact of specific emotional states on cryptocurrency prices, offering valuable insights for market participants.},
  archive      = {J_CC},
  author       = {Shahiki Tash, Moein and Ahani, Zahra and Tash, Mohim and Kolesnikova, Olga and Sidorov, Grigori},
  doi          = {10.1007/s12559-024-10335-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3168-3185},
  shortjournal = {Cogn. Comput.},
  title        = {Analyzing emotional trends from x platform using SenticNet: A comparative analysis with cryptocurrency price},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitive analysis of medical decision-making: An extended
MULTIMOORA-based multigranulation probabilistic model with evidential
reasoning. <em>CC</em>, <em>16</em>(6), 3149–3167. (<a
href="https://doi.org/10.1007/s12559-024-10340-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive computation has leveraged the capabilities of computer algorithms, rendering it an exceptionally efficient approach for addressing multi-attribute group decision-making (MAGDM) problems. Due to the stability of MULTIMOORA (Multi-Objective Optimization by Ratio Analysis plus the full MULTIplicative form) and the capability of evidential reasoning (ER) to combine information from multiple sources, the technique of multigranulation probabilistic rough sets (MG PRSs) holds great promise for solving MAGDM problems. Thus, a new and stable method for MAGDM is proposed. Initially, three forms of multigranulation Pythagorean fuzzy probabilistic rough sets (MG PF PRSs) are constructed using MULTIMOORA approaches. Next, the hierarchical clustering method is employed to cluster similar decision information and consolidate the decision-makers’ preferences. Representatives are chosen from each category to simplify information fusion calculations and reduce complexity by reducing the model’s dimensionality. Following that, the rankings obtained from the three methods are fused using ER. Ultimately, the validity of our method is revealed via a case analysis on chickenpox cases from the UCI data set by employing cognitive analysis. The paper outlines a method for MAGDM that provides significant advantages. Specifically, the use of MULTIMOORA improves the stability of decision results, while the incorporation of ER reduces the overall uncertainty of entire decision processes.},
  archive      = {J_CC},
  author       = {Bai, Wenhui and Zhang, Chao and Zhai, Yanhui and Sangaiah, Arun Kumar and Wang, Baoli and Li, Wentao},
  doi          = {10.1007/s12559-024-10340-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3149-3167},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive analysis of medical decision-making: An extended MULTIMOORA-based multigranulation probabilistic model with evidential reasoning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decision-analytics-based risk allocation in the
micromobility sector: Sugeno-weber operators and picture fuzzy distance
methodology. <em>CC</em>, <em>16</em>(6), 3122–3148. (<a
href="https://doi.org/10.1007/s12559-024-10333-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Alrasheedi, Adel Fahad and Mishra, Arunodaya Raj and Alshamrani, Ahmad M. and Rani, Pratibha and Pamucar, Dragan},
  doi          = {10.1007/s12559-024-10333-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3122-3148},
  shortjournal = {Cogn. Comput.},
  title        = {Decision-analytics-based risk allocation in the micromobility sector: Sugeno-weber operators and picture fuzzy distance methodology},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fermatean fuzzy dombi generalized maclaurin symmetric mean
operators for prioritizing bulk material handling technologies.
<em>CC</em>, <em>16</em>(6), 3096–3121. (<a
href="https://doi.org/10.1007/s12559-024-10323-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Saha, Abhijit and Dabic-Miletic, Svetlana and Senapati, Tapan and Simic, Vladimir and Pamucar, Dragan and Ala, Ali and Arya, Leena},
  doi          = {10.1007/s12559-024-10323-y},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3096-3121},
  shortjournal = {Cogn. Comput.},
  title        = {Fermatean fuzzy dombi generalized maclaurin symmetric mean operators for prioritizing bulk material handling technologies},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable AI for text classification: Lessons from a
comprehensive evaluation of post hoc methods. <em>CC</em>,
<em>16</em>(6), 3077–3095. (<a
href="https://doi.org/10.1007/s12559-024-10325-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the notable gap in evaluating eXplainable Artificial Intelligence (XAI) methods for text classification. While existing frameworks focus on assessing XAI in areas such as recommender systems and visual analytics, a comprehensive evaluation is missing. Our study surveys and categorises recent post hoc XAI methods according to their scope of explanation and output format. We then conduct a systematic evaluation, assessing the effectiveness of these methods across varying scopes and levels of output granularity using a combination of objective metrics and user studies. Key findings reveal that feature-based explanations exhibit higher fidelity than rule-based ones. While global explanations are perceived as more satisfying and trustworthy, they are less practical than local explanations. These insights enhance understanding of XAI in text classification and offer valuable guidance for developing effective XAI systems, enabling users to evaluate each explainer’s pros and cons and select the most suitable one for their needs.},
  archive      = {J_CC},
  author       = {Cesarini, Mirko and Malandri, Lorenzo and Pallucchini, Filippo and Seveso, Andrea and Xing, Frank},
  doi          = {10.1007/s12559-024-10325-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3077-3095},
  shortjournal = {Cogn. Comput.},
  title        = {Explainable AI for text classification: Lessons from a comprehensive evaluation of post hoc methods},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning of XAI models in healthcare: A case study
on parkinson’s disease. <em>CC</em>, <em>16</em>(6), 3051–3076. (<a
href="https://doi.org/10.1007/s12559-024-10332-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) systems are increasingly used in healthcare applications, although some challenges have not been completely overcome to make them fully trustworthy and compliant with modern regulations and societal needs. First of all, sensitive health data, essential to train AI systems, are typically stored and managed in several separate medical centers and cannot be shared due to privacy constraints, thus hindering the use of all available information in learning models. Further, transparency and explainability of such systems are becoming increasingly urgent, especially at a time when “opaque” or “black-box” models are commonly used. Recently, technological and algorithmic solutions to these challenges have been investigated: on the one hand, federated learning (FL) has been proposed as a paradigm for collaborative model training among multiple parties without any disclosure of private raw data; on the other hand, research on eXplainable AI (XAI) aims to enhance the explainability of AI systems, either through interpretable by-design approaches or post-hoc explanation techniques. In this paper, we focus on a healthcare case study, namely predicting the progression of Parkinson’s disease, and assume that raw data originate from different medical centers and data collection for centralized training is precluded due to privacy limitations. We aim to investigate how FL of XAI models can allow achieving a good level of accuracy and trustworthiness. Cognitive and biologically inspired approaches are adopted in our analysis: FL of an interpretable by-design fuzzy rule-based system and FL of a neural network explained using a federated version of the SHAP post-hoc explanation technique. We analyze accuracy, interpretability, and explainability of the two approaches, also varying the degree of heterogeneity across several data distribution scenarios. Although the neural network is generally more accurate, the results show that the fuzzy rule-based system achieves competitive performance in the federated setting and presents desirable properties in terms of interpretability and transparency.},
  archive      = {J_CC},
  author       = {Ducange, Pietro and Marcelloni, Francesco and Renda, Alessandro and Ruffini, Fabrizio},
  doi          = {10.1007/s12559-024-10332-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3051-3076},
  shortjournal = {Cogn. Comput.},
  title        = {Federated learning of XAI models in healthcare: A case study on parkinson’s disease},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluative item-contrastive explanations in rankings.
<em>CC</em>, <em>16</em>(6), 3035–3050. (<a
href="https://doi.org/10.1007/s12559-024-10311-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable success of Artificial Intelligence in advancing automated decision-making is evident both in academia and industry. Within the plethora of applications, ranking systems hold significant importance in various domains. This paper advocates for the application of a specific form of Explainable AI—namely, contrastive explanations—as particularly well-suited for addressing ranking problems. This approach is especially potent when combined with an Evaluative AI methodology, which conscientiously evaluates both positive and negative aspects influencing a potential ranking. Therefore, the present work introduces Evaluative Item-Contrastive Explanations tailored for ranking systems and illustrates its application and characteristics through an experiment conducted on publicly available data.},
  archive      = {J_CC},
  author       = {Castelnovo, Alessandro and Crupi, Riccardo and Mombelli, Nicolò and Nanino, Gabriele and Regoli, Daniele},
  doi          = {10.1007/s12559-024-10311-2},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3035-3050},
  shortjournal = {Cogn. Comput.},
  title        = {Evaluative item-contrastive explanations in rankings},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Granular syntax processing with multi-task and curriculum
learning. <em>CC</em>, <em>16</em>(6), 3020–3034. (<a
href="https://doi.org/10.1007/s12559-024-10320-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Syntactic processing techniques are the foundation of natural language processing (NLP), supporting many downstream NLP tasks. In this paper, we conduct pair-wise multi-task learning (MTL) on syntactic tasks with different granularity, namely Sentence Boundary Detection (SBD), text chunking, and Part-of-Speech (PoS) tagging, so as to investigate the extent to which they complement each other. We propose a novel soft parameter-sharing mechanism to share local and global dependency information that is learned from both target tasks. We also propose a curriculum learning (CL) mechanism to improve MTL with non-parallel labeled data. Using non-parallel labeled data in MTL is a common practice, whereas it has not received enough attention before. For example, our employed PoS tagging data do not have text chunking labels. When learning PoS tagging and text chunking together, the proposed CL mechanism aims to select complementary samples from the two tasks to update the parameters of the MTL model in the same training batch. Such a method yields better performance and learning stability. We conclude that the fine-grained tasks can provide complementary features to coarse-grained ones, while the most coarse-grained task, SBD, provides useful information for the most fine-grained one, PoS tagging. Additionally, the text chunking task achieves state-of-the-art performance when joint learning with PoS tagging. Our analytical experiments also show the effectiveness of the proposed soft parameter-sharing and CL mechanisms.},
  archive      = {J_CC},
  author       = {Zhang, Xulang and Mao, Rui and Cambria, Erik},
  doi          = {10.1007/s12559-024-10320-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {3020-3034},
  shortjournal = {Cogn. Comput.},
  title        = {Granular syntax processing with multi-task and curriculum learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable histopathology image classification with
self-organizing maps: A granular computing perspective. <em>CC</em>,
<em>16</em>(6), 2999–3019. (<a
href="https://doi.org/10.1007/s12559-024-10312-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic analysis of histology images is an open research field where machine learning techniques and neural networks, especially deep architectures, are considered successful tools due to their abilities in image classification. This paper proposes a granular computing methodology for histopathological image classification. It is based on embedding tiles of histopathology images using deep metric learning, where a self-organizing map is adopted to generate the granular structure in this learned embedding space. The SOM enables the implementation of an explainable mechanism by visualizing a knowledge space that the experts can use to analyze and classify the new images. Additionally, it provides confidence in the classification results while highlighting each important image fragment, with the benefit of reducing the number of false negatives. An exemplary case is when an image detail is indicated, with small confidence, as malignant in an image globally classified as benign. Another implemented feature is the proposal of additional labelled image tiles sharing the same characteristics to specify the context of the output decision. The proposed system was tested using three histopathology image datasets, obtaining the accuracy of the state-of-the-art black-box methods based on deep learning neural networks. Differently from the methodologies proposed so far for the same purpose, this paper introduces a novel explainable method for medical image analysis where the advantages of the deep learning neural networks used to build the embedding space for the image tiles are combined with the intrinsic explainability of the granular process obtained using the clustering property of a self-organizing map.},
  archive      = {J_CC},
  author       = {Amato, Domenico and Calderaro, Salvatore and Lo Bosco, Giosué and Rizzo, Riccardo and Vella, Filippo},
  doi          = {10.1007/s12559-024-10312-1},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2999-3019},
  shortjournal = {Cogn. Comput.},
  title        = {Explainable histopathology image classification with self-organizing maps: A granular computing perspective},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unmasking GAN-generated faces with optimal deep learning and
cognitive computing-based cutting-edge detection system. <em>CC</em>,
<em>16</em>(6), 2982–2998. (<a
href="https://doi.org/10.1007/s12559-024-10318-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of deep learning (DL) has improved the excellence of generated media. However, with the enlarged level of photorealism, synthetic media is becoming very similar to tangible media, increasing severe problems regarding transmitting fake or deployed data over the Internet. In this situation, it is significant to improve automatic tools to constantly and early identify synthetic media. Generative Adversarial Network (GAN)-based models can create realistic faces that cause deep social and security issues. Existing techniques for identifying GAN-generated faces can execute well on restricted public datasets. Nevertheless, images from existing datasets must signify real situations sufficient for view variants and data distributions, where real faces mainly outnumber artificial ones. Therefore, this study develops an optimal DL-based GAN-generated face detection and classification (ODL-GANFDC) technique. The ODL-GANFDC technique aims to examine the input images properly and recognize whether GAN generates them. To accomplish this, the ODL-GANFDC technique follows the initial stage of the CLAHE-based contrast enhancement process. In addition, the deep residual network (DRN) model must be employed to learn the complex and intrinsic patterns from the preprocessed images. Besides, the hyperparameters of the DRN model can be optimally chosen using an improved sand cat swarm optimization (ISCSO) algorithm. Finally, the GAN-generated faces can be detected using a variational autoencoder (VAE). An extensive set of experimentations can be carried out to highlight the performance of the ODL-GANFDC technique. The experimental outcomes stated the promising results of the ODL-GANFDC technique over compared approaches on the GAN-generated face detection process.},
  archive      = {J_CC},
  author       = {Alabdan, Rana and Alsamri, Jamal and Hassine, Siwar Ben Haj and Alotaibi, Faiz Abdullah and Alotaibi, Saud S. and Yafoz, Ayman and Alnfiai, Mrim M. and Al Duhayyim, Mesfer},
  doi          = {10.1007/s12559-024-10318-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2982-2998},
  shortjournal = {Cogn. Comput.},
  title        = {Unmasking GAN-generated faces with optimal deep learning and cognitive computing-based cutting-edge detection system},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitive intelligent decisions for big data and cloud
computing in industrial applications using trifold algorithms.
<em>CC</em>, <em>16</em>(6), 2967–2981. (<a
href="https://doi.org/10.1007/s12559-024-10317-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contemporary real-time applications, diminutive devices are increasingly employing a greater portion of the spectrum to transmit data despite the relatively small size of said data. The demand for big data in cloud storage networks is on the rise, as cognitive networks can enable intelligent decision-making with minimal spectrum utilization. The introduction of cognitive networks has facilitated the provision of a novel channel that enables the allocation of low power resources while minimizing path loss. The proposed method involves the integration of three algorithms to examine the process of big data. Whenever big data applications are examined then distance measurement, decisions mechanism and learning techniques from past data is much importance thus algorithms are chosen according to the requirements of big data and cloud storage networks. Further the effect of integration process is examined with three case studies that considers low resource, path loss and weight functions where optimized outcome is achieved in all defined case studies as compared to existing approach.},
  archive      = {J_CC},
  author       = {Selvarajan, Shitharth and Manoharan, Hariprasath and Alsowail, Rakan A. and Shankar, Achyut and Pandiaraj, Saravanan and Maple, Carsten and Viriyasitavat, Wattana},
  doi          = {10.1007/s12559-024-10317-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2967-2981},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive intelligent decisions for big data and cloud computing in industrial applications using trifold algorithms},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal generative DeepFake detection via
visual-language pretraining with gate fusion for cognitive computation.
<em>CC</em>, <em>16</em>(6), 2953–2966. (<a
href="https://doi.org/10.1007/s12559-024-10316-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of deep learning, there has been a notable increase in the prevalence of multimodal deepfake content. These deepfakes pose a substantial risk to both individual privacy and the security of their assets. In response to this pressing issue, researchers have undertaken substantial endeavors in utilizing generative AI and cognitive computation to leverage multimodal data to detect deepfakes. However, the efforts thus far have fallen short of fully exploiting the extensive reservoir of multimodal feature information, which leads to a deficiency in leveraging spatial information across multiple dimensions. In this study, we introduce a framework called Visual-Language Pretraining with Gate Fusion (VLP-GF), designed to identify multimodal deceptive content and enhance the accurate localization of manipulated regions within both images and textual annotations. Specifically, we introduce an adaptive fusion module tailored to integrate local and global information simultaneously. This module captures global context and local details concurrently, thereby improving the performance of image bounding-box grounding within the system. Additionally, to maximize the utilization of semantic information from diverse modalities, we incorporate a gating mechanism to strengthen the interaction of multimodal information further. Through a series of ablation experiments and comprehensive comparisons with state-of-the-art approaches on extensive benchmark datasets, we empirically demonstrate the superior efficacy of VLP-GF.},
  archive      = {J_CC},
  author       = {Zhang, Guisheng and Gao, Mingliang and Li, Qilei and Zhai, Wenzhe and Jeon, Gwanggil},
  doi          = {10.1007/s12559-024-10316-x},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2953-2966},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-modal generative DeepFake detection via visual-language pretraining with gate fusion for cognitive computation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pruning deep neural networks for green energy-efficient
models: A survey. <em>CC</em>, <em>16</em>(6), 2931–2952. (<a
href="https://doi.org/10.1007/s12559-024-10313-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, larger and deeper neural network models, particularly convolutional neural networks (CNNs), have consistently advanced state-of-the-art performance across various disciplines. Yet, the computational demands of these models have escalated exponentially. Intensive computations hinder not only research inclusiveness and deployment on resource-constrained devices, such as Edge Internet of Things (IoT) devices, but also result in a substantial carbon footprint. Green deep learning has emerged as a research field that emphasizes energy consumption and carbon emissions during model training and inference, aiming to innovate with light and energy-efficient neural networks. Various techniques are available to achieve this goal. Studies show that conventional deep models often contain redundant parameters that do not alter outcomes significantly, underpinning the theoretical basis for model pruning. Consequently, this timely review paper seeks to systematically summarize recent breakthroughs in CNN pruning methods, offering necessary background knowledge for researchers in this interdisciplinary domain. Secondly, we spotlight the challenges of current model pruning methods to inform future avenues of research. Additionally, the survey highlights the pressing need for the development of innovative metrics to effectively balance diverse pruning objectives. Lastly, it investigates pruning techniques oriented towards sophisticated deep learning models, including hybrid feedforward CNNs and long short-term memory (LSTM) recurrent neural networks, a field ripe for exploration within green deep learning research.},
  archive      = {J_CC},
  author       = {Tmamna, Jihene and Ayed, Emna Ben and Fourati, Rahma and Gogate, Mandar and Arslan, Tughrul and Hussain, Amir and Ayed, Mounir Ben},
  doi          = {10.1007/s12559-024-10313-0},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2931-2952},
  shortjournal = {Cogn. Comput.},
  title        = {Pruning deep neural networks for green energy-efficient models: A survey},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel multimodal generative learning model based on basic
fuzzy concepts. <em>CC</em>, <em>16</em>(6), 2916–2930. (<a
href="https://doi.org/10.1007/s12559-024-10336-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal models are designed to process different types of data within a single generative framework. The prevalent strategy in previous methods involves learning joint representations that are shared across different modalities. These joint representations are typically obtained by concatenating the top of layers of modality-specific networks. Recently, significant advancements have been made in generating images from text and vice versa. Despite these successes, current models often overlook the role of fuzzy concepts, which are crucial given that human cognitive processes inherently involve a high degree of fuzziness. Recognizing and incorporating fuzzy concepts is therefore essential for enhancing the effectiveness of multimodal cognition models. In this paper, a novel framework, named the Fuzzy Concept Learning Model (FCLM), is proposed to process modalities based on fuzzy concepts. The high-level abstractions between different modalities in the FCLM are represented by the ‘fuzzy concept functions.’ After training, the FCLM is capable of generating images from attribute descriptions and inferring the attributes of input images. Additionally, it can formulate fuzzy concepts at various levels of abstraction. Extensive experiments were conducted on the dSprites and 3D Chairs datasets. Both qualitative and quantitative results from these experiments demonstrate the effectiveness and efficiency of the proposed framework. The FCLM integrates the fuzzy cognitive mechanism with the statistical characteristics of the environment. This innovative cognition-inspired framework offers a novel perspective for processing multimodal information.},
  archive      = {J_CC},
  author       = {Sheng, Huankun and Mo, Hongwei and Zhang, Tengteng},
  doi          = {10.1007/s12559-024-10336-7},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2916-2930},
  shortjournal = {Cogn. Comput.},
  title        = {A novel multimodal generative learning model based on basic fuzzy concepts},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image retrieval using multilayer feature aggregation
histogram. <em>CC</em>, <em>16</em>(6), 2902–2915. (<a
href="https://doi.org/10.1007/s12559-024-10334-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregating the diverse features into a compact representation is a hot issue in image retrieval. However, aggregating the differential feature of multilayer into a discriminative representation remains challenging. Inspired by the value-guided neural mechanisms, a novel representation method, namely, the multilayer feature aggregation histogram was proposed to image retrieval. It can aggregate multilayer features, such as low-, mid-, and high-layer features, into a discriminative yet compact representation via simulating the neural mechanisms that mediate the ability to make value-guided decisions. The highlights of the proposed method have the following: (1) A detail-attentive map was proposed to represent the aggregation of low- and mid-layer features. It can be well used to evaluate the distinguishable detail feature. (2) A simple yet straightforward aggregation method is proposed to re-evaluate the distinguishable high-layer feature. It can provide aggregated features including detail, object, and semantic by using semantic-attentive map. (3) A novel whitening method, namely difference whitening, is introduced to reduce dimensionality. It did not need to seek a training dataset of semantical similarity and can provide a compact yet discriminative representation. Experiments on the popular benchmark datasets demonstrate the proposed method can obviously increase retrieval performance in terms of mAP metric. The proposed method using 128-dimensionality representation can provide significantly higher mAPs than the DSFH, DWDF, and OSAH methods by 0.083, 0.043, and 0.022 on the Oxford5k dataset and by 0.195, 0.036, and 0.071 on the Paris6k dataset. The difference whitening method can conveniently transfer the deep learning model to a new task. Our method provided competitive performance compared with the existing aggregation methods and can retrieve scene images with similar colors, objects, and semantics.},
  archive      = {J_CC},
  author       = {Lu, Fen and Liu, Guang-Hai and Gao, Xiao-Zhi},
  doi          = {10.1007/s12559-024-10334-9},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2902-2915},
  shortjournal = {Cogn. Comput.},
  title        = {Image retrieval using multilayer feature aggregation histogram},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced dynamic key-value memory networks for personalized
student modeling and learning ability classification. <em>CC</em>,
<em>16</em>(6), 2878–2901. (<a
href="https://doi.org/10.1007/s12559-024-10341-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) is a technique that can be applied to predict students’ current skill mastery levels and future academic performance based on previous question-answering data. A good KT model can more accurately reflect a student’s cognitive processes and provide a more realistic assessment of skill mastery level. Currently, most KT models regard all students as a whole, while ignoring their personal differences; a few KT models attempt to personalize the modeling of students from the perspective of their learning abilities, among which a typical example is Deep Knowledge Tracing with Dynamic Student Classification (DKT-DSC). However, these models have a relatively coarse-grained approach to modeling students’ learning abilities and cannot accurately capture the nonlinear relationship between students’ learning abilities and the questions they answer. To solve these problems, we propose a novel KT model named the Enhanced Dynamic Key-Value Memory Networks for Dynamic Student Classification (EnDKVMN-DSC). This model is specifically designed for personalized student modeling and learning ability classification. Specifically, first, we propose a novel Enhanced Dynamic Key-Value Memory Network (EnDKVMN) and use it to model each student’s learning ability. Second, students are classified according to their learning abilities based on the K-means algorithm. Finally, the enriched input features are constructed and passed through Gated Recurrent Unit (GRU) networks to obtain prediction results. All experiments are conducted on four real-world datasets to evaluate our proposed model, and the results show that EnDKVMN-DSC outperforms the other four state-of-the-art KT models based on DKT or DKVMN in predicting student performance.},
  archive      = {J_CC},
  author       = {Zhang, Huanhuan and Wang, Lei and Qu, Yuxian and Li, Wei and Jiang, Qiaoyong},
  doi          = {10.1007/s12559-024-10341-w},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2878-2901},
  shortjournal = {Cogn. Comput.},
  title        = {Enhanced dynamic key-value memory networks for personalized student modeling and learning ability classification},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scrutinizing label: Contrastive learning on label semantics
and enriched representation for relation extraction. <em>CC</em>,
<em>16</em>(6), 2863–2877. (<a
href="https://doi.org/10.1007/s12559-024-10338-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentence-level relation extraction is a technique for extracting factual information about relationships between entities from a sentence. However, the customary method overlooks the semantic information conveyed by the label itself, thereby compromising the efficacy of rare types. Furthermore, there is a growing interest in exploring the use of textual information as a crucial resource to enhance RE models for more effectiveness. To address these two issues, CLERE (Contrastive Learning and Enriched Representation for Relation Extraction) based on contrastive learning and enriched representation of context is proposed. Firstly, by contrastive learning to incorporate semantic information of labels, CLERE is able to effectively convey and exploit the underlying semantics of various sample categories. Thereby enhancing its semantics understanding and classification capabilities, the issue of misclassification due to data imbalance is alleviated. Secondly, both semantics of context and positional information of tagged entities are enhanced by employing weighted layer pooling on pre-trained language models, which improves the representation of context and entity mentions. Experiments are conducted on three public dataset to authenticate the effectiveness of CLERE. The results demonstrate that the proposed model outperforms existing mainstream baseline methods significantly.},
  archive      = {J_CC},
  author       = {Zhou, Zhenyu and Zhang, Qinghua and Zhao, Fan},
  doi          = {10.1007/s12559-024-10338-5},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2863-2877},
  shortjournal = {Cogn. Comput.},
  title        = {Scrutinizing label: Contrastive learning on label semantics and enriched representation for relation extraction},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shift-reduce task-oriented semantic parsing with
stack-transformers. <em>CC</em>, <em>16</em>(6), 2846–2862. (<a
href="https://doi.org/10.1007/s12559-024-10339-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent voice assistants, such as Apple Siri and Amazon Alexa, are widely used nowadays. These task-oriented dialogue systems require a semantic parsing module in order to process user utterances and understand the action to be performed. This semantic parsing component was initially implemented by rule-based or statistical slot-filling approaches for processing simple queries; however, the appearance of more complex utterances demanded the application of shift-reduce parsers or sequence-to-sequence models. Although shift-reduce approaches were initially considered the most promising option, the emergence of sequence-to-sequence neural systems has propelled them to the forefront as the highest-performing method for this particular task. In this article, we advance the research on shift-reduce semantic parsing for task-oriented dialogue. We implement novel shift-reduce parsers that rely on Stack-Transformers. This framework allows to adequately model transition systems on the transformer neural architecture, notably boosting shift-reduce parsing performance. Furthermore, our approach goes beyond the conventional top-down algorithm: we incorporate alternative bottom-up and in-order transition systems derived from constituency parsing into the realm of task-oriented parsing. We extensively test our approach on multiple domains from the Facebook TOP benchmark, improving over existing shift-reduce parsers and state-of-the-art sequence-to-sequence models in both high-resource and low-resource settings. We also empirically prove that the in-order algorithm substantially outperforms the commonly used top-down strategy. Through the creation of innovative transition systems and harnessing the capabilities of a robust neural architecture, our study showcases the superiority of shift-reduce parsers over leading sequence-to-sequence methods on the main benchmark.},
  archive      = {J_CC},
  author       = {Fernández-González, Daniel},
  doi          = {10.1007/s12559-024-10339-4},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2846-2862},
  shortjournal = {Cogn. Comput.},
  title        = {Shift-reduce task-oriented semantic parsing with stack-transformers},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prescribed-time sampled-data control for the bipartite
consensus of linear multi-agent systems in singed networks. <em>CC</em>,
<em>16</em>(6), 2833–2845. (<a
href="https://doi.org/10.1007/s12559-024-10319-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article examines the prescribed-time sampled-data control problem for multi-agent systems in signed networks. A time-varying high gain-based protocol is devised to solve the prescribed-time bipartite consensus problem of the linear multi-agent systems with the control gain matrix being resolved through the utilization of the parametric Lyapunov equation. By using the method of scalarization, sufficient conditions are attained to ensure the prescribed-time bipartite consensus of linear multi-agent systems, where the maximum allowable sampling interval (MASI) ensuring the prescribed-time consensus is determined by the initial values of the system state, the linear dynamics of the system, and the maximum eigenvalue of the Laplacian matrix. Specifically, the MASI is inversely proportional to the maximum eigenvalue of the Laplacian matrix. Finally, the validity of the conclusion is ensured through numerical simulation.},
  archive      = {J_CC},
  author       = {Liu, Mengke and Zhang, Wenbing and Wu, Guanglei},
  doi          = {10.1007/s12559-024-10319-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2833-2845},
  shortjournal = {Cogn. Comput.},
  title        = {Prescribed-time sampled-data control for the bipartite consensus of linear multi-agent systems in singed networks},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Internet of things for emotion care: Advances, applications,
and challenges. <em>CC</em>, <em>16</em>(6), 2812–2832. (<a
href="https://doi.org/10.1007/s12559-024-10327-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Xu, Xu and Fu, Chong and Camacho, David and Park, Jong Hyuk and Chen, Junxin},
  doi          = {10.1007/s12559-024-10327-8},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2812-2832},
  shortjournal = {Cogn. Comput.},
  title        = {Internet of things for emotion care: Advances, applications, and challenges},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards long-term remembering in federated continual
learning. <em>CC</em>, <em>16</em>(6), 2803–2811. (<a
href="https://doi.org/10.1007/s12559-024-10314-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Continual Learning (FCL) involves learning from distributed data on edge devices with incremental knowledge. However, current FCL methods struggle to retain long-term memories on the server. In this paper, we introduce a method called Fisher INformation Accumulation Learning (FINAL) to address catastrophic forgetting in FCL. First, we accumulate a global Fisher with a federated Fisher information matrix formed from clients task by task to remember long-term knowledge. Second, we present a novel multi-node collaborative integration strategy to assemble the federated Fisher, which reveals the task-specific co-importance of parameters among clients. Finally, we raise a Fisher balancing method to combine the global Fisher and federated Fisher, avoiding neglecting new learning or causing catastrophic forgetting. We conducted evaluations on four FCL datasets, and the findings demonstrate that the proposed FINAL effectively maintains long-term knowledge on the server. The exceptional performance of this method indicates its significant value for future FCL research.},
  archive      = {J_CC},
  author       = {Zhao, Ziqin and Lyu, Fan and Li, Linyan and Hu, Fuyuan and Gu, Minming and Sun, Li},
  doi          = {10.1007/s12559-024-10314-z},
  journal      = {Cognitive Computation},
  month        = {11},
  number       = {6},
  pages        = {2803-2811},
  shortjournal = {Cogn. Comput.},
  title        = {Towards long-term remembering in federated continual learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NeuralPMG: A neural polyphonic music generation system based
on machine learning algorithms. <em>CC</em>, <em>16</em>(5), 2779–2802.
(<a href="https://doi.org/10.1007/s12559-024-10280-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The realm of music composition, augmented by technological advancements such as computers and related equipment, has undergone significant evolution since the 1970s. In the field algorithmic composition, however, the incorporation of artificial intelligence (AI) in sound generation and combination has been limited. Existing approaches predominantly emphasize sound synthesis techniques, with no music composition systems currently employing Nicolas Slonimsky’s theoretical framework. This article introduce NeuralPMG, a computer-assisted polyphonic music generation framework based on a Leap Motion (LM) device, machine learning (ML) algorithms, and brain-computer interface (BCI). ML algorithms are employed to classify user’s mental states into two categories: focused and relaxed. Interaction with the LM device allows users to define a melodic pattern, which is elaborated in conjunction with the user’s mental state as detected by the BCI to generate polyphonic music. NeuralPMG was evaluated through a user study that involved 19 students of Electronic Music Laboratory at a music conservatory, all of whom are active in the music composition field. The study encompassed a comprehensive analysis of participant interaction with NeuralPMG. The compositions they created during the study were also evaluated by two domain experts who addressed their aesthetics, innovativeness, elaboration level, practical applicability, and emotional impact. The findings indicate that NeuralPMG represents a promising tool, offering a simplified and expedited approach to music composition, and thus represents a valuable contribution to the field of algorithmic music composition.},
  archive      = {J_CC},
  author       = {Colafiglio, Tommaso and Ardito, Carmelo and Sorino, Paolo and Lofù, Domenico and Festa, Fabrizio and Di Noia, Tommaso and Di Sciascio, Eugenio},
  doi          = {10.1007/s12559-024-10280-6},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2779-2802},
  shortjournal = {Cogn. Comput.},
  title        = {NeuralPMG: A neural polyphonic music generation system based on machine learning algorithms},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The duo of visual servoing and deep learning-based methods
for situation-aware disaster management: A comprehensive review.
<em>CC</em>, <em>16</em>(5), 2756–2778. (<a
href="https://doi.org/10.1007/s12559-024-10290-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) have become essential in disaster management due to their ability to provide real-time situational awareness and support decision-making processes. Visual servoing, a technique that uses visual feedback to control the motion of a robotic system, has been used to improve the precision and accuracy of UAVs in disaster scenarios. The study integrates visual servoing to enhance UAV precision while exploring recent advancements in deep learning. This integration enhances the precision and efficiency of disaster response by enabling UAVs to navigate complex environments, identify critical areas for intervention, and provide actionable insights to decision-makers in real time. It discusses disaster management aspects like search and rescue, damage assessment, and situational awareness, while also analyzing the challenges associated with integrating visual servoing and deep learning into UAVs. This review article provides a comprehensive analysis to offer real-time situational awareness and decision support in disaster management. It highlights that deep learning along with visual servoing enhances precision and accuracy in disaster scenarios. The analysis also summarizes the challenges and the need for high computational power, data processing, and communication capabilities. UAVs, especially when combined with visual servoing and deep learning, play a crucial role in disaster management. The review underscores the potential benefits and challenges of integrating these technologies, emphasizing their significance in improving disaster response and recovery, with possible means of enhanced situational awareness and decision-making.},
  archive      = {J_CC},
  author       = {Jagatheesaperumal, Senthil Kumar and Hassan, Mohammad Mehedi and Hassan, Md. Rafiul and Fortino, Giancarlo},
  doi          = {10.1007/s12559-024-10290-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2756-2778},
  shortjournal = {Cogn. Comput.},
  title        = {The duo of visual servoing and deep learning-based methods for situation-aware disaster management: A comprehensive review},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synergy of human-centered AI and cyber-physical-social
systems for enhanced cognitive situation awareness: Applications,
challenges and opportunities. <em>CC</em>, <em>16</em>(5), 2735–2755.
(<a href="https://doi.org/10.1007/s12559-024-10271-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the convergence of Human-Centered AI (HCAI) and Cyber-Physical Social Systems (CPSS) in pursuing advanced Cognitive Situation Awareness (CSA). Integrating HCAI principles within CPSS fosters systems prioritizing human needs, values, and experiences, improving perception, understanding, and responsiveness to complex environments. By incorporating transparency, interpretability, and usability into Artificial Intelligence (AI) systems, the human-centered approach enhances user interaction and cooperation with intelligent systems, leading to more adaptive and efficient CPSS. The study employs a comprehensive approach to explore the intersection of HCAI and CPSS. Moreover, the paper presents case studies to illustrate real-world applications of HCAI and CPSS, such as self-driving cars and smart homes, transportation, healthcare, energy management, social media, and emergency response systems. Nevertheless, technical complexities, privacy concerns, and regulatory considerations must be addressed. The paper demonstrates the practical implications of integrating HCAI into CPSS through case studies in various domains. Furthermore, It highlights the positive impact of CSA systems such as self-driving cars, showcasing improvements in transportation. This paper contributes to advancing CSA and designing intelligent systems, promoting human–machine collaboration and societal well-being. By examining the intersection of HCAI and CPSS, this study advances research in CSA and designing intelligent systems prioritizing human needs, values, and experiences.},
  archive      = {J_CC},
  author       = {Alsamhi, Saeed Hamood and Kumar, Santosh and Hawbani, Ammar and Shvetsov, Alexey V. and Zhao, Liang and Guizani, Mohsen},
  doi          = {10.1007/s12559-024-10271-7},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2735-2755},
  shortjournal = {Cogn. Comput.},
  title        = {Synergy of human-centered AI and cyber-physical-social systems for enhanced cognitive situation awareness: Applications, challenges and opportunities},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A perceived risk index leveraging social media data:
Assessing severity of fire on microblogging. <em>CC</em>,
<em>16</em>(5), 2724–2734. (<a
href="https://doi.org/10.1007/s12559-024-10266-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fires represent a significant threat to the environment, infrastructure, and human safety, often spreading rapidly with wide-ranging consequences such as economic losses and life risks. Early detection and swift response to fire outbreaks are crucial to mitigating their impact. While satellite-based monitoring is effective, it may miss brief or indoor fires. This paper introduces a novel Perceived Risk Index (PRI) that, complementing satellite data, leverages social media data to provide insights into the severity of fire events. In the light of the results of statistical analysis, the PRI incorporates the number of fire-related tweets and the associated emotional expressions to gauge the perceived risk. The index’s evaluation involves the development of a comprehensive system that collects, classifies, annotates, and correlates social media posts with satellite data, presenting the findings in an interactive dashboard. Experimental results using diverse datasets of real-fire tweets demonstrate an average best correlation of 77% between PRI and the brightness values of fires detected by satellites. This correlation extends to the real intensity of the corresponding fires, showcasing the potential of social media platforms in furnishing information for emergency response and decision-making. The proposed PRI proves to be a valuable tool for ongoing monitoring efforts, having the potential to capture data on fires missed by satellites. This contributes to the development to more effective strategies for mitigating the environmental, infrastructural, and safety impacts of fire events.},
  archive      = {J_CC},
  author       = {De Maio, Carmen and Fenza, Giuseppe and Gallo, Mariacristina and Loia, Vincenzo and Volpe, Alberto},
  doi          = {10.1007/s12559-024-10266-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2724-2734},
  shortjournal = {Cogn. Comput.},
  title        = {A perceived risk index leveraging social media data: Assessing severity of fire on microblogging},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identity, gender, age, and emotion recognition from speaker
voice with multi-task deep networks for cognitive robotics. <em>CC</em>,
<em>16</em>(5), 2713–2723. (<a
href="https://doi.org/10.1007/s12559-023-10241-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a study on the use of multi-task neural networks (MTNs) for voice-based soft biometrics recognition, e.g., gender, age, and emotion, in social robots. MTNs enable efficient analysis of audio signals for various tasks on low-power embedded devices, thus eliminating the need for cloud-based solutions that introduce network latency. However, the strict dataset requirements for training limit the potential of MTNs, which are commonly used to optimize a single reference problem. In this paper, we propose three MTN architectures with varying accuracy-complexity trade-offs for voice-based soft biometrics recognition. In addition, we adopt a learnable voice representation, that allows to adapt the specific cognitive robotics application to the environmental conditions. We evaluate the performance of these models on standard large-scale benchmarks, and our results show that the proposed architectures outperform baseline models for most individual tasks. Furthermore, one of our proposed models achieves state-of-the-art performance on three out of four of the considered benchmarks. The experimental results demonstrate that the proposed MTNs have the potential for being part of effective and efficient voice-based soft biometrics recognition in social robots.},
  archive      = {J_CC},
  author       = {Foggia, Pasquale and Greco, Antonio and Roberto, Antonio and Saggese, Alessia and Vento, Mario},
  doi          = {10.1007/s12559-023-10241-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2713-2723},
  shortjournal = {Cogn. Comput.},
  title        = {Identity, gender, age, and emotion recognition from speaker voice with multi-task deep networks for cognitive robotics},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Person re-identification with spatial multi-granularity
feature exploration for social risk situational assessment. <em>CC</em>,
<em>16</em>(5), 2701–2712. (<a
href="https://doi.org/10.1007/s12559-024-10249-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the “human-oriented” concept of security development has become a consensus among all countries. This depends mainly on intelligent surveillance systems that can support person re-identification (Re-ID) technology to empower social risk situational assessment applications. However, existing Re-ID methods mainly focus on single and fixed convolutional operations for feature extraction, ignoring the multi-dimensional spatial association of the human body, which limits the performance of Re-ID. Human cognition when identifying people does not solely rely on visual cues of the individual in sight, but also on his/her behavioral and gestural characteristics. To solve this issue and inspired by the aforementioned cognitive mechanism of the human brain, this study developed a spatial multi-granularity feature exploration (SMGFE) model for person Re-ID. The proposed SMGFE model comprises two main steps: (i) a multi-granularity feature exploration strategy and (ii) a human spatial association scheme. The former mainly includes coarse (original person images), medium (multi-regional divided person images), and fine-tuned (keypoints of the human body) level features, which form the multi-granularity feature representation. An undirected graph model was then developed to construct multi-dimensional spatial relations for each person. Finally, the unified optimization strategy was applied to train the framework to achieve promising accuracy. We evaluated the proposed algorithm on frequently used and benchmark person Re-ID datasets (Market-1501 and DukeMTMC-reID). The cumulative match curve (CMC) and mean average precision (mAP), which are the common measuring criteria for most person Re-ID methods reported to date, were used to verify the experimental results. Experiments show that our proposed algorithm achieved unrivaled performance levels. In addition, based on the spatial multi-granularity feature exploration strategy, the time efficiency of the proposed method for detecting specific instances can reach O(n), making it suitable for deployment in low-resource terminals for security risk assessment, including Android/iOS analysis servers, urban safety risk surveillance systems, and warning platforms for situational awareness.},
  archive      = {J_CC},
  author       = {Xiong, Mingfu and Chen, Hanmei and Wen, Yi and Saudagar, Abdul Khader Jilani and Del Ser, Javier and Muhammad, Khan},
  doi          = {10.1007/s12559-024-10249-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2701-2712},
  shortjournal = {Cogn. Comput.},
  title        = {Person re-identification with spatial multi-granularity feature exploration for social risk situational assessment},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterfactual explanations in the big picture: An approach
for process prediction-driven job-shop scheduling optimization.
<em>CC</em>, <em>16</em>(5), 2674–2700. (<a
href="https://doi.org/10.1007/s12559-024-10294-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a pioneering framework for generating multi-objective counterfactual explanations in job-shop scheduling contexts, combining predictive process monitoring with advanced mathematical optimization techniques. Using the Non-dominated Sorting Genetic Algorithm II (NSGA-II) for multi-objective optimization, our approach enhances the generation of counterfactual explanations that illuminate potential enhancements at both the operational and systemic levels. Validated with real-world data, our methodology underscores the superiority of NSGA-II in crafting pertinent and actionable counterfactual explanations, surpassing traditional methods in both efficiency and practical relevance. This work advances the domains of explainable artificial intelligence (XAI), predictive process monitoring, and combinatorial optimization, providing an effective tool for improving automated scheduling systems’ clarity, and decision-making capabilities.},
  archive      = {J_CC},
  author       = {Mehdiyev, Nijat and Majlatow, Maxim and Fettke, Peter},
  doi          = {10.1007/s12559-024-10294-0},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2674-2700},
  shortjournal = {Cogn. Comput.},
  title        = {Counterfactual explanations in the big picture: An approach for process prediction-driven job-shop scheduling optimization},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ConceptGlassbox: Guided concept-based explanation for deep
neural networks. <em>CC</em>, <em>16</em>(5), 2660–2673. (<a
href="https://doi.org/10.1007/s12559-024-10262-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various industries and fields have utilized machine learning models, particularly those that demand a significant degree of accountability and transparency. With the introduction of the General Data Protection Regulation (GDPR), it has become imperative for machine learning model predictions to be both plausible and verifiable. One approach to explaining these predictions involves assigning an importance score to each input element. Another category aims to quantify the importance of human-understandable concepts to explain global and local model behaviours. The way concepts are constructed in such concept-based explanation techniques lacks inherent interpretability. Additionally, the magnitude and diversity of the discovered concepts make it difficult for machine learning practitioners to comprehend and make sense of the concept space. To this end, we introduce ConceptGlassbox, a novel local explanation framework that seeks to learn high-level transparent concept definitions. Our approach leverages human knowledge and feedback to facilitate the acquisition of concepts with minimal human labelling effort. The ConceptGlassbox learns concepts consistent with the user’s understanding of a concept’s meaning. It then dissects the evidence for the prediction by identifying the key concepts the black-box model uses to arrive at its decision regarding the instance being explained. Additionally, ConceptGlassbox produces counterfactual explanations, proposing the smallest changes to the instance’s concept-based explanation that would result in a counterfactual decision as specified by the user. Our systematic experiments confirm that ConceptGlassbox successfully discovers relevant and comprehensible concepts that are important for neural network predictions.},
  archive      = {J_CC},
  author       = {El Shawi, Radwa},
  doi          = {10.1007/s12559-024-10262-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2660-2673},
  shortjournal = {Cogn. Comput.},
  title        = {ConceptGlassbox: Guided concept-based explanation for deep neural networks},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An eXplainable artificial intelligence methodology on big
data architecture. <em>CC</em>, <em>16</em>(5), 2642–2659. (<a
href="https://doi.org/10.1007/s12559-024-10272-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although artificial intelligence has become part of everyone’s real life, a trust crisis against such systems is occurring, thus increasing the need to explain black-box predictions, especially in the military, medical, and financial domains. Modern eXplainable Artificial Intelligence (XAI) techniques focus on benchmark datasets, but the cognitive applicability of such solutions under big data settings is still unclear due to memory or computation constraints. In this paper, we extend a model-agnostic XAI methodology, named Cluster-Aided Space Transformation for Local Explanation (CASTLE), to be able to deal with high-volume datasets. CASTLE aims to explain the black-box behavior of predictive models by combining both local (i.e., based on the input sample) and global (i.e., based on the whole scope for action of the model) information. In particular, the local explanation provides a rule-based explanation for the prediction of a target instance as well as the directions to update the likelihood of the predicted class. Our extension leverages modern big data technologies (e.g., Apache Spark) to handle the high volume, variety, and velocity of huge datasets. We have evaluated the framework on five datasets, in terms of temporal efficiency, explanation quality, and model significance. Our results indicate that the proposed approach retains the high-quality explanations associated with CASTLE while efficiently handling large datasets. Importantly, it exhibits a sub-linear, rather than exponential, dependence on dataset size, making it a scalable solution for massive datasets or in any big data scenario.},
  archive      = {J_CC},
  author       = {La Gatta, Valerio and Moscato, Vincenzo and Postiglione, Marco and Sperlì, Giancarlo},
  doi          = {10.1007/s12559-024-10272-6},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2642-2659},
  shortjournal = {Cogn. Comput.},
  title        = {An eXplainable artificial intelligence methodology on big data architecture},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SPEI-FL: Serverless privacy edge intelligence-enabled
federated learning in smart healthcare systems. <em>CC</em>,
<em>16</em>(5), 2626–2641. (<a
href="https://doi.org/10.1007/s12559-024-10310-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart healthcare systems promise significant benefits for fast and accurate medical decisions. However, working with personal health data presents new privacy issues and constraints that must be solved from a cybersecurity perspective. Edge intelligence-enabled federated learning is a new scheme that utilises decentralised computing that allows data analytics to be carried out at the edge of a network, enhancing data privacy. However, this scheme suffers from privacy attacks, including inference, free-riding, and man-in-the-middle attacks, especially with serverless computing for allocating resources to user needs. Edge intelligence-enabled federated learning requires client data insertion and deletion to authenticate genuine clients and a serverless computing capability to ensure the security of collaborative machine learning models. This work introduces a serverless privacy edge intelligence-based federated learning (SPEI-FL) framework to address these issues. SPEI-FL includes a federated edge aggregator and authentication method to improve the data privacy of federated learning and allow client adaptation and removal without impacting the overall learning processes. It also can classify intruders through serverless computing processes. The proposed framework was evaluated with the unstructured COVID-19 medical chest x-rays and MNIST digit datasets, and the structured BoT-IoT dataset. The performance of the framework is comparable with existing authentication methods and reported a higher accuracy than comparable methods (approximately 90% as compared with the 81% reported by peer methods). The proposed authentication method prevents the exposure of sensitive patient information during medical device authentication and would become the cornerstone of the next generation of medical security with serverless computing.},
  archive      = {J_CC},
  author       = {Akter, Mahmuda and Moustafa, Nour and Turnbull, Benjamin},
  doi          = {10.1007/s12559-024-10310-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2626-2641},
  shortjournal = {Cogn. Comput.},
  title        = {SPEI-FL: Serverless privacy edge intelligence-enabled federated learning in smart healthcare systems},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative AI and cognitive computing-driven intrusion
detection system in industrial CPS. <em>CC</em>, <em>16</em>(5),
2611–2625. (<a
href="https://doi.org/10.1007/s12559-024-10309-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Cyber-Physical Systems (ICPSs) are becoming more and more networked and essential to modern infrastructure. This has led to an increase in the complexity of their dynamics and the challenges of protecting them from advanced cyber threats have escalated. Conventional intrusion detection systems (IDS) often struggle to interpret high-dimensional, sequential data efficiently and extract meaningful features. They are characterized by low accuracy and a high rate of false positives. In this article, we adopt the computational design science approach to design an IDS for ICPS, driven by Generative AI and cognitive computing. Initially, we designed a Long Short-Term Memory-based Sparse Variational Autoencoder (LSTM-SVAE) technique to extract relevant features from complex data patterns efficiently. Following this, a Bidirectional Recurrent Neural Network with Hierarchical Attention (BiRNN-HAID) is constructed. This stage focuses on proficiently identifying potential intrusions by processing data with enhanced focus and memory capabilities. Next, a Cognitive Enhancement for Contextual Intrusion Awareness (CE-CIA) is designed to refine the initial predictions by applying cognitive principles. This enhances the system’s reliability by effectively balancing sensitivity and specificity, thereby reducing false positives. The final stage, Interpretive Assurance through Activation Insights in Detection Models (IAA-IDM), involves the visualizations of mean activations of LSTM and GRU layers for providing in-depth insights into the decision-making process for cybersecurity analysts. Our framework undergoes rigorous testing on two publicly accessible industrial datasets, ToN-IoT and Edge-IIoTset, demonstrating its superiority over both baseline methods and recent state-of-the-art approaches.},
  archive      = {J_CC},
  author       = {Islam, Shareeful and Javeed, Danish and Saeed, Muhammad Shahid and Kumar, Prabhat and Jolfaei, Alireza and Islam, A. K. M. Najmul},
  doi          = {10.1007/s12559-024-10309-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2611-2625},
  shortjournal = {Cogn. Comput.},
  title        = {Generative AI and cognitive computing-driven intrusion detection system in industrial CPS},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative adversarial network-assisted framework for power
management. <em>CC</em>, <em>16</em>(5), 2596–2610. (<a
href="https://doi.org/10.1007/s12559-024-10284-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise in power consumption (PC) is caused by several factors such as the growing global population, urbanization, technological advances, economic development, and growth of businesses and commercial sectors. In these days, intermittent renewable energy sources (RESs) are widely utilized in electric grids to meet the need for power. Data-driven techniques are essential to assuring the steady operation of the electric grid and accurate power consumption and generation forecasting. Conversely, the available datasets for time series electric power forecasting in the energy industry are not as large as those for other domains such as in computer vision. Thus, a deep learning (DL) framework for predicting PC in residential and commercial buildings as well as the power generation (PG) from RESs is introduced. The raw power data obtained from buildings and RESs-based power plants are conceded by the purging process where absent values are filled in and noise and outliers are eliminated. Next, the proposed generative adversarial network (GAN) uses a portion of the cleaned data to generate synthetic parallel data, which is combined with the actual data to make a hybrid dataset. Subsequently, the stacked gated recurrent unit (GRU) model, which is optimized for power forecasting, is trained using the hybrid dataset. Six existent power data are used to train and test sixteen linear and nonlinear models for energy forecasting. The best-performing network is selected as the proposed method for forecasting tasks. For Korea Yeongam solar power (KYSP), individual household electric power consumption (IHEPC), and advanced institute of convergence technology (AICT) datasets, the proposed model obtains mean absolute error (MAE) values of 0.0716, 0.0819, and 0.0877, respectively. Similarly, its MAE values are 0.1215, 0.5093, and 0.5751, for Australia Alice Springs solar power (AASSP), Korea south east wind power (KSEWP), and, Korea south east solar power (KSESP) datasets, respectively.},
  archive      = {J_CC},
  author       = {Khan, Noman and Khan, Samee Ullah and Farouk, Ahmed and Baik, Sung Wook},
  doi          = {10.1007/s12559-024-10284-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2596-2610},
  shortjournal = {Cogn. Comput.},
  title        = {Generative adversarial network-assisted framework for power management},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision-enabled large language and deep learning models for
image-based emotion recognition. <em>CC</em>, <em>16</em>(5), 2566–2579.
(<a href="https://doi.org/10.1007/s12559-024-10281-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant advancements in the capabilities, reasoning, and efficiency of artificial intelligence (AI)-based tools and systems are evident. Some noteworthy examples of such tools include generative AI-based large language models (LLMs) such as generative pretrained transformer 3.5 (GPT 3.5), generative pretrained transformer 4 (GPT-4), and Bard. LLMs are versatile and effective for various tasks such as composing poetry, writing codes, generating essays, and solving puzzles. Thus far, LLMs can only effectively process text-based input. However, recent advancements have enabled them to handle multimodal inputs, such as text, images, and audio, making them highly general-purpose tools. LLMs have achieved decent performance in pattern recognition tasks (such as classification), therefore, there is a curiosity about whether general-purpose LLMs can perform comparable or even superior to specialized deep learning models (DLMs) trained specifically for a given task. In this study, we compared the performances of fine-tuned DLMs with those of general-purpose LLMs for image-based emotion recognition. We trained DLMs, namely, a convolutional neural network (CNN) (two CNN models were used: $$CNN_1$$ and $$CNN_2$$ ), ResNet50, and VGG-16 models, using an image dataset for emotion recognition, and then tested their performance on another dataset. Subsequently, we subjected the same testing dataset to two vision-enabled LLMs (LLaVa and GPT-4). The $$CNN_2$$ was found to be the superior model with an accuracy of 62% while VGG16 produced the lowest accuracy with 31%. In the category of LLMs, GPT-4 performed the best, with an accuracy of 55.81%. LLava LLM had a higher accuracy than $$CNN_1$$ and VGG16 models. The other performance metrics such as precision, recall, and F1-score followed similar trends. However, GPT-4 performed the best with small datasets. The poor results observed in LLMs can be attributed to their general-purpose nature, which, despite extensive pretraining, may not fully capture the features required for specific tasks like emotion recognition in images as effectively as models fine-tuned for those tasks. The LLMs did not surpass specialized models but achieved comparable performance, making them a viable option for specific tasks without additional training. In addition, LLMs can be considered a good alternative when the available dataset is small.},
  archive      = {J_CC},
  author       = {Nadeem, Mohammad and Sohail, Shahab Saquib and Javed, Laeeba and Anwer, Faisal and Saudagar, Abdul Khader Jilani and Muhammad, Khan},
  doi          = {10.1007/s12559-024-10281-5},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2566-2579},
  shortjournal = {Cogn. Comput.},
  title        = {Vision-enabled large language and deep learning models for image-based emotion recognition},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated constrastive learning and visual transformers for
personal recommendation. <em>CC</em>, <em>16</em>(5), 2551–2565. (<a
href="https://doi.org/10.1007/s12559-024-10286-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel solution for personal recommendation in consumer electronic applications. It addresses, on the one hand, the data confidentiality during the training, by exploring federated learning and trusted authority mechanisms. On the other hand, it deals with data quantity, and quality by exploring both transformers and consumer clustering. The process starts by clustering the consumers into similar clusters using contrastive learning and k-means algorithm. The local model of each consumer is trained on the local data. The local models of the consumers with the clustering information are then sent to the server, where integrity verification is performed by a trusted authority. Instead of traditional federated learning solutions, two kinds of aggregation are performed. The first one is the aggregation of all models of the consumers to derive the global model. The second one is the aggregation of the models of each cluster to derive a local model of similar consumers. Both models are sent to the consumers, where each consumer decides which appropriate model might be used for personal recommendation. Robust experiments have been carried out to demonstrate the applicability of the method using MovieLens-1M, and Amazon-book. The results reveal the superiority of the proposed method compared to the baseline methods, where it reaches an average accuracy of 0.27, against the other methods that do not exceed 0.25.},
  archive      = {J_CC},
  author       = {Belhadi, Asma and Djenouri, Youcef and de Alcantara Andrade, Fabio Augusto and Srivastava, Gautam},
  doi          = {10.1007/s12559-024-10286-0},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2551-2565},
  shortjournal = {Cogn. Comput.},
  title        = {Federated constrastive learning and visual transformers for personal recommendation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ChatGPT needs SPADE (sustainability, PrivAcy, digital
divide, and ethics) evaluation: A review. <em>CC</em>, <em>16</em>(5),
2528–2550. (<a
href="https://doi.org/10.1007/s12559-024-10285-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ChatGPT is another large language model (LLM) vastly available for the consumers on their devices but due to its performance and ability to converse effectively, it has gained a huge popularity amongst research as well as industrial community. Recently, many studies have been published to show the effectiveness, efficiency, integration, and sentiments of chatGPT and other LLMs. In contrast, this study focuses on the important aspects that are mostly overlooked, i.e. sustainability, privacy, digital divide, and ethics and suggests that not only chatGPT but every subsequent entry in the category of conversational bots should undergo Sustainability, PrivAcy, Digital divide, and Ethics (SPADE) evaluation. This paper discusses in detail the issues and concerns raised over chatGPT in line with aforementioned characteristics. We also discuss the recent EU AI Act briefly in accordance with the SPADE evaluation. We support our hypothesis by some preliminary data collection and visualizations along with hypothesized facts. We also suggest mitigations and recommendations for each of the concerns. Furthermore, we also suggest some policies and recommendations for EU AI policy act concerning ethics, digital divide, and sustainability.},
  archive      = {J_CC},
  author       = {Khowaja, Sunder Ali and Khuwaja, Parus and Dev, Kapal and Wang, Weizheng and Nkenyereye, Lewis},
  doi          = {10.1007/s12559-024-10285-1},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2528-2550},
  shortjournal = {Cogn. Comput.},
  title        = {ChatGPT needs SPADE (Sustainability, PrivAcy, digital divide, and ethics) evaluation: A review},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DFootNet: A domain adaptive classification framework for
diabetic foot ulcers using dense neural network architecture.
<em>CC</em>, <em>16</em>(5), 2511–2527. (<a
href="https://doi.org/10.1007/s12559-024-10282-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic foot ulcers (DFUs) are a prevalent and serious complication of diabetes, often leading to severe morbidity and even amputations if not timely diagnosed and managed. The increasing prevalence of DFUs poses a significant challenge to healthcare systems worldwide. Accurate and timely classification of DFUs is crucial for effective treatment and prevention of complications. In this paper, we present “DFootNet”, an innovative and comprehensive classification framework for the accurate assessment of diabetic foot ulcers using a dense neural network architecture. Our proposed approach leverages the power of deep learning to automatically extract relevant features from diverse clinical DFU images. The proposed model comprises a multi-layered dense neural network designed to handle the intricate patterns and variations present in different stages and types of DFUs. The network architecture integrates convolutional and fully connected layers, allowing for hierarchical feature extraction and robust feature representation. To evaluate the efficacy of DFootNet, we conducted experiments on a large and diverse dataset of diabetic foot ulcers. Our results demonstrate that DFootNet achieves a remarkable accuracy of 98.87%, precision—99.01%, recall—98.73%, F1-score as 98.86%, and AUC-ROC as 98.13%, outperforming existing methods in distinguishing between ulcer and non-ulcer images. Moreover, our framework provides insights into the decision-making process, offering transparency and interpretability through attention mechanisms that highlight important regions within ulcer images. We also present a comparative analysis of DFootNet’s performance against other popular deep learning models, showcasing its robustness and adaptability across various scenarios.},
  archive      = {J_CC},
  author       = {Bansal, Nishu and Vidyarthi, Ankit},
  doi          = {10.1007/s12559-024-10282-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2511-2527},
  shortjournal = {Cogn. Comput.},
  title        = {DFootNet: A domain adaptive classification framework for diabetic foot ulcers using dense neural network architecture},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transforming conversations with AI—a comprehensive study of
ChatGPT. <em>CC</em>, <em>16</em>(5), 2487–2510. (<a
href="https://doi.org/10.1007/s12559-023-10236-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of cognitive computing, conversational AI has witnessed remarkable progress, largely driven by the development of the Generative Pre-trained Transformer (GPT) series, notably ChatGPT. These transformer-based models have revolutionized natural language understanding by effectively capturing context and long-range dependencies. In light of this, this paper conducts a comprehensive exploration of ChatGPT, encompassing its architectural design, training methodology, real-world applications, and future potential within the conversational AI landscape. The paper studies the ChatGPT ability for advanced control and responsiveness, exhibiting a superior capacity for comprehending language and generating precise, informative responses. The comprehensive survey depicts ChatGPT excels in sustaining context and engaging in multi-turn dialogues, thereby fostering more interactive and meaningful conversations. Furthermore, its adaptability for integration into various systems and scalability has broadened its applicability across diverse domains, including customer service, education, content generation, healthcare, gaming, research, and exploration. Additionally, the paper presents alternative conversational AI models, such as Amazon Codewhisperer, Google Bard (LaMDA), Microsoft Bing AI, DeepMind Sparrow, and Character AI, providing a comparative analysis that underscores ChatGPT’s advantages in terms of inference capabilities and future promise. Recognizing the evolution and profound impact of ChatGPT holds paramount significance for researchers and developers at the forefront of AI innovation. In a rapidly evolving conversational AI landscape, ChatGPT emerges as a pivotal player, capable of reshaping the way we interact with AI systems across a wide array of applications.},
  archive      = {J_CC},
  author       = {Bansal, Gaurang and Chamola, Vinay and Hussain, Amir and Guizani, Mohsen and Niyato, Dusit},
  doi          = {10.1007/s12559-023-10236-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2487-2510},
  shortjournal = {Cogn. Comput.},
  title        = {Transforming conversations with AI—A comprehensive study of ChatGPT},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cognitive medical decision support system for IoT-based
human-computer interface in pervasive computing environment.
<em>CC</em>, <em>16</em>(5), 2471–2486. (<a
href="https://doi.org/10.1007/s12559-023-10242-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s advanced applications, such as memory interfaces, feature-based detection, and sensory games, human-computer interaction (HCI) plays a pivotal role. A medical decision support system (MDSS) emerges from the integration of a data system with resources for medical decision-making. Within MDSS, human-computer interaction and perceptual medical decision-making stand out as two highly valuable technologies. Systems enabled by the Internet of Things (IoT), which leverage decentralized, diverse communication and networking technology to cater to a wide range of end-users, are referred to as pervasive computing. A challenging aspect of pervasive computing is ensuring transparency in interaction, managing administration levels, and accommodating varying tolerance levels for widely dispersed users. This paper presents a uniquely flexible MDSS framework designed to enhance end-user confidence in the availability of MDSS through ubiquitous IoT devices within the context of HCI. This architecture utilizes recurring training to assess resource allocation based on demand and collaborative characteristics. Projected resource requirements enable pervasive computing to better serve end-users by reducing latency and increasing communication speeds for MDSS in HCI. The primary goal of this framework is to simplify the management of terminal transitions by facilitating the allocation and utilization of resources for data transfer from peripheral technology. Experimental analysis is employed to estimate the framework’s performance, utilizing various metrics to demonstrate its consistency. These metrics encompass responsiveness, transaction success rates, processed demands, application caseloads, capacity utilization, and memory usage. The uniquely flexible and distributed computing framework optimizes request handling, network accuracy, and memory utilization, resulting in reduced transaction failures and lower latency, ultimately leading to shorter response times. The proposed UFDSS maintains a transaction failure rate below 25% with increasing requests and achieves 100 MHz bandwidth utilization, surpassing other techniques capped at 80 MHz. UFDSS exhibits a lower average latency of around 30 ms for a range of energy data inputs. This uniquely flexible MDSS framework showcases its potential to enhance MDSS availability through IoT devices within HCI contexts. By optimizing resource allocation and utilization, it successfully reduces latency, improves communication speeds, and ultimately leads to shorter response times, contributing to more efficient and reliable medical decision support. Further, integrating generative AI into MDSS for IoT-based HCI could also enhance data-driven decision support.},
  archive      = {J_CC},
  author       = {Gou, Haosong and Zhang, Gaoyi and Medeiros, Elias Paulino and Jagatheesaperumal, Senthil Kumar and de Albuquerque, Victor Hugo C.},
  doi          = {10.1007/s12559-023-10242-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2471-2486},
  shortjournal = {Cogn. Comput.},
  title        = {A cognitive medical decision support system for IoT-based human-computer interface in pervasive computing environment},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing three-way decision of rough fuzzy sets from the
perspective of uncertainties. <em>CC</em>, <em>16</em>(5), 2454–2470.
(<a href="https://doi.org/10.1007/s12559-023-10147-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the perspective of human cognition, three-way decision (3WD) explores thinking, problem solving, and information processing in three paradigms. Rough fuzzy sets (RFS) are constructed to handle fuzzy concepts by extending the classical rough sets. In three-way decision with rough fuzzy sets (3WDRFS), current works are mainly concerned with calculating the thresholds according to the given risk parameters to make 3WD with minimum cost. However, in real applications, the risk parameters are given in a subjective way based on expert experience. As a result, the risk parameters may be difficult to accurately obtain in 3WDRFS. To solve this problem, uncertainty measure is introduced into 3WDRFS, which provides a new perspective for 3WD theory. First, the fuzziness-based uncertainty for the average-step-fuzzy sets of RFS is analyzed. Then, based on the average-step-fuzzy sets, a 3WDRFS is proposed with the idea of minimizing the uncertainty loss. Furthermore, the sequential three-way decision of RFS (S3WDRFS) with adaptive thresholds from the perspective of fuzziness is presented. The relevant experiments suggest that the objective function designed in the proposed 3WDRFS is effective and reasonable. Moreover, 3WDRFS based on uncertainty loss has better performance than 0.5-approximation model.},
  archive      = {J_CC},
  author       = {Yang, Jie and Wang, Xiaoqi and Wang, Guoyin and Xia, Deyou},
  doi          = {10.1007/s12559-023-10147-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2454-2470},
  shortjournal = {Cogn. Comput.},
  title        = {Constructing three-way decision of rough fuzzy sets from the perspective of uncertainties},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperautomation for air quality evaluations: A perspective
of evidential three-way decision-making. <em>CC</em>, <em>16</em>(5),
2437–2453. (<a
href="https://doi.org/10.1007/s12559-022-10101-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperautomation acts as a real digital transformation with the support of several cutting-edge cognitive computation methods that include robotic process automation, natural language processing, artificial intelligence, and other emerging ones, which is conducive to processing complex industrial processes via extending the range of various data-driven cognitive decision-making algorithms. The study of air quality evaluations (AQE) plays a significant role in ensuring healthy atmospheric environments. In view of the objective existence of uncertainties, AQE can be modeled and addressed by a typical data-driven automated decision-making problem, and hyperautomation can provide a reasonable solution via associating with a variety of techniques. This article explores hyperautomation for AQE via evidential three-way large-scale group decision-making (LSGDM) in an intuitionistic fuzzy (IF) setting. First, the notion of intuitionistic fuzzy sets (IFSs) is incorporated into the paradigm of multi-granularity (MG) three-way decisions (TWD), and the model of adjustable MG IF probabilistic rough sets (PRSs) is developed. Second, an IF clustering analysis with the improved technique for order preference by similarity to ideal solution (TOPSIS) method is conducted to affirm representative members within a decision group. Third, a novel IF LSGDM method is built via adjustable MG IF PRSs and the evidence reasoning (ER) method. Finally, a case study in the setting of AQE is studied by using the presented evidential three-way LSGDM method. Corresponding experimental analyses are carried out for illustrating the efficiency of hyperautomation for AQE. In general, the proposed method improves the performance of information fusion by virtue of adjustable MG IF PRSs, and the TOPSIS method avoids the influence of subjective factors on decision results. Meanwhile, the evaluation information of decision-makers (DMs) is fully analyzed by means of the ER method, which can provide more explainable decision results.},
  archive      = {J_CC},
  author       = {Ding, Juanjuan and Zhang, Chao and Li, Deyu and Sangaiah, Arun Kumar},
  doi          = {10.1007/s12559-022-10101-8},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2437-2453},
  shortjournal = {Cogn. Comput.},
  title        = {Hyperautomation for air quality evaluations: A perspective of evidential three-way decision-making},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). What AI, neuroscience, and cognitive science can learn from
each other: An embedded perspective. <em>CC</em>, <em>16</em>(5),
2428–2436. (<a
href="https://doi.org/10.1007/s12559-023-10194-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientists studying in the fields of AI and neuroscience can learn much from each other, but unfortunately, since about the 1950s, it has been mostly one-sided: neuroscientists have learned from AI, but less so the other way. I argue this is holding back both brain understanding and progress in AI. Current AI (“neural network”/deep learning algorithms) and the brain are very different from each other. The brain does not seem to use trial-and-error–type learning algorithms such as backpropagation to modify weights and more importantly does not require the cumbersome rehearsal needed for trial-and-error implementation. The brain can learn information in a modular and true “one-shot” fashion as the information is encountered while the AI cannot. Instead of backpropagation and rehearsal, there is evidence that the brain regulates its inputs during recognition using regulatory feedback: form the outputs back to inputs—the same inputs that activate the outputs. This is observed through evidence from the fields of neuroscience and cognitive psychology but is not present in current algorithms. Thus, the brain provides an abundance of evidence about its underlying algorithms and while computer science tools and analysis are essential, algorithms guided by computer science should not be standardized into neuroscience theories.},
  archive      = {J_CC},
  author       = {Achler, Tsvi},
  doi          = {10.1007/s12559-023-10194-9},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2428-2436},
  shortjournal = {Cogn. Comput.},
  title        = {What AI, neuroscience, and cognitive science can learn from each other: An embedded perspective},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convolutionary, evolutionary, and revolutionary: What’s next
for brains, bodies, and AI? <em>CC</em>, <em>16</em>(5), 2420–2427. (<a
href="https://doi.org/10.1007/s12559-023-10181-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexibility, adaptability, and resilience of even simple brains are unmatched by any current technology. Recent unexpected difficulties in realising truly autonomous vehicles, making reliable medical diagnoses, detecting offensive online content and even just recognising faces, show that brains remain significantly functionally more capable than we can currently emulate. Fittingly, in recent years we have made significant progress identifying computational principles that underlie neural function. We are beginning to dispense with the overly simplistic stimulus-driven encode/transmit/decode doctrine. Instead we must embrace the brain’s inherent dynamic complexity and emergent properties and explain how plasticity moulds the dynamics to capture useful couplings across brain regions and between the brain, the body, and the world. While certainly not complete, we have sufficient evidence that a synthesis of these ideas could result in a deeper understanding of neural computation and which could potentially be used to construct new AI technologies with unique capabilities. I discuss the relevant neuroscientific principles, the advantages they have for computation, and how they can benefit AI. Limitations of current AI are now generally recognised. I postulate that we understand enough about the brain to immediately offer novel AI formulations.},
  archive      = {J_CC},
  author       = {Stratton, Peter},
  doi          = {10.1007/s12559-023-10181-0},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2420-2427},
  shortjournal = {Cogn. Comput.},
  title        = {Convolutionary, evolutionary, and revolutionary: What’s next for brains, bodies, and AI?},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The strange and promising relationship between EEG and AI
methods of analysis. <em>CC</em>, <em>16</em>(5), 2411–2419. (<a
href="https://doi.org/10.1007/s12559-023-10142-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the utility of AI methods for classifying EEG data is widespread in research laboratories. The constant in this field of research is to find out a suite method for differentiating EEG data accurately. The principal methods of AI used in EEG data analysis are machine learning and deep learning. In this article, we explore the scope of AI in light of the results in EEG analysis data. We begin presenting the scope of computing analysis to set up the context for understanding the procedures of algorithms applied by AI to classify EEG data. Next, we review the achievements of AI classification algorithms to some cases of EEG data. With the result of this, we analyze and better understand the contribution of AI to the epistemology of neuroscience, with special regard to EEG brain imaging neuroscience. Finally, we will show some learnings from this analysis, in which we argue, emerge a fundamental lesson from AI analysis of EEG data to theoretical neuroscience, namely when it is about brain imaging, the need for convergent scientific methods rises the question about the unity of (neuro)science. This opens the possibility of multi-approaches to be the major feature of current practice of this science field. Hence, applications of current AI methods for analyzing brain functioning advance the epistemology of neuroscience to a paradigm from localizing to dynamic representation of data.},
  archive      = {J_CC},
  author       = {Garcia-Aguilar, Gregorio},
  doi          = {10.1007/s12559-023-10142-7},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2411-2419},
  shortjournal = {Cogn. Comput.},
  title        = {The strange and promising relationship between EEG and AI methods of analysis},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Re-thinking the organization of cortico-basal
ganglia-thalamo-cortical loops. <em>CC</em>, <em>16</em>(5), 2405–2410.
(<a href="https://doi.org/10.1007/s12559-023-10140-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First concepts of cortex-basal ganglia interactions suggested that cognitive functions are implemented through different parallel, segregated cortico-basal ganglia-cortical loops. Recent evidence however shows that there are at least 4 ways by which different loops could interact: overlapping cortico-pallidal projections, overlapping cortico-striatal projections, striato-nigro-striatal spirals, and cortico-thalamo-striatal projections. We propose that current evidence, if incorporated into neuro-computational models, provides new avenues for explaining cognitive functions. Using a recently introduced hierarchical neuro-computational model of multiple cortico-basal ganglia-cortical loops, we exemplify how interaction between loops can explain behavioral data linked to the ideomotor theory. During training of a stimulus–response task, a task-irrelevant tone is played after each action. Then, during a test period, the same tones are played but together with the stimuli. The model learns a distributed representation of action outcomes which is then used to select actions. Similar to observations in human subjects, the model’s response time is larger if an inconsistent tone (previously listened together with an alternative action) is played with the stimulus. Understanding the function of different communication strategies between loops could be the key to fully unravel the neural basis of the numerous functions supported by the basal ganglia. The multiple-loop structure allows for a more complex representation of behavior in which action outcomes are considered.},
  archive      = {J_CC},
  author       = {Baladron, Javier and Hamker, Fred H.},
  doi          = {10.1007/s12559-023-10140-9},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2405-2410},
  shortjournal = {Cogn. Comput.},
  title        = {Re-thinking the organization of cortico-basal ganglia-thalamo-cortical loops},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep intelligence: What AI should learn from nature’s
imagination. <em>CC</em>, <em>16</em>(5), 2389–2404. (<a
href="https://doi.org/10.1007/s12559-023-10124-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has recently seen explosive growth and remarkable successes in several application areas. However, it is becoming clear that the methods that have made this possible are subject to several limitations that might inhibit progress towards replicating the more general intelligence seen in humans and other animals. In contrast to current AI methods that focus on specific tasks and rely on large amounts of offline data and extensive, slow, and mostly supervised learning, this natural intelligence is quick, versatile, agile, and open-ended. This position paper brings together ideas from neuroscience, evolutionary and developmental biology, and complex systems to analyze why such natural intelligence is possible in animals and suggests that AI should exploit the same strategies to move in a different direction. In particular, it argues that integrated embodiment, modularity, synergy, developmental learning, and evolution are key enablers of natural intelligence and should be at the core of AI systems as well. The analysis in the paper leads to the description of a biologically grounded deep intelligence (DI) framework for understanding natural intelligence and developing a new approach to building more versatile, autonomous, and integrated AI. The paper concludes that the dominant paradigm of AI today is unlikely to lead to truly natural general intelligence and that something like the biologically inspired DI framework is needed for that.},
  archive      = {J_CC},
  author       = {Minai, Ali A.},
  doi          = {10.1007/s12559-023-10124-9},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2389-2404},
  shortjournal = {Cogn. Comput.},
  title        = {Deep intelligence: What AI should learn from nature’s imagination},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Does deep learning have epileptic seizures? On the modeling
of the brain. <em>CC</em>, <em>16</em>(5), 2382–2388. (<a
href="https://doi.org/10.1007/s12559-023-10113-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {If the development of machine learning and artificial intelligence plays a role in many fields of research and technology today, it has a special relationship with neurosciences. Indeed, historically inspired by our knowledge of the brain, deep learning shares some vocabularies with neurosciences and can sometimes be considered a brain’s model. Taking the particular example of seizure, which can develop in any biological neural tissue, we question if and how the models used for deep learning can capture or model these pathological events. This particular example is a starting point to discuss the nature, limits, and functions of these models, and we discuss what we expect from a model of the brain. Finally, we argue that a pluralistic approach leading to the integrated coexistence of different models is necessary to study the brain in all its complexity.},
  archive      = {J_CC},
  author       = {Depannemaecker, Damien and Pio-Lopez, Léo and Gauld, Christophe},
  doi          = {10.1007/s12559-023-10113-y},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2382-2388},
  shortjournal = {Cogn. Comput.},
  title        = {Does deep learning have epileptic seizures? on the modeling of the brain},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward a brain-inspired theory of artificial learning.
<em>CC</em>, <em>16</em>(5), 2374–2381. (<a
href="https://doi.org/10.1007/s12559-023-10121-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid progress made by artificial neural networks (ANNs), the design of these models makes it unlikely that incremental improvements will eventually bring them on par with human-level cognitive capabilities. Here, three fundamental shortcomings of ANNs are described, namely the strictly statistical nature of the learning process, the inability to handle universal mappings, and the lack of key structural brain features that constitute the building blocks of behavior and cognition. Solutions to these issues are discussed, including the use of few-shot learning paradigms, network architectures inspired by cytoarchitectural features of the brain, and neuromodulator-derived rules for learning and updating environmental variables. We cast these solutions in the broader context of recent discoveries about the brain. Their implementation in ANNs, however, will require a deeper understanding of the cognitome—the map between elementary cognitive functions and the patterns of neural connections that support them. We contend that to reach true human-level cognitive capabilities, ANNs require both a principled approach to extending their architecture and learning rules and a deep understanding of the cognitome linking brain structures to mental operations.},
  archive      = {J_CC},
  author       = {Thivierge, J. P. and Giraud, Éloïse and Lynn, Michael},
  doi          = {10.1007/s12559-023-10121-y},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2374-2381},
  shortjournal = {Cogn. Comput.},
  title        = {Toward a brain-inspired theory of artificial learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modularity in nervous systems—a key to efficient adaptivity
for deep reinforcement learning. <em>CC</em>, <em>16</em>(5), 2358–2373.
(<a href="https://doi.org/10.1007/s12559-022-10080-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modularity as observed in biological systems has proven valuable for guiding classical motor theories towards good answers about action selection and execution. New challenges arise when we turn to learning: Trying to scale current computational models, such as deep reinforcement learning (DRL), to action spaces, input dimensions, and time horizons seen in biological systems still faces severe obstacles unless vast amounts of training data are available. This leads to the question: does biological modularity also hold an important key for better answers to obtain efficient adaptivity for deep reinforcement learning? We review biological experimental work on modularity in biological motor control and link this with current examples of (deep) RL approaches. Analyzing outcomes of simulation studies, we show that these approaches benefit from forms of modularization as found in biological systems. We identify three different strands of modularity exhibited in biological control systems. Two of them—modularity in state (i) and in action (ii) spaces—appear as a consequence of local interconnectivity (as in reflexes) and are often modulated by higher levels in a control hierarchy. A third strand arises from chunking of action elements along a (iii) temporal dimension. Usually interacting in an overarching spatio-temporal hierarchy of the overall system, the three strands offer major “factors” decomposing the entire modularity structure. We conclude that modularity with its above strands can provide an effective prior for DRL approaches to speed up learning considerably and making learned controllers more robust and adaptive.},
  archive      = {J_CC},
  author       = {Schilling, Malte and Hammer, Barbara and Ohl, Frank W. and Ritter, Helge J. and Wiskott, Laurenz},
  doi          = {10.1007/s12559-022-10080-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2358-2373},
  shortjournal = {Cogn. Comput.},
  title        = {Modularity in nervous systems—a key to efficient adaptivity for deep reinforcement learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncovering the secrets of the concept of place in cognitive
maps aided by artificial intelligence. <em>CC</em>, <em>16</em>(5),
2334–2344. (<a
href="https://doi.org/10.1007/s12559-022-10064-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncovering how mental representations acquire, recall, and decode spatial information about relative locations and environmental attributes (cognitive map) involves different challenges. This work is geared towards theoretical discussions on the controversial issue of cognitive scalability for understanding cognitive map emergence from place and grid cells at the intersection between neuroscience and artificial intelligence. In our view, different place maps emerge from parallel and hierarchical neural structures supporting a global cognitive map. The mechanisms sustaining these maps do not only process sensory input but also assign the input to a location. Contentious issues are presented around these concepts and provide concrete suggestions for moving the field forward. We recommend approaching the described challenges guided by AI-based theoretical aspects of encoded place instead of based chiefly on technological aspects to study the brain. SIGNIFICANCE: A formal difference exists between the concepts of spatial representations between experimental neuroscientists and computer scientists and engineers in the so-called neural-based autonomous navigation field. From a neuroscience perspective, we consider the position of an organism’s body to be entirely determined by translational spatial information (e.g., visited places and velocities). An organism predicts where it is at a specific time using continuous or discrete spatial functions embedded into navigation systems. From these functions, we infer that the concept of place has emerged. However, from an engineering standpoint, we represent structured scaffolds of behavioral processes to determine movements from the organism’s current position to some other spatial locations. These scaffolds are certainly affected by the system’s designer. Therefore, the coding of place, in this case, is predetermined. The contrast between emergent cognitive map through inputs versus predefined spatial recognition between two fields creates an inconsistency. Clarifying this tension can inform us on how the brain encodes abstract knowledge to represent spatial positions, which hints at a universal theory of cognition.},
  archive      = {J_CC},
  author       = {Fernandez-Leon, Jose A. and Acosta, Gerardo G.},
  doi          = {10.1007/s12559-022-10064-w},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2334-2344},
  shortjournal = {Cogn. Comput.},
  title        = {Uncovering the secrets of the concept of place in cognitive maps aided by artificial intelligence},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial: What AI and neuroscience can learn from each
other—open problems in models and theories. <em>CC</em>, <em>16</em>(5),
2331–2333. (<a
href="https://doi.org/10.1007/s12559-024-10324-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Roy, Asim and Minai, Ali A. and Thivierge, Jean-Philippe and Achler, Tsvi and Weng, Juyang},
  doi          = {10.1007/s12559-024-10324-x},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2331-2333},
  shortjournal = {Cogn. Comput.},
  title        = {Editorial: What AI and neuroscience can learn from each Other—Open problems in models and theories},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient deep learning approach for diagnosis of
attention-deficit/hyperactivity disorder in children based on EEG
signals. <em>CC</em>, <em>16</em>(5), 2315–2330. (<a
href="https://doi.org/10.1007/s12559-024-10302-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention-deficit/hyperactivity disorder (ADHD) is a behavioral disorder in children that can persist into adulthood if not treated. Early diagnosis of this condition is crucial for effective treatment. The database includes 61 children with attention-deficit/hyperactivity disorder and 60 healthy children as a control group. To diagnose children with ADHD, features were first extracted from EEG signals. Next, a convolutional neural network model was trained, and a new residual network was introduced. The two proposed models were evaluated using tenfold cross-validation on the test data. The average accuracy and F1 score were 92.52% and 93.6%, respectively, for the convolutional model and 96.8% and 97.1% for the ResNet model on the epoch data, respectively. On the other hand, accuracy for subject-based prediction was 96.5% for the convolution model and 98.6% for the modified ResNet model. Accuracy, precision, recall, and F1 score for the proposed ResNet model are better than the convolution model proposed in previous studies and better than the proposed model in the literature. This work presents a paradigm shift in the cognitive-inspired domain by introducing a novel ResNet model for ADHD diagnosis. The model’s exceptional accuracy, exceeding conventional methods, showcases its potential as a biologically inspired tool. This opens avenues for exploring the neurological underpinnings of ADHD because the model can be used for the manifold learning of EEG signals. Analyzing the proposed network can lead to a deeper understanding of EEG, bridging the gap between artificial intelligence and cognitive neuroscience. The paper’s innovative approach has far-reaching implications, offering a concrete application of cognitive principles to improve mental health diagnostics in children. It is important to note that the data were augmented and the classification model is based on a single experiment containing a very small number of children but the results, and accuracy of classification, are based on classifying augmented data samples that compose the EEG signals of this small number of individuals. It is prudent to undertake a comprehensive investigation into the efficacy of these models across a broad cohort of subjects.},
  archive      = {J_CC},
  author       = {Jahani, Hamid and Safaei, Ali Asghar},
  doi          = {10.1007/s12559-024-10302-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2315-2330},
  shortjournal = {Cogn. Comput.},
  title        = {Efficient deep learning approach for diagnosis of attention-Deficit/Hyperactivity disorder in children based on EEG signals},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigating the influence of scene video on EEG-based
evaluation of interior sound in passenger cars. <em>CC</em>,
<em>16</em>(5), 2297–2314. (<a
href="https://doi.org/10.1007/s12559-024-10303-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of automobile sound quality is an important research topic in the interior sound design of passenger car, and the accurate and effective evaluation methods are required for the determination of the acoustic targets in automobile development. However, there are some deficiencies in the existing evaluation studies of automobile sound quality. (1) Most of subjective evaluations only considered the auditory perception, which is easy to be achieved but does not fully reflect the impacts of sound on participants; (2) similarly, most of the existing subjective evaluations only considered the inherent properties of sounds, such as physical and psychoacoustic parameters, which make it difficult to reflect the complex relationship between the sound and the subjective perception of the evaluators; (3) the construction of evaluation models only from physical and psychoacoustic perspectives does not provide a comprehensive analysis of the real subjective emotions of the participants. Therefore, to alleviate the above flaws, the auditory and visual perceptions are combined to explore the inference of scene video on the evaluation of sound quality, and the EEG signal is introduced as a physiological acoustic index to evaluate the sound quality; simultaneously, an Elman neural network model is constructed to predict the powerful sound quality combined with the proposed indexes of physical acoustics, psychoacoustics, and physiological acoustics. The results show that evaluation results of sound quality combined with scene videos better reflect the subjective perceptions of participants. The proposed objective evaluation indexes of physical, psychoacoustic, and physiological acoustic contribute to mapping the subjective results of the powerful sound quality, and the constructed Elman model outperforms the traditional back propagation (BP) and support vector machine (SVM) models. The analysis method proposed in this paper can be better applied in the field of automotive sound design, providing a clear guideline for the evaluation and optimization of automotive sound quality in the future.},
  archive      = {J_CC},
  author       = {Xie, Liping and Liu, Zhien and Sun, Yi and Zhu, Yawei},
  doi          = {10.1007/s12559-024-10303-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2297-2314},
  shortjournal = {Cogn. Comput.},
  title        = {Investigating the influence of scene video on EEG-based evaluation of interior sound in passenger cars},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RA-net: Region-aware attention network for skin lesion
segmentation. <em>CC</em>, <em>16</em>(5), 2279–2296. (<a
href="https://doi.org/10.1007/s12559-024-10304-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise segmentation of skin lesion in dermoscopic images is essential for the early detection of skin cancer. However, the irregular shapes of the lesions, the absence of sharp edges, the existence of artifacts like hair follicles, and marker color make this task difficult. Currently, fully connected networks (FCNs) and U-Nets are the most commonly used techniques for melanoma segmentation. However, as the depth of these neural network models increases, they become prone to various challenges. The most pertinent of these challenges are the vanishing gradient problem and the parameter redundancy problem. These can result in a decline in Jaccard index of the segmentation model. This study introduces a novel end-to-end trainable network designed for skin lesion segmentation. The proposed methodology consists of an encoder-decoder, a region-aware attention approach, and guided loss function. The trainable parameters are reduced using depth-wise separable convolution, and the attention features are refined using a guided loss, resulting in a high Jaccard index. We assessed the effectiveness of our proposed RA-Net on four frequently utilized benchmark datasets for skin lesion segmentation: ISIC 2016, ISIC 2017, ISIC 2018, and PH2. The empirical results validate that our method achieves state-of-the-art performance, as indicated by a notably high Jaccard index.},
  archive      = {J_CC},
  author       = {Naveed, Asim and Naqvi, Syed S. and Iqbal, Shahzaib and Razzak, Imran and Khan, Haroon Ahmed and Khan, Tariq M.},
  doi          = {10.1007/s12559-024-10304-1},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2279-2296},
  shortjournal = {Cogn. Comput.},
  title        = {RA-net: Region-aware attention network for skin lesion segmentation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of cardiovascular diseases using data mining
approaches: Application of an ensemble-based model. <em>CC</em>,
<em>16</em>(5), 2264–2278. (<a
href="https://doi.org/10.1007/s12559-024-10306-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases are the leading contributor of mortality worldwide. Accurate cardiovascular disease prediction is crucial, and the application of machine learning and data mining techniques could facilitate decision-making and improve predictive capabilities. This study aimed to present a model for accurate prediction of cardiovascular diseases and identifying key contributing factors with the greatest impact. The Cleveland dataset besides the locally collected dataset, called the Noor dataset, was used in this study. Accordingly, various data mining techniques besides four ensemble learning-based models were implemented on both datasets. Moreover, a novel model for combining individual classifiers in ensemble learning, wherein weights were assigned to each classifier (using a genetic algorithm), was developed. The predictive strength of each feature was also investigated to ensure the generalizability of the outcomes. The ultimate ensemble-based model achieved a precision rate of 88.05% and 90.12% on the Cleveland and Noor datasets, respectively, demonstrating its reliability and suitability for future research in predicting the likelihood of cardiovascular diseases. Not only the proposed model introduces an innovative approach for specifying cardiovascular diseases by unraveling the intricate relationships between various biological variables but also facilitates early detection of cardiovascular diseases.},
  archive      = {J_CC},
  author       = {Nazari, Mojdeh and Emami, Hassan and Rabiei, Reza and Hosseini, Azamossadat and Rahmatizadeh, Shahabedin},
  doi          = {10.1007/s12559-024-10306-z},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2264-2278},
  shortjournal = {Cogn. Comput.},
  title        = {Detection of cardiovascular diseases using data mining approaches: Application of an ensemble-based model},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent fisheries: Cognitive solutions for improving
aquaculture commercial efficiency through enhanced biomass estimation
and early disease detection. <em>CC</em>, <em>16</em>(5), 2241–2263. (<a
href="https://doi.org/10.1007/s12559-024-10292-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the burgeoning global demand for seafood, potential solutions like aquaculture are increasingly significant, provided they address issues like pollution and food security challenges in a sustainable manner. However, significant obstacles such as disease outbreaks and inaccurate biomass estimation underscore the need for optimized solutions. This paper proposes “Fish-Sense”, a deep learning-based pipeline inspired by the human visual system’s ability to recognize and classify objects, developed in conjunction with fish farms, aiming to enhance disease detection and biomass estimation in the aquaculture industry. Our automated framework is two-pronged: one module for biomass estimation using deep learning algorithms to segment fish, classify species, and estimate biomass; and another for disease symptom detection symptoms, employing deep learning algorithms to classify fish into healthy and unhealthy categories, and subsequently identifying symptoms and locations of bacterial infections if a fish is classified as unhealthy. To overcome data scarcity in this field, we have created four novel real-world datasets for fish segmentation, health classification, species classification, and fish part segmentation. Our biomass estimation algorithms demonstrated substantial accuracy across five species, and the health classification. These algorithms provide a foundation for the development of industrial software solutions to improve fish health monitoring in aquaculture farms. Our integrated pipeline facilitates the transition from research to real-world applications, potentially encouraging responsible aquaculture practices. Nevertheless, these advancements must be seen as part of a comprehensive strategy aimed at improving the aquaculture industry’s sustainability and efficiency, in line with the United Nations’ Sustainable Development Goals’ evolving interpretations. The code, trained models, and the data for this project can be obtained from the following GitHub repository: https://github.com/Vision-At-SEECS/Fish-Sense .},
  archive      = {J_CC},
  author       = {Aftab, Kanwal and Tschirren, Linda and Pasini, Boris and Zeller, Peter and Khan, Bostan and Fraz, Muhammad Moazam},
  doi          = {10.1007/s12559-024-10292-2},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2241-2263},
  shortjournal = {Cogn. Comput.},
  title        = {Intelligent fisheries: Cognitive solutions for improving aquaculture commercial efficiency through enhanced biomass estimation and early disease detection},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning from failure: Towards developing a disease
diagnosis assistant that also learns from unsuccessful diagnoses.
<em>CC</em>, <em>16</em>(5), 2222–2240. (<a
href="https://doi.org/10.1007/s12559-024-10274-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, automatic disease diagnosis has gained immense popularity in research and industry communities. Humans learn a task through both successful and unsuccessful attempts in real life, and physicians are not different. When doctors fail to diagnose disease correctly, they re-assess the extracted symptoms and re-diagnose the patient by inspecting a few more symptoms guided by their previous experience and current context. Motivated by the experience gained from failure assessment, we propose a novel end-to-end automatic disease diagnosis dialogue system called Failure Assessment incorporated Symptom Investigation and Disease Diagnosis (FA-SIDD) Assistant. The proposed FA-SIDD model includes a knowledge-guided, incorrect disease projection-aware failure assessment module that analyzes unsuccessful diagnosis attempts and reinforces the assessment for further investigation and re-diagnosis. We formulate a novel Markov decision process for the proposed failure assessment, incorporating symptom investigation and disease diagnosis frameworks, and optimize the policy using deep reinforcement learning. The proposed model has outperformed several baselines and the existing symptom investigation and diagnosis methods by a significant margin (1–3%) in all evaluation metrics (including human evaluation). The improvements over the multiple datasets and across multiple algorithms firmly establish the efficacy of learning gained from unsuccessful diagnoses. The work is the first attempt that investigate the importance of learning gained from unsuccessful diagnoses. The developed assistant learns diagnosis task more efficiently than traditional assistants and shows robust behavior. Furthermore, the code is available at https://github.com/AbhisekTiwari/FA-SIDA .},
  archive      = {J_CC},
  author       = {Tiwari, Abhisek and S, Swarna and Saha, Sriparna and Bhattacharyya, Pushpak and Dhar, Minakshi and Tiwari, Sarbajeet},
  doi          = {10.1007/s12559-024-10274-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2222-2240},
  shortjournal = {Cogn. Comput.},
  title        = {Learning from failure: Towards developing a disease diagnosis assistant that also learns from unsuccessful diagnoses},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quasi-projective synchronization control of delayed
stochastic quaternion-valued fuzzy cellular neural networks with
mismatched parameters. <em>CC</em>, <em>16</em>(5), 2206–2221. (<a
href="https://doi.org/10.1007/s12559-024-10299-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the quasi-projective synchronization problem of delayed stochastic quaternion fuzzy cellular neural networks with mismatch parameters. Although the parameter mismatch of the drive-response system increases the computational complexity of the article, it is of practical significance to consider the existence of deviations between the two systems. The method of this article is to design an appropriate controller and construct Lyapunov functional and stochastic analysis theory based on the Itô formula in the quaternion domain. We adopt the non-decomposable method of quaternion FCNN, which preserves the original data and reduces computational effort. We obtain sufficient conditions for quasi-projective synchronization of the considered random quaternion numerical FCNNs with mismatched parameters. Additionally, we estimate the error bounds of quasi-projective synchronization and then carry out a numerical example to verify their validity. Our results are novel even if the considered neural networks degenerate into real-valued or complex-valued neural networks. This article provides a good research idea for studying the quasi-projective synchronization problem of random quaternion numerical FCNN with time delay and has obtained good results. The method in this article can also be used to study the quasi-projective synchronization of a Clifford-valued neural network.},
  archive      = {J_CC},
  author       = {Meng, Xiaofang and Fei, Yu and Li, Zhouhong},
  doi          = {10.1007/s12559-024-10299-9},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2206-2221},
  shortjournal = {Cogn. Comput.},
  title        = {Quasi-projective synchronization control of delayed stochastic quaternion-valued fuzzy cellular neural networks with mismatched parameters},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Twin bounded support vector machine with capped pinball
loss. <em>CC</em>, <em>16</em>(5), 2185–2205. (<a
href="https://doi.org/10.1007/s12559-024-10307-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to obtain a more robust and sparse classifier, in this paper, we propose a novel classifier termed as twin bounded support vector machine with capped pinball loss (CPin-TBSVM), which has the excellent properties of being insensitive to feature and label noise. Given that the proposed model is non-convex, we use the convex-concave procedure algorithm (CCCP) to solve a series of two smaller-sized quadratic programming problems to find the optimal solution. In the process of solving the iterative subproblem, the dual coordinate descent method (DCDM) is used for speeding up solving optimization problems. Moreover, we analyze its theoretical properties, including that the capped pinball loss satisfies Bayes’ rule and CPin-TBSVM has certain noise insensitivity and sparsity. The properties are verified on an artificial dataset as well. The numerical experiment is conducted on 24 UCI datasets and the results are compared with four other models which include SVM, TSVM, Pin-GTSVM and TPin-TSVM. The results show that the proposed CPin-TBSVM has a better classification effect and noise insensitivity.},
  archive      = {J_CC},
  author       = {Wang, Huiru and Hong, Xiaoqing and Zhang, Siyuan},
  doi          = {10.1007/s12559-024-10307-y},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2185-2205},
  shortjournal = {Cogn. Comput.},
  title        = {Twin bounded support vector machine with capped pinball loss},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effect of leakage delays on bifurcation in fractional-order
bidirectional associative memory neural networks with five neurons and
discrete delays. <em>CC</em>, <em>16</em>(5), 2169–2184. (<a
href="https://doi.org/10.1007/s12559-024-10305-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is well known that time delays are inevitable in practice due to the finite switching speed of amplifiers and information transmission between neurons. So the study on the Hopf bifurcation of delayed neural networks has aroused extensive attention in recent years. However, it’s worth mentioning that only the communication delays between neurons were generally considered in most existing relevant literatures. Actually, it has been proven that a kind of so-called leakage delays cannot be ignored because the self-decay process of a neuron’s action potential is not instantaneous in hardware implementation of neural networks. Though leakage delays have been taken into account in a few more recent works concerning the Hopf bifurcation of fractional-order bidirectional associative memory neural networks, the addressed neural networks were low-dimension or the involved time delays were single. In this paper, we propose a five-neuron fractional-order bidirectional associative memory neural network model, which includes leakage delays and discrete communication delays to meet the characteristics of real neural networks better. Then we use the stability theory of fractional differential equations and Hopf bifurcation theory to investigate its dynamic behavior of Hopf bifurcation. The Hopf bifurcation of the proposed model are studied by taking the involved two different leakage delays as the bifurcation parameter respectively, and two kinds of sufficient conditions for Hopf bifurcation are obtained. A numerical example as well as its simulation plots and phase portraits are given at last. Our results indicate that a Hopf bifurcation rises near the zero equilibrium point when the leakage delay reaches its critical value which is given by an explicit formula. Particularly, the results of numerical simulations show that the leakage delay would narrow the stability region of the proposed system and make the Hopf bifurcation occur earlier.},
  archive      = {J_CC},
  author       = {Wang, Yangling and Cao, Jinde and Huang, Chengdai},
  doi          = {10.1007/s12559-024-10305-0},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2169-2184},
  shortjournal = {Cogn. Comput.},
  title        = {Effect of leakage delays on bifurcation in fractional-order bidirectional associative memory neural networks with five neurons and discrete delays},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced android ransomware detection through hybrid
simultaneous swarm-based optimization. <em>CC</em>, <em>16</em>(5),
2154–2168. (<a
href="https://doi.org/10.1007/s12559-024-10301-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ransomware is a significant security threat that poses a serious risk to the security of smartphones, and its impact on portable devices has been extensively discussed in a number of research papers. In recent times, this threat has witnessed a significant increase, causing substantial losses for both individuals and organizations. The emergence and widespread occurrence of diverse forms of ransomware present a significant impediment to the pursuit of reliable security measures that can effectively combat them. This constitutes a formidable challenge due to the dynamic nature of ransomware, which renders traditional security protocols inadequate, as they might have a high false alarm rate and exert significant processing demands on mobile devices that are restricted by limited battery life, CPU, and memory. This paper proposes a novel intelligent method for detecting ransomware that is based on a hybrid multi-solution binary JAYA algorithm with a single-solution simulated annealing (SA). The primary objective is to leverage the exploitation power of SA in supporting the exploration power of the binary JAYA algorithm. This approach results in a better balance between global and local search milestones. The empirical results of our research demonstrate the superiority of the proposed SMO-BJAYA-SA-SVM method over other algorithms based on the evaluation measures used. The proposed method achieved an accuracy rate of 98.7%, a precision of 98.6%, a recall of 98.7%, and an F1 score of 98.6%. Therefore, we believe that our approach is an effective method for detecting ransomware on portable devices. It has the potential to provide a more reliable and efficient solution to this growing security threat.},
  archive      = {J_CC},
  author       = {Alazab, Moutaz and Khurma, Ruba Abu and Camacho, David and Martín, Alejandro},
  doi          = {10.1007/s12559-024-10301-4},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2154-2168},
  shortjournal = {Cogn. Comput.},
  title        = {Enhanced android ransomware detection through hybrid simultaneous swarm-based optimization},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing medical imaging through generative adversarial
networks: A comprehensive review and future prospects. <em>CC</em>,
<em>16</em>(5), 2131–2153. (<a
href="https://doi.org/10.1007/s12559-024-10291-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical imaging, traditional methods have long been relied upon. However, the integration of Generative Adversarial Networks (GANs) has sparked a paradigm shift, ushering in a new era of innovation. Our comprehensive investigation explores the groundbreaking impact of GANs on medical imaging, examining the evolution from traditional techniques to GAN-driven approaches. Through meticulous analysis, we dissect various aspects of GANs, encompassing their taxonomy, historical progression, and diverse iterations such as Self-Attention GANs (SAGAN), Conditional GANs, and Progressive Growing GANs (PGGAN). Complemented by a practical case study, we scrutinize the extensive applications of GANs, spanning image generation, reconstruction, enhancement, segmentation, and super-resolution. Despite promising prospects, enduring challenges including data scarcity, interpretability issues, and ethical concerns persist. Looking ahead, we anticipate advancements in personalized and pathological image generation, cross-modal synthesis, real-time interactive image generation, and enhanced anomaly detection. Through this review, we underscore the transformative potential of GANs in reshaping medical imaging practices, while also outlining avenues for future research endeavors.},
  archive      = {J_CC},
  author       = {Mamo, Abiy Abinet and Gebresilassie, Bealu Girma and Mukherjee, Aniruddha and Hassija, Vikas and Chamola, Vinay},
  doi          = {10.1007/s12559-024-10291-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {2131-2153},
  shortjournal = {Cogn. Comput.},
  title        = {Advancing medical imaging through generative adversarial networks: A comprehensive review and future prospects},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neurodynamical computing at the information boundaries of
intelligent systems. <em>CC</em>, <em>16</em>(5), 1–13. (<a
href="https://doi.org/10.1007/s12559-022-10081-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence has not achieved defining features of biological intelligence despite models boasting more parameters than neurons in the human brain. In this perspective article, we synthesize historical approaches to understanding intelligent systems and argue that methodological and epistemic biases in these fields can be resolved by shifting away from cognitivist brain-as-computer theories and recognizing that brains exist within large, interdependent living systems. Integrating the dynamical systems view of cognition with the massive distributed feedback of perceptual control theory highlights a theoretical gap in our understanding of nonreductive neural mechanisms. Cell assemblies—properly conceived as reentrant dynamical flows and not merely as identified groups of neurons—may fill that gap by providing a minimal supraneuronal level of organization that establishes a neurodynamical base layer for computation. By considering information streams from physical embodiment and situational embedding, we discuss this computational base layer in terms of conserved oscillatory and structural properties of cortical-hippocampal networks. Our synthesis of embodied cognition, based in dynamical systems and perceptual control, aims to bypass the neurosymbolic stalemates that have arisen in artificial intelligence, cognitive science, and computational neuroscience.},
  archive      = {J_CC},
  author       = {Monaco, Joseph D. and Hwang, Grace M.},
  doi          = {10.1007/s12559-022-10081-9},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Cogn. Comput.},
  title        = {Neurodynamical computing at the information boundaries of intelligent systems},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative model-driven synthetic training image generation:
An approach to cognition in railway defect detection. <em>CC</em>,
<em>16</em>(5), 1–16. (<a
href="https://doi.org/10.1007/s12559-024-10283-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in cognitive computing, through the integration of artificial intelligence (AI) techniques, have facilitated the development of intelligent cognitive systems (ICS). This benefits railway defect detection by enabling ICS to emulate human-like analysis of defect patterns in image data. Although visual defect classification based on convolutional neural networks (CNN) has achieved decent performance, the scarcity of large datasets for railway defect detection remains a challenge. This scarcity stems from the infrequent nature of accidents that result in defective railway parts. Existing research efforts have addressed the challenge of data scarcity by exploring rule-based and generative data augmentation approaches. Among these approaches, variational autoencoder (VAE) models can generate realistic data without the need for extensive baseline datasets for noise modeling. This study proposes a VAE-based synthetic image generation technique for training railway defect classifiers. Our approach introduces a modified regularization strategy that combines weight decay with reconstruction loss. Using this method, we created a synthetic dataset for the Canadian Pacific Railway (CPR), consisting of 50 real samples across five classes. Remarkably, our method generated 500 synthetic samples, achieving a minimal reconstruction loss of 0.021. A visual transformer (ViT) model, fine-tuned using this synthetic CPR dataset, achieved high accuracy rates (98–99%) in classifying the five railway defect classes. This research presents an approach that addresses the data scarcity issue in railway defect detection, indicating a path toward enhancing the development of ICS in this field.},
  archive      = {J_CC},
  author       = {Ferdousi, Rahatara and Yang, Chunsheng and Hossain, M. Anwar and Laamarti, Fedwa and Hossain, M. Shamim and Saddik, Abdulmotaleb El},
  doi          = {10.1007/s12559-024-10283-3},
  journal      = {Cognitive Computation},
  month        = {9},
  number       = {5},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {Generative model-driven synthetic training image generation: An approach to cognition in railway defect detection},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel convolutional neural network for head detection and
pose estimation in complex environments from single-depth images.
<em>CC</em>, <em>16</em>(4), 2116–2129. (<a
href="https://doi.org/10.1007/s12559-023-10209-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision based on neural networks is an important part of modern cognitive research. As important applications, head detection and pose estimation have made breakthrough progress in recent years. Compared to RGB sensors, depth cameras can provide a reliable solution in unstable or poor lighting conditions. An efficient pose estimation method relies on accurate head centre localization. Based only on depth images, a new convolutional neural network named HDPNet, which implemented complete head detection and pose estimation in complex environments, was proposed. For the head detection part, HDPNet adopted a convolutional neural classification network and the mean shift algorithm to achieve high-precision head centre localization, and for the pose estimation part, a novel guidance network with L2-norm was introduced to constrain the regression process of pose features. Moreover, soft label was adopted to encode the probability distribution between the pose ranges. To verify the performance of HDPNet, a series of experiments were conducted on four challenging public datasets: Watch-n-patch, the Biwi Head Pose dataset, Pandora and ICT-3DHP. Based on our experimental results with a comparison to state-of-the-art methods, the IoU of the head localization was improved by 2.2%, and the mean error in pose estimation was reduced by 0.1. The performance of our HDPNet outperformed the latest methods and could be effectively applied in a real environment.},
  archive      = {J_CC},
  author       = {Wang, Qi and Lei, Hang and Li, Gun and Wang, Xupeng and Chen, Lu},
  doi          = {10.1007/s12559-023-10209-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {2116-2129},
  shortjournal = {Cogn. Comput.},
  title        = {A novel convolutional neural network for head detection and pose estimation in complex environments from single-depth images},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Role of artificial intelligence techniques and neuroimaging
modalities in detection of parkinson’s disease: A systematic review.
<em>CC</em>, <em>16</em>(4), 2078–2115. (<a
href="https://doi.org/10.1007/s12559-023-10175-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD), a neurodegenerative disorder, is caused due to the lack of dopamine neurotransmitters throughout the substantia nigra. Its diagnosis in the earlier stages is a very intricate process due to non-identified onset symptoms. Thus, it becomes imperative to establish its manifestations, causes, and treatment for better management and minimization of time-consuming medical examinations. This extensive literature review was conducted to summarize the earlier work in this area, and the articles were searched using different keywords in various repositories. From the year 2015 to 2022, a total of 648 publications were scanned from which 75 studies were chosen for analysis in this article. The comprehensive literature survey shows the development of numerous therapeutic methods for the treatment of PD with limited studies on a particular diagnostic method for detection. Nevertheless, automatic artificial intelligence-based systems and neuroimaging modalities have the potential to detect the severity and stages of PD. The present review discusses the role of single and multimodalities of neuroimaging with the integration of various artificial intelligence techniques along with research gaps, technical limitations, and future directions. This review may help provide the researchers and clinicians with the necessary guidelines for finding the appropriate biomarkers for disease diagnosis.},
  archive      = {J_CC},
  author       = {Aggarwal, Nikita and Saini, B. S. and Gupta, Savita},
  doi          = {10.1007/s12559-023-10175-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {2078-2115},
  shortjournal = {Cogn. Comput.},
  title        = {Role of artificial intelligence techniques and neuroimaging modalities in detection of parkinson’s disease: A systematic review},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-kernel attention for 3D medical image segmentation.
<em>CC</em>, <em>16</em>(4), 2063–2077. (<a
href="https://doi.org/10.1007/s12559-023-10126-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated segmentation of multiple organs and tumors from 3D medical images such as magnetic resonance imaging (MRI) and computed tomography (CT) scans using deep learning methods can aid in diagnosing and treating cancer. However, organs often overlap and are complexly connected, characterized by extensive anatomical variation and low contrast. In addition, the diversity of tumor shape, location, and appearance, coupled with the dominance of background voxels, makes accurate 3D medical image segmentation difficult. In this paper, a novel 3D large-kernel (LK) attention module is proposed to address these problems to achieve accurate multi-organ segmentation and tumor segmentation. The advantages of biologically inspired self-attention and convolution are combined in the proposed LK attention module, including local contextual information, long-range dependencies, and channel adaptation. The module also decomposes the LK convolution to optimize the computational cost and can be easily incorporated into CNNs such as U-Net. Comprehensive ablation experiments demonstrated the feasibility of convolutional decomposition and explored the most efficient and effective network design. Among them, the best Mid-type 3D LK attention-based U-Net network was evaluated on CT-ORG and BraTS 2020 datasets, achieving state-of-the-art segmentation performance when compared to avant-garde CNN and Transformer-based methods for medical image segmentation. The performance improvement due to the proposed 3D LK attention module was statistically validated.},
  archive      = {J_CC},
  author       = {Li, Hao and Nan, Yang and Del Ser, Javier and Yang, Guang},
  doi          = {10.1007/s12559-023-10126-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {2063-2077},
  shortjournal = {Cogn. Comput.},
  title        = {Large-kernel attention for 3D medical image segmentation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG signal classification using a novel universum-based twin
parametric-margin support vector machine. <em>CC</em>, <em>16</em>(4),
2047–2062. (<a
href="https://doi.org/10.1007/s12559-023-10115-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Universum data, which indicates a sample that does not belong to any of the classes, has been proved to be useful in supervised learning. The researchers have explored the support vector machine (SVM) and its twin variants by embedding them with Universum data for classifying the electroencephalogram (EEG) signal. To improve generalization performance even further, this paper presents a novel twin parametric margin SVM based on Universum data (UTPMSVM) for classifying EEG signals. The proposed UTPMSVM forms a pair of non-parallel parametric hyperplanes that solves two small SVM-type problems. The addition of prior information, i.e., the Universum data, boosts the performance of the model. The dimensionality of the EEG datasets is reduced using principal component analysis (PCA), independent component analysis (ICA), and wavelet analysis. Experimental simulations have been carried out on 14 EEG datasets as well as 30 real-world datasets. The classification performance of the proposed model is compared with Universum-based SVM (USVM), Universum non-parallel hyperplane-based SVM (UNHSVM), TPMSVM, and angle-based Universum least squares twin SVM (AULSTSVM) models. Further two different statistical tests are performed to evaluate the performance of the proposed model. For EEG datasets, the UTPMSVM showed the highest accuracy of 78% and the highest F1-score of 0.78658. Moreover, for the real-world datasets, the proposed UTPMSVM showed the highest accuracy of 100%. In addition to that, it is observed that the mean accuracy and F1-score of UTPMSVM are comparatively better than USVM, UNHSVM TPMSVM, and AULSTSVM. The results demonstrate the applicability of UTPMSVM for EEG signal classification problems as well as real-world data classification problems.},
  archive      = {J_CC},
  author       = {Hazarika, Barenya Bikash and Gupta, Deepak and Kumar, Bikram},
  doi          = {10.1007/s12559-023-10115-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {2047-2062},
  shortjournal = {Cogn. Comput.},
  title        = {EEG signal classification using a novel universum-based twin parametric-margin support vector machine},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tumor localization and classification from MRI of brain
using deep convolution neural network and salp swarm algorithm.
<em>CC</em>, <em>16</em>(4), 2036–2046. (<a
href="https://doi.org/10.1007/s12559-022-10096-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of brain tumors is crucial for treatment planning and increasing the survival rates of infected patients. In fact, brain tumors exist in a range of different forms, sizes, and features, as well as treatment choices. One of the essential roles of neurologists and radiologists is the diagnosis of brain tumors in their early stages. However, manual brain tumor diagnosis is difficult, time-consuming, and prone to error. Based on the problem highlighted, an automated brain tumor detection system is mandatory to identify the tumor in its initial stages. This research presents an efficient deep learning-based system for the classification of brain tumors from brain MRI using the deep convolutional network and salp swarm algorithm. All experiments are performed using the publicly available brain tumor Kaggle dataset. To enhance the classification rate, preprocessing and data augmentation such as skewed data ideas are devised. In addition, AlexNet and VGG19 are leveraged to perform specific functionality. Finally, all features merged into a single feature vector for brain tumor classification. Some of the extracted features found insignificant towards effective classification. Hence, we employed an efficient feature selection technique named slap swarm to find the most discriminative features to attain best tumor classification rate. Finally, several SVM kernels are merged for the final classification and 99.1% accuracy is achieved by selecting 4111 optimal features from 8192.},
  archive      = {J_CC},
  author       = {Alyami, Jaber and Rehman, Amjad and Almutairi, Fahad and Fayyaz, Abdul Muiz and Roy, Sudipta and Saba, Tanzila and Alkhurim, Alhassan},
  doi          = {10.1007/s12559-022-10096-2},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {2036-2046},
  shortjournal = {Cogn. Comput.},
  title        = {Tumor localization and classification from MRI of brain using deep convolution neural network and salp swarm algorithm},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight 3D convolutional neural network for
schizophrenia diagnosis using MRI images and ensemble bagging
classifier. <em>CC</em>, <em>16</em>(4), 2019–2035. (<a
href="https://doi.org/10.1007/s12559-022-10093-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural alterations have been thoroughly investigated in the brain during the early onset of schizophrenia (SCZ) with the development of neuroimaging methods. The objective of the paper is an efficient classification of SCZ in 2 different classes: cognitive normal (CN) and SCZ using magnetic resonance imaging (MRI) images. This paper proposes a lightweight 3D convolutional neural network (CNN) based framework for SCZ diagnosis using MRI images. In the proposed model, lightweight 3D CNN is used to extract both spatial and spectral features simultaneously from 3D volume MRI scans, and classification is done using an ensemble bagging classifier. Ensemble bagging classifier contributes to preventing overfitting, reduces variance, and improves the model’s accuracy. The proposed algorithm is tested on datasets taken from three benchmark databases available as open-source: MCICShare, COBRE, and fBRINPhase-II. All MRI images have undergone preprocessing steps to register all the MRI images to the standard template and reduce the artifacts. The model achieves the highest accuracy 92.22%, sensitivity 94.44%, specificity 90%, precision 90.43%, recall 94.44%, F1-score 92.39%, and G-mean 92.19% as compared to the current state-of-the-art techniques. The performance metrics evidenced the use of this model to assist the clinicians in automatic accurate diagnosis of SCZ.},
  archive      = {J_CC},
  author       = {SupriyaPatro, P. and Goel, Tripti and VaraPrasad, S. A. and Tanveer, M. and Murugan, R.},
  doi          = {10.1007/s12559-022-10093-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {2019-2035},
  shortjournal = {Cogn. Comput.},
  title        = {Lightweight 3D convolutional neural network for schizophrenia diagnosis using MRI images and ensemble bagging classifier},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DCTGM: A novel dual-channel transformer graph model for
miRNA-disease association prediction. <em>CC</em>, <em>16</em>(4),
2009–2018. (<a
href="https://doi.org/10.1007/s12559-022-10092-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies have shown that as non-coding RNAs, miRNAs regulate all levels of life activities and most pathological processes. Therefore, identifying disease-related miRNAs is essential for disease diagnosis and treatment. However, traditional biological experiments are highly uncertain and time-consuming. Hence, advanced intelligent computational models are needed to address this problem. We propose a dual-channel transformer graph model, named DCTGM, to learn multi-scale representations for miRNA-disease association prediction. Specifically, DCTGM includes a transformer encoder (TE) and GraphSAGE encoder (GE). The TE intensely captures the important interaction information between miRNA-disease pairs, and the GE aggregates multi-hop neighbor information of miRNA-disease association heterograph to enrich node features. Then, an attention module is proposed to aggregate the dual-channel interactive representations, and we adopt a multi-layer perceptron (MLP) to predict the miRNA-disease association scores. The fivefold cross-validation experimental results demonstrate that our proposed DCTGM achieves the AP of 92.735%, F1 of 84.430%, accuracy of 85.255%, and ROC of 93.012%. In addition, we conduct case studies on brain neoplasms, kidney neoplasms, and breast neoplasms. The extensive experiments show that the dbDEMC database validates 100% of the top 20 predicted miRNAs associated with these diseases. This model can effectively predict the potential mirNA-disease association. Experiments have shown that miRNA associated with a new disease can also be predicted.},
  archive      = {J_CC},
  author       = {Pang, Shanchen and Zhuang, Yu and Qiao, Sibo and Wang, Fuyu and Wang, Shudong and Lv, Zhihan},
  doi          = {10.1007/s12559-022-10092-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {2009-2018},
  shortjournal = {Cogn. Comput.},
  title        = {DCTGM: A novel dual-channel transformer graph model for miRNA-disease association prediction},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantitative susceptibility mapping in cognitive decline: A
review of technical aspects and applications. <em>CC</em>,
<em>16</em>(4), 1992–2008. (<a
href="https://doi.org/10.1007/s12559-022-10095-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the human brain, essential iron molecules for proper neurological functioning exist in transferrin $$(tf)$$ and ferritin $$(Fe3+)$$ forms. However, its unusual increment manifests iron overload, which reacts with hydrogen peroxide. This reaction will generate hydroxyl radicals, and iron’s higher oxidation states. Furthermore, this reaction causes tissue damage or cognitive decline in the brain and also leads to neurodegenerative diseases. The susceptibility difference due to iron overload within the volume of interest (VOI) responsible for field perturbation of MRI and can benefit in estimating the neural disorder. The quantitative susceptibility mapping (QSM) technique can estimate susceptibility alteration and assist in quantifying the local tissue susceptibility differences. It has attracted many researchers and clinicians to diagnose and detect neural disorders such as Parkinson’s, Alzheimer’s, multiple sclerosis, and aging. The paper presents a systematic review illustrating QSM fundamentals and its processing steps, including phase unwrapping, background field removal, and susceptibility inversion. Using QSM, the present work delivers novel predictive biomarkers for various neural disorders. It can strengthen new researchers’ fundamental knowledge and provides insight into its applicability for cognitive decline disclosure. The paper discusses the future scope of QSM processing stages and their applications in identifying new biomarkers for neural disorders.},
  archive      = {J_CC},
  author       = {Verma, Shradha and Goel, Tripti and Tanveer, M.},
  doi          = {10.1007/s12559-022-10095-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1992-2008},
  shortjournal = {Cogn. Comput.},
  title        = {Quantitative susceptibility mapping in cognitive decline: A review of technical aspects and applications},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning approach for robust, multi-oriented, and
curved text detection. <em>CC</em>, <em>16</em>(4), 1979–1991. (<a
href="https://doi.org/10.1007/s12559-022-10072-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic text localization and segmentation in a normal environment with vertical or curved texts are core elements of numerous tasks comprising the identification of vehicles and self-driving cars, and preparing significant information from real scenes to visually impaired people. Nevertheless, texts in the real environment can be discovered with a high level of angles, profiles, dimensions, and colors which is an arduous process to detect. In this paper, a new framework based on a convolutional neural network (CNN) is introduced to obtain high efficiency in detecting text even in the presence of a complex background. Due to using a new inception layer and an improved ReLU layer, an excellent result is gained to detect text even in the presence of complex backgrounds. At first, four new m.ReLU layers are employed to explore low-level visual features. The new m.ReLU building block and inception layer are optimized to detect vital information maximally. The effect of stacking up inception layers (kernels with the dimension of 3 × 3 or bigger) is explored and it is demonstrated that this strategy is capable of obtaining mostly varying-sized texts further successfully than a linear chain of convolution layers (Conv layers). The suggested text detection algorithm is conducted in four well-known databases, namely ICDAR 2013, ICDAR 2015, ICDAR 2017, and ICDAR 2019. Text detection results on all mentioned databases with the highest recall of 94.2%, precision of 95.6%, and F-score of 94.8% illustrate that the developed strategy outperforms the state-of-the-art frameworks.},
  archive      = {J_CC},
  author       = {Ranjbarzadeh, Ramin and Jafarzadeh Ghoushchi, Saeid and Anari, Shokofeh and Safavi, Sadaf and Tataei Sarshar, Nazanin and Babaee Tirkolaee, Erfan and Bendechache, Malika},
  doi          = {10.1007/s12559-022-10072-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1979-1991},
  shortjournal = {Cogn. Comput.},
  title        = {A deep learning approach for robust, multi-oriented, and curved text detection},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep recurrent regression with a heatmap coupling module for
facial landmarks detection. <em>CC</em>, <em>16</em>(4), 1964–1978. (<a
href="https://doi.org/10.1007/s12559-022-10065-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial landmarks detection is an essential step in many face analysis applications for ambient understanding (people, scenes) and for dynamically adapting the interaction with humans and environment. The current methods have difficulties with real-world images. This paper proposes a simple and effective method to detect the essential points in human faces. The proposed method comprises a two-stage coordinated regression deep convolutional neural network (CR-CNN) with a heatmap coupling module to convert the detected facial landmarks of the first stage into a Gaussian heatmap. To take advantage of the prior stage knowledge, the generated heatmap is concatenated with the original image of the input face and entered into the network in the second stage. The two-stage implementation based on CR-CNN has same layers structure to simplify the design and complexity. The $$L_1$$ loss function is used for each stage and the total loss equals the sum of the two loss functions from both stages. Comprehensive experiments are conducted to evaluate the proposed method on three common challenging facial landmark datasets, namely AFLW, 300W, and WFLW. The proposed method achieves normalized mean error (NME) of 1.56% on the AFLW, 4.20% on the 300W, and 5.53% on the WFLW datasets. Moreover, the execution time of the proposed two-stage CR-HC is calculated as 3.33 ms. The obtained results show the robustness and outstanding performance of the proposed method over some of the state-of-the-art methods. The source code is provided as an open repository to the community for further research activities.},
  archive      = {J_CC},
  author       = {Hassaballah, M. and Salem, Eman and Ali, Abdel-Magid M. and Mahmoud, Mountasser M.},
  doi          = {10.1007/s12559-022-10065-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1964-1978},
  shortjournal = {Cogn. Comput.},
  title        = {Deep recurrent regression with a heatmap coupling module for facial landmarks detection},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WatMIF: Multimodal medical image fusion-based watermarking
for telehealth applications. <em>CC</em>, <em>16</em>(4), 1947–1963. (<a
href="https://doi.org/10.1007/s12559-022-10040-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over recent years, the volume of big data has drastically increased for medical applications. Such data are shared by cloud providers for storage and further processing. Medical images contain sensitive information, and these images are shared with healthcare workers, patients, and, in some scenarios, researchers for diagnostic and study purposes. However, the security of these images in the transfer process is extremely important, especially after the COVID-19 pandemic. This paper proposes a secure watermarking algorithm, termed WatMIF, based on multimodal medical image fusion. The proposed algorithm consists of three major parts: the encryption of the host media, the fusion of multimodal medical images, and the embedding and extraction of the fused mark. We encrypt the host media with a key-based encryption scheme. Then, a nonsubsampled contourlet transform (NSCT)-based fusion scheme is employed to fuse the magnetic resonance imaging (MRI) and computed tomography (CT) scan images to generate the fused mark image. Furthermore, the encrypted host media conceals the fused watermark using redundant discrete wavelet transform (RDWT) and randomised singular value decomposition (RSVD). Finally, denoising convolutional neural network (DnCNN) is used to improve the robustness of the WatMIF algorithm. The simulation experiments on two standard datasets were used to evaluate the algorithm in terms of invisibility, robustness, and security. When compared with the existing algorithms, the robustness is improved by 20.14%. Overall, the implementation of proposed watermarking for hiding fused marks and efficient encryption improved the identity verification, invisibility, robustness and security criteria in our WatMIF algorithm.},
  archive      = {J_CC},
  author       = {Singh, Kedar Nath and Singh, Om Prakash and Singh, Amit Kumar and Agrawal, Amrit Kumar},
  doi          = {10.1007/s12559-022-10040-4},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1947-1963},
  shortjournal = {Cogn. Comput.},
  title        = {WatMIF: Multimodal medical image fusion-based watermarking for telehealth applications},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization based deep learning for COVID-19 detection
using respiratory sound signals. <em>CC</em>, <em>16</em>(4), 1927–1946.
(<a href="https://doi.org/10.1007/s12559-024-10300-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 prediction process is more indispensable to handle the spread and death occurred rate because of COVID-19. However, early and precise prediction of COVID-19 is more difficult, because of different sizes and resolutions of input image. Thus, these challenges and problems experienced by traditional COVID-19 detection methods are considered as major motivation to develop SJHBO-based Deep Q Network. The classification issue of respiratory sound has perceived a great focus from the clinical scientists as well as the community of medical researcher in the previous year for the identification of COVID-19 disease. The major contribution of this research is to design an effectual COVID-19 detection model using devised SJHBO-based Deep Q Network. In this paper, the COVID-19 detection is carried out by the deep learning with optimization technique, namely Snake Jaya Honey Badger Optimization (SJHBO) algorithm-driven Deep Q Network. Here, the SJHBO algorithm is the incorporation of Jaya Honey Badger Optimization (JHBO) along with Snake optimization (SO). Here, the COVID-19 is detected by the Deep Q Network wherein the weights of Deep Q Network are tuned by the SJHBO algorithm. Moreover, JHBO is modelled by hybrids, which are the Jaya algorithm and Honey Badger Optimization (HBO) algorithm. Furthermore, the features, such as spectral contrast, Mel frequency cepstral coefficients (MFCC), empirical mode decomposition (EMD) algorithm, spectral flux, fast Fourier transform (FFT), spectral roll-off, spectral centroid, zero-crossing rate, root mean square energy, spectral bandwidth, spectral flatness, power spectral density, mobility complexity, fluctuation index and relative amplitude, are mined for enlightening the detection performance. The developed method realized the better performance based on the accuracy, sensitivity and specificity of 0.9511, 0.9506 and 0.9469. All test results are validated with the k-fold cross validation method in order to make an assessment of the generalizability of these results. Statistical analysis is performed to analyze the performance of the proposed method based on testing accuracy, sensitivity and specificity. Hence, this paper presents the newly devised SJHBO-based Deep Q-Net for COVID-19 detection. This research considers the audio samples as an input, which is acquired from the Coswara dataset. The SJHBO-based Deep Q network approach is developed for COVID-19 detection. The developed approach can be extended by including other hybrid optimization algorithms as well as other features that can be extracted for further improving the detection performance. The proposed COVID-19 detection method is useful in various applications, like medical and so on. Developed SJHBO-enabled Deep Q network for COVID-19 detection: An effective COVID-19 detection technique is introduced based on hybrid optimization–driven deep learning model. The Deep Q Network is used for detecting COVID-19, which classifies the feature vector as COVID-19 or non-COVID-19. Moreover, the Deep Q Network is trained by devised SJHBO approach, which is the incorporation of Jaya Honey Badger Optimization (JHBO) along with Snake optimization (SO).},
  archive      = {J_CC},
  author       = {Dar, Jawad Ahmad and Srivastava, Kamal Kr and Lone, Sajaad Ahmed},
  doi          = {10.1007/s12559-024-10300-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1927-1946},
  shortjournal = {Cogn. Comput.},
  title        = {Optimization based deep learning for COVID-19 detection using respiratory sound signals},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 detection: A systematic review of machine and deep
learning-based approaches utilizing chest x-rays and CT scans.
<em>CC</em>, <em>16</em>(4), 1889–1926. (<a
href="https://doi.org/10.1007/s12559-022-10076-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review study presents the state-of-the-art machine and deep learning-based COVID-19 detection approaches utilizing the chest X-rays or computed tomography (CT) scans. This study aims to systematically scrutinize as well as to discourse challenges and limitations of the existing state-of-the-art research published in this domain from March 2020 to August 2021. This study also presents a comparative analysis of the performance of four majorly used deep transfer learning (DTL) models like VGG16, VGG19, ResNet50, and DenseNet over the COVID-19 local CT scans dataset and global chest X-ray dataset. A brief illustration of the majorly used chest X-ray and CT scan datasets of COVID-19 patients utilized in state-of-the-art COVID-19 detection approaches are also presented for future research. The research databases like IEEE Xplore, PubMed, and Web of Science are searched exhaustively for carrying out this survey. For the comparison analysis, four deep transfer learning models like VGG16, VGG19, ResNet50, and DenseNet are initially fine-tuned and trained using the augmented local CT scans and global chest X-ray dataset in order to observe their performance. This review study summarizes major findings like AI technique employed, type of classification performed, used datasets, results in terms of accuracy, specificity, sensitivity, F1 score, etc., along with the limitations, and future work for COVID-19 detection in tabular manner for conciseness. The performance analysis of the four majorly used deep transfer learning models affirms that Visual Geometry Group 19 (VGG19) model delivered the best performance over both COVID-19 local CT scans dataset and global chest X-ray dataset.},
  archive      = {J_CC},
  author       = {Bhatele, Kirti Raj and Jha, Anand and Tiwari, Devanshu and Bhatele, Mukta and Sharma, Sneha and Mithora, Muktasha R. and Singhal, Stuti},
  doi          = {10.1007/s12559-022-10076-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1889-1926},
  shortjournal = {Cogn. Comput.},
  title        = {COVID-19 detection: A systematic review of machine and deep learning-based approaches utilizing chest X-rays and CT scans},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emotion analysis of COVID-19 vaccines based on a fuzzy
convolutional neural network. <em>CC</em>, <em>16</em>(4), 1874–1888.
(<a href="https://doi.org/10.1007/s12559-022-10068-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 created immense global challenges in 2020, and the world will live under its threat indefinitely. Much of the information on social media supported the government in addressing this major public health event. On January 9, to control the virus, the Chinese government announced universal vaccinations. However, due to a range of varied interpretations, people held different attitudes towards vaccination. Therefore, the success of the mass immunization strategy greatly depended on the public perception of the COVID-19 vaccine. This article explores the changes in people’s emotional attitudes towards vaccines and the reasons behind them in the context of the global pandemic in an effort to help mankind overcome this ongoing crisis. For this article, microblogs from January to September containing Chinese people’s responses to the COVID-19 vaccines were collected. Based on fuzzy logic and deep learning, we advance the hypothesis that fuzzy vector adaptive improvements will make it possible to better express language emotion and that fuzzy emotion vectors can be integrated into deep learning models, thus making these models more interpretable. Based on this assumption, we design a deep learning model with a fuzzy emotion vector. The experimental results show the positive effect of this model. By applying the model in analyses of people’s attitudes towards vaccines, we can obtain people’s attitudes towards vaccines in different time periods. We discovered that the most negative emotions about the vaccine appeared in April and that the most positive emotions about the vaccine appeared in February. Combined with word cloud technology and the LDA model, we can effectively explore the reasons for the changes in vaccine attitudes. Our findings show that people’s negative emotions about the vaccine are always higher than their positive emotions about the vaccine and that people’s attitudes towards the vaccine are closely related to the progress of the epidemic. There is also a certain relationship between people’s attitudes towards the vaccine and those towards the vaccination.},
  archive      = {J_CC},
  author       = {Qiu, Dong and Yu, Yang and Chen, Lei},
  doi          = {10.1007/s12559-022-10068-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1874-1888},
  shortjournal = {Cogn. Comput.},
  title        = {Emotion analysis of COVID-19 vaccines based on a fuzzy convolutional neural network},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Particle swarm optimization-based extreme learning machine
for COVID-19 detection. <em>CC</em>, <em>16</em>(4), 1858–1873. (<a
href="https://doi.org/10.1007/s12559-022-10063-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 (coronavirus disease 2019) is an ongoing global pandemic caused by severe acute respiratory syndrome coronavirus 2. Recently, it has been demonstrated that the voice data of the respiratory system (i.e., speech, sneezing, coughing, and breathing) can be processed via machine learning (ML) algorithms to detect respiratory system diseases, including COVID-19. Consequently, many researchers have applied various ML algorithms to detect COVID-19 by using voice data from the respiratory system. However, most of the recent COVID-19 detection systems have worked on a limited dataset. In other words, the systems utilize cough and breath voices only and ignore the voices of the other respiratory system, such as speech and vowels. In addition, another issue that should be considered in COVID-19 detection systems is the classification accuracy of the algorithm. The particle swarm optimization-extreme learning machine (PSO-ELM) is an ML algorithm that can be considered an accurate and fast algorithm in the process of classification. Therefore, this study proposes a COVID-19 detection system by utilizing the PSO-ELM as a classifier and mel frequency cepstral coefficients (MFCCs) for feature extraction. In this study, respiratory system voice samples were taken from the Corona Hack Respiratory Sound Dataset (CHRSD). The proposed system involves thirteen different scenarios: breath deep, breath shallow, all breath, cough heavy, cough shallow, all cough, count fast, count normal, all count, vowel a, vowel e, vowel o, and all vowels. The experimental results demonstrated that the PSO-ELM was capable of attaining the highest accuracy, reaching 95.83%, 91.67%, 89.13%, 96.43%, 92.86%, 88.89%, 96.15%, 96.43%, 88.46%, 96.15%, 96.15%, 95.83%, and 82.89% for breath deep, breath shallow, all breath, cough heavy, cough shallow, all cough, count fast, count normal, all count, vowel a, vowel e, vowel o, and all vowel scenarios, respectively. The PSO-ELM is an efficient technique for the detection of COVID-19 utilizing voice data from the respiratory system.},
  archive      = {J_CC},
  author       = {Albadr, Musatafa Abbas Abbood and Tiun, Sabrina and Ayob, Masri and AL-Dhief, Fahad Taha},
  doi          = {10.1007/s12559-022-10063-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1858-1873},
  shortjournal = {Cogn. Comput.},
  title        = {Particle swarm optimization-based extreme learning machine for COVID-19 detection},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Text analysis of evolving emotions and sentiments in
COVID-19 twitter communication. <em>CC</em>, <em>16</em>(4), 1834–1857.
(<a href="https://doi.org/10.1007/s12559-022-10025-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientists and regular citizens alike search for ways to manage the widespread effects of the COVID-19 pandemic. While scientists are busy in their labs, other citizens often turn to online sources to report their experiences and concerns and to seek and share knowledge of the virus. The text generated by those users in online social media platforms can provide valuable insights about evolving users’ opinions and attitudes. The objective of this research is to analyze text of such user disclosures to study human communication during a pandemic in four primary ways. First, we analyze Twitter tweet information, generated throughout the pandemic, to understand users’ communications concerning COVID-19 and how those communications have evolved during the pandemic. Second, we analyze linguistic sentiment concepts (analytic, authentic, clout, and tone concepts) in different Twitter settings (sentiment in tweets with pictures or no pictures and tweets versus retweets). Third, we investigate the relationship between Twitter tweets with additional forms of internet activity, namely, Google searches and Wikipedia page views. Finally, we create and use a dictionary of specific COVID-19-related concepts (e.g., symptom of lost taste) to assess how the use of those concepts in tweets are related to the spread of information and the resulting influence of Twitter users. The analysis showed a surprisingly lack of emotion in the initial phases of the pandemic as people were information seeking. As time progressed, there were more expressions of sentiment, including anger. Further, tweets with and without pictures and/or video had statistically significant differences in text sentiment characteristics. Similarly, there were differences between the sentiment in tweets and retweets and tweets. We also found that Google and Wikipedia searches were predictive of sentiment in the tweets. Finally, a variable representing a dictionary of COVID-related concepts was statistically significant when related to users’ Twitter influence score and number of retweets, illustrating the general impact of COVID-19 on Twitter and human communication. Overall, the results provide insights into human communication as well as models of human internet and social media use. These findings could be useful for the management of global challenges beyond, or different from, a pandemic.},
  archive      = {J_CC},
  author       = {Storey, Veda C. and O’Leary, Daniel E.},
  doi          = {10.1007/s12559-022-10025-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1834-1857},
  shortjournal = {Cogn. Comput.},
  title        = {Text analysis of evolving emotions and sentiments in COVID-19 twitter communication},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning–based approaches to improve classification
parameters for diagnosing COVID-19 from CT images. <em>CC</em>,
<em>16</em>(4), 1806–1833. (<a
href="https://doi.org/10.1007/s12559-021-09915-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients infected with the COVID-19 virus develop severe pneumonia, which generally leads to death. Radiological evidence has demonstrated that the disease causes interstitial involvement in the lungs and lung opacities, as well as bilateral ground-glass opacities and patchy opacities. In this study, new pipeline suggestions are presented, and their performance is tested to decrease the number of false-negative (FN), false-positive (FP), and total misclassified images (FN + FP) in the diagnosis of COVID-19 (COVID-19/non-COVID-19 and COVID-19 pneumonia/other pneumonia) from CT lung images. A total of 4320 CT lung images, of which 2554 were related to COVID-19 and 1766 to non-COVID-19, were used for the test procedures in COVID-19 and non-COVID-19 classifications. Similarly, a total of 3801 CT lung images, of which 2554 were related to COVID-19 pneumonia and 1247 to other pneumonia, were used for the test procedures in COVID-19 pneumonia and other pneumonia classifications. A 24-layer convolutional neural network (CNN) architecture was used for the classification processes. Within the scope of this study, the results of two experiments were obtained by using CT lung images with and without local binary pattern (LBP) application, and sub-band images were obtained by applying dual-tree complex wavelet transform (DT-CWT) to these images. Next, new classification results were calculated from these two results by using the five pipeline approaches presented in this study. For COVID-19 and non-COVID-19 classification, the highest sensitivity, specificity, accuracy, F-1, and AUC values obtained without using pipeline approaches were 0.9676, 0.9181, 0.9456, 0.9545, and 0.9890, respectively; using pipeline approaches, the values were 0.9832, 0.9622, 0.9577, 0.9642, and 0.9923, respectively. For COVID-19 pneumonia/other pneumonia classification, the highest sensitivity, specificity, accuracy, F-1, and AUC values obtained without using pipeline approaches were 0.9615, 0.7270, 0.8846, 0.9180, and 0.9370, respectively; using pipeline approaches, the values were 0.9915, 0.8140, 0.9071, 0.9327, and 0.9615, respectively. The results of this study show that classification success can be increased by reducing the time to obtain per-image results through using the proposed pipeline approaches.},
  archive      = {J_CC},
  author       = {Yasar, Huseyin and Ceylan, Murat},
  doi          = {10.1007/s12559-021-09915-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1806-1833},
  shortjournal = {Cogn. Comput.},
  title        = {Deep Learning–Based approaches to improve classification parameters for diagnosing COVID-19 from CT images},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data analysis and forecasting of the COVID-19 spread: A
comparison of recurrent neural networks and time series models.
<em>CC</em>, <em>16</em>(4), 1794–1805. (<a
href="https://doi.org/10.1007/s12559-021-09885-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To understand and approach the spread of the SARS-CoV-2 epidemic, machine learning offers fundamental tools. This study presents the use of machine learning techniques for projecting COVID-19 infections and deaths in Mexico. The research has three main objectives: first, to identify which function adjusts the best to the infected population growth in Mexico; second, to determine the feature importance of climate and mobility; third, to compare the results of a traditional time series statistical model with a modern approach in machine learning. The motivation for this work is to support health care providers in their preparation and planning. The methods compared are linear, polynomial, and generalized logistic regression models to describe the growth of COVID-19 incidents in Mexico. Additionally, machine learning and time series techniques are used to identify feature importance and perform forecasting for daily cases and fatalities. The study uses the publicly available data sets from the John Hopkins University of Medicine in conjunction with the mobility rates obtained from Google’s Mobility Reports and climate variables acquired from the Weather Online API. The results suggest that the logistic growth model fits best the pandemic’s behavior, that there is enough correlation of climate and mobility variables with the disease numbers, and that the Long short-term memory network can be exploited for predicting daily cases. Given this, we propose a model to predict daily cases and fatalities for SARS-CoV-2 using time series data, mobility, and weather variables.},
  archive      = {J_CC},
  author       = {Gomez-Cravioto, Daniela A. and Diaz-Ramos, Ramon E. and Cantu-Ortiz, Francisco J. and Ceballos, Hector G.},
  doi          = {10.1007/s12559-021-09885-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1794-1805},
  shortjournal = {Cogn. Comput.},
  title        = {Data analysis and forecasting of the COVID-19 spread: A comparison of recurrent neural networks and time series models},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An early warning tool for predicting mortality risk of
COVID-19 patients using machine learning. <em>CC</em>, <em>16</em>(4),
1778–1793. (<a
href="https://doi.org/10.1007/s12559-020-09812-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 pandemic has created an extreme pressure on the global healthcare services. Fast, reliable, and early clinical assessment of the severity of the disease can help in allocating and prioritizing resources to reduce mortality. In order to study the important blood biomarkers for predicting disease mortality, a retrospective study was conducted on a dataset made public by Yan et al. in [1] of 375 COVID-19 positive patients admitted to Tongji Hospital (China) from January 10 to February 18, 2020. Demographic and clinical characteristics and patient outcomes were investigated using machine learning tools to identify key biomarkers to predict the mortality of individual patient. A nomogram was developed for predicting the mortality risk among COVID-19 patients. Lactate dehydrogenase, neutrophils (%), lymphocyte (%), high-sensitivity C-reactive protein, and age (LNLCA)—acquired at hospital admission—were identified as key predictors of death by multi-tree XGBoost model. The area under curve (AUC) of the nomogram for the derivation and validation cohort were 0.961 and 0.991, respectively. An integrated score (LNLCA) was calculated with the corresponding death probability. COVID-19 patients were divided into three subgroups: low-, moderate-, and high-risk groups using LNLCA cutoff values of 10.4 and 12.65 with the death probability less than 5%, 5–50%, and above 50%, respectively. The prognostic model, nomogram, and LNLCA score can help in early detection of high mortality risk of COVID-19 patients, which will help doctors to improve the management of patient stratification.},
  archive      = {J_CC},
  author       = {Chowdhury, Muhammad E. H. and Rahman, Tawsifur and Khandakar, Amith and Al-Madeed, Somaya and Zughaier, Susu M. and Doi, Suhail A. R. and Hassen, Hanadi and Islam, Mohammad T.},
  doi          = {10.1007/s12559-020-09812-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1778-1793},
  shortjournal = {Cogn. Comput.},
  title        = {An early warning tool for predicting mortality risk of COVID-19 patients using machine learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 infection detection from chest x-ray images using
hybrid social group optimization and support vector classifier.
<em>CC</em>, <em>16</em>(4), 1765–1777. (<a
href="https://doi.org/10.1007/s12559-021-09848-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel strain of Coronavirus, identified as the Severe Acute Respiratory Syndrome-2 (SARS-CoV-2), outbroke in December 2019 causing the novel Corona Virus Disease (COVID-19). Since its emergence, the virus has spread rapidly and has been declared a global pandemic. As of the end of January 2021, there are almost 100 million cases worldwide with over 2 million confirmed deaths. Widespread testing is essential to reduce further spread of the disease, but due to a shortage of testing kits and limited supply, alternative testing methods are being evaluated. Recently researchers have found that chest X-Ray (CXR) images provide salient information about COVID-19. An intelligent system can help the radiologists to detect COVID-19 from these CXR images which can come in handy at remote locations in many developing nations. In this work, we propose a pipeline that uses CXR images to detect COVID-19 infection. The features from the CXR images were extracted and the relevant features were then selected using Hybrid Social Group Optimization algorithm. The selected features were then used to classify the CXR images using a number of classifiers. The proposed pipeline achieves a classification accuracy of 99.65% using support vector classifier, which outperforms other state-of-the-art deep learning algorithms for binary and multi-class classification.},
  archive      = {J_CC},
  author       = {Singh, Asu Kumar and Kumar, Anupam and Mahmud, Mufti and Kaiser, M Shamim and Kishore, Akshat},
  doi          = {10.1007/s12559-021-09848-3},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1765-1777},
  shortjournal = {Cogn. Comput.},
  title        = {COVID-19 infection detection from chest X-ray images using hybrid social group optimization and support vector classifier},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning–driven automated detection of COVID-19 from
radiography images: A comparative analysis. <em>CC</em>, <em>16</em>(4),
1735–1764. (<a
href="https://doi.org/10.1007/s12559-020-09779-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has wreaked havoc on the whole world, taking over half a million lives and capsizing the world economy in unprecedented magnitudes. With the world scampering for a possible vaccine, early detection and containment are the only redress. Existing diagnostic technologies with high accuracy like RT-PCRs are expensive and sophisticated, requiring skilled individuals for specimen collection and screening, resulting in lower outreach. So, methods excluding direct human intervention are much sought after, and artificial intelligence-driven automated diagnosis, especially with radiography images, captured the researchers’ interest. This survey marks a detailed inspection of the deep learning–based automated detection of COVID-19 works done to date, a comparison of the available datasets, methodical challenges like imbalanced datasets and others, along with probable solutions with different preprocessing methods, and scopes of future exploration in this arena. We also benchmarked the performance of 315 deep models in diagnosing COVID-19, normal, and pneumonia from X-ray images of a custom dataset created from four others. The dataset is publicly available at https://github.com/rgbnihal2/COVID-19-X-ray-Dataset . Our results show that DenseNet201 model with Quadratic SVM classifier performs the best (accuracy: 98.16%, sensitivity: 98.93%, specificity: 98.77%) and maintains high accuracies in other similar architectures as well. This proves that even though radiography images might not be conclusive for radiologists, but it is so for deep learning algorithms for detecting COVID-19. We hope this extensive review will provide a comprehensive guideline for researchers in this field.},
  archive      = {J_CC},
  author       = {Rahman, Sejuti and Sarker, Sujan and Miraj, Md Abdullah Al and Nihal, Ragib Amin and Nadimul Haque, A. K. M. and Noman, Abdullah Al},
  doi          = {10.1007/s12559-020-09779-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1735-1764},
  shortjournal = {Cogn. Comput.},
  title        = {Deep Learning–Driven automated detection of COVID-19 from radiography images: A comparative analysis},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An agent-based modeling of COVID-19: Validation, analysis,
and recommendations. <em>CC</em>, <em>16</em>(4), 1723–1734. (<a
href="https://doi.org/10.1007/s12559-020-09801-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease 2019 (COVID-19) has resulted in an ongoing pandemic worldwide. Countries have adopted non-pharmaceutical interventions (NPI) to slow down the spread. This study proposes an agent-based model that simulates the spread of COVID-19 among the inhabitants of a city. The agent-based model can be accommodated for any location by integrating parameters specific to the city. The simulation gives the number of total COVID-19 cases. Considering each person as an agent susceptible to COVID-19, the model causes infected individuals to transmit the disease via various actions performed every hour. The model is validated by comparing the simulation to the real data of Ford County, KS, USA. Different interventions, including contact tracing, are applied on a scaled-down version of New York City, USA, and the parameters that lead to a controlled epidemic are determined. Our experiments suggest that contact tracing via smartphones with more than 60% of the population owning a smartphone combined with city-wide lockdown results in the effective reproduction number (Rt) to fall below 1 within 3 weeks of intervention. For 75% or more smartphone users, new infections are eliminated, and the spread is contained within 3 months of intervention. Contact tracing accompanied with early lockdown can suppress the epidemic growth of COVID-19 completely with sufficient smartphone owners. In places where it is difficult to ensure a high percentage of smartphone ownership, tracing only emergency service providers during a lockdown can go a long way to contain the spread.},
  archive      = {J_CC},
  author       = {Shamil, Md. Salman and Farheen, Farhanaz and Ibtehaz, Nabil and Khan, Irtesam Mahmud and Rahman, M. Sohel},
  doi          = {10.1007/s12559-020-09801-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1723-1734},
  shortjournal = {Cogn. Comput.},
  title        = {An agent-based modeling of COVID-19: Validation, analysis, and recommendations},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 4P model for dynamic prediction of COVID-19: A statistical
and machine learning approach. <em>CC</em>, <em>16</em>(4), 1709–1722.
(<a href="https://doi.org/10.1007/s12559-020-09786-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Around the world, scientists are racing hard to understand how the COVID-19 epidemic is spreading and growing, thus trying to find ways to prevent it before medications are available. Many different models have been proposed so far correlating different factors. Some of them are too localized to indicate a general trend of the pandemic while some others have established transient correlations only. Hence, in this study, taking Bangladesh as a case, a 4P model has been proposed based on four probabilities (4P) which have been found to be true for all affected countries. Efficiency scores have been estimated from survey analysis not only for governing authorities on managing the situation (P(G)) but also for the compliance of the citizens ((P(P)). Since immune responses to a specific pathogen can vary from person to person, the probability of a person getting infected ((P(I)) after being exposed has also been estimated. And the vital one is the probability of test positivity ((P(T)) which is a strong indicator of how effectively the infected people are diagnosed and isolated from the rest of the group that affects the rate of growth. All the four parameters have been fitted in a non-linear exponential model that partly updates itself periodically with everyday facts. Along with the model, all the four probabilistic parameters are engaged to train a recurrent neural network using long short-term memory neural network and the followed trial confirmed a ruling functionality of the 4Ps.},
  archive      = {J_CC},
  author       = {Hasan, Khandaker Tabin and Rahman, M. Mostafizur and Ahmmed, Md. Mortuza and Chowdhury, Anjir Ahmed and Islam, Mohammad Khairul},
  doi          = {10.1007/s12559-020-09786-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1709-1722},
  shortjournal = {Cogn. Comput.},
  title        = {4P model for dynamic prediction of COVID-19: A statistical and machine learning approach},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shallow convolutional neural network for COVID-19 outbreak
screening using chest x-rays. <em>CC</em>, <em>16</em>(4), 1695–1708.
(<a href="https://doi.org/10.1007/s12559-020-09775-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among radiological imaging data, Chest X-rays (CXRs) are of great use in observing COVID-19 manifestations. For mass screening, using CXRs, a computationally efficient AI-driven tool is the must to detect COVID-19-positive cases from non-COVID ones. For this purpose, we proposed a light-weight Convolutional Neural Network (CNN)-tailored shallow architecture that can automatically detect COVID-19-positive cases using CXRs, with no false negatives. The shallow CNN-tailored architecture was designed with fewer parameters as compared to other deep learning models. The shallow CNN-tailored architecture was validated using 321 COVID-19-positive CXRs. In addition to COVID-19-positive cases, another set of non-COVID-19 5856 cases (publicly available, source: Kaggle) was taken into account, consisting of normal, viral, and bacterial pneumonia cases. In our experimental tests, to avoid possible bias, 5-fold cross-validation was followed, and both balanced and imbalanced datasets were used. The proposed model achieved the highest possible accuracy of 99.69%, sensitivity of 1.0, where AUC was 0.9995. Furthermore, the reported false positive rate was only 0.0015 for 5856 COVID-19-negative cases. Our results stated that the proposed CNN could possibly be used for mass screening. Using the exact same set of CXR collection, the current results were better than other deep learning models and major state-of-the-art works.},
  archive      = {J_CC},
  author       = {Mukherjee, Himadri and Ghosh, Subhankar and Dhar, Ankita and Obaidullah, Sk Md and Santosh, K. C. and Roy, Kaushik},
  doi          = {10.1007/s12559-020-09775-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1695-1708},
  shortjournal = {Cogn. Comput.},
  title        = {Shallow convolutional neural network for COVID-19 outbreak screening using chest X-rays},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning-based potential ligand prediction framework
for COVID-19 with drug–target interaction model. <em>CC</em>,
<em>16</em>(4), 1682–1694. (<a
href="https://doi.org/10.1007/s12559-021-09840-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To fight against the present pandemic scenario of COVID-19 outbreak, medication with drugs and vaccines is extremely essential other than ventilation support. In this paper, we present a list of ligands which are expected to have the highest binding affinity with the S-glycoprotein of 2019-nCoV and thus can be used to make the drug for the novel coronavirus. Here, we implemented an architecture using 1D convolutional networks to predict drug–target interaction (DTI) values. The network was trained on the KIBA (Kinase Inhibitor Bioactivity) dataset. With this network, we predicted the KIBA scores (which gives a measure of binding affinity) of a list of ligands against the S-glycoprotein of 2019-nCoV. Based on these KIBA scores, we are proposing a list of ligands (33 top ligands based on best interactions) which have a high binding affinity with the S-glycoprotein of 2019-nCoV and thus can be used for the formation of drugs.},
  archive      = {J_CC},
  author       = {Majumdar, Shatadru and Nandi, Soumik Kumar and Ghosal, Shuvam and Ghosh, Bavrabi and Mallik, Writam and Roy, Nilanjana Dutta and Biswas, Arindam and Mukherjee, Subhankar and Pal, Souvik and Bhattacharyya, Nabarun},
  doi          = {10.1007/s12559-021-09840-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1682-1694},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning-based potential ligand prediction framework for COVID-19 with Drug–Target interaction model},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic screening of COVID-19 using an optimized
generative adversarial network. <em>CC</em>, <em>16</em>(4), 1666–1681.
(<a href="https://doi.org/10.1007/s12559-020-09785-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quick spread of coronavirus disease (COVID-19) has resulted in a global pandemic and more than fifteen million confirmed cases. To battle this spread, clinical imaging techniques, for example, computed tomography (CT), can be utilized for diagnosis. Automatic identification software tools are essential for helping to screen COVID-19 using CT images. However, there are few datasets available, making it difficult to train deep learning (DL) networks. To address this issue, a generative adversarial network (GAN) is proposed in this work to generate more CT images. The Whale Optimization Algorithm (WOA) is used to optimize the hyperparameters of GAN&#39;s generator. The proposed method is tested and validated with different classification and meta-heuristics algorithms using the SARS-CoV-2 CT-Scan dataset, consisting of COVID-19 and non-COVID-19 images. The performance metrics of the proposed optimized model, including accuracy (99.22%), sensitivity (99.78%), specificity (97.78%), F1-score (98.79%), positive predictive value (97.82%), and negative predictive value (99.77%), as well as its confusion matrix and receiver operating characteristic (ROC) curves, indicate that it performs better than state-of-the-art methods. This proposed model will help in the automatic screening of COVID-19 patients and decrease the burden on medicinal services frameworks.},
  archive      = {J_CC},
  author       = {Goel, Tripti and Murugan, R. and Mirjalili, Seyedali and Chakrabartty, Deba Kumar},
  doi          = {10.1007/s12559-020-09785-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1666-1681},
  shortjournal = {Cogn. Comput.},
  title        = {Automatic screening of COVID-19 using an optimized generative adversarial network},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 diagnosis via DenseNet and optimization of transfer
learning setting. <em>CC</em>, <em>16</em>(4), 1649–1665. (<a
href="https://doi.org/10.1007/s12559-020-09776-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is an ongoing pandemic disease. To make more accurate diagnosis on COVID-19 than existing approaches, this paper proposed a novel method combining DenseNet and optimization of transfer learning setting (OTLS) strategy. Preprocessing was used to enhance, crop, and resize the collected chest CT images. Data augmentation method was used to increase the size of training set. A composite learning factor (CLF) was employed which assigned different learning factor to three types of layers: frozen layers, middle layers, and new layers. Meanwhile, the OTLS strategy was proposed. Finally, precomputation method was utilized to reduce RAM storage and accelerate the algorithm. We observed that optimization setting “201-IV” can achieve the best performance by proposed OTLS strategy. The sensitivity, specificity, precision, and accuracy of our proposed method were 96.35 ± 1.07, 96.25 ± 1.16, 96.29 ± 1.11, and 96.30 ± 0.56, respectively. The proposed DenseNet-OTLS method achieved better performances than state-of-the-art approaches in diagnosing COVID-19.},
  archive      = {J_CC},
  author       = {Zhang, Yu-Dong and Satapathy, Suresh Chandra and Zhang, Xin and Wang, Shui-Hua},
  doi          = {10.1007/s12559-020-09776-8},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1649-1665},
  shortjournal = {Cogn. Comput.},
  title        = {COVID-19 diagnosis via DenseNet and optimization of transfer learning setting},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Principal component analysis applications in COVID-19 genome
sequence studies. <em>CC</em>, <em>16</em>(4), 1637–1648. (<a
href="https://doi.org/10.1007/s12559-020-09790-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RNA genomes from coronavirus have a length as long as 32 kilobases, and the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) that caused the outbreak of coronavirus disease 2019 (COVID-19) pandemic has long sequences which made the analysis difficult. Over 20,000 sequences have been submitted to GISAID, and the number is growing fast each day which increased the difficulties in data analysis; however, genome sequence analysis is critical in understanding the COVID-19 and preventing the spread of the disease. In this study, a principal component analysis (PCA) was applied to the aligned large size genome sequences and the numerical numbers were converted from the letters using a published method designed for protein sequence cluster analysis. The study initialized with a shortlist sequence testing, and the PCA score plot showed high tolerance with low-quality data, and the major virus sequences from humans were separated from the pangolin and bat samples. Our study also successfully built a model for a large number of sequences with more than 20,000 sequences which indicate the potential mutation directions for the COVID-19 which can be served as a pretreatment method for detailed studies such as decision tree-based methods. In summary, our study provided a fast tool to analyze the high-volume genome sequences such as the COVID-19 and successfully applied to more than 20,000 sequences which may provide mutation direction information for COVID-19 studies.},
  archive      = {J_CC},
  author       = {Wang, Bo and Jiang, Lin},
  doi          = {10.1007/s12559-020-09790-w},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1637-1648},
  shortjournal = {Cogn. Comput.},
  title        = {Principal component analysis applications in COVID-19 genome sequence studies},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating metamaterial antenna node and LiFi for privacy
preserving intelligent COVID-19 hospital patient management.
<em>CC</em>, <em>16</em>(4), 1623–1636. (<a
href="https://doi.org/10.1007/s12559-020-09778-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light fidelity (LiFi) and wireless fidelity (WiFi) can be applied with the same network under the different constraints, which is suitable for COVID-19 surveillance in hospitals. The LiFi network is a high-capacity and security platform. A COVID-19 surveillance system using LiFi is proposed, which consists of two switching modes: communication and surveillance. Firstly, the communication targets are to accommodate the electromagnetic interference (EMI) immunity and high-capacity and security data transmission, where secondly the COVID-19 surveillance can be applied. In operation, the up and downlink system uses a metamaterial antenna embedded by Mach Zehnder interferometer (MZI). An antenna consists of silver bars embedded at the microring center with two-phase modulators at its sides. The entangled source namely a dark soliton is applied to form the transmission, where the information security based on quantum cryptography can be managed. By using the suitable parameters, the whispering gallery modes (WGMs) are generated and the up and downlink nodes are formed. The input information is multiplexed with time to form the multiplexed signals, where the big data transmission (40 Pbit $${\mathrm{s}}^{-1})$$ can be employed. By using the surveillance mode, the plasmonic antenna can be applied for temperature and electric force sensors, which can offer the disinfectant spray and temperature sensor for COVID-19 applications. The optimum plasma force sensitivity is 0.16 N kg−1 mW−1. The center frequencies of 191.48 THz and 199.41 THz are obtained for uplink and downlink antennas, respectively. The optimum temperature sensitivity is 0.05 rads−1 °C−1. In conclusion, the novelty of proposed work is that the integrated sensor circuits are employed for COVID-19 surveillance in the hospital. The fuzzy-based system is designed for critical patient monitoring alert using this surveillance and management inside the hospital for COVID-19 patients.},
  archive      = {J_CC},
  author       = {Garhwal, A. and Bunruangses, M. and Arumona, A. E. and Youplao, P. and Ray, K. and Suwandee, S. and Yupapin, P.},
  doi          = {10.1007/s12559-020-09778-6},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1623-1636},
  shortjournal = {Cogn. Comput.},
  title        = {Integrating metamaterial antenna node and LiFi for privacy preserving intelligent COVID-19 hospital patient management},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COV19-CNNet and COV19-ResNet: Diagnostic inference engines
for early detection of COVID-19. <em>CC</em>, <em>16</em>(4), 1612–1622.
(<a href="https://doi.org/10.1007/s12559-020-09795-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest CT is used in the COVID-19 diagnosis process as a significant complement to the reverse transcription polymerase chain reaction (RT–PCR) technique. However, it has several drawbacks, including long disinfection and ventilation times, excessive radiation effects, and high costs. While X-ray radiography is more useful for detecting COVID-19, it is insensitive to the early stages of the disease. We have developed inference engines that will turn X-ray machines into powerful diagnostic tools by using deep learning technology to detect COVID-19. We named these engines COV19-CNNet and COV19-ResNet. The former is based on convolutional neural network architecture; the latter is on residual neural network (ResNet) architecture. This research is a retrospective study. The database consists of 210 COVID-19, 350 viral pneumonia, and 350 normal (healthy) chest X-ray (CXR) images that were created using two different data sources. This study was focused on the problem of multi-class classification (COVID-19, viral pneumonia, and normal), which is a rather difficult task for the diagnosis of COVID-19. The classification accuracy levels for COV19-ResNet and COV19-CNNet were 97.61% and 94.28%, respectively. The inference engines were developed from scratch using new and special deep neural networks without pre-trained models, unlike other studies in the field. These powerful diagnostic engines allow for the early detection of COVID-19 as well as distinguish it from viral pneumonia with similar radiological appearances. Thus, they can help in fast recovery at the early stages, prevent the COVID-19 outbreak from spreading, and contribute to reducing pressure on health-care systems worldwide.},
  archive      = {J_CC},
  author       = {Keles, Ayturk and Keles, Mustafa Berk and Keles, Ali},
  doi          = {10.1007/s12559-020-09795-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1612-1622},
  shortjournal = {Cogn. Comput.},
  title        = {COV19-CNNet and COV19-ResNet: Diagnostic inference engines for early detection of COVID-19},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A study of the neutrosophic set significance on deep
transfer learning models: An experimental case on a limited COVID-19
chest x-ray dataset. <em>CC</em>, <em>16</em>(4), 1602–1611. (<a
href="https://doi.org/10.1007/s12559-020-09802-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronavirus, also known as COVID-19, has spread to several countries around the world. It was announced as a pandemic disease by The World Health Organization (WHO) in 2020 for its devastating impact on humans. With the advancements in computer science algorithms, the detection of this type of virus in the early stages is urgently needed for the fast recovery of patients. In this paper, a study of neutrosophic set significance on deep transfer learning models will be presented. The study will be conducted over a limited COVID-19 x-ray. The study relies on neutrosophic set and theory to convert the medical images from the grayscale spatial domain to the neutrosophic domain. The neutrosophic domain consists of three types of images, and they are the True (T) images, the Indeterminacy (I) images, and the Falsity (F) images. The dataset used in this research has been collected from different sources. The dataset is classified into four classes {COVID-19, normal, pneumonia bacterial, and pneumonia virus}. This study aims to review the effect of neutrosophic sets on deep transfer learning models. The selected deep learning models in this study are Alexnet, Googlenet, and Restnet18. Those models are selected as they have a small number of layers on their architectures. To test the performance of the conversion to the neutrosophic domain, more than 36 trials have been conducted and recorded. A combination of training and testing strategies by splitting the dataset into (90–10%, 80–20%, 70–30) is included in the experiments. Four domains of images are tested, and they are, the original domain, the True (T) domain, the Indeterminacy (I) domain, and the Falsity (F) domain. The four domains with the different training and testing strategies were tested using the selected deep transfer models. According to the experimental results, the Indeterminacy (I) neutrosophic domain achieves the highest accuracy possible with 87.1% in the testing accuracy and performance metrics such as Precision, Recall, and F1 Score. The study concludes that using the neutrosophic set with deep learning models may be an encouraging transition to achieve better testing accuracy, especially with limited COVID-19 datasets.},
  archive      = {J_CC},
  author       = {Khalifa, Nour Eldeen M. and Smarandache, Florentin and Manogaran, Gunasekaran and Loey, Mohamed},
  doi          = {10.1007/s12559-020-09802-9},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1602-1611},
  shortjournal = {Cogn. Comput.},
  title        = {A study of the neutrosophic set significance on deep transfer learning models: An experimental case on a limited COVID-19 chest X-ray dataset},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pneumonia classification using deep learning from chest
x-ray images during COVID-19. <em>CC</em>, <em>16</em>(4), 1589–1601.
(<a href="https://doi.org/10.1007/s12559-020-09787-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of the novel corona virus disease (COVID-19) in December 2019 has led to global crisis around the world. The disease was declared pandemic by World Health Organization (WHO) on 11th of March 2020. Currently, the outbreak has affected more than 200 countries with more than 37 million confirmed cases and more than 1 million death tolls as of 10 October 2020. Reverse-transcription polymerase chain reaction (RT-PCR) is the standard method for detection of COVID-19 disease, but it has many challenges such as false positives, low sensitivity, expensive, and requires experts to conduct the test. As the number of cases continue to grow, there is a high need for developing a rapid screening method that is accurate, fast, and cheap. Chest X-ray (CXR) scan images can be considered as an alternative or a confirmatory approach as they are fast to obtain and easily accessible. Though the literature reports a number of approaches to classify CXR images and detect the COVID-19 infections, the majority of these approaches can only recognize two classes (e.g., COVID-19 vs. normal). However, there is a need for well-developed models that can classify a wider range of CXR images belonging to the COVID-19 class itself such as the bacterial pneumonia, the non-COVID-19 viral pneumonia, and the normal CXR scans. The current work proposes the use of a deep learning approach based on pretrained AlexNet model for the classification of COVID-19, non-COVID-19 viral pneumonia, bacterial pneumonia, and normal CXR scans obtained from different public databases. The model was trained to perform two-way classification (i.e., COVID-19 vs. normal, bacterial pneumonia vs. normal, non-COVID-19 viral pneumonia vs. normal, and COVID-19 vs. bacterial pneumonia), three-way classification (i.e., COVID-19 vs. bacterial pneumonia vs. normal), and four-way classification (i.e., COVID-19 vs. bacterial pneumonia vs. non-COVID-19 viral pneumonia vs. normal). For non-COVID-19 viral pneumonia and normal (healthy) CXR images, the proposed model achieved 94.43% accuracy, 98.19% sensitivity, and 95.78% specificity. For bacterial pneumonia and normal CXR images, the model achieved 91.43% accuracy, 91.94% sensitivity, and 100% specificity. For COVID-19 pneumonia and normal CXR images, the model achieved 99.16% accuracy, 97.44% sensitivity, and 100% specificity. For classification CXR images of COVID-19 pneumonia and non-COVID-19 viral pneumonia, the model achieved 99.62% accuracy, 90.63% sensitivity, and 99.89% specificity. For the three-way classification, the model achieved 94.00% accuracy, 91.30% sensitivity, and 84.78%. Finally, for the four-way classification, the model achieved an accuracy of 93.42%, sensitivity of 89.18%, and specificity of 98.92%.},
  archive      = {J_CC},
  author       = {Ibrahim, Abdullahi Umar and Ozsoz, Mehmet and Serte, Sertan and Al-Turjman, Fadi and Yakoi, Polycarp Shizawaliyi},
  doi          = {10.1007/s12559-020-09787-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1589-1601},
  shortjournal = {Cogn. Comput.},
  title        = {Pneumonia classification using deep learning from chest X-ray images during COVID-19},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smart data driven decision trees ensemble methodology for
imbalanced big data. <em>CC</em>, <em>16</em>(4), 1572–1588. (<a
href="https://doi.org/10.1007/s12559-024-10295-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differences in data size per class, also known as imbalanced data distribution, have become a common problem affecting data quality. Big Data scenarios pose a new challenge to traditional imbalanced classification algorithms, since they are not prepared to work with such amount of data. Split data strategies and lack of data in the minority class due to the use of MapReduce paradigm have posed new challenges for tackling the imbalance between classes in Big Data scenarios. Ensembles have been shown to be able to successfully address imbalanced data problems. Smart Data refers to data of enough quality to achieve high-performance models. The combination of ensembles and Smart Data, achieved through Big Data preprocessing, should be a great synergy. In this paper, we propose a novel Smart Data driven Decision Trees Ensemble methodology for addressing the imbalanced classification problem in Big Data domains, namely SD_DeTE methodology. This methodology is based on the learning of different decision trees using distributed quality data for the ensemble process. This quality data is achieved by fusing random discretization, principal components analysis, and clustering-based random oversampling for obtaining different Smart Data versions of the original data. Experiments carried out in 21 binary adapted datasets have shown that our methodology outperforms random forest.},
  archive      = {J_CC},
  author       = {García-Gil, Diego and García, Salvador and Xiong, Ning and Herrera, Francisco},
  doi          = {10.1007/s12559-024-10295-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1572-1588},
  shortjournal = {Cogn. Comput.},
  title        = {Smart data driven decision trees ensemble methodology for imbalanced big data},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-task shared cascade learning for aspect sentiment
triplet extraction using BERT-MRC. <em>CC</em>, <em>16</em>(4),
1554–1571. (<a
href="https://doi.org/10.1007/s12559-024-10247-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aspect sentiment triplet extraction (Triplet) aims at extracting aspect terms (AE), extracting aspect-oriented opinion terms (AOE), and discriminating aspect-level sentiment polarity (ASC) from the comments. To address the current study, the end-to-end framework-based approach suffers from the problem of contribution distribution among multiple components, while the pipeline framework-based approach is susceptible to error propagation. Moreover, the complexity of the model limits the detection of long-distance aspect terms and opinion terms. In this paper, we propose a framework based on multi-task shared cascade learning and machine reading comprehension (MRC), which is called Triple-MRC. The multi-task shared cascade learning can effectively avoid the problem of contribution distribution among components. The MRC approach leverages the prior knowledge from the question to reduce the error propagation between tasks and mitigate the limitation associated with model complexity. We conduct experiments on publicly available two benchmark datasets for the Triplet task. The experimental results demonstrate the superior performance of the Triple-MRC framework compared to the baseline model, which better achieves the Triplet task. Through the analysis of the comparison study, model training process, error analysis, ablation study, attention visualization, and case study, we have confirmed the effectiveness of introducing the multi-task shared cascade learning method and MRC method into the model.},
  archive      = {J_CC},
  author       = {Zou, Wang and Zhang, Wubo and Wu, Wenhuan and Tian, Zhuoyan},
  doi          = {10.1007/s12559-024-10247-7},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1554-1571},
  shortjournal = {Cogn. Comput.},
  title        = {A multi-task shared cascade learning for aspect sentiment triplet extraction using BERT-MRC},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neurosymbolic AI for mining public opinions about wildfires.
<em>CC</em>, <em>16</em>(4), 1531–1553. (<a
href="https://doi.org/10.1007/s12559-023-10195-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wildfires are among the most threatening hazards to life, property, well-being, and the environment. Studying public opinions about wildfires can help monitor the perception of the impacted communities. Nevertheless, wildfire research is relatively limited compared to other climate-related hazards. This article presents our data mining work on public opinions about wildfires in Australia from 2014 to 2021. Three key aspects are analyzed: the topic of concern, sentiment polarization, and perceived emotions. We propose a data filtering approach to acquire golden samples to train a supervised model for emotion quantification to achieve the last target. The results show that the new model produces a more accurate emotion estimation than the existing lexicon approach. Through data analysis, we find that people have seen wildfires as one of the impacts of climate change; trends of tweets can reflect the damage of wildfires in real life.},
  archive      = {J_CC},
  author       = {Duong, Cuc and Raghuram, Vethavikashini Chithrra and Lee, Amos and Mao, Rui and Mengaldo, Gianmarco and Cambria, Erik},
  doi          = {10.1007/s12559-023-10195-8},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1531-1553},
  shortjournal = {Cogn. Comput.},
  title        = {Neurosymbolic AI for mining public opinions about wildfires},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A review of key technologies for emotion analysis using
multimodal information. <em>CC</em>, <em>16</em>(4), 1504–1530. (<a
href="https://doi.org/10.1007/s12559-024-10287-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion analysis, an integral aspect of human–machine interactions, has witnessed significant advancements in recent years. With the rise of multimodal data sources such as speech, text, and images, there is a profound need for a comprehensive review of pivotal elements within this domain. Our paper delves deep into the realm of emotion analysis, examining multimodal data sources encompassing speech, text, images, and physiological signals. We provide a curated overview of relevant literature, academic forums, and competitions. Emphasis is laid on dissecting unimodal processing methods, including preprocessing, feature extraction, and tools across speech, text, images, and physiological signals. We further discuss the nuances of multimodal data fusion techniques, spotlighting early, late, model, and hybrid fusion strategies. Key findings indicate the essentiality of analyzing emotions across multiple modalities. Detailed discussions on emotion elicitation, expression, and representation models are presented. Moreover, we uncover challenges such as dataset creation, modality synchronization, model efficiency, limited data scenarios, cross-domain applicability, and the handling of missing modalities. Practical solutions and suggestions are provided to address these challenges. The realm of multimodal emotion analysis is vast, with numerous applications ranging from driver sentiment detection to medical evaluations. Our comprehensive review serves as a valuable resource for both scholars and industry professionals. It not only sheds light on the current state of research but also highlights potential directions for future innovations. The insights garnered from this paper are expected to pave the way for subsequent advancements in deep multimodal emotion analysis tailored for real-world deployments.},
  archive      = {J_CC},
  author       = {Zhu, Xianxun and Guo, Chaopeng and Feng, Heyang and Huang, Yao and Feng, Yichen and Wang, Xiangyang and Wang, Rui},
  doi          = {10.1007/s12559-024-10287-z},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1504-1530},
  shortjournal = {Cogn. Comput.},
  title        = {A review of key technologies for emotion analysis using multimodal information},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CPD-NSL: A two-stage brain effective connectivity network
construction method based on dynamic bayesian network. <em>CC</em>,
<em>16</em>(4), 1484–1503. (<a
href="https://doi.org/10.1007/s12559-024-10296-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current brain science reveals that the connectivity patterns of the human brain are constantly changing when performing different tasks. Thus, brain effective connectivity networks based on non-stationary assumption can describe such neurodynamics better than the ones based on stationary assumption. However, existing methods for inferring non-stationary brain effective connectivity networks are committed to estimating the change points and network structures simultaneously. It is even worse that these methods will inevitably focus on one part of the estimation process and lead to the deviation of the results obtained by the other part. Then, the construction results of non-stationary brain effective connectivity networks cannot accurately reflect the real brain dynamics. In this paper, a novel approach to constructing non-stationary brain effective connectivity networks is proposed, namely CPD-NSL. It involves two stages including change point detection and network structure learning. In the first stage, the latent block model is used, and then the improved forward-backward search method is used to construct the stationary networks between adjacent change points in the network structure learning part. Finally, the constructed stationary networks are arranged in chronological order to obtain the final time-varying brain effective connectivity network. CPD-NSL is validated using simulated data as well as real fMRI data from HCP public datasets. The results show that CPD-NSL can restore the real network more accurately and consume less time. Experimental results on both simulated and real data demonstrate the effectiveness of the proposed method in constructing non-stationary state brain effective connectivity networks.},
  archive      = {J_CC},
  author       = {Wang, Zhiqiong and Chen, Qi and Wang, Zhongyang and Wang, Xinlei and Qu, Luxuan and Xin, Junchang},
  doi          = {10.1007/s12559-024-10296-y},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1484-1503},
  shortjournal = {Cogn. Comput.},
  title        = {CPD-NSL: A two-stage brain effective connectivity network construction method based on dynamic bayesian network},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel memristors based echo state network model inspired
by the brain’s uni-hemispheric slow-wave sleep characteristics.
<em>CC</em>, <em>16</em>(4), 1470–1483. (<a
href="https://doi.org/10.1007/s12559-024-10265-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristors serve as electronic components with the ability to store charge and demonstrate resistive states, which are similar to the synaptic connections between biological neurons. For this reason, they have been widely applied in the research and development of neuromorphic computing models to achieve functions similar to synaptic transmission. As early as the 1960s, some studies suggested that some animals could enter a sleep state in which one hemisphere of the brain is in an asleep state while the other remains active, controlling essential physiological functions like breathing, swimming, and avoiding danger. This phenomenon is known as uni-hemispheric slow-wave sleep (USWS). On the other hand, the echo state network (ESN) is a kind of neural network that has a simple but high-efficiency structure and has garnered significant attention lately. However, there is limited research on using ESN and MEM to simulate USWS. In this paper, we propose a new echo state network model based on memristors, which is used to simulate the brain of animals with USWS. In our model, two ESNs based on memristors are used as the left and right brains to switch between sleep and wakefulness. In addition, we use an elastic network to optimize the output, which combines the advantages of ridge regression and lasso regression. Finally, we evaluate the results using mean squared error (MSE). Our model demonstrates effective sequence data prediction and classification with high stability. Nevertheless, a drawback associated with this is the extended time required to accomplish the tasks. This paper proposes a new ESN model based on memristors, which simulates the USWS characteristics of the brain using the new intelligent component memristor. It addresses the architectural limitations of ESN and promotes the further development of memristor neural networks and brain-inspired models.},
  archive      = {J_CC},
  author       = {Sun, Jingyu and Li, Lixiang and Peng, Haipeng and Meng, Yin},
  doi          = {10.1007/s12559-024-10265-5},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1470-1483},
  shortjournal = {Cogn. Comput.},
  title        = {A novel memristors based echo state network model inspired by the brain’s uni-hemispheric slow-wave sleep characteristics},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-resolution twinned residual auto-encoders (MR-TRAE)—a
novel DL model for image multi-resolution. <em>CC</em>, <em>16</em>(4),
1447–1469. (<a
href="https://doi.org/10.1007/s12559-024-10293-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design and evaluate the performance of the Multi-resolution Twinned Residual Auto-Encoders (MR-TRAE) model, a deep learning (DL)-based architecture specifically designed for achieving multi-resolution super-resolved images from low-resolution (LR) inputs at various scaling factors. For this purpose, we expand on the recently introduced Twinned Residual Auto-Encoders (TRAE) paradigm for single-image super-resolution (SISR) to extend it to the multi-resolution (MR) domain. The main contributions of this work include (i) the architecture of the MR-TRAE model, which utilizes cascaded trainable up-sampling modules for progressively increasing the spatial resolution of low-resolution (LR) input images at multiple scaling factors; (ii) a novel loss function designed for the joint and semi-blind training of all MR-TRAE model components; and (iii) a comprehensive analysis of the MR-TRAE trade-off between model complexity and performance. Furthermore, we thoroughly explore the connections between the MR-TRAE architecture and broader cognitive paradigms, including knowledge distillation, the teacher-student learning model, and hierarchical cognition. Performance evaluations of the MR-TRAE benchmarked against state-of-the-art models (such as U-Net, generative adversarial network (GAN)-based, and single-resolution baselines) were conducted using publicly available datasets. These datasets consist of LR computer tomography (CT) scans from patients with COVID-19. Our tests, which explored multi-resolutions at scaling factors $$\times (2,4,8)$$ , showed a significant finding: the MR-TRAE model can reduce training times by up to $$60\%$$ compared to those of the baselines, without a noticeable impact on achieved performance.},
  archive      = {J_CC},
  author       = {Momenzadeh, Alireza and Baccarelli, Enzo and Scarpiniti, Michele and Sarv Ahrabi, Sima},
  doi          = {10.1007/s12559-024-10293-1},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1447-1469},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-resolution twinned residual auto-encoders (MR-TRAE)—A novel DL model for image multi-resolution},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating explainable machine learning models for
clinicians. <em>CC</em>, <em>16</em>(4), 1436–1446. (<a
href="https://doi.org/10.1007/s12559-024-10297-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaining clinicians’ trust will unleash the full potential of artificial intelligence (AI) in medicine, and explaining AI decisions is seen as the way to build trustworthy systems. However, explainable artificial intelligence (XAI) methods in medicine often lack a proper evaluation. In this paper, we present our evaluation methodology for XAI methods using forward simulatability. We define the Forward Simulatability Score (FSS) and analyze its limitations in the context of clinical predictors. Then, we applied FSS to our XAI approach defined over an ML-RO, a machine learning clinical predictor based on random optimization over a multiple kernel support vector machine (SVM) algorithm. To Compare FSS values before and after the explanation phase, we test our evaluation methodology for XAI methods on three clinical datasets, namely breast cancer, VTE, and migraine. The ML-RO system is a good model on which to test our XAI evaluation strategy based on the FSS. Indeed, ML-RO outperforms two other base models—a decision tree (DT) and a plain SVM—in the three datasets and gives the possibility of defining different XAI models: TOPK, MIGF, and F4G. The FSS evaluation score suggests that the explanation method F4G for the ML-RO is the most effective in two datasets out of the three tested, and it shows the limits of the learned model for one dataset. Our study aims to introduce a standard practice for evaluating XAI methods in medicine. By establishing a rigorous evaluation framework, we seek to provide healthcare professionals with reliable tools for assessing the performance of XAI methods to enhance the adoption of AI systems in clinical practice.},
  archive      = {J_CC},
  author       = {Scarpato, Noemi and Nourbakhsh, Aria and Ferroni, Patrizia and Riondino, Silvia and Roselli, Mario and Fallucchi, Francesca and Barbanti, Piero and Guadagni, Fiorella and Zanzotto, Fabio Massimo},
  doi          = {10.1007/s12559-024-10297-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1436-1446},
  shortjournal = {Cogn. Comput.},
  title        = {Evaluating explainable machine learning models for clinicians},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuromorphic cognitive learning systems: The future of
artificial intelligence? <em>CC</em>, <em>16</em>(4), 1433–1435. (<a
href="https://doi.org/10.1007/s12559-024-10308-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this position paper, I outline the caveats of the current artificial intelligence (AI) field driven by deep learning (DL) and large data volumes. Although AI/DL has demonstrated huge potential and attracted huge investments globally, it encounters big problems – it not only need to collect huge datasets and spend enormous time and resources to be trained on them, but also the trained system cannot deal effectively with any never encountered before (novel) data. From a human perspective, any current AI/DL system is completely unintelligent. It is only able to represent information but have no awareness of what this information means. I propose as an alternative the Neuromorphic Cognitive Learning Systems (NCLS), intimate imitations of animal and human brains, able to address the AI/DL limitations and achieve true artificial general intelligence. Similar to human and animal brains NCLS are unparalleled in their ability to rapidly, and on their own, adapt and learn from changing and unexpected environmental contingencies with very limited resources. I describe how NCLS driven AI inspired by human/animal brains can pave the way to new computing technologies with the potential to revolutionize the industry, economy and society. It is my strong belief that NCLS investigations will have major impact to real-time autonomous systems to achieve human-like intelligence capabilities.},
  archive      = {J_CC},
  author       = {Cutsuridis, Vassilis},
  doi          = {10.1007/s12559-024-10308-x},
  journal      = {Cognitive Computation},
  month        = {7},
  number       = {4},
  pages        = {1433-1435},
  shortjournal = {Cogn. Comput.},
  title        = {Neuromorphic cognitive learning systems: The future of artificial intelligence?},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diabetic foot ulcer detection: Combining deep learning
models for improved localization. <em>CC</em>, <em>16</em>(3),
1413–1431. (<a
href="https://doi.org/10.1007/s12559-024-10267-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes mellitus (DM) can cause chronic foot issues and severe infections, including Diabetic Foot Ulcers (DFUs) that heal slowly due to insufficient blood flow. A recurrence of these ulcers can lead to 84% of lower limb amputations and even cause death. High-risk diabetes patients require expensive medications, regular check-ups, and proper personal hygiene to prevent DFUs, which affect 15–25% of diabetics. Accurate diagnosis, appropriate care, and prompt response can prevent amputations and fatalities through early and reliable DFU detection from image analysis. We propose a comprehensive deep learning-based system for detecting DFUs from patients’ feet images by reliably localizing ulcer points. Our method utilizes innovative model ensemble techniques—non-maximum suppression (NMS), Soft-NMS, and weighted bounding box fusion (WBF)—to combine predictions from state-of-the-art object detection models. The performances of diverse cutting-edge model architectures used in this study complement each other, leading to more generalized and improved results when combined in an ensemble. Our WBF-based approach combining YOLOv8m and FRCNN-ResNet101 achieves a mean average precision (mAP) score of 86.4% at the IoU threshold of 0.5 on the DFUC2020 dataset, significantly outperforming the former benchmark by 12.4%. We also perform external validation on the IEEE DataPort Diabetic Foot dataset which has demonstrated robust and reliable model performance on the qualitative analysis. In conclusion, our study effectively developed an innovative diabetic foot ulcer (DFU) detection system using an ensemble model of deep neural networks (DNNs). This AI-driven tool serves as an initial screening aid for medical professionals, augmenting the diagnostic process by enhancing sensitivity to potential DFU cases. While recognizing the presence of false positives, our research contributes to improving patient care through the integration of human medical expertise with AI-based solutions in DFU management.},
  archive      = {J_CC},
  author       = {Sarmun, Rusab and Chowdhury, Muhammad E. H. and Murugappan, M. and Aqel, Ahmed and Ezzuddin, Maymouna and Rahman, Syed Mahfuzur and Khandakar, Amith and Akter, Sanzida and Alfkey, Rashad and Hasan, Anwarul},
  doi          = {10.1007/s12559-024-10267-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1413-1431},
  shortjournal = {Cogn. Comput.},
  title        = {Diabetic foot ulcer detection: Combining deep learning models for improved localization},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TB-CXRNet: Tuberculosis and drug-resistant tuberculosis
detection technique using chest x-ray images. <em>CC</em>,
<em>16</em>(3), 1393–1412. (<a
href="https://doi.org/10.1007/s12559-024-10259-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tuberculosis (TB) is a chronic infectious lung disease, which caused the death of about 1.5 million people in 2020 alone. Therefore, it is important to detect TB accurately at an early stage to prevent the infection and associated deaths. Chest X-ray (CXR) is the most popularly used method for TB diagnosis. However, it is difficult to identify TB from CXR images in the early stage, which leads to time-consuming and expensive treatments. Moreover, due to the increase of drug-resistant tuberculosis, the disease becomes more challenging in recent years. In this work, a novel deep learning-based framework is proposed to reliably and automatically distinguish TB, non-TB (other lung infections), and healthy patients using a dataset of 40,000 CXR images. Moreover, a stacking machine learning-based diagnosis of drug-resistant TB using 3037 CXR images of TB patients is implemented. The largest drug-resistant TB dataset will be released to develop a machine learning model for drug-resistant TB detection and stratification. Besides, Score-CAM-based visualization technique was used to make the model interpretable to see where the best performing model learns from in classifying the image. The proposed approach shows an accuracy of 93.32% for the classification of TB, non-TB, and healthy patients on the largest dataset while around 87.48% and 79.59% accuracy for binary classification (drug-resistant vs drug-sensitive TB), and three-class classification (multi-drug resistant (MDR), extreme drug-resistant (XDR), and sensitive TB), respectively, which is the best reported result compared to the literature. The proposed solution can make fast and reliable detection of TB and drug-resistant TB from chest X-rays, which can help in reducing disease complications and spread.},
  archive      = {J_CC},
  author       = {Rahman, Tawsifur and Khandakar, Amith and Rahman, Ashiqur and Zughaier, Susu M. and Al Maslamani, Muna and Chowdhury, Moajjem Hossain and Tahir, Anas M. and Hossain, Md. Sakib Abrar and Chowdhury, Muhammad E. H.},
  doi          = {10.1007/s12559-024-10259-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1393-1412},
  shortjournal = {Cogn. Comput.},
  title        = {TB-CXRNet: Tuberculosis and drug-resistant tuberculosis detection technique using chest X-ray images},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SPS vision net: Measuring sensory processing sensitivity via
an artificial neural network. <em>CC</em>, <em>16</em>(3), 1379–1392.
(<a href="https://doi.org/10.1007/s12559-023-10216-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensory processing sensitivity (SPS) is a biological trait associated with heightened sensitivity and responsivity to the environment. One important question is how those with the trait perceive their environments, thus giving rise to differential responses and outcomes. In this study, we used an artificial intelligence (AI) model—SPS Vision Net—to investigate perceptual differences associated with SPS and to begin to predict sensitivity levels based on a visual perception task. 190 participants (M age = 22.91; 102 (53%) females), completed an online experiment where they rated 100 images from the Open Affective Standardized Image Set (OASIS) on arousal, valence, and visual saliency. They also completed the Highly Sensitive Person (HSP) Scale measure of SPS. Results showed that SPS was positively associated with arousal in response to negative (vs. positive and neutral images), and, namely, sad (vs. happy, neutral, or fear) images. Also, SPS was negatively associated with positive ratings of negative images, specifically those showing frightening images. SPS was unrelated to response times and the number of salient selection blocks made. However, the AI model showed high accuracy (83.31%) in predicting SPS levels (R2 = 0.77). Consistent with theory and research, this study showed that SPS is associated with higher arousal and lower positive ratings in response to the OASIS image rating task. Novel findings showed that a new, accurate AI-backed SPS measurement system, based on a visual selection, was predictive of HSP scores with high accuracy. Finally, the AI model indicates that visual perception differs as a function of SPS.},
  archive      = {J_CC},
  author       = {Sadeghzadeh, Nima and Farajzadeh, Nacer and Dattatri, Novia and Acevedo, Bianca P.},
  doi          = {10.1007/s12559-023-10216-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1379-1392},
  shortjournal = {Cogn. Comput.},
  title        = {SPS vision net: Measuring sensory processing sensitivity via an artificial neural network},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fuzzy ensemble-based deep learning model for EEG-based
emotion recognition. <em>CC</em>, <em>16</em>(3), 1364–1378. (<a
href="https://doi.org/10.1007/s12559-023-10171-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition from EEG signals is a major field of research in cognitive computing. The major challenges involved in the task are extracting meaningful features from the signals and building an accurate model. This paper proposes a fuzzy ensemble-based deep learning approach to classify emotions from EEG-based models. Three individual deep learning models have been trained and combined using a fuzzy rank-based approach implemented using the Gompertz function. The model has been tested on two benchmark datasets: DEAP and AMIGOS. Our model has achieved 90.84% and 91.65% accuracies on the valence and arousal dimensions, respectively, for the DEAP dataset. The model also achieved accuracy above 95% on the DEAP dataset for the subject-dependent approach. On the AMIGOS dataset, our model has achieved state-of-the-art accuracies of 98.73% and 98.39% on the valence and arousal dimensions, respectively. The model achieved accuracies of 99.38% and 98.66% for the subject-independent and subject-dependent cases, respectively. The proposed model has provided satisfactory results on both DEAP and AMIGOS datasets and in both subject-dependent and subject-independent setups. Hence, we can conclude that this is a robust model for emotion recognition from EEG signals.},
  archive      = {J_CC},
  author       = {Dhara, Trishita and Singh, Pawan Kumar and Mahmud, Mufti},
  doi          = {10.1007/s12559-023-10171-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1364-1378},
  shortjournal = {Cogn. Comput.},
  title        = {A fuzzy ensemble-based deep learning model for EEG-based emotion recognition},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel discrete deep learning–based cancer classification
methodology. <em>CC</em>, <em>16</em>(3), 1345–1363. (<a
href="https://doi.org/10.1007/s12559-023-10170-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is one of the most well-known data mining branches used in diverse domains and fields. In the literature, many different classification techniques, such as statistical/intelligent, linear/nonlinear, fuzzy/crisp, shallow/deep, and single/hybrid, have been developed to cover data and systems with different characteristics. Intelligent classification approaches, especially deep learning classifiers, due to their unique features to provide accurate and efficient results, have recently attracted a lot of attention. However, in the learning process of the intelligent classifiers, a continuous distance-based cost function is used to estimate the connection weights, though the goal function in classification problems is discrete and using a continuous cost function in their learning process is unreasonable and inefficient. In this paper, a novel discrete learning–based methodology is proposed to estimate the connection weights of intelligent classifiers more accurately. In the proposed learning process, they are discretely adjusted and at once jumped to the target. This is in contrast to conventional continuous learning algorithms in which the connection weights are continuously adjusted and step by step near the target. In the present research, the proposed methodology is exemplarily applied to the deep neural network (DNN), which is one of the most recognized deep classification approaches, with a solid mathematical foundation and strong practical results in complex problems. Although the proposed methodology is just implemented on the DNN, it is a general methodology that can be similarly applied to other shallow and deep intelligent classification models. It can be generally demonstrated that the performance of the proposed discrete learning–based DNN (DIDNN) model, due to its consistency property, will not be worse than the conventional ones. The proposed DIDNN model is exemplarily evaluated on some well-known cancer classification benchmarks to illustrate the efficiency of the proposed model. The empirical results indicate that the proposed model outperforms the conventional versions of the selected deep approach in all data sets. Based on the performance analysis, the DIDNN model can improve the performance of the classic version by approximately 3.39%. Therefore, using this technique is an appropriate and effective alternative to conventional DNN-based models for classification purposes.},
  archive      = {J_CC},
  author       = {Soltani, Marzieh and Khashei, Mehdi and Bakhtiarvand, Negar},
  doi          = {10.1007/s12559-023-10170-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1345-1363},
  shortjournal = {Cogn. Comput.},
  title        = {A novel discrete deep Learning–Based cancer classification methodology},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards automated optimization of residual convolutional
neural networks for electrocardiogram classification. <em>CC</em>,
<em>16</em>(3), 1334–1344. (<a
href="https://doi.org/10.1007/s12559-022-10103-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interpretation of biological data such as the ElectroCardioGram (ECG) signal gives clinical information and helps to assess the heart function. There are distinct ECG patterns associated with a specific class of arrhythmia. The convolutional neural network, inspired by findings in the study of biological vision, is currently one of the most commonly employed deep neural network algorithms for ECG processing. However, deep neural network models require many hyperparameters to tune. Selecting the optimal or the best hyperparameter for the convolutional neural network algorithm is a highly challenging task. Often, we end up tuning the model manually with different possible ranges of values until a best fit model is obtained. Automatic hyperparameters tuning using Bayesian Optimization (BO) and evolutionary algorithms can provide an effective solution to current labour-intensive manual configuration approaches. In this paper, we propose to optimize the Residual one Dimensional Convolutional Neural Network model (R-1D-CNN) at two levels. At the first level, a residual convolutional layer and one-dimensional convolutional neural layers are trained to learn patient-specific ECG features over which multilayer perceptron layers can learn to produce the final class vectors of each input. This level is manual and aims to limit the search space and select the most important hyperparameters to optimize. The second level is automatic and based on our proposed BO-based algorithm. Our optimized proposed architecture (BO-R-1D-CNN) is evaluated on two publicly available ECG datasets. Comparative experimental results demonstrate that our BO-based algorithm achieves an optimal rate of 99.95% for the MIT-BIH database to discriminate between five kinds of heartbeats, including normal heartbeats, left bundle branch block, atrial premature, right bundle branch block, and premature ventricular contraction. Moreover, experiments demonstrate that the proposed architecture fine-tuned with BO achieves a higher accuracy tested on the 10,000 ECG patients dataset compared to the other proposed architectures. Our optimized architecture achieves excellent results compared to previous works on the two benchmark datasets.},
  archive      = {J_CC},
  author       = {Fki, Zeineb and Ammar, Boudour and Ayed, Mounir Ben},
  doi          = {10.1007/s12559-022-10103-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1334-1344},
  shortjournal = {Cogn. Comput.},
  title        = {Towards automated optimization of residual convolutional neural networks for electrocardiogram classification},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guest editorial: Advances in deep learning for clinical and
healthcare applications. <em>CC</em>, <em>16</em>(3), 1331–1333. (<a
href="https://doi.org/10.1007/s12559-022-10049-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Ieracitano, Cosimo and Morabito, Francesco Carlo and Squartini, Stefano and Huang, Kaizhu and Li, Xuelong and Mahmud, Mufti},
  doi          = {10.1007/s12559-022-10049-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1331-1333},
  shortjournal = {Cogn. Comput.},
  title        = {Guest editorial: Advances in deep learning for clinical and healthcare applications},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel resilient and intelligent predictive model for
CPS-enabled e-health applications. <em>CC</em>, <em>16</em>(3),
1321–1330. (<a
href="https://doi.org/10.1007/s12559-024-10278-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical-social-systems interconnect diverse technologies and communication infrastructure to the Internet for environmental sensing and computation. They offer many real-time autonomous services for smart cities, industry, transportation, medical systems, etc. The Internet of Medical Things (IoMT) has gained the potential for developing cyber-physical system (CPS) to facilitate healthcare applications and analyze the records of patients. Such a communication paradigm is integrated into many wireless standards for managing crucial data with cloud computing. However, the limitations of low-powered resources of such healthcare infrastructures increase the complexity level of sustainable growth. Wireless connectivity in next-generation networks is another research goal due to unbalanced load distribution. Furthermore, low-powered computing devices can be easily accessible by intruders and eliminate the confidentiality of any data transmission, so privacy is another research concern for healthcare systems. Therefore, using intelligent computing, this paper proposed a novel resilient predictive model for e-health sensing. The proposed model provides an efficient CPS-enabled automated routing system by exploring the optimization process with edge intelligence. This particular solution increases the level of cooperation between communication devices with intelligent data processing and higher predictive services. Moreover, by offering a trustworthy scheme, it seeks to enhance digital communication, data aggregation, and data breach prevention. The experimental findings highlight significant outcomes of the proposed model for packet reception, network overhead, data delay, and reliability as compared to alternative solutions.},
  archive      = {J_CC},
  author       = {Rehman, Amjad and Haseeb, Khalid and Alam, Teg and Saba, Tanzila and Jeon, Gwanggil},
  doi          = {10.1007/s12559-024-10278-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1321-1330},
  shortjournal = {Cogn. Comput.},
  title        = {A novel resilient and intelligent predictive model for CPS-enabled E-health applications},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accurate prediction of lysine methylation sites using
evolutionary and structural-based information. <em>CC</em>,
<em>16</em>(3), 1300–1320. (<a
href="https://doi.org/10.1007/s12559-024-10268-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methylation is considered one of the proteins’ most important post-translational modifications (PTM). Plasticity and cellular dynamics are among the many traits that are regulated by methylation. Currently, methylation sites are identified using experimental approaches. However, these methods are time-consuming and expensive. With the use of computer modelling, methylation sites can be identified quickly and accurately, providing valuable information for further trial and investigation. In this study, we propose a new machine-learning model called MeSEP to predict methylation sites that incorporates both evolutionary and structural-based information. To build this model, we first extract evolutionary and structural features from the PSSM and SPD2 profiles, respectively. We then employ Extreme Gradient Boosting (XGBoost) as the classification model to predict methylation sites. To address the issue of imbalanced data and bias towards negative samples, we use the SMOTETomek-based hybrid sampling method. The MeSEP was validated on an independent test set (ITS) and 10-fold cross-validation (TCV) using lysine methylation sites. The method achieved: an accuracy of 82.9% in ITS and 84.6% in TCV; precision of 0.92 in ITS and 0.94 in TCV; area under the curve values of 0.90 in ITS and 0.92 in TCV; F1 score of 0.81 in ITS and 0.83 in TCV; and MCC of 0.67 in ITS and 0.70 in TCV. MeSEP significantly outperformed previous studies found in the literature. MeSEP as a standalone toolkit and all its source codes are publicly available at https://github.com/arafatro/MeSEP .},
  archive      = {J_CC},
  author       = {Arafat, Md. Easin and Ahmad, Md. Wakil and Shovan, S. M. and Haq, Towhid Ul and Islam, Nazrul and Mahmud, Mufti and Kaiser, M. Shamim},
  doi          = {10.1007/s12559-024-10268-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1300-1320},
  shortjournal = {Cogn. Comput.},
  title        = {Accurate prediction of lysine methylation sites using evolutionary and structural-based information},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion selectivity of the local filed potentials in the
primary visual cortex of rats: A machine learning approach. <em>CC</em>,
<em>16</em>(3), 1287–1299. (<a
href="https://doi.org/10.1007/s12559-024-10263-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using rodents as a model of physiological vision studies requires adequate information about their visual cortex. Although the primary visual cortex of rats has different sub-regions, there are few studies on the different response patterns of these sub-regions. In this study, we recorded the local field potentials (LFPs) from sub-regions of the primary visual cortex (V1) of anesthetized rats. We used random dots patterns as moving stimuli presented in random sequences. Then we used machine learning methods to decode the direction and speed of the stimuli from the recorded signals. Our results revealed that there are different patterns of responses to motion stimuli across sub-regions. Although the decoding results using LFPs were not high, they were enhanced by moving to the lateral sub-regions of the V1. Our results suggested that the location of the recording areas impact reaction time, the pattern of the responses in time- and frequency- domains, and encoding the motion stimuli.},
  archive      = {J_CC},
  author       = {Pourhedayat, Abbas and Aghababaeipour Dehkordi, Marzie and Daliri, Mohammad Reza},
  doi          = {10.1007/s12559-024-10263-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1287-1299},
  shortjournal = {Cogn. Comput.},
  title        = {Motion selectivity of the local filed potentials in the primary visual cortex of rats: A machine learning approach},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mutual information-based many-objective optimization
method for EEG channel selection in the epileptic seizure prediction
task. <em>CC</em>, <em>16</em>(3), 1268–1286. (<a
href="https://doi.org/10.1007/s12559-024-10261-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epileptic seizure prediction using multi-channel electroencephalogram (EEG) signals is very important in clinical therapy. A large number of channels lead to high computational complexity with low model performance. To improve the performance and reduce the overfitting that arises due to the use of unrelevant channels, the present paper proposed a channel selection method to study the brain region activation related to epileptic seizure. Our method is bio-inspired and cognitive since it integrates the novel binary many-objective particle swarm optimization with a ConvLSTM model. The proposed method has two advantages. First, it performed a new initialization strategy based on channel weighting with mutual information, thereby promoting the fast convergence of the optimization algorithm. Second, it captures spatio-temporal information from raw EEG segments thanks to the ConvLSTM model. The selected sub-channels are optimized as many-objective optimization problem that includes maximizing F1-score, sensitivity, specificity, and minimizing the ratio rate of selected channels. Our results have shown a performance of up to $$97.94\%$$ with only one EEG channel. Interestingly, when using all the EEG channels available, lower performance was achieved compared to the case when EEG channels were selected by our approach. This study revealed that it is possible to predict epileptic seizures using a few channels, which provides evidence for the future development of portable EEG seizure prediction devices.},
  archive      = {J_CC},
  author       = {Kouka, Najwa and Fourati, Rahma and Baghdadi, Asma and Siarry, Patrick and Adel, M.},
  doi          = {10.1007/s12559-024-10261-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1268-1286},
  shortjournal = {Cogn. Comput.},
  title        = {A mutual information-based many-objective optimization method for EEG channel selection in the epileptic seizure prediction task},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Studying drowsiness detection performance while driving
through scalable machine learning models using electroencephalography.
<em>CC</em>, <em>16</em>(3), 1253–1267. (<a
href="https://doi.org/10.1007/s12559-023-10233-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver drowsiness is a significant concern and one of the leading causes of traffic accidents. Advances in cognitive neuroscience and computer science have enabled the detection of drivers’ drowsiness using Brain-Computer Interfaces (BCIs) and Machine Learning (ML). However, the literature lacks a comprehensive evaluation of drowsiness detection performance using a heterogeneous set of ML algorithms, being also necessary to study the performance of scalable ML models suitable for groups of subjects. To address these limitations, this work presents an intelligent framework employing BCIs and features based on electroencephalography for detecting drowsiness in driving scenarios. The SEED-VIG dataset is used to evaluate the best-performing models for individual subjects and groups. Results show that Random Forest (RF) outperformed other models used in the literature, such as Support Vector Machine (SVM), with a 78% f1-score for individual models. Regarding scalable models, RF reached a 79% f1-score, demonstrating the effectiveness of these approaches. This publication highlights the relevance of exploring a diverse set of ML algorithms and scalable approaches suitable for groups of subjects to improve drowsiness detection systems and ultimately reduce the number of accidents caused by driver fatigue. The lessons learned from this study show that not only SVM but also other models not sufficiently explored in the literature are relevant for drowsiness detection. Additionally, scalable approaches are effective in detecting drowsiness, even when new subjects are evaluated. Thus, the proposed framework presents a novel approach for detecting drowsiness in driving scenarios using BCIs and ML.},
  archive      = {J_CC},
  author       = {Hidalgo Rogel, José Manuel and Martínez Beltrán, Enrique Tomás and Quiles Pérez, Mario and López Bernal, Sergio and Martínez Pérez, Gregorio and Huertas Celdrán, Alberto},
  doi          = {10.1007/s12559-023-10233-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1253-1267},
  shortjournal = {Cogn. Comput.},
  title        = {Studying drowsiness detection performance while driving through scalable machine learning models using electroencephalography},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Harnessing cognitively inspired predictive models to improve
investment decision-making. <em>CC</em>, <em>16</em>(3), 1237–1252. (<a
href="https://doi.org/10.1007/s12559-023-10240-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, researchers and practitioners have focused on defining portfolio optimization approaches. This task aims to identify a suitable distribution of assets for maximizing profits and minimizing risks, also offering protection against unexpected market behaviors. Nevertheless, the state-of-the-art approaches encounter significant limitations due to the complex nature of the task: (1) forecasting of non-stationary, non-linearity and volatile stock price; (2) budget allocation over different stocks satisfying multi-objective objective function; (3) risk costs can significantly affect the effectiveness of the designed approaches. In this paper, we propose a cognitively inspired framework for portfolio optimization by integrating deep learning-based stock forecasting for maximizing the revenue and portfolio diversification and Shape Ratio for minimizing the risk. Furthermore, the cognitively inspired forecasting module relies on the LSTM-based approach which combines historical financial data and technical indicators. Hence, this approach addresses the portfolio optimization task with the aim of designing more and more cognitive agents that perform autonomous actions for supporting decision-making. To make these agents cognitive, we further integrate stock forecasting into the portfolio optimization model, also investigating the main factors affecting both stock forecasting and portfolio optimization tasks. The proposed framework has been evaluated in two stages on a real-world dataset, composed of four years of information about stocks from six different areas. Firstly, we compare the proposed forecasting models based on LSTM and GRU, pointing out that the former achieves higher effectiveness results although the latter has a shorter training time. Finally, the proposed framework has been compared with different baselines, obtaining a net difference of $168 at the maximum. Finally, we compare the proposed approach w.r.t. several baselines in terms of total revenue, also providing an ablation analysis to investigate how stock prediction might support investors in dealing with portfolio optimization task.},
  archive      = {J_CC},
  author       = {Carandente, Vincenzo and Sperlí, Giancarlo},
  doi          = {10.1007/s12559-023-10240-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1237-1252},
  shortjournal = {Cogn. Comput.},
  title        = {Harnessing cognitively inspired predictive models to improve investment decision-making},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards efficient recurrent architectures: A deep LSTM
neural network applied to speech enhancement and recognition.
<em>CC</em>, <em>16</em>(3), 1221–1236. (<a
href="https://doi.org/10.1007/s12559-024-10288-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long short-term memory (LSTM) has proven effective in modeling sequential data. However, it may encounter challenges in accurately capturing long-term temporal dependencies. LSTM plays a central role in speech enhancement by effectively modeling and capturing temporal dependencies in speech signals. This paper introduces a variable-neurons-based LSTM designed for capturing long-term temporal dependencies by reducing neuron representation in layers with no loss of data. A skip connection between nonadjacent layers is added to prevent gradient vanishing. An attention mechanism in these connections highlights important features and spectral components. Our LSTM is inherently causal, making it well-suited for real-time processing without relying on future information. Training involves utilizing combined acoustic feature sets for improved performance, and the models estimate two time–frequency masks—the ideal ratio mask (IRM) and the ideal binary mask (IBM). Comprehensive evaluation using perceptual evaluation of speech quality (PESQ) and short-time objective intelligibility (STOI) showed that the proposed LSTM architecture demonstrates enhanced speech intelligibility and perceptual quality. Composite measures further substantiated performance, considering residual noise distortion (Cbak) and speech distortion (Csig). The proposed model showed a 16.21% improvement in STOI and a 0.69 improvement in PESQ on the TIMIT database. Similarly, with the LibriSpeech database, the STOI and PESQ showed improvements of 16.41% and 0.71 over noisy mixtures. The proposed LSTM architecture outperforms deep neural networks (DNNs) in different stationary and nonstationary background noisy conditions. To train an automatic speech recognition (ASR) system on enhanced speech, the Kaldi toolkit is used for evaluating word error rate (WER). The proposed LSTM at the front-end notably reduced WERs, achieving a notable 15.13% WER across different noisy backgrounds.},
  archive      = {J_CC},
  author       = {Wang, Jing and Saleem, Nasir and Gunawan, Teddy Surya},
  doi          = {10.1007/s12559-024-10288-y},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1221-1236},
  shortjournal = {Cogn. Comput.},
  title        = {Towards efficient recurrent architectures: A deep LSTM neural network applied to speech enhancement and recognition},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method for human-vehicle recognition based on
wireless sensing and deep learning technologies. <em>CC</em>,
<em>16</em>(3), 1210–1220. (<a
href="https://doi.org/10.1007/s12559-024-10276-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, human-vehicle recognition (HVR) method has been applied in road monitoring, congestion control, and safety protection situations. However, traditional vision-based HVR methods suffer from problems such as high construction cost and low robustness in scenarios with insufficient lighting. For this reason, it is necessary to develop a low-cost and high-robust HVR method for intelligent street light systems (ISLS). A well-designed HVR method can aid the brightness adjustment in ISLSs that operate exclusively at night, facilitating lower power consumption and carbon emission. The paper proposes a novel wireless sensing-based human-vehicle recognition (WsHVR) method based on deep learning technologies, which can be applied in ISLSs that assembled with wireless sensor network (WSN). To solve the problem of limited recognition ability of wireless sensing technology, a deep feature extraction model that combines multi-scale convolution and attention mechanism is proposed, in which the received signal strength (RSS) features of road users are extracted by multi-scale convolution. WsHVR integrates an adaptive registration convolutional attention mechanism (ARCAM) to further feature extraction and classification. The final normalized classification result is obtained by SoftMax function. Experiments show that the proposed WsHVR outperforms existing methods with an accuracy of 99.07%. The dataset and source code related to the paper have been published at https://github.com/TZ-mx/WiParam and https://github.com/TZ-mx/WsHVR , respectively. The proposed WsHVR method has high performance in the field of human-vehicle recognition, potentially providing valuable guidance for the design of intelligent streetlight systems in intelligent transportation systems.},
  archive      = {J_CC},
  author       = {Lou, Liangliang and Cai, Ruyin and Lu, Mingan and Wang, Mingmin and Chen, Guang},
  doi          = {10.1007/s12559-024-10276-2},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1210-1220},
  shortjournal = {Cogn. Comput.},
  title        = {A novel method for human-vehicle recognition based on wireless sensing and deep learning technologies},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigation of scalograms with a deep feature fusion
approach for detection of parkinson’s disease. <em>CC</em>,
<em>16</em>(3), 1198–1209. (<a
href="https://doi.org/10.1007/s12559-024-10254-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a neurological condition that millions of people worldwide suffer from. Early symptoms include a slight sense of weakness and a propensity for involuntary tremulous motion in body limbs, particularly in the arms, hands, and head. PD is diagnosed based on motor symptoms. Additionally, scholars have proposed various remote monitoring tests that offer benefits such as early diagnosis, ease of application, and cost-effectiveness. PD patients often exhibit voice disorders. Speech signals of the patients can be used for early diagnosis of the disease. This study proposed an artificial intelligence–based approach for PD diagnosis using speech signals. Scalogram images, generated through the Continuous Wavelet Transform of the speech signals, were employed in deep learning techniques to detect PD. The scalograms were tested with various deep learning techniques. In the first part of the experiment, AlexNet, GoogleNet, ResNet50, and a majority voting-based hybrid system were used as classifiers. Secondly, a deep feature fusion method based on DenseNet and NasNet was investigated. Several evaluation metrics were employed to assess the performance. The deep feature fusion system achieved an accuracy of 0.95 and an F1 score with stratified 10-fold cross-validation, improving accuracy by 38% over the ablation study. The key contributions of this study include the investigation of scalogram images with a comprehensive analysis of deep learning models and deep feature fusion for PD detection.},
  archive      = {J_CC},
  author       = {Cantürk, İsmail and Günay, Osman},
  doi          = {10.1007/s12559-024-10254-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1198-1209},
  shortjournal = {Cogn. Comput.},
  title        = {Investigation of scalograms with a deep feature fusion approach for detection of parkinson’s disease},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CIL-net: Densely connected context information learning
network for boosting thyroid nodule segmentation using ultrasound
images. <em>CC</em>, <em>16</em>(3), 1176–1197. (<a
href="https://doi.org/10.1007/s12559-024-10289-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thyroid nodule (TYN) is a life-threatening disease that is commonly observed among adults globally. The applications of deep learning in computer-aided diagnosis systems (CADs) for diagnosing thyroid nodules have attracted attention among clinical professionals due to their significantly potential role in reducing the occurrence of missed diagnoses. However, most techniques for segmenting thyroid nodules rely on U-Net structures or deep convolutional neural networks, which have limitations in obtaining different context information due to the diversities in the shapes and sizes, ambiguous boundaries, and heterostructure of thyroid nodules. To resolve these challenges, we present an encoder-decoder-based architecture (referred to as CIL-Net) for boosting TYN segmentation. There are three contributions in the proposed CIL-Net. First, the encoder is established using dense connectivity for efficient feature extraction and the triplet attention block (TAB) for highlighting essential feature maps. Second, we design a feature improvement block (FIB) using dilated convolutions and attention mechanisms to capture the global context information and also build up robust feature maps between the encoder-decoder branches. Third, we introduce the residual context block (RCB), which leverages residual units (ResUnits) to accumulate the context information from the multiple blocks of decoders in the decoder branch. We assess the segmentation quality of our proposed method using six different evaluation metrics on two standard datasets (DDTI and TN3K) of TYN and demonstrate competitive performance against advanced state-of-the-art methods. We consider that the proposed method advances the performance of TYN region localization and segmentation, which heavily rely on an accurate assessment of different context information. This advancement is primarily attributed to the comprehensive incorporation of dense connectivity, TAB, FIB, and RCB, which effectively capture both extensive and intricate contextual details. We anticipate that this approach reliability and visual explainability make it a valuable tool that holds the potential to significantly enhance clinical practices by offering reliable predictions to facilitate cognitive and healthcare decision-making.},
  archive      = {J_CC},
  author       = {Ali, Haider and Wang, Mingzhao and Xie, Juanying},
  doi          = {10.1007/s12559-024-10289-x},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1176-1197},
  shortjournal = {Cogn. Comput.},
  title        = {CIL-net: Densely connected context information learning network for boosting thyroid nodule segmentation using ultrasound images},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intelligent inspection guidance of urethral endoscopy based
on SLAM with blood vessel attentional features. <em>CC</em>,
<em>16</em>(3), 1161–1175. (<a
href="https://doi.org/10.1007/s12559-024-10264-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to small imaging range of lens, blurring by jitter in the operation process and high similarity of urethral image features observed in different positions, doctors often face challenges in conducting a quick and comprehensive microscopic examination. In this paper, we combine image processing, simultaneous localization and mapping (SLAM) and intelligent navigation technologies to build an ORB-SLAM-based auxiliary microscopy guiding system. It can automatically process real-time microscopy videos, analyze the doctor’s detection path and provide direction for areas that have not been detected, assisting the doctor in completing urethral wall detection. In this system, a generative adversarial network-based deblurring algorithm is used to deblur the urethral images before SLAM processing. We creatively propose a vascular attention-based feature extraction algorithm tailored for urethral images. This algorithm combines F3Net and U-Net networks to detect the main body and branch points of blood vessels, respectively, which demonstrates the capability to assist the SLAM system in tracking the urethra more stably. Moreover, we design the direction guidance rules to aid doctors in urethral endoscopy. The system has been evaluated with a real urethral endoscope video dataset. Compared to other mainstream feature extraction algorithms, the method proposed in this paper is more accurate and comprehensive in identifying urethral vascular features, resulting in a 4.34% accuracy improvement, which confirms its effectiveness.},
  archive      = {J_CC},
  author       = {Lin, Jie and Zeng, Xiangyu and Pan, Yulong and Ren, Shangqing and Bao, Yige},
  doi          = {10.1007/s12559-024-10264-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1161-1175},
  shortjournal = {Cogn. Comput.},
  title        = {Intelligent inspection guidance of urethral endoscopy based on SLAM with blood vessel attentional features},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-layer ensemble of deep learning models for medical image
segmentation. <em>CC</em>, <em>16</em>(3), 1141–1160. (<a
href="https://doi.org/10.1007/s12559-024-10257-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important areas in medical image analysis is segmentation, in which raw image data is partitioned into structured and meaningful regions to gain further insights. By using Deep Neural Networks (DNN), AI-based automated segmentation algorithms can potentially assist physicians with more effective imaging-based diagnoses. However, since it is difficult to acquire high-quality ground truths for medical images and DNN hyperparameters require significant manual tuning, the results by DNN-based medical models might be limited. A potential solution is to combine multiple DNN models using ensemble learning. We propose a two-layer ensemble of deep learning models in which the prediction of each training image pixel made by each model in the first layer is used as the augmented data of the training image for the second layer of the ensemble. The prediction of the second layer is then combined by using a weight-based scheme which is found by solving linear regression problems. To the best of our knowledge, our paper is the first work which proposes a two-layer ensemble of deep learning models with an augmented data technique in medical image segmentation. Experiments conducted on five different medical image datasets for diverse segmentation tasks show that proposed method achieves better results in terms of several performance metrics compared to some well-known benchmark algorithms. Our proposed two-layer ensemble of deep learning models for segmentation of medical images shows effectiveness compared to several benchmark algorithms. The research can be expanded in several directions like image classification.},
  archive      = {J_CC},
  author       = {Dang, Truong and Nguyen, Tien Thanh and McCall, John and Elyan, Eyad and Moreno-García, Carlos Francisco},
  doi          = {10.1007/s12559-024-10257-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1141-1160},
  shortjournal = {Cogn. Comput.},
  title        = {Two-layer ensemble of deep learning models for medical image segmentation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MFCTrans: Multi-scale feature connection transformer for
deformable medical image registration. <em>CC</em>, <em>16</em>(3),
1125–1140. (<a
href="https://doi.org/10.1007/s12559-023-10239-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable Medical Image Registration (DMIR) aims to establish precise anatomical alignment of multiple medical images. However, the existing U-shape networks encounter difficulties in efficiently transferring multi-scale feature information from the encoder to the decoder. To address this issue, we propose a novel backbone network called MFCTrans, which constructs effective feature connection in DMIR. Drawing inspiration from the attention mechanism observed in the human cognitive system, our proposed method employs a Feature Fusion and Assignment Transformer (FFAT) module and a Spatial Cross Attention Fusion (SCAF) module. The former facilitates the fusion of multi-channel features, while the latter guides the integration of multi-scale information. A Multiple Residual (MR) branch is also deployed between the encoder and FFAT to improve the network’s generalization. We conduct extensive qualitative and quantitative evaluations on the OASIS and LPBA40 datasets. The proposed method achieves higher Dice scores than Transmorph by 1.3% and 2.0% on the respective datasets while maintaining a comparable voxel folding percentage. Ablation studies analyze the impacts and efficiency of each component in the proposed method. In summary, our proposed network offers a promising framework for achieving high-quality medical image registration and holds significant potential for applications in computer vision and cognitive computation.},
  archive      = {J_CC},
  author       = {Wang, Longji and Yan, Zhiyue and Cao, Wenming and Ji, Jianhua},
  doi          = {10.1007/s12559-023-10239-z},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1125-1140},
  shortjournal = {Cogn. Comput.},
  title        = {MFCTrans: Multi-scale feature connection transformer for deformable medical image registration},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing document-level relation extraction with
attention-convolutional hybrid networks and evidence extraction.
<em>CC</em>, <em>16</em>(3), 1113–1124. (<a
href="https://doi.org/10.1007/s12559-024-10269-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction aims at extracting relations between entities in a document. In contrast to sentence-level correspondences, document-level relation extraction requires reasoning over multiple sentences to extract complex relational triples. Recent work has found that adding additional evidence extraction tasks and using the extracted evidence sentences to help predict can improve the performance of document-level relation extraction tasks, however, these approaches still face the problem of inadequate modeling of the interactions between entity pairs. In this paper, based on the review of human cognitive processes, we propose a hybrid network HIMAC applied to the entity pair feature matrix, in which the multi-head attention sub-module can fuse global entity-pair information on a specific inference path, while the convolution sub-module is able to obtain local information of adjacent entity pairs. Then we incorporate the contextual interaction information learned by the entity pairs into the relation prediction and evidence extraction tasks. Finally, the extracted evidence sentences are used to further correct the relation extraction results. We conduct extensive experiments on two document-level relation extraction benchmark datasets (DocRED/Re-DocRED), and the experimental results demonstrate that our method achieves state-of-the-art performance (62.84/75.89 F1). Experiments demonstrate the effectiveness of the proposed method.},
  archive      = {J_CC},
  author       = {Zhang, Feiyu and Hu, Ruiming and Duan, Guiduo and Huang, Tianxi},
  doi          = {10.1007/s12559-024-10269-1},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1113-1124},
  shortjournal = {Cogn. Comput.},
  title        = {Enhancing document-level relation extraction with attention-convolutional hybrid networks and evidence extraction},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Normal template mapping: An association-inspired handwritten
character recognition model. <em>CC</em>, <em>16</em>(3), 1103–1112. (<a
href="https://doi.org/10.1007/s12559-024-10270-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In identifying objects, people usually associate memory templates to guide visual attention and determine the category of an object. The initial character images that children learn are usually normal patterns. However, the variation in corresponding handwritten patterns is quite large. To learn these deformed images with large variance, current deep models must involve millions of parameters for such kind of classification tasks that seem much easier and simpler to children who learn to recognize new characters associated with their initially taught normal patterns. From the perspective of humans’ perception, when people see a new object, they first think of a template image in their memory, which is similar to the object. This mapping process makes it easier for humans to learn new objects. Inspired by this cognitive association mechanism, this study developed a cognition-inspired handwritten character recognition model using a proposed normal template mapping neural network. This model uses an encoder-decoder architecture to build a normal template mapping neural network that transforms handwritten character images of one class to normalized characters similar to a given printed template character image representing that class. Then, a simple shallow classifier recognizes these normalized images, which are easier to classify. The experimental results show that the proposed model completes handwritten character recognition with comparable or higher precision at a much lower parameter count than current representative deep models. The proposed model removes the individual styles of handwritten character images and maps them to patterns similar to normal template images. This greatly reduces the classification difficulty and enables the classifier to classify only known standard character images.},
  archive      = {J_CC},
  author       = {Miao, Jun and Liu, Peng and Chen, Chen and Qiao, Yuanhua},
  doi          = {10.1007/s12559-024-10270-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1103-1112},
  shortjournal = {Cogn. Comput.},
  title        = {Normal template mapping: An association-inspired handwritten character recognition model},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep multi-task learning for animal chest circumference
estimation from monocular images. <em>CC</em>, <em>16</em>(3),
1092–1102. (<a
href="https://doi.org/10.1007/s12559-024-10250-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The applications of deep learning algorithms with images to various scenarios have attracted significant research attention. However, application scenarios in animal breeding managements are still limited. In this paper we propose a new deep learning framework to estimate the chest circumference of domestic animals from images. This parameter is a key metric for breeding and monitoring the quality of animal in animal husbandry. We design a set of feature extraction methods based on a multi-task learning framework to address the challenging issues in the main estimation task. The multiple tasks in our proposed framework include object segmentation, keypoint estimation, and depth estimation of cow from monocular images. The domain-specific features extracted from these tasks improve upon our main estimation task. In addition, we also attempt to reduce unnecessary computations during the framework design to reduce the cost of subsequent practical implementation of the developed system. Our proposed framework is tested on our own collected dataset to evaluate its performance.},
  archive      = {J_CC},
  author       = {Zhang, Hongtao and Gu, Dongbing},
  doi          = {10.1007/s12559-024-10250-y},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1092-1102},
  shortjournal = {Cogn. Comput.},
  title        = {Deep multi-task learning for animal chest circumference estimation from monocular images},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel blockchain-based deepfake detection method using
federated and deep learning models. <em>CC</em>, <em>16</em>(3),
1073–1091. (<a
href="https://doi.org/10.1007/s12559-024-10255-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the proliferation of deep learning (DL) techniques has given rise to a significant challenge in the form of deepfake videos, posing a grave threat to the authenticity of media content. With the rapid advancement of DL technology, the creation of convincingly realistic deepfake videos has become increasingly prevalent, raising serious concerns about the potential misuse of such content. Deepfakes have the potential to undermine trust in visual media, with implications for fields as diverse as journalism, entertainment, and security. This study presents an innovative solution by harnessing blockchain-based federated learning (FL) to address this issue, focusing on preserving data source anonymity. The approach combines the strengths of SegCaps and convolutional neural network (CNN) methods for improved image feature extraction, followed by capsule network (CN) training to enhance generalization. A novel data normalization technique is introduced to tackle data heterogeneity stemming from diverse global data sources. Moreover, transfer learning (TL) and preprocessing methods are deployed to elevate DL performance. These efforts culminate in collaborative global model training zfacilitated by blockchain and FL while maintaining the utmost confidentiality of data sources. The effectiveness of our methodology is rigorously tested and validated through extensive experiments. These experiments reveal a substantial improvement in accuracy, with an impressive average increase of 6.6% compared to six benchmark models. Furthermore, our approach demonstrates a 5.1% enhancement in the area under the curve (AUC) metric, underscoring its ability to outperform existing detection methods. These results substantiate the effectiveness of our proposed solution in countering the proliferation of deepfake content. In conclusion, our innovative approach represents a promising avenue for advancing deepfake detection. By leveraging existing data resources and the power of FL and blockchain technology, we address a critical need for media authenticity and security. As the threat of deepfake videos continues to grow, our comprehensive solution provides an effective means to protect the integrity and trustworthiness of visual media, with far-reaching implications for both industry and society. This work stands as a significant step toward countering the deepfake menace and preserving the authenticity of visual content in a rapidly evolving digital landscape.},
  archive      = {J_CC},
  author       = {Heidari, Arash and Navimipour, Nima Jafari and Dag, Hasan and Talebi, Samira and Unal, Mehmet},
  doi          = {10.1007/s12559-024-10255-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1073-1091},
  shortjournal = {Cogn. Comput.},
  title        = {A novel blockchain-based deepfake detection method using federated and deep learning models},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-keys attention network for image captioning.
<em>CC</em>, <em>16</em>(3), 1061–1072. (<a
href="https://doi.org/10.1007/s12559-023-10231-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image captioning task aims to generate descriptions from the main content of images. Recently, the Transformer with a self-attention mechanism has been widely used for the image captioning task, where the attention mechanism helps the encoder to generate image region features, and guides caption output in the decoder. However, the vanilla decoder uses a simple conventional self-attention mechanism, resulting in captions with poor semantic information and incomplete sentence logic. In this paper, we propose a novel attention block, Multi-Keys attention block, that fully enhances the relevance between explicit and implicit semantic information. Technically, the Multi-Keys attention block first concatenates the key vector and the value vector and spreads it into both the explicit channel and the implicit channel. Then, the “related value” is generated with more semantic information by applying the element-wise multiplication to them. Moreover, to perfect the sentence logic, the reverse key vector with another information flow is residually connected to the final attention result. We also apply the Multi-Keys attention block into the sentence decoder in the transformer named as Multi-Keys Transformer (MKTrans). The experiments demonstrate that our MKTrans achieves 138.6% CIDEr score on MS COCO “Karpathy” offline test split. The proposed Multi-Keys attention block and MKTrans model are proven to be more effective and superior than the state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Yang, Ziqian and Li, Hui and Ouyang, Renrong and Zhang, Quan and Xiao, Jimin},
  doi          = {10.1007/s12559-023-10231-7},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1061-1072},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-keys attention network for image captioning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pupil size variations reveal information about hierarchical
decision-making processes. <em>CC</em>, <em>16</em>(3), 1049–1060. (<a
href="https://doi.org/10.1007/s12559-024-10246-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Pupil size is a well-known indicator of low-level decision-making processes. However, it is unclear whether these involuntary eye data can represent information about the interwoven processes of hierarchical decision-making. In hierarchical decisions, high-level decision-making depends on the process of making low-level decisions, and the result of these interwoven processes is determined by feedback. Therefore, the exact cause of negative feedback is unclear, as it may be the result of low-level, high-level, or both low- and high-level incorrect decisions. In this study, we investigated the characteristics of eye data (pupil diameter) in the interwoven processes of hierarchical decision-making. Methods: We designed a hierarchical psychophysical experiment in which participants were asked to report their low- and high-level decisions and their confidence simultaneously on one of the colored bars. Participants received correct feedback in a trial when reporting both decisions correctly. During the experiment, the eye data of the participants were recorded by an eye-tracking device. Results: Our findings suggest that pupil size conveys information about high-level decisions as well. Furthermore, this study shows that three parameters (introduced in previous studies), negative feedback in successive trials, stimulus strength (uniformity with confidence), and decision urgency, are all represented in pupil size. Conclusion: The findings support the idea that involuntary eye data are influenced by decision-making-related brain activity in decision-making processes and not just visual stimulus features.},
  archive      = {J_CC},
  author       = {Yahyaie, Leyla and Ebrahimpour, Reza and Koochari, Abbas},
  doi          = {10.1007/s12559-024-10246-8},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1049-1060},
  shortjournal = {Cogn. Comput.},
  title        = {Pupil size variations reveal information about hierarchical decision-making processes},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structured encoding based on semantic disambiguation for
video captioning. <em>CC</em>, <em>16</em>(3), 1032–1048. (<a
href="https://doi.org/10.1007/s12559-024-10275-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning, which aims to automatically generate video captions, has gained significant attention due to its wide range of applications in video surveillance and retrieval. However, most existing methods focus on frame-level convolution to extract features, which ignores the semantic relationships between objects, resulting in the inability to encode video details. To address this problem, inspired by human cognitive processes towards the world, we propose a video captioning method based on semantic disambiguation through structured encoding. First, the conceptual semantic graph of a video is constructed by introducing a knowledge graph. Then, the graph convolution networks are used for relational learning of the conceptual semantic graph to mine the semantic relationships of objects and form the detail encoding of video. Aiming to address the semantic ambiguity of multiple relationships between objects, we propose a method to dynamically learn the most relevant relationships using video scene semantics to construct semantic graphs based on semantic disambiguation. Finally, we propose a cross-domain guided relationship learning strategy to avoid the negative impact caused by using only captions as cross-entropy loss. Experiments based on three datasets—MSR-VTT, ActivityNet Captions, and Student Classroom Behavior—showed that our method outperforms other methods. The results show that introducing a knowledge graph for common sense reasoning of objects in videos can deeply encode the semantic relationships between objects to capture video details and improve captioning performance.},
  archive      = {J_CC},
  author       = {Sun, Bo and Tian, Jinyu and Wu, Yong and Yu, Lunjun and Tang, Yuanyan},
  doi          = {10.1007/s12559-024-10275-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1032-1048},
  shortjournal = {Cogn. Comput.},
  title        = {Structured encoding based on semantic disambiguation for video captioning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video summarization using knowledge distillation-based
attentive network. <em>CC</em>, <em>16</em>(3), 1022–1031. (<a
href="https://doi.org/10.1007/s12559-023-10243-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast volumes of videos produced daily require highly efficient measures to ensure that key information is reported for effective review and storage, which leads to the popularity of video summarization techniques. Deep learning has shown its advantages in video summarization, especially convolutional neural network, which are effective in extracting features for video summarization. However, the deep network layers and the limited range of temporal dependence make it challenging to deploy the network and thus affect the accuracy of identifying important video frames. To tackle these issues, we present a knowledge distillation-based attentive network (KDAN) for supervised video summarization in this paper. The proposed method separates the full convolutional network from the attention mechanism based on the idea of education and learning processes in biology and uses a full convolutional network as a teacher network to guide the learning of the student network consisting of an attention mechanism. The obtained lightweight network considers the knowledge learned from both networks, thus solving the problems of explosion in the number of participants and slow training. We have conducted experiments on two widely used benchmarks SumMe and TVSum. DANtea achieves F-scores 53.09 and 60.30, and DAN achieves F-scores 51.26 and 61.55 in Canonical settings on the SumMe and TVSum datasets, respectively. Experiments on two public benchmarks SumMe and TVSum demonstrate the effectiveness and superiority of the proposed network over existing state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Qin, Jialin and Yu, Hui and Liang, Wei and Ding, Derui},
  doi          = {10.1007/s12559-023-10243-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1022-1031},
  shortjournal = {Cogn. Comput.},
  title        = {Video summarization using knowledge distillation-based attentive network},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitive impairment detection based on frontal camera scene
while performing handwriting tasks. <em>CC</em>, <em>16</em>(3),
1004–1021. (<a
href="https://doi.org/10.1007/s12559-024-10279-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosing cognitive impairment is an ongoing field of research especially in the elderly. Assessing the health status of the elderly can be a complex process that requires both subjective and objective measures. Subjective measures, such as self-reported responses to questions, can provide valuable information about a person’s experiences, feelings, and beliefs. However, from a scientific point of view, objective measures, based on quantifiable data that can be used to assess a person’s physical and cognitive functioning, are more appropriate and rigorous. The proposed system is based on the use of non-invasive instrumentation, which includes video images acquired with a frontal camera while the user performs different handwriting tasks on a Wacom tablet. We have acquired a new multimodal database of 191 elder subjects, which has been classified by human experts into healthy and cognitive impairment users by means of the standard pentagon copying test. The automatic classification was carried out using a video segmentation algorithm through the technique of shot boundary detection, in conjunction with a Transformer neural network. We obtain a multiclass classification accuracy of 77% and two-class accuracy of 83% based on frontal camera images, which basically detects head movements during handwriting tasks. Our automatic system can replicate human classification of handwritten pentagon copying test, opening a new method for cognitive impairment detection based on head movements. We also demonstrate the possibility to identifying the handwritten task performed by the user, based on frontal camera images and a Transformer neural network.},
  archive      = {J_CC},
  author       = {Candela, Federico and Romeo, Santina and Faundez-Zanuy, Marcos and Ferrer-Ramos, Pau},
  doi          = {10.1007/s12559-024-10279-z},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {1004-1021},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive impairment detection based on frontal camera scene while performing handwriting tasks},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ArQuAD: An expert-annotated arabic machine reading
comprehension dataset. <em>CC</em>, <em>16</em>(3), 984–1003. (<a
href="https://doi.org/10.1007/s12559-024-10248-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Reading Comprehension (MRC) is a task that enables machines to mirror key cognitive processes involving reading, comprehending a text passage, and answering questions about it. There has been significant progress in this task for English in recent years, where recent systems not only surpassed human-level performance but also demonstrated advancements in emulating complex human cognitive processes. However, the development of Arabic MRC has not kept pace due to language challenges and the lack of large-scale, high-quality datasets. Existing datasets are either small, low quality or released as a part of large multilingual corpora. We present the Arabic Question Answering Dataset (ArQuaD), a large MRC dataset for the Arabic language. The dataset comprises 16,020 questions posed by language experts on passages extracted from Arabic Wikipedia articles, where the answer to each question is a text segment from the corresponding reading passage. Besides providing various dataset analyses, we fine-tuned several pre-trained language models to obtain benchmark results. Among the compared methods, AraBERTv0.2-large achieved the best performance with an exact match of 68.95% and an F1-score of 87.15%. However, the significantly higher performance observed in human evaluations (exact match of 86% and F1-score of 95.5%) suggests a significant margin of possible improvement in future research. We release the dataset publicly at https://github.com/RashaMObeidat/ArQuAD to encourage further development of language-aware MRC models for the Arabic language.},
  archive      = {J_CC},
  author       = {Obeidat, Rasha and Al-Harbi, Marwa and Al-Ayyoub, Mahmoud and Alawneh, Luay},
  doi          = {10.1007/s12559-024-10248-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {984-1003},
  shortjournal = {Cogn. Comput.},
  title        = {ArQuAD: An expert-annotated arabic machine reading comprehension dataset},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced decision-making framework driven by complex
semantics under nested probabilistic linguistic environments.
<em>CC</em>, <em>16</em>(3), 964–983. (<a
href="https://doi.org/10.1007/s12559-024-10245-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language is the most important way of information transmission for human beings, through which people exchange ideas and guide practice. But the semantic expression has uncertainty, which usually brings difficulties to human’s decision-making behaviors in routine life. Hence, exploring methods to effectively handle the uncertain cognitive information has been an enduring research topic in recent years. Nested probabilistic linguistic term set (NPLTS) and ELECTRE II, as a powerful linguistic model and a classical decision-making method respectively, provide us useful tools. But the extant studies have some noticeable defects. Thus, this work proposes an enhanced decision-making framework in nested probabilistic linguistic environments. We refine the comparison method of NPLTSs by using a novel calculation method of the performance score and confusion degree. And we propose a new distance measurement method based on a symmetric linguistic scale. Considering the objective and subjective weights of criteria, we establish an entropy-based model to calculate the comprehensive weights of criteria. Then, we refine the classical ELECTRE II method. Based on which, we develop an enhanced ELECTRE II framework. The proposed model successfully addresses the potential failure of the classical ELECTRE II method. Based on comparisons with other methods, the alternative ranking changes in response to the fluctuation of criteria weights while maintaining rationality. Thus, it is proved that the proposed model is of excellent effectiveness, good reliability, and appropriate sensitivity.},
  archive      = {J_CC},
  author       = {Gan, Weidong and Xu, Zeshui and Wang, Xinxin},
  doi          = {10.1007/s12559-024-10245-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {964-983},
  shortjournal = {Cogn. Comput.},
  title        = {An enhanced decision-making framework driven by complex semantics under nested probabilistic linguistic environments},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fistful of vectors: A tool for intrinsic evaluation of
word embeddings. <em>CC</em>, <em>16</em>(3), 949–963. (<a
href="https://doi.org/10.1007/s12559-023-10235-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of word embeddings—powerful models computed through Neural Network architectures that encode words as vectors—has witnessed rapid growth across various Natural Language Processing applications, encompassing semantic analysis, information retrieval, dependency parsing, question answering, and machine translation. The efficacy of these tasks is strictly linked to the quality of the embeddings, underscoring the critical importance of evaluating and selecting optimal embedding models. While established procedures and benchmarks exist for intrinsic evaluation, the authors note a conspicuous absence of comprehensive evaluations of intrinsic embedding quality across multiple tasks. This paper introduces vec2best, a unified tool encompassing state-of-the-art intrinsic evaluation tasks across diverse benchmarks. vec2best furnishes the user with an extensive evaluation of word embedding models. It represents a framework for evaluating word embeddings trained using various methods and hyper-parameters on a range of tasks from the literature. The tool yields a holistic evaluation metric for each model called the PCE (Principal Component Evaluation). We conducted evaluations on 135 word embedding models, trained using GloVe, fastText, and word2vec, across four tasks integrated into vec2best (similarity, analogy, categorization, and outlier detection), along with their respective benchmarks. Additionally, we leveraged vec2best to optimize embedding hyper-parameter configurations in a real-world scenario. vec2best is conveniently accessible as a pip-installable Python package.},
  archive      = {J_CC},
  author       = {Ascari, Roberto and Giabelli, Anna and Malandri, Lorenzo and Mercorio, Fabio and Mezzanzanica, Mario},
  doi          = {10.1007/s12559-023-10235-3},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {949-963},
  shortjournal = {Cogn. Comput.},
  title        = {A fistful of vectors: A tool for intrinsic evaluation of word embeddings},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pairwise-pixel self-supervised and superpixel-guided
prototype contrastive loss for weakly supervised semantic segmentation.
<em>CC</em>, <em>16</em>(3), 936–948. (<a
href="https://doi.org/10.1007/s12559-024-10277-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation plays an important role in many fields because of its powerful ability to classify each pixel efficiently and accurately, but it relies on a large amount of manual annotations. In many cases, the annotations are very scarce and expensive, such as in medical image segmentation. To address this problem, researchers have been increasingly concerned about building efficient deep learning algorithms using rough label information in the past few years, with weakly supervised semantic segmentation method being one of them. Currently, most weakly supervised semantic segmentation methods rely on prototype learning to obtain the correlation between pixels; when the images of different categories are similar or indistinguishable, the extracted prototype has no representativeness to guide the training of model. Inspired by metric learning, we construct the pixel-level pairwise samples and propose a new self-supervised contrastive loss based on them, which makes full use of the class activation maps to reduce the intra-class difference and increase the inter-class difference; we also propose a novel prototype loss by a superpixel-guided clustering method to mine the valuable information in the image, which gathers the similar feature vectors to obtain the prototypes more accurately. The comparative experiments are carried out on PASCAL VOC 2012 and MS COCO 2014, the segmentation mIoU on the test set of PASCAL VOC 2012 has reached 69.5%, and the mIoU on the test set of MS COCO 2014 has reached 40.6%. The experimental results demonstrate our method achieves new state-of-the-art performance, which verifies the effectiveness and feasibility of the proposed method.},
  archive      = {J_CC},
  author       = {Xie, Lu and Li, Weigang and Zhao, Yuntao},
  doi          = {10.1007/s12559-024-10277-1},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {936-948},
  shortjournal = {Cogn. Comput.},
  title        = {Pairwise-pixel self-supervised and superpixel-guided prototype contrastive loss for weakly supervised semantic segmentation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Category-aware siamese learning network for few-shot
segmentation. <em>CC</em>, <em>16</em>(3), 924–935. (<a
href="https://doi.org/10.1007/s12559-024-10273-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FS) which aims to segment unseen query image based on a few annotated support samples is an active problem in computer vision and multimedia field. It is known that the core issue of FS is how to leverage the annotated information from the support images to guide query image segmentation. Existing methods mainly adopt Siamese Convolutional Neural Network (SCNN) which first encodes both support and query images and then utilizes the masked Global Average Pooling (GAP) to facilitate query image pixel-level representation and segmentation. However, this pipeline generally fails to fully exploit the category/class coherent information between support and query images. For FS task, one can observe that both support and query images share the same category information. This inherent property provides an important cue for FS task. However, previous methods generally fail to fully exploit it for FS task. To overcome this limitation, in this paper, we propose a novel Category-aware Siamese Learning Network (CaSLNet) to encode both support and query images. The proposed CaSLNet conducts Category Consistent Learning (CCL) for both support images and query images and thus can achieve the information communication between support and query images more sufficiently. Comprehensive experimental results on several public datasets demonstrate the advantage of our proposed CaSLNet. Our code is publicly available at https://github.com/HuiSun123/CaSLN .},
  archive      = {J_CC},
  author       = {Sun, Hui and Zhang, Ziyan and Huang, Lili and Jiang, Bo and Luo, Bin},
  doi          = {10.1007/s12559-024-10273-5},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {924-935},
  shortjournal = {Cogn. Comput.},
  title        = {Category-aware siamese learning network for few-shot segmentation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shift-equivariant similarity-preserving hypervector
representations of sequences. <em>CC</em>, <em>16</em>(3), 909–923. (<a
href="https://doi.org/10.1007/s12559-024-10258-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperdimensional Computing (HDC), also known as Vector-Symbolic Architectures (VSA), is a promising framework for the development of cognitive architectures and artificial intelligence systems, as well as for technical applications and emerging neuromorphic and nanoscale hardware. HDC/VSA operate with hypervectors, i.e., neural-like distributed vector representations of large fixed dimension (usually &gt; 1000). One of the key ingredients of HDC/VSA are the methods for encoding various data types (from numeric scalars and vectors to graphs) by hypervectors. In this paper, we propose an approach for the formation of hypervectors of sequences that provides both an equivariance with respect to the shift of sequences and preserves the similarity of sequences with identical elements at nearby positions. Our methods represent the sequence elements by compositional hypervectors and exploit permutations of hypervectors for representing the order of sequence elements. We experimentally explored the proposed representations using a diverse set of tasks with data in the form of symbolic strings. Although we did not use any features here (hypervector of a sequence was formed just from the hypervectors of its symbols at their positions), the proposed approach demonstrated the performance on a par with the methods that exploit various features, such as subsequences. The proposed techniques were designed for the HDC/VSA model known as Sparse Binary Distributed Representations. However, they can be adapted to hypervectors in formats of other HDC/VSA models, as well as for representing sequences of types other than symbolic strings. Directions for further research are discussed.},
  archive      = {J_CC},
  author       = {Rachkovskij, Dmitri A.},
  doi          = {10.1007/s12559-024-10258-4},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {909-923},
  shortjournal = {Cogn. Comput.},
  title        = {Shift-equivariant similarity-preserving hypervector representations of sequences},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synchronization of hypercomplex neural networks with mixed
time-varying delays. <em>CC</em>, <em>16</em>(3), 888–908. (<a
href="https://doi.org/10.1007/s12559-024-10253-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the fixed-time synchronization (FTS) of hypercomplex neural networks (HCNNs) with mixed time-varying delays. Unlike finite-time synchronization (FNTS) based on initial conditions, the settling time of FTS can be adjusted to meet the needs. The state vector, weight matrices, activation functions, and input vectors of HCNNs are all hypercomplex numbers. The techniques used in complex-valued neural networks (CVNNs) and quaternion-valued neural networks (QVNNs) cannot be used directly with HCNNs because they do not work with eight or more dimensions. To begin with, the decomposition method is used to split the HCNNs into $$(n+1)$$ real-valued neural networks (RVNNs) applying distributive law to handle non-commutativity and non-associativity. A nonlinear controller is constructed to synchronize the master-response systems of the HCNNs. Lyapunov-based method is used to prove the stability of an error system. The FTS of mixed time-varying delayed HCNNs is achieved using a suitable lemma, Lipschitz condition, appropriate Lyapunov functional construction, and designing suitable controllers. Two different algebraic criteria for settling time have been achieved by employing two distinct lemmas. It is demonstrated that the settling time derived from Lemma 1 produces a more precise result than that obtained from Lemma 2. Three numerical examples for CVNNs, QVNNs, and octonions-valued neural networks (OVNNs) are provided to demonstrate the efficacy and effectiveness of the proposed theoretical results.},
  archive      = {J_CC},
  author       = {Baluni, Sapna and K. Yadav, Vijay and Das, Subir and Cao, Jinde},
  doi          = {10.1007/s12559-024-10253-9},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {888-908},
  shortjournal = {Cogn. Comput.},
  title        = {Synchronization of hypercomplex neural networks with mixed time-varying delays},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Impulsive projection neural networks for variational
inequalities and sparse signal reconstruction application. <em>CC</em>,
<em>16</em>(3), 877–887. (<a
href="https://doi.org/10.1007/s12559-024-10252-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational inequalities (VIs) have become a general framework for efficient problems in various fields such as optimal control and nonlinear programming. Some real problems in application areas such as signal processing and network resource allocation can be transformed into VIs. VIs have been frequently solved using neurodynamic approaches, which have good performance and low computational cost. In this paper, two novel projection neural networks (PNNs) with impulsive effects are presented to deal with VIs. Based on the impulsive system theory and PNN, an impulsive projection neural network (IPNN) and its modified version are proposed. Then the stability properties of the presented IPNN and modified impulsive projection neural network (MIPNN) are analyzed by Lyapunov functions and impulsive system theory. VIs can be addressed with the proposed IPNN and MIPNN. Furthermore, two PNNs are applied to sparse signal reconstruction. It is also shown that the solutions of the proposed IPNN and MIPNN converge to the solution of the corresponding VIs. Meanwhile, sparse signals can also be accurately reconstructed by IPNN and MIPNN. Compared with the classical neural network, the newly designed IPNN and MIPNN have an improvement in the convergence rates because of the introduction of impulsive effects. Theoretical results and simulations show the effectiveness and feasibility of the IPNN and MIPNN.},
  archive      = {J_CC},
  author       = {Xu, Jing and Li, Chuandong and He, Xing and Wen, Hongsong},
  doi          = {10.1007/s12559-024-10252-w},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {877-887},
  shortjournal = {Cogn. Comput.},
  title        = {Impulsive projection neural networks for variational inequalities and sparse signal reconstruction application},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). The improved ordering-based search method incorporating
with ensemble learning. <em>CC</em>, <em>16</em>(3), 852–876. (<a
href="https://doi.org/10.1007/s12559-024-10251-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayesian network provides a useful way to deal with uncertain information, which helps researchers to better understand the human cognitive process. The foundation of the Bayesian network focuses on identifying the qualitative relations between variables, which is also called structure learning. Local search in the ordering space is an effective method for learning the structure of large-scale Bayesian networks. However, the existing algorithms tend to the local optimum and stop searching for superior solutions. To tackle the problem, random perturbations are applied to the local optimum without specific strategies, resulting in many meaningless restarts that sacrifice much time but still fail to improve the results. As an extension of the local search, simulated annealing stochastically searches the solution spaces and selects relatively poor solutions with a certain probability. This paper proposes a method based on simulated annealing to learn Bayesian network structure in the ordering space, which expands the search scope by probabilistically accepting poorer solutions. Moreover, we improve simulated annealing by adding a memory module and modifying the termination condition. The memory module records the optimal solution before accepting a worse solution, which avoids losing the possible global optimal solution. The new termination condition is related to the quality of the search results, which reduces many redundant searches. Besides, we design a new restart strategy based on ensemble learning. When the search traps in the local optimum, a new ordering is obtained to restart the search by perturbing the current ordering with constraints. The constraints are generated by the results of ensemble learning on multiple structures, which help the algorithm approach the global optimum solution. Experimental results show that our proposed methods improve the accuracy and efficiency in learning the optimal structure over the benchmarks compared to the state-of-the-art algorithms.},
  archive      = {J_CC},
  author       = {Wang, Hao and Wang, Zidong and Zhong, Ruiguo and Liu, Xiaohan and Gao, Xiaoguang},
  doi          = {10.1007/s12559-024-10251-x},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {852-876},
  shortjournal = {Cogn. Comput.},
  title        = {The improved ordering-based search method incorporating with ensemble learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time neuro-adaptive controller algorithms for
nonlinear multiagent systems with state constraints and unmodeled
dynamics. <em>CC</em>, <em>16</em>(3), 841–851. (<a
href="https://doi.org/10.1007/s12559-024-10256-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the distributed adaptive algorithm design for multiagent systems has attracted considerable attention due to the fact that multiagent systems have shared broad application in many practical systems including unmanned aircraft clusters, intelligent robots, and intelligent transportation. However, most of the previous outcomes have overlooked the full-state constraints and unmodeled dynamics phenomenons, which widely existed in many practical scenarios. Hence, quite different from the existing literatures, the current investigation focuses on the finite-time neuro-adaptive controller algorithms design for nonlinear multiagent systems both confining with full-state constraints and unmodeled dynamics. (1) So as to prevent the violation of the constraints, the barrier Lyapunov function (BLF) method is ingeniously integrated into the entire design process. Considering the existence of unmodeled dynamics, the dynamic signal is introduced to deal with the effect of the unmodeled dynamics on consensus performance. (2) The proposed control architecture depending on the command filter backstepping method is capable of tacking the explosion problem of computation complexity and compensating the errors induced by the command filter. (3) With the finite-time stability theory, the finite-time command filtered backstepping strategy is formulated to accomplish the finite-time consensus controller design. The novel finite-time command filtered backstepping strategy is formulated to resolve the consensus issue for non-strict feedback multiagent systems suffering from the state constraints and unmodeled dynamics. The simulation result further manifests the effectiveness of the proposed adaptive algorithms.},
  archive      = {J_CC},
  author       = {Tan, Lihua and Wang, Xin},
  doi          = {10.1007/s12559-024-10256-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {841-851},
  shortjournal = {Cogn. Comput.},
  title        = {Finite-time neuro-adaptive controller algorithms for nonlinear multiagent systems with state constraints and unmodeled dynamics},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint label propagation, graph and latent subspace
estimation for semi-supervised classification. <em>CC</em>,
<em>16</em>(3), 827–840. (<a
href="https://doi.org/10.1007/s12559-023-10232-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining labeled images and samples is a very expensive process and can require intensive labor. At the same time, there are often not enough labeled samples to train an effective classifier. Graph-based semi-supervised methods have attracted much attention in the field because they can use both labeled and unlabeled data. In this letter, we suggest a novel graph-based semi-supervised learning approach that takes full advantage of a small set of labeled samples and a large set of unlabeled samples. We first explain the concept of graph-based semi-supervised learning. Our central proposal is to jointly estimate a low-rank graph together with a latent subspace and soft labels. The proposed system exploits the synergy between the graph information and the latent data representation. This extends and enriches the supervision information in the semi-supervised context and produces a good discriminative linear mapping between the original space and the latent subspace. Several experiments were performed with five image datasets using state-of-the-art methods. The results of the study reveal several noteworthy findings. The proposed framework generally outperforms recent competing approaches in estimating labels and linear embeddings, especially for large datasets such as MNIST. The superiority is maintained even for minimally labeled images, but the recognition accuracy does not always increase. However, in a few cases, the proposed method may be outperformed by other method when the number of labeled samples per class is only one (the dataset UMIST). When we set the number of labeled samples per class to 2, we find that the proposed method consistently performs better than the competing methods. For the extended Yale dataset, the accuracy of the proposed method is 67.08%. This is 1.68% higher than the accuracy of the nearest competing method and an impressive 30.08% higher than the accuracy of the farthest competing method. In the case of the FacePix dataset, the accuracy of the proposed method is 58.08%. This is 2.58% higher than the nearest competing method and 13.58% higher than the farthest competing method. For the UMIST dataset, the accuracy reaches 54.2%, outperforming the nearest competing method by 0.9% and the farthest competing method by 7.5%. We have introduced a novel graph-based semi-supervised method capable of jointly predicting the soft labels and linear embedding and constructing a data graph. The main contribution in this work is the integration of the graph estimation into the objective function of the model. By computing the graph structure while estimating the semi-supervised model, a more optimal solution can be obtained. The synergistic use of data features and adaptive soft labels has indeed contributed to the estimation of a good discriminant model.},
  archive      = {J_CC},
  author       = {Dornaika, Fadi and Baradaaji, Abdullah},
  doi          = {10.1007/s12559-023-10232-6},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {827-840},
  shortjournal = {Cogn. Comput.},
  title        = {Joint label propagation, graph and latent subspace estimation for semi-supervised classification},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature analysis network: An interpretable idea in deep
learning. <em>CC</em>, <em>16</em>(3), 803–826. (<a
href="https://doi.org/10.1007/s12559-023-10238-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) stands out as a leading model for processing high-dimensional data, where the nonlinear transformation of hidden layers effectively extracts features. However, these unexplainable features make DL a low interpretability model. Conversely, Bayesian network (BN) is transparent and highly interpretable, and it can be helpful for interpreting DL. To improve the interpretability of DL from the perspective of feature cognition, we propose the feature analysis network (FAN), a DL structure fused with BN. FAN retains the DL feature extraction capability and applies BN as the output layer to learn the relationships between the features and the outputs. These relationships can be probabilistically represented by the structure and parameters of the BN, intuitively. In a further study, a correlation clustering-based feature analysis network (cc-FAN) is proposed to detect the correlations among inputs and to preserve this information to explain the features’ physical meaning to a certain extent. To quantitatively evaluate the interpretability of the model, we design the network simplification and interpretability indicators separately. Experiments on eight datasets show that FAN has better interpretability than that of the other models with basically unchanged model accuracy and similar model complexities. On the radar effect mechanism dataset, from the feature structure-based relevance interpretability indicator, FAN is up to 4.8 times better than that of the other models, and cc-FAN is up to 21.5 times better than that of the other models. FAN and cc-FAN enhance the interpretability of the DL model structure from the aspects of features; moreover, based on the input correlations, cc-FAN can help us to better understand the physical meaning of features.},
  archive      = {J_CC},
  author       = {Li, Xinyu and Gao, Xiaoguang and Wang, Qianglong and Wang, Chenfeng and Li, Bo and Wan, Kaifang},
  doi          = {10.1007/s12559-023-10238-0},
  journal      = {Cognitive Computation},
  month        = {5},
  number       = {3},
  pages        = {803-826},
  shortjournal = {Cogn. Comput.},
  title        = {Feature analysis network: An interpretable idea in deep learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AGD-net: Attention-guided dense inception u-net for
single-image dehazing. <em>CC</em>, <em>16</em>(2), 788–801. (<a
href="https://doi.org/10.1007/s12559-023-10244-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hazing poses a significant challenge in various computer vision applications, degrading the visual quality and reducing the perceptual clarity of captured scenes. The proposed AGD-Net utilizes a U-Net style architecture with an Attention-Guided Dense Inception encoder-decoder framework. Unlike existing methods that heavily rely on synthetic datasets which are based on CARLA simulation, our model is trained and evaluated exclusively on realistic data, enabling its effectiveness and reliability in practical scenarios. The key innovation of AGD-Net lies in its attention-guided mechanism, which empowers the network to focus on crucial information within hazy images and effectively suppress artifacts during the dehazing process. The dense inception modules further advance the representation capabilities of the model, facilitating the extraction of intricate features from the input images. To assess the performance of AGD-Net, a detailed experimental analysis is conducted on four benchmark haze datasets. The results show that AGD-Net significantly outperforms the state-of-the-art methods in terms of PSNR and SSIM. Moreover, a visual comparison of the dehazing results further validates the superior performance gains achieved by AGD-Net over other methods. By leveraging realistic data exclusively, AGD-Net overcomes the limitations associated with synthetic datasets which are based on CARLA simulation, ensuring its adaptability and effectiveness in real-world circumstances. The proposed AGD-Net offers a robust and reliable solution for single-image dehazing, presenting a significant advancement over existing methods.},
  archive      = {J_CC},
  author       = {Chougule, Amit and Bhardwaj, Agneya and Chamola, Vinay and Narang, Pratik},
  doi          = {10.1007/s12559-023-10244-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {788-801},
  shortjournal = {Cogn. Comput.},
  title        = {AGD-net: Attention-guided dense inception U-net for single-image dehazing},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time multi-class classification of respiratory diseases
through dimensional data combinations. <em>CC</em>, <em>16</em>(2),
776–787. (<a href="https://doi.org/10.1007/s12559-023-10228-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, there has been active research on multi-disease classification that aim to diagnose lung diseases and respiratory conditions using respiratory data. Recorded respiratory data can be used to diagnose various chronic diseases, such as asthma and pneumonia by applying different feature extraction methods. Previous studies have primarily focused on respiratory disease classification using 2D image conversion techniques, such as spectrograms and mel frequency cepstral coefficients (MFCC) for respiratory data. However, as the number of respiratory disease classes increased, the classification accuracy tended to decrease. To address this challenge, this study proposes a novel approach that combines 1D and 2D data to enhance the multi-classification performance regarding respiratory disease. We incorporated widely used 2D representations such as spectrograms, gammatone-based spectrograms, and MFCC images, along with raw data. The proposed respiratory disease classification method comprises 2D data conversion, combined data generation, classification model development, and multi-disease classification steps. Our method achieved high classification accuracies of 92.93%, 91.30%, and 88.58% using the TCN, Wavenet, and BiLSTM models, respectively. Compared to using solely 1D data, our approach demonstrated a 4.89% improvement in accuracy and more than 3 times better training speed when using only 2D data. These results confirmed the superiority of the proposed method. This allows us to leverage the advantages of fast learning provided by time-series models, as well as the high classification accuracy demonstrated by 2D image approaches.},
  archive      = {J_CC},
  author       = {Kim, Yejin and Camacho, David and Choi, Chang},
  doi          = {10.1007/s12559-023-10228-2},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {776-787},
  shortjournal = {Cogn. Comput.},
  title        = {Real-time multi-class classification of respiratory diseases through dimensional data combinations},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Synaptic facilitation: A key biological mechanism for
resource allocation in computational models of working memory.
<em>CC</em>, <em>16</em>(2), 756–775. (<a
href="https://doi.org/10.1007/s12559-023-10234-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Working memory (WM) is a crucial cognitive function required to maintain and manipulate information that is no longer present through the senses. Two key features of WM are its limited capacity and the emergence of serial order effects. This study investigates how synaptic facilitation and diverse display dynamics influence the encoding and retention of multiple items in WM. A biophysically inspired attractor model of WM, endowed with synaptic facilitation, is considered in this study. The investigation delves into the behaviour of the model under both sequential and simultaneous display protocols. Synaptic facilitation plays a crucial role in establishing the response of the WM system by regulating resource allocation during the encoding stage. It boosts WM capacity and is a key mechanism in the emergence of serial order effects. The synaptic facilitation time constant ( $$\tau _F$$ ) is critical in modulating these effects, and its heterogeneity in the prefrontal cortex (PFC) may contribute to the combination of primacy and recency effects observed experimentally. Additionally, we demonstrate that the WM capacity exhibited by the network is heavily influenced by factors such as the stimuli nature, and their display duration. Although the network connectivity determines the WM capacity by regulating the excitation-inhibition balance, the display protocol modulates its effective limit. Our findings shed light on how different stimulation protocol dynamics affect WM, underscoring the importance of synaptic facilitation and experimental protocol design in modulating WM capacity.},
  archive      = {J_CC},
  author       = {Balagué-Marmaña, Marta and Dempere-Marco, Laura},
  doi          = {10.1007/s12559-023-10234-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {756-775},
  shortjournal = {Cogn. Comput.},
  title        = {Synaptic facilitation: A key biological mechanism for resource allocation in computational models of working memory},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cognitively inspired multi-granularity model incorporating
label information for complex long text classification. <em>CC</em>,
<em>16</em>(2), 740–755. (<a
href="https://doi.org/10.1007/s12559-023-10237-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because the abstracts contain complex information and the labels of abstracts do not contain information about categories, it is difficult for cognitive models to extract comprehensive features to match the corresponding labels. In this paper, a cognitively inspired multi-granularity model incorporating label information (LIMG) is proposed to solve these problems. Firstly, we use information of abstracts to give labels the actual semantics. It can improve the semantic representation of word embeddings. Secondly, the model uses the dual channel pooling convolutional neural network (DCP-CNN) and the timescale shrink gated recurrent units (TSGRU) to extract multi-granularity information of abstracts. One of the channels in DCP-CNN highlights the key content and the other is used for TSGRU to extract context-related features of abstracts. Finally, TSGRU adds a timescale to retain the long-term dependence by recuring the past information and a soft thresholding algorithm to realize the noise reduction. Experiments were carried out on four benchmark datasets: Arxiv Academic Paper Dataset (AAPD), Web of Science (WOS), Amazon Review and Yahoo! Answers. As compared to the baseline models, the accuracy is improved by up to 3.36%. On AAPD (54,840 abstracts) and WOS (46,985 abstracts) datasets, the micro-F1 score reached 75.62% and 81.68%, respectively. The results show that acquiring label semantics from abstracts can enhance text representations and multi-granularity feature extraction can inspire the cognitive system’s understanding of the complex information in abstracts.},
  archive      = {J_CC},
  author       = {Gao, Li and Liu, Yi and Zhu, Jianmin and Yu, Zhen},
  doi          = {10.1007/s12559-023-10237-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {740-755},
  shortjournal = {Cogn. Comput.},
  title        = {A cognitively inspired multi-granularity model incorporating label information for complex long text classification},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced interactive and multi-criteria decision-making
(TODIM) method with probabilistic dual hesitant fuzzy sets for risk
evaluation of arctic geopolitics. <em>CC</em>, <em>16</em>(2), 727–739.
(<a href="https://doi.org/10.1007/s12559-023-10229-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The psychological factors of experts play a special role in the process of decision-making, especially in some situations that experts are not completely rational. Traditional decision-making methods always just focus on the aggregation of positive preference information, which do not take the negative attribute information into account at the same time. The probabilistic dual hesitant fuzzy set (PDHFS) is one of the latest fuzzy sets, which can depict experts’ positive and negative preference information with the corresponding probability at the same time. Therefore, to manage the applications with incomplete rationality and two opposite kinds of uncertain preference information, this paper considers the influence of psychological behavior on decision-making results and introduces an interactive method based on the prospect theory. Taking the advantages of PDHFSs in group decision-making problems, we propose the distance measure of PDHFSs, based on which an improved TODIM (TOmada deDecisão Iterativa Multicritério) method under the probabilistic dual hesitant fuzzy environment is also developed. Meanwhile, we provide the specific implementation process of the proposed method. The proposed improved TODIM is applied to the risk evaluation of Arctic geopolitics. We also make a comparison with the traditional aggregation method of PDHFSs. The difference among alternatives obtained by the proposed TODIM method with prospect theory is much greater than the traditional aggregation methods without prospect theory. This paper highlights the benefits and advantages of the proposed TODIM method that is developed based on the prospect theory and probabilistic dual hesitant fuzzy distance measure.},
  archive      = {J_CC},
  author       = {Song, Chenyang and Xu, Zeshui and Zhang, Yixin},
  doi          = {10.1007/s12559-023-10229-1},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {727-739},
  shortjournal = {Cogn. Comput.},
  title        = {An enhanced interactive and multi-criteria decision-making (TODIM) method with probabilistic dual hesitant fuzzy sets for risk evaluation of arctic geopolitics},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Event-triggered adaptive neural control for full
state-constrained nonlinear systems with unknown disturbances.
<em>CC</em>, <em>16</em>(2), 717–726. (<a
href="https://doi.org/10.1007/s12559-023-10223-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the adaptive control issue for a class of uncertain nonlinear systems subject to full state constraints and external disturbance. A novel adaptive nonlinear observer is proposed to compensate for disturbance variables in the transformed system. Combining with radial basis function neural networks (RBFNNs) and nonlinear mapping (NM) mechanism, the constrained system is transformed into an unconstrained form and the system uncertainties are effectively handled. Besides that, an adaptive tracking control approach is formulated by invoking backstepping techniques and the event-sampled scheme is utilized to address the sparsity of resources. The adaptive control problem can be addressed with the proposed algorithm, applying the Lyapunov functions, RBF NNs theory, and inequality techniques. Based on the Lyapunov stability theory, it is proved that the system can never violate the specified state constraints and all the closed-loop signals are semiglobally uniformly ultimately bounded (SGUUB). The validity of the proposed approach is well illustrated by a developed numerical example.},
  archive      = {J_CC},
  author       = {Wang, Ziming and Wang, Hui and Wang, Xin and Pang, Ning and Shi, Quan},
  doi          = {10.1007/s12559-023-10223-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {717-726},
  shortjournal = {Cogn. Comput.},
  title        = {Event-triggered adaptive neural control for full state-constrained nonlinear systems with unknown disturbances},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification of developmental and brain disorders via
graph convolutional aggregation. <em>CC</em>, <em>16</em>(2), 701–716.
(<a href="https://doi.org/10.1007/s12559-023-10224-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While graph convolution-based methods have become the de-facto standard for graph representation learning, their applications to disease prediction tasks remain quite limited, particularly in the classification of neurodevelopmental and neurodegenerative brain disorders. In this paper, we introduce an aggregator normalization graph convolutional network by leveraging aggregation in graph sampling, as well as skip connections and identity mapping. The proposed model learns discriminative graph node representations by incorporating both imaging and non-imaging features into the graph nodes and edges, respectively, with the aim of augmenting predictive capabilities and providing a holistic perspective on the underlying mechanisms of brain disorders. Skip connections enable the direct flow of information from the input features to later layers of the network, while identity mapping helps maintain the structural information of the graph during feature learning. We benchmark our model against several recent baseline methods on two large datasets, Autism Brain Imaging Data Exchange (ABIDE) and Alzheimer’s Disease Neuroimaging Initiative (ADNI), for the prediction of autism spectrum disorder and Alzheimer’s disease, respectively. Experimental results demonstrate the competitive performance of our approach in comparison with recent baselines in terms of several evaluation metrics, achieving relative improvements of 50% and 13.56% in classification accuracy over graph convolutional networks (GCNs) on ABIDE and ADNI, respectively. Our study involved the development of a graph convolutional aggregation model, which aimed to predict the status of subjects in a population graph. We learned discriminative node representations by utilizing imaging and non-imaging features associated with the graph nodes and edges. Our model outperformed existing graph convolutional-based methods for disease prediction on two large benchmark datasets, as shown through extensive experiments. We achieved significant relative improvements in classification accuracy over GCN and other strong baselines.},
  archive      = {J_CC},
  author       = {Salim, Ibrahim and Hamza, A. Ben},
  doi          = {10.1007/s12559-023-10224-6},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {701-716},
  shortjournal = {Cogn. Comput.},
  title        = {Classification of developmental and brain disorders via graph convolutional aggregation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel heuristic exploration method based on action
effectiveness constraints to relieve loop enhancement effect in
reinforcement learning with sparse rewards. <em>CC</em>, <em>16</em>(2),
682–700. (<a href="https://doi.org/10.1007/s12559-023-10226-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In realistic sparse reward tasks, existing theoretical methods cannot be effectively applied due to the low sampling probability ofrewarded episodes. Profound research on methods based on intrinsic rewards has been conducted to address this issue, but exploration with sparse rewards remains a great challenge. This paper describes the loop enhancement effect in exploration processes with sparse rewards. After each fully trained iteration, the execution probability of ineffective actions is higher than thatof other suboptimal actions, which violates biological habitual behavior principles and is not conducive to effective training. This paper proposes corresponding theorems of relieving the loop enhancement effect in the exploration process with sparse rewards and a heuristic exploration method based on action effectiveness constraints (AEC), which improves policy training efficiency by relieving the loop enhancement effect. Inspired by the fact that animals form habitual behaviors and goal-directed behaviors through the dorsolateral striatum and dorsomedial striatum. The function of the dorsolateral striatum is simulated by an action effectiveness evaluation mechanism (A2EM), which aims to reduce the rate of ineffective samples and improve episode reward expectations. The function of the dorsomedial striatum is simulated by an agent policy network, which aims to achieve task goals. The iterative training of A2EM and the policy forms the AEC model structure. A2EM provides effective samples for the agent policy; the agent policy provides training constraints for A2EM. The experimental results show that A2EM can relieve the loop enhancement effect and has good interpretability and generalizability. AEC enables agents to effectively reduce the loop rate in samples, can collect more effective samples, and improve the efficiency of policy training. The performance of AEC demonstrates the effectiveness of a biological heuristic approach that simulates the function of the dorsal striatum. This approach can be used to improve the robustness of agent exploration with sparse rewards.},
  archive      = {J_CC},
  author       = {Ni, Zhenghongyuan and Jin, Ye and Liu, Peng and Zhao, Wei},
  doi          = {10.1007/s12559-023-10226-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {682-700},
  shortjournal = {Cogn. Comput.},
  title        = {A novel heuristic exploration method based on action effectiveness constraints to relieve loop enhancement effect in reinforcement learning with sparse rewards},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global exponential synchronization of clifford-valued
memristive fuzzy neural networks with delayed impulses. <em>CC</em>,
<em>16</em>(2), 671–681. (<a
href="https://doi.org/10.1007/s12559-023-10221-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global exponential synchronization of Clifford-valued memristive fuzzy neural networks (CLVMFNNs) with delayed impulses and time-varying delays is investigated. The Clifford-valued NNs are an extension of complex-valued and quaternion-valued NNs. In order to describe the system as realistically as possible, Clifford-valued memristive fuzzy neural networks with delayed impulses and time-varying delays are established. To avoid non-commutativity of the multiplication of Clifford numbers, Clifford-valued neural networks are decomposed into real-valued neural networks. To explore the exponential stability of delayed impulsive systems, a novel lemma is proposed by using Halanay differential inequality. To induce the global exponential synchronization, a novel and simple linear feedback controller is designed. Sufficient conditions are given to ensure the global exponential synchronization using the proposed novel lemma under the designed feedback controller. Compared with the previous results, the conditions given in this paper are more effective and less conservative. A numerical simulation is given to verify the effectiveness of the theoretical results.},
  archive      = {J_CC},
  author       = {Zhao, Ningning and Qiao, Yuanhua},
  doi          = {10.1007/s12559-023-10221-9},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {671-681},
  shortjournal = {Cogn. Comput.},
  title        = {Global exponential synchronization of clifford-valued memristive fuzzy neural networks with delayed impulses},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-linear feature selection based on convolution neural
networks with sparse regularization. <em>CC</em>, <em>16</em>(2),
654–670. (<a href="https://doi.org/10.1007/s12559-023-10230-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficacy of feature selection methods in dimensionality reduction and enhancing the performance of learning algorithms has been well documented. Traditional feature selection algorithms often grapple with delineating non-linear relationships between features and responses. While deep neural networks excel in capturing such non-linearities, their inherent “black-box” nature detracts from their interpretability. Furthermore, the complexity of deep network architectures can give rise to prolonged training durations and the challenge of vanishing gradients. This study aims to refine network structures, hasten network training, and bolster model interpretability without forfeiting accuracy. This paper delves into a sparse-weighted feature selection approach grounded in convolutional neural networks, termed the low-dimensional sparse-weighted feature selection network (LSWFSNet). LSWFSNet integrates a convolutional selection kernel between the input and convolutional layers, facilitating weighted convolutional calculations on input data while imposing sparse constraints on the selection kernel. Features with significant weights in this kernel are earmarked for subsequent operations in the LSWFSNet computational domain, while those with negligible weights are eschewed to diminish model intricacy. By streamlining the network’s input data, LSWFSNet refines the post-convolution feature maps, thus simplifying its structure. Acknowledging the intrinsic interconnections within the data, our study amalgamates diverse sparse constraints into a cohesive objective function. This ensures the convolutional kernel’s sparsity while acknowledging the structural dynamics of the data. Notably, the foundational convolutional network in this method can be substituted with any deep convolutional network, contingent upon suitable adjustments to the convolutional selection kernel in relation to input data dimensions. The LSWFSNet model was tested on human emotion electroencephalography (EEG) datasets curated by Shanghai Jiao Tong University. When various sparse constraint methodologies were employed, the convolutional kernel manifested sparsity. Regions in the convolutional selection kernel with non-zero weights were identified as having strong correlations with emotional responses. The empirical outcomes not only resonate with extant neuroscience insights but also supersede the baseline network in accuracy metrics. LSWFSNet’s applicability extends to pivotal tasks like keypoint recognition, be it the extraction of salient pixels in facial detection models or the isolation of target attributes in object detection frameworks. This study’s significance is anchored in the amalgamation of sparse constraint techniques with deep convolutional networks, supplanting traditional fully connected networks. This fusion amplifies model interpretability and broadens its applicability, notably in image processing arenas.},
  archive      = {J_CC},
  author       = {Wu, Wen-Bin and Chen, Si-Bao and Ding, Chris and Luo, Bin},
  doi          = {10.1007/s12559-023-10230-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {654-670},
  shortjournal = {Cogn. Comput.},
  title        = {Non-linear feature selection based on convolution neural networks with sparse regularization},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel regularized extreme learning machine based on <span
class="math display"><em>L</em><sub>1</sub></span> -norm and <span
class="math display"><em>L</em><sub>2</sub></span> -norm: A sparsity
solution alternative to lasso and elastic net. <em>CC</em>,
<em>16</em>(2), 641–653. (<a
href="https://doi.org/10.1007/s12559-023-10220-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to present a new regularized extreme learning machine (ELM) algorithm that can perform variable selection based on the simultaneous use of both ridge and Liu regressions in order to cope with some disadvantages of ELM and its variants such as instability and poor generalization performance and lack of sparsity. The proposed algorithm was compared with the classical ELM as well as the variants based on ridge, Liu, Lasso and Elastic Net approaches by cross-validation process and best tuning parameter over seven different real-world applications and their performances were presented comparatively. The proposed algorithm outperformed ridge, Lasso and Elastic Net algorithms in training performance prediction (average 40%) and stability (average 80%) and in test performance prediction (average 20%) and stability (60%) in the majority of the data. In addition, the proposed ELM was found to be more compact (better sparsity capability) with lower norm values. The results confirmed that the proposed ELM presents more stable and sparse solutions with better generalization performance than any other algorithm under favorable conditions. The findings based on experimental study via real-world applications indicate that the proposed ELM provides effective solutions to the mentioned drawbacks and yields more stable and sparse performance with better generalization capability than its competitors. Consequently, the proposed algorithm represents a powerful alternative both regression and classification tasks in machine learning field due to its theoretical flexibility.},
  archive      = {J_CC},
  author       = {Yıldırım, Hasan and Özkale, M. Revan},
  doi          = {10.1007/s12559-023-10220-w},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {641-653},
  shortjournal = {Cogn. Comput.},
  title        = {A novel regularized extreme learning machine based on $$L_{1}$$ -norm and $$L_{2}$$ -norm: A sparsity solution alternative to lasso and elastic net},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing sentiment analysis: A cognitive approach with
negation handling via mathematical modelling. <em>CC</em>,
<em>16</em>(2), 624–640. (<a
href="https://doi.org/10.1007/s12559-023-10227-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negation handling is a crucial aspect of sentiment analysis, as it presents challenges to accurate sentiment classification by altering polarity and reducing reliability. Traditional lexicon-based approaches often lack adequate techniques for modeling negation and fail to identify the appropriate negation window. Moreover, building machine learning models for negation handling in conversational text data proves difficult due to the intricate syntactic structure of negation. To address these issues, we propose a novel unsupervised cognitive sentiment classification approach. Our research introduces the multi-criteria decision-making (MCDM)–based “Negation Handling of the Text Using the VIKOR Optimization Technique” (NEGVOT) model, which effectively handles negation in sentiment analysis. By employing the decision science method, the NEGVOT model provides a solution for correctly labeling text sentiment in both negation-free and negation-containing texts. Our approach utilizes a lexicon database to obtain context scores of textual comments and integrates emotional scores to achieve accurate sentiment classification. Through experiments conducted on three benchmarked datasets, we demonstrate that the NEGVOT model performs comparably to state-of-the-art models. The NEGVOT model achieves the accuracy of 83%, 85%, and 82% over three datasets. It significantly enhances the accuracy of sentiment orientation tagging by effectively handling sentences with negation. We employ statistical analysis to support the relevance of our findings. The NEGVOT paradigm ensures logical and consistent results while exhibiting a strong generalization capacity, enabling sentiment classification for texts containing negations. This study makes notable contributions to the advancement of unsupervised techniques and provides a robust framework for handling negation in sentiment classification tasks.},
  archive      = {J_CC},
  author       = {Punetha, Neha and Jain, Goonjan},
  doi          = {10.1007/s12559-023-10227-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {624-640},
  shortjournal = {Cogn. Comput.},
  title        = {Optimizing sentiment analysis: A cognitive approach with negation handling via mathematical modelling},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient-based competitive learning: theory. <em>CC</em>,
<em>16</em>(2), 608–623. (<a
href="https://doi.org/10.1007/s12559-023-10225-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been recently used to extract the relevant features for representing input data also in the unsupervised setting. However, state-of-the-art techniques focus mostly on algorithmic efficiency and accuracy rather than mimicking the input manifold. On the contrary, competitive learning is a powerful tool for replicating the input distribution topology. It is cognitive/biologically inspired as it is founded on Hebbian learning, a neuropsychological theory claiming that neurons can increase their specialization by competing for the right to respond to/represent a subset of the input data. This paper introduces a novel perspective by combining these two techniques: unsupervised gradient-based and competitive learning. The theory is based on the intuition that neural networks can learn topological structures by working directly on the transpose of the input matrix. At this purpose, the vanilla competitive layer and its dual are presented. The former is representative of a standard competitive layer for deep clustering, while the latter is trained on the transposed matrix. The equivalence of the layers is extensively proven both theoretically and experimentally. The dual competitive layer has better properties. Unlike the vanilla layer, it directly outputs the prototypes of the data inputs, while still allowing learning by backpropagation. More importantly, this paper proves theoretically that the dual layer is better suited for handling high-dimensional data (e.g., for biological applications), because the estimation of the weights is driven by a constraining subspace which does not depend on the input dimensionality, but only on the dataset cardinality. This paper has introduced a novel approach for unsupervised gradient-based competitive learning. This approach is very promising both in the case of small datasets of high-dimensional data and for better exploiting the advantages of a deep architecture: the dual layer perfectly integrates with the deep layers. A theoretical justification is also given by using the analysis of the gradient flow for both vanilla and dual layers.},
  archive      = {J_CC},
  author       = {Cirrincione, Giansalvo and Randazzo, Vincenzo and Barbiero, Pietro and Ciravegna, Gabriele and Pasero, Eros},
  doi          = {10.1007/s12559-023-10225-5},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {608-623},
  shortjournal = {Cogn. Comput.},
  title        = {Gradient-based competitive learning: Theory},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MC-GAT: Multi-channel graph attention networks for capturing
diverse information in complex graphs. <em>CC</em>, <em>16</em>(2),
595–607. (<a href="https://doi.org/10.1007/s12559-023-10222-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph attention networks (GAT), which have strong performance in tackling various analytical tasks on network data, have attracted wide attention. However, complex real-world networks have both edge topology and node features. GAT only relies on the topology of edges to extract network information, and the association between node features is underutilized, which may seriously hinder GAT’s expressive ability on some tasks. In addition, the attention mechanism can automatically assign different weights to different pieces of information, making it easier to express information with multiple aspects. Therefore, we propose semi-supervised multi-channel attention networks (MC-GAT), which simultaneously extract node features, topological structures, and their combination information. The MC-GAT model consists of two specific attention modules, one common attention module, and the attention mechanism. To create node embeddings containing various informational aspects, we use the attention mechanism to assign weights to each. Extensive testing on benchmark datasets has shown us to be at our best. The performance of the proposed model is demonstrated by the fact that MC-GAT achieves relative maximum improvements of 4.22% for accuracy (ACC) on BlogCatalog and 5.23% for macro F1-score (F1) on UAI2010. Experimental results on relevant datasets show that the method has satisfactory performance, and multi-channel graph attention can capture richer structural and feature information within linear time complexity. This work provides a new way of thinking about graph neural networks.},
  archive      = {J_CC},
  author       = {La, Zhiyao and Qian, Yurong and Leng, Hongyong and Gu, Tianyu and Gong, Weijun and Chen, Jiaying},
  doi          = {10.1007/s12559-023-10222-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {595-607},
  shortjournal = {Cogn. Comput.},
  title        = {MC-GAT: Multi-channel graph attention networks for capturing diverse information in complex graphs},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-attention triple decoder deep convolution network
for breast cancer segmentation using ultrasound images. <em>CC</em>,
<em>16</em>(2), 581–594. (<a
href="https://doi.org/10.1007/s12559-023-10214-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is a widely diagnosed deadly disease commonly present in middle-aged women around the globe. Ultrasound (U/S) imaging is widely used for the early prediction and segmentation of BC due to low radiation and cheapness. Manual BC segmentation from ultrasound imaging is a complex and laborious task due to inherited noise. Many deep learning-based breast cancer diagnostic methods are presented that can further be enhanced to improve the segmentation performance. This work proposed a U-shaped auto encoder-based multi-attention triple decoder convolution neural network for BC segmentation from U/S images. To capture multi-scale diverse spatial image features this work introduced a multi-scale convolution operation-based encoder network. To process the multi-scale learned diverse spatial features in the encoder path multi-scale triple decoder network is designed that was not found in earlier studies. To highlight the tumor region at different scales multi-attention mechanism is introduced in each decoder network. The multi-attention mechanism is designed to suppress the other region information and to highlight the tumor region features at different scales. The proposed deep network produced the segmentation dice of 90.45% on the UDIAT dataset and the segmentation dice of 89.13% on the BUSI dataset. The testing Jaccard index of 83.40% is recorded on the UDIAT dataset and a Jaccard index of 82.31% is recorded on the BUSI dataset. The result comparison with existing methods shows that our method achieved the highest results. The segmentation performance of the triple decoder-based BC segmentation model suggested that it can effectively be used to automate the manual breast cancer segmentation task from ultrasound images.},
  archive      = {J_CC},
  author       = {Umer, Muhammad Junaid and Sharif, Muhammad and Raza, Mudassar},
  doi          = {10.1007/s12559-023-10214-8},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {581-594},
  shortjournal = {Cogn. Comput.},
  title        = {A multi-attention triple decoder deep convolution network for breast cancer segmentation using ultrasound images},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel feature fusion approach for classification of motor
imagery EEG based on hierarchical extreme learning machine. <em>CC</em>,
<em>16</em>(2), 566–580. (<a
href="https://doi.org/10.1007/s12559-023-10217-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because feature extraction from electroencephalogram (EEG) signals is essential for cognitive investigations, effective feature extraction approaches are needed to improve the practical recognition accuracy of EEG signals. In this paper, a strategy is presented for fusing both the linear and nonlinear features from EEG signals to improve the accuracy of motor imagery classification. First, principal component analysis (PCA) is used to extract the linear features from EEG, and linear discriminant analysis (LDA) is introduced to supplement the discriminant features by utilizing the label information of the training data. Second, we use parametric t-distributed stochastic neighbor embedding (PTSNE) to extract the nonlinear features reflecting the original manifold structure of the EEG data. Third, these linear and nonlinear features are fused to generate the final features for classification. After feature extraction, we choose the hierarchical extreme learning machine (HELM) algorithm, which has a high classification accuracy for EEG signal classification of motor imagery. To verify the validity of the strategy, we compare the accuracy of the proposed method with that of other methods on the motor imagery dataset. We achieve a high accuracy of 95.89% and an average accuracy of 93.45%. The performance shows that the accuracy of the proposed feature fusion strategy is effective for classification and that the recognition accuracy is improved compared with other state-of-the-art methods.},
  archive      = {J_CC},
  author       = {Duan, Lijuan and Lian, Zhaoyang and Qiao, Yuanhua and Chen, Juncheng and Miao, Jun and Li, Mingai},
  doi          = {10.1007/s12559-023-10217-5},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {566-580},
  shortjournal = {Cogn. Comput.},
  title        = {A novel feature fusion approach for classification of motor imagery EEG based on hierarchical extreme learning machine},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast clustering for cooperative perception based on LiDAR
adaptive dynamic grid encoding. <em>CC</em>, <em>16</em>(2), 546–565.
(<a href="https://doi.org/10.1007/s12559-023-10211-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a strategy inspired by cooperative behavior in nature to enhance information sharing among autonomous vehicles (AVs), advancing intelligent transportation systems. However, in the context of multiple light detection and ranging (LiDAR)-equipped vehicles cooperating, the generated point cloud data can obstruct real-time environment perception. This research assumes real-time, lossless data transmission, and accurate and reliable pose information sharing between cooperative vehicles. Based on human-inspired principles and computer imaging techniques, a method was proposed to encode dynamic grids for fusion LiDAR point cloud data, contingent upon inter-vehicle distances. Each grid cell corresponds to an image pixel, creating smaller cells for dense point clouds and larger cells for sparse point clouds. This maintains an approximately equal number of point clouds per cell. Additionally, a ground segmentation approach is developed, based on density and elevation differences of adjacent grids to retain significant obstacle points. A grid density-based adjacent clustering approach was proposed, which effectively classified the connected grid cells containing the obstacle points. Experiments using the robot operating system on a standard computer with public data show that the perception processing period for six cooperative vehicles is merely 43.217 ms. This demonstrates the efficacy of our method in handling large volumes of LiDAR point cloud data. Comparative analysis with three alternative methods confirmed the superior accuracy and recall of our clustering approach. This underscores the robustness of our biologically inspired methodology for the design of cooperative perception, thereby promoting efficient and safe vehicle navigation.},
  archive      = {J_CC},
  author       = {Kuang, Xinkai and Zhu, Hui and Yu, Biao and Li, Bichun},
  doi          = {10.1007/s12559-023-10211-x},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {546-565},
  shortjournal = {Cogn. Comput.},
  title        = {Fast clustering for cooperative perception based on LiDAR adaptive dynamic grid encoding},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trustworthy artificial intelligence based on an explicable
temporal feature network for industrial fault diagnosis. <em>CC</em>,
<em>16</em>(2), 534–545. (<a
href="https://doi.org/10.1007/s12559-023-10218-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is extensively utilized across various high-risk domains, and ensuring the safety, reliability, and trustworthiness of these systems is of paramount importance. This necessitates adherence to several imperative requirements such as fairness, explainability, accountability, reliability, and acceptability in order to establish the trustworthiness of these systems. The decision-making process of the systems relies heavily on data quality. However, existing studies in the field of industrial fault diagnosis have not fully considered the influence of noise interference on the system accuracy and the interpretability of the algorithm. Therefore, this study aims to investigate reliable and robust diagnostic techniques along with black-box model interpretation when confronted with noise interference in practical applications for industrial fault diagnosis. To solve the above problems, an explicable temporal feature network (ETFN) based on deep Shapley additive explanation (Deep SHAP) values is proposed, which increases the robustness and interpretability of the model. First, adaptive features extracted from the improved deep residual shrinkage network are combined with empirical features to increase the robustness of the model. Then, the combined features are used as input to the ETFN model for rotating device diagnosis. Deep SHAP is used to rank all the combined feature contributions and further interpret the model diagnosis by adjusting the number of features. The proposed ETFN achieves a good balance between stability, accuracy, and interpretation on three real-world datasets. Leading accuracy is achieved on all three datasets. In particular, a diagnostic accuracy of more than 97% can still be maintained when perturbed by noise, which is not achieved by alternative methods. The interoperability of the proposed method in industrial diagnostic applications is also enhanced by Deep SHAP. We implemented ETFN for extremely robust diagnosis and human-computer interaction in real noise for industrial data.},
  archive      = {J_CC},
  author       = {Hu, Junwei and Zhang, Yong and Li, Weigang and Zheng, Xiujuan and Tian, Zhiqiang},
  doi          = {10.1007/s12559-023-10218-4},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {534-545},
  shortjournal = {Cogn. Comput.},
  title        = {Trustworthy artificial intelligence based on an explicable temporal feature network for industrial fault diagnosis},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel cognitively inspired deep learning approach to
detect drivable areas for self-driving cars. <em>CC</em>,
<em>16</em>(2), 517–533. (<a
href="https://doi.org/10.1007/s12559-023-10215-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road drivable area detection is an important task in computer vision with applications in self-driving cars. Accurately detecting and mapping drivable areas in a scene allow vehicles and robots to plan safe trajectories. In this paper, a novel cognitively inspired approach is proposed that considers both the salient areas in a driving scene and the driver’s attention mechanism. Specifically, the attention point is computed by combining salient areas and attention regions. Furthermore, we use the attention point and two boundary nodes on the road edge to form a triangular road surface area. Finally, we segment this area and remove the salient region within this area to obtain the drivable road area. Experimental results show that our proposed method can address the shortcomings of traditional vanishing point detection algorithms and enhance drivable area perception when combined with 4 different backbones on the DeepLabV3+ model. In particular, we demonstrate the effectiveness of merging salient area and attention area algorithms and explore the joint understanding of these complementary visual cues.},
  archive      = {J_CC},
  author       = {Jiang, Fengling and Wang, Zeling and Yue, Guoqing},
  doi          = {10.1007/s12559-023-10215-7},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {517-533},
  shortjournal = {Cogn. Comput.},
  title        = {A novel cognitively inspired deep learning approach to detect drivable areas for self-driving cars},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-based interactive matching for pairs of news articles.
<em>CC</em>, <em>16</em>(2), 507–516. (<a
href="https://doi.org/10.1007/s12559-023-10208-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-text document matching has been widely applied in many applications, such as topic detection and tracking and relative article recommendation. However, existing methods still have many defects in extracting and utilizing long text features, especially in news articles. In this paper, we propose a novel long-text pair matching framework that constructs texts into graphs and comprehensively utilizes graphs for interactive matching. We conduct extensive experiments on four datasets, including CNSE, CNSS, TNSE, and TNSS. Extensive experimental results demonstrate the significant improvements over a wide range of state-of-the-art methods. The proposed EEG model is novel, and it significantly outperforms an extensive range of baselines.},
  archive      = {J_CC},
  author       = {Pan, Kunhao and Zhang, Guowei and Liao, Meng and Xu, Jin},
  doi          = {10.1007/s12559-023-10208-6},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {507-516},
  shortjournal = {Cogn. Comput.},
  title        = {Graph-based interactive matching for pairs of news articles},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine un-learning: An overview of techniques,
applications, and future directions. <em>CC</em>, <em>16</em>(2),
482–506. (<a href="https://doi.org/10.1007/s12559-023-10219-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ML applications proliferate across various sectors. Large internet firms employ ML to train intelligent models using vast datasets, including sensitive user information. However, new regulations like GDPR require data removal by businesses. Deleting data from ML models is more complex than databases. Machine Un-learning (MUL), an emerging field, garners academic interest for selectively erasing learned data from ML models. MUL benefits multiple disciplines, enhancing privacy, security, usability, and accuracy. This article reviews MUL’s significance, providing a taxonomy and summarizing key MUL algorithms. We categorize modern MUL models by criteria, including model independence, data driven, and implementation considerations. We explore MUL applications in smart devices and recommendation systems. We also identify open questions and future research areas. This work advances methods for implementing regulations like GDPR and safeguarding user privacy.},
  archive      = {J_CC},
  author       = {Sai, Siva and Mittal, Uday and Chamola, Vinay and Huang, Kaizhu and Spinelli, Indro and Scardapane, Simone and Tan, Zhiyuan and Hussain, Amir},
  doi          = {10.1007/s12559-023-10219-3},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {482-506},
  shortjournal = {Cogn. Comput.},
  title        = {Machine un-learning: An overview of techniques, applications, and future directions},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State-of-the-art of stress prediction from heart rate
variability using artificial intelligence. <em>CC</em>, <em>16</em>(2),
455–481. (<a href="https://doi.org/10.1007/s12559-023-10200-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in the manufacturing and commercialisation of miniaturised sensors and low-cost wearables have enabled an effortless monitoring of lifestyle by detecting and analysing physiological signals. Heart rate variability (HRV) denotes the time interval between consecutive heartbeats.The HRV signal, as detected by the sensors and devices, has been popularly used as an indicative measure to estimate the level of stress, depression, and anxiety. For years, artificial intelligence (AI)-based learning systems have been known for their predictive capabilities, and in recent years, AI models with deep learning (DL) architectures have been successfully applied to achieve unprecedented accuracy. In order to determine effective methodologies applied to the collection, processing, and prediction of stress from HRV data, this work presents an in depth analysis of 43 studies reporting the application of various AI algorithms. The methods are summarised in tables and thoroughly evaluated to ensure the completeness of their findings and reported results. To make the work comprehensive, a detailed review has been conducted on sensing technologies, pre-processing methods applied on multi-modal data, and employed prediction models. This is followed by a critical examination of how various Machine Learning (ML) models, have been utilised in predicting stress from HRV data. In addition, the reported reseults from the selected studies have been carefully analysed to identify features that enable the models to perform better. Finally, the challenges of using HRV to predict stress are listed, along with some possible mitigation strategies. This work aims to highlight the impact of AI-based stress prediction methodologies from HRV data, and is expected to aid the development of more meticulous techniques.},
  archive      = {J_CC},
  author       = {Haque, Yeaminul and Zawad, Rahat Shahriar and Rony, Chowdhury Saleh Ahmed and Al Banna, Hasan and Ghosh, Tapotosh and Kaiser, M. Shamim and Mahmud, Mufti},
  doi          = {10.1007/s12559-023-10200-0},
  journal      = {Cognitive Computation},
  month        = {3},
  number       = {2},
  pages        = {455-481},
  shortjournal = {Cogn. Comput.},
  title        = {State-of-the-art of stress prediction from heart rate variability using artificial intelligence},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using curiosity for an even representation of tasks in
continual offline reinforcement learning. <em>CC</em>, <em>16</em>(1),
425–453. (<a href="https://doi.org/10.1007/s12559-023-10213-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the means of using curiosity on replay buffers to improve offline multi-task continual reinforcement learning when tasks, which are defined by the non-stationarity in the environment, are non labeled and not evenly exposed to the learner in time. In particular, we investigate the use of curiosity both as a tool for task boundary detection and as a priority metric when it comes to retaining old transition tuples, which we respectively use to propose two different buffers. Firstly, we propose a Hybrid Reservoir Buffer with Task Separation (HRBTS), where curiosity is used to detect task boundaries that are not known due to the task-agnostic nature of the problem. Secondly, by using curiosity as a priority metric when it comes to retaining old transition tuples, a Hybrid Curious Buffer (HCB) is proposed. We ultimately show that these buffers, in conjunction with regular reinforcement learning algorithms, can be used to alleviate the catastrophic forgetting issue suffered by the state of the art on replay buffers when the agent’s exposure to tasks is not equal along time. We evaluate catastrophic forgetting and the efficiency of our proposed buffers against the latest works such as the Hybrid Reservoir Buffer (HRB) and the Multi-Time Scale Replay Buffer (MTR) in three different continual reinforcement learning settings. These settings are defined based on how many times the agent encounters the same task, how long they last, and how different new tasks are when compared to the old ones (i.e., how large the task drift is). The three settings are namely, 1. prolonged task encounter with substantial task drift, and no task re-visitation, 2. frequent, short-lived task encounter with substantial task drift and task re-visitation, and 3. every timestep task encounter with small task drift and task re-visitation. Experiments were done on classical control tasks and Metaworld environment. Experiments show that our proposed replay buffers display better immunity to catastrophic forgetting compared to existing works in all but the every time step task encounter with small task drift and task re-visitation. In this scenario curiosity will always be higher, thus not being an useful measure in both proposed buffers, making them not universally better than other approaches across all types of CL settings, and thereby opening up an avenue for further research.},
  archive      = {J_CC},
  author       = {Pathmanathan, Pankayaraj and Díaz-Rodríguez, Natalia and Del Ser, Javier},
  doi          = {10.1007/s12559-023-10213-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {425-453},
  shortjournal = {Cogn. Comput.},
  title        = {Using curiosity for an even representation of tasks in continual offline reinforcement learning},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multispectral image quality improvement based on global
iterative fusion constrained by meteorological factors. <em>CC</em>,
<em>16</em>(1), 404–424. (<a
href="https://doi.org/10.1007/s12559-023-10207-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been proven that the refractive index is related to meteorological parameters in physics. The temperature changes the atmospheric and lens refractive indices, resulting in image degradation. Image restoration aims to recover the sharp image from the degraded images. It is also the basis of many computer vision tasks. A series of methods have been explored and used in this area. Sometimes, meteorological factors cause image degradation. Most of the existing image restoration methods do not consider meteorological factors’ influence on image degradation. How meteorological factors affect image quality is not yet known. A multispectral image dataset with corresponding meteorological parameters is presented to solve the problem. We propose a novel multispectral image restoration algorithm using global iterative fusion. The proposed method firstly enhances image edge features through spatial filtering. Then, the Gaussian function is used to constrain the weights between each channel in the image. Finally, a global iterative fusion method is used to fuse image spatial and spectral features to obtain an improved multispectral image. The algorithm explores the impact of meteorological factors on image quality. It considers the impact of atmospheric factors on image quality and incorporates it into the image restoration process. Extensive experimental results illustrate that the method achieves favorable performance on real data. The proposed algorithm is also more robust than other state-of-the-art algorithms. In this paper, we present an algorithm for improving the quality of multispectral images. The proposed algorithm incorporates the influence of meteorological parameters into the image restoration method to better describe the relationship between different spectral channels. Extensive experiments are conducted to validate the effectiveness of the algorithm. Additionally, we investigate the impact of near-surface meteorological parameters on multispectral image quality.},
  archive      = {J_CC},
  author       = {Shi, Yuetian and Fu, Bin and Wang, Nan and Chen, Yaxiong and Fang, Jie},
  doi          = {10.1007/s12559-023-10207-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {404-424},
  shortjournal = {Cogn. Comput.},
  title        = {Multispectral image quality improvement based on global iterative fusion constrained by meteorological factors},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability analysis of quaternion-valued neutral neural
networks with generalized activation functions. <em>CC</em>,
<em>16</em>(1), 392–403. (<a
href="https://doi.org/10.1007/s12559-023-10212-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stability is a central issue in the study of dynamical systems, and quaternion-valued neural networks (QVNNs) perform well in handling the problem involving high-dimension date. The paper is dedicated to investigating the stability problem of QVNNs with neutral delay. In order to accurately estimate the derivative of Lyapunov functional, both reciprocally convex inequality and Wirtinger-based inequality are extended to the quaternion domain. And the direct quaternion method is used to analyze the quaternion-valued neutral neural networks (QVNNNs). Based on the generalized inequalities, the existence, uniqueness, and global stability criteria for QVNNS with several freedom matrices are derived. Concision and compact stability criteria of QVNNNs are established in the form of quaternion-valued LMIs, and the correctness of the theoretical results was verified through a numerical example.},
  archive      = {J_CC},
  author       = {Wu, Yanqiu and Tu, Zhengwen and Dai, Nina and Wang, Liangwei and Hu, Ning and Peng, Tao},
  doi          = {10.1007/s12559-023-10212-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {392-403},
  shortjournal = {Cogn. Comput.},
  title        = {Stability analysis of quaternion-valued neutral neural networks with generalized activation functions},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cognitively-inspired multi-scale spectral-spatial
transformer for hyperspectral image super-resolution. <em>CC</em>,
<em>16</em>(1), 377–391. (<a
href="https://doi.org/10.1007/s12559-023-10210-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hyperspectral image (HSI) super-resolution (SR) without auxiliary high-resolution images is a challenging task in computer vision applications. The existing methods almost resort to the deep convolutional neural networks of fixed geometrical kernel, which can not model the long-range dependencies and does not conform to the human visual cognition. To address this issue, we propose the cognitively-inspired multi-scale spectral-spatial transformer for HSI SR. To solve the problem of high storage and computation burden, the overlapped band grouping strategy is adopted in light of high similarity between neighboring spectral bands of HSI. Considering the different textures and details that appear in HSIs, inspired by the human cognitive mechanism, the multi-scale spatial and spectral transformer blocks are developed which can efficiently and effectively learn the spatial and spectral feature representation at different scales and long-range dependencies of features. Finally, to fuse the feature information of neighboring groups, the 2D convolution mixed with 3D separable convolution is designed, which fully explores the complementarity and continuity of spatial and spectral information. Extensive experiments conducted on three benchmark datasets demonstrate that the proposed method yields state-of-the-art results at different scales. The effectiveness of the proposed method is verified through spatial and spectral dimension data visualization and ablation experiments. The code and models are publicly available at https://github.com/liushiji666/MMSSTN . The experimental results prove the effectiveness of our proposed method, which largely overcomes the disadvantage that convolution is ineffective for long-range dependence modeling. The method performs long-range dependence modeling on both spatial and spectral features and efficiently mines complementary information between bands, thereby enhancing the model’s high perceptual ability.},
  archive      = {J_CC},
  author       = {Xu, Qin and Liu, Shiji and Liu, Jinpei and Luo, Bin},
  doi          = {10.1007/s12559-023-10210-y},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {377-391},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitively-inspired multi-scale spectral-spatial transformer for hyperspectral image super-resolution},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-guided multi-scale fusion network for similar
objects semantic segmentation. <em>CC</em>, <em>16</em>(1), 366–376. (<a
href="https://doi.org/10.1007/s12559-023-10206-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation accuracy is critical in marine ecological detection utilizing unmanned aerial vehicles (UAVs). By flying a drone around, we can swiftly determine the location of a variety of species. However, remote sensing photos, particularly those of inter-class items, are remarkably similar, and there are a significant number of little objects. The universal segmentation network is ineffective. This research constructs attentional networks that imitate the human cognitive system, inspired by camouflaged object detection and the management of human attentional mechanisms in the recognition of diverse things. This research proposes TriseNet, an attention-guided multi-scale fusion semantic segmentation network that solves the challenges of high item similarity and poor segmentation accuracy in UAV settings. To begin, we employ a bidirectional feature extraction network to extract low-level spatial and high-level semantic information. Second, we leverage the attention-induced cross-level fusion module (ACFM) to create a new multi-scale fusion branch that performs cross-level learning and enhances the representation of inter-class comparable objects. Finally, the receptive field block (RFB) module is used to increase the receptive field, resulting in richer characteristics in specific layers. The inter-class similarity increases the difficulty of segmentation accuracy greatly, whereas the three modules improve feature expression and segmentation results. Experiments are conducted using our UAV dataset, UAV-OUC-SEG (55.61% MIoU), and the public dataset, Cityscapes (76.10% MIoU), to demonstrate the efficacy of our strategy. In two datasets, the TriseNet delivers the best results when compared to other prominent segmentation algorithms.},
  archive      = {J_CC},
  author       = {Yao, Fengqin and Wang, Shengke and Ding, Laihui and Zhong, Guoqiang and Li, Shu and Xu, Zhiwei},
  doi          = {10.1007/s12559-023-10206-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {366-376},
  shortjournal = {Cogn. Comput.},
  title        = {Attention-guided multi-scale fusion network for similar objects semantic segmentation},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving knowledge learning through modelling students’
practice-based cognitive processes. <em>CC</em>, <em>16</em>(1),
348–365. (<a href="https://doi.org/10.1007/s12559-023-10201-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practice is an essential means by which humans and animals engage in cognitive activities. Intelligent tutoring systems, with a crucial component of modelling learners’ cognitive processes during learning and optimizing their learning strategies, offer an excellent platform to investigate students’ practice-based cognitive processes. In related studies, modelling methods for cognitive processes have demonstrated commendable performance. Furthermore, researchers have extended their investigations using decision-theoretic approaches, such as a partially observable Markov decision process (POMDP), to induce learning strategies by modelling the students’ cognitive processes. However, the existing research has primarily centered around the modelling of macro-level instructional behaviors rather than the specific practice selection made by the students within the intricate realms of cognitive domains. In this paper, we adapt the POMDP model to represent relations between the student’s performance on cognitive tasks and his/her cognitive states. By doing so, we can predict his/her performance while inducing learning strategies. More specifically, we focus on question selection during the student’s real-time learning activities in an intelligent tutoring system. To address the challenges on modelling complex cognitive domains, we exploit the question types to automate parameter learning and subsequently employ information entropy techniques to refine learning strategies in the POMDP. We conduct the experiments in two real-world knowledge concept learning domains. The experimental results show that the performance of the learning strategies induced by our new model is superior to that of other learning strategies. Moreover, the new model has good reliability in predicting the student’s performance. Utilizing an intelligent tutoring system as the research platform, this article addresses the modelling and strategy induction challenges of practice-based cognitive processes with intricate structures, aiming to tutor students effectively. Our work provides a new approach of predicting the students’ performance as well as personalizing their learning strategies.},
  archive      = {J_CC},
  author       = {Gao, Huifan and Zeng, Yifeng and Ma, Biyang and Pan, Yinghui},
  doi          = {10.1007/s12559-023-10201-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {348-365},
  shortjournal = {Cogn. Comput.},
  title        = {Improving knowledge learning through modelling students’ practice-based cognitive processes},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Construction of a hierarchical organization in semantic
memory: A model based on neural masses and gamma-band synchronization.
<em>CC</em>, <em>16</em>(1), 326–347. (<a
href="https://doi.org/10.1007/s12559-023-10202-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic memory is characterized by a hierarchical organization of concepts based on shared properties. However, this aspect is insufficiently dealt with in recent neurocomputational models. Moreover, in many cognitive problems that exploit semantic memory, gamma-band synchronization can be relevant in favoring information processing and feature binding. In this work, we propose an attractor network model of semantic memory. Each computational unit, coding for a different feature, is described with a neural mass circuit oscillating in the gamma range. The model is trained with an original nonsymmetric Hebb rule based on a presynaptic gating mechanism. After training, the network creates a taxonomy of categories, distinguishes between subordinate and superordinate concepts, and discriminates between salient and marginal features. Examples are provided concerning a fourteen-animal taxonomy, including several subcategories. A sensitivity analysis reveals the robustness of the network but also points out conditions leading to confusion among categories, similar to the one observed in dreaming and some neurological disorders. Finally, the analysis emphasizes the role of fast GABAergic interneurons and inhibitory-excitatory balance to allow the correct synchronization of features. The model represents an original attempt to deal with a hierarchical organization of objects in semantic memory and correlated patterns, still exploiting gamma-band synchronization to favor neural processing. The same ideas, introduced in a more sophisticated multilayer network, can deepen our knowledge of semantic memory organization in the brain. Finally, they can open new perspectives in quantitatively analyzing neurological disorders connected with distorted semantics.},
  archive      = {J_CC},
  author       = {Ursino, Mauro and Pirazzini, Gabriele},
  doi          = {10.1007/s12559-023-10202-y},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {326-347},
  shortjournal = {Cogn. Comput.},
  title        = {Construction of a hierarchical organization in semantic memory: A model based on neural masses and gamma-band synchronization},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoDeS: A deep learning framework for identifying
COVID-caused depression symptoms. <em>CC</em>, <em>16</em>(1), 305–325.
(<a href="https://doi.org/10.1007/s12559-023-10190-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a serious mental health condition that affects a person’s ability to feel happy and engaged in activities. The COVID-19 pandemic has led to an increase in depression due to factors such as isolation, financial stress, and uncertainty about the future. Additionally, restrictions on travel and socializing have contributed to feelings of loneliness and isolation. In this research, we present a deep learning framework named CoDeS (COVID-caused depression symptoms) for detecting prodromes of depression in online users caused due to COVID pandemic. This framework uses a combination of CNN, LSTM, and integrated CNN-LSTM techniques, with three different feature representation methods, viz. Word2Vec, TF-IDF, and BERT. Nine experiments were conducted on individual and integrated models, and the results were evaluated based on the accuracy, precision, recall, F1-score, and Matthews correlation coefficient (MCC) performance metric. The highest accuracy value of 98.95% was recorded for the TF-IDF-based integrated CNN+LSTM model. When the same integrated model was trained using Word2Vec and BERT-based features, it still performed well with an accuracy of 97.32% and 98.51% respectively. The results demonstrate that the TF-IDF-based feature representation performed better than the Word2Vec and BERT-based feature representations for the CNN and LSTM models in identifying COVID-caused depression symptoms. The proposed approaches showcased substantial advancements over the existing ones, with significant improvements in accuracy. TF-IDF-CNN+LSTM achieved an accuracy approximately 37.28% higher, while BERT-CNN, BERT-LSTM, and BERT-CNN+LSTM achieved accuracy enhancements of approximately 29.78%, 34.44%, and 27.14% respectively. These accuracy improvements demonstrate the superior classification capabilities of the proposed approaches, leading to more precise depression analysis outcomes. In terms of F1 measure, the proposed approaches consistently demonstrated superior performance, with F1 measure values ranging from 0.965 to 0.987. BERT-CNN+LSTM achieved the highest F1 measure, highlighting its balanced precision and recall. Overall, the proposed approaches outperformed existing ones in terms of recall, precision, accuracy, and F1 measure, with improvements ranging from 27.14 to 44.85%. By incorporating advanced techniques such as TF-IDF, CNN, LSTM, and BERT, more accurate and reliable sentiment analysis outcomes can be achieved, offering the potential for enhanced applications in this field.},
  archive      = {J_CC},
  author       = {Wani, Mudasir Ahmad and ELAffendi, Mohammad and Bours, Patrick and Imran, Ali Shariq and Hussain, Amir and Abd El-Latif, Ahmed A.},
  doi          = {10.1007/s12559-023-10190-z},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {305-325},
  shortjournal = {Cogn. Comput.},
  title        = {CoDeS: A deep learning framework for identifying COVID-caused depression symptoms},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personality enhanced emotion generation modeling for
dialogue systems. <em>CC</em>, <em>16</em>(1), 293–304. (<a
href="https://doi.org/10.1007/s12559-023-10204-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion plays a crucial role in human communication, as it adds depth and richness to conversations. In recent years, there has been growing interest in developing conversation systems with the ability to generate emotions. However, to create more engaging and realistic interactions, it is essential to consider the influence of personality on emotion generation. This paper proposes a novel approach that combines personality modeling with emotion generation for conversation systems. By incorporating personality traits into the emotion generation process, we aim to create more personalized and contextually appropriate emotional responses. Drawing from BigFive model and emotion computation techniques, our model takes into account individual differences in personality to generate emotions that align with each user’s unique characteristics. Experiments show that combining emotion modeling with personality in a dialogue system helps improve the performance of emotion generation models. Additionally, it is also verified that our approach outperforms other baselines on several metrics.},
  archive      = {J_CC},
  author       = {Ma, Zhiqiang and Jia, Wenchao and Zhou, Yutong and Xu, Biqi and Liu, Zhiqiang and Wu, Zhuoyi},
  doi          = {10.1007/s12559-023-10204-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {293-304},
  shortjournal = {Cogn. Comput.},
  title        = {Personality enhanced emotion generation modeling for dialogue systems},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bifurcation−driven tipping in a novel bicyclic crossed
neural network with multiple time delays. <em>CC</em>, <em>16</em>(1),
278–292. (<a href="https://doi.org/10.1007/s12559-023-10199-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anatomical experiments have proved that a large number of ring structures exist in neural networks. Therefore, many scholars have focused on modeling and dynamic analysis of multi-ring neural networks. However, most current research regarding multi-ring neural networks considers the case that rings share only one neuron with each other. This type of connection among rings fails to adequately capture the complex structure of actual neural networks. In this paper, we consider two sharing neurons between rings and propose a bicyclic crossed neural network model with multiple time delays. Then, the stability condition of the proposed neural network model is given without time delays. By choosing the sum of time delays as the bifurcation parameter, the occurrence conditions of tipping due to Hopf bifurcation are derived, and the tipping point (bifurcation threshold) is accurately determined. In addition, the explicit formulae for ascertaining the Hopf bifurcation properties are given by utilizing the center manifold theory, which further reveals the evolutionary tipping mechanism. Finally, through numerical simulations, the validity of the theoretical analysis is verified. The results show that with the increase in time delays, the network will gradually lose stability, and the tipping driven by Hopf bifurcation will occur. Moreover, the magnitude of time delays emerges as a significant determinant of both the amplitude and the oscillation period of unstable neurons.},
  archive      = {J_CC},
  author       = {Du, Xiangyu and Xiao, Min and Ding, Jie and He, Jiajin and Yao, Yi and Cao, Jinde},
  doi          = {10.1007/s12559-023-10199-4},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {278-292},
  shortjournal = {Cogn. Comput.},
  title        = {Bifurcation−Driven tipping in a novel bicyclic crossed neural network with multiple time delays},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online signature recognition: A biologically inspired
feature vector splitting approach. <em>CC</em>, <em>16</em>(1), 265–277.
(<a href="https://doi.org/10.1007/s12559-023-10205-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research introduces an innovative approach to explore the cognitive and biologically inspired underpinnings of feature vector splitting for analyzing the significance of different attributes in e-security biometric signature recognition applications. Departing from traditional methods of concatenating features into an extended set, we employ multiple splitting strategies, aligning with cognitive principles, to preserve control over the relative importance of each feature subset. Our methodology is applied to three diverse databases (MCYT100, MCYT300, and SVC) using two classifiers (vector quantization and dynamic time warping with one and five training samples). Experimentation demonstrates that the fusion of pressure data with spatial coordinates (x and y) consistently enhances performance. However, the inclusion of pen-tip angles in the same feature set yields mixed results, with performance improvements observed in select cases. This work delves into the cognitive aspects of feature fusion, shedding light on the cognitive relevance of feature vector splitting in e-security biometric applications.},
  archive      = {J_CC},
  author       = {Faundez-Zanuy, Marcos and Diaz, Moises and Ferrer, Miguel Angel},
  doi          = {10.1007/s12559-023-10205-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {265-277},
  shortjournal = {Cogn. Comput.},
  title        = {Online signature recognition: A biologically inspired feature vector splitting approach},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-stage deep ensemble paradigm based on optimal
multi-scale decomposition and multi-factor analysis for stock price
prediction. <em>CC</em>, <em>16</em>(1), 243–264. (<a
href="https://doi.org/10.1007/s12559-023-10203-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price forecasting is important for financial risk management and investment decisions. However, traditional forecasting techniques are challenged and under pressure due to the complex characteristics of stock prices and the impact of quantitative trading. Therefore, to address these issues and produce a more accurate stock price forecasting method, this study proposes a two-stage deep integration paradigm based on optimal multi-scale decomposition and multi-factor analysis. This paradigm will also serve as a scientific support and reference for investors’ actual investment decisions. (1) Optimal multi-scale decomposition methods are proposed to achieve decomposition of the closing price. Noise suppression and optimal decomposition modes are achieved by singular spectrum analysis (SSA) and variable mode decomposition (VMD) to reconstruct the high- and low-frequency sub-series. (2) The approximate entropy is used to measure the complexity of the time series, and the approximate entropy of the decomposed sequence is judged to reconstruct the characteristic subsequence. (3) The multi-factor analysis method uses a joint feature selection technique, the spearman correlation coefficient test, and the mutual information (MI) index to find the optimal feature influence factor and extract the optimal influence factor using feature compression. (4) Two-stage deep integration was performed using bidirectional gate recurrent unit (BIGRU) to obtain the final predictions. The two major indices of the Chinese A-share market, namely the Shenzhen Stock Index (SZI) and Shanghai Stock Exchange (SSEC), with data sourced from the Flush Finance website, were used to verify the validity of the model proposed in this paper. The MAE, RMSE, and MAPE values of the proposed model in this paper are 171.1673, 221.2086, and 1.2796% in SZI market and 29.9973, 39.3508, and 0.8946% in SSEC market, respectively, which are significantly better than other comparative models. Based on the experiments, it can be seen that the optimal multi-scale decomposition method performs better in capturing the hidden information of the original data, while the multi-factor analysis provides more relevant data for the prediction, which helps to improve the accuracy of the prediction. After integrating the predictions, the decomposition-integrated hybrid model proposed in this paper predicts significantly better than with other prediction models.},
  archive      = {J_CC},
  author       = {Wang, Jujie and Liu, Jing},
  doi          = {10.1007/s12559-023-10203-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {243-264},
  shortjournal = {Cogn. Comput.},
  title        = {Two-stage deep ensemble paradigm based on optimal multi-scale decomposition and multi-factor analysis for stock price prediction},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing the potential of data augmentation in EEG
functional connectivity for early detection of alzheimer’s disease.
<em>CC</em>, <em>16</em>(1), 229–242. (<a
href="https://doi.org/10.1007/s12559-023-10188-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalographic (EEG) signals are acquired non-invasively from electrodes placed on the scalp. Experts in the field can use EEG signals to distinguish between patients with Alzheimer’s disease (AD) and normal control (NC) subjects using classification models. However, the training of deep learning or machine learning models requires a large number of trials. Datasets related to Alzheimer’s disease are typically small in size due to the lack of AD patient samples. The lack of data samples required for the training process limits the use of deep learning techniques for further development in clinical settings. We propose to increase the number of trials in the training set by means of a decomposition–recombination system consisting of three steps. Firstly, the original signals from the training set are decomposed into multiple intrinsic mode functions via multivariate empirical mode decomposition. Next, these intrinsic mode functions are randomly recombined across trials. Finally, the recombined intrinsic mode functions are added together as artificial trials, which are used for training the models. We evaluated the decomposition–recombination system on a small dataset using each subject’s functional connectivity matrices as inputs. Three different neural networks, including ResNet, BrainNet CNN, and EEGNet, were used. Overall, the system helped improve ResNet training in both the mild AD dataset, with an increase of 5.24%, and in the mild cognitive impairment dataset, with an increase of 4.50%. The evaluation of the proposed data augmentation system shows that the performance of neural networks can be improved by enhancing the training set with data augmentation. This work shows the need for data augmentation on the training of neural networks in the case of small-size AD datasets.},
  archive      = {J_CC},
  author       = {Jia, Hao and Huang, Zihao and Caiafa, Cesar F. and Duan, Feng and Zhang, Yu and Sun, Zhe and Solé-Casals, Jordi},
  doi          = {10.1007/s12559-023-10188-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {229-242},
  shortjournal = {Cogn. Comput.},
  title        = {Assessing the potential of data augmentation in EEG functional connectivity for early detection of alzheimer’s disease},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prototype consistency learning for medical image
segmentation by cross pseudo supervision. <em>CC</em>, <em>16</em>(1),
215–228. (<a href="https://doi.org/10.1007/s12559-023-10198-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the acquisition of anatomical/pathological labels is expensive and time-consuming, semi-supervised semantic segmentation is commonly utilized in medical image analysis. Previous studies have overlooked the high similarity of the pixels in medical images, resulting in many models cannot effectively distinguish the pixels of different categories. A new semi-supervised semantic segmentation framework based on prototype learning is proposed in this paper. It contains a feature extractor and a superpixel-based graph convolutional network (GCN). Two consistency loss functions are proposed in our paper. The prototype cyclic consistency loss is utilized to incorporate explicit guidance of the labeled data; the cross pseudo supervised loss is applied to make full use of the context information of the unlabeled data. We evaluate the effectiveness of our proposed method on two classical public medical image datasets (MC and JSRT). On MC dataset, the predicted IoU of our method is 94.92 ±0.5% with only 25% annotated data; on JSRT dataset, the MIoU of our method reaches 89.51 ±0.37% (with 25% annotated data) and 90.98 ±0.4% (with 50% annotated data). Our proposed method outperforms most existing semi-supervised semantic segmentation methods, even exceeds the fully supervised semantic segmentation methods, and achieves high-precision semi-supervised semantic segmentation effectively.},
  archive      = {J_CC},
  author       = {Xie, Lu and Li, Weigang and Wang, Yongqiang and Zhao, Yuntao},
  doi          = {10.1007/s12559-023-10198-5},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {215-228},
  shortjournal = {Cogn. Comput.},
  title        = {Prototype consistency learning for medical image segmentation by cross pseudo supervision},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TEGAN: Transformer embedded generative adversarial network
for underwater image enhancement. <em>CC</em>, <em>16</em>(1), 191–214.
(<a href="https://doi.org/10.1007/s12559-023-10197-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater robots are widely used in underwater missions. However, due to complex scenes, it is difficult to obtain high-quality underwater images, which usually suffer from severe distortions such as low visibility, blurred edges, and color cast. In this paper, a Transformer embedded generative adversarial network for underwater image enhancement is presented. We propose a window-based dual local enhancement block to compensate for the Transformer’s shortcomings in extracting local features and improving image clarity. Convolutional neural network is deployed in sequential and parallel modes for local enhancement. Second, for generator construction, a fusion scheme combining convolutional neural network and Transformer block in units is designed. We exploit a self-attention mechanism to extract long-distance dependencies and fully extract the original features at the initial stage to enhance the image details. Meanwhile, global information is captured through the bottleneck for color correction. Convolutional neural network, which is good at extracting local features, is introduced in Encoder/Decoder units for multiscale feature extraction and reconstruction to effectively reduce edge blurring. Finally, a Transformer embedded generative adversarial network with a two-branch discriminator is established to generate more realistic colors while preserving the image content. Comparative experimental results show that our method can achieve superior results to the state-of-the-art approaches on both paired and unpaired datasets. Excellent learning and generalization ability make it outperform others in subjective perception and overall performance evaluated by image quality metrics. In addition, the enhancement results also show the significant improvement it brings in the downstream visual application tasks.},
  archive      = {J_CC},
  author       = {Gao, Zhi and Yang, Jing and Zhang, Lu and Jiang, Fengling and Jiao, Xixiang},
  doi          = {10.1007/s12559-023-10197-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {191-214},
  shortjournal = {Cogn. Comput.},
  title        = {TEGAN: Transformer embedded generative adversarial network for underwater image enhancement},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel ensemble-learning-based convolution neural network
for handling imbalanced data. <em>CC</em>, <em>16</em>(1), 177–190. (<a
href="https://doi.org/10.1007/s12559-023-10187-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-learning-based fault diagnosis of wind turbine has played a significant role in advancing the renewable energy industry. However, the imbalanced data sampled by the supervisory control and data acquisition systems has led to low diagnosis accuracy. Additionally, deep neural networks can encounter issues like gradient vanishing and insufficient feature learning during backpropagation when the model is too deep. This article introduces a novel approach that is based on dynamic weight loss functions to modulate unbalanced data and improve diagnostic accuracy by focusing on misclassification of a small sample number. The proposed approach employs a 1D-CNN model and an ensemble-learning-based convolution neural network (EL-CNN) to enhance diversity of models and complementarity of feature learning. The EL-CNN model addresses the problem of local features being overlooked and provides more accurate results. The effectiveness of this proposed approach is well demonstrated through experimental cases on real wind turbine pitch system fault data. Two different networks using three different loss functions and three state-of-the-art fault diagnosis models are tested, demonstrating the EL-CNN model’s superiority.},
  archive      = {J_CC},
  author       = {Wu, Xianbin and Wen, Chuanbo and Wang, Zidong and Liu, Weibo and Yang, Junjie},
  doi          = {10.1007/s12559-023-10187-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {177-190},
  shortjournal = {Cogn. Comput.},
  title        = {A novel ensemble-learning-based convolution neural network for handling imbalanced data},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). O <span class="math display"><sup>2</sup></span> -bert:
Two-stage target-based sentiment analysis. <em>CC</em>, <em>16</em>(1),
158–176. (<a href="https://doi.org/10.1007/s12559-023-10191-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target-based sentiment analysis (TBSA) is one of the most important NLP research topics for widespread applications. However, the task is challenging, especially when the targets contain multiple words or do not exist in the sequences. Conventional approaches cannot accurately extract the (target, sentiment) pairs due to the limitations of the fixed end-to-end architecture design. In this paper, we propose a framework named O $$^2$$ -Bert, which consists of Opinion target extraction (OTE-Bert) and Opinion sentiment classification (OSC-Bert) to complete the task in two stages. More specifically, we divide the OTE-Bert into three modules. First, an entity number prediction module predicts the number of entities in a sequence, even in an extreme situation where no entities are contained. Afterwards, with predicted number of entities, an entity starting annotation module is responsible for predicting their starting positions. Finally, an entity length prediction module predicts the lengths of these entities, and thus, accomplishes target extraction. In OSC-Bert, the sentiment polarities of extracted targets from OTE-Bert. According to the characteristics of BERT encoders, our framework can be adapted to short English sequences without domain limitations. For other languages, our approach might work through altering the tokenization. Experimental results on the SemEval 2014-16 benchmarks show that the proposed model achieves competitive performances on both domains (restaurants and laptops) and both tasks (target extraction and sentiment classification), with F1-score as evaluated metrics. Specifically, OTE-Bert achieves 84.63%, 89.20%, 83.16%, and 86.88% F1 scores for target extraction, while OSC-Bert achieves 82.90%, 80.73%, 76.94%, and 83.58% F1 scores for sentiment classification, on the chosen benchmarks. The statistics validate the effectiveness and robustness of our approach and the new “two-stage paradigm”. In future work, we will explore more possibilities of the new paradigm on other NLP tasks.},
  archive      = {J_CC},
  author       = {Yan, Yan and Zhang, Bo-Wen and Ding, Guanwen and Li, Wenjie and Zhang, Jie and Li, Jia-Jing and Gao, Wenchao},
  doi          = {10.1007/s12559-023-10191-y},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {158-176},
  shortjournal = {Cogn. Comput.},
  title        = {O $$^2$$ -bert: Two-stage target-based sentiment analysis},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MDIW-13: A new multi-lingual and multi-script database and
benchmark for script identification. <em>CC</em>, <em>16</em>(1),
131–157. (<a href="https://doi.org/10.1007/s12559-023-10193-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Script identification plays a vital role in applications that involve handwriting and document analysis within a multi-script and multi-lingual environment. Moreover, it exhibits a profound connection with human cognition. This paper provides a new database for benchmarking script identification algorithms, which contains both printed and handwritten documents collected from a wide variety of scripts, such as Arabic, Bengali (Bangla), Gujarati, Gurmukhi, Devanagari, Japanese, Kannada, Malayalam, Oriya, Roman, Tamil, Telugu, and Thai. The dataset consists of 1,135 documents scanned from local newspaper and handwritten letters as well as notes from different native writers. Further, these documents are segmented into lines and words, comprising a total of 13,979 and 86,655 lines and words, respectively, in the dataset. Easy-to-go benchmarks are proposed with handcrafted and deep learning methods. The benchmark includes results at the document, line, and word levels with printed and handwritten documents. Results of script identification independent of the document/line/word level and independent of the printed/handwritten letters are also given. The new multi-lingual database is expected to create new script identifiers, present various challenges, including identifying handwritten and printed samples and serve as a foundation for future research in script identification based on the reported results of the three benchmarks.},
  archive      = {J_CC},
  author       = {Ferrer, Miguel A. and Das, Abhijit and Diaz, Moises and Morales, Aythami and Carmona-Duarte, Cristina and Pal, Umapada},
  doi          = {10.1007/s12559-023-10193-w},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {131-157},
  shortjournal = {Cogn. Comput.},
  title        = {MDIW-13: A new multi-lingual and multi-script database and benchmark for script identification},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transfer learning-based CNN deep learning model for
unfavorable driving state recognition. <em>CC</em>, <em>16</em>(1),
121–130. (<a href="https://doi.org/10.1007/s12559-023-10196-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of unfavorable driving states (UDS) of drivers based on electroencephalogram (EEG) measures has received continuous attention from extensive scholars on account of directly reflecting brain neural activity with high temporal resolution and low risk of being deceived. However, the existing EEG-based driver UDS detection methods involve limited exploration of the functional connectivity patterns and interaction relationships within the brain network. Therefore, there is still room for improvement in the accuracy of detection. In this project, we propose three pretrained convolutional neural network (CNN)-based automatic detection frameworks for UDS of drivers with 30-channel EEG signals. The frameworks are investigated by adjusting the learning rate and choosing the optimization solver, etc. Two different conditions of driving experiments are performed, collecting EEG signals from sixteen subjects. The acquired 1-dimensional 30-channel EEG signals are converted into 2-dimensional matrices by the Granger causality (GC) method to form the functional connectivity graphs of the brain (FCGB). Then, the FCGB are fed into pretrained deep learning models that employed transfer learning strategy for feature extraction and judgment of different EEG signal types. Furthermore, we adopt two visualization interpretability techniques, named, activation visualization and gradient-weighted class activation mapping (Grad-CAM) for better visualizing and understanding the predictions of the pretrained models after fine-tuning. The experimental outcomes show that Resnet 18 model yields the highest average recognition accuracy of 90% using the rmsprop optimizer with a learning rate of 1e − 3. The overall outcomes suggest that cooperating of biologically inspired functional connectivity graphs of the brain and pretrained transfer learning algorithms is a prospective approach in reducing the rate of major traffic accidents caused by driver unfavorable driving states.},
  archive      = {J_CC},
  author       = {Chen, Jichi and Wang, Hong and He, Enqiu},
  doi          = {10.1007/s12559-023-10196-7},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {121-130},
  shortjournal = {Cogn. Comput.},
  title        = {A transfer learning-based CNN deep learning model for unfavorable driving state recognition},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A yolo-based model for breast cancer detection in
mammograms. <em>CC</em>, <em>16</em>(1), 107–120. (<a
href="https://doi.org/10.1007/s12559-023-10189-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to implement an automated data-driven model for breast cancer detection in mammograms to support physicians’ decision process within a breast cancer screening or detection program. The public available CBIS-DDSM and the INbreast datasets were used as sources to implement the transfer learning technique on full-field digital mammography proprietary dataset. The proprietary dataset reflects a real heterogeneous case study, consisting of 190 masses, 46 asymmetries, and 71 distortions. Several Yolo architectures were compared, including YoloV3, YoloV5, and YoloV5-Transformer. In addition, Eigen-CAM was implemented for model introspection and outputs explanation by highlighting all the suspicious regions of interest within the mammogram. The small YoloV5 model resulted in the best developed solution obtaining an mAP of 0.621 on proprietary dataset. The saliency maps computed via Eigen-CAM have proven capable solution reporting all regions of interest also on incorrect prediction scenarios. In particular, Eigen-CAM produces a substantial reduction in the incidence of false negatives, although accompanied by an increase in false positives. Despite the presence of hard-to-recognize anomalies such as asymmetries and distortions on the proprietary dataset, the trained model showed encouraging detection capabilities. The combination of Yolo predictions and the generated saliency maps represent two complementary outputs for the reduction of false negatives. Nevertheless, it is imperative to regard these outputs as qualitative tools that invariably necessitate clinical radiologic evaluation. In this view, the model represents a trusted predictive system to support cognitive and decision-making, encouraging its integration into real clinical practice.},
  archive      = {J_CC},
  author       = {Prinzi, Francesco and Insalaco, Marco and Orlando, Alessia and Gaglio, Salvatore and Vitabile, Salvatore},
  doi          = {10.1007/s12559-023-10189-6},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {107-120},
  shortjournal = {Cogn. Comput.},
  title        = {A yolo-based model for breast cancer detection in mammograms},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large group decision-making method based on social network
analysis: Integrating evaluation information and trust relationships.
<em>CC</em>, <em>16</em>(1), 86–106. (<a
href="https://doi.org/10.1007/s12559-023-10184-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of large group decision-making (LGDM), the opinions of individuals can influence each other due to their trust relationships. So, trust relationships should be deemed as just as important as evaluation information, and they should be considered jointly throughout the LGDM. This study first transforms the trust relationships between decision-makers into an information type, labeled as compromise information, whose form is the same as the evaluation information. The compromise information is utilized to incorporate trust relationships into various stages of the decision-making process, including clustering, weight determination, consensus reaching, and alternative selection. In the expert clustering and weight determination processes, more criteria and factors are considered by considering the compromise information. In the consensus reaching process, an optimization model is built to adjust the evaluation information of clusters to simultaneously guarantee a substantial increase in the global consensus level and minimize the adjustment cost. The compromise information also serves as a reference to limit the range of the adjusted information. An objective method to determine the consensus threshold is proposed. The proposed method is validated through an application example and comparisons, demonstrating its rationality and effectiveness. Simulation results indicate that the proposed consensus reaching method converges regardless of the number of experts, alternatives, and criteria. The proposed method integrates evaluation information and trust relationships into the LGDM process, thereby improving the rationality and scientificity of the decision results.},
  archive      = {J_CC},
  author       = {Zhong, Xiangyu and Xu, Xuanhua and Goh, Mark and Pan, Bin},
  doi          = {10.1007/s12559-023-10184-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {86-106},
  shortjournal = {Cogn. Comput.},
  title        = {Large group decision-making method based on social network analysis: Integrating evaluation information and trust relationships},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An event-triggered method for stabilization of stochastic
quaternion-valued memristive neural networks. <em>CC</em>,
<em>16</em>(1), 75–85. (<a
href="https://doi.org/10.1007/s12559-023-10186-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic disturbances are common in real world and usually cause significant influence to engineering system. In this work, the stochastic disturbance is introduced into the quaternion-valued memristive neural networks (QVMNNs). The exponential input-to-state stabilization (EITSS) problem of stochastic QVMNNs is investigated. In order to be more effective and less costly in real applications, an event-triggered control strategy is adopted. The original QVMNNs are separated into four equivalent real-valued NNs by using Hamilton rule. Then, by using the Lyapunov functional approach and stochastic analysis technique, novel sufficient conditions for mean square EITSS of stochastic QVMNNs are derived. Moreover, it is proved that Zeno behavior will not take place in our event-triggered control method. Thus, the mean square EITSS problem of stochastic QVMNNs is solved in this work with less control cost. Lastly, simulation is performed to manifest the correctness of the theorem.},
  archive      = {J_CC},
  author       = {Wei, Ruoyu and Cao, Jinde and Gorbachev, Sergey},
  doi          = {10.1007/s12559-023-10186-9},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {75-85},
  shortjournal = {Cogn. Comput.},
  title        = {An event-triggered method for stabilization of stochastic quaternion-valued memristive neural networks},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpreting black-box models: A review on explainable
artificial intelligence. <em>CC</em>, <em>16</em>(1), 45–74. (<a
href="https://doi.org/10.1007/s12559-023-10179-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as &#39;Black-Box&#39;. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.},
  archive      = {J_CC},
  author       = {Hassija, Vikas and Chamola, Vinay and Mahapatra, Atmesh and Singal, Abhinandan and Goel, Divyansh and Huang, Kaizhu and Scardapane, Simone and Spinelli, Indro and Mahmud, Mufti and Hussain, Amir},
  doi          = {10.1007/s12559-023-10179-8},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {45-74},
  shortjournal = {Cogn. Comput.},
  title        = {Interpreting black-box models: A review on explainable artificial intelligence},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable artificial intelligence in alzheimer’s disease
classification: A systematic review. <em>CC</em>, <em>16</em>(1), 1–44.
(<a href="https://doi.org/10.1007/s12559-023-10192-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unprecedented growth of computational capabilities in recent years has allowed Artificial Intelligence (AI) models to be developed for medical applications with remarkable results. However, a large number of Computer Aided Diagnosis (CAD) methods powered by AI have limited acceptance and adoption in the medical domain due to the typical blackbox nature of these AI models. Therefore, to facilitate the adoption of these AI models among the medical practitioners, the models&#39; predictions must be explainable and interpretable. The emerging field of explainable AI (XAI) aims to justify the trustworthiness of these models&#39; predictions. This work presents a systematic review of the literature reporting Alzheimer&#39;s disease (AD) detection using XAI that were communicated during the last decade. Research questions were carefully formulated to categorise AI models into different conceptual approaches (e.g., Post-hoc, Ante-hoc, Model-Agnostic, Model-Specific, Global, Local etc.) and frameworks (Local Interpretable Model-Agnostic Explanation or LIME, SHapley Additive exPlanations or SHAP, Gradient-weighted Class Activation Mapping or GradCAM, Layer-wise Relevance Propagation or LRP, etc.) of XAI. This categorisation provides broad coverage of the interpretation spectrum from intrinsic (e.g., Model-Specific, Ante-hoc models) to complex patterns (e.g., Model-Agnostic, Post-hoc models) and by taking local explanations to a global scope. Additionally, different forms of interpretations providing in-depth insight into the factors that support the clinical diagnosis of AD are also discussed. Finally, limitations, needs and open challenges of XAI research are outlined with possible prospects of their usage in AD detection.},
  archive      = {J_CC},
  author       = {Viswan, Vimbi and Shaffi, Noushath and Mahmud, Mufti and Subramanian, Karthikeyan and Hajamohideen, Faizal},
  doi          = {10.1007/s12559-023-10192-x},
  journal      = {Cognitive Computation},
  month        = {1},
  number       = {1},
  pages        = {1-44},
  shortjournal = {Cogn. Comput.},
  title        = {Explainable artificial intelligence in alzheimer’s disease classification: A systematic review},
  volume       = {16},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
