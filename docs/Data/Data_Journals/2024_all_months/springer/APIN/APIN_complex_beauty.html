<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>APIN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="apin---666">APIN - 666</h2>
<ul>
<li><details>
<summary>
(2024a). Correction to: LegalATLE: An active transfer learning
framework for legal triple extraction. <em>APIN</em>, <em>54</em>(24),
13179. (<a href="https://doi.org/10.1007/s10489-024-05844-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Zhang, Haiguang and Sun, Yuanyuan and Xu, Bo and Lin, Hongfei},
  doi          = {10.1007/s10489-024-05844-w},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13179},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: LegalATLE: an active transfer learning framework for legal triple extraction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: Tri-channel visualised malicious code
classification based on improved ResNet. <em>APIN</em>, <em>54</em>(24),
13178. (<a href="https://doi.org/10.1007/s10489-024-05843-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Li, Sicong and Wang, Jian and Song, Yafei and Wang, Shuo},
  doi          = {10.1007/s10489-024-05843-x},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13178},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Tri-channel visualised malicious code classification based on improved ResNet},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Voxel-wise segmentation for porosity investigation of
additive manufactured parts with 3D unsupervised and (deeply) supervised
neural networks. <em>APIN</em>, <em>54</em>(24), 13160–13177. (<a
href="https://doi.org/10.1007/s10489-024-05647-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive Manufacturing (AM) has emerged as a manufacturing process that allows the direct production of samples from digital models. To ensure that quality standards are met in all samples of a batch, X-ray computed tomography (X-CT) is often used in combination with automated anomaly detection. For the latter, deep learning (DL) anomaly detection techniques are increasingly used, as they can be trained to be robust to the material being analysed and resilient to poor image quality. Unfortunately, most recent and popular DL models have been developed for 2D image processing, thereby disregarding valuable volumetric information. Additionally, there is a notable absence of comparisons between supervised and unsupervised models for voxel-wise pore segmentation tasks. This study revisits recent supervised (UNet, UNet++, UNet 3+, MSS-UNet, ACC-UNet) and unsupervised (VAE, ceVAE, gmVAE, vqVAE, RV-VAE) DL models for porosity analysis of AM samples from X-CT images and extends them to accept 3D input data with a 3D-patch approach for lower computational requirements, improved efficiency and generalisability. The supervised models were trained using the Focal Tversky loss to address class imbalance that arises from the low porosity in the training datasets. The output of the unsupervised models was post-processed to reduce misclassifications caused by their inability to adequately represent the object surface. The findings were cross-validated in a 5-fold fashion and include: a performance benchmark of the DL models, an evaluation of the post-processing algorithm, an evaluation of the effect of training supervised models with the output of unsupervised models. In a final performance benchmark on a test set with poor image quality, the best performing supervised model was UNet++ with an average precision of 0.751 ± 0.030, while the best unsupervised model was the post-processed ceVAE with 0.830 ± 0.003. Notably, the ceVAE model, with its post-processing technique, exhibited superior capabilities, endorsing unsupervised learning as the preferred approach for the voxel-wise pore segmentation task.},
  archive      = {J_APIN},
  author       = {Iuso, Domenico and Chatterjee, Soumick and Cornelissen, Sven and Verhees, Dries and Beenhouwer, Jan De and Sijbers, Jan},
  doi          = {10.1007/s10489-024-05647-z},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13160-13177},
  shortjournal = {Appl. Intell.},
  title        = {Voxel-wise segmentation for porosity investigation of additive manufactured parts with 3D unsupervised and (deeply) supervised neural networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concertorl: A reinforcement learning approach for
finite-time single-life enhanced control and its application to
direct-drive tandem-wing experiment platforms. <em>APIN</em>,
<em>54</em>(24), 13121–13159. (<a
href="https://doi.org/10.1007/s10489-024-05720-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving control of mechanical systems using finite-time single-life methods presents significant challenges in safety and efficiency for existing control algorithms. To address these issues, the ConcertoRL algorithm is introduced, featuring two main innovations: a time-interleaved mechanism based on Lipschitz conditions that integrates classical controllers with reinforcement learning-based controllers to enhance initial stage safety under single-life conditions and a policy composer based on finite-time Lyapunov convergence conditions that organizes past learning experiences to ensure efficiency within finite time constraints. Experiments are conducted on Direct-Drive Tandem-Wing Experiment Platforms, a typical mechanical system operating under nonlinear unsteady load conditions. First, compared with established algorithms such as the Soft Actor-Critic (SAC) algorithm, Proximal Policy Optimization (PPO) algorithm, and Twin Delayed Deep Deterministic policy gradient (TD3) algorithm, ConcertoRL demonstrates nearly an order of magnitude performance advantage within the first 500 steps under finite-time single-life conditions. Second, ablation experiments on the time-interleaved mechanism show that introducing this module results in a performance improvement of nearly two orders of magnitude in single-life last average reward. Furthermore, the integration of this module yields a substantial performance boost of approximately 60% over scenarios without reinforcement learning enhancements and a 30% increase in efficiency compared to reference controllers operating at doubled control frequencies. These results highlight the algorithm&#39;s ability to create a synergistic effect that exceeds the sum of its parts. Third, ablation studies on the rule-based policy composer further verify its significant impact on enhancing ConcertoRL&#39;s convergence speed. Finally, experiments on the universality of the ConcertoRL framework demonstrate its compatibility with various classical controllers, consistently achieving excellent control outcomes. ConcertoRL offers a promising approach for mechanical systems under nonlinear, unsteady load conditions. It enables plug-and-play use with high control efficiency under finite-time, single-life constraints. This work sets a new benchmark in control effectiveness for challenges posed by direct-drive platforms under tandem wing influence.},
  archive      = {J_APIN},
  author       = {Zhang, Minghao and Song, Bifeng and Chen, Changhao and Lang, Xinyu and Wang, Liang},
  doi          = {10.1007/s10489-024-05720-7},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13121-13159},
  shortjournal = {Appl. Intell.},
  title        = {Concertorl: A reinforcement learning approach for finite-time single-life enhanced control and its application to direct-drive tandem-wing experiment platforms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A typhoon optimization algorithm and difference of CNN
integrated bi-level network for unsupervised underwater image
enhancement. <em>APIN</em>, <em>54</em>(24), 13101–13120. (<a
href="https://doi.org/10.1007/s10489-024-05827-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater image processing presents a greater challenge compared to its land-based counterpart due to inherent issues such as pervasive color distortion, diminished saturation, contrast degradation, and blurred content. Existing methods rooted in general image theory and models of image formation often fall short in delivering satisfactory results, as they typically consider only common factors and make assumptions that do not hold in complex underwater environments. Furthermore, the scarcity of extensive real-world datasets for underwater image enhancement (UIE) covering diverse scenes hinders progress in this field. To address these limitations, we propose an end-to-end unsupervised underwater image enhancement network, TOLPnet. It adopts a bi-level structure, utilizing the Typhoon Optimization (TO) algorithm at the upper level to optimize the super-parameters of the convolutional neural network (CNN) model. The lower level involves a Difference of CNN that employs trainable parameters for image input-output mapping. A novel energy-limited method is proposed for dehazing, and the Laplacian pyramid mechanism decomposes the image into high-frequency and low-frequency components for enhancement. The TO algorithm is leveraged to select enhancement strength and weight coefficients for loss functions. The cascaded CNN acts as a refining network. Experimental results on typical underwater image datasets demonstrate that our proposed method surpasses many state-of-the-art approaches.},
  archive      = {J_APIN},
  author       = {Lin, Feng and Wang, Jian and Pedrycz, Witold and Zhang, Kai and Ablameyko, Sergey},
  doi          = {10.1007/s10489-024-05827-x},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13101-13120},
  shortjournal = {Appl. Intell.},
  title        = {A typhoon optimization algorithm and difference of CNN integrated bi-level network for unsupervised underwater image enhancement},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Making platform recommendations more responsive to the
expectations of different types of consumers: A recommendation method
based on online reviews. <em>APIN</em>, <em>54</em>(24), 13075–13100.
(<a href="https://doi.org/10.1007/s10489-024-05756-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing hotel recommendation systems based on consumer preferences is crucial for online hotel booking platforms. The purpose of this study is to reveal differences in hotel recommendation results for different types of consumers by considering consumer expectations. Specifically, this study introduces an online hotel recommendation method that considers three preferences for five types of consumers (business, couples, families, friends, and solo): attribute importance, consumer expectations, and actual hotel attribute performance. Here, consumer expectations are expressed in the form of the 2-tuple. 2-tuple expectations mean that customers can not only express specific demands but also express the probability of meeting the demands. Further, using three different consumer preferences, a similarity measurement model is constructed to recommend hotels for different types of consumers. This study puts this innovative method to the test using a dataset covering 40 hotels in the Beijing area and analyzes the impact of three preferences for different types of consumers on their hotel recommendation results. The method introduced in this study has two management implications. On the one hand, the recommendation method based on consumer preferences can optimize hotel recommendation systems and help online hotel booking platforms improve the accuracy of recommendation results. On the other hand, the proposed method can offer valuable insights to hotel managers, helping them measure their competitiveness and providing guidance for developing service improvement strategies.},
  archive      = {J_APIN},
  author       = {Meng, Xinyu and Zhao, Meng and Zhang, Chenxi and Zhang, Yimai},
  doi          = {10.1007/s10489-024-05756-9},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13075-13100},
  shortjournal = {Appl. Intell.},
  title        = {Making platform recommendations more responsive to the expectations of different types of consumers: A recommendation method based on online reviews},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MHA-DGCLN: Multi-head attention-driven dynamic graph
convolutional lightweight network for multi-label image classification
of kitchen waste. <em>APIN</em>, <em>54</em>(24), 13057–13074. (<a
href="https://doi.org/10.1007/s10489-024-05819-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kitchen waste images encompass a wide range of garbage categories, posing a typical multi-label classification challenge. However, due to the complex background and significant variations in garbage morphology, there is currently limited research on kitchen waste classification. In this paper, we propose a multi-head attention-driven dynamic graph convolution lightweight network for multi-label classification of kitchen waste images. Firstly, we address the issue of large model parameterization in traditional GCN methods by optimizing the backbone network for lightweight model design. Secondly, to overcome performance losses resulting from reduced model parameters, we introduce a multi-head attention mechanism to mitigate feature information loss, enhancing the feature extraction capability of the backbone network in complex scenarios and improving the correlation between graph nodes. Finally, the dynamic graph convolution module is employed to adaptively capture semantic-aware regions, further boosting recognition capabilities. Experiments conducted on our self-constructed multi-label kitchen waste classification dataset MLKW demonstrate that our proposed algorithm achieves a 8.6% and 4.8% improvement in mAP compared to the benchmark GCN-based methods ML-GCN and ADD-GCN, respectively, establishing state-of-the-art performance. Additionally, extensive experiments on two public datasets, MS-COCO and VOC2007, showcase excellent classification results, highlighting the strong generalization ability of our algorithm.},
  archive      = {J_APIN},
  author       = {Liang, Qiaokang and Li, Jintao and Qin, Hai and Liu, Mingfeng and Xiao, Xiao and Zhang, Dongbo and Wang, Yaonan and Zhang, Dan},
  doi          = {10.1007/s10489-024-05819-x},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13057-13074},
  shortjournal = {Appl. Intell.},
  title        = {MHA-DGCLN: Multi-head attention-driven dynamic graph convolutional lightweight network for multi-label image classification of kitchen waste},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DGTAD: Decomposition GAN-based transformer for anomaly
detection in multivariate time series data. <em>APIN</em>,
<em>54</em>(24), 13038–13056. (<a
href="https://doi.org/10.1007/s10489-024-05693-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of the computer and information industry has led to the emergence of new demands for multivariate time series anomaly detection (MTSAD) models, namely, the necessity for unsupervised anomaly detection that is both efficient and accurate. However, long-term time series data typically encompass a multitude of intricate temporal pattern variations and noise. Consequently, accurately capturing anomalous patterns within such data and establishing precise and rapid anomaly detection models pose challenging problems. In this paper, we propose a decomposition GAN-based transformer for anomaly detection (DGTAD) in multivariate time series data. Specifically, DGTAD integrates a time series decomposition structure into the original transformer model, further decomposing the extracted global features into deep trend information and seasonal information. On this basis, we improve the attention mechanism, which uses decomposed time-dependent features to change the traditional focus of the transformer, enabling the model to reconstruct anomalies of different types in a targeted manner. This makes it difficult for anomalous data to adapt to these changes, thereby amplifying the anomalous features. Finally, by combining the GAN structure and using multiple generators from different perspectives, we alleviate the mode collapse issue, thereby enhancing the model’s generalizability. DGTAD has been validated on nine benchmark datasets, demonstrating significant performance improvements and thus proving its effectiveness in unsupervised anomaly detection.},
  archive      = {J_APIN},
  author       = {Chen, Zixin and Yu, Jiong and Tan, Qiyin and Li, Shu and Du, XuSheng},
  doi          = {10.1007/s10489-024-05693-7},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13038-13056},
  shortjournal = {Appl. Intell.},
  title        = {DGTAD: Decomposition GAN-based transformer for anomaly detection in multivariate time series data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated classification of remote sensing satellite images
using deep learning based vision transformer. <em>APIN</em>,
<em>54</em>(24), 13018–13037. (<a
href="https://doi.org/10.1007/s10489-024-05818-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic classification of remote sensing images using machine learning techniques is challenging due to the complex features of the images. The images are characterized by features such as multi-resolution, heterogeneous appearance and multi-spectral channels. Deep learning methods have achieved promising results in the analysis of remote sensing satellite images in the recent past. However, deep learning methods based on convolutional neural networks (CNN) experience difficulties in the analysis of intrinsic objects from satellite images. These techniques have not achieved optimum performance in the analysis of remote sensing satellite images due to their complex features, such as coarse resolution, cloud masking, varied sizes of embedded objects and appearance. The receptive fields in convolutional operations are not able to establish long-range dependencies and lack global contextual connectivity for effective feature extraction. To address this problem, we propose an improved deep learning-based vision transformer model for the efficient analysis of remote sensing images. The proposed model incorporates a multi-head local self-attention mechanism with patch shifting procedure to provide both local and global context for effective extraction of multi-scale and multi-resolution spatial features of remote sensing images. The proposed model is also enhanced by fine-tuning the hyper-parameters by introducing dropout modules and a decay linear learning rate scheduler. This approach leverages local self-attention for learning and extraction of the complex features in satellite images. Four distinct remote sensing image datasets, namely RSSCN, EuroSat, UC Merced (UCM) and SIRI-WHU, were subjected to experiments and analysis. The results show some improvement in the proposed vision transformer on the CNN-based methods.},
  archive      = {J_APIN},
  author       = {Adegun, Adekanmi and Viriri, Serestina and Tapamo, Jules-Raymond},
  doi          = {10.1007/s10489-024-05818-y},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13018-13037},
  shortjournal = {Appl. Intell.},
  title        = {Automated classification of remote sensing satellite images using deep learning based vision transformer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpretable fracturing optimization of shale oil reservoir
production based on causal inference. <em>APIN</em>, <em>54</em>(24),
13001–13017. (<a
href="https://doi.org/10.1007/s10489-024-05829-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The micro- and nanopore throats in shale oil reservoirs are finer than those in conventional oil reservoirs and have a larger specific surface area, potentially resulting in a more pronounced crude oil boundary effect. The prediction of recoverable reserves in shale oil reservoirs is influenced by factors such as geological complexity, fracture characteristics, and multiphase flow characteristics. The application of conventional reservoir seepage theories and engineering methods is challenging because of the unique characteristics of shale formations. A novel computational framework is proposed for the prediction of recoverable reserves and optimization of fracturing parameters by combining machine learning algorithms with causal discovery. Based on the theory of causal inference, the framework discovers the underlying causal relationships of the data, mines the internal laws of the data, and evaluates the causal effects, aiming to build an interpretable machine learning model to better understand the properties of shale oil reservoirs. Compared to traditional methods, the interpretable machine learning model has an outstanding prediction ability, with R2 of 0.94 and average error as low as 8.57%, which is 5.22% lower than that of traditional methods. Moreover, the maximum prediction error is only 21.84%, which is 25.2% smaller than the maximum error of traditional methods. The prediction robustness is good. An accurate prediction of recoverable reserves can be achieved. Furthermore, by integrating particle swarm optimization and TabNet, a fracturing parameter optimization model for shale oil reservoirs is developed. According to an on-site validation, this optimization results in an average increase of 13.45% in recoverable reserves. This study provides an accurate reference for reserve assessment and production design in the exploration and development of shale oil reservoirs.},
  archive      = {J_APIN},
  author       = {Yang, Huohai and Li, Yi and Min, Chao and Yue, Jie and Li, Fuwei and Li, Renze and Chu, Xiangshu},
  doi          = {10.1007/s10489-024-05829-9},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {13001-13017},
  shortjournal = {Appl. Intell.},
  title        = {Interpretable fracturing optimization of shale oil reservoir production based on causal inference},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long short-term temporal fusion transformer for short-term
forecasting of limit order book in china markets. <em>APIN</em>,
<em>54</em>(24), 12979–13000. (<a
href="https://doi.org/10.1007/s10489-024-05789-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term forecasting of the Limit Order Book (LOB) is challenging due to market noise. Traditionally, technical analysis using candlestick charts has been effective for market analysis and predictions. Inspired by this, we introduce a novel methodology. First, we preprocess the LOB data into long-term frame data resembling candlestick patterns to reduce noise interference. We then present the Long Short-Term Temporal Fusion Transformer (LSTFT), skillfully integrating both short-term and long-term information to capture complex dependencies and enhance prediction accuracy. Additionally, we propose a Temporal Attention Mechanism (TAM) that effectively distinguishes between long-term and short-term temporal relationships in LOB data. Our experimental results demonstrate the effectiveness of our approach in accurately forecasting the Limit Order Book in the short term.},
  archive      = {J_APIN},
  author       = {Wu, Yucheng and Wang, Shuxin and Fu, Xianghua},
  doi          = {10.1007/s10489-024-05789-0},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12979-13000},
  shortjournal = {Appl. Intell.},
  title        = {Long short-term temporal fusion transformer for short-term forecasting of limit order book in china markets},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based causal representation learning for
out-of-distribution recommendation. <em>APIN</em>, <em>54</em>(24),
12964–12978. (<a
href="https://doi.org/10.1007/s10489-024-05835-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution (OOD) recommendations have emerged as a popular field in recommendation systems. Traditional causal OOD recommendation frameworks often overlook shifts in latent user features and the interrelations between different user preferences. To address these issues, this paper proposes an innovative framework called Attention-based Causal OOD Recommendation (ABCOR), which applies the attention mechanism in two distinct ways. For shifts in latent user features, variational attention is employed to analyze shift information and refine the interaction-generation process. Besides, ABCOR integrates a multi-head self-attention layer to infer the complex user preference relationship and enhance recommendation accuracy before calculating post-intervention interaction probabilities. The proposed method has been validated on two public real-world datasets, and the results demonstrate that the proposal significantly outperforms the current state-of-the-art COR methods. Codes are available at https://github.com/YaffaGan/ABCOR .},
  archive      = {J_APIN},
  author       = {Gan, Yuehua and Wang, Qianqian and Huang, Zhejun and Yang, Lili},
  doi          = {10.1007/s10489-024-05835-x},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12964-12978},
  shortjournal = {Appl. Intell.},
  title        = {Attention-based causal representation learning for out-of-distribution recommendation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EU-net: A segmentation network based on semantic fusion and
edge guidance for road crack images. <em>APIN</em>, <em>54</em>(24),
12949–12963. (<a
href="https://doi.org/10.1007/s10489-024-05788-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An enhanced U-shaped network (EU-Net) based on deep semantic information fusion and edge information guidance is studied to improve the segmentation accuracy of road cracks under hazy conditions. The EU-Net comprises multimode feature fusion, side information fusion and edge extraction modules. The feature and side information fusion modules are applied to fuse deep semantic information with multiscale features. The edge extraction module uses the Canny edge detection algorithm to guide and constrain crack edge information from the neural network. The experimental results show that the method in this work is superior to the most widely used crack segmentation methods. Compared with that of the baseline U-Net, the mIoU of the EU-Net increases by 0.59% and 5.7% on the Crack500 and Masonry datasets, respectively.},
  archive      = {J_APIN},
  author       = {Gao, Jing and Gui, Yiting and Ji, Wen and Wen, Jun and Zhou, Yueyu and Huang, Xiaoxiao and Wang, Qiang and Wei, Chenlong and Huang, Zhong and Wang, Chuanlong and Zhu, Zhu},
  doi          = {10.1007/s10489-024-05788-1},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12949-12963},
  shortjournal = {Appl. Intell.},
  title        = {EU-net: A segmentation network based on semantic fusion and edge guidance for road crack images},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SCSformer: Cross-variable transformer framework for
multivariate long-term time series forecasting via statistical
characteristics space. <em>APIN</em>, <em>54</em>(24), 12922–12948. (<a
href="https://doi.org/10.1007/s10489-024-05764-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based models have emerged as promising tools for multivariate long-term time series forecasting. These models are finely structured to perform feature extraction from time series, greatly improving the accuracy of multivariate long-term time series forecasting. However, to the best of our knowledge, few scholars have focused their research on preprocessing time series, such as analyzing their periodic distributions or analyzing their values and volatility at the global level. In fact, properly preprocessing time series can often significantly improve the accuracy of multivariate long-term time series forecasting. In this paper, using the cross-variable transformer as a basis, we introduce a statistical characteristics space fusion module to preprocess the time series, this module takes the mean and standard deviation values of the time series during different periods as part of the model’s inputs and greatly improves the model’s performance. The Statistical Characteristics Space Fusion Module consists of a statistical characteristics space, which represents the mean and standard deviation values of a time series under different periods, and a convolutional neural network, which is used to fuse the original time series with the corresponding mean and standard deviation values. Moreover, to extract the linear dependencies of the time series variables more efficiently, we introduce three different linear projection layers at different nodes of the model, which we call the Multi-level Linear Projection Module. This new methodology, called the SCSformer, includes three innovations. First, we propose a Statistical Characteristics Space Fusion Module, which is capable of calculating the statistical characteristics space of the time series and fusing the original time series with a specific element of the statistical characteristics space as inputs of the model. Second, we introduce a Multi-level Linear Projection Module to capture linear dependencies of time series from different stages of the model. Third, we combine the Statistical Characteristics Space Fusion Module, the Multi-level Linear Projection Module, the Reversible Instance Normalization and the Cross-variable Transformer proposed in Client in a certain order to generate the SCSformer. We test this combination on nine real-world time series datasets and achieve optimal results on eight of them. Our code is publicly available at https://github.com/qiuyueli123/SCSformer .},
  archive      = {J_APIN},
  author       = {Su, Yongfeng and Zhang, Juhui and Li, Qiuyue},
  doi          = {10.1007/s10489-024-05764-9},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12922-12948},
  shortjournal = {Appl. Intell.},
  title        = {SCSformer: Cross-variable transformer framework for multivariate long-term time series forecasting via statistical characteristics space},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Siam2C: Siamese visual segmentation and tracking with
classification-rank loss and classification-aware. <em>APIN</em>,
<em>54</em>(24), 12898–12921. (<a
href="https://doi.org/10.1007/s10489-024-05840-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Siamese visual trackers based on segmentation have garnered considerable attention due to their high accuracy. However, these trackers rely solely on simple classification confidence to distinguish between positive and negative samples (foreground or background), lacking more precise discrimination capabilities for objects. Moreover, the backbone network excels at focusing on local information during feature extraction, failing to capture the long-distance contextual semantics crucial for classification. Consequently, these trackers are highly susceptible to interference during actual tracking, leading to erroneous object segmentation and subsequent tracking failures, thereby compromising robustness. For this purpose, we propose a Siamese visual segmentation and tracking network with classification-rank loss and classification-aware (Siam2C). We design a classification-rank loss (CRL) algorithm to enlarge the margin between positive and negative samples, ensuring that positive samples are ranked higher than negative ones. This optimization enhances the network’s ability to learn from positive and negative samples, allowing the tracker to accurately select the object for segmentation and tracking rather than being misled by interfering targets. Additionally, we design a classification-aware attention module (CAM), which employs spatial and channel self-attention mechanisms to capture long-distance dependencies between different positions in the feature map. The module enhances the feature representation capability of the backbone network, providing richer global contextual semantic information for the tracking network’s classification decisions. Extensive experiments on the VOT2016, VOT2018, VOT2019, OTB100, UAV123, GOT-10k, DAVIS2016, and DAVIS2017 datasets demonstrate the outstanding performance of Siam2C.},
  archive      = {J_APIN},
  author       = {Lei, Bangjun and Ding, Qishuai and Li, Weisheng and Tian, Hao and Zhou, Lifang},
  doi          = {10.1007/s10489-024-05840-0},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12898-12921},
  shortjournal = {Appl. Intell.},
  title        = {Siam2C: Siamese visual segmentation and tracking with classification-rank loss and classification-aware},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive hypersphere data description for few-shot one-class
classification. <em>APIN</em>, <em>54</em>(24), 12885–12897. (<a
href="https://doi.org/10.1007/s10489-024-05836-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot one-class classification (FS-OCC) is an important and challenging problem involving the recognition of a class using a limited number of positive training samples. Data description is essential for solving the FS-OCC problem as it delineates a region that separates positive data from other classes in the feature space. This paper introduces an effective FS-OCC model named Adaptive Hypersphere Data Description (AHDD). AHDD utilizes hypersphere-based data description with a learnable radius to determine the appropriate region for positive samples in the feature space. Both the radius and the feature network are learned concurrently using meta-learning. We propose a loss function for AHDD that enables the mutual adaptation of the radius and feature within a single FS-OCC task. AHDD significantly outperforms other state-of-the-art FS-OCC methods across various benchmarks and demonstrates strong performance on test sets with extreme class imbalance rates. Experimental results indicate that AHDD learns a robust feature representation, and the implementation of an adaptive radius can also improve the existing FS-OCC baselines.},
  archive      = {J_APIN},
  author       = {Ren, Yuchen and Liu, Xiabi and Pan, Liyuan and Niu, Lijuan},
  doi          = {10.1007/s10489-024-05836-w},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12885-12897},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive hypersphere data description for few-shot one-class classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Power allocation method based on modified social network
search algorithm. <em>APIN</em>, <em>54</em>(24), 12851–12884. (<a
href="https://doi.org/10.1007/s10489-024-05804-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of communication devices and demands, the problems of high power consumption, tight spectrum resources, and low energy efficiency in the two-layer heterogeneous network are the popular topics, which need to be solved urgently. For the purpose of solving these problems in a two-layer heterogeneous network consisting of femtocell base stations in randomly distributed a macrocell base station, which can also be called the Macrocell/Femtocell two-layer heterogeneous network, the hierarchical clustering algorithm is firstly used to cluster femtocell base stations in accordance with a distance threshold, the spectrum partitioning mechanism and non-orthogonal multiple access technique are combined to obtain spectrum allocation schemes for different users. Then, the modified social network search algorithm is used to simulate the power allocation problem in the two-layer heterogeneous network with system energy efficiency as the objective function. By comparing with the previous algorithms, the proposed algorithm’s superior performance is verified on the test functions. The results show that the proposed method can effectively improve spectrum utilization and reduce interference. The modified social network search algorithm is more robust and widely applicable regarding energy and computational efficiency.},
  archive      = {J_APIN},
  author       = {Gao, Hongyuan and Li, Huishuang and Lin, Yun and Ma, Jingya},
  doi          = {10.1007/s10489-024-05804-4},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12851-12884},
  shortjournal = {Appl. Intell.},
  title        = {Power allocation method based on modified social network search algorithm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). LegalATLE: An active transfer learning framework for legal
triple extraction. <em>APIN</em>, <em>54</em>(24), 12835–12850. (<a
href="https://doi.org/10.1007/s10489-024-05842-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the rich content of Chinese legal documents has attracted considerable scholarly attention. Legal Relational Triple Extraction which is a critical way to enable machines to understand the semantic information presents a significant challenge in Natural Language Processing, as it seeks to discern the connections between pairs of entities within legal case texts. This challenge is compounded by the intricate nature of legal language and the substantial expense associated with human annotation. Despite these challenges, existing models often overlook the incorporation of cross-domain features. To address this, we introduce LegalATLE, an innovative method for legal Relational Triple Extraction that integrates active learning and transfer learning, reducing the model’s reliance on annotated data and enhancing its performance within the target domain. Our model employs active learning to prudently assess and select samples with high information value. Concurrently, it applies domain adaptation techniques to effectively transfer knowledge from the source domain, thereby improving the model’s generalization and accuracy. Additionally, we have manually annotated a new theft-related triple dataset for use as the target domain. Comprehensive experiments demonstrate that LegalATLE outperforms existing efficient models by approximately 1.5%, reaching 92.90% on the target domain. Notably, with only 4% and 5% of the full dataset used for training, LegalATLE performs about 10% better than other models, demonstrating its effectiveness in data-scarce scenarios.},
  archive      = {J_APIN},
  author       = {Zhang, Haiguang and Sun, Yuanyuan and Xu, Bo and Lin, Hongfei},
  doi          = {10.1007/s10489-024-05842-y},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12835-12850},
  shortjournal = {Appl. Intell.},
  title        = {LegalATLE: An active transfer learning framework for legal triple extraction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic graph attention-guided graph clustering with entropy
minimization self-supervision. <em>APIN</em>, <em>54</em>(24),
12819–12834. (<a
href="https://doi.org/10.1007/s10489-024-05745-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering is one of the most fundamental tasks in graph learning. Recently, numerous graph clustering models based on dual network (Auto-encoder+Graph Neural Network(GNN)) architectures have emerged and achieved promising results. However, we observe several limitations in the literature: 1) simple graph neural networks that fail to capture the intricate relationships between nodes are used for graph clustering tasks; 2) heterogeneous information is inadequately interacted and merged; and 3) the clustering boundaries are fuzzy in the feature space. To address the aforementioned issues, we propose a novel graph clustering model named Dynamic Graph Attention-guided Graph Clustering with Entropy Minimization self-supervision(DGAGC-EM). Specifically, we introduce DGATE, a graph auto-encoder based on dynamic graph attention, to capture the intricate relationships among graph nodes. Additionally, we perform feature enhancement from both global and local perspectives via the proposed Global-Local Feature Enhancement (GLFE) module. Finally, we propose a self-supervised strategy based on entropy minimization theory to guide network training process to achieve better performance and produce sharper clustering boundaries. Extensive experimental results obtained on four datasets demonstrate that our method is highly competitive with the SOTA methods. The figure presents the overall framework of proposed Dynamic Graph Attention-guided Graph Clustering with Entropy Minimization selfsupervision(DGAGC-EM). Specifically, the Dynamic Graph Attetion Auto-Encoder Module is our proposed graph auto-encoder based on dynamic graph attention, to capture the intricate relationships among graph nodes. The Auto-Encoder Module is a basic autoencoder with simple MLPs to extract embeddings from node attributes. Additionally, the proposed Global-Local Feature Enhancement (GLFE) module perform feature enhancement from both global and local perspectives. Finally, the proposed Self-supervised Module guide network training process to achieve better performance and produce sharper clustering boundaries},
  archive      = {J_APIN},
  author       = {Zhu, Ran and Peng, Jian and Huang, Wen and He, Yujun and Tang, Chengyi},
  doi          = {10.1007/s10489-024-05745-y},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12819-12834},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic graph attention-guided graph clustering with entropy minimization self-supervision},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic noise self-recovery ECM clustering algorithm with
adaptive spatial constraints for image segmentation. <em>APIN</em>,
<em>54</em>(24), 12791–12818. (<a
href="https://doi.org/10.1007/s10489-024-05813-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidence c-means(ECM) has certain advantages in dealing with uncertainty and imprecision, and it is widely applied to data clustering and image segmentation. However, ECM does not utilize spatial information and unable to recover noise, resulting in poor performance for noisy image segmentation. To address these problems, we propose a dynamic noise self-recovery ECM clustering algorithm with adaptive spatial constraints for image segmentation. The proposed algorithm has the following novelties. Firstly, the non-local spatial information is modified by initializing the noise probability to obtain more reliable spatial information. Secondly, the adaptive constraint factors are constructed by using the absolute difference between the original image and the modified non-local spatial information, which can reduce the sensitivity of the algorithm to noise. Finally, the self-recovery factors are constructed on the basis of the neighborhood belief degrees. And a dynamic anti-noise distance is proposed to replace the Euclidean distance. The dynamic anti-noise distance is more suitable for noise self-recover, enabling noise self-recovery during the iterative process. Extensive experiments on synthetic, natural, SAR and MR images show that the proposed algorithm has good performance for image segmentation.},
  archive      = {J_APIN},
  author       = {Lan, Rong and Wang, Bo and Yu, Xiaoying and Zhao, Feng and Mi, Haowen and Yu, Haiyan and Zhang, Lu},
  doi          = {10.1007/s10489-024-05813-3},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12791-12818},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic noise self-recovery ECM clustering algorithm with adaptive spatial constraints for image segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-geometric block diagonal representation subspace
clustering with low-rank kernel. <em>APIN</em>, <em>54</em>(24),
12764–12790. (<a
href="https://doi.org/10.1007/s10489-024-05833-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popular block diagonal representation subspace clustering approach shows high effectiveness in dividing a high-dimensional data space into the corresponding subspaces. However, existing subspace clustering algorithms have some weaknesses in achieving high clustering performance. This paper presents a multi-geometric block diagonal representation subspace clustering with low-rank kernel (MBDR-LRK) method that includes two major improvements. First, as visual data often exists on a Riemannian manifold not captured by Euclidean geometry, we harness the multi-order data complementarity to develop a multi-geometric block diagonal representation (MBDR) subspace clustering. Secondly, the proposed MBDR-LRK approach ensures the low-rankness in the mapped space, by adapting the kernel matrix to a pre-defined one rather than relying on a fixed kernel as in traditional methods. The paper also presents details on the monotonic decrease of the objective function and the boundedness and convergence of the affinity matrix, and the experimental results prove the convergence of the proposed method. Based on the MATLAB development environment, the proposed MBDR-LRK algorithm outperforms other related algorithms and obtained an accuracy of 88.70% on the ORL (40 classes), 89.39% on the Extended Yale B (38 classes), 50.22% on the AR (100 classes) and 75.47% on the COIL (50 classes) datasets.},
  archive      = {J_APIN},
  author       = {Liu, Maoshan and Palade , Vasile and Zheng, Zhonglong},
  doi          = {10.1007/s10489-024-05833-z},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12764-12790},
  shortjournal = {Appl. Intell.},
  title        = {Multi-geometric block diagonal representation subspace clustering with low-rank kernel},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SmartRAN: Smart routing attention network for multimodal
sentiment analysis. <em>APIN</em>, <em>54</em>(24), 12742–12763. (<a
href="https://doi.org/10.1007/s10489-024-05839-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis has received widespread attention from the research community in recent years; it aims to use information from different modalities to predict sentiment polarity. However, the model architecture of most existing methods is fixed, and data can only flow along an established path, which leads to poor generalization of the model to different types of data. Furthermore, most methods explore only intra- or intermodal interactions and do not combine the two. In this paper, we propose the Smart Routing Attention Network (SmartRAN). SmartRAN can smartly select the data flow path on the basis of the smart routing attention module, effectively avoiding the disadvantages of poor adaptability and generalizability caused by a fixed model architecture. In addition, SmartRAN includes the learning process of both intra- and intermodal information, which can enhance the semantic consistency of comprehensive information and improve the learning ability of the model for complex relationships. Extensive experiments on two benchmark datasets, CMU-MOSI and CMU-MOSEI, prove that the proposed SmartRAN has superior performance to state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Guo, Xueyu and Tian, Shengwei and Yu, Long and He, Xiaoyu},
  doi          = {10.1007/s10489-024-05839-7},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12742-12763},
  shortjournal = {Appl. Intell.},
  title        = {SmartRAN: Smart routing attention network for multimodal sentiment analysis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel stochastic algorithms for privacy-preserving utility
mining. <em>APIN</em>, <em>54</em>(24), 12725–12741. (<a
href="https://doi.org/10.1007/s10489-024-05826-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-utility itemset mining (HUIM) is a technique for extracting valuable insights from data. When dealing with sensitive information, HUIM can raise privacy concerns. As a result, privacy-preserving utility mining (PPUM) has become an important research direction. PPUM involves transforming quantitative transactional databases into sanitized versions that protect sensitive data while retaining useful patterns. Researchers have previously employed stochastic optimization methods to conceal sensitive patterns in databases through the addition or deletion of transactions. However, these approaches alter the database structure. To address this issue, this paper introduces a novel approach for hiding data with stochastic optimization without changing the database structure. We design a flexible objective function to let users restrict the negative effects of PPUM according to their specific requirements. We also develop a general strategy for establishing constraint matrices. In addition, we present a stochastic algorithm that applies the ant lion optimizer along with a hybrid algorithm, which combines both exact and stochastic optimization methods, to resolve the hiding problem. The results of extensive experiments are presented, demonstrating the efficiency and flexibility of the proposed algorithms.},
  archive      = {J_APIN},
  author       = {Nguyen, Duc and Le, Bac},
  doi          = {10.1007/s10489-024-05826-y},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12725-12741},
  shortjournal = {Appl. Intell.},
  title        = {Novel stochastic algorithms for privacy-preserving utility mining},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A group consensus reaching model balancing individual
satisfaction and group fairness for distributed linguistic preference
relations. <em>APIN</em>, <em>54</em>(24), 12697–12724. (<a
href="https://doi.org/10.1007/s10489-024-05732-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world complex group decision-making problems, preference inconsistency and opinion conflict are common and crucial challenges that need to be tackled. To promote consensus reaching, a novel group consensus reaching model is constructed considering individual satisfaction and group fairness. This study focuses on managing the group consensus reaching process based on flexible and adaptable information, modelled as distributed linguistic preference relations (DLPRs). First, a building process for DLPRs is discussed by integrating cumulative distribution functions converted from single linguistic term sets, hesitant fuzzy linguistic term sets, and comparative linguistic expressions. Furthermore, a two-stage consistency improvement method is proposed, which makes a trade-off between the frequency and magnitude of adjustments. Finally, we establish an improved group consensus model to balance individual satisfaction and group fairness, where individual satisfaction is measured by the deviation between the original and revised preferences and group fairness is measured by the deviation between individual satisfactions. The emergency response plan selection is conducted to show the validity and advantages of the proposed approach.},
  archive      = {J_APIN},
  author       = {Liang, Yingying and Zhang, Tianyu and Tu, Yan and Zhao, Qian},
  doi          = {10.1007/s10489-024-05732-3},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12697-12724},
  shortjournal = {Appl. Intell.},
  title        = {A group consensus reaching model balancing individual satisfaction and group fairness for distributed linguistic preference relations},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMMTSE: Complex road network map matching based on
trajectory structure extraction. <em>APIN</em>, <em>54</em>(24),
12676–12696. (<a
href="https://doi.org/10.1007/s10489-024-05751-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory mapping onto a road network is a complex yet important task. This is because, in the presence of circular sections, Y-shaped intersections, and sections with elevated overlaps with the ground, the conditions of road networks become complicated. Consequently, trajectory mapping becomes challenging owing to the complexities of road networks and the noise generated by high positioning errors. In this study, in response to the difficulty in handling redundant noisy trajectory data in complex road network environments, a complex road network map-matching method based on trajectory structure extraction is proposed. The features of the structure are extracted from the original trajectory data to reduce the effects of redundancy and noise on matching. An adaptive screening candidate method is proposed using driver behavior to estimate the road density and reduce the matching time by selecting effective candidates. A spatiotemporal analysis function is redefined using speed and distance features, and a directional analysis function is proposed for use in combination with directional features to improve the matching accuracy of complex road networks. An experimental evaluation based on real-ground trajectory data collected using in-vehicle sensing devices is conducted to verify the effectiveness of the algorithm. Moreover, extensive experiments are performed on challenging real datasets to evaluate the proposed method, and its accuracy and efficiency are compared with those of two state-of-the-art map-matching algorithms. The experimental results confirm the effectiveness of the proposed algorithm.},
  archive      = {J_APIN},
  author       = {Wang, Xiaohan and Wang, Pei and Wang, Jing and Luo, Yonglong and Chen, Jiaqing and Wu, Junze},
  doi          = {10.1007/s10489-024-05751-0},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12676-12696},
  shortjournal = {Appl. Intell.},
  title        = {CMMTSE: Complex road network map matching based on trajectory structure extraction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework based on physics-informed graph neural ODE: For
continuous spatial-temporal pandemic prediction. <em>APIN</em>,
<em>54</em>(24), 12661–12675. (<a
href="https://doi.org/10.1007/s10489-024-05834-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed spatial-temporal discrete sequence learning networks have great potential in solving partial differential equations and time series prediction compared to traditional fully connected PINN algorithms, and can serve as the foundation for data-driven sequence prediction modeling and inverse problem analysis. However, such existing models are unable to deal with inverse problem scenarios in which the parameters of the physical process are time-varying and unknown, while usually failing to make predictions in continuous time. In this paper, we propose a continuous time series prediction algorithm constructed by the physics-informed graph neural ordinary differential equation (PGNODE). Proposed parameterized GNODE-GRU and physics-informed loss constraints are used to explicitly characterize and solve unknown time-varying hyperparameters. The GNODE solver integrates this physical parameter to predict the sequence value at any time. This paper uses epidemic prediction tasks as a case study, and experimental results demonstrate that the proposed algorithm can effectively improve the prediction accuracy of the spread of epidemics in the future continuous time.},
  archive      = {J_APIN},
  author       = {Cheng, Haodong and Mao, Yingchi and Jia, Xiao},
  doi          = {10.1007/s10489-024-05834-y},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12661-12675},
  shortjournal = {Appl. Intell.},
  title        = {A framework based on physics-informed graph neural ODE: For continuous spatial-temporal pandemic prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic rib segmentation and sequential labeling via
multi-axial slicing and 3D reconstruction. <em>APIN</em>,
<em>54</em>(24), 12644–12660. (<a
href="https://doi.org/10.1007/s10489-024-05785-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiologists often inspect hundreds of two-dimensional computed-tomography (CT) images to accurately locate lesions and make diagnoses, by classifying and labeling the ribs. However, this task is repetitive and time consuming. To effectively address this problem, we propose a multi-axial rib segmentation and sequential labeling (MARSS) method. First, we slice the CT volume into sagittal, frontal, and transverse planes for segmentation. The segmentation masks generated for each plane are then reconstructed into a single 3D segmentation mask using binarization techniques. After separating the left and right rib volumes from the entire CT volume, we cluster the connected components identified as bones and sequentially assign labels to each rib. The segmentation and sequential labeling performance of this method outperformed existing methods by up to 4.2%. The proposed automatic rib sequential labeling method enhances the efficiency of radiologists. In addition, this method provides an extended opportunity for advancements not only in rib segmentation but also in bone-fracture detection and lesion-diagnosis research.},
  archive      = {J_APIN},
  author       = {Kim, Hyunsung and Ko, Seonghyeon and Bum, Junghyun and Le, Duc-Tai and Choo, Hyunseung},
  doi          = {10.1007/s10489-024-05785-4},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12644-12660},
  shortjournal = {Appl. Intell.},
  title        = {Automatic rib segmentation and sequential labeling via multi-axial slicing and 3D reconstruction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FMCF: Few-shot multimodal aspect-based sentiment analysis
framework based on contrastive finetuning. <em>APIN</em>,
<em>54</em>(24), 12629–12643. (<a
href="https://doi.org/10.1007/s10489-024-05841-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal aspect-based sentiment analysis (MABSA) aims to predict the sentiment of aspect by the fusion of different modalities such as image, text and so on. However, the availability of high-quality multimodal data remains limited. Therefore, few-shot MABSA is a new challenge. Previous works are rarely able to cope with low-resource and few-shot scenarios. In order to address the above problems, we design a Few-shot Multimodal aspect-based sentiment analysis framework based on Contrastive Finetuning (FMCF). Initially, the image modality is transformed to the corresponding textual caption to achieve the entailed semantic information and a contrastive dataset is constructed based on similarity retrieval for finetuning in the following stage. Further, a sentence encoder is trained based on SBERT, which combines supervised contrastive learning and sentence-level multi-feature fusion to complete MABSA. The experiments demonstrate that our framework achieves excellent performance in the few-shot scenarios. Importantly, with only 256 training samples and limited computational resources, the proposed method outperforms fine-tuned models that use all available data on the Twitter dataset.},
  archive      = {J_APIN},
  author       = {Du, Yongping and Xie, Runfeng and Zhang, Bochao and Yin, Zihao},
  doi          = {10.1007/s10489-024-05841-z},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12629-12643},
  shortjournal = {Appl. Intell.},
  title        = {FMCF: Few-shot multimodal aspect-based sentiment analysis framework based on contrastive finetuning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable cognitive decline detection in free dialogues
with a machine learning approach based on pre-trained large language
models. <em>APIN</em>, <em>54</em>(24), 12613–12628. (<a
href="https://doi.org/10.1007/s10489-024-05808-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive and neurological impairments are very common, but only a small proportion of affected individuals are diagnosed and treated, partly because of the high costs associated with frequent screening. Detecting pre-illness stages and analyzing the progression of neurological disorders through effective and efficient intelligent systems can be beneficial for timely diagnosis and early intervention. We propose using Large Language Models to extract features from free dialogues to detect cognitive decline. These features comprise high-level reasoning content-independent features (such as comprehension, decreased awareness, increased distraction, and memory problems). Our solution comprises (i) preprocessing, (ii) feature engineering via Natural Language Processing techniques and prompt engineering, (iii) feature analysis and selection to optimize performance, and (iv) classification, supported by automatic explainability. We also explore how to improve Chatgpt’s direct cognitive impairment prediction capabilities using the best features in our models. Evaluation metrics obtained endorse the effectiveness of a mixed approach combining feature extraction with Chatgpt and a specialized Machine Learning model to detect cognitive decline within free-form conversational dialogues with older adults. Ultimately, our work may facilitate the development of an inexpensive, non-invasive, and rapid means of detecting and explaining cognitive decline.},
  archive      = {J_APIN},
  author       = {de Arriba-Pérez, Francisco and García-Méndez, Silvia and Otero-Mosquera, Javier and González-Castaño, Francisco J.},
  doi          = {10.1007/s10489-024-05808-0},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {24},
  pages        = {12613-12628},
  shortjournal = {Appl. Intell.},
  title        = {Explainable cognitive decline detection in free dialogues with a machine learning approach based on pre-trained large language models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label feature selection for missing labels by
granular-ball based mutual information. <em>APIN</em>, <em>54</em>(23),
12589–12612. (<a
href="https://doi.org/10.1007/s10489-024-05809-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection serves an effective dimensionality reduction technique in the high-dimensional multi-label data. However, most feature selection methods regard the label as complete. In fact, in real-world applications, labels in a multi-label dataset may be missing due to various difficulties in collecting sufficient labels, which enables some valuable information to be overlooked and leads to an inaccurate prediction in the classification. To address these issues, a feature selection algorithm based on the granular-ball based mutual information is proposed for the multi-label data with missing labels in this paper. At first, to improve the classification ability, a label recovery model is proposed to calculate some labels, which utilizes the correlation between labels, the properties of label specific features and global common features. Secondly, to avoid computing the neighborhood radius, a granular-ball based mutual information metric for evaluating candidate features is proposed, which well fits the data distribution. Finally, the corresponding feature selection algorithm is developed for selecting a subset from the multi-label data with missing labels. Experiments on the different datasets demonstrate that compared with the state-of-the-art algorithms the proposed algorithm considerably improves the classification accuracy. The code is publicly available online at https://github.com/skylark-leo/MLMLFS.git},
  archive      = {J_APIN},
  author       = {Shu, Wenhao and Hu, Yichen and Qian, Wenbin},
  doi          = {10.1007/s10489-024-05809-z},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12589-12612},
  shortjournal = {Appl. Intell.},
  title        = {Multi-label feature selection for missing labels by granular-ball based mutual information},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptation of time series via contrastive learning
with task-specific consistency. <em>APIN</em>, <em>54</em>(23),
12576–12588. (<a
href="https://doi.org/10.1007/s10489-024-05799-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) for time series analysis remains challenging due to the lack of labeled data in target domains. Existing methods rely heavily on auxiliary data yet often fail to fully exploit the intrinsic task consistency between different domains. To address this limitation, we propose a novel time series UDA framework called CLTC that enhances feature transferability by capturing semantic context and reconstructing class-wise representations. Specifically, contrastive learning is first utilized to capture contextual representations that enable label transfer across domains. Dual reconstruction on samples from the same class then refines the task-specific features to improve consistency. To align the cross-domain distributions without target labels, we leverage Sinkhorn divergence which can handle non-overlapping supports. Consequently, our CLTC reduces the domain gap while retaining task-specific consistency for effective knowledge transfer. Extensive experiments on four time series benchmarks demonstrate state-of-the-art performance improvements of 0.7-3.6% over existing methods, and ablation study validates the efficacy of each component.},
  archive      = {J_APIN},
  author       = {Wu, Tao and Chen, Qiushu and Zhao, Dongfang and Wang, Jinhua and Jiang, Linhua},
  doi          = {10.1007/s10489-024-05799-y},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12576-12588},
  shortjournal = {Appl. Intell.},
  title        = {Domain adaptation of time series via contrastive learning with task-specific consistency},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved KD-tree based imbalanced big data classification
and oversampling for MapReduce platforms. <em>APIN</em>,
<em>54</em>(23), 12558–12575. (<a
href="https://doi.org/10.1007/s10489-024-05763-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, it is necessary to provide novel and efficient platforms for training machine learning models over large volumes of data. The MapReduce approach and its Apache Spark implementation are among the most popular methods that provide high-performance computing for classification algorithms. However, they require dedicated implementations that will take advantage of such architectures. Additionally, many real-world big data problems are plagued by class imbalance, posing challenges to the classifier training step. Existing solutions for alleviating skewed distributions do not work well in the MapReduce environment. In this paper, we propose a novel KD-tree based classifier, together with a variation of the SMOTE algorithm dedicated to the Spark platform. Our algorithms offer excellent predictive power and can work simultaneously with binary and multi-class imbalanced data. Exhaustive experiments conducted using the Amazon Web Service platform showcase the high efficiency and flexibility of our proposed algorithms.},
  archive      = {J_APIN},
  author       = {Sleeman, William C. and Roseberry, Martha and Ghosh, Preetam and Cano, Alberto and Krawczyk, Bartosz},
  doi          = {10.1007/s10489-024-05763-w},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12558-12575},
  shortjournal = {Appl. Intell.},
  title        = {Improved KD-tree based imbalanced big data classification and oversampling for MapReduce platforms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Multi-objective optimization enabling CFRP energy-efficient
milling based on deep reinforcement learning. <em>APIN</em>,
<em>54</em>(23), 12531–12557. (<a
href="https://doi.org/10.1007/s10489-024-05800-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expanding application of Carbon Fiber Reinforced Polymer (CFRP) in industries is drawing increasing attention to energy efficiency improvement and cost reducing during the secondary processing, particularly in milling. Machining parameter optimization is a practical and economical way to achieve this goal. However, the unclear milling mechanism and dynamic machining conditions of CFRP make it challenging. To fill this gap, this paper proposes a DRL-based approach that integrates physics-guided Transformer networks with Twin Delayed Deep Deterministic Policy Gradient (PGTTD3) to optimize CFRP milling parameters with multi-objectives. Firstly, a PG-Transformer-based CFRP milling energy consumption model is proposed, which modifies the existing De-stationary Attention module by integrating external physical variables to enhance modeling accuracy and efficiency. Secondly, a multi-objective optimization model considering energy consumption, milling time and machining cost for CFRP milling is formulated and mapped to a Markov Decision Process, and a reward function is designed. Thirdly, a PGTTD3 approach is proposed for dynamic parameter decision-making, incorporating a time difference strategy to enhance agent training stability and online adjustment reliability. The experimental results show that the proposed method reduces energy consumption, milling time and machining cost by 10.98%, 3.012%, and 14.56% in CFRP milling respectively, compared to the actual averages. The proposed algorithm exhibits excellent performance metrics when compared to state-of-the-art optimization algorithms, with an average improvement in optimization efficiency of over 20% and a maximum enhancement of 88.66%.},
  archive      = {J_APIN},
  author       = {Zhang, Meihang and Zhang, Hua and Yan, Wei and Zhang, Lin and Jiang, Zhigang},
  doi          = {10.1007/s10489-024-05800-8},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12531-12557},
  shortjournal = {Appl. Intell.},
  title        = {Multi-objective optimization enabling CFRP energy-efficient milling based on deep reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DAGCN: Hybrid model for efficiently handling joint node and
link prediction in cloud workflows. <em>APIN</em>, <em>54</em>(23),
12505–12530. (<a
href="https://doi.org/10.1007/s10489-024-05828-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the cloud computing domain, significant strides have been made in performance prediction for cloud workflows, yet link prediction for cloud workflows remains largely unexplored. This paper introduces a novel challenge: joint node and link prediction in cloud workflows, with the aim of increasing the efficiency and overall performance of cloud computing resources. GNN-based methods have gained traction in handling graph-related tasks. The unique format of the DAG presents an underexplored area for GNNs effectiveness. To enhance comprehension of intricate graph structures and interrelationships, this paper introduces two novel models under the DAGCN framework: DAG-ConvGCN and DAG-AttGCN. The former synergizes the local receptive fields of the CNN with the global interpretive power of the GCN, whereas the latter integrates an attention mechanism to dynamically weigh the significance of node adjacencies. Through rigorous experimentation on a meticulously crafted joint node and link prediction task utilizing the Cluster-trace-v2018 dataset, both DAG-ConvGCN and DAG-AttGCN demonstrate superior performance over a spectrum of established machine learning and deep learning benchmarks. Moreover, the application of similarity measures such as the propagation kernel and the innovative GRBF kernel-which merges the graphlet kernel with the radial basis function kernel to accentuate graph topology and node features-reinforces the superiority of DAGCN models over graph-level prediction accuracy conventional baselines. This paper offers a fresh vantage point for advancing predictive methodologies within graph theory.},
  archive      = {J_APIN},
  author       = {Ma, Ruimin and Gao, Junqi and Cheng, Li and Zhang, Yuyi and Petrosian, Ovanes},
  doi          = {10.1007/s10489-024-05828-w},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12505-12530},
  shortjournal = {Appl. Intell.},
  title        = {DAGCN: Hybrid model for efficiently handling joint node and link prediction in cloud workflows},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive multimodal prompt for human-object interaction with
local feature enhanced transformer. <em>APIN</em>, <em>54</em>(23),
12492–12504. (<a
href="https://doi.org/10.1007/s10489-024-05774-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-object interaction (HOI) detection is an important computer vision task for recognizing the interaction between humans and surrounding objects in an image or video. The HOI datasets have a serious long-tailed data distribution problem because it is challenging to have a dataset that contains all potential interactions. Many HOI detectors have addressed this issue by utilizing visual-language models. However, due to the calculation mechanism of the Transformer, the visual-language model is not good at extracting the local features of input samples. Therefore, we propose a novel local feature enhanced Transformer to motivate encoders to extract multi-modal features that contain more information. Moreover, it is worth noting that the application of prompt learning in HOI detection is still in preliminary stages. Consequently, we propose a multi-modal adaptive prompt module, which uses an adaptive learning strategy to facilitate the interaction of language and visual prompts. In the HICO-DET and SWIG-HOI datasets, the proposed model achieves full interaction with 24.21% mAP and 14.29% mAP, respectively. Our code is available at https://github.com/small-code-cat/AMP-HOI .},
  archive      = {J_APIN},
  author       = {Xue, Kejun and Gao, Yongbin and Fang, Zhijun and Jiang, Xiaoyan and Yu, Wenjun and Chen, Mingxuan and Wu, Chenmou},
  doi          = {10.1007/s10489-024-05774-7},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12492-12504},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive multimodal prompt for human-object interaction with local feature enhanced transformer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GaitLRDF: Gait recognition via local relevant feature
representation and discriminative feature learning. <em>APIN</em>,
<em>54</em>(23), 12476–12491. (<a
href="https://doi.org/10.1007/s10489-024-05837-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging biometric recognition technology, gait recognition has the advantages of non-contact long distance and difficult to imitate. Existing gait recognition methods perform gait recognition by using features extracted from the overall appearance or local regions of humans. However, the detailed features extracted by current gait recognition methods based on human local region lose the overall relevance of the image and the edge information of human local region. Secondly, the method based on the local area of the human body does not focus on the local parts of the human body that are less affected by clothing occlusion. To solve the above problems, this paper proposes a new gait recognition network framework GaitLRDF, which improves the accuracy and robustness of gait recognition by Local Relation Convolutional layers (LRConv) and Human Body Focusing module(HBF). LRConv can simultaneously use the global and local information of the human body, and the local detail features extracted in the module can retain the edge information of the human body. HBF can focuse on the gait parts that are less affected by clothing occlusion, and obtain more discriminative gait detail features. The experimental results show that in the three gait environments of NM, BG and CL set by CASIA-B dataset, GaitLRDF is 0.40%, 0.10% and 1.10% higher than the current most advanced method respectively. The recognition accuracy on OU-MVLP dataset reaches 91.40%.},
  archive      = {J_APIN},
  author       = {Pan, Xiaoying and Xie, Hewei and Zhang, Nijuan and Li, Shoukun},
  doi          = {10.1007/s10489-024-05837-9},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12476-12491},
  shortjournal = {Appl. Intell.},
  title        = {GaitLRDF: Gait recognition via local relevant feature representation and discriminative feature learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Tri-channel visualised malicious code classification based
on improved ResNet. <em>APIN</em>, <em>54</em>(23), 12453–12475. (<a
href="https://doi.org/10.1007/s10489-024-05707-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As malicious code attacks continue to evolve, attackers leverage techniques like packing and code obfuscation to generate numerous variants, challenging traditional detection methods. Addressing the limitations of current deep learning-based malicious code classification approaches in feature extraction and accuracy, this paper introduces an innovative RGB visualization detection method based on a hybrid multi-head attention mechanism. Initially, a feature representation method utilizing RGB images is introduced. This approach focuses on semantic relationships between a malware’s binary information, assembly details, and API data, generating images with richer textural information. This technique effectively uncovers the deep dependencies between the original and variant versions of malicious code, providing stronger support for subsequent classification tasks. Furthermore, to tackle the issues of malware encryption and obfuscation, a deep neural network framework is adopted, incorporating a modular design philosophy and integrating a multi-head attention mechanism. This design not only enhances the expressiveness of critical features but also helps the model better focus on key aspects of the malicious code, thereby improving classification accuracy. Through comparative experiments and in-depth analysis, the effectiveness and superiority of the proposed RGB visualization method and MSA-ResNet model in the field of malicious code variant classification are validated. The accuracy rates achieved on the Kaggle and DataCon datasets are 99.49% and 97.70%, respectively, representing significant improvements over other methods. This approach demonstrates strong generalization capabilities and resistance to obfuscation, offering a new and effective tool for malicious code detection.},
  archive      = {J_APIN},
  author       = {Li, Sicong and Wang, Jian and Song, Yafei and Wang, Shuo},
  doi          = {10.1007/s10489-024-05707-4},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12453-12475},
  shortjournal = {Appl. Intell.},
  title        = {Tri-channel visualised malicious code classification based on improved ResNet},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weakly supervised point cloud semantic segmentation based on
scene consistency. <em>APIN</em>, <em>54</em>(23), 12439–12452. (<a
href="https://doi.org/10.1007/s10489-024-05822-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised point cloud segmentation has garnered considerable interest recently, primarily due to its ability to diminish labor-intensive manual labeling costs. The effectiveness of such methods hinges on their ability to augment the supervision signals available for training implicitly. However, we found that most approaches tend to be implemented through complex modeling, which is not conducive to deployment and implementation in resource-poor scenarios. Our study introduces a novel scene consistency modeling approach that significantly enhances weakly supervised point cloud segmentation in this context. By synergistically modeling both complete and incomplete scenes, our method can improve the quality of the supervision signal and save more resources and ease of deployment in practical applications. To achieve this, we first generate the corresponding incomplete scene for the whole scene using windowing techniques. Next, we input the complete and incomplete scenes into a network encoder and obtain prediction results for each scene through two decoders. We enforce semantic consistency between the labeled and unlabeled data in the two scenes by employing cross-entropy and KL loss. This consistent modeling method enables the network to focus more on the same areas in both scenes, capturing local details and effectively increasing the supervision signals. One of the advantages of the proposed method is its simplicity and cost-effectiveness. Because we rely solely on variance and KL loss to model scene consistency, resulting in straightforward computations. Our experimental evaluations on S3DIS, ScanNet, and Semantic3D datasets provide further evidence that our method can effectively leverage sparsely labeled data and abundant unlabeled data to enhance supervision signals and improve the overall model performance.},
  archive      = {J_APIN},
  author       = {Niu, Yingchun and Yin, Jianqin and Qi, Chao and Geng, Liang},
  doi          = {10.1007/s10489-024-05822-2},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12439-12452},
  shortjournal = {Appl. Intell.},
  title        = {Weakly supervised point cloud semantic segmentation based on scene consistency},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HDML: Hybrid data-driven multi-task learning for china’s
stock price forecast. <em>APIN</em>, <em>54</em>(23), 12420–12438. (<a
href="https://doi.org/10.1007/s10489-024-05838-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the rapid development of the China’s stock market, but investment risks have also emerged. Stock price is always unstable and non-linear, affected not only by historical transaction data but also by national policies, news, and other data. Stock price and textual data are beginning to be employed in the prediction process. However, the challenge lies in effectively integrating feature information derived from stock price and textual information. To address the problem, in this paper, this paper proposes a Hybrid Data-driven Multi-task Learning(HDML) framework to predict stock price. HDML adopts hybrid data as model input, mining the transaction and capital flow data information in the stock market and considering the impact of investors’ emotions on the stock market. In addition, we incorporate multi-task learning, which predicts the closing price range of stock based on structured data and then corrects the prediction results through investors’ comment text data. HDML effectively captures the relationship between different modal data through multi-task learning and achieve improvements on both tasks. The experimental results show that compared with previous work, HDML reduces the RMSE of the evaluation set by 12.14% and improves the F1 score by an average of 13.64% at the same time. Moreover, value at risk (VaR), together with the HDML model, can help investors weigh the potential gains against the associated risks.},
  archive      = {J_APIN},
  author       = {Xu, Weiqiang and Liu, Yang and Liu, Wenjie and Li, Huakang and Sun, Guozi},
  doi          = {10.1007/s10489-024-05838-8},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12420-12438},
  shortjournal = {Appl. Intell.},
  title        = {HDML: Hybrid data-driven multi-task learning for china’s stock price forecast},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving routing policies for electric vehicles by means of
genetic programming. <em>APIN</em>, <em>54</em>(23), 12391–12419. (<a
href="https://doi.org/10.1007/s10489-024-05803-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the growing interest in environmental sustainability has led to Electric Vehicle Routing Problems (EVRPs) attracting more and more attention. EVRPs involve the use of electric vehicles, which have additional constraints, such as range and recharging time, compared to conventional Vehicle Routing Problems (VRPs). The complexity and dynamic nature of solving VRPs often lead to the introduction of Routing Policies (RPs), simple heuristics that incrementally build routes. However, manually designing efficient RPs proves to be a challenging and time-consuming task. Therefore, there is a pressing need to explore the application of hyper-heuristics, in particular Genetic Programming (GP), to automatically generate new RPs. Since this method has not yet been investigated in the literature in the context of EVRPs, this study explores the applicability of GP to automatically generate new RPs for EVRP. To this end, three RP variants (serial, semiparallel, and parallel) are introduced in this study, along with a set of domain-specific terminal nodes to optimise three criteria: the number of vehicles, energy consumption, and total tardiness. The experimental analysis shows that the serial variant performs best in terms of energy consumption and number of vehicles, while the parallel variant is most effective in minimising the total tardiness. A comprehensive analysis of the proposed method is conducted to determine its convergence properties and the impact of the proposed terminal nodes on performance and to describe several generated RPs. The results show that the automatically generated RPs perform commendably compared to traditional methods such as metaheuristics and exact methods, which usually require significantly more runtime. More specifically, depending on the scenario in which they are used, the generated RPs achieve results that are about 20%-37% worse compared to the best known results for the number of vehicles in almost negligible time, in just some milliseconds.},
  archive      = {J_APIN},
  author       = {Gil-Gala, Francisco J. and Đurasević, Marko and Jakobović, Domagoj},
  doi          = {10.1007/s10489-024-05803-5},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12391-12419},
  shortjournal = {Appl. Intell.},
  title        = {Evolving routing policies for electric vehicles by means of genetic programming},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Affinity adaptive sparse subspace clustering via constrained
laplacian rank. <em>APIN</em>, <em>54</em>(23), 12378–12390. (<a
href="https://doi.org/10.1007/s10489-024-05812-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering typically clusters data by performing spectral clustering to an affinity matrix constructed in some deterministic ways of self-representation coefficient matrix. Therefore, the quality of the affinity matrix is vital to their performance. However, traditional deterministic ways only provide a feasible affinity matrix but not the most suitable one for showing data structures. Besides, post-processing commonly on the coefficient matrix also affects the affinity matrix’s quality. Furthermore, constructing the affinity matrix is separate from optimizing the coefficient matrix and performing spectral clustering, which can not guarantee the optimal overall result. To this end, we propose a new method, affinity adaptive sparse subspace clustering (AASSC), by adding Laplacian rank constraint into a subspace sparse-representation model to adaptively learn a high-quality affinity matrix having accurate p-connected components from a sparse coefficient matrix without post-processing, where p represents categories. In addition, by relaxing the Laplacian rank constraint into a trace minimization, AASSC naturally combines the operations of the coefficient matrix, affinity matrix, and spectral clustering into a unified optimization, guaranteeing the overall optimal result. Extensive experimental results verify the proposed method to be effective and superior.},
  archive      = {J_APIN},
  author       = {Yang, Ting and Zhou, Shuisheng and Zhang, Zhuan},
  doi          = {10.1007/s10489-024-05812-4},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12378-12390},
  shortjournal = {Appl. Intell.},
  title        = {Affinity adaptive sparse subspace clustering via constrained laplacian rank},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of AHP and fuzzy inference systems for
empowering transformative journeys in organizations: Assessing the
implementation of industry 4.0 in SMEs. <em>APIN</em>, <em>54</em>(23),
12357–12377. (<a
href="https://doi.org/10.1007/s10489-024-05816-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combined use of the Analytical Hierarchy Process (AHP) and Fuzzy Inference Systems (FISs) can significantly enhance the effectiveness of transformative projects in organizations by better managing their complexities and uncertainties. This work develops a novel multicriteria model that integrates both methodologies to assist organizations in these projects. To demonstrate the value of the proposed approach, we present an illustrative example focused on the implementation of Industry 4.0 in SMEs. First, through a review of relevant literature, we identify the key barriers to improving SMEs&#39; capability to implement Industry 4.0 effectively. Subsequently, the AHP, enhanced through Dong and Saaty’s methodology, establishes a consensus-based assessment of the importance of these barriers, using the judgments of five experts. Next, a FIS is utilized, with rule bases automatically derived from the preceding weights, eliminating the need for another round of expert input. This paper shows and discusses how SMEs can use this model to self-assess their adaptability to the Industry 4.0 landscape and formulate improvement strategies to achieve deeper alignment with this transformative paradigm.},
  archive      = {J_APIN},
  author       = {Fernández, Isabel and Puente, Javier and Ponte, Borja and Gómez, Alberto},
  doi          = {10.1007/s10489-024-05816-0},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12357-12377},
  shortjournal = {Appl. Intell.},
  title        = {Integration of AHP and fuzzy inference systems for empowering transformative journeys in organizations: Assessing the implementation of industry 4.0 in SMEs},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal graphs anomaly emergence detection: Benchmarking
for social media interactions. <em>APIN</em>, <em>54</em>(23),
12347–12356. (<a
href="https://doi.org/10.1007/s10489-024-05821-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal graphs have become an essential tool for analyzing complex dynamic systems with multiple agents. Detecting anomalies in temporal graphs is crucial for various applications, including identifying emerging trends, monitoring network security, understanding social dynamics, tracking disease outbreaks, and understanding financial dynamics. In this paper, we present a comprehensive benchmarking study that compares 12 data-driven methods for anomaly detection in temporal graphs. We conduct experiments on two temporal graphs extracted from Twitter and Facebook, aiming to identify anomalies in group interactions. Surprisingly, our study reveals an unclear pattern regarding the best method for such tasks, highlighting the complexity and challenges involved in anomaly emergence detection in large and dynamic systems. The results underscore the need for further research and innovative approaches to effectively detect emerging anomalies in dynamic systems represented as temporal graphs.},
  archive      = {J_APIN},
  author       = {Lazebnik, Teddy and Iny, Or},
  doi          = {10.1007/s10489-024-05821-3},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12347-12356},
  shortjournal = {Appl. Intell.},
  title        = {Temporal graphs anomaly emergence detection: Benchmarking for social media interactions},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view denoising contrastive learning for bundle
recommendation. <em>APIN</em>, <em>54</em>(23), 12332–12346. (<a
href="https://doi.org/10.1007/s10489-024-05825-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of bundle recommendation is to offer users a set of items that match their preferences. Current methods mainly categorize user preferences into bundle and item levels, and then use graph neural networks to obtain representations of users and bundles at both levels. However, real-world interaction data often contains irrelevant and uninformative noise connections, leading to inaccurate representations of user interests and bundle content. In this paper, we introduce a Multi-view Denoising Contrastive Learning approach for Bundle Recommendation (MDCLBR), aiming to reduce the negative effects of noisy data on users’ and bundles’ representations. We use the original view, which includes bundle and item levels, to guide data augmentation for creating augmented views. Then, we apply the multi-view contrastive learning paradigm to enhance collaboration within the original view, the augmented views, and between them. This leads to more accurate representations of users and bundles, reducing the impact of noisy data. Our method outperforms previous approaches in extensive experiments on three real-world public datasets.},
  archive      = {J_APIN},
  author       = {Sang, Lei and Hu, Yang and Zhang, Yi and Zhang, Yiwen},
  doi          = {10.1007/s10489-024-05825-z},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12332-12346},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view denoising contrastive learning for bundle recommendation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive structural enhanced representation learning for
deep document clustering. <em>APIN</em>, <em>54</em>(23), 12315–12331.
(<a href="https://doi.org/10.1007/s10489-024-05791-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural deep document clustering methods, which leverage both structural information and inherent data properties to learn document representations using deep neural networks for clustering, have recently garnered increased research interest. However, the structural information used in these methods is usually static and remains unchanged during the clustering process. This can negatively impact the clustering results if the initial structural information is inaccurate or noisy. In this paper, we present an adaptive structural enhanced representation learning network for document clustering. This network can adjust the structural information with the help of clustering partitions and consists of two components: an adaptive structure learner, which automatically evaluates and adjusts structural information at both the document and term levels to facilitate the learning of more effective structural information, and a structural enhanced representation learning network. The latter incorporates integrates this adjusted structural information to enhance text document representations while reducing noise, thereby improving the clustering results. The iterative process between clustering results and the adaptive structural enhanced representation learning network promotes mutual optimization, progressively enhancing model performance. Extensive experiments on various text document datasets demonstrate that the proposed method outperforms several state-of-the-art methods. The overall framework of adaptive structural enhanced representation learning network},
  archive      = {J_APIN},
  author       = {Xue, Jingjing and Huang, Ruizhang and Bai, Ruina and Chen, Yanping and Qin, Yongbin and Lin, Chuan},
  doi          = {10.1007/s10489-024-05791-6},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12315-12331},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive structural enhanced representation learning for deep document clustering},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel approach for predicting the spread of APT malware in
the network. <em>APIN</em>, <em>54</em>(23), 12293–12314. (<a
href="https://doi.org/10.1007/s10489-024-05750-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced Persistent Threat (APT) attack is one of the most dangerous cyber-attack techniques nowadays. Therefore, the issue of detecting and predicting the spread of APT malware in the network is a very urgent issue to help the process of preventing this attack effectively. In this paper, we propose a new approach that is capable of predicting the spread of APT malware in the network based on the APT&#39;s own behaviors. Accordingly, to predict the spread of APT malicious code in the system, we propose to use a combination of two single Susceptible‐Infected‐Recovered (SIR) models. Specifically, the first SIR model was built to predict the spread of APT malicious code to devices and computers within the organization. These devices and computers are often used by APT malicious code as a basis to escalate privileges to devices or computers containing important and sensitive information of the organization. The second SIR model has the function of predicting the spread of APT malware to a group of computers containing sensitive information or potentially causing high risks to the organization. The two SIR models will provide information about infections between computer groups in the system to help accurately predict the spread of APT malware in the system. The proposal to combine two SIR models in the article is a new proposal based on the behavior of APT malware in practice. By combining two SIR models, the proposal in this article has opened up a new approach for a number of problems predicting the spread in the internet such as malicious code in wireless sensor networks or malicious information on the social network.},
  archive      = {J_APIN},
  author       = {Do, Xuan Cho and Tran, Hai Anh and Nguyen, Thi Lan Phuong},
  doi          = {10.1007/s10489-024-05750-1},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12293-12314},
  shortjournal = {Appl. Intell.},
  title        = {A novel approach for predicting the spread of APT malware in the network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). MDHT-net: Multi-scale deformable u-net with cos-spatial and
channel hybrid transformer for pancreas segmentation. <em>APIN</em>,
<em>54</em>(23), 12272–12292. (<a
href="https://doi.org/10.1007/s10489-024-05780-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate pancreas segmentation is essential for the diagnosis of pancreas disease, while it is still challenging due to the variable structure and small size of the pancreas. In this paper, we propose a Multi-scale Deformable U-Net with Cos-spatial and Channel Hybrid Transformer (MDHT-Net) for pancreas segmentation. To mitigate the ambiguity between the codec stages, the Cos-spatial and Channel Hybrid Transformer (CCHT) module is designed as a novel skip connection, enhancing the network’s ability to perceive spatial information and reveal the inter-channel relationships within different layers’ features. Furthermore, the CCHT efficiently aggregates multi-stage contextual information by improving the self-attention mechanism in two different manners, overcoming the limitation of computational complexity. In addition, to comprehensively understand deep semantic information, the Multi-scale Feature Adaptive-extraction (MFA) module is proposed to dynamically enhance the network’s receptive field by integrating the pancreas characteristics of scale variations. The experimental results present that our proposed MDHT-Net achieves superior performance compared to other existing state-of-the-art methods on two public pancreas datasets, with the mean Dice coefficient of $$91.07\pm 1.19$$ % for NIH and $$91.52\pm 0.66$$ % for MSD, respectively. Given the effectiveness and advantages of our proposed MDHT-Net, it is expected to be a potential tool to assist clinicians in detecting pancreas disease and making reasonable treatment plans.},
  archive      = {J_APIN},
  author       = {Wang, HuiFang and Yang, DaWei and Zhu, Yu and Liu, YaTong and Lin, JiaJun},
  doi          = {10.1007/s10489-024-05780-9},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12272-12292},
  shortjournal = {Appl. Intell.},
  title        = {MDHT-net: Multi-scale deformable U-net with cos-spatial and channel hybrid transformer for pancreas segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An offline-to-online reinforcement learning approach based
on multi-action evaluation with policy extension. <em>APIN</em>,
<em>54</em>(23), 12246–12271. (<a
href="https://doi.org/10.1007/s10489-024-05806-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (Offline RL) is able to learn from pre-collected offline data without real-time interaction with the environment by policy regularization via distributional constraints or support set constraints. However, since the policy learned from offline data under the constrains of support set is usually similar to the behavioral policy due to the overly conservative constraints, offline RL confronts challenges in active behavioral exploration. Moreover, without online interaction, policy evaluation becomes prone to inaccuracy, and the learned policy may lack robustness in the presence of sub-optimal state-action pairs or noise in a dataset. In this paper, we propose an Offline-to-Online Reinforcement Learning Approach based on Multi-action Evaluation with Policy Extension(MAERL) for improving the ability of the policy exploration and the effective value evaluation of state-action in offline RL. In MAERL, we develop four modules: (1) in the policy extension module, we design a policy extension method, which uses the online policy to extend the offline policy; (2) in the multi-action evaluation module, we present an adaptive manner to merge the offline and online policies to generate an action of the agent; (3) in the action-oriented module, we learn the action trajectories of the agent from the dataset, mitigating the issue of actions deviating excessively during environmental exploration; (4) to maintain the consistency in the agent’s actions, we propose an action temporally-aligned representation learning method to maintain the trend of actions of agents. This approach ensures that the agent’s actions align with the learned trajectories, preventing significant deviations during exploration. Extensive experiments are conducted on 15 scenarios of the D4RL/mujoco environment. Results demonstrate that our proposed methods achieve the best performance in 12 scenarios and the second-best performance in 3 scenarios compared to state-of-the-art methods. The project’s code can be found at https://github.com/FrankGod111/Policy-Expansion.git},
  archive      = {J_APIN},
  author       = {Cheng, Xuebo and Huang, Xiaohui and Huang, Zhichao and Jiang, Nan},
  doi          = {10.1007/s10489-024-05806-2},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12246-12271},
  shortjournal = {Appl. Intell.},
  title        = {An offline-to-online reinforcement learning approach based on multi-action evaluation with policy extension},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-modality interaction reasoning for enhancing
vision-language pre-training in image-text retrieval. <em>APIN</em>,
<em>54</em>(23), 12230–12245. (<a
href="https://doi.org/10.1007/s10489-024-05823-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent days have seen significant improvements in multi-modal learning made by Vision-Language Pre-training (VLP) models. However, most of them employ the coarse-grained global alignment to overcome semantic gap for generating common representations, which makes them inadequate to capture intrinsic semantic correlations in image-text retrieval and consequently degrading the accuracy. Moreover, it is expensive to fine-tune a VLP model to perform image-text retrieval due to its large number of parameters. In this paper, we propose a simple yet effective image-text retrieval method, termed Cross-Modality Interaction Reasoning for enhancing Vision-Language Pre-training (CMIR-VLP). Specifically, a Cross Modality Interaction Reasoning (CMIR) module, which is designed to inject fine-grained image-text associations into semantic correlations learning, integrates the patch cues into the word reasoning with a multi-modal interaction encoder. Besides, we propose a cross-interaction process to associate each local text semantics with local visual information for fine-grained image-text alignment. Extensive experiments demonstrate our method gains 52 and 97.5 over state-of-the-art non-pre-training methods on two widely used datasets, and it also outperforms several mainstream fine-tuned VIP models. The related code repository in https://github.com/PSYGIM/CMIR-VLP .},
  archive      = {J_APIN},
  author       = {Yao, Tao and Peng, Shouyong and Wang, Lili and Li, Ying and Sun, Yujuan},
  doi          = {10.1007/s10489-024-05823-1},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12230-12245},
  shortjournal = {Appl. Intell.},
  title        = {Cross-modality interaction reasoning for enhancing vision-language pre-training in image-text retrieval},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GEML: A graph-enhanced pre-trained language model framework
for text classification via mutual learning. <em>APIN</em>,
<em>54</em>(23), 12215–12229. (<a
href="https://doi.org/10.1007/s10489-024-05831-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale Pre-trained Language Models (PLMs) have become the backbones of text classification due to their exceptional performance. However, they treat input documents as independent and uniformly distributed, thereby disregarding potential relationships among the documents. This limitation could lead to some miscalculations and inaccuracies in text classification. To address this issue, some recent work explores the integration of Graph Neural Networks (GNNs) with PLMs, as GNNs can effectively model document relationships. Yet, combining graph-based methods with PLMs is challenging due to the structural incompatibility between graphs and sequences. To tackle this challenge, we propose a graph-enhanced text mutual learning framework that integrates graph-based models with PLMs to boost classification performance. Our approach separates graph-based methods and language models into two independent channels and allows them to approximate each other through mutual learning of probability distributions. This probability-distribution-guided approach simplifies the adaptation of graph-based models to PLMs and enables seamless end-to-end training of the entire architecture. Moreover, we introduce Asymmetrical Learning, a strategy that enhances the learning process, and incorporate Uncertainty Weighting loss to achieve smoother probability distribution learning. These enhancements significantly improve the performance of mutual learning. The practical value of our research lies in its potential applications in various industries, such as social network analysis, information retrieval, and recommendation systems, where understanding and leveraging document relationships are crucial. Importantly, our method can be easily combined with different PLMs and consistently achieves state-of-the-art results on multiple public datasets.},
  archive      = {J_APIN},
  author       = {Yu, Tao and Song, Rui and Pinto, Sandro and Gomes, Tiago and Tavares, Adriano and Xu, Hao},
  doi          = {10.1007/s10489-024-05831-1},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12215-12229},
  shortjournal = {Appl. Intell.},
  title        = {GEML: A graph-enhanced pre-trained language model framework for text classification via mutual learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Improving the transferability of adversarial examples with
path tuning. <em>APIN</em>, <em>54</em>(23), 12194–12214. (<a
href="https://doi.org/10.1007/s10489-024-05820-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks pose a significant threat to real-world applications based on deep neural networks (DNNs), especially in security-critical applications. Research has shown that adversarial examples (AEs) generated on a surrogate model can also succeed on a target model, which is known as transferability. Feature-level transfer-based attacks improve the transferability of AEs by disrupting intermediate features. They target the intermediate layer of the model and use feature importance metrics to find these features. However, current methods overfit feature importance metrics to surrogate models, which results in poor sharing of the importance metrics across models and insufficient destruction of deep features. This work demonstrates the trade-off between feature importance metrics and feature corruption generalization, and categorizes feature destructive causes of misclassification. This work proposes a generative framework named PTNAA to guide the destruction of deep features across models, thus improving the transferability of AEs. Specifically, the method introduces path methods into integrated gradients. It selects path functions using only a priori knowledge and approximates neuron attribution using nonuniform sampling. In addition, it measures neurons based on the attribution results and performs feature-level attacks to remove inherent features of the image. Extensive experiments demonstrate the effectiveness of the proposed method. The code is available at https://github.com/lounwb/PTNAA .},
  archive      = {J_APIN},
  author       = {Li, Tianyu and Li, Xiaoyu and Ke, Wuping and Tian, Xuwei and Zheng, Desheng and Lu, Chao},
  doi          = {10.1007/s10489-024-05820-4},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12194-12214},
  shortjournal = {Appl. Intell.},
  title        = {Improving the transferability of adversarial examples with path tuning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). StreamTrack: Real-time meta-detector for streaming
perception in full-speed domain driving scenarios. <em>APIN</em>,
<em>54</em>(23), 12177–12193. (<a
href="https://doi.org/10.1007/s10489-024-05748-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Streaming perception is a crucial task in the field of autonomous driving, which aims to eliminate the inconsistency between the perception results and the real environment due to the delay. In high-speed driving scenarios, the inconsistency becomes larger. Previous research has ignored the study of streaming perception in high-speed driving scenarios and the robustness of the model to object’s speed. To fill this gap, we first define the full-speed domain streaming perception problem and construct a real-time meta-detector, StreamTrack. Second, to perform motion trend extraction, Swift Multi-Cost Tracker (SMCT) is proposed for fast and accurate data association. Meanwhile, the Direct-Decoupled Prediction Head (DDPH) is introduced for predicting future locations. Furthermore, we introduce the Uniform Motion Prior Loss (UMPL), which ensures stable learning of the model for rapidly moving objects. Compared with the strong baseline, our model improves the SAsAP (Speed-Adaptive steaming Average Precision) by 15.46 %. Extensive experiments show that our approach achieves state-of-the-art performance in the full-speed domain streaming perception task.},
  archive      = {J_APIN},
  author       = {Ge, Weizhen and Wang, Xin and Mao, Zhaoyong and Ren, Jing and Shen, Junge},
  doi          = {10.1007/s10489-024-05748-9},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12177-12193},
  shortjournal = {Appl. Intell.},
  title        = {StreamTrack: Real-time meta-detector for streaming perception in full-speed domain driving scenarios},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving time-delay issues in reinforcement learning via
transformers. <em>APIN</em>, <em>54</em>(23), 12156–12176. (<a
href="https://doi.org/10.1007/s10489-024-05830-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of observation and action delays in remote control scenarios significantly challenges the decision-making of agents that depend on immediate interactions, particularly within traditional deep reinforcement learning (DRL) algorithms. Existing approaches attempt to tackle this problem through various strategies, such as predicting delayed states, transforming delayed Markov Decision Processes (MDPs) into delay-free equivalents. However, both model-free and model-based methods require extensive online data, making them time-consuming and resource-intensive. To effectively handle time-delay challenges and develop a competent and robust RL algorithm, the Augmented Decision Transformer (ADT) is proposed as the first offline RL algorithm designed to enable agents to manage diverse tasks with various constant delays. It transforms a deterministic delayed MDP (DDMDP) into a standard MDP by simulating trajectories in delayed environments using offline dataset from undelayed environments. The Decision Transformer, an autoregressive model, is then employed to train a decision model based on expected rewards, past state sequences and past action sequences. Extensive experiments conducted on MuJoCo and Adroit tasks validate the robustness and efficiency of the ADT, with its average performance across all tasks being 56% better than the worst-performing comparative algorithms. The results demonstrate that the ADT can outperform state-of-the-art RL counterparts, achieving superior performance across various tasks with different delay conditions.},
  archive      = {J_APIN},
  author       = {Xia, Bo and Yang, Zaihui and Xie, Minzhi and Chang, Yongzhe and Yuan, Bo and Li, Zhiheng and Wang, Xueqian and Liang, Bin},
  doi          = {10.1007/s10489-024-05830-2},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12156-12176},
  shortjournal = {Appl. Intell.},
  title        = {Solving time-delay issues in reinforcement learning via transformers},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ERG-AI: Enhancing occupational ergonomics with
uncertainty-aware ML and LLM feedback. <em>APIN</em>, <em>54</em>(23),
12128–12155. (<a
href="https://doi.org/10.1007/s10489-024-05796-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers, especially those involved in jobs requiring extended standing or repetitive movements, often face significant health challenges due to Musculoskeletal Disorders (MSDs). To mitigate MSD risks, enhancing workplace ergonomics is vital, which includes forecasting long-term employee postures, educating workers about related occupational health risks, and offering relevant recommendations. However, research gaps remain, such as the lack of a sustainable AI/ML pipeline that combines sensor-based, uncertainty-aware posture prediction with large language models for natural language communication of occupational health risks and recommendations. We introduce ERG-AI, a machine learning pipeline designed to predict extended worker postures using data from multiple wearable sensors. Alongside providing posture prediction and uncertainty estimates, ERG-AI also provides personalized health risk assessments and recommendations by generating prompts based on its performance and prompting Large Language Model (LLM) APIs, like GPT-4, to obtain user-friendly output. We used the Digital Worker Goldicare dataset to assess ERG-AI, which includes data from 114 home care workers who wore five tri-axial accelerometers in various bodily positions for a cumulative 2913 hours. The evaluation focused on the quality of posture prediction under uncertainty, energy consumption and carbon footprint of ERG-AI and the effectiveness of personalized recommendations rendered in easy-to-understand language.},
  archive      = {J_APIN},
  author       = {Sen, Sagar and Gonzalez, Victor and Husom, Erik Johannes and Tverdal, Simeon and Tokas, Shukun and Tjøsvoll, Svein O},
  doi          = {10.1007/s10489-024-05796-1},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12128-12155},
  shortjournal = {Appl. Intell.},
  title        = {ERG-AI: Enhancing occupational ergonomics with uncertainty-aware ML and LLM feedback},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-transfer learning-based method for multi-fault analysis
and assessment in power system. <em>APIN</em>, <em>54</em>(23),
12112–12127. (<a
href="https://doi.org/10.1007/s10489-024-05772-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the largest and most complex artificial systems in the world, power systems present challenges for statistical analysis under multi-fault contingencies that alter the network topology. This paper proposes a meta-transfer learning-based (MTL) method, where base-learners are designed to learn the power flow mapping relationships for different network topologies, and a meta-learner is developed to guide the updating of structural parameters in base-learners in response to topological changes. The proposed MTL model quickly generates base-learners to adapt to new topologies and enables large-scale statistical analysis of multi-fault contingencies in power systems. The efficacy of the proposed method has been validated using the benchmark Institute of Electrical and Electronics Engineers (IEEE) 39-bus and 300-bus systems, specifically focusing on multi-fault contingencies. The results indicate that the proposed MTL model not only achieves high accuracy in dynamic topologies but also provides adaptive initial parameters for few/zero-shot learning within each topology.},
  archive      = {J_APIN},
  author       = {Zheng, Lingfeng and Zhu, Yuhong and Zhou, Yongzhi},
  doi          = {10.1007/s10489-024-05772-9},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12112-12127},
  shortjournal = {Appl. Intell.},
  title        = {Meta-transfer learning-based method for multi-fault analysis and assessment in power system},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing deep reinforcement learning model decisions with
shapley additive explanations for counter drone operations.
<em>APIN</em>, <em>54</em>(23), 12095–12111. (<a
href="https://doi.org/10.1007/s10489-024-05733-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the use of drones continues to increase, their capabilities pose a threat to airspace safety when they are misused. Deploying AI models for intercepting these unwanted drones becomes crucial. However, these AI models, such as deep learning models, often operate as “black boxes”, making it hard to trust their decision-making system. This also affects end-users’ confidence in these AI systems. In this paper, the explainability of deep reinforcement learning is investigated and a deep reinforcement learning (DRL) method, double deep Q-network with dueling architecture and prioritized experience replay is applied to train the AI models. To make the AI model decisions more transparent and to understand the reasoning behind the AI decisions for counter-drone systems, Shapley Additive Explanations (SHAP) method is implemented. After training the DRL agent, experience replay is visualized, and the absolute SHAP values are calculated to explain the key factors that influence the deep reinforcement learning agent’s choices. The integration of DRL with explainable AI methods such as SHAP demonstrates significant potential for the advancement of robust and efficient counter-drone systems.},
  archive      = {J_APIN},
  author       = {Çetin, Ender and Barrado, Cristina and Salamí, Esther and Pastor, Enric},
  doi          = {10.1007/s10489-024-05733-2},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12095-12111},
  shortjournal = {Appl. Intell.},
  title        = {Analyzing deep reinforcement learning model decisions with shapley additive explanations for counter drone operations},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FSRM-DDIE: Few-shot learning methods based on relation
metrics for the prediction of drug-drug interaction events.
<em>APIN</em>, <em>54</em>(23), 12081–12094. (<a
href="https://doi.org/10.1007/s10489-024-05832-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-drug interaction (DDI) prediction aims to predict and evaluate potential interactions between different drugs, assisting healthcare professionals in optimizing drug therapy, enhancing treatment outcomes, and minimizing adverse effects from drug combinations. Traditional research has extensively focused on whether two drugs interact, but predicting the specific events or effects resulting from these interactions may be more effective in understanding the underlying mechanisms of drug combinations. However, data scarcity in drug research significantly hampers the effectiveness of computational models. To address these challenges, we propose FSRM-DDIE, a novel few-shot drug-drug interaction events (DDIE) prediction model. This metric-based meta-learning framework first learns the features of a DDIE using a feature extractor fusing a graph neural network and an auto-encoder Siamese network. Subsequently, a relation metrics module is proposed to capture similar relations between events for classification. By employing meta-learning, our model could perform effectively even with fewer and rare events. Through the comparative experiments, FSRM-DDIE outperforms state-of-the-art methods, demonstrating its potential for accurately predicting DDIE and providing options for understanding drug-drug interactions despite data limitations. In addition, we discuss limitations of the methodology and possible future research trends.},
  archive      = {J_APIN},
  author       = {Zhang, Lianwei and Niu, Dongjiang and Zhang, Beiyi and Zhang, Qiang and Li, Zhen},
  doi          = {10.1007/s10489-024-05832-0},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12081-12094},
  shortjournal = {Appl. Intell.},
  title        = {FSRM-DDIE: Few-shot learning methods based on relation metrics for the prediction of drug-drug interaction events},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interactive segmentation based on multiscale feature
cascading. <em>APIN</em>, <em>54</em>(23), 12067–12080. (<a
href="https://doi.org/10.1007/s10489-024-05824-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we explore a principal method to enhance image segmentation quality through limited user interaction. We propose a model solution called the multiscale feature cascading network (MFC-Net), which effectively leverages annotated information and enhances segmentation performance in complex scenes. First, we convert the user-provided click information into a disk map, using two different disk radii to capture interaction influences within different ranges. Then, we employ a dual-channel attention module via multiscale feature cascading. Finally, we devise a refinement module to improve the segmentation results. We validated the effectiveness of MFC-Net on four commonly used image segmentation datasets. Extensive experiments show that MFC-Net could better perceive user’s intentions and significantly reduce the burden of user interaction.},
  archive      = {J_APIN},
  author       = {Tang, Jiaying and Ding, Zongyuan and Wang, Hongyuan},
  doi          = {10.1007/s10489-024-05824-0},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12067-12080},
  shortjournal = {Appl. Intell.},
  title        = {Interactive segmentation based on multiscale feature cascading},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel fuzzification-forecasting-optimization ensemble
system for wind speed based on fuzzy theory and a multiobjective
optimizer. <em>APIN</em>, <em>54</em>(23), 12037–12066. (<a
href="https://doi.org/10.1007/s10489-024-05350-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of a new energy generation industry, represented by wind power generation, constitutes a crucial endeavor in attaining the dual carbon goal. Nonetheless, the high-dimensional, nonlinear, and stochastic nature of wind speed sequences imposes substantial demands on power systems&#39; peak regulation capability. To address the limitations of traditional prediction methods, which struggle to provide probabilistic prediction outcomes and exhibit poor generalizability, this paper introduces a fusion of fuzzy theory and advanced artificial intelligence algorithms. The proposed approach, termed the fuzzification-forecasting-optimization ensemble system (FFOES), enables both point and interval predictions of wind speed, thereby complementing the emerging literature on power system dispatch. By leveraging fuzzy set theory and the concept of information granulation, the original sequence is initially divided into manageable particles of smaller scales. Subsequently, the computational efficiency of shallow neural networks and the automatic feature extraction capability of deep learning are harnessed to construct a comprehensive and integrated strategy for wind speed prediction. The numerical results demonstrate that the FFOES achieves a superior balance between prediction accuracy and stability compared to that of 15 benchmark models. Notably, the system&#39;s robust performance across distinct sites and time intervals underscores the significant potential of the FFOES in the realm of wind system risk management.},
  archive      = {J_APIN},
  author       = {Zhao, Yang and Wang, Jianzhou and Niu, Tong and Wang, Ying and Lv, Mengzheng},
  doi          = {10.1007/s10489-024-05350-z},
  journal      = {Applied Intelligence},
  month        = {12},
  number       = {23},
  pages        = {12037-12066},
  shortjournal = {Appl. Intell.},
  title        = {A novel fuzzification-forecasting-optimization ensemble system for wind speed based on fuzzy theory and a multiobjective optimizer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: Pose pattern mining using transformer for
motion classification. <em>APIN</em>, <em>54</em>(22), 12036. (<a
href="https://doi.org/10.1007/s10489-024-05515-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Lee, Seo-El and Yoo, Hyun and Chung, Kyungyong},
  doi          = {10.1007/s10489-024-05515-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {12036},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Pose pattern mining using transformer for motion classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: Mitigating selection bias in counterfactual
prediction through self-supervised domain embedding learning with
virtual samples. <em>APIN</em>, <em>54</em>(22), 12035. (<a
href="https://doi.org/10.1007/s10489-024-05628-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Zhu, Qianyang and Sun, Heyuan and Yang, Bo},
  doi          = {10.1007/s10489-024-05628-2},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {12035},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Mitigating selection bias in counterfactual prediction through self-supervised domain embedding learning with virtual samples},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertainty modified policy for multi-agent reinforcement
learning. <em>APIN</em>, <em>54</em>(22), 12020–12034. (<a
href="https://doi.org/10.1007/s10489-024-05811-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty in the evolution of opponent behavior creates a non-stationary environment for the agent, reducing the reliability of value estimation and strategy selection while compromising security during the exploration process. Previous studies have developed various uncertainty quantification techniques and designed uncertainty-aware exploration methods for multi-agent reinforcement learning (MARL). However, existing methods have gaps in theoretical research and experimental verification of decoupling uncertainty between opponents and environment, which can decrease learning efficiency and lead to an unstable training process. Due to inaccurate opponent modeling, the agent is vulnerable to harm from opponents, which is undesirable in real-world tasks. To address these issues, this study proposes a novel uncertainty-guided safe exploration strategy for MARL that decouples the two types of uncertainty originating from the environment and opponents. Specifically, we introduce an uncertainty decoupling quantification technique based on a novel variance decomposition method for action-value functions. Furthermore, we present an uncertainty-aware policy optimization mechanism to facilitate safe exploration in MARL. Finally, we propose a new adaptive parameter scaling method to ensure efficient exploration by the agents. Theoretical analysis establishes the proposed approach’s convergence rate, and its effectiveness is demonstrated empirically. Extensive experiments on benchmark tasks spanning differential games, multi-agent particle environments, and RoboSumo validate the proposed uncertainty-guided method’s significant advantages in attaining higher scores and facilitating safe agent exploration.},
  archive      = {J_APIN},
  author       = {Zhao, Xinyu and Liu, Jianxiang and Wu, Faguo and Zhang, Xiao and Wang, Guojian},
  doi          = {10.1007/s10489-024-05811-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {12020-12034},
  shortjournal = {Appl. Intell.},
  title        = {Uncertainty modified policy for multi-agent reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RI-PCGrad: Optimizing multi-task learning with rescaling and
impartial projecting conflict gradients. <em>APIN</em>, <em>54</em>(22),
12009–12019. (<a
href="https://doi.org/10.1007/s10489-024-05805-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-task learning model is a learning paradigm that shares features across multiple tasks, and it has achieved great success in fields such as computer vision and natural language processing etc. Multiple tasks often conflict and even compete with each other, which seriously reduces the model performance of multi task learning. Most existing optimization methods alleviate multi task gradient conflicts by adjusting task weights. However, it is also important to consider the magnitude and direction of task gradients during the training process. The magnitude and direction of task gradients reflect the conflict and dominance among tasks, which can disrupt the training process and cause instability. In this paper, we present a rescaling and balancing approach for tackling conflicting and dominating gradients. The approach employs a projecting conflict strategy to mitigate the influence of conflicting gradients from multiple tasks and utilize rescaling and balancing techniques to mitigate gradient dominance during training. The proposed method comprehensively considers the weighting, magnitude, and directions of gradients from tasks. We conduct a series of ablation experiments and comparative experiments on different multi-task networks to validate the effectiveness of the proposed algorithm.},
  archive      = {J_APIN},
  author       = {Meng, Fanyun and Xiao, Zehao and Zhang, Yuanyuan and Wang, Jinlong},
  doi          = {10.1007/s10489-024-05805-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {12009-12019},
  shortjournal = {Appl. Intell.},
  title        = {RI-PCGrad: Optimizing multi-task learning with rescaling and impartial projecting conflict gradients},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ESRNet: An exploring sample relationships network for
arbitrary-shaped scene text detection. <em>APIN</em>, <em>54</em>(22),
11995–12008. (<a
href="https://doi.org/10.1007/s10489-024-05773-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently transformer-based scene text detection methods have been gradually investigated. However, these methods usually use attention to model visual content relationships in single sample, ignoring the relationships between samples. Exploring sample relationships enables feature propagation between samples, which facilitates detector to detect scene text images with more complex features. Aware of the challenges above, this paper proposes exploring sample relationships network (ESRNet) for detecting arbitrary-shaped texts. In detail, we construct the exploring sample relationships module (ESRM) to model sample relationships in the encoder, capturing interactions between all samples in each batch and propagating features across samples. Because of the inconsistency in batch sizes for training and testing leads to differences in exploring sample relationships between these two phases, so two-stream encoder method is used to solve the problem. Moreover, we propose location-aware factorized self-attention (LAFSA), which incorporates the sequential information of text polygon control points into the modeling and effectively improves the accuracy of label reading order in terms of visual features. Experimental results on multiple datasets demonstrate that ESRNet exhibits superior performance compared to other methods. Notably, ESRNet achieves F-measure of 88.9 $$\%$$ , 88.4 $$\%$$ , and 77.4 $$\%$$ on the Total-Text, CTW1500, and ArT datasets, respectively.},
  archive      = {J_APIN},
  author       = {Fan, Huageng and Lu, Tongwei},
  doi          = {10.1007/s10489-024-05773-8},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11995-12008},
  shortjournal = {Appl. Intell.},
  title        = {ESRNet: An exploring sample relationships network for arbitrary-shaped scene text detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SSGCRTN: A space-specific graph convolutional recurrent
transformer network for traffic prediction. <em>APIN</em>,
<em>54</em>(22), 11978–11994. (<a
href="https://doi.org/10.1007/s10489-024-05815-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current research often formalizes traffic prediction tasks as spatio-temporal graph modeling problems. Despite some progress, this approach still has the following limitations. First, space can be divided into intrinsic and latent spaces. Static graphs in intrinsic space lack flexibility when facing changing prediction tasks, while dynamic relationships in latent space are influenced by multiple factors. A deep understanding of specific traffic patterns in different spaces is crucial for accurately modeling spatial dependencies. Second, most studies focus on correlations in sequential time periods, neglecting both reverse and global temporal correlations. This oversight leads to incomplete temporal representations in models. In this work, we propose a Space-Specific Graph Convolutional Recurrent Transformer Network (SSGCRTN) to address these limitations simultaneously. For the spatial aspect, we propose a space-specific graph convolution operation to identify patterns unique to each space. For the temporal aspect, we introduce a spatio-temporal interaction module that integrates spatial and temporal domain knowledge of nodes at multiple granularities. This module learns and utilizes parallel spatio-temporal relationships between different time points from both forward and backward perspectives, revealing latent patterns in spatio-temporal associations. Additionally, we use a transformer-based global temporal fusion module to capture global spatio-temporal correlations. We conduct experiments on four real-world traffic flow datasets (PeMS03/04/07/08) and two traffic speed datasets (PeMSD7(M)/(L)), achieving better performance than existing technologies. Notably, on the PeMS08 dataset, our model improves the MAE by 6.41% compared to DGCRN. The code of SSGCRTN is available at https://github.com/OvOYu/SSGCRTN .},
  archive      = {J_APIN},
  author       = {Yang, Shiyu and Wu, Qunyong and Wang, Yuhang and Lin, Tingyu},
  doi          = {10.1007/s10489-024-05815-1},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11978-11994},
  shortjournal = {Appl. Intell.},
  title        = {SSGCRTN: A space-specific graph convolutional recurrent transformer network for traffic prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Artificial intelligence for the study of human ageing: A
systematic literature review. <em>APIN</em>, <em>54</em>(22),
11949–11977. (<a
href="https://doi.org/10.1007/s10489-024-05817-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As society experiences accelerated ageing, understanding the complex biological processes of human ageing, which are affected by a large number of variables and factors, becomes increasingly crucial. Artificial intelligence (AI) presents a promising avenue for ageing research, offering the ability to detect patterns, make accurate predictions, and extract valuable insights from large volumes of complex, heterogeneous data. As ageing research increasingly leverages AI techniques, we present a timely systematic literature review to explore the current state-of-the-art in this field following a rigorous and transparent review methodology. As a result, a total of 77 articles have been identified, summarised, and categorised based on their characteristics. AI techniques, such as machine learning and deep learning, have been extensively used to analyse diverse datasets, comprising imaging, genetic, behavioural, and contextual data. Findings showcase the potential of AI in predicting age-related outcomes, developing ageing biomarkers, and determining factors associated with healthy ageing. However, challenges related to data quality, interpretability of AI models, and privacy and ethical considerations have also been identified. Despite the advancements, novel approaches suggest that there is still room for improvement to provide personalised AI-driven healthcare services and promote active ageing initiatives with the ultimate goal of enhancing the quality of life and well-being of older adults. Overview of the literature review.},
  archive      = {J_APIN},
  author       = {Bernal, Mary Carlota and Batista, Edgar and Martínez-Ballesté, Antoni and Solanas, Agusti},
  doi          = {10.1007/s10489-024-05817-z},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11949-11977},
  shortjournal = {Appl. Intell.},
  title        = {Artificial intelligence for the study of human ageing: A systematic literature review},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PM2.5 prediction based on dynamic spatiotemporal graph
neural network. <em>APIN</em>, <em>54</em>(22), 11933–11948. (<a
href="https://doi.org/10.1007/s10489-024-05801-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution is one of the main public health and safety issues facing humanity. PM2.5 concentration prediction (PCP) helps the public to prevent and make government decisions in advance. PCP is a typical knowledge mining problem based on spatiotemporal sequential data, which still faces great challenges up to now. Aiming at the complex conundrum of meteorological, geographical, and temporal factors interference and concentration sudden changes, a dynamic spatiotemporal graph neural network (DST_GNN) method for PCP is proposed by using the advantages of graph neural network (GNN) and mechanism model. Its main methods are: The graph structure is used to construct the spatial relationship of PM2.5 among different monitoring stations, the mechanism model HYSPLIT is used to construct the dynamic edge relationship among graph nodes, and the gate recurrent unit of attention mechanism is used to learn the timing of PM2.5 concentration, thus forming a GNN architecture that integrates machine learning and domain knowledge. In addition, a loss function based on trend and shape is proposed when the model objective function is designed. The proposed model innovatively uses HYSPLIT to assist in building a dynamic spatiotemporal graph network and uses trend loss function for model training, which provides a new way for the dynamic construction of GNN, and provides a reference for PCP by combining domain knowledge and deep learning. Experimental results show that the proposed method has the best prediction accuracy among GNN based methods, which reduced the mean absolute error by about 14% and root mean square error by about 13% compared with the advanced GNN methods. The mean absolute error within 48 h forecast is less than 50, which predictive performance is far superior to the traditional mechanism model, and it also has the characteristics of flexible deployment and easy implementation.},
  archive      = {J_APIN},
  author       = {Liao, Haibin and Wu, Mou and Yuan, Li and Hu, Yiyang and Gong, Haowei},
  doi          = {10.1007/s10489-024-05801-7},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11933-11948},
  shortjournal = {Appl. Intell.},
  title        = {PM2.5 prediction based on dynamic spatiotemporal graph neural network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to rank through graph-based feature fusion using
fuzzy integral operators. <em>APIN</em>, <em>54</em>(22), 11914–11932.
(<a href="https://doi.org/10.1007/s10489-024-05755-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately ranking search results based on user query relevance is a complex, multi-dimensional challenge in information retrieval systems, inherently subject to ambiguity and uncertainty. This inherent complexity stems from the ambiguity and uncertainty surrounding relevance judgments. Factors like imprecise user queries, expert disagreements on relevance, and complex relationships between features of documents and queries all contribute to this. Traditional learning-to-rank algorithms often struggle to handle these uncertainties. This paper proposes a novel approach that leverages Sugeno and Choquet fuzzy integrals to model the uncertainty of features and their interactions. This allows our algorithm to make more nuanced ranking decisions. The proposed approach is extensively evaluated on major benchmark datasets like MSLR-Web10K, Istella LETOR, and WCL2R, demonstrating its effectiveness in outperforming baseline methods across standard criteria such as P@n, MAP, and NDCG@n. Notably, the proposed algorithm ranks top results, which are most crucial for user satisfaction. This practical improvement can benefit web search engines by providing users with more relevant information at the top of their search results.},
  archive      = {J_APIN},
  author       = {Keyhanipour, Amir Hosein},
  doi          = {10.1007/s10489-024-05755-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11914-11932},
  shortjournal = {Appl. Intell.},
  title        = {Learning to rank through graph-based feature fusion using fuzzy integral operators},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive weighted stacking model with optimal weights
selection for mortality risk prediction in sepsis patients.
<em>APIN</em>, <em>54</em>(22), 11892–11913. (<a
href="https://doi.org/10.1007/s10489-024-05783-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis patients in the ICU face heightened mortality risks. There still exist challenges that hinder the development of mortality risk prediction models for sepsis patients. In the ensemble model, the differences between base classifier performance can affect the model accuracy and efficiency, and overlapping sample training will lead to repetitive learning, which reduces the model generalization. To tackle these challenges, we propose an Adaptive Weighted Stacking based on Optimal Weights Selection (AWS-OWS) model. A random sampling without replacement is employed to prevent repetitive learning in base classifiers. Additionally, a weighted function and the gradient descent algorithm is adopted to select optimal weights for base classifiers, enhancing the performance of stacking model. The MIMIC-IV dataset is used for model training and internal testing, and the independent samples from MIMIC-III are used for external validation. The results show that AWS-OWS achieves the best AUC of 0.88 in the internal test, with a threefold reduction in computation time compared to standard stacking. In external validation, it also demonstrates good model generalization. AWS-OWS significantly improves the prediction performance and model efficiency, facilitates the identification of high-risk patients with sepsis and supports clinicians in determining appropriate management and treatment strategies.},
  archive      = {J_APIN},
  author       = {Zhou, Liang and Li, Wenjin and Wu, Tao and Fan, Zhiping and Ismaili, Levent and Komolafe, Temitope Emmanuel and Zhang, Siwen},
  doi          = {10.1007/s10489-024-05783-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11892-11913},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive weighted stacking model with optimal weights selection for mortality risk prediction in sepsis patients},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel proportional fusion of a spiking quantum neural
network for optimizing image classification. <em>APIN</em>,
<em>54</em>(22), 11876–11891. (<a
href="https://doi.org/10.1007/s10489-024-05786-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent emergence of the hybrid quantum-classical neural network (HQCNN) architecture has garnered considerable attention because of the potential advantages associated with integrating quantum principles to enhance various facets of machine learning algorithms and computations. However, the current investigated serial structure of HQCNN, wherein information sequentially passes from one network to another, often imposes limitations on the trainability and expressivity of the network. In this study, we introduce a novel architecture termed parallel proportional fusion of spiking and quantum neural networks (PPF-SQNN). The dataset information is simultaneously fed into both the spiking neural network and the variational quantum circuits, with the outputs amalgamated in proportion to their individual contributions. We systematically assess the impact of diverse PPF-SQNN parameters on network performance for image classification, aiming to identify the optimal configuration. On three datasets for image classification tasks, the final classification accuracy reached 98.2%, 99.198%, and 97.921%, respectively, with loss values all below 0.2, outperforming the compared serial networks. In noise testing, it also demonstrates good classification performance even under noise intensities of 0.9 Gaussian and uniform noise. This study introduces a novel and effective amalgamation approach for HQCNN, laying the groundwork for the advancement and application of quantum advantages in artificial intelligence computations.},
  archive      = {J_APIN},
  author       = {Xu, Zuyu and Shen, Kang and Cai, Pengnian and Yang, Tao and Hu, Yuanming and Chen, Shixian and Zhu, Yunlai and Wu, Zuheng and Dai, Yuehua and Wang, Jun and Yang, Fei},
  doi          = {10.1007/s10489-024-05786-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11876-11891},
  shortjournal = {Appl. Intell.},
  title        = {Parallel proportional fusion of a spiking quantum neural network for optimizing image classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on the prediction algorithm of aero engine
lubricating oil consumption based on multi-feature information fusion.
<em>APIN</em>, <em>54</em>(22), 11845–11875. (<a
href="https://doi.org/10.1007/s10489-024-05759-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lubrication system supplies lubrication and cleans the rotating parts and contacting machinery during the operation of an aero-engine. It is crucial to maintain an adequate amount of lubricant by predicting and analyzing the consumption rate to ensure endurance and maintenance programs are effective. This paper examines the combination of temporal and non-temporal data that impact the characteristic parameters of lubricant consumption rate in aero-engines. Our study focuses on the merging of LSTM (Long Short-Term Memory) + LightGBM (Light Gradient Boosting Machine) + CatBoost, and uses KPCA dimensionality reduction optimization, along with Stacking for the fusion of a multi-feature regression prediction algorithm. On the one hand, this study utilizes integrated learning to fuse feature extractions from LSTM for temporal information and non-temporal information by GDBT (Gradient Boosting Decision Tree). This approach considers the trend and distribution of feature samples to develop a more robust feature extraction method. On the other hand, the integrated learning framework incorporates multi-decision making and feature importance extraction to strengthen the mapping relationship with the predicted output of lubrication oil consumption rate, enabling regression prediction. The algorithm for regression prediction has been executed and the results indicate a final regression prediction MAPE (Mean Absolute Percentage Error) of less than 3%. MSE and RMSE reached 1.28% and 1.33%, the results are in an ideal state. The algorithms used in this paper will be applied in the future to aero-engine lubricant systems and eventually to engines in general.},
  archive      = {J_APIN},
  author       = {Zhou, Qifan and Guo, Yingqing and Xu, Kejie and Chai, Bosong and Li, Guicai and Wang, Kun and Dong, Yunhui},
  doi          = {10.1007/s10489-024-05759-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11845-11875},
  shortjournal = {Appl. Intell.},
  title        = {Research on the prediction algorithm of aero engine lubricating oil consumption based on multi-feature information fusion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review of model compression techniques in
machine learning. <em>APIN</em>, <em>54</em>(22), 11804–11844. (<a
href="https://doi.org/10.1007/s10489-024-05747-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper critically examines model compression techniques within the machine learning (ML) domain, emphasizing their role in enhancing model efficiency for deployment in resource-constrained environments, such as mobile devices, edge computing, and Internet of Things (IoT) systems. By systematically exploring compression techniques and lightweight design architectures, it is provided a comprehensive understanding of their operational contexts and effectiveness. The synthesis of these strategies reveals a dynamic interplay between model performance and computational demand, highlighting the balance required for optimal application. As machine learning (ML) models grow increasingly complex and data-intensive, the demand for computational resources and memory has surged accordingly. This escalation presents significant challenges for the deployment of artificial intelligence (AI) systems in real-world applications, particularly where hardware capabilities are limited. Therefore, model compression techniques are not merely advantageous but essential for ensuring that these models can be utilized across various domains, maintaining high performance without prohibitive resource requirements. Furthermore, this review underscores the importance of model compression in sustainable artificial intelligence (AI) development. The introduction of hybrid methods, which combine multiple compression techniques, promises to deliver superior performance and efficiency. Additionally, the development of intelligent frameworks capable of selecting the most appropriate compression strategy based on specific application needs is crucial for advancing the field. The practical examples and engineering applications discussed demonstrate the real-world impact of these techniques. By optimizing the balance between model complexity and computational efficiency, model compression ensures that the advancements in AI technology remain sustainable and widely applicable. This comprehensive review thus contributes to the academic discourse and guides innovative solutions for efficient and responsible machine learning practices, paving the way for future advancements in the field.},
  archive      = {J_APIN},
  author       = {Dantas, Pierre Vilar and Sabino da Silva, Waldir and Cordeiro, Lucas Carvalho and Carvalho, Celso Barbosa},
  doi          = {10.1007/s10489-024-05747-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11804-11844},
  shortjournal = {Appl. Intell.},
  title        = {A comprehensive review of model compression techniques in machine learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel differential evolution algorithm based on periodic
intervention and systematic regulation mechanisms. <em>APIN</em>,
<em>54</em>(22), 11779–11803. (<a
href="https://doi.org/10.1007/s10489-024-05781-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) has attracted widespread attention due to its outstanding optimization performance and ease of operation, but it cannot avoid the dilemmas of premature convergence or stagnation when faced with complex optimization problems. To reduce the probability of such difficulties for DE, we sort out the factors that influence the balance between global exploration and local exploitation in the DE algorithm, and we design a novel DE variant (abbreviated as PISRDE) by integrating the corresponding influence factors through a periodic intervention mechanism and a systematic regulation mechanism. The periodic intervention mechanism divides the optimization operations of PISRDE into routine operation and intervention operation, and it balances global exploration and local exploitation at the macro level by executing the two operations alternately. The systematic regulation mechanism treats the involved optimization strategies and parameter settings as an organic system for targeted design, to balance global exploration and local exploitation at the meso or micro level. To evaluate and verify the optimization performance of PISRDE, we employ seven DE variants with excellent optimization performance to conduct comparison experiments on the IEEE CEC 2014 and IEEE CEC 2017 benchmarks. The comparison results indicate that PISRDE outperforms all competitors overall, and its relative advantage is even more significant when dealing with high-dimensional and complex optimization problems. Schematic design philosophy of PISRDE},
  archive      = {J_APIN},
  author       = {Yuan, Guanyu and Sun, Gaoji and Deng, Libao and Li, Chunlei and Yang, Guoqing},
  doi          = {10.1007/s10489-024-05781-8},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11779-11803},
  shortjournal = {Appl. Intell.},
  title        = {A novel differential evolution algorithm based on periodic intervention and systematic regulation mechanisms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Improving text classification through pre-attention
mechanism-derived lexicons. <em>APIN</em>, <em>54</em>(22), 11765–11778.
(<a href="https://doi.org/10.1007/s10489-024-05742-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive and high-quality lexicon plays a crucial role in traditional text classification approaches. It improves the utilization of linguistic knowledge. Although it is helpful for this task, the lexicon has received little attention in current neural network models. First, obtaining a high-quality lexicon is not easy. Second, an effective automated lexicon extraction method is lacking, and most lexicons are handcrafted, which is very inefficient for big data. Finally, there is no effective way to use a lexicon in a neural network. To address these limitations, we propose a pre-attention mechanism for text classification in this study, which can learn the attention values of various words based on their effects on classification tasks. Words with different attention values can form a domain lexicon. Experiments on three publicly available and authoritative benchmark text classification tasks show that our models obtain competitive results compared with state-of-the-art models. For the same dataset, when we use the pre-attention mechanism to obtain attention values, followed by different neural networks, words with high attention values have a high degree of coincidence, which proves the versatility and portability of the pre-attention mechanism. We can obtain stable lexicons using attention values, which is an inspiring method of information extraction.},
  archive      = {J_APIN},
  author       = {Wang, Zhe and Li, Qingbiao and Wang, Bin and Wu, Tong and Chang, Chengwei},
  doi          = {10.1007/s10489-024-05742-1},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11765-11778},
  shortjournal = {Appl. Intell.},
  title        = {Improving text classification through pre-attention mechanism-derived lexicons},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task-based dialogue policy learning based on diffusion
models. <em>APIN</em>, <em>54</em>(22), 11752–11764. (<a
href="https://doi.org/10.1007/s10489-024-05810-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of task-based dialogue systems is to help users achieve their dialogue needs using as few dialogue rounds as possible. As the demand increases, the dialogue tasks gradually involve multiple domains and develop in the direction of complexity and diversity. Achieving high performance with low computational effort has become an essential metric for multi-domain task-based dialogue systems. This paper proposes a new approach to guided dialogue policy. The method introduces a conditional diffusion model in the reinforcement learning Q-learning algorithm to regularise the policy in a diffusion Q-learning manner. The conditional diffusion model is used to learn the action value function, regulate the actions using regularisation, sample the actions, use the sampled actions in the policy update process, and additionally add a loss term that maximizes the value of the actions in the policy update process to improve the learning efficiency. Our proposed method is based on a conditional diffusion model, combined with the reinforcement learning TD3 algorithm as a dialogue policy and an inverse reinforcement learning approach to construct a reward estimator to provide rewards for policy updates as a way of completing a multi-domain dialogue task.},
  archive      = {J_APIN},
  author       = {Liu, Zhibin and Pang, Rucai and Dong, Zhaoan},
  doi          = {10.1007/s10489-024-05810-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11752-11764},
  shortjournal = {Appl. Intell.},
  title        = {Task-based dialogue policy learning based on diffusion models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive and flexible <span
class="math display"><em>ℓ</em><sub>1</sub></span> -norm graph embedding
for unsupervised feature selection. <em>APIN</em>, <em>54</em>(22),
11732–11751. (<a
href="https://doi.org/10.1007/s10489-024-05760-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection (UFS) is a fundamental and indispensable dimension reduction method for large amount of high-dimensional unlabeled data samples. Without label information, the manifold learning technique is leveraged to compensate for the lack of discrimination with the selected features. However, it is still a challenging problem to capture the geometrical structure for practical data, which are often contaminated by noises and outliers. Additionally, the predetermined graph embedded UFS models suffer from the parameter tuning problem and the separated model optimization procedures. To generate more compact and discriminative feature subsets, we propose a Robust UFS model with Adaptive and Flexible $$\varvec{\ell }_\textbf{1}$$ -norm Graph (RAFG) embedding. Specifically, the $$\varvec{\ell }_\textbf{2,1}$$ -norm is imposed on the flexible regression term to alleviate the adverse effects of both noisy features and outliers, and $$\varvec{\ell }_\textbf{2,p}$$ -norm regularization term is incorporated to ensure that the selected transformation matrix is sufficiently sparse. Moreover, the adaptive $$\varvec{\ell }_\textbf{1}$$ -norm graph learning characterize the clustering distribution via consistent embeddings, which avoids time-consuming distance computations in a high-dimensional feature space. To solve the challenging problem, we propose an efficient alternative updating algorithm with an iterative reweighted strategy, together with the necessary convergence and complexity analyses. Finally, experimental results on two synthetic data and eight benchmark datasets illustrate the effectiveness and superiority of the proposed RAFG method compared with state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Jiang, Kun and Cao, Ting and Zhu, Lei and Sun, Qindong},
  doi          = {10.1007/s10489-024-05760-z},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11732-11751},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive and flexible $$\ell _1$$ -norm graph embedding for unsupervised feature selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel WiFi-based milk freshness detection method using
image features and tensor construction. <em>APIN</em>, <em>54</em>(22),
11709–11731. (<a
href="https://doi.org/10.1007/s10489-024-05797-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of food safety, milk has become an indispensable beverage in people’s lives. Therefore, it is of great significance to detect milk freshness. Starting from the milk freshness detection, the perspective can be extended to liquid detection. Liquid detection has attracted much attention and has been applied in many fields. However, current liquid detection methods are either contact detection methods that can lead to sample damage, or require specialized instruments, expertise for operation or cumbersome hardware deployment. This paper introduces a non-contact milk freshness detection method based on image features and tensor construction. Unlike existing liquid detection methods, our method relies on ubiquitous WiFi signals to achieve non-contact and non-invasive milk freshness detection. The design intuition is that the WiFi signals will lead to different multipath propagation when passing through milk with different freshness, which can be used to detect milk freshness. We use existing commercial devices to collect WiFi signal data of milk with different freshness, denoise the collected data and transform the denoised data into multiple types of time-frequency images and spatial-temporal images, and input the images into the deep learning network to extract image features that contain richer and more comprehensive information, and then utilize the extracted image features to perform tensor construction to better retain the original time, frequency and spatial feature information, and apply 3D convolutional layer and fully connected layers for milk freshness detection. The experimental results show that our method achieves a high accuracy of 93.25% in detecting milk freshness.},
  archive      = {J_APIN},
  author       = {Zhang, Jie and Tang, Lei and He, Lang and Wang, Zhongmin and Chen, Jing},
  doi          = {10.1007/s10489-024-05797-0},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11709-11731},
  shortjournal = {Appl. Intell.},
  title        = {A novel WiFi-based milk freshness detection method using image features and tensor construction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent platform to support trading decisions in the
FOREX market. <em>APIN</em>, <em>54</em>(22), 11690–11708. (<a
href="https://doi.org/10.1007/s10489-024-05770-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trading decisions often encounter risk and uncertainty complexities, significantly influencing their overall performance. Recognizing the intricacies of this challenge, computational models within information systems have become essential to support and augment trading decisions. The paper introduces the concepts of trading software agents, investment strategies, and evaluation functions that automate the selection of the most suitable strategy in near real-time, offering the potential to enhance trading effectiveness. This approach holds the promise of significantly increasing the effectiveness of investments. The research also seeks to discern how changing market conditions influence the performance of these strategies, emphasizing that no single agent or strategy universally outperforms the rest. In summary, the overarching objective of this research is to contribute to the realm of financial decision-making by introducing a pragmatic platform and strategies tailored for traders, investors, and market participants in the FOREX market. Ultimately, this endeavor aims to empower people with more informed and productive trading decisions. The contributions of this work extend beyond the theoretical realm, demonstrating a commitment to address the practical challenges faced by traders and investors in real-time decision-making within the financial markets. This multidimensional approach to financial decision support promises to enhance investment effectiveness and contribute to the broader field of algorithmic trading.},
  archive      = {J_APIN},
  author       = {Hernes, Marcin and Korczak, Jerzy and Krol, Dariusz and Pondel, Maciej and Becker, Jörg},
  doi          = {10.1007/s10489-024-05770-x},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11690-11708},
  shortjournal = {Appl. Intell.},
  title        = {Multi-agent platform to support trading decisions in the FOREX market},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multivariate graph neural networks on enhancing syntactic
and semantic for aspect-based sentiment analysis. <em>APIN</em>,
<em>54</em>(22), 11672–11689. (<a
href="https://doi.org/10.1007/s10489-024-05802-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims to predict sentiment orientations towards textual aspects by extracting insights from user comments. While pretrained large language models (LLMs) demonstrate proficiency in sentiment analysis, incorporating syntactic and semantic features into ABSA remains a challenge. Additionally, employing LLMs for sentiment analysis often requires significant computational resources, rendering them impractical for use by individuals or small-scale entities. To address this, we propose the semiotic signal integration network (SSIN), which effectively combines syntactic and semantic features. The core syncretic information network leverages isomorphism and syntax to enhance knowledge acquisition. The semantically guided syntactic attention module further enables integrated semiotic representations via sophisticated attention mechanisms. Experiments on the publicly available SemEval dataset show that SSIN performs better than existing state-of-the-art ABSA baselines and LLMs such as Llama and Alpaca with high accuracy and macro-F1 scores. Moreover, our model demonstrates exceptional interpretability and the ability to discern both positive and negative sentiments, which is vitally important for real-world applications such as social media monitoring, health care, and customer service. Code is available at https://github.com/AmbitYuki/SSIN .},
  archive      = {J_APIN},
  author       = {Wang, Haoyu and Qiu, Xihe and Tan, Xiaoyu},
  doi          = {10.1007/s10489-024-05802-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11672-11689},
  shortjournal = {Appl. Intell.},
  title        = {Multivariate graph neural networks on enhancing syntactic and semantic for aspect-based sentiment analysis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multifidelity surrogates-assisted multi-objective particle
swarm algorithm for offline data-driven optimization. <em>APIN</em>,
<em>54</em>(22), 11649–11671. (<a
href="https://doi.org/10.1007/s10489-024-05612-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have been widely employed to solve data-driven optimization problems. However, for offline data-driven optimization, it is very challenging to perform evolutionary search efficiently as well as accurately since no new data is available during the optimization process. To mitigate this issue, a multifidelity surrogates-assisted multi-objective particle swarm optimization (MFSa-PSO) algorithm is proposed in this paper. First, two low-fidelity models with convergence and diversity characteristics separately and a high-fidelity model are constructed to assemble multifidelity surrogate models. Second, by adopting the knowledge transfer strategy, the multifidelity surrogates-assisted two-archive multi-objective particle swarm optimization is conducted to search optimal solutions more exactly and effectively. Third, the output solution set is achieved by associating the solutions of two archives with reference vectors. Finally, the proposed MFSa-PSO is compared with some popular surrogate-assisted evolutionary algorithms on benchmark problems to verify its effectiveness and outperformance. Additionally, a real-world application of the municipal solid waste incineration process is carried out to verify the engineering applicability of MFSa-PSO.},
  archive      = {J_APIN},
  author       = {Cui, Yingying and Meng, Xi and Qiao, Junfei},
  doi          = {10.1007/s10489-024-05612-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11649-11671},
  shortjournal = {Appl. Intell.},
  title        = {Multifidelity surrogates-assisted multi-objective particle swarm algorithm for offline data-driven optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A clustering-based archive handling method and
multi-objective optimization of the optimal power flow problem.
<em>APIN</em>, <em>54</em>(22), 11603–11648. (<a
href="https://doi.org/10.1007/s10489-024-05714-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main challenge in finding the optimal Pareto Front (PF) and Pareto Set (PS) sets for multimodal multi-objective optimization problems (MMOPs) with conflicting objective functions is to exhibit a balanced and sustainable diversity and exploitation capability in both the objective and decision spaces. This paper introduces dynamic reference spaces based clustering (DRSC) as a new archive handling method to overcome this challenge. DRSC incorporates a niche method called dynamically  switched reference spaces and adapts the K-means-based method for clustering non-dominant vectors and handling the archive. The performance of the proposed DRSC is tested on twenty-four benchmark problems. According to the results  of non-parametric statistical analysis using data from four different performance metrics, DRSC-MOAGDE designed using the proposed archiving mechanism managed to achieve the best Friedman rank among thirty different competitors. According to the stability analysis results, the average success rates and average computation times of the three best performing algorithms DRSC-MOAGDE, MMODE-ICD and SSMOPSO are (88.69%, 3.01 s), (66.87%, 9.47 s) and (64.29%, 1372.49 s), respectively. It is also observed that the proposed DRSC-MOAGDE outperforms the best cost optimization values in the literature with a minimum of 0.1838 $/h and a maximum of 30.9157 $/h for the multi-objective OPF real-world problem.},
  archive      = {J_APIN},
  author       = {Akbel, Mustafa and Kahraman, Hamdi Tolga and Duman, Serhat and Temel, Seyithan},
  doi          = {10.1007/s10489-024-05714-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11603-11648},
  shortjournal = {Appl. Intell.},
  title        = {A clustering-based archive handling method and multi-objective optimization of the optimal power flow problem},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel dual-level multi-source information fusion approach
for multicriteria decision making applications. <em>APIN</em>,
<em>54</em>(22), 11577–11602. (<a
href="https://doi.org/10.1007/s10489-024-05624-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this paper is to propose a novel dual-level multisource information fusion approach for handling open multicriteria decision-making (MCDM) issues related to accurately determining the weights of criteria while considering the relative importance of expert opinions, handling heterogeneous information, and selecting an appropriate MCDM ranking method. The proposed approach includes two levels. The first integrates the “analytic hierarchy process (AHP)—full consistency method (FUCOM)”, which comprises two phases. In the first phase, criteria weights are assigned using AHP, and FUCOM is employed to correct inconsistencies. In the second phase, the weights are computed for decision-makers. Triangular fuzzy numbers are employed due to their ability to encapsulate all the utilized heterogeneous data types. At the second level of the approach, three well-known distance-based methods, including “technique for order preference by similarity to ideal solution”, “visekriterijumska optimizacija i kompromisno resenje”, and “multiattributive border approximation area comparison”, are fused to process a homogeneous decision matrix and provide comprehensive and robust rankings for alternatives. To develop our novel approach, a renewable energy source for Pakistan&#39;s electricity generation is adopted as a case study. The decision matrix contains four alternatives (i.e., hydropower, biomass energy, solar energy, and wind energy) and six main evaluation criteria (i.e., economic, quality of energy, social, political, environmental, and technical), with several subevaluation criteria under each criterion. The findings of the proposed approach were as follows: A2 was in the first rank with a score of 1.7889, and A4 was in the last rank with a score of 0.1199. The rest of the alternatives were distributed between them. The paper’s implications include the advancement of decision-making methods, enhancement of decision-making outcomes, and addressing heterogeneous information to highlight the relative importance of experts.},
  archive      = {J_APIN},
  author       = {Sharaf, Iman Mohamad and Albahri, O. S. and Alsalem, M. A. and Alamoodi, A. H. and Albahri, A. S.},
  doi          = {10.1007/s10489-024-05624-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11577-11602},
  shortjournal = {Appl. Intell.},
  title        = {A novel dual-level multi-source information fusion approach for multicriteria decision making applications},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open-world knowledge embedding in a low-text resource
environment. <em>APIN</em>, <em>54</em>(22), 11564–11576. (<a
href="https://doi.org/10.1007/s10489-024-05744-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of knowledge embedding (KE) is to represent entities and relations in a knowledge graph (KG) in a continuous low-dimensional vector space, thereby facilitating the integration of the KG into various downstream applications. Existing KE methods can be classified into two categories: closed-world knowledge embedding methods (CWKEs) and open-world knowledge embedding methods (OWKEs). CWKEs necessitate the re-training of the entire model upon the addition of new entities to the KG. In contrast, OWKEs offer greater practical application value as they do not require re-training due to their capacity to generate vector representations for new entities. The current major OWKEs employ the description text of new entities to generate vector representations for new entities. However, these methods are highly dependent on the richness of entity relationships and attribute information present in the text, and they are ineffective when there are only a few textual resources, such as entity names. In reality, most KGs have only a limited number of textual resources. For this reason, we propose the first open-world Knowledge Embedding method (LTKE) in a low textual resource environment. LTKE is designed to efficiently generate vector representations for new entities when KGs have only a few textual resources. By efficiently serializing the local structure of entities, LTKE can obtain information-rich text when an entity has only the entity name. Additionally, we develop a new scoring function to enhance model efficiency. Extensive experiments on real-world KG datasets (Freebase, WordNet) have demonstrated the effectiveness of the model.},
  archive      = {J_APIN},
  author       = {Wang, Liqin and Geng, Zhilei and Wang, Xu and Dong, Yongfeng and Li, Jianxin},
  doi          = {10.1007/s10489-024-05744-z},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11564-11576},
  shortjournal = {Appl. Intell.},
  title        = {Open-world knowledge embedding in a low-text resource environment},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning quadrupedal locomotion on tough terrain using an
asymmetric terrain feature mining network. <em>APIN</em>,
<em>54</em>(22), 11547–11563. (<a
href="https://doi.org/10.1007/s10489-024-05782-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of robust and agile locomotion skills for legged robots using reinforcement learning is challenging, particularly in demanding environments. In this study, we propose a blind locomotion control learning framework that enables fast and stable walking on challenging terrains. First, we construct an asymmetric terrain feature extraction network that uses a multilayer perceptron to effectively infer terrain features from the history of proprioceptive states, consisting only of inertial measurement unit and joint encoder data. Additionally, our asymmetric actor-critic framework implicitly infers terrain features, thereby enhancing the accuracy of terrain representation. Second, we introduce a foot trajectory generator based on prior gait behaviors, which improves the gait periodicity and provides accurate state information for terrain feature inference. Compared to state-of-the-art methods, our approach significantly increases the learning efficiency by 26.0% and enhances terrain adaptation by 5.0%. It also achieved a more periodic gait, with the state-command tracking error reduced by 38.5% compared with advanced methods. The success rate for traversing complex terrains was similar to that of the baseline methods, with a 31.3% increase in the step height on stair-like terrains. The experimental results demonstrate that the proposed method enables fast and stable walking on challenging terrains.},
  archive      = {J_APIN},
  author       = {Zuo, Guoyu and Wang, Yong and Gong, Daoxiong and Yu, Shuangyue},
  doi          = {10.1007/s10489-024-05782-7},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11547-11563},
  shortjournal = {Appl. Intell.},
  title        = {Learning quadrupedal locomotion on tough terrain using an asymmetric terrain feature mining network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced graph convolutional network with property fusion
for acupoint recommendation. <em>APIN</em>, <em>54</em>(22),
11536–11546. (<a
href="https://doi.org/10.1007/s10489-024-05792-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acupuncture therapy, rooted in traditional Chinese medicine (TCM), plays a pivotal role in both disease treatment and preventive health care. A significant challenge within this realm is precise acupoint recommendations tailored to specific symptoms, with consideration of the intricate inherent relationships between the symptoms and acupoints. Traditional recommendation methods encounter another difficulty in grappling with the sparse nature of TCM data. To address these issues, we present a novel approach called the enhanced graph convolutional network with property fusion (PEGCN), which consists of two key components, the property feature graph encoder module and the enhanced graph convolutional network module. The former extracts property knowledge of acupoints to enrich their representations. The latter integrates the GCN structure and an attention mechanism to efficiently capture the underlying relationships between symptoms and acupoints. In this paper, we apply the PEGCN model to a real-world dataset related to acupuncture therapy, and the experimental results demonstrate its superiority over the baseline models in terms of the evaluation metrics, which include Precision@K, Recall@K, and NDCG@K. This finding suggests that our model effectively addresses the challenges associated with acupoint recommendations, offering an improved method for personalized treatments in the TCM context.},
  archive      = {J_APIN},
  author       = {Li, Ruiling and Wu, Song and Tu, Jinyu and Peng, Limei and Ma, Li},
  doi          = {10.1007/s10489-024-05792-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11536-11546},
  shortjournal = {Appl. Intell.},
  title        = {An enhanced graph convolutional network with property fusion for acupoint recommendation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cospeech body motion generation using a transformer.
<em>APIN</em>, <em>54</em>(22), 11525–11535. (<a
href="https://doi.org/10.1007/s10489-024-05769-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Body language is a method for communicating across languages and cultures. Making good use of body motions in speech can enhance persuasiveness, improve personal charisma, and make speech more effective. Generating matching body motions for digital avatars and social robots based on content has become an important topic. In this paper, we propose a transformer-based network model to generate body motions from input speech. Our model includes an audio transformer encoder, motion transformer encoder, template variational autoencoder, cross-modal transformer encoder, and motion decoder. Additionally, we propose a novel evaluation metric for describing motion change trends in terms of distance. The experimental results show that the proposed model provides higher-quality motion generation results than state-of-the-art models. As indicated by visual skeleton motions, our results are more natural and realistic than those of other methods. Additionally, the generated motions yield superior results in terms of multiple evaluation metrics.},
  archive      = {J_APIN},
  author       = {Lu, Zixiang and He, Zhitong and Hong, Jiale and Gao, Ping},
  doi          = {10.1007/s10489-024-05769-4},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11525-11535},
  shortjournal = {Appl. Intell.},
  title        = {Cospeech body motion generation using a transformer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast detection and obstacle avoidance on UAVs using
lightweight convolutional neural network based on the fusion of radar
and camera. <em>APIN</em>, <em>54</em>(22), 11510–11524. (<a
href="https://doi.org/10.1007/s10489-024-05768-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-sensor information fusion (MSIF) technology based on deep convolutional neural networks (CNN) has been widely used in UAV obstacle avoidance. However, detection efficiency needs to be improved in practice because of its high computational complexity and limited airborne hardware resources. A lightweight CNN-based fast detection method based on the fusion of millimeter-wave (MMW) radar and camera is proposed in this paper. In the data preprocessing stage, the input images to the network were preprocessed based on the radar and image data. A rough detection algorithm calculates and segments the saliency image to obtain regions of interest (ROI). The computational complexity of the network training and prediction was reduced by setting the image pixels outside the ROI. In the detection stage based on deep learning, a lightweight network structure based on ResNet18 was designed to fuse the saliency images at different convolution depths. In the post-decoding stage, the calibration points are fused for local non-maximum suppression (NMS). In contrast to typical detection methods, the proposed method improves the detection speed by removing redundant pixels and local NMS, increasing the detection accuracy by fusing the feature information of the radar and camera in multiple stages. The experimental results indicate that compared with the latest lightweight network (YOLOv8n), the detection accuracy is increased by 10.51%, and the FPS increased by 44.43%. Compared with the latest YOLOv8s and YOLOv9m models, the FPS is increased by 3.0X-4.4X. The field programmable gate array (FPGA) implementation achieves a performance of 60.0 FPS. This is an improvement compared with typical methods, demonstrating that the proposed method is more effective than state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Wang, Xiyue and Wang, Xinsheng and Zhou, Zhiquan and Song, Yanhong},
  doi          = {10.1007/s10489-024-05768-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11510-11524},
  shortjournal = {Appl. Intell.},
  title        = {Fast detection and obstacle avoidance on UAVs using lightweight convolutional neural network based on the fusion of radar and camera},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Type-adaptive graph transformer for heterogeneous
information networks. <em>APIN</em>, <em>54</em>(22), 11496–11509. (<a
href="https://doi.org/10.1007/s10489-024-05793-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications use diverse types of nodes and edges to retain rich semantic information. These applications are modeled as heterogeneous graphs. Recent research on heterogeneous graph embedding has made great progress because of the powerful ability of graph neural networks (GNNs) to capture the structural information of graphs. However, the performance of existing heterogeneous graph neural networks (HGNNs) is still unsatisfactory because 1) the aggregation and update functions of GNNs do not exploit the types of nodes and edges, which provide task-relevant information in heterogeneous information networks (HINs), and 2) message-passing-based GNNs are limited by oversmoothing and oversquashing, which prevents the central node from obtaining information from its higher-order neighbors. In this paper, we propose a type-adaptive graph Transformer (Tagformer) that considers not only local structure information and higher-order neighbor information in HINs but also type information to improve performance across various downstream tasks. Specifically, Tagformer assigns each node with the corresponding type feature and uses a GNN and graph Transformer (GT) to extract local structure information and higher-order neighbor information, respectively. Furthermore, to reduce the quadratic complexity and eliminate irrelevant information, we design an intraclass pooling module to condense the large-scale nodes of a graph into a reduced set of pooling nodes. We conduct extensive experiments on four HIN benchmark datasets, demonstrating that Tagformer consistently outperforms state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Tang, Yuxin and Huang, Yanzhe and Hou, Jingyi and Liu, Zhijie},
  doi          = {10.1007/s10489-024-05793-4},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11496-11509},
  shortjournal = {Appl. Intell.},
  title        = {Type-adaptive graph transformer for heterogeneous information networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MeFD-net: Multi-expert fusion diagnostic network for
generating radiology image reports. <em>APIN</em>, <em>54</em>(22),
11484–11495. (<a
href="https://doi.org/10.1007/s10489-024-05680-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the task of radiology image report generation has been highly favored by researchers. Research on this task not only alleviates the tedious work of radiologists but also enhances the healthcare standards in underdeveloped regions. The previous methods primarily followed the image captioning task, using an encoder-decoder architecture to forcibly align the visual and textual domains. However, they overlooked the cross-modal semantic gap between the visual and textual fields. Based on the multi-expert collaborative diagnosis model used in hospitals, we have developed a “multi-expert diagnostic” mechanism to bridge the gap between these modalities. To achieve this, we propose Multi expert Diagnostic Module(MeDM), whose key design involves introducing multiple learnable matrices to replace the expert’s brain for interactive learning between radiology images and their corresponding reports. Specifically, we interact each expert matrix with visual-textual features to capture abundant multimodal information. To ensure that different expert matrices focus on various feature information, they are constrained by an orthogonal loss. Additionally, we have designed a lightweight Diagnostic Fusion Module(DFM) to integrate and summarize the results from multiple expert matrices. The experimental results on two widely used datasets show that the proposed method leads in most metrics.},
  archive      = {J_APIN},
  author       = {Ran, Ruisheng and Pan, Renjie and Yang, Wen and Deng, Yan and Zhang, Wenfeng and Hu, Wei and Qing, Qibing},
  doi          = {10.1007/s10489-024-05680-y},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11484-11495},
  shortjournal = {Appl. Intell.},
  title        = {MeFD-net: Multi-expert fusion diagnostic network for generating radiology image reports},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph network-driven process reasoning for laser
metal additive manufacturing based on relation mining. <em>APIN</em>,
<em>54</em>(22), 11472–11483. (<a
href="https://doi.org/10.1007/s10489-024-05757-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive Manufacturing (AM) technology offers remarkable flexibility in fabricating products with intricate geometries, presenting unprecedented advantages in material efficiency and speed. The process planning of AM plays a pivotal role in ensuring overall quality and time-efficiency of printed products. This drives engineers and researchers to explore various approaches to achieve optimal AM process solutions. However, numerous challenges persist, particularly in logical relationship reasoning and information representation for complex manufacturing tasks and design requirements. In this study, a novel AM process reasoning method based on relation mining is proposed, leveraging knowledge graph representation and graph neural networks (GNN). An AM knowledge graph is constructed comprising essential process information, followed by implementing RED-GNN to accomplish graph reasoning tasks for parameter recommendation. We then focus on the process planning scenario of lattice structures, a common geometry used for designing products with weight-relief requirements and high sensitivity to process parameters. A series of lattice structure parts are designed and tested using our proposed method, demonstrating strong performance and unveiling new potentials and opportunities in advancing knowledge-based engineering and intelligent manufacturing.},
  archive      = {J_APIN},
  author       = {Xiong, Changri and Xiao, Jinhua and Li, Zhuangyu and Zhao, Gang and Xiao, Wenlei},
  doi          = {10.1007/s10489-024-05757-8},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11472-11483},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge graph network-driven process reasoning for laser metal additive manufacturing based on relation mining},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of an adaptive reliability analysis framework
for reinforced concrete frame structures using uncertainty
quantification. <em>APIN</em>, <em>54</em>(22), 11450–11471. (<a
href="https://doi.org/10.1007/s10489-024-05731-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performing reliability analysis for reinforced concrete structures is a tedious and challenging task because it requires conducting a four-nested loop calculation procedure involving millions of data samples to account for the complex behaviours of the structures and multiple random variables. Therefore, the study proposes a novel, practical, and accurate reliability framework that is applicable for multi-component RC frame structures exhibiting different behaviours ranging from linear elastic and non-linear elastic to non-linear plastic. For this purpose, this study first employs a tree-based boosting ensemble model combined with quantile regression, dubbed as QR-LightGBM to calculate the structures’ limit state function and the associated uncertainty estimation at the same time. Next, an active learning process is implemented to improve the computed reliability results progressively. During each active learning step, relevant data samples with potentially high impacts on the model accuracy are determined based on their uncertainty, and then QR-LightGBM is retrained utilizing these samples. By doing so, the prediction performance of the surrogate model is enhanced with a minimized number of actual data samples, thus significantly reducing overall computational resources. The viability and effectiveness of the proposed framework are validated through three case studies involving a simple 1D reinforced concrete beam, a 2D three-story frame, and a 3D five-story building structure. Furthermore, its performance is quantitatively demonstrated via comparison studies with competing methods such as Monte Carlo simulation, Kriging-based models, and an original LightGBM without active learning.},
  archive      = {J_APIN},
  author       = {Nguyen, Truong-Thang and Dang, Viet-Hung and Ha, Manh-Hung and Pham, Thanh-Tung and Phan, Quang-Minh},
  doi          = {10.1007/s10489-024-05731-4},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11450-11471},
  shortjournal = {Appl. Intell.},
  title        = {Development of an adaptive reliability analysis framework for reinforced concrete frame structures using uncertainty quantification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive over-sampling method for imbalanced data based
on simultaneous clustering and filtering noisy. <em>APIN</em>,
<em>54</em>(22), 11430–11449. (<a
href="https://doi.org/10.1007/s10489-024-05754-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data classification problem is a prevalent concern within the realms of machine learning and data mining. However, conventional methods primarily concentrate on between-class imbalance, ignoring noisy, overlap and within-class issues. To address these issues, a new adaptive over-sampling method for imbalanced data based on simultaneous clustering and filtering noisy (ASCFNO) was proposed in this study. First, this method develops a new DPINF (Density Peak Clustering with Improved Noise Filter) clustering algorithm not only to identify minority class sub-clusters with various sizes and densities but also simultaneously filter noisy instances, which can deal with noisy problem and be more beneficial for the subsequent steps to solve between-class and within-class imbalance problems. Second, an adaptive strategy determines the over-sampling size for each minority class sub-cluster, which assigns various weights to each sub-cluster by considering different factors to settle the issues of within-class imbalance. In the end, novel synthetic minority instances are generated between two instances located in the same sub-cluster that are selected according to their probability distribution, which prevents the generation of any noisy or overlapped synthetic instances by the traditional SMOTE method. The performance of the proposed ASCFNO was assessed on 32 benchmark imbalanced datasets. The experiment results prove the effectiveness and feasibility of the above improvements.},
  archive      = {J_APIN},
  author       = {Chen, Wei and Guo, Wenjie and Mao, Weijie},
  doi          = {10.1007/s10489-024-05754-x},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11430-11449},
  shortjournal = {Appl. Intell.},
  title        = {An adaptive over-sampling method for imbalanced data based on simultaneous clustering and filtering noisy},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel multi-view contrastive learning for herb
recommendation. <em>APIN</em>, <em>54</em>(22), 11412–11429. (<a
href="https://doi.org/10.1007/s10489-024-05546-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Herb recommendation plays a crucial role in Traditional Chinese Medicine (TCM) by prescribing therapeutic herbs given symptoms. Current herb recommendation methods make promising progress by utilizing graph neural network, but most fail to capture the underlying distribution of the prescription, particularly the long-tailed distribution, and then suffer from cold-start and data sparsity problems such as emerging epidemics or rare diseases. To effectively alleviate these problems, we first propose a novel multi-view contrastive learning method to improve the prediction performance as contrastive learning can derive self-supervision signals from raw data. For exploiting structural and semantic relationship of symptoms and herbs, we construct the symptom-herb graph from inter-view, and the symptom-symptom interactions and the herb-herb interactions from intra-view. From inter-view, we present a new dual structural contrastive learning that adds and drops data depending on the frequency of the prescription dataset to exploit unbalanced data distribution rather than traditional data augmentation. From intra-view, we propose multi-level semantic contrastive learning depending on the co-occurrence frequencies of symptoms and herbs respectively for utilizing various correlations based on statistical results. Experiments conducted on real-world datasets demonstrate the superiority of the proposed method, which improves performance, and robustness against data sparsity.},
  archive      = {J_APIN},
  author       = {Yang, Qiyuan and Cheng, Zhongtian and Kang, Yan and Wang, Xinchao},
  doi          = {10.1007/s10489-024-05546-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11412-11429},
  shortjournal = {Appl. Intell.},
  title        = {A novel multi-view contrastive learning for herb recommendation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust and adaptive subspace learning for fast hyperspectral
image denoising. <em>APIN</em>, <em>54</em>(22), 11400–11411. (<a
href="https://doi.org/10.1007/s10489-024-05762-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) denoising can be implemented in a low-dimensional spectral subspace to utilize the high correlations across different bands and reduce the imposed computational burden, and subspace learning is a key strategy for achieving improved denoising performance. In the previously developed subspace-based HSI denoising methods, the subspace learning task is usually seriously deteriorated by noise or suffers from high computational costs, and subspace dimensionality determination has not been carefully and specifically studied for subspace denoising. In this paper, we propose a highly efficient HSI denoising method by developing a robust and adaptive subspace learning algorithm. Specifically, we introduce a semisequentially truncated higher-order singular value decomposition scheme for jointly performing basic estimation and learning a robust subspace basis, and the subspace dimensionality is adaptively detected by designing an appropriate information-theoretic criterion. Then we conduct noise reduction by applying a bandwise denoiser in the subspace since various subspace bands generally have significantly different noise levels. The applied bandwise denoiser can be a single-band deep learning method, which do not require hyperspectral training data when the hyperspectral training data are few in number and more difficult to obtain than single-band images. The proposed HSI denoising method is very fast and effective. Experimental results demonstrate that the proposed method can achieve state-of-the-art denoising performance.},
  archive      = {J_APIN},
  author       = {Wu, Yue and Li, Weisheng},
  doi          = {10.1007/s10489-024-05762-x},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11400-11411},
  shortjournal = {Appl. Intell.},
  title        = {Robust and adaptive subspace learning for fast hyperspectral image denoising},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). EDOM-MFIF: An end-to-end decision optimization model for
multi-focus image fusion. <em>APIN</em>, <em>54</em>(22), 11373–11399.
(<a href="https://doi.org/10.1007/s10489-024-05722-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multi-focus image fusion process, generating a focus decision map is typically a requisite step before the actual fusion of images. Many multi-focus image fusion methods often require optimization through post-processing techniques such as hole filling and removal of small regions in the decision map. To solve these problems and obtain better fusion images, we propose a multi-focus image fusion algorithm based on an end-to-end decision optimization model called EDOM-MFIF. Firstly, we design a cross-scale feature extraction encoder based on the joint attention fusion of upper and lower information, which can fully extract the shallow texture information and high-level semantic information of images. Secondly, we design a feature fusion module using convolution and spatial attention for comprehensive feature fusion and maximal retention of global image information. Finally, we achieve end-to-end training and optimization of the focusing decision map by integrating the decision map’s optimization into the whole image fusion architecture. This prevents evident pixel faults in the immediate area from spreading to other areas during post-processing, which could lead to inaccurate classification findings, in addition to maintaining pixel consistency with the original image to the greatest extent possible. To facilitate training of the multi-focus image fusion model, we construct a large-scale multi-focus image dataset with a supervised decision map and test the algorithm on three different types of public datasets. The experimental results show that the proposed algorithm outperforms other advanced multi-focus image fusion algorithms in both objective evaluation and visual evaluation.},
  archive      = {J_APIN},
  author       = {Liu, Shuaiqi and Liu, Yali and Su, Yonggang and Zhang, Yudong},
  doi          = {10.1007/s10489-024-05722-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11373-11399},
  shortjournal = {Appl. Intell.},
  title        = {EDOM-MFIF: An end-to-end decision optimization model for multi-focus image fusion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid offline-online method for sound event localization
and detection. <em>APIN</em>, <em>54</em>(22), 11357–11372. (<a
href="https://doi.org/10.1007/s10489-024-05702-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of sound event localization and detection (SELD) is to accurately identify the temporal occurrence and spatial coordinates of a specific sound category. The existing mainstream offline methods may unintentionally introduce unfavorable future feature information during the training process, thereby potentially hindering the system’s performance. The utilization of online methods can lead to improved localization accuracy to a certain extent. Nevertheless, it may result in a diminished ability with the detection capability for sound events. In this paper, a hybrid offline-online method (HOOM) is proposed that involves extracting comprehensive audio information using offline network layers, while simultaneously filtering out irrelevant future information using online network layers. Based on this method, we designed two simple sub-network architectures. The first, convolution and causal convolution alternating network (CCAN), employs regular convolution along with causal convolutions to achieve the offline and online convolution features, respectively. The second, bidirectional and unidirectional alternating network (BUAN), combines bidirectional recurrent neural networks with unidirectional recurrent neural networks, capturing the offline and online contextual sequence information, respectively. Our proposed method demonstrates a 6% improvement in localization recall on the Sony-TAU Realistic Spatial Soundscapes 2023 (STARSS23) dataset. Furthermore, compared to offline or online methods, there is a 4% overall performance improvement. On the detection and classification of acoustic scenes and events 2022 (DCASE2022) synthetic dataset, the overall performance improvement is 5%. These results indicate a significant advantage and provide a novel and robust solution for the SELD task. Propose a hybrid offline-online method for SELD. The extracted hybrid features or temporal sequences enable the acquisition of a more comprehensive range of audio information.},
  archive      = {J_APIN},
  author       = {Zhang, Wenjie and Yu, Peng and Wang, Zhan and Wang, Zhenhe and Xu, Mingliang},
  doi          = {10.1007/s10489-024-05702-9},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11357-11372},
  shortjournal = {Appl. Intell.},
  title        = {A hybrid offline-online method for sound event localization and detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attribute community detection based on attribute edges
weights fusion and graph embedding factorization. <em>APIN</em>,
<em>54</em>(22), 11342–11356. (<a
href="https://doi.org/10.1007/s10489-024-05687-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, factorization combined with attribute information has played an important role in attribute community detection. However, previous studies focused more on connecting the original shallow topological and attribute data. They ignored the potential representation structure of the network. To solve the problem that shallow information cannot fully represent the network structure, this paper proposes an attribute node classification method based on Attribute Edges weights Fusion and graph Embedding Factorization, called AEFEF. First, AEFEF converts topological information and attribute information into corresponding matrices representing node associations. Then, AEFEF constructs a new adjacency matrix by increasing the weights of shared edges between the topology structure and attribute structure. This operation can strengthen the tightness between nodes. Second, to explore the potential community structure, feature embedding is obtained by factorizing the attribute similarity matrix. Meanwhile, the new adjacency matrix is designed as a weight matrix to make the feature embedding between related nodes more similar. Finally, semi Non-negative Matrix Factorization (NMF) is introduced to modify the feature embedding by converting the negative values into positive values. Then the embedding is factorized to generate the membership matrix. At the same time, the network with a rich structure is decomposed with topological data as the main component. Otherwise, attribute information is the main component of NMF used to increase the accuracy of node classification. AEFEF is compared with 10 state-of-the-art algorithms on 7 real network datasets. The results reveal that AEFEF can improve the precision of attribute community detection.},
  archive      = {J_APIN},
  author       = {Yang, Shuaize and Zhang, Weitong and Shang, Ronghua and Xu, Songhua and Wang, Chao},
  doi          = {10.1007/s10489-024-05687-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11342-11356},
  shortjournal = {Appl. Intell.},
  title        = {Attribute community detection based on attribute edges weights fusion and graph embedding factorization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). FGLNet: Frequency global and local context channel
attention networks. <em>APIN</em>, <em>54</em>(22), 11325–11341. (<a
href="https://doi.org/10.1007/s10489-024-05729-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of attention mechanisms, especially channel attention, has achieved huge success in the field of computer vision. However, existing methods mainly focus on more sophisticated attention modules for better performance, but ignore global and local contexts in the frequency domain. This work focuses on the channel relationship and proposes a novel architectural unit called Frequency Global and Local (FGL) context block. It adaptively recalibrates global-local channel-wise feature responses by explicitly modeling interdependencies between channels in the frequency domain. The proposed lightweight FGL module is efficient well generalizable across different datasets. Meanwhile, the FGL context block significantly improves the performance of existing convolutional neural networks (CNNs) at a slight computational cost. Our FGL module is extensively evaluated with applications of image classification, object detection, and semantic segmentation with the backbones of ResNets, MobileNetV2, and MobileNeXt. The experimental results indicate that our module is more efficient than its counterparts. Our model is open-sourced at https://github.com/YunDuanFei/FGL .},
  archive      = {J_APIN},
  author       = {Liu, Yunfei and Liu, Yan and Li, Huaqiang and Zhang, Junran},
  doi          = {10.1007/s10489-024-05729-y},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11325-11341},
  shortjournal = {Appl. Intell.},
  title        = {FGLNet: Frequency global and local context channel attention networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semantic visual SLAM towards object selection and tracking
optimization. <em>APIN</em>, <em>54</em>(22), 11311–11324. (<a
href="https://doi.org/10.1007/s10489-024-05761-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous localization and mapping (SLAM) technology has garnered considerable attention as a pivotal component for the autonomous navigation of intelligent mobile vehicles. Integrating target detection and target tracking technology into SLAM enhances scene perception, resulting in a more resilient SLAM system. Consequently, this article presents a pose optimization algorithm based on image segmentation, coupled with object detection technology, to achieve superior multi-frame association feature matching. Subsequently, this paper proposes a method for selecting the most stable targets to better conduct pose optimization. Finally, experimental validation was conducted on five sequences from the TUM dataset. We conducted tracking performance experiments to demonstrate the necessity of selecting stable targets for pose optimization. Afterwards, we carried out a comprehensive comparison with the current state-of-the-art SLAM implementations in terms of accuracy and robustness. The average absolute trajectory error of our method in the dynamic benchmark datasets is $$\sim $$ 94.14% lower than that of ORB-SLAM2, $$\sim $$ 61.90% lower than that of RS-SLAM, and $$\sim $$ 80.89% lower than that of DS-SLAM. At the end of the experiment, the process performance of the proposed method is demonstrated. The experiments collectively showcase the system’s capability to deliver outstanding results.},
  archive      = {J_APIN},
  author       = {Sun, Tian and Cheng, Lei and Hu, Yaqi and Yuan, Xiaoping and Liu, Yong},
  doi          = {10.1007/s10489-024-05761-y},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11311-11324},
  shortjournal = {Appl. Intell.},
  title        = {A semantic visual SLAM towards object selection and tracking optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-functional scar tissue discrimination platform
construction and exploration of molecular mechanism for scar formation.
<em>APIN</em>, <em>54</em>(22), 11295–11310. (<a
href="https://doi.org/10.1007/s10489-024-05625-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scars that form after skin injury can cause structural and functional skin damage. Currently, scar tissue determination relies mainly on doctors’ subjective observations and judgments and lacks objectivity. However, current deep learning models can only achieve specific discrimination using unimodal data, which limits the comprehensive understanding of scar tissue and may reduce accuracy and stability. To solve these problems, in this study, a skin scar recognition platform based on advanced deep learning and a weighted aggregation network fusion method is proposed. It is implemented using a residual network-based CNN model and a logistic regression model with L1 regularization and is suitable for both unimodal and multimodal data. The experimental results showed that the proposed platform achieved a satisfactory accuracy of 98.26% for image discrimination. In the gene discrimination model test performed on a test dataset containing 17 gene expression samples, all samples were accurately discriminated. In addition, the proposed multimodal discrimination model achieved a discrimination accuracy of 98.23%. These results validate the effectiveness of deep feature extraction and multimodal feature fusion techniques for image discrimination tasks. On this basis, to deeply explore the pathogenesis of scar formation, a method with the ability to integrate regularization, sparsity, and orthogonality constraints, multiconstraint joint non-negative matrix factorization (MCJNMF), was used to explore the genetic correlation between collagen micrographic image features and gene expression data. In this study, we confirmed the association between the calcium signaling pathway, MAPK signaling pathway, and collagen fiber repair, and successfully identified 11 potential therapeutic targets, including TRIM59 and TBC1D9, which provide important clues for future scar treatment and prevention strategies.},
  archive      = {J_APIN},
  author       = {Hu, Xiaoqian and Yu, Yaling and Kong, Wei and Wang, Shuaiqun and Wen, Gen},
  doi          = {10.1007/s10489-024-05625-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11295-11310},
  shortjournal = {Appl. Intell.},
  title        = {Multi-functional scar tissue discrimination platform construction and exploration of molecular mechanism for scar formation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved transferability of self-supervised learning models
through batch normalization finetuning. <em>APIN</em>, <em>54</em>(22),
11281–11294. (<a
href="https://doi.org/10.1007/s10489-024-05758-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abundance of unlabelled data and advances in Self-Supervised Learning (SSL) have made it the preferred choice in many transfer learning scenarios. Due to the rapid and ongoing development of SSL approaches, practitioners are now faced with an overwhelming amount of models trained for a specific task/domain, calling for a method to estimate transfer performance on novel tasks/domains. Typically, the role of such estimator is played by linear probing which trains a linear classifier on top of the frozen feature extractor. In this work we address a shortcoming of linear probing — it is not very strongly correlated with the performance of the models finetuned end-to-end— the latter often being the final objective in transfer learning— and, in some cases, catastrophically misestimates a model’s potential. We propose a way to obtain a significantly better proxy task by unfreezing and jointly finetuning batch normalization layers together with the classification head. At a cost of extra training of only 0.16% model parameters, in case of ResNet-50, we acquire a proxy task that (i) has a stronger correlation with end-to-end finetuned performance, (ii) improves the linear probing performance in the many- and few-shot learning regimes and (iii) in some cases, outperforms both linear probing and end-to-end finetuning, reaching the state-of-the-art performance on a pathology dataset. Finally, we analyze and discuss the changes batch normalization training introduces in the feature distributions that may be the reason for the improved performance. The code is available at https://github.com/vpulab/bn_finetuning .},
  archive      = {J_APIN},
  author       = {Sirotkin, Kirill and Escudero-Viñolo, Marcos and Carballeira, Pablo and García-Martín, Álvaro},
  doi          = {10.1007/s10489-024-05758-7},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11281-11294},
  shortjournal = {Appl. Intell.},
  title        = {Improved transferability of self-supervised learning models through batch normalization finetuning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic region-division based pricing strategy in
ride-hailing. <em>APIN</em>, <em>54</em>(22), 11267–11280. (<a
href="https://doi.org/10.1007/s10489-024-05711-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, ride-hailing has played an important role in daily transportation. In the ride-hailing system, how to set the prices for orders is a crucial issue. Considering the variations in vehicle supply and order demand in different regions of the same city, it is necessary to divide regions according to the supply and demand in each region and develop differentiate pricing strategy. However, the traditional fixed region-division strategy is difficult to adapt to the dynamically changed supply and demand over the time. To address this issue, we propose a dynamic region-division based pricing strategy to set prices according to the demand and supply of different regions to maximize the long-term profit of the platform. Specifically, we first design a dynamic region-clustering algorithm based on Deep Q Network and K-Means algorithm to dynamically cluster small zones with similar demand and supply status and nearby locations into the same region. We then propose an adaptive multi-region dynamic pricing algorithm to set unit price for each clustered region to maximize the long-term profit of the ride-hailing platform. We further run extensive experiments based on a real-world dataset to demonstrate the effectiveness of our proposed algorithm. The experimental results show that the platform’s profit is increased under different pricing algorithms combined with dynamic region-clustering algorithm. Furthermore, we find that the combination of adaptive multi-region dynamic pricing algorithm with dynamic region-clustering algorithm can bring higher profits, serve more orders and have a higher service rate than benchmark approaches.},
  archive      = {J_APIN},
  author       = {Shi, Bing and Lu, Yan and Cao, Zhi},
  doi          = {10.1007/s10489-024-05711-8},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11267-11280},
  shortjournal = {Appl. Intell.},
  title        = {A dynamic region-division based pricing strategy in ride-hailing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HEFANet: Hierarchical efficient fusion and aggregation
segmentation network for enhanced rgb-thermal urban scene parsing.
<em>APIN</em>, <em>54</em>(22), 11248–11266. (<a
href="https://doi.org/10.1007/s10489-024-05743-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-Thermal semantic segmentation is important in widespread applications in adverse illumination conditions, such as autonomous driving and robotic sensing. However, most existing methods ignore the feature differences between the two modalities and do not effectively exploit and handle the features at different levels. In this paper, we present a novel multimodal feature fusion network named HEFANet, which effectively enhances the interaction and fusion of features. Concretely, we propose a Cross-layer and Cross-modal Feature Descriptor module (CCFD) to mitigate differences between different multimodal data and to mine the valuable and correlated features of cross-layers. To effectively fuse multimodal features at different levels, we propose a Multi-modal Interleaved Sparse Self-Attention module (MISSA) to aggregate rich spatial semantic information in the earlier layers. Then, we propose the Spatial Interaction and Channel Selection module (SICS) in the last layer to enhance the representation of rich contextual features and highlight important information by channel communication interactions for optimal sparse feature aggregation selectively. Extensive experiments were carried out on three publicly available datasets (MFNet, PST900, and FMB), and achieved new state-of-the-art results. The code and results are available at https://github.com/shenzw21/HEFANet .},
  archive      = {J_APIN},
  author       = {Shen, Zhengwen and Pan, Zaiyu and Weng, Yuchen and Li, Yulian and Wang, Jiangyu and Wang, Jun},
  doi          = {10.1007/s10489-024-05743-0},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11248-11266},
  shortjournal = {Appl. Intell.},
  title        = {HEFANet: Hierarchical efficient fusion and aggregation segmentation network for enhanced rgb-thermal urban scene parsing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage group stochastic preference analysis based on
best-worst method. <em>APIN</em>, <em>54</em>(22), 11233–11247. (<a
href="https://doi.org/10.1007/s10489-024-05730-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an integrated approach to group decision-making (GDM) by using stochastic preference analysis (SPA) and best-worst method (BWM). BWM preparation algorithm is proposed to obtain the best and worst of experts and the relative importance degree. Meanwhile, expert weights model and expert’s priority vector model are proposed. Furthermore, the stochastic composite rank acceptability index, stochastic composite expected priority vector, stochastic composite expected rank and stochastic composite confidence factor are developed based on SPA to describe the ranks of alternatives based on SPA. Finally, a group stochastic preference analysis-best worst method (GSPA-BWM) algorithm is developed by analyzing the judgments space through Monte Carlo simulation. The experts can use this method to choose some of the outcomes which they find most useful to make reliable decisions. Examples and comparison analyses show that the proposed method is effective.},
  archive      = {J_APIN},
  author       = {Dai, Ning and Zhou, Ligang and Wu, Qun},
  doi          = {10.1007/s10489-024-05730-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11233-11247},
  shortjournal = {Appl. Intell.},
  title        = {A two-stage group stochastic preference analysis based on best-worst method},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic consistency knowledge transfer for unsupervised
cross domain object detection. <em>APIN</em>, <em>54</em>(22),
11212–11232. (<a
href="https://doi.org/10.1007/s10489-024-05713-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the data distributions between the source and target domains are inconsistent, unsupervised cross domain object detection improves the performance of the detector without the need to add any additional annotation information. However, existing advanced methods overlook the semantic consistency of images, which leads to incorrect transfer knowledge in feature learning and reduces adaptive performance. Therefore, we propose a feature correlation learning method, called Semantic Consistency Knowledge Transfer (SCKT) for unsupervised cross domain object detection, which focuses on similar semantic information and achieves fine-grained corresponding scales domain adaptation. Specifically, we design a Multi-channel Adaptive Correction (MAC) module for image enhancement, which alleviates pixel distortion and maintains semantic consistency. Furthermore, the proposed Related Knowledge Mining (RKM) module consists of Feature Correlation Learning (FCL) and Consistent Knowledge Learning (CKL), which use generated semantic consistency features to capture different levels of image details and semantic information, achieving corresponding domain alignment at multiple levels. Most importantly, SCKT does not rely on a specific network structure, and does not reduce inference speed, which is suitable for different object detectors. Extensive experiments show that our SCKT can exhibit optimal performance in multiple domain migration scenarios. Especially for the challenging PASCAL VOC $$\rightarrow $$ Clipart, SCKT generates 54.6% mAP.},
  archive      = {J_APIN},
  author       = {Chen, Zichong and Xia, Ziying and Li, Xiaochen and Shi, Junhao and Tashi, Nyima and Cheng, Jian},
  doi          = {10.1007/s10489-024-05713-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11212-11232},
  shortjournal = {Appl. Intell.},
  title        = {Semantic consistency knowledge transfer for unsupervised cross domain object detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Cross-modal guides spatio-temporal enrichment network for
few-shot action recognition. <em>APIN</em>, <em>54</em>(22),
11196–11211. (<a
href="https://doi.org/10.1007/s10489-024-05617-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot action recognition aims to learn a model that can be easily adapted to identify novel action classifications using only a few labeled samples. Recent methods primarily focus on visual features and fail to fully utilize the available classification title of the video. In addition, they capture higher-order temporal relationships among video frames through averaging, which neglects the long-range dependencies information of the video. To address these issues, we designed a novel cross-modal guided spatio-temporal enrichment network (X-STEN) for few-shot action recognition. The model includes a cross-modal spatial enrichment module (X-SEM), a temporal enrichment module (TEM), and a non-parametric metrics module (NMM). Firstly, we extract and fuse multi-modal feature representations of videos. Then, we enhance the spatial context information of the video using the X-SEM and model the temporal context information of the video using the TEM. Finally, we generate the query and support prototypes and measure the similarity between them. Extensive experiments demonstrate that our X-STEN achieve excellent results on few-shot splits of Kinetics, HMDB51 and UCF101. Importantly, our method outperforms prior work on Kinetics by a wide margin (13.9%).},
  archive      = {J_APIN},
  author       = {Chen, Zhiwen and Yang, Yi and Li, Li and Li, Min},
  doi          = {10.1007/s10489-024-05617-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11196-11211},
  shortjournal = {Appl. Intell.},
  title        = {Cross-modal guides spatio-temporal enrichment network for few-shot action recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating pseudo labeling with contrastive clustering for
transformer-based semi-supervised action recognition. <em>APIN</em>,
<em>54</em>(22), 11177–11195. (<a
href="https://doi.org/10.1007/s10489-024-05661-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action recognition with semi-supervised learning is a challenging research topic due to the low-labeling ratio. Previous works mainly tackle the problem with two kinds of approaches: pseudo labeling and contrastive learning. Different from existing approaches that often treat the two parts separately, we propose an integrated learning framework that incorporates pseudo labeling and contrastive clustering in a coherent and mutually beneficial way. On one hand, the contrastive learning aggregates data from the same class into clusters, yielding more reliable pseudo labels for training the classifier; on the other hand, the re-trained classifier predicts categories for unlabeled data, thereby guiding contrastive learning to establish discriminative representations. We theoretically prove that the two iterative operations can be formulated as an E-M algorithm and validate its generalization ability upon the semi-supervised classification task with experiments. Specifically, we construct a MoCo-like structure to implement the proposed learning framework and explore the potential of employing the video tramsformer for semi-supervised action recognition. Furthermore, We also devise a global-local view sampling strategy for video data augmentation, which verifies to facilitate the representation learning and advance the performance. We implement extensive experiments on three video action recognition datasets with a series of data labeling ratios. Compared with state-of-the-art (SOTA) methods, the proposed approach achieves superior or competitive performances. For example, with $$1\%$$ labeling ratio, the top-1 accuracy increase to $$49.1\%$$ and $$52.4\%$$ on UCF-101 and Kinetics-400 datasets, respectively, surpassing SOTA by $$2.8\%$$ and $$3.3\%$$ .},
  archive      = {J_APIN},
  author       = {Li, Nannan and Huang, Kan and Wu, Qingtian and Zhao, Yang},
  doi          = {10.1007/s10489-024-05661-1},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11177-11195},
  shortjournal = {Appl. Intell.},
  title        = {Integrating pseudo labeling with contrastive clustering for transformer-based semi-supervised action recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic training for handling textual label noise.
<em>APIN</em>, <em>54</em>(22), 11161–11176. (<a
href="https://doi.org/10.1007/s10489-024-05738-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise causes deep neural networks to gradually memorize incorrect labels, leading to a decline in generalization. In this paper, based on three observations from learning behavior in textual noise scenarios, we propose a dynamic training method to enhance model robustness and generalization against textual label noise. This method corrects noisy labels by dynamically incorporating the model’s predictions. The combination weight of the original labels is a decay function on training time, which relates to the learning dynamics. Additionally, our method introduces r-drop and prior regularization terms to ensure that the single-model backbone generates reliable predictions, thereby obtaining accurate corrected labels. This design removes the stage splitting and data segmentation required by existing SOTA methods and effectively mitigates the adverse impact of erroneous labels without introducing additional dependencies. Experimental results on four text classification datasets demonstrate that dynamic training outperforms strong baselines designed for class-conditional and instance-dependent noises within the common noise range. Our code is available at https://github.com/shaohuancheng/noisy_label_for_exp_decay .},
  archive      = {J_APIN},
  author       = {Cheng, Shaohuan and Chen, Wenyu and Liu, Wanlong and Zhou, Li and Zhao, Honglin and Kong, Weishan and Qu, Hong and Fu, Mingsheng},
  doi          = {10.1007/s10489-024-05738-x},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {22},
  pages        = {11161-11176},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic training for handling textual label noise},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: WSMOTER: A novel approach for imbalanced
regression. <em>APIN</em>, <em>54</em>(21), 11160. (<a
href="https://doi.org/10.1007/s10489-024-05704-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Camacho, Luís and Bacao, Fernando},
  doi          = {10.1007/s10489-024-05704-7},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11160},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: WSMOTER: a novel approach for imbalanced regression},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-step on-policy deep reinforcement learning method
assisted by off-policy policy evaluation. <em>APIN</em>,
<em>54</em>(21), 11144–11159. (<a
href="https://doi.org/10.1007/s10489-024-05508-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-policy deep reinforcement learning (DRL) has the inherent advantage of using multi-step interaction data for policy learning. However, on-policy DRL still faces challenges in improving the sample efficiency of policy evaluations. Therefore, we propose a multi-step on-policy DRL method assisted by off-policy policy evaluation (abbreviated as MSOAO), whichs integrates on-policy and off-policy policy evaluations and belongs to a new type of DRL method. We propose a low-pass filtering algorithm for state-values to perform off-policy policy evaluation and make it efficiently assist on-policy policy evaluation. The filtered state-values and the multi-step interaction data are used as the input of the V-trace algorithm. Then, the state-value function is learned by simultaneously approximating the target state-values obtained from the V-trace output and the action-values of the current policy. The action-value function is learned by using the one-step bootstrapping algorithm to approximate the target action-values obtained from the V-trace output. Extensive evaluation results indicate that MSOAO outperformed the performance of state-of-the-art on-policy DRL algorithms, and the simultaneous learning of the state-value function and the action-value function in MSOAO can promote each other, thus improving the learning capability of the algorithm.},
  archive      = {J_APIN},
  author       = {Zhang, Huaqing and Ma, Hongbin and Mersha, Bemnet Wondimagegnehu and Jin, Ying},
  doi          = {10.1007/s10489-024-05508-9},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11144-11159},
  shortjournal = {Appl. Intell.},
  title        = {A multi-step on-policy deep reinforcement learning method assisted by off-policy policy evaluation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mining emotion soft factors in linguistic preference time
sequences based on personalized individual semantics in group
decision-making. <em>APIN</em>, <em>54</em>(21), 11120–11143. (<a
href="https://doi.org/10.1007/s10489-024-05697-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals’ emotions, such as hesitation and unwavering confidence, can influence the ability of decision-makers (DMs) to make rational judgments. The emotion is always hidden in individual preference series, which is referred to as emotion soft factors, It is a prerequisite for avoiding unfavorable impacts on consensus reaching process. This study focuses on structuring a consensus model with emotion soft factors in linguistic preference time sequence. Specifically, a personalized individual semantics (PIS) learning process is implemented to obtain the personalized numerical scales of DMs’ linguistic terms. Subsequently, we propose a consensus model incorporating the consensus measurement and feedback modification phase. In the process, a grey clustering scheme is devised to mine emotion soft factors from DMs’ preference sequences and manage individuals in different grey classes. Finally, numerical examples, simulation analysis, and comparison study are presented to illustrate the influence of different parameters and justify the validity of the proposed model.},
  archive      = {J_APIN},
  author       = {Jing, Fuying and Xu, Mengru and Chao, Xiangrui and Herrera-viedma, Enrique},
  doi          = {10.1007/s10489-024-05697-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11120-11143},
  shortjournal = {Appl. Intell.},
  title        = {Mining emotion soft factors in linguistic preference time sequences based on personalized individual semantics in group decision-making},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving multi-UAV cooperative path-finding through
multiagent experience learning. <em>APIN</em>, <em>54</em>(21),
11103–11119. (<a
href="https://doi.org/10.1007/s10489-024-05771-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A collaborators’ experiences learning (CEL) algorithm, based on multiagent reinforcement learning (MARL) is presented for multi-UAV cooperative path-finding, where reaching destinations and avoiding obstacles are simultaneously considered as independent or interactive tasks. In this article, we are inspired by the experience learning phenomenon to propose the multiagent experience learning theory based on MARL. A strategy for updating parameters randomly is also suggested to allow homogeneous UAVs to effectively learn cooperative strategies. Additionally, the convergence of this algorithm is theoretically demonstrated. To demonstrate the effectiveness of the algorithm, we conduct experiments with different numbers of UAVs and different algorithms. The experiments show that the proposed method can achieve experience sharing and learning among UAVs and complete the cooperative path-finding task very well in unknown dynamic environments.},
  archive      = {J_APIN},
  author       = {Longting, Jiang and Ruixuan, Wei and Dong, Wang},
  doi          = {10.1007/s10489-024-05771-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11103-11119},
  shortjournal = {Appl. Intell.},
  title        = {Improving multi-UAV cooperative path-finding through multiagent experience learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view deep subspace clustering via level-by-level
guided multi-level features learning. <em>APIN</em>, <em>54</em>(21),
11083–11102. (<a
href="https://doi.org/10.1007/s10489-024-05807-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering has attracted extensive attention due to its ability to efficiently handle data from diverse sources. In recent years, plentiful multi-view subspace clustering methods have emerged and achieved satisfactory clustering performance. However, these methods rarely consider simultaneously handling data with a nonlinear structure and exploiting the structural and multi-level information inherent in the data. To remedy these shortcomings, we propose the novel multi-view deep subspace clustering via level-by-level guided multi-level features learning (MDSC-LGMFL). Specifically, an autoencoder is used for each view to extract the view-specific multi-level features, and multiple self-representation layers are introduced into the autoencoder to learn the subspace representations corresponding to the multi-level features. These self-representation layers not only provide multiple information flow paths through the autoencoder but also enforce multiple encoder layers to produce the multi-level features that satisfy the linear subspace assumption. With the novel level-by-level guidance strategy, the last-level feature is guaranteed to encode the structural information from the view and the previous-level features. Naturally, the subspace representation of the last-level feature can more reliably reflect the data affinity relationship and thus can be viewed as the new, better representation of the view. Furthermore, to guarantee the structural consistency among different views, instead of simply learning the common subspace structure by enforcing it to be close to different view-specific new, better representations, we conduct self-representation on these new, better representations to learn the common subspace structure, which can be applied to the spectral clustering algorithm to achieve the final clustering results. Numerous experiments on six widely used benchmark datasets show the superiority of the proposed method.},
  archive      = {J_APIN},
  author       = {Xu, Kaiqiang and Tang, Kewei and Su, Zhixun},
  doi          = {10.1007/s10489-024-05807-1},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11083-11102},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view deep subspace clustering via level-by-level guided multi-level features learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved generative adversarial imputation networks for
missing data. <em>APIN</em>, <em>54</em>(21), 11068–11082. (<a
href="https://doi.org/10.1007/s10489-024-05814-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional statistical methods for missing data imputation have been challenging to adapt to the large-scale new features of high dimensionality. Moreover, the missing data imputation methods based on Generative Adversarial Networks (GAN) are plagued with gradient vanishing and mode collapse. To address these problems, we have proposed a new imputation method based on GAN to enhance the accuracy of missing data imputation in this study. We refer to our missing data method using Generative Adversarial Imputation Networks (MGAIN). Specifically, the least squares loss is first introduced to solve the gradient vanishing problem and ensure the high quality of the output data in MGAIN. To mitigate mode collapse, dual discriminator is used in the model, which improved the diversity of output data to avoid the degradation of computational performance caused by single data. As a result, MGAIN generates rich and accurate imputation values. The MGAIN enhances imputation accuracy and reduces the root mean square error metric by 21.66% compared to the baseline model. We evaluated our method on baseline datasets and found that MGAIN outperformed state-of-the-art and popular imputation methods, demonstrating its effectiveness and superiority.},
  archive      = {J_APIN},
  author       = {Qin, Xiwen and Shi, Hongyu and Dong, Xiaogang and Zhang, Siqi and Yuan, Liping},
  doi          = {10.1007/s10489-024-05814-2},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11068-11082},
  shortjournal = {Appl. Intell.},
  title        = {Improved generative adversarial imputation networks for missing data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view multi-label learning for label-specific features
via GLocal shared subspace learning. <em>APIN</em>, <em>54</em>(21),
11054–11067. (<a
href="https://doi.org/10.1007/s10489-024-05779-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning (MLL), label-specific feature (LSF) learning assumes that labels are determined by their inherent characteristics. However, in multi-view multi-label learning (MVMLL), the heterogeneity problem persists within the feature space. The views with varying dimensions can result in different dimensions of extracted LSF. Existing algorithms extract the LSF for each view separately, suffering the inadequate communication of the LSF and poor classification accuracy. The subspace learning method can address the dimension-inconsistency problem in multi-views by extracting extract the shared subspace for each view by substituting the original view feature space. However, the individual subspaces contain relatively homogeneous information. Based on this analysis, the GLocal Shared Subspace Learning (GLSSL) algorithm was proposed for multi-view multi-label learning to access more informative subspaces. First, the label groups were obtained through spectral clustering, entirely considering the correlation between the label groups and features to identify the specific relevant view features corresponding to each label group. Subsequently, the global shared subspace (global subspace) and local shared subspace (local subspace) were extracted from the original feature space and feature sets, respectively. Finally, the local subspace was complemented with the global subspace for LSF learning. The proposed algorithm was validated through comparative experiments with several state-of-the-art algorithms on multiple benchmark multi-view multi-label datasets.},
  archive      = {J_APIN},
  author       = {Cheng, Yusheng and Xu, Yuting and Ge, Wenxin},
  doi          = {10.1007/s10489-024-05779-2},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11054-11067},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view multi-label learning for label-specific features via GLocal shared subspace learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Aerial-view geo-localization based on multi-layer local
pattern cross-attention network. <em>APIN</em>, <em>54</em>(21),
11034–11053. (<a
href="https://doi.org/10.1007/s10489-024-05777-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial-view geo-localization aims to determine locations of interest to drones by matching drone-view images against a satellite database with geo-tagging. The key underpinning of this task is to mine discriminative features to form a view-invariant representation of the same target location. To achieve this purpose, existing methods usually focus on extracting fine-grained information from the final feature map while neglecting the importance of middle-layer outputs. In this work, we propose a Transformer-based network, named Multi-layer Local Pattern Cross Attention Network (MLPCAN). Particularly, we employ the cross-attention block (CAB) to establish correlations between information of feature maps from different layers when images are fed into the network. Then, we apply the square-ring partition strategy to divide feature maps from different layers and acquire multiple local pattern blocks. For the information misalignment within multi-layer features, we propose the multi-layer aggregation block (MAB) to aggregate the high-association feature blocks obtained by the division. Extensive experiments on two public datasets, i.e., University-1652 and SUES-200, show that the proposed model significantly improves the accuracy of geo-localization and achieves competitive results.},
  archive      = {J_APIN},
  author       = {Li, Haoran and Wang, Tingyu and Chen, Quan and Zhao, Qiang and Jiang, Shaowei and Yan, Chenggang and Zheng, Bolun},
  doi          = {10.1007/s10489-024-05777-4},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11034-11053},
  shortjournal = {Appl. Intell.},
  title        = {Aerial-view geo-localization based on multi-layer local pattern cross-attention network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical symmetric cross entropy for distant supervised
relation extraction. <em>APIN</em>, <em>54</em>(21), 11020–11033. (<a
href="https://doi.org/10.1007/s10489-024-05798-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distant supervised relation extraction has been increasingly popular in recent years, which generates datasets automatically without human intervention. However, the distant supervised assumption has the limitation that the generated datasets have inevitable labeling errors. This paper proposes the method of Hierarchical Symmetric Cross Entropy for Distant Supervised Relation Extraction (HSCERE) to alleviate the impact of the noisy labels. Specifically, HSCERE simultaneously utilizes two extractors with the same network structure for collaborative learning. This collaborative learning process guides the optimization of the extractor through a joint loss function, namely Hierarchical Symmetric Cross Entropy (HSCE). Within the HSCE loss, the predicted probability distribution of the extractors serves as the supervisory signal, guiding the optimization of the extractors on two levels to reduce the impact of noisy labels. The two levels include the internal optimization within each extractor and the collaborative optimization between extractors. Experiments on generally used datasets show that HSCERE can effectively handle noisy labels and can be incorporated into various methods to enhance their performance.},
  archive      = {J_APIN},
  author       = {Liu, Yun and Jiang, Xiaoheng and Lv, Pengshuai and Lu, Yang and Li, Shupan and Zhang, Kunli and Xu, Mingliang},
  doi          = {10.1007/s10489-024-05798-z},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {11020-11033},
  shortjournal = {Appl. Intell.},
  title        = {Hierarchical symmetric cross entropy for distant supervised relation extraction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting sexism in social media: An empirical analysis of
linguistic patterns and strategies. <em>APIN</em>, <em>54</em>(21),
10995–11019. (<a
href="https://doi.org/10.1007/s10489-024-05795-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of social networks, there has been a marked increase in offensive content targeting women, ranging from overt acts of hatred to subtler, often overlooked forms of sexism. The EXIST (sEXism Identification in Social neTworks) competition, initiated in 2021, aimed to advance research in automatically identifying these forms of online sexism. However, the results revealed the multifaceted nature of sexism and emphasized the need for robust systems to detect and classify such content. In this study, we provide an extensive analysis of sexism, highlighting the characteristics and diverse manifestations of sexism across multiple languages on social networks. To achieve this objective, we conducted a detailed analysis of the EXIST dataset to evaluate its capacity to represent various types of sexism. Moreover, we analyzed the systems submitted to the EXIST competition to identify the most effective methodologies and resources for the automated detection of sexism. We employed statistical methods to discern textual patterns related to different categories of sexism, such as stereotyping, misogyny, and sexual violence. Additionally, we investigated linguistic variations in categories of sexism across different languages and platforms. Our results suggest that the EXIST dataset covers a broad spectrum of sexist expressions, from the explicit to the subtle. We observe significant differences in the portrayal of sexism across languages; English texts predominantly feature sexual connotations, whereas Spanish texts tend to reflect neosexism. Across both languages, objectification and misogyny prove to be the most challenging to detect, which is attributable to the varied vocabulary associated with these forms of sexism. Additionally, we demonstrate that models trained on platforms like Twitter can effectively identify sexist content on less-regulated platforms such as Gab. Building on these insights, we introduce a transformer-based system with data augmentation techniques that outperforms competition benchmarks. Our work contributes to the field by enhancing the understanding of online sexism and advancing the technological capabilities for its detection.},
  archive      = {J_APIN},
  author       = {Rodríguez-Sánchez, Francisco and Carrillo-de-Albornoz, Jorge and Plaza, Laura},
  doi          = {10.1007/s10489-024-05795-2},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10995-11019},
  shortjournal = {Appl. Intell.},
  title        = {Detecting sexism in social media: An empirical analysis of linguistic patterns and strategies},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-grained gaze estimation based on the combination of
regression and classification losses. <em>APIN</em>, <em>54</em>(21),
10982–10994. (<a
href="https://doi.org/10.1007/s10489-024-05778-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human gaze is a crucial cue used in various applications such as human-robot interaction, autonomous driving, and virtual reality. Recently, convolution neural network (CNN) approaches have made notable progress in predicting gaze angels. However, estimating accurate gaze direction in-the-wild is still a challenging problem due to the difficulty of obtaining the most crucial gaze information that exists in the eye area which constitutes a small part of the face images. In this paper, we introduce a novel two-branch CNN architecture with a multi-loss approach to estimate gaze angles (pitch and yaw) from face images. Our approach utilizes separate fully connected layers for each gaze angle prediction, allowing explicit learning of discriminative features and emphasizing the distinct information associated with each gaze angle. Moreover, we adopt a multi-loss approach, incorporating both classification and regression losses. This allows for joint optimization of the combined loss for each gaze angle, resulting in improved overall gaze performance. To evaluate our model, we conduct experiments on three popular datasets collected under unconstrained settings: MPIIFaceGaze, Gaze360, and RT-GENE. Our proposed model surpasses current state-of-the-art methods and achieves state-of-the-art performance on all three datasets, showcasing its superior capability in gaze estimation.},
  archive      = {J_APIN},
  author       = {Abdelrahman, Ahmed A. and Hempel, Thorsten and Khalifa, Aly and Al-Hamadi, Ayoub},
  doi          = {10.1007/s10489-024-05778-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10982-10994},
  shortjournal = {Appl. Intell.},
  title        = {Fine-grained gaze estimation based on the combination of regression and classification losses},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Z-number linguistic term set for multi-criteria group
decision-making and its application in predicting the acceptance of
academic papers. <em>APIN</em>, <em>54</em>(21), 10962–10981. (<a
href="https://doi.org/10.1007/s10489-024-05765-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world information is often characterized by uncertainty and partial reliability, which led Zadeh to introduce the concept of Z-numbers as a more appropriate formal structure for describing such information. However, the computation of Z-numbers requires solving highly complex optimization problems, limiting their practical application. Although linguistic Z-numbers have been explored for their computational straightforwardness, they lack theoretical support from Z-number theory and exhibit certain limitations. To address these issues and provide theoretical support from Z-numbers, we propose a Z-number linguistic term set to facilitate more efficient processing of Z-number-based information. Specifically, we redefine linguistic Z-numbers as Z-number linguistic terms. By analyzing the hidden probability density functions of these terms, we identify patterns for ranking them. These patterns are used to define the Z-number linguistic term set, which includes all Z-number linguistic terms sorted in order. We also discuss the basic operators between these terms. Furthermore, we develop a multi-criteria group decision-making (MCGDM) model based on the Z-number linguistic term set. Applying our method to predict the acceptance of academic papers, we demonstrate its effectiveness and superiority. We compare the performance of our MCGDM method with five existing Z-number-based MCGDM methods and eight traditional machine learning clustering algorithms. Our results show that the proposed method outperforms others in terms of accuracy and time consumption, highlighting the potential of Z-number linguistic terms for enhancing Z-number computation and extending the application of Z-number-based information to real-world problems.},
  archive      = {J_APIN},
  author       = {Li, Yangxue and Kou, Gang and Peng, Yi and Morente-Molinera, Juan Antonio},
  doi          = {10.1007/s10489-024-05765-8},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10962-10981},
  shortjournal = {Appl. Intell.},
  title        = {Z-number linguistic term set for multi-criteria group decision-making and its application in predicting the acceptance of academic papers},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accuracy and generalization improvement for image quality
assessment of authentic distortion by semi-supervised learning.
<em>APIN</em>, <em>54</em>(21), 10948–10961. (<a
href="https://doi.org/10.1007/s10489-024-05790-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image quality assessment of authentically distorted images constitutes a indispensable part of numerous computer vision tasks. Despite the substantial progress in recent years, accuracy and generalization performance is still unsatisfactory. These challenges are primarily attributed to the scarcity of labeled images. In order to increase the amount of images for training, we use semi-supervised learning to combine labeled images and specifically selected unlabeled images. In our new training paradigm, denominated Selected Data Retrain under Regularization, the selection criteria of unlabeled images is based on the supposition that an image and a certain of its patches ought to have approximate image quality scores. Unlabeled images that meets the aforementioned criteria, named as Highly Credible Unlabeled Images, mitigate the problem of scarcity, thus, improve accuracy. However generalization may be compromised due to selection procedure’s reliance on labeled images and presence of coherent variance existed between labeled images and unlabeled images. Therefore we incorporate a sorting loss function to reduce variation within the new dataset of labeled images and specifically selected unlabeled images, and thus achieve better generalization. The effectiveness of our proposed paradigm is empirically validated using public datasets. Codes are available at https://github.com/dvstter/SDRR_IQA.},
  archive      = {J_APIN},
  author       = {Yang, Hanlin and Zhu, William and Wang, Shiping},
  doi          = {10.1007/s10489-024-05790-7},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10948-10961},
  shortjournal = {Appl. Intell.},
  title        = {Accuracy and generalization improvement for image quality assessment of authentic distortion by semi-supervised learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal knowledge graph reasoning based on evolutional
representation and contrastive learning. <em>APIN</em>, <em>54</em>(21),
10929–10947. (<a
href="https://doi.org/10.1007/s10489-024-05767-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graphs (TKGs) are a form of knowledge representation constructed based on the evolution of events at different time points. It provides an additional perspective by extending the temporal dimension for a range of downstream tasks. Given the evolving nature of events, it is essential for TKGs to reason about non-existent or future events. Most of the existing models divide the graph into multiple time snapshots and predict future events by modeling information within and between snapshots. However, since the knowledge graph inherently suffers from missing data and uneven data distribution, this time-based division leads to a drastic reduction in available data within each snapshot, which makes it difficult to learn high-quality representations of entities and relationships. In addition, the contribution of historical information changes over time, distinguishing its importance to the final results when capturing information that evolves over time. In this paper, we introduce CH-TKG (Contrastive Learning and Historical Information Learning for TKG Reasoning) to addresses issues related to data sparseness and the ambiguity of historical information weights. Firstly, we obtain embedding representations of entities and relationships with evolutionary dependencies by R-GCN and GRU. On this foundation, we introduce a novel contrastive learning method to optimize the representation of entities and relationships within individual snapshots of sparse data. Then we utilize self-attention and copy mechanisms to learn the effects of different historical data on the final inference results. We conduct extensive experiments on four datasets, and the experimental results demonstrate the effectiveness of our proposed model with sparse data.},
  archive      = {J_APIN},
  author       = {Ma, Qiuying and Zhang, Xuan and Ding, ZiShuo and Gao, Chen and Shang, Weiyi and Nong, Qiong and Ma, Yubin and Jin, Zhi},
  doi          = {10.1007/s10489-024-05767-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10929-10947},
  shortjournal = {Appl. Intell.},
  title        = {Temporal knowledge graph reasoning based on evolutional representation and contrastive learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient treatment method of scrap intelligent rating
based on machine vision. <em>APIN</em>, <em>54</em>(21), 10912–10928.
(<a href="https://doi.org/10.1007/s10489-024-05581-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scrap steel is a green resource that can substitute iron ore and is an important raw material in the modern steel industry. To address the many issues such as high risk, low accuracy in grading, and the susceptibility to questioning fairness in the manual inspection process of scrap steel, we propose an efficient intelligent scrap steel classification method based on machine vision, achieving accurate classification and grading of nine types of scrap steel. Firstly, a scrap steel quality inspection system was established at the scrap steel recycling site, where images of various types of scrap steel were collected and various image processing methods were employed for preprocessing, leading to the establishment of scrap steel datasets and carriage segmentation datasets. Secondly, a carriage segmentation model was built based on image segmentation technology to significantly reduce the influence of complex backgrounds of scrap steel images on classification and grading. Subsequently, an intelligent scrap steel classification grading model was established based on the attention mechanism in deep learning, combined with the Spatially Adaptive Heterogeneous Image Slicing (SAHI) image slicing prediction method, achieving accurate classification and grading of scrap steel under complex backgrounds and high-resolution images in scrap steel recycling. Finally, we conducted tests on the proposed method. Experimental results demonstrate the good generalization of our proposed method, accurately detecting various types of scrap steel, meeting the requirements of accuracy, real-time performance, and good generalization in scrap steel recycling classification and grading, achieving initial industrial application, and exhibiting significant advantages compared to traditional manual scrap steel quality inspection.},
  archive      = {J_APIN},
  author       = {Xu, Wenguang and Xiao, Pengcheng and Zhu, Liguang and Wei, Guangsheng and Zhu, Rong},
  doi          = {10.1007/s10489-024-05581-0},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10912-10928},
  shortjournal = {Appl. Intell.},
  title        = {An efficient treatment method of scrap intelligent rating based on machine vision},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AdaGuiDE: An adaptive and guided differential evolution for
continuous optimization problems. <em>APIN</em>, <em>54</em>(21),
10833–10911. (<a
href="https://doi.org/10.1007/s10489-024-05675-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) has been proven as a simple yet powerful meta-heuristic algorithm on tackling continuous optimization problems. Nevertheless most existing DE methods still suffer from certain drawbacks including the use of ineffective mechanisms to adjust mutation strategies and their control parameters that may possibly mislead the search directions, and also the lack of intelligent guidance and reset mechanisms to escape from local optima. Therefore, to enhance the adaptability of DE-based search frameworks and the robustness on optimizing complex problems full of local optima, an adaptive and guided differential evolution (AdaGuiDE) algorithm is proposed. Essentially, the adaptability of the AdaGuiDE search framework is enhanced by three schemes to iteratively refine the search behaviour at two different levels. At the macroscopic level, the AdaGuiDE search framework revises the existing adaptive mechanism for selecting appropriate DE search strategies by counting the actual contributions in terms of solution quality. In addition, the adaption strategy is extended to the microscopic level where a penalty-based guided DE search is employed to guide the search escaping from local optima through temporarily penalizing the local optima and their neighborhood. Furthermore, a systematic boundary revision scheme is introduced to dynamically adjust the search boundary for locating any potential regions of interest during the search. For a rigorous evaluation of the proposed search framework, the AdaGuiDE algorithm is compared against other well-known meta-heuristic approaches on three sets of benchmark functions involving different dimensions in which the AdaGuiDE algorithm attained remarkable results especially on the high-dimensional and complex optimization problems. More importantly, the proposed AdaGuiDE framework shed lights on many possible directions to further enhance the adaptability of the underlying DE-based search strategies in tackling many challenging real-world applications.},
  archive      = {J_APIN},
  author       = {Li, Zhenglong and Tam, Vincent},
  doi          = {10.1007/s10489-024-05675-9},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10833-10911},
  shortjournal = {Appl. Intell.},
  title        = {AdaGuiDE: An adaptive and guided differential evolution for continuous optimization problems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PatchBreaker: Defending against adversarial attacks by
cutting-inpainting patches and joint adversarial training.
<em>APIN</em>, <em>54</em>(21), 10819–10832. (<a
href="https://doi.org/10.1007/s10489-024-05735-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial patches can disrupt computer vision systems, seriously threatening people’s lives and property security. Existing defense methods seldom consider the generalization for defending against different patches and the compatibility with various models. Furthermore, the severe security situation necessitates the combination of data defense and model defense to build a comprehensive defense system. To address these issues, we propose a defense method named PatchBreaker, which consists of three components. In data defense, PatchBreaker uses the Semantic-Cutter trained by annotated patch images to cut patches and output incomplete images. Next, the Image-Inpainter trained by clean-incomplete image pairs is used to inpaint these incomplete images and output inpainted images. In model defense, the Adversaril-Classifier will be trained by joint adversarial training with clean images and patch images. Finally, PatchBreaker inputs inpainted images into Adversarial-Classifier to output correct results. Comparative experiments show that PatchBreaker outperforms other comparative defense methods in most cases, which indicates the excellent patch generalization and model compatibility of PatchBreaker. Meanwhile, ablation studies show the effectiveness of combining data defense and model defense. Additionally, PatchBreaker has minimal impact on the clean accuracy (about 1 $$\%$$ ). The background, mechanisms and defense effectiveness of PatchBreaker. Intelligent systems are easily disrupted by adversarial patches. Therefore, we propose the PatchBreaker, which consists of data defense and model defense. In data defense, the Semantic-Cutter cuts patches by BiseNetV2 model and output incomplete images, then the Image-Inpainter inpaints incomplete images by a bilateral image inpainting model. In model defense, we utilize clean and patch images to train the Adversarial-Classifier for classifying inpainted images to output correct results. After defense, the green high-light regions of integrated gradients attribution are more regular, which indicates the effectiveness of PatchBreaker},
  archive      = {J_APIN},
  author       = {Huang, Shiyu and Ye, Feng and Huang, Zuchao and Li, Wei and Huang, Tianqiang and Huang, Liqing},
  doi          = {10.1007/s10489-024-05735-0},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10819-10832},
  shortjournal = {Appl. Intell.},
  title        = {PatchBreaker: Defending against adversarial attacks by cutting-inpainting patches and joint adversarial training},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing SLAM efficiency: A comparative analysis of
b-spline surface mapping and grid-based approaches. <em>APIN</em>,
<em>54</em>(21), 10802–10818. (<a
href="https://doi.org/10.1007/s10489-024-05776-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental mapping serves as a crucial element in Simultaneous Localization and Mapping (SLAM) algorithms, playing a pivotal role in ensuring the accurate representation necessary for autonomous robot navigation guided by SLAM. Current SLAM systems predominantly rely on grid-based map representations, encountering challenges such as measurement discretization for cell fitting and grid map interpolation for online posture prediction. Splines present a promising alternative, capable of mitigating these issues while maintaining computational efficiency. This paper delves into the efficiency disparities between B-Spline surface mapping and discretized cell-based approaches, such as grid mapping, within indoor environments. B-Spline Online SLAM and FastSLAM, utilizing Rao-Blackwellized Particle Filter (RBPF), are employed to achieve range-based mapping of the unknown 2D environment. The system incorporates deep learning networks in the B-Spline curve estimation process to compute parameterizations and knot vectors. The research implementation utilizes the Intel Research Lab benchmark dataset to conduct a comprehensive qualitative and quantitative analysis of both approaches. The B-Spline surface approach demonstrates significantly superior performance, evidenced by low error metrics, including an average squared translational error of 0.0016 and an average squared rotational error of 1.137. Additionally, comparative analysis with Vision Benchmark Suite demonstrates robustness across different environments, highlighting the effectiveness of B-Spline SLAM for real-world applications.},
  archive      = {J_APIN},
  author       = {Kanna, B. Rajesh and AV, Shreyas Madhav and Hemalatha, C. Sweetlin and Rajagopal, Manoj Kumar},
  doi          = {10.1007/s10489-024-05776-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10802-10818},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing SLAM efficiency: A comparative analysis of B-spline surface mapping and grid-based approaches},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing UAV-based edge computing: A study on nonhovering
operations and two-stage optimization strategies. <em>APIN</em>,
<em>54</em>(21), 10780–10801. (<a
href="https://doi.org/10.1007/s10489-024-05737-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of 5G/6G wireless communications, mobile edge computing (MEC) technology is widely utilized for efficient data transmission. Unmanned aerial vehicles (UAVs) have emerged as the most recent transmission carriers in this landscape. However, the challenges associated with UAV deployment and path planning are often regarded as NP-hard, nonconvex, and nonlinear problems. Traditional optimization techniques struggle to address these complexities effectively. To address this issue, this study proposes &quot;Edge-UAV&quot;, a novel mobile edge computing system specifically designed for UAVs. The primary objective of Edge-UAV is to minimize energy consumption and optimize the operational efficiency of UAVs. To achieve this goal, this study introduces a two-stage optimization strategy and a nonhovering transmission strategy. First, the coordinate updating operation of the UAVs&#39; hovering points is decoupled from the path planning task. Additionally, the perturbation-inheritance algorithm is employed to enhance the coordinate updating process. In the second stage, the nonhovering transmission strategy enables UAVs to perform data transmission tasks while in flight, effectively optimizing their working time. This paper provides a detailed elucidation of the roles played by these innovative strategies within the Edge-UAV system. To assess the superiority of the proposed strategies, eight sets of comparative experiments involving 60–200 individual devices awaiting data transmission are conducted. The experimental results demonstrate the significant advantages of the Edge-UAV system in terms of reducing total energy consumption and optimizing the operational hours of UAVs. Through comprehensive experimentation and analysis, this study contributes to the advancement of UAV-assisted mobile edge computing in 5G/6G wireless communication networks. The proposed strategies exhibit promising potential for enhancing the efficiency and performance of UAVs.},
  archive      = {J_APIN},
  author       = {Qin, Lishu and Zheng, Ye and Gao, Yu},
  doi          = {10.1007/s10489-024-05737-y},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10780-10801},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing UAV-based edge computing: A study on nonhovering operations and two-stage optimization strategies},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Product quality time series prediction with attention-based
convolutional recurrent neural network. <em>APIN</em>, <em>54</em>(21),
10763–10779. (<a
href="https://doi.org/10.1007/s10489-024-05709-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The product quality is the key index to measure the process of the industrial manufacture. Thanks to the ever-expanding scale of time-series data, the deep learning technology can be regarded as the effective approach to predict the future product quality accurately. In this article, the product quality with time series data is considered and an attention-based convolutional recurrent neural network (ACRNN) is proposed for the prediction of the product quality. Firstly, by reconstructing the time series data into the two dimensions the convolutional layers are built to compress the information of the product quality data, and the more comprehensive features can be extracted. Furthermore, to ensure the prediction accuracy of the time series data process and extract the 2-dimmension feature of the data, the long short-term memory (LSTM) based on recurrent neural network (RNN) layers are constructed. After that, the fully connection layers with attention mechanism is applied to improve the calculation efficiency and accuracy of the models. Finally, the test experiments on the time series data of the industrial product are given and the comparisons show that the effectiveness of the proposed algorithm framework.},
  archive      = {J_APIN},
  author       = {Shi, Yiguan and Chen, Yong and Zhang, Longjie},
  doi          = {10.1007/s10489-024-05709-2},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10763-10779},
  shortjournal = {Appl. Intell.},
  title        = {Product quality time series prediction with attention-based convolutional recurrent neural network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ETransCap: Efficient transformer for image captioning.
<em>APIN</em>, <em>54</em>(21), 10748–10762. (<a
href="https://doi.org/10.1007/s10489-024-05739-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning is a challenging task in computer vision that automatically generates a textual description of an image by integrating visual and linguistic information, as the generated captions must accurately describe the image’s content while also adhering to the conventions of natural language. We adopt the encoder-decoder framework employed by various CNN-RNN-based models for image captioning in the past few years. Recently, we observed that the CNN-Transformer-based models have achieved great success and surpassed traditional CNN-RNN-based models in the area. Many researchers have concentrated on Transformers, exploring and uncovering its vast possibilities. Unlike conventional CNN-RNN-based models in image captioning, transformer-based models have achieved notable success and offer the benefit of handling longer input sequences more efficiently. However, they are resource-intensive to train and deploy, particularly for large-scale tasks or for tasks that require real-time processing. In this work, we introduce a lightweight and efficient transformer-based model called the Efficient Transformer Captioner (ETransCap), which consumes fewer computation resources to generate captions. Our model operates in linear complexity and has been trained and tested on MS-COCO dataset. Comparisons with existing state-of-the-art models show that ETransCap achieves promising results. Our results support the potential of ETransCap as a good approach for image captioning tasks in real-time applications. Code for this project will be available at https://github.com/albertmundu/etranscap .},
  archive      = {J_APIN},
  author       = {Mundu, Albert and Singh, Satish Kumar and Dubey, Shiv Ram},
  doi          = {10.1007/s10489-024-05739-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10748-10762},
  shortjournal = {Appl. Intell.},
  title        = {ETransCap: Efficient transformer for image captioning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Generating crisp boundaries using multi-scale features and
mixed loss function. <em>APIN</em>, <em>54</em>(21), 10731–10747. (<a
href="https://doi.org/10.1007/s10489-024-05784-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, boundary or edge detection has made great progress under the development of convolutional neural networks (CNNs), and some algorithms have achieved a beyond human-level performance. However, CNNs tend to generate blurred edge maps, and their boundary lines are very thick and noisy. In this work, we propose a method named GCB-Net to address this problem. The GCB-Net adopts a simple yet effective fully convolutional U-shape encoder-decoder architecture, with the encoder built on VGG-16 and a novel decoder comprising a feature enhancement module (FEM) and a feature fusion module (FFM). This setup allows our method to produce more discriminative multi-scale features and leverage them for edge detection effectively. Additionally, we construct a novel mixed loss function based on Tversky index, which can guide the network to generate high-quality and crisp edge maps without postprocessing. The experiment results illustrate that the GCB-Net not only enhances the visual effect of edge maps, but also achieves a top performance among several state-of-the-art methods on the BSDS500 dataset (ODS F-score is 0.824) and NYUD-V2 dataset (ODS F-score is 0.766). Our codes are available at https://github.com/AlbertTJU/GCB-Net .},
  archive      = {J_APIN},
  author       = {Liu, Changsong and Zhang, Wei and Liu, Yanyan and Li, Yuming and Jing, Rudong},
  doi          = {10.1007/s10489-024-05784-5},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10731-10747},
  shortjournal = {Appl. Intell.},
  title        = {Generating crisp boundaries using multi-scale features and mixed loss function},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Crowd behavior detection: Leveraging video swin transformer
for crowd size and violence level analysis. <em>APIN</em>,
<em>54</em>(21), 10709–10730. (<a
href="https://doi.org/10.1007/s10489-024-05775-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, crowd behavior detection has posed significant challenges in the realm of public safety and security, even with the advancements in surveillance technologies. The ability to perform real-time surveillance and accurately identify crowd behavior by considering factors such as crowd size and violence levels can avert potential crowd-related disasters and hazards to a considerable extent. However, most existing approaches are not viable to deal with the complexities of crowd dynamics and fail to distinguish different violence levels within crowds. Moreover, the prevailing approach to crowd behavior recognition, which solely relies on the analysis of closed-circuit television (CCTV) footage and overlooks the integration of online social media video content, leads to a primarily reactive methodology. This paper proposes a crowd behavior detection framework based on the swin transformer architecture, which leverages crowd counting maps and optical flow maps to detect crowd behavior across various sizes and violence levels. To support this framework, we created a dataset comprising videos capable of recognizing crowd behaviors based on size and violence levels sourced from CCTV camera footage and online videos. Experimental analysis conducted on benchmark datasets and our proposed dataset substantiates the superiority of our proposed approach over existing state-of-the-art methods, showcasing its ability to effectively distinguish crowd behaviors concerning size and violence level. Our method’s validation through Nvidia’s DeepStream Software Development Kit (SDK) highlights its competitive performance and potential for real-time intelligent surveillance applications.},
  archive      = {J_APIN},
  author       = {Qaraqe, Marwa and Yang, Yin David and Varghese, Elizabeth B and Basaran, Emrah and Elzein, Almiqdad},
  doi          = {10.1007/s10489-024-05775-6},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10709-10730},
  shortjournal = {Appl. Intell.},
  title        = {Crowd behavior detection: Leveraging video swin transformer for crowd size and violence level analysis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight hierarchical graph convolutional model for
knowledge graph representation learning. <em>APIN</em>, <em>54</em>(21),
10695–10708. (<a
href="https://doi.org/10.1007/s10489-024-05787-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have emerged as powerful tools for handling graph-structured data. Many knowledge graph embedding models leverage GCNs as encoders to learn the relationships between central entities and their neighbors, showing impressive performance in the knowledge graph completion task. However, the incorporation of GCNs increases the computational burden of the model. Moreover, due to the complex graph structure of knowledge graphs, treating all neighboring entities equally will cause the model to lose its ability to capture important information. To address these challenges, we present a lightweight hierarchical graph convolutional network (Light-HGCN). Light-HGCN removes feature transformation and selectively uses nonlinearity activation in standard GCNs to accelerate model convergence. Additionally, Light-HGCN introduces a hierarchical attention mechanism to determine the neighboring weights to capture complex graph structures. Light-HGCN achieves promising performance for the link prediction task across multiple benchmark datasets. Ablation experiments further illustrate the effectiveness of the hierarchical attention mechanism. The analysis of feature transformation and nonlinearity activation in GCNs on the KGC task indicates that lightweight GCNs can enhance computational efficiency while preserving promising performance.},
  archive      = {J_APIN},
  author       = {Zhang, Jinglin and Shen, Bo},
  doi          = {10.1007/s10489-024-05787-2},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10695-10708},
  shortjournal = {Appl. Intell.},
  title        = {A lightweight hierarchical graph convolutional model for knowledge graph representation learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised regression with label-guided adaptive graph
optimization. <em>APIN</em>, <em>54</em>(21), 10671–10694. (<a
href="https://doi.org/10.1007/s10489-024-05766-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the semi-supervised regression task, both the similarity of paired samples and the limited label information serve as core indicators. Nevertheless, most traditional semi-supervised regression methods cannot make full use of both simultaneously. To alleviate the above deficiency, this paper proposes a novel semi-supervised regression with label-guided adaptive graph optimization (LGAGO-SSR). Basically, LGAGO-SSR involves two phases: graph representation and label-guided adaptive graph construction. The first phase seeks two low-dimensional manifold spaces based on two similarity matrices. The second phase aims at adaptively learning these similarity matrices by integrating the data structure information in both the low-dimensional manifold spaces and the label spaces. Each phase has its optimization problems, and the final solution is obtained by iteratively solving problems in two phases. Additionally, the idea of decomposition optimization in twin support vector regression (TSVR) is used to accelerate the training of our LGAGO-SSR. Regression results on 12 benchmark datasets with different unlabeled rates demonstrate the effectiveness of LGAGO-SSR in semi-supervised regression tasks.},
  archive      = {J_APIN},
  author       = {Zheng, Xiaohan and Zhang, Li and Yan, Leilei and Zhao, Lei},
  doi          = {10.1007/s10489-024-05766-7},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10671-10694},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised regression with label-guided adaptive graph optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Unsupervised attribute reduction based on neighborhood
dependency. <em>APIN</em>, <em>54</em>(21), 10653–10670. (<a
href="https://doi.org/10.1007/s10489-024-05604-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood rough set theory is an important computational model in granular computing and has been successfully applied in many areas. One of its most prominent applications is in attribute reduction. However, most current attribute reduction methods for neighborhood rough sets are supervised or semi-supervised, which makes them unable to handle datasets without decision information. To address this, we propose an unsupervised attribute reduction strategy based on neighborhood dependency. First, a neighborhood rough set model based on conditional attribute sets is constructed. Then, based on all individual attribute subsets in the datasets, the importance of the attributes is defined to indicate the significance of the candidate attributes. Furthermore, a neighborhood dependency-based unsupervised attribute reduction (NDUAR) algorithm is designed. Finally, NDUAR is compared with existing algorithms on publicly available datasets. The experimental results show that NDUAR can select fewer attributes to maintain or improve the performance of the clustering algorithm. The effectiveness of the algorithm proposed in this paper is thereby confirmed.},
  archive      = {J_APIN},
  author       = {Li, Yi and Zhang, Benwen and Yuan, Zhong and Liu, Yuncheng and Lei, Shenhong and Tan, Xingqiang},
  doi          = {10.1007/s10489-024-05604-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10653-10670},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised attribute reduction based on neighborhood dependency},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep-SEA: A deep learning based patient specific
multi-modality post-cancer survival estimation architecture.
<em>APIN</em>, <em>54</em>(21), 10640–10652. (<a
href="https://doi.org/10.1007/s10489-024-05794-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer survival estimation is essential for post-cancer patient care, cancer management policy building, and the development of tailored treatment plans. Existing survival estimation methods use censored data; therefore, standard machine learning methods can not be used directly. Some censoring-based semi-machine learning methods have recently been proposed; however, these methods pose challenges. They are less patient-specific and non-linear. Furthermore, they rely on single-modality features. These drawbacks result in lower survival estimation performance. To address these issues, this work proposes a framework named Deep-SEA. Compared to the state-of-the-art, Deep-SEA uses multi-modality features, i.e., clinical, radiology, and histology features. These features are analyzed with statistical methods, and only significant features are selected. Then, the baseline hazard of the Cox model is estimated using Breslow’s estimator, which is optimized using stochastic gradient descent. Finally, the risk function, i.e., the parameters of our model, are estimated via an ANN with time as additional input. ANN makes it non-linear while training on the patient-specific features makes it more patient-specific than the state-of-the-art. We train and evaluate Deep-SEA on five datasets, including head, neck, and colorectal-liver cancer. We have achieved a Concordance-index (C-index) score of 0.7181, the highest compared to the state-of-the-art. Results and ablation studies on Deep-SEA suggest that the proposed method improves cancer survival estimation and can be applied to other estimations, such as cancer recurrence estimation.},
  archive      = {J_APIN},
  author       = {Ahmad, Ibtihaj and Riaz, Saleem},
  doi          = {10.1007/s10489-024-05794-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10640-10652},
  shortjournal = {Appl. Intell.},
  title        = {Deep-SEA: A deep learning based patient specific multi-modality post-cancer survival estimation architecture},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Radar-camera fusion for 3D object detection with
aggregation transformer. <em>APIN</em>, <em>54</em>(21), 10627–10639.
(<a href="https://doi.org/10.1007/s10489-024-05718-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the continuous development of autonomous driving, monocular 3D object detection has garnered increasing attention as a crucial research topic. However, the precision of 3D object detection is impeded by the limitations of monocular camera sensors, which struggle to capture accurate depth information. To address this challenge, a novel Aggregation Transformer Network (ATNet) is introduced, featuring Cross-Attention based Positional Aggregation and Dual Expansion-Squeeze based Channel Aggregation. The proposed ATNet adaptively fuses radar and camera data at both positional and channel levels. Specifically, the Cross-Attention based Positional Aggregation leverages camera-radar information to compute a non-linear attention coefficient, which reinforces salient features and suppresses irrelevant ones. The Dual Expansion-Squeeze based Channel Aggregation utilizes refined processing techniques to integrate radar and camera data adaptively at the channel level. Furthermore, to enhance feature-level fusion, we propose a multi-scale radar-camera fusion strategy that integrates radar information across multiple stages of the camera subnet’s backbone, allowing for improved object detection across various scales. Extensive experiments conducted on the widely-used nuScenes dataset validate that our proposed Aggregation Transformer, when integrated into superb monocular 3D object detection models, delivers promising results compared to existing methods.},
  archive      = {J_APIN},
  author       = {Li, Jun and Zhang, Han and Wu, Zizhang and Xu, Tianhao},
  doi          = {10.1007/s10489-024-05718-1},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10627-10639},
  shortjournal = {Appl. Intell.},
  title        = {Radar-camera fusion for 3D object detection with aggregation transformer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the transferability of adversarial attacks via
self-ensemble. <em>APIN</em>, <em>54</em>(21), 10608–10626. (<a
href="https://doi.org/10.1007/s10489-024-05728-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have been used extensively for diverse visual tasks, including object detection, face recognition, and image classification. However, they face several security threats, such as adversarial attacks. To improve the resistance of neural networks to adversarial attacks, researchers have investigated the security issues of models from the perspectives of both attacks and defenses. Recently, the transferability of adversarial attacks has received extensive attention, which promotes the application of adversarial attacks in practical scenarios. However, existing transferable attacks tend to trap into a poor local optimum and significantly degrade the transferability because the production of adversarial samples lacks randomness. Therefore, we propose a self-ensemble-based feature-level adversarial attack (SEFA) to boost transferability by randomly disrupting salient features. We provide theoretical analysis to demonstrate the superiority of the proposed method. In particular, perturbing the refined feature importance weighted intermediate features suppresses positive features and encourages negative features to realize adversarial attacks. Subsequently, self-ensemble is introduced to solve the optimization problem, thus enhancing the diversity from an optimization perspective. The diverse orthogonal initial perturbations disrupt these features stochastically, searching the space of transferable perturbations exhaustively to avoid poor local optima and improve transferability effectively. Extensive experiments show the effectiveness and superiority of the proposed SEFA, i.e., the success rates against undefended models and defense models are improved by 7.7 $$\%$$ and 13.4 $$\%$$ , respectively, compared with existing transferable attacks. Our code is available at https://github.com/chengshuyan/SEFA .},
  archive      = {J_APIN},
  author       = {Cheng, Shuyan and Li, Peng and Liu, Jianguo and Xu, He and Yao, Yudong},
  doi          = {10.1007/s10489-024-05728-z},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10608-10626},
  shortjournal = {Appl. Intell.},
  title        = {Improving the transferability of adversarial attacks via self-ensemble},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning the structure of multivariate regression chain
graphs by testing complete separators in prime blocks. <em>APIN</em>,
<em>54</em>(21), 10596–10607. (<a
href="https://doi.org/10.1007/s10489-024-05752-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an algorithm to construct a bidirectional causal graph using an augmented graph. The algorithm decomposes the augmented graph, significantly reducing the size of the variable set required for conditional independence testing. Simultaneously, it preserves the fundamental structure of the augmented graph after decomposition, saving time and cost in constructing a global skeleton graph. Through experiments on discrete and continuous datasets, the algorithm demonstrates a clear advantage in runtime compared to traditional methods. In large-scale sparse networks, the training time is only about one-tenth of traditional methods. Additionally, the algorithm shows improvement in terms of construction error. Since the input to the algorithm is an augmented graph, this paper also discusses the impact on construction error when using both real and generated augmented graphs as input. Furthermore, the concept of markov blanket is extended to multivariate regression chain graphs, providing a method for rapidly constructing augmented graphs given certain prior knowledge.},
  archive      = {J_APIN},
  author       = {Rao, Mingxuan and Lv, Shu and Shi, Kaibo},
  doi          = {10.1007/s10489-024-05752-z},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10596-10607},
  shortjournal = {Appl. Intell.},
  title        = {Learning the structure of multivariate regression chain graphs by testing complete separators in prime blocks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Swin transformer-based traffic video text tracking.
<em>APIN</em>, <em>54</em>(21), 10581–10595. (<a
href="https://doi.org/10.1007/s10489-024-05710-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent systems, such as driving assistance systems, can assist drivers by providing basic traffic, road blockage and possible route information to enable safe driving. The goal of scene text tracking in driver assistance systems is to locate and track scene text, milestone signs, traffic panels and road signs in real time. Therefore, the accuracy and real-time performance of scene text localization tracking play vital roles in intelligent driving assistance systems. However, traffic video text tracking often has the problems of missed and false detections because of illumination occlusion and similar appearances. In this paper, we propose a new Swin transformer-based traffic video text tracking method, known as STVT, which is composed of a Siamese SwinDC transformer module, a deformable text detection module, and a text matching module. The STVT method employs the Siamese SwinDC transformer module, which performs text detection by considering both temporal and spatial dimensions, mitigating the issue of missed detections caused by occlusion. The text matching module combines the semantic, visual, and geometric features of text instances to effectively differentiate visually similar text instances. Extensive experiments demonstrated that our proposed STVT method outperformed the state-of-the-art methods on various benchmark datasets. On the ICDAR2015 dataset, compared with those of the Free method, the mostly matched (MM) result increased by 32.0% (702 vs. 926), and the mostly lost (ML) result decreased by 33.2% (568 vs. 850). The visualization results demonstrated that the proposed STVT model can accurately detect and track occluded text instances in traffic videos. On the ICDAR2023 dataset, our method achieved a 6.01% improvement in MOTA compared to that of the TransDETR method, demonstrating that our proposed method is effective for small and dense text detection problems. In addition, qualitative and quantitative analyses confirmed the effectiveness and real-time performance of our proposed STVT method.},
  archive      = {J_APIN},
  author       = {Yu, Jinyao and Qian, Jiangbo and Xin, Yu and Wang, Chong and Dong, Yihong},
  doi          = {10.1007/s10489-024-05710-9},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10581-10595},
  shortjournal = {Appl. Intell.},
  title        = {Swin transformer-based traffic video text tracking},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view pre-trained transformer via hierarchical capsule
network for answer sentence selection. <em>APIN</em>, <em>54</em>(21),
10561–10580. (<a
href="https://doi.org/10.1007/s10489-024-05513-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer selection requires technology that effectively captures in-depth semantic information between the question and the corresponding answer. Most existing studies focus on using linear or pooling operations to directly classify the output representation, resulting in the absence of critical information and the emergence of single-label predictions. To address these issues, we propose a novel Multi-view Pre-trained Transformer with Hierarchical Capsule Network (MPT-HCN). Specifically, we propose a Hierarchical Capsule Network composed of three capsule networks to independently process high-dimensional sparse information of words, semantic information of similar expressions, and feature classification information so that multiple attributes can be fully considered and accurately clustered. Moreover, we consider the impact of the intermediate encoder layer output information on the overall sequence semantic representation and propose a Multi-view Information Fusion that obtains the final semantic representation information by weighted fusion of the output information of all encoder layers, thereby avoiding the appearance of a single prediction label. Extensive experiments on five typical representative datasets, especially on the WikiQA dataset, show that our model MPT-HCN (RL) achieves an excellent performance of 0.939 on MAP and 0.942 on MRR, which is a significant improvement of 3.9% and 2.7% respectively, compared to the state-of-the-art baseline model.},
  archive      = {J_APIN},
  author       = {Li, Bing and Yang, Peng and Sun, Yuankang and Hu, Zhongjian and Yi, Meng},
  doi          = {10.1007/s10489-024-05513-y},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10561-10580},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view pre-trained transformer via hierarchical capsule network for answer sentence selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting sparsely annotated shadow detection. <em>APIN</em>,
<em>54</em>(21), 10541–10560. (<a
href="https://doi.org/10.1007/s10489-024-05740-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsely annotated image segmentation has gained popularity due to its ability to significantly reduce the labeling burden on training data. However, existing methods still struggle to learn complete object structures, especially for complex shadow objects. This paper discusses two prevalent issues existing in previous methods, i.e., generating noisy pseudo labels and misdetecting ambiguous regions. To tackle these challenges, we propose a novel weakly-supervised learning framework to boost sparsely annotated shadow detection. Concretely, a reliable label propagation (RLP) scheme is first designed to diffuse sparse annotations into unlabeled regions, thereby generating denser pseudo shadow masks. This scheme effectively reduces the number of noisy labels by incorporating uncertainty analysis. Then, a multi-cue semantic calibration (MSC) strategy is presented to refine the semantic features extracted from the backbone by employing edge, global, and adjacent priors. Embedded with MSC, the detection network becomes more discriminative against ambiguous regions. By combining RLP and MSC, the proposed weakly-supervised framework can detect complete and accurate shadow regions from sparse annotations. Experimental results on three benchmark datasets demonstrate that our method achieves comparable performance to recent fully-supervised methods, while requiring only about 4.5% of the pixels to be labeled. Boosting sparsely annotated shadow detection},
  archive      = {J_APIN},
  author       = {Zhou, Kai and Shao, Yanli and Fang, Jinglong and Wei, Dan and Sun, Wanlu},
  doi          = {10.1007/s10489-024-05740-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10541-10560},
  shortjournal = {Appl. Intell.},
  title        = {Boosting sparsely annotated shadow detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entity clustering-based meta-learning for link prediction in
evolutionary fault diagnosis event graphs. <em>APIN</em>,
<em>54</em>(21), 10525–10540. (<a
href="https://doi.org/10.1007/s10489-024-05749-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis plays an important role in intelligent manufacturing. Knowledge modelling is often used for intelligent fault diagnosis purposes, and link prediction is performed in knowledge graphs to locate and trace system faults. However, due to the sparsity of data during the training process, meta-learning methods have been introduced, but they can lead to the overgeneralization of the training parameters and affect the accuracy of link prediction. To address this issue, this paper proposes an entity clustering-based meta-learning model for link prediction in evolutionary fault diagnosis event graphs. The model consists of three parts: triple clustering based on graph convolutional networks, meta-learning for divide-and-conquer data, and meta-learning model reinforcement based on scene information. Through data preprocessing and additional model fitting steps, the weaknesses of the existing meta-learning approaches regarding dissimilated data learning are overcome. The experimental results show that compared with traditional embedding-based models and the existing meta-learning-based link prediction methods, the proposed method can not only improve the link prediction accuracy achieved on public datasets but also have attain performance on datasets with fault diagnosis background information.},
  archive      = {J_APIN},
  author       = {Wang, Tian and Fang, Qiang and Chi, Meng and Shen, Jianming and Zhang, Xuebing and Shan, Dandan},
  doi          = {10.1007/s10489-024-05749-8},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10525-10540},
  shortjournal = {Appl. Intell.},
  title        = {Entity clustering-based meta-learning for link prediction in evolutionary fault diagnosis event graphs},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dirichlet stochastic weights averaging for graph neural
networks. <em>APIN</em>, <em>54</em>(21), 10516–10524. (<a
href="https://doi.org/10.1007/s10489-024-05708-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of Graph Neural Networks (GNNs) has grown significantly because GNNs handle relational datasets such as social networks and citation networks. However, the usual relational dataset is sparse, and GNNs are easy to overfit to the dataset. To alleviate the overfitting problems, model ensemble methods are widely studied and adopted. However, model ensemble methods for GNNs are not well explored. In this study, we propose simple but effective model ensemble methods for GNNs. This is the first study that adopts stochastic weights averaging (SWA) for GNNs. Furthermore, we propose a new model ensemble method, Dirichlet stochastic weighs averaging (DSWA). DSWA adopts the running averages of the trained weights with random proportions sampled by Dirichlet distributions. DSWA provides the diverse model and its ensembles on inference time without the training time increases. We validate our models on the Cora, the Citeseer, and Pubmed datasets under usual settings and few-shot learning settings. We observe that the performance of current GNNs deteriorates when the number of specified data is limited. DSWA improves the performance of few-shot node classification tasks as well as the general node classification tasks.},
  archive      = {J_APIN},
  author       = {Park, Minhoi and Chang, Rakwoo and Song, Kyungwoo},
  doi          = {10.1007/s10489-024-05708-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10516-10524},
  shortjournal = {Appl. Intell.},
  title        = {Dirichlet stochastic weights averaging for graph neural networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance metrics for multi-step forecasting measuring
win-loss, seasonal variance and forecast stability: An empirical study.
<em>APIN</em>, <em>54</em>(21), 10490–10515. (<a
href="https://doi.org/10.1007/s10489-024-05715-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the evaluation of multi-step point forecasting models. Currently, deep learning models for multi-step forecasting are evaluated on datasets by selecting one error metric that is aggregated across the time series and the forecast horizon. This approach hides insights that would otherwise be useful for practitioners when evaluating and selecting forecasting models. We propose four novel metrics to provide additional insights when evaluating models: 1) a win-loss metric that shows how models perform across time series in the dataset , allowing the practitioner to check whether the model is superior for all series or just a subset of series. 2) a variance weighted metric that accounts for differences in variance across the seasonal period. It can be used to evaluate models for seasonal datasets such as rush hour traffic prediction, where it is desirable to select the model that performs best during the periods of high uncertainty. 3) a delta horizon metric measuring how much models update their forecast for a period in the future over the forecast horizon. Less change to the forecast means more stability over time and is desirable for most forecasting applications. 4) decomposed errors that relate the forecasting error to trend, seasonality, and noise. Decomposing the errors allows the practitioners to identify for which components the model is making more errors and adjust the model accordingly. To show the applicability of the proposed metrics, we implement four deep learning architectures and conduct experiments on five benchmark datasets. We highlight several use cases for the proposed metrics and discuss the applicability in light of the empirical results.},
  archive      = {J_APIN},
  author       = {Strøm, Eivind and Gundersen, Odd Erik},
  doi          = {10.1007/s10489-024-05715-4},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10490-10515},
  shortjournal = {Appl. Intell.},
  title        = {Performance metrics for multi-step forecasting measuring win-loss, seasonal variance and forecast stability: An empirical study},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal data generation based on separated attention
for ENSO prediction. <em>APIN</em>, <em>54</em>(21), 10473–10489. (<a
href="https://doi.org/10.1007/s10489-024-05547-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The El Niño-Southern Oscillation (ENSO) phenomenon is often accompanied by multiple extreme hazards—thus, its accurate prediction is crucial to the prevention of such crises. Recently, machine learning algorithms have exhibited excellent ENSO prediction performance. However, most models are committed to directly capture the relationship between the Nino3.4 index (an important indicator of ENSO phenomenon monitoring) and historical ocean data, which reduces the interpretability of the algorithms. In this study, we propose a new method for ENSO prediction with better interpretability. In particular, we design a spatiotemporal data generative model (SADG model) based on the separated attention mechanism and apply it to ENSO prediction, completing the generation of sea surface temperature anomaly data for the next 20 months and achieving proficient prediction of the Nino3.4 index with a prediction period of one and a half years. The experimental results demonstrate that the proposed model exhibits high algorithm efficiency without any prediction preference, and outperforms all baseline models in ENSO prediction.},
  archive      = {J_APIN},
  author       = {Lin, Lianlei and Wang, Junkai and Tan, Aidi and Chen, Jiawei},
  doi          = {10.1007/s10489-024-05547-2},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10473-10489},
  shortjournal = {Appl. Intell.},
  title        = {Spatio-temporal data generation based on separated attention for ENSO prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Securing IP in edge AI: Neural network watermarking for
multimodal models. <em>APIN</em>, <em>54</em>(21), 10455–10472. (<a
href="https://doi.org/10.1007/s10489-024-05746-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of edge AI systems where deep learning is paramount, protecting the intellectual property (IP) of multimodal neural network models is crucial. Current watermarking solutions often bypass the intricacies of multimodal models and the unique constraints of edge environments. Addressing this, a novel watermarking scheme specifically devised for multimodal neural networks is introduced, marking a significant stride in securing these models against IP theft and unauthorized use. A discrete watermark is ingeniously embedded within each modality of a multimodal model, synthesizing a comprehensive watermark that spans the entire model. This method ensures IP protection across varied data types without hampering the model’s performance or imposing undue computational demands, making it ideal for resource-limited edge devices. By leveraging the redundancies inherent in multimodal data, watermarks are embedded efficiently, maintaining model integrity and operational effectiveness. A robust verification mechanism is implemented, accurately identifying watermark presence across modalities with minimal computational overhead. Empirical validation on a benchmark dataset demonstrates the method’s efficacy in embedding watermarks discreetly while preserving the model’s original task performance, showing a 1 to 4% increase in watermark detection rates and a 6 to 10% reduction in false positives compared to existing approaches. This positions the scheme as an effective strategy for IP protection in multimodal neural network models, especially suited for the computational economy required in edge AI systems. The work advances neural network watermarking and addresses the urgent need for scalable IP protection solutions in the evolving AI landscape.},
  archive      = {J_APIN},
  author       = {Nie, Hewang and Lu, Songfeng},
  doi          = {10.1007/s10489-024-05746-x},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10455-10472},
  shortjournal = {Appl. Intell.},
  title        = {Securing IP in edge AI: Neural network watermarking for multimodal models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single-source unsupervised domain adaptation for
cross-subject MI-EEG classification based on discriminative information.
<em>APIN</em>, <em>54</em>(21), 10438–10454. (<a
href="https://doi.org/10.1007/s10489-024-05662-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) provides a wealth of physiological and psychological information. Decoding EEG signals enables machines to recognize brain activity, a crucial aspect in brain-computer interaction and medical rehabilitation. However, the non-stationarity and inter-individual variability of EEG signals pose challenges for existing EEG signal classification models to achieve the desired level of cross-subject generalization, limiting the practical applications of EEG-based brain computer interface systems. Unsupervised Domain Adaptation (UDA) aims to improve the model’s generalization performance on the target domain by minimizing the discrepancies between the source and target domain data distributions. Many researchers treat different subjects as distinct domains and utilize Unsupervised Domain Adaptation (UDA) in transfer learning to guide the model for effective cross-subject EEG Classification. Strategies involve reducing distribution discrepancies between the source and target domains by minimizing well-designed discrepancy metrics or using an adversarial discriminator to capture domain-invariant features. However, neglecting category-discriminatory (abbreviated as discriminative) features leads to the limited effectiveness of these domain-level alignment methods. To tackle these issues, we propose the Discriminative Clustering Domain Adaptation Network (DCDAN), aimed at utilizing an unsupervised approach to construct discriminative information for facilitating Unsupervised Domain Adaptation (UDA) in achieving category-level feature alignment between the source and target domains. Specifically, we employ a clustering algorithm based on adversarial domain adaptation to associate pseudo-labels with target domain samples. Implementing a self-supervised training framework enables the model to acquire discriminative features. Moreover, we introduce the Pseudo Label-Common Spatial Pattern (PL-CSP) component, which integrates the prediction confidence of pseudo-labels from target domain samples with discriminative information from source domain samples through a covariance matrix weighting strategy based on sample confidence. This integration enhances the robustness of the learned spatial filter on the target domain. Experimental results on public datasets demonstrate the effectiveness of our proposed method in extracting more discriminative features.},
  archive      = {J_APIN},
  author       = {Shi, Yufan and Wang, Yuhao and Meng, Hua},
  doi          = {10.1007/s10489-024-05662-0},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10438-10454},
  shortjournal = {Appl. Intell.},
  title        = {Single-source unsupervised domain adaptation for cross-subject MI-EEG classification based on discriminative information},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The fuzzy inference system based on axiomatic fuzzy sets
using overlap functions as aggregation operators and its approximation
properties. <em>APIN</em>, <em>54</em>(21), 10414–10437. (<a
href="https://doi.org/10.1007/s10489-024-05716-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As significant vehicles for applying fuzzy set theories, fuzzy inference systems (FISs) have been widely utilized in artificial intelligence. However, challenges such as computational complexity and subjective design persist in FIS implementation. To address these issues, this paper introduces the fuzzy inference system based on axiomatic fuzzy sets (FIS-AFSs), which includes a fuzzy rule base and a fuzzy inference engine. This system eliminates the need for subjective decisions in the selection of fuzzification and defuzzification methods. The theoretical foundation of the approach involves defining the multi-dimensional vague partition (VP) of the multi-dimensional universe using an overlap function to aggregate one-dimensional VPs. Additionally, an axiomatic fuzzy set (AFS) on the multi-dimensional universe is defined. Building on this foundation, algorithms for single-input single-output (SISO) and multi-input single-output (MISO) fuzzy inference are developed using AFSs, eliminating the need for subjective fuzzy implication operators. The FIS-AFSs, with its universal approximation property and theoretical approximation precision, are then analyzed. Experimental tests are conducted to evaluate the approximation capabilities of the FIS-AFSs. Results from both theoretical analysis and experimental testing demonstrate that FIS-AFSs can achieve high approximation precision.},
  archive      = {J_APIN},
  author       = {Shen, Hanhan and Yao, Qin and Pan, Xiaodong},
  doi          = {10.1007/s10489-024-05716-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10414-10437},
  shortjournal = {Appl. Intell.},
  title        = {The fuzzy inference system based on axiomatic fuzzy sets using overlap functions as aggregation operators and its approximation properties},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). MAPM: Multiscale attention pre-training model for TextVQA.
<em>APIN</em>, <em>54</em>(21), 10401–10413. (<a
href="https://doi.org/10.1007/s10489-024-05727-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text Visual Question Answering (TextVQA) task aims to enable models to read and answer questions based on images with text. Existing attention-based methods for TextVQA tasks often face challenges in effectively aligning local features between modalities during multimodal information interaction. This misalignment hinders their performance in accurately answering questions based on images with text. To address this issue, the Multiscale Attention Pre-training Model (MAPM) is proposed to enhance multimodal feature fusion. MAPM introduces the multiscale attention modules, which facilitate finegrained local feature enhancement and global feature fusion across modalities. By adopting these modules, MAPM achieves superior performance in aligning and integrating visual and textual information. Additionally, MAPM benefits from being pre-trained with scene text, employing three pre-training tasks: masked language model, visual region matching, and OCR visual text matching. This pre-training process establishes effective semantic alignment relationships among different modalities. Experimental evaluations demonstrate the superiority of MAPM, achieving a 1.2% higher accuracy compared to state-of-the-art models on the TextVQA dataset, especially when handling numerical data within images. Multiscale Attention Pre-training Model (MAPM) is proposed to enhance local fine-grained features (Joint Attention Module) and effectively addresses redundancy in global features (Global Attention Module) in text VQA task. Three pre-training tasks are designed to enhance the model’s expressive power and address the issue of cross modal semantic alignment},
  archive      = {J_APIN},
  author       = {Yang, Yue and Yu, Yue and Li, Yingying},
  doi          = {10.1007/s10489-024-05727-0},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10401-10413},
  shortjournal = {Appl. Intell.},
  title        = {MAPM: Multiscale attention pre-training model for TextVQA},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated diagnosis of cervical spine physiological
curvature based on deep neural networks with transformer by using nmODE.
<em>APIN</em>, <em>54</em>(21), 10386–10400. (<a
href="https://doi.org/10.1007/s10489-024-05736-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the automated diagnosis of physiological curvature in the cervical spine, with an emphasis on feature point localization. Cervical spine deformity is prevalent, and the Cobb angle is widely recognized as the gold standard for diagnosing and treating it. However, manual measurement is time-consuming, labor-intensive, and heavily reliant on clinical experience. Therefore, there is an urgent need for a high-precision automatically detecting algorithm to meet the clinical requirements of orthopedic surgeons. Traditional methods are constrained by complex steps and limited data, which pose challenges. Therefore, we propose an efficient framework that formulates an automatic diagnosis of cervical spine physiological curvature based on a novel deep neural network. By leveraging the excellent properties of neural memory Ordinary Differential Equation (nmODE) in long-term memory retention and nonlinear representation capabilities, we effectively improve the network’s performance in keypoint detection branching tasks. Additionally, we integrate a novel hybrid transformer based on residual structures and a multi-stage dilated dynamic convolution to alleviate false detections caused by X-ray obstruction and shadows, and the integration also captures the relationship between vertebrae and landmarks to compensate for the lack of detailed information. We constructed a dataset named CSL-947X, comprising 947 cervical spine lateral X-ray images of patients to train and evaluate our proposed model. Extensive experiments on CSL-947X demonstrate that our framework achieves higher accuracy and outperforms most state-of-the-art methods. These results highlight the effectiveness of the proposed architecture and its potential feasibility as a clinical decision-making tool for healthcare professionals.},
  archive      = {J_APIN},
  author       = {Li, Qingtai and Yang, Yi and Xu, Lei and Shen, Yiwei and Yi, Nengmin and Yi, Zhang and Ergu, Daji and Cai, Ying},
  doi          = {10.1007/s10489-024-05736-z},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10386-10400},
  shortjournal = {Appl. Intell.},
  title        = {Automated diagnosis of cervical spine physiological curvature based on deep neural networks with transformer by using nmODE},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differentiating broadcast from viral: A causal inference
approach for information diffusion analysis. <em>APIN</em>,
<em>54</em>(21), 10374–10385. (<a
href="https://doi.org/10.1007/s10489-024-05723-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying information diffusion patterns is critical to many information analysis areas, e.g., misleading information detection. However, diffusion pattern classification remains challenging when multiple users are involved. To address this challenge, this study aims to classify how information diffuses, distinguishing between broadcast and viral spreading, solely through the analysis of observational data from retweet networks on X (formerly known as Twitter). In broadcasting, most users directly receive information. However, viral spreading allows users the opportunity to receive information from a variety of sources. Therefore, viral spreading increases the likelihood of identifying misleading information. Existing methods classify diffusion types mainly through structural virality, which relies on the average distance between the users. However, when dealing with diffusion networks involving two or more information sources, these approaches can potentially lead to confusion regarding causality. To tackle this problem, we develop a deterministic causal inference method for categorizing information diffusion types. To the best of our knowledge, this is the first study investigating information diffusion types based on causality. This approach can be used to assess source credibility and assist in detecting misleading information. It can also be extended to other social media platforms.},
  archive      = {J_APIN},
  author       = {Riazi, Amin and Wang, Yingfeng},
  doi          = {10.1007/s10489-024-05723-4},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10374-10385},
  shortjournal = {Appl. Intell.},
  title        = {Differentiating broadcast from viral: A causal inference approach for information diffusion analysis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Chaotic image encryption based on partial face recognition
and DNA diffusion. <em>APIN</em>, <em>54</em>(21), 10360–10373. (<a
href="https://doi.org/10.1007/s10489-024-05613-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an innovative image encryption algorithm that leverages partial face recognition and DNA diffusion, building upon advancements in chaotic image encryption and face recognition technologies. The key is generated using the secure SHA-512 algorithm, while the chaotic sequence for the encryption algorithm is derived from the Chen system. This paper begins by employing facial recognition technology to identify and focus on specific facial regions within an image. Subsequently, DNA diffusion is applied to encrypt the recognized face segment via a diffusion-scrambling encryption process. Following this, the entire image undergoes diffusion utilizing the devised diffusion rules. Finally, a uniform scrambling operation based on Fisher-Yeats is performed on the entire image. The experimental results and safety analysis show that the information entropy can exceed 7.9973, the average correlation can be less than 0.0023, the pixel number change rate can reach 99.6052%, and the unified average change intensity can reach 33.4644%, all of which are very close to the ideal values.},
  archive      = {J_APIN},
  author       = {Teng, Lin and Du, Longbiao and Leng, Ziyu and Wang, Xiaoli},
  doi          = {10.1007/s10489-024-05613-9},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10360-10373},
  shortjournal = {Appl. Intell.},
  title        = {Chaotic image encryption based on partial face recognition and DNA diffusion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph-based recommendation with knowledge noise
reduction and data augmentation. <em>APIN</em>, <em>54</em>(21),
10333–10359. (<a
href="https://doi.org/10.1007/s10489-024-05657-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of recommendation algorithms, Knowledge Graphs are often utilized as supplementary information to enhance recommendation accuracy. However, while applying Knowledge Graphs enriches recommendation information, it also introduces potentially misleading effects due to Knowledge Graph noise. To address these challenges, we propose a method to achieve Knowledge Graph Noise Reduction and Knowledge Perception Enhancement through positive contrast learning. The method employs Fourier Transform, Inverse Transform, and Convolution Optimization Computation techniques to transform and analyze Knowledge Graph triplet information in the frequency domain. The process filters and reduces noise through Convolution Optimization Computation by integrating frequency domain feature information, eliminating misleading relational information that cannot effectively infer user preferences. Subsequently, Positive Contrastive Learning enhances the acquired ternary information and improves the applicability of the information to recognize user preference information accurately. The proposed method reduces noise and enhances knowledge perception, strengthens the application of strong relationships, reduces the impact of weak relationships, and improves recommendation accuracy by utilizing frequency-domain features. The KG-CFCL_RippleNet and KG-CFCL_MKR models validate the effectiveness of this optimization method, and significant improvements are achieved in the area of book, music, and movie recommendations compared to existing models. Experiments demonstrate the advantages of KG-CFCL in terms of noise reduction, Knowledge Perception Enhancement, and data optimization, improving the interpretability of the models.},
  archive      = {J_APIN},
  author       = {Yang, Zhisheng and Li, Li},
  doi          = {10.1007/s10489-024-05657-x},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10333-10359},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge graph-based recommendation with knowledge noise reduction and data augmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSA-net: A temporal knowledge graph completion method with
temporal-structural adaptation. <em>APIN</em>, <em>54</em>(21),
10320–10332. (<a
href="https://doi.org/10.1007/s10489-024-05734-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph Completion (TKGC) aims to infer missing facts in Temporal Knowledge Graphs (TKGs), where facts are stored along with significant temporal information. However, existing TKGC methods only consider message passing on pairwise relations and fail to capture the complex temporal structural dependencies at the levels of time, predicate and entity in TKGs. To fill this gap, we collect high-frequency patterns in TKGs using mathematical statistics and propose a Temporal-Structural Adaptation Network that is equipped with three specific components, time-component, pred-component, and ent-component, as well as one general component, res-component. Concretely, specific components utilize the time consistency pattern to capture facts with significant regularity in time, and complex structural dependencies in TKGs are handled through predicate concurrency and entity collaboration. Moreover, considering low-frequency and nonoccurrence facts, an additional general component is introduced to make predictions on all entities. The outputs of different components are adaptively fused to vote for the final result. Extensive experiments on six benchmarks demonstrate that our method outperforms state-of-the-art baselines.},
  archive      = {J_APIN},
  author       = {Xie, Ruzhong and Ruan, Ke and Huang, Bosong and Yu, Weihao and Xiao, Jing and Huang, Jin},
  doi          = {10.1007/s10489-024-05734-1},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10320-10332},
  shortjournal = {Appl. Intell.},
  title        = {TSA-net: A temporal knowledge graph completion method with temporal-structural adaptation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of a dense fusion attention network in fault
diagnosis of centrifugal fan. <em>APIN</em>, <em>54</em>(21),
10300–10319. (<a
href="https://doi.org/10.1007/s10489-024-05643-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the deep learning recognition model has been widely used in the condition monitoring of rotating machinery. However, it is still a challenge to understand the correspondence between the structure and function of the model and the diagnosis process. Therefore, this paper discusses embedding distributed attention modules into dense connections instead of traditional dense cascading operations. It not only decouples the influence of space and channel on fault feature adaptive recalibration feature weights, but also forms a fusion attention function. The proposed dense fusion focuses on the visualization of the network diagnosis process, which increases the interpretability of model diagnosis. How to continuously and effectively integrate different functions to enhance the ability to extract fault features and the ability to resist noise is answered. Centrifugal fan and rotor fault data are used to verify this network. Experimental results show that the network has stronger diagnostic performance than other advanced fault diagnostic models.},
  archive      = {J_APIN},
  author       = {Wang, Ruijun and Liu, Yuan and Fan, Zhixia and Xu, Xiaogang and Wang, Huijie},
  doi          = {10.1007/s10489-024-05643-3},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10300-10319},
  shortjournal = {Appl. Intell.},
  title        = {Application of a dense fusion attention network in fault diagnosis of centrifugal fan},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-branch network based on optical flow learning and
semantic consistency for macro-expression spotting. <em>APIN</em>,
<em>54</em>(21), 10284–10299. (<a
href="https://doi.org/10.1007/s10489-024-05726-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Macro-expression spotting is an important prior step in many dynamic facial expression analysis applications. It automatically detects the onset and offset image frames of a macro-expression in the video. The state-of-the-art methods of macro-expression spotting characterize the movement of facial muscle through explicit analysis of the optical flow map and have achieved promising results. However, optical flow map estimation and expression spotting in these methods are performed in two separate and successive stages. In this paper, we propose a new dual-branch network to achieve unified optimization for expression spotting and optical flow estimation tasks. The proposed dual-branch network implicitly learns optical flow during training and enriches the feature representation with motion information. During inference, we use only the encoder of the optical flow estimation network for motion feature extraction and integrate it with expression spotting into a one-stage framework. The proposed method eliminates the need to construct optical flow maps explicitly during inference and significantly reduces the computational cost. We also apply a consistency constraint on the global- and local-level semantic features of the clip to guide the model to focus on the category-consistent regions of the video. We evaluate the proposed methods extensively on two popular facial expression spotting datasets, CAS(ME) $$^2$$ and SAMM Long Videos. The experimental results show that compared with the state-of-the-art methods, the proposed method improves the F1-scores for MaE spotting by 5.81 $$\%$$ and 1.57 $$\%$$ on the CAS(ME) $$^2$$ and SAMM Long Videos datasets respectively.},
  archive      = {J_APIN},
  author       = {Xian, Yun and Zhang, Dong and Wang, Xingzhi and Lee, Dah-Jye},
  doi          = {10.1007/s10489-024-05726-1},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10284-10299},
  shortjournal = {Appl. Intell.},
  title        = {A dual-branch network based on optical flow learning and semantic consistency for macro-expression spotting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning models for perception of brightness related
illusions. <em>APIN</em>, <em>54</em>(21), 10259–10283. (<a
href="https://doi.org/10.1007/s10489-024-05658-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illusions are like holes in our effortless visual mechanism through which we can peep into the internal mechanisms of the brain. Scientists attempted to explain underlying physiological, physical, and cognitive mechanisms of illusions by the receptive field hierarchical organizations, information sampling, filtering, etc. Some antagonistic illusions cannot be explained by them and for this, deep learning networks were used recently as a model for illusion perception. To further broaden the scope of the perceptual functionality in the brightness contrast genre, handle the background removal effects on some illusions that reduce the illusory effects, and replicate the antagonistic illusions with the same parameter setup, we have used Convolutional Neural Network, Autoencoder, U-Net, and U-Net++ models for replicating the visual illusions. The networks are specialized in low-level vision tasks like De-noising, De-blurring, and a combination of both. A high number of brightness contrast visual illusions are tested on all the networks and most of the outcomes significantly matched human perceptions. Overall, our method will guide the development of neurobiological frameworks which might enrich the computational neuroscience study by distilling some biological principles. On the other hand, the machine learning community will benefit from knowing the inherent flaws of the networks so that the true image of reality can be taken into consideration, especially in imaging situations where experts too can be deceived.},
  archive      = {J_APIN},
  author       = {Mukherjee, Amrita and Paul, Avijit and Ghosh, Kuntal},
  doi          = {10.1007/s10489-024-05658-w},
  journal      = {Applied Intelligence},
  month        = {11},
  number       = {21},
  pages        = {10259-10283},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning models for perception of brightness related illusions},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Deformation prediction of arch dams by coupling STL
decomposition and LSTM neural network. <em>APIN</em>, <em>54</em>(20),
10242–10257. (<a
href="https://doi.org/10.1007/s10489-024-05741-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformation plays an important role in dam monitoring, especially in judging potential damage. Excessive deformation serves as an indicator of the abnormal evolution of dam structures, but the pivotal issue lies in definition for “excessive” precisely. Deformation prediction serves as reference for detection, but it is challenged by multiple factors. Sequence decomposition is an approach to select related factors and predict precisely, but the mechanism in application is a critical problem. This study proposes a decomposition Long short-term memory (DLSTM) model for the deformation prediction of arch dams. Segmented correlation feature extraction method balances feature correlation and consistency. Multiple linear regression is introduced for the integration, and the periodic extension is used to simplify unnecessary predicting operations. The proposed DLSTM model is evaluated using monitoring data from the LYX arch dam. The results show an 18% improvement in the accuracy, as well as better stability of the prediction model. The DLSTM-based multiple linear regression outperforms nonlinear neural network methods in terms of both physical interpretation and performance. The superiority of the proposed model over BP neural network, wavelet neural network, and LSTM model demonstrates that the DLSTM model is a promising approach for practical applications in dam deformation monitoring.},
  archive      = {J_APIN},
  author       = {Yang, Jiaqi and Liu, Changwei and Pan, Jianwen},
  doi          = {10.1007/s10489-024-05741-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10242-10257},
  shortjournal = {Appl. Intell.},
  title        = {Deformation prediction of arch dams by coupling STL decomposition and LSTM neural network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and stable deep reinforcement learning: Selective
priority timing entropy. <em>APIN</em>, <em>54</em>(20), 10224–10241.
(<a href="https://doi.org/10.1007/s10489-024-05705-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has made significant strides in addressing tasks with high-dimensional continuous action spaces. However, the field still faces the challenges of low sample utilization and insufficient exploration-exploitation balance, limiting the generalizability of algorithms across different environments. To effectively improve sample utilization, optimize the exploration-exploitation balance, and achieve higher rewards in tasks, this paper designs the selective priority timing entropy (SPTE) algorithm. Subsequently, selective prioritized experience replay (SPER) is proposed, which employs frequent replay of multiframe memories to enhance sample utilization and improve the stability of policy updates. Additionally, the temporal advantage with decay (TAD) method introduces a decay factor to help adjust the weights of the variance and bias, thereby reducing estimation errors. The reward mechanism is augmented with multientropy (ME) for entropy-regularized training, achieving a balance between information exploration and exploitation. Finally, experimental testing on the challenging Arcade platform demonstrated that the SPTE algorithm surpasses the average testing level of human players by 104.936%. Furthermore, compared to other algorithms, SPTE achieves an average score increase of over 32.75%, and it consistently outperforms the compared methods in more than 60% of tasks, indicating its strong adaptability and robustness. The implementation process of SPTE},
  archive      = {J_APIN},
  author       = {Huo, Lin and Mao, Jianlin and San, Hongjun and Zhang, Shufan and Li, Ruiqi and Fu, Lixia},
  doi          = {10.1007/s10489-024-05705-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10224-10241},
  shortjournal = {Appl. Intell.},
  title        = {Efficient and stable deep reinforcement learning: Selective priority timing entropy},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and evaluation of exoskeleton device for
rehabilitation of index finger using nature-inspired algorithms.
<em>APIN</em>, <em>54</em>(20), 10206–10223. (<a
href="https://doi.org/10.1007/s10489-024-05725-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel robotic exoskeleton for rehabilitation of the index finger. Though all motions of index finger are essential, the major range of motion is covered by flexion/extension motion. Hence, a Stephenson III six-bar mechanism has been synthesized for the robotic exoskeleton device for a pre-defined trajectory to address post stroke rehabilitation of patients. The flexion/extension trajectory was obtained experimentally using image processing. Based on the trajectory, a mathematical model was formulated which was used as the objective function for the optimization problem. To eliminate any defects that may be encountered during the synthesis, “loop-by-loop defect rectification” procedure was implemented along with well-established optimization algorithms such as TLBO, BWP, GWO and PSO for synthesis of the desired mechanism. It has been found that TLBO outperformed all the others as it could reduce the objective function value to 0.69849. whereas, BWP reduced it to 8.9952, GWO reduced it to 13.1388, and PSO could only reduce it to 6 × 105. Therefore, the design obtained using TLBO was considered for developing the prototype of the device. The device was validated experimentally using image processing, and it is found to cover the prescribed range of motion. Thus, the proposed exoskeleton is deemed to be a viable solution for post stroke index-finger rehabilitation.},
  archive      = {J_APIN},
  author       = {Chakraborty, Debaditya and Rathi, Ayush and Singh, Ramanpreet},
  doi          = {10.1007/s10489-024-05725-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10206-10223},
  shortjournal = {Appl. Intell.},
  title        = {Design and evaluation of exoskeleton device for rehabilitation of index finger using nature-inspired algorithms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Key attribute generation from review texts based on
in-context learning for recommender systems. <em>APIN</em>,
<em>54</em>(20), 10194–10205. (<a
href="https://doi.org/10.1007/s10489-024-05698-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User review texts provide valuable information for recommender systems, as they express various dimensions and perspectives regarding the experience of a user with a specific item. Consequently, many studies have proposed recommender systems based on review texts. However, because review texts typically contain a high proportion of noise that is not related to user preferences or item characteristics, existing studies that input the entire review text into the model are vulnerable to noise issues. Therefore, this study proposes a methodology for extracting key attributes based on in-context learning(ICL) to fundamentally address the noise problem in review texts. We used zero-shot, one-shot, and few-shot large language model (LLM) ICL to generate key attributes that define user preferences and item characteristics from integrated review texts, and we trained a recommender system to predict user ratings on items using the generated key attributes as new input. Our proposed research is the first to create and utilize new user and item characteristics through LLM ICL for a recommender system. Experiments demonstrate that our methodology effectively generates key attributes related to user preferences and item characteristics from review texts and achieves superior predictive performance compared to existing review-based recommender systems.},
  archive      = {J_APIN},
  author       = {Park, Jungmin and Lee, Younghoon},
  doi          = {10.1007/s10489-024-05698-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10194-10205},
  shortjournal = {Appl. Intell.},
  title        = {Key attribute generation from review texts based on in-context learning for recommender systems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-strategy continual learning for knowledge refinement
and consolidation. <em>APIN</em>, <em>54</em>(20), 10176–10193. (<a
href="https://doi.org/10.1007/s10489-024-05717-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saving part of the old class data for replay is one of the most effective approaches to alleviate the catastrophic forgetting of deep learning models when the class is incrementally updated data, but there are problems such as easy overfitting of the model and serious imbalance between the data of old and new classes. In this paper, we propose a multi-strategy continual learning model, which contains three strategies: the significant sample retention strategy, the significant feature distillation strategy, and the old task attention strategy. The significant sample retention strategy and the significant feature distillation strategy help the new model to refine and consolidate the old task knowledge by acquiring significant samples and significant features through uncertainty metric and attention mechanism, respectively. Then, the old task attention strategy is used to capture the inter-class semantic consistency across tasks to correct the model imbalance gradient propagation to alleviate the old task forgetting caused by the imbalance between the significant samples and the new task samples. The three strategies synergistically alleviate the catastrophic forgetting problem in the replay continual learning approach from multiple perspectives such as sample storage, stability-plasticity balance, and task classification bias. Our model outperforms state-of-the-art methods by 0.9% $$\sim $$ 6.9% in terms of average accuracy on representative benchmark datasets.},
  archive      = {J_APIN},
  author       = {Zeng, Xianhua and Nie, Xueyun and Li, Laquan and Zhou, Mingkun},
  doi          = {10.1007/s10489-024-05717-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10176-10193},
  shortjournal = {Appl. Intell.},
  title        = {Multi-strategy continual learning for knowledge refinement and consolidation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated framework for accurate trajectory prediction
based on deep learning. <em>APIN</em>, <em>54</em>(20), 10161–10175. (<a
href="https://doi.org/10.1007/s10489-024-05724-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction for moving objects is a critical task for intelligent transportation with numerous applications, such as route planning, traffic management, congestion alleviation, etc. In this paper, we propose a novel framework that integrates sequence modeling, trajectory clustering and topology extraction to improve the accuracy of trajectory prediction. By incorporating self-attention for sequence modeling, we are able to effectively capture the temporal dependencies in trajectory data. Additionally, by taking into account the clustering information via a variational auto-encoder and the topological information based on a graphical neural network (GNN), we can further improve the accuracy of trajectory prediction. Furthermore, integrating a GNN facilitates our framework to handle diverse characteristics of road networks, such as road distance and traffic status, thereby making the proposed approach adaptive to different practical scenarios. As demonstrated by the experimental results on two publicly available datasets, our proposed method improves the accuracies by up to 0.5% and 3.8% for 1-step and 15-step predictions respectively, compared to the state-of-the-art method.},
  archive      = {J_APIN},
  author       = {Zhao, Shuo and Li, Zhaozhi and Zhu, Zikun and Chang, Charles and Li, Xin and Chen, Ying-Chi and Yang, Bo},
  doi          = {10.1007/s10489-024-05724-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10161-10175},
  shortjournal = {Appl. Intell.},
  title        = {An integrated framework for accurate trajectory prediction based on deep learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fusion autoencoder model and piecewise anomaly index for
aero-engine fault diagnosis. <em>APIN</em>, <em>54</em>(20),
10148–10160. (<a
href="https://doi.org/10.1007/s10489-024-05712-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety, efficiency, and reliability are essential requirements for aero-engines. Timely and accurate diagnosis of engine faults enables effective planning of maintenance operations and reduces downtime. Although traditional physics-based methods perform well under controlled test bench scenarios, their effectiveness in handling very noisy data and missing values is limited, constraining their utility in real-world settings. To address these gaps, we propose a fusion autoencoder that combines physics-informed and pattern-informed techniques, augmented with a Beta-Variational Autoencoder learning backbone to enhance the robustness of the model. Additionally, a novel health index called the piecewise anomaly index is proposed that can detect and classify faults simultaneously. To evaluate the efficacy of the novel framework, we modified the New Commercial Modular Aero-Propulsion System Simulation (N-CMAPSS) dataset to simulate real-world scenarios and conducted experiments. The results show that the proposed method can detect faults earlier than common techniques, while also achieving accurate fault classification and degree determination with the new index.},
  archive      = {J_APIN},
  author       = {Feng, Kun and Xiao, Yuan and Li, Zhouzheng and Miao, Dongyan},
  doi          = {10.1007/s10489-024-05712-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10148-10160},
  shortjournal = {Appl. Intell.},
  title        = {A fusion autoencoder model and piecewise anomaly index for aero-engine fault diagnosis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Action recognition method based on multi-stream
attention-enhanced recursive graph convolution. <em>APIN</em>,
<em>54</em>(20), 10133–10147. (<a
href="https://doi.org/10.1007/s10489-024-05719-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition methods have become a research hotspot due to their robustness against variations in lighting, complex backgrounds, and viewpoint changes. Addressing the issues of long-distance joint associations and time-varying joint correlations in skeleton data, this paper proposes a Multi-Stream Attention-Enhanced Recursive Graph Convolution method for action recognition. This method extracts four types of features from the skeleton data: joints, bones, joint movements, and bone movements. It models the potential relationships between non-adjacent nodes through adaptive graph convolution and utilizes a long short-term memory network for recursive learning of the graph structure to capture the temporal correlations of joints. Additionally, a spatio-temporal channel attention module is introduced to enable the model to focus more on important joints, frames, and channel features, further improving performance. Finally, the recognition results of the four branches are fused at the decision level to complete the action recognition. Experimental results on public datasets (UTD-MHAD, CZU-MHAD) and a self-constructed dataset (KTH-Skeleton) demonstrate that the proposed method achieves accuracies of 94.65%, 95.01%, and 97.50%, respectively, fully proving the good performance of the method.},
  archive      = {J_APIN},
  author       = {Wang, Huaijun and Bai, Bingqian and Li, Junhuai and Ke, Hui and Xiang, Wei},
  doi          = {10.1007/s10489-024-05719-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10133-10147},
  shortjournal = {Appl. Intell.},
  title        = {Action recognition method based on multi-stream attention-enhanced recursive graph convolution},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PSO-based unified framework for unsupervised domain
adaptation in image classification. <em>APIN</em>, <em>54</em>(20),
10106–10132. (<a
href="https://doi.org/10.1007/s10489-024-05706-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning classification problems, it is overly assumed that training and test data must be drawn from the same locale and essentially follow the same distribution for optimal performance. However, acquiring sufficient labeled data from the same locale is impractical and labeling is resource-intensive. Domain Adaptation (DA) offers a reliable solution, but manual feature and parameter selection for multi-dimensional image data are also resource-intensive and time-consuming. To address these issues collectively, we propose “PSO-based Unified Framework for Unsupervised Domain Adaptation in Image Classification” (PSO-UDAIC), an unsupervised domain adaptation framework, that minimizes domain discrepancy between labeled and unlabeled data by learning a subspace applying various objective functions, making them appear from the same distribution. The PSO technique is utilized to automate the selection of the optimal common subset of features and objective function parameters, reducing manual effort and time. Extensive experiments on benchmark image datasets (Office+Caltech (SURF, DeCAF, VGG6), USPS+MNIST, COIL20, and VLCS) with varied images and settings across diverse image classification tasks which achieved average accuracies of 58.18%, 93.71%, 91.64%, 100%, 81.76%, and 67.38%, respectively, outperforming the base method LDAPL by 12%, 2.12%, 2.55%, 0.28%, 2.76%, and 14.61% showing PSO-UDAIC’s superior performance compared to primitive and domain adaptation methods. Statistical paired t-tests reaffirmed the significantly improved performance of PSO-UDAIC over the compared methods.},
  archive      = {J_APIN},
  author       = {Karn, Ravi Ranjan Prasad and Sanodiya, Rakesh Kumar},
  doi          = {10.1007/s10489-024-05706-5},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10106-10132},
  shortjournal = {Appl. Intell.},
  title        = {PSO-based unified framework for unsupervised domain adaptation in image classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel individual-relational consistency for bad
semi-supervised generative adversarial networks (IRC-BSGAN) in image
classification and synthesis. <em>APIN</em>, <em>54</em>(20),
10084–10105. (<a
href="https://doi.org/10.1007/s10489-024-05688-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning leverages both labeled and unlabeled images for model training, addressing the scarcity of labeled data. However, challenges persist, including the determination of appropriate thresholds for pseudo-labeling, the effective utilization of uncertain unlabeled images, the absence of consistency regularization, and the oversight of inter-image relationships among images in low-density areas. This study introduces a novel approach named the Individual-Relational Consistency for Bad Semi-supervised Generative Adversarial Networks (IRC-BSGAN) to tackle these issues. IRC-BSGAN integrates bad adversarial training, consistency regularization, and pseudo-labeling to reduce error rates and enhance classifier performance. It includes various components, such as a bad generator network, a discriminator network, a classifier, and consistency regularization modules. IRC-BSGAN introduces new individual and relational consistency regularization losses on bad fake images in low-density areas, thereby generating informative images that precisely estimate the classifier&#39;s decision boundary. The proposed method ensures diversity and consistent labeling of bad fake images by integrating consistency mechanisms. It particularly focuses on low-density areas and extracts extra semantic details from these images by promoting local consistency and coherence among them. The effectiveness of IRC-BSGAN is realized by improving the pseudo-labeling of unlabeled images, especially for low-confidence unlabeled images. For the SVHN dataset with 1000 labeled training images and the CIFAR-10 dataset with 4000 labeled training images, the error rate reduced from 3.89 to 3.67 and from 7.29 to 6.17, respectively. Similarly, on the CINIC-10 dataset with 1000 labeled training images per class, IRC-BSGAN achieved a reduction in error rate from 19.38 to 15.45. On the COVID-19 dataset with 30 labeled training images, the error rate decreased from 7.41 to 5.55.},
  archive      = {J_APIN},
  author       = {Iraji, Mohammad Saber and Tanha, Jafar and Balafar, Mohammad-Ali and Feizi-Derakhshi, Mohammad-Reza},
  doi          = {10.1007/s10489-024-05688-4},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10084-10105},
  shortjournal = {Appl. Intell.},
  title        = {A novel individual-relational consistency for bad semi-supervised generative adversarial networks (IRC-BSGAN) in image classification and synthesis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-scale deep learning model for time series forecasting.
<em>APIN</em>, <em>54</em>(20), 10072–10083. (<a
href="https://doi.org/10.1007/s10489-024-05701-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data, characterized by large volumes and wide-ranging applications, requires accurate predictions of future values based on historical data. Recent advancements in deep learning models, particularly in the field of time series forecasting, have shown promising results by leveraging neural networks to capture complex patterns and dependencies. However, existing models often overlook the influence of short-term cyclical patterns in the time series, leading to a lag in capturing changes and accurately tracking fluctuations in forecast data. To overcome this limitation, this paper introduces a new method that utilizes an interpolation technique to create a fine-scaled representation of the cyclical pattern, thereby alleviating the impact of the irregularity in the cyclical component and hence enhancing prediction accuracy. The proposed method is presented along with evaluation metrics and loss functions suitable for time series forecasting. Experiment results on benchmark datasets demonstrate the effectiveness of the proposed approach in effectively capturing cyclical patterns and improving prediction accuracy.},
  archive      = {J_APIN},
  author       = {Chen, Yuwei and Jia, Wenjing and Wu, Qiang},
  doi          = {10.1007/s10489-024-05701-w},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10072-10083},
  shortjournal = {Appl. Intell.},
  title        = {Fine-scale deep learning model for time series forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised heterogeneous graph contrastive learning
with label-guided. <em>APIN</em>, <em>54</em>(20), 10055–10071. (<a
href="https://doi.org/10.1007/s10489-024-05703-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks represent a powerful approach to understand and utilize the intricate structures and semantics within complex graphs. When it comes to semi-supervised learning on graphs, the challenge lies in effectively leveraging labeled data to generalize predictions to unlabeled nodes. Traditional methods often fall short in fully utilizing labeled information, limiting their performance to the number of available labels. To overcome these limitations, in this paper, we propose a Semi-Supervised Heterogeneous Graph Contrastive Learning with Label-Guided (SSGCL-LG) model. SSGCL-LG tackles this challenge by fully integrating label information into the learning process through contrastive learning. Specifically, it constructs a label graph that incorporates both node and label representations, enhancing the supervised signal. Moreover, we propose a novel strategy for selecting positive and negative samples based on labels and meta-paths, effectively pulling positive samples closer together in the embedding space. To optimize node representations, SSGCL-LG combines contrastive loss with semi-supervised loss, enabling the model to learn from both labeled and unlabeled data. Extensive experiments on real-world datasets validate the effectiveness of our framework, demonstrating its superiority over existing methods. The code for this work is publicly available in the https://github.com/sun281210/SSGCL-LG .},
  archive      = {J_APIN},
  author       = {Li, Chao and Sun, Guoyi and Li, Xin and Shan, Juan},
  doi          = {10.1007/s10489-024-05703-8},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10055-10071},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised heterogeneous graph contrastive learning with label-guided},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Omni-scale feature learning for lightweight image dehazing.
<em>APIN</em>, <em>54</em>(20), 10039–10054. (<a
href="https://doi.org/10.1007/s10489-024-05721-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image dehazing is a critical pre-processing step in high-level computer vision tasks. Existing deep models often have complex network structures and low computational efficiency, while lightweight models typically sacrifice dehazing performance. To handle these issues, we propose a novel Lightweight Omni-Scale Dehaze Network (LOS-DehazeNet). LOS-DehazeNet includes two novel blocks: the Omni-Scale Feature Aggregation (OSFA) block and the Omni-Scale Hybrid Attention (OSHAtt) block. Both of them realize the role of omni-scale feature learning. Specifically, the OSFA block leverages two mapping operations to aggregate features, enabling rich interactions among multi-scale convolutional streams. The OSHAtt block combines dual residual connections with three scales of attention mechanisms (channel, spatial, and pixel). This combination successfully alleviates the performance degradation problem of lightweight dehazing models, bringing its performance to be close to that of deep models while maintaining a low number of parameters. Compared with the latest lightweight dehazing model GRFANet, our LOS-DehazeNet not only achieves state-of-the-art dehazing results, but also has the fastest inference speed. Additionally, our model achieves a remarkable 5 $$\times $$ reduction in network parameters. Extensive experiments validate the effectiveness and superiority of LOS-DehazeNet in both quantitative assessments and visual quality.},
  archive      = {J_APIN},
  author       = {Chen, Zheng and Bi, Xiaojun and Li, Shuo and Yue, Jianyu},
  doi          = {10.1007/s10489-024-05721-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10039-10054},
  shortjournal = {Appl. Intell.},
  title        = {Omni-scale feature learning for lightweight image dehazing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WDTtrack: Tracking multiple objects with indistinguishable
appearance and irregular motion. <em>APIN</em>, <em>54</em>(20),
10018–10038. (<a
href="https://doi.org/10.1007/s10489-024-05682-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surge in object detection, Multi-Object Tracking (MOT) research has recently witnessed significant advancements. However, most previous studies have primarily focused on benchmarks involving distinguishing appearances and linear motion. In scenarios involving non-linear motion and similar appearances, these methods exhibit a drastic drop in performance. To address this issue, we propose WDTtrack, which incorporates spatiotemporal proximity, velocity orientation, and appearance similarity simultaneously. Firstly, we employ the Centroid Triplet Loss ReID (CTL) model to extract high-quality appearance embeddings. Second, we introduce Wider Bounding Box (W-BBox) and Direction Bank (DB) to capture abundant credible, and discriminative motion cues. Finally, we devise the Tracklet Recovery Mechanism (TRM) to facilitate long-term tracking maintenance. Extensive empirical results demonstrate that WDTtrack outperforms other trackers on the DanceTrack and SportsMOT dataset, highlighting its effectiveness and potential for further development. Specifically, WDTtrack achieves a 66.8 HOTA score, a 72.8 IDF1 score and a 55.9 AssA score on DanceTrack, and a 73.8 HOTA score, a 80.5 IDF1 score and a 64.3 AssA score on SportsMOT, substantially surpassing other non-Transformer algorithms.},
  archive      = {J_APIN},
  author       = {Zhao, Zeyong and Wu, Jingyi and Zhi, Ruicong},
  doi          = {10.1007/s10489-024-05682-w},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10018-10038},
  shortjournal = {Appl. Intell.},
  title        = {WDTtrack: Tracking multiple objects with indistinguishable appearance and irregular motion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving diversity and discriminability based implicit
contrastive learning for unsupervised domain adaptation. <em>APIN</em>,
<em>54</em>(20), 10007–10017. (<a
href="https://doi.org/10.1007/s10489-024-05351-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised domain adaptation (UDA), knowledge is transferred from label-rich source domains to relevant but unlabeled target domains. Current most popular state-of-the-art works suggest that performing domain alignment from the class perspective can alleviate domain shift. However, most of them based on domain adversarial which is hard to train and converge. In this paper, we propose a novel contrastive learning to improve diversity and discriminability for domain adaptation, dubbed as IDD_ICL, which improve the discriminativeness of the model while increasing the sample diversity. To be precise, we first design a novel implicits contrastive learning loss at sample-level by implicit augment sample of the source domain. While augmenting the diversity of the source domain, we can cluster the samples of the same category in the source domain together, and disperse the samples of different categories, thereby improving the discriminative ability of the model. Furthermore, we show that our algorithm is effective by implicitly learning an infinite number of similar samples. Our results demonstrate that our method doesn’t require complex technologies or specialized equipment, making it readily adoptable and applicable in practical scenarios.},
  archive      = {J_APIN},
  author       = {Xu, Heng and Shi, Chuanqi and Fan, WenZe and Chen, Zhenghan},
  doi          = {10.1007/s10489-024-05351-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {10007-10017},
  shortjournal = {Appl. Intell.},
  title        = {Improving diversity and discriminability based implicit contrastive learning for unsupervised domain adaptation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constrained feature weighting for semi-supervised learning.
<em>APIN</em>, <em>54</em>(20), 9987–10006. (<a
href="https://doi.org/10.1007/s10489-024-05691-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised feature selection plays a crucial role in semi-supervised classification tasks by identifying the most informative and relevant features while discarding irrelevant or redundant features. Many semi-supervised feature selection approaches take advantage of pairwise constraints. However, these methods either encounter obstacles when attempting to automatically determine the appropriate number of features or cannot make full use of the given pairwise constraints. Thus, we propose a constrained feature weighting (CFW) approach for semi-supervised feature selection. CFW has two goals: maximizing the modified hypothesis margin related to cannot-link constraints and minimizing the must-link preserving regularization related to must-link constraints. The former makes the selected features strongly discriminative, and the latter makes similar samples with selected features more similar in the weighted feature space. In addition, L1-norm regularization is incorporated in the objective function of CFW to automatically determine the number of features. Extensive experiments are conducted on real-world datasets, and experimental results demonstrate the superior effectiveness of CFW compared to that of the existing popular supervised and semi-supervised feature selection methods.},
  archive      = {J_APIN},
  author       = {Chen, Xinyi and Zhang, Li and Zhao, Lei and Zhang, Xiaofang},
  doi          = {10.1007/s10489-024-05691-9},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9987-10006},
  shortjournal = {Appl. Intell.},
  title        = {Constrained feature weighting for semi-supervised learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Class-incremental learning via prototype similarity replay
and similarity-adjusted regularization. <em>APIN</em>, <em>54</em>(20),
9971–9986. (<a
href="https://doi.org/10.1007/s10489-024-05695-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of incremental learning is to enable machine learning models to continuously learn and adapt to new tasks and data in changing environments while maintaining knowledge of prior tasks. Recently, researchers have proposed a variety of incremental learning methods. Some methods rely on data storage or complex generative models to perform satisfactorily. However, existing incremental learning approaches typically focus on mitigating catastrophic forgetting, with less emphasis on effectively applying old knowledge to facilitate learning new tasks. In this paper, we propose a non-exemplar-based incremental learning approach called Class-Incremental Learning via Prototype Similarity Replay and Similarity-adjusted Regularization (PSSR) to tackle catastrophic forgetting in incremental learning. The essence of PSSR is leveraging prior knowledge of prior tasks to facilitate the acquisition of new tasks. PSSR memorizes a prototype for each old class, representing the class, and learns the new classes based on the similarity between the prototypes and the new class samples during the learning process. The feature space distribution is modified by the old class prototypes to enhance the model’s learning of the new classes. Extensive experiments on three benchmark datasets demonstrate the superior incremental performance of PSSR, with classification accuracy improvements of 2.73%, 3.37%, and 4.21% over state-of-the-art methods. Code available at https://github.com/FutureIAI/PSSR .},
  archive      = {J_APIN},
  author       = {Chen, Runji and Chen, Guangzhu and Liao, Xiaojuan and Xiong, Wenjie},
  doi          = {10.1007/s10489-024-05695-5},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9971-9986},
  shortjournal = {Appl. Intell.},
  title        = {Class-incremental learning via prototype similarity replay and similarity-adjusted regularization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3D industrial anomaly detection via dual reconstruction
network. <em>APIN</em>, <em>54</em>(20), 9956–9970. (<a
href="https://doi.org/10.1007/s10489-024-05700-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, 2D anomaly detection has demonstrated outstanding performance. However, 2D images limit the improvement of anomaly detection accuracy without utilizing depth information. Therefore, this paper proposes a Dual Reconstruction viA Inpainting Network for 3D industrial anomaly detection (DRAIN). Firstly, we design a 3D reconstruction network using an encoder-decoder-based U-shaped network for processing RGB images and depth images. Subsequently, accurate anomaly segmentation is implemented through a 3D segmentation network. We introduce a lightweight MLP module to enhance segmentation performance to capture long-range dependencies in the reconstructed images. Furthermore, we propose a dual attention-based information entropy fusion module to expedite feature fusion in the inference process, aiming for enhanced deployment in the industry. Extensive experiments demonstrate that DRAIN achieves a 94.3% AUROC on the 3D anomaly detection dataset MVTec 3D-AD, surpassing other research methods. Overall architecture for 3D industrial anomaly detection via dual reconstruction network},
  archive      = {J_APIN},
  author       = {Li, Zhuo and Ge, Yifei and Wang, Xin and Meng, Lin},
  doi          = {10.1007/s10489-024-05700-x},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9956-9970},
  shortjournal = {Appl. Intell.},
  title        = {3D industrial anomaly detection via dual reconstruction network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory tracking control of discrete non-affine MIMO
iterative systems with unknown models: A neural-network-based
data-driven algorithm. <em>APIN</em>, <em>54</em>(20), 9936–9955. (<a
href="https://doi.org/10.1007/s10489-024-05633-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper devises a neural-network-based data-driven (NN-DD) algorithm to address the trajectory tracking control (TC) of discrete non-affine MIMO systems with unknown models and repetitive operation patterns. Data-driven control no longer relies on the precise model of the controlled system, thereby breaking free from the limitations of model-based control strategies. Inspired by this, the primary objective of the algorithm is to ensure that the tracking error of the system is uniformly ultimately bounded through a data-driven approach. The algorithm is comprised of a DD modeling approach based on an enhanced stochastic configuration network (ESCN), and a control input solving approach based on radial basis function neural networks (RBFNNs). The numerical simulations indicate that the proposed algorithm achieves a decrease in the modeling error to $$3.29e-7$$ and the tracking error to $$1e-8$$ after just 20 iterations. In addition, the numerical simulations also demonstrate that the modeling algorithm based on an ESCN reduces the modeling errors by $$48.11\%$$ and $$99.95\%$$ respectively compared to the modeling algorithms using only stochastic configuration networks (SCNs) or extreme learning machines (ELMs). Regarding tracking errors, the proposed RBFNN-based controller reduces the tracking error by $$100\%$$ compared to the backpropagation NN (BPNN)-based controller. Furthermore, the robustness of the algorithm against time-varying interference is tested via the unmanned vehicle simulations. This paper covers several contributions: 1) The proposed algorithm is entirely DD and can directly establish the relationship between inputs and outputs. 2) The designed ESCN fully integrates the advantages of SCNs and ELMs, in contrast to simply combining basic algorithms. 3) The RBFNN-based controller is independent of the actual system structure and exhibits excellent generalization capabilities.},
  archive      = {J_APIN},
  author       = {Shi, Qingyu and Huang, Xia and Wang, Zhen},
  doi          = {10.1007/s10489-024-05633-5},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9936-9955},
  shortjournal = {Appl. Intell.},
  title        = {Trajectory tracking control of discrete non-affine MIMO iterative systems with unknown models: A neural-network-based data-driven algorithm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ReNDCF: Relation network with dual-channel feature fusion
for few-shot learning. <em>APIN</em>, <em>54</em>(20), 9924–9935. (<a
href="https://doi.org/10.1007/s10489-024-05699-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RelationNet is a highly effective metric-based few-shot learning method. However, RelationNet uses only shallow convolutional networks in the feature extraction stage, yielding less representative sample features. In addition, RelationNet simply uses summing or averaging to compute prototypes in the prototype learning stage, making it difficult to obtain very representative prototypes. To address these two aspects, we propose a Relation Network with Dual-Channel Feature Fusion for Few-shot Learning(ReNDCF). Firstly, in the feature extraction stage, a Dual-Channel feature extractor is proposed and a multi-head self-attention mechanism is introduced to enhance the feature extraction ability for fine-grained samples by exploiting the correlation between sample categories. Secondly, in the prototype learning module, an improved adaptive prototype learner is proposed, which further enables the final prototype to represent a certain class of samples more accurately. Finally, our ReNDCF achieves better classification performance than RelationNet and other state-of-the-art classification methods on three widely used fine-grained benchmark datasets CUB-200-2011, Stanford-Cars, and Stanford-Dogs.},
  archive      = {J_APIN},
  author       = {Xu, Yi and Chu, Wenke and Lu, Mingyue},
  doi          = {10.1007/s10489-024-05699-1},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9924-9935},
  shortjournal = {Appl. Intell.},
  title        = {ReNDCF: Relation network with dual-channel feature fusion for few-shot learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Population-based detection of children ASD/ADHD comorbidity
from atypical sensory processing. <em>APIN</em>, <em>54</em>(20),
9906–9923. (<a
href="https://doi.org/10.1007/s10489-024-05655-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comorbidity between neurodevelopmental disorders is common, especially between autism spectrum disorder (ASD) and attention deficit/hyperactivity disorder (ADHD). This study aimed to detect overlapped sensory processing alterations in a sample of children and adolescents diagnosed with both ASD and ADHD. A collection of 42 standard and 8 proposed machine learning classifiers, 22 feature selection methods and 19 unbalanced classification strategies were applied on the 6 standard question groups of the Sensory Profile-2 questionnaire. The relatively low performance achieved by state-of-the-art classifiers led us to propose the feature population sum classifier, a probabilistic method based on class and feature value populations, designed for datasets where features are discrete numeric answers to questions in a questionnaire. The proposed method achieves the best kappa and accuracy, 60% and 82.5%, respectively, reaching 68% and 86.5% combined with backward sequential feature selection, with false positive and negative rates below 15%. Since the SP2 questionnaire can be filled by parents for children from three years, our prediction can alert the clinicians with an early diagnosis in order to apply early interventions.},
  archive      = {J_APIN},
  author       = {Fernández-Delgado, Manuel and Cruz, Sara and Cernadas, Eva and Alateyat, Heba and Tubío-Fungueiriño, María and Sampaio, Adriana and Carracedo, Angel and Fernández-Prieto, Montse},
  doi          = {10.1007/s10489-024-05655-z},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9906-9923},
  shortjournal = {Appl. Intell.},
  title        = {Population-based detection of children ASD/ADHD comorbidity from atypical sensory processing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on heterogeneous multi-UAV collaborative
decision-making method based on improved PPO. <em>APIN</em>,
<em>54</em>(20), 9892–9905. (<a
href="https://doi.org/10.1007/s10489-024-05674-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problem that the Proximal Policy Optimization (PPO) algorithm is difficult to converge in the air-sea battle scenarios with high dynamics, strong interference, and complex state space, the Ray-LAPPO algorithm based on Long Short-Term Memory (LSTM) and Attention mechanism is proposed in this paper under the distributed training framework Ray. Firstly, the idea of Centralized Training Distributed Execution (CTDE) is adopted to extend the PPO algorithm to the field of multi-agent and the policy entropy is added to the loss function to encourage the exploration of agents; Secondly, the LSTM network is added to the actor and critic networks to explore the timing relationship between non-independent and identically distributed samples and improve the learning performance of the UAV; In addition, the Attention mechanism is introduced to obtain the states at different time steps and establish a weighted differentiation model of the final value function; Finally, the simulation experiments on the self-developed heterogeneous UAV collaborative decision-making environment show that Ray-LAPPO can get the most advanced performance in different scenarios, and also possesses potential value for large-scale real-world applications.},
  archive      = {J_APIN},
  author       = {Xu, Lin and Zhang, Xinmiao and Xiao, Dong and Liu, Beihong and Liu, Aixue},
  doi          = {10.1007/s10489-024-05674-w},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9892-9905},
  shortjournal = {Appl. Intell.},
  title        = {Research on heterogeneous multi-UAV collaborative decision-making method based on improved PPO},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PVII: A pedestrian-vehicle interactive and iterative
prediction framework for pedestrian’s trajectory. <em>APIN</em>,
<em>54</em>(20), 9881–9891. (<a
href="https://doi.org/10.1007/s10489-024-05595-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced Driving Assistance System (ADAS) can predict pedestrian’s trajectory, in order to avoid traffic accidents and guarantee driving safety. A few current pedestrian trajectory prediction methods use a pedestrian’s historical motion to predict the future trajectory, but the pedestrian’s trajectory is also affected by the vehicle using the ADAS for prediction (target vehicle). Other studies predict the pedestrian’s and vehicle’s trajectories separately, and use the latter to adjust the former, but their interaction is a continuous process and should be considered during prediction rather than after. Therefore, we propose PVII, a pedestrian-vehicle interactive and iterative prediction framework for pedestrian’s trajectory. It makes prediction for one iteration based on the results from previous iteration, which essentially models the vehicle-pedestrian interaction. In this iterative framework, to avoid accumulation of prediction errors along with the increased iterations, we design a bi-layer Bayesian en/decoder. For each iteration, it not only uses inaccurate results from previous iteration but also accurate historical data for prediction, and calculates Bayesian uncertainty values to evaluate the results. In addition, the pedestrian’s trajectory is affected by both target vehicle and other vehicles around it (surrounding vehicle), so we include into the framework a pre-trained speed estimation module for surrounding vehicles (SE module). It estimates the speed based on pedestrian’s motion and we collect data from pedestrian’s view for training. In experiments, PVII can achieve the highest prediction accuracy compared to the current methods.},
  archive      = {J_APIN},
  author       = {Shen, Qianwen and Huang, Shien and Sun, Baixi and Chen, Xinyu and Tao, Dingwen and Wan, Huaiyu and Bao, Ergude},
  doi          = {10.1007/s10489-024-05595-8},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9881-9891},
  shortjournal = {Appl. Intell.},
  title        = {PVII: A pedestrian-vehicle interactive and iterative prediction framework for pedestrian’s trajectory},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pseudo-label meta-learner in semi-supervised few-shot
learning for remote sensing image scene classification. <em>APIN</em>,
<em>54</em>(20), 9864–9880. (<a
href="https://doi.org/10.1007/s10489-024-05670-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing image scene classification (RSISC) greatly benefits from the use of few-shot learning, as it enables the recognition of novel scenes with only a small amount of labeled data. Most previous works focused on learning representations of prior knowledge with scarce labeled data while ignoring the feasibility of using potential information with large amounts of unlabeled data. In this paper, we introduce a novel semi-supervised few-shot pseudo-label propagation method through the introduction of unlabeled knowledge. This approach utilizes the pseudo-loss property generated by the classifier to indirectly reflect the credibility of pseudo-labeled samples. Therefore, we propose a semi-supervised pseudo-loss confidence metric-based method called a pseudolabel meta-learner (PLML) for RSISC. Specifically, we adopt a pseudoloss estimation module to map the pseudo-labeled data obtained from different tasks to a unified pseudo-loss metric space. Then, the distributions of the pseudolosses with both correct and incorrect pseudolabels are fitted by a semi-supervised beta mixture model (ss-BMM). This model can iteratively select high-quality unlabeled data to enhance the self-training effect of the classifier. Finally, to address the problem of shifting pseudo-loss distributions in remote sensing images, a progressive self-training strategy is proposed to mitigate the cumulative error induced by the classifier. Experimental results demonstrate that our proposed PLML approach outperforms the existing alternatives on the NWPU-RESISC45, AID, and UC Merced datasets.},
  archive      = {J_APIN},
  author       = {Miao, Wang and Huang, Kai and Xu, Zhe and Zhang, Jianting and Geng, Jie and Jiang, Wen},
  doi          = {10.1007/s10489-024-05670-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9864-9880},
  shortjournal = {Appl. Intell.},
  title        = {Pseudo-label meta-learner in semi-supervised few-shot learning for remote sensing image scene classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gated filter pruning via sample manifold relationships.
<em>APIN</em>, <em>54</em>(20), 9848–9863. (<a
href="https://doi.org/10.1007/s10489-024-05690-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning is an essential method for compressing and accelerating deep neural networks on computationally restricted devices. Despite recognizing the high correlation between filter redundancy and samples, existing methods primarily focus on independently searching for optimal subnetworks from individual input while ignoring the relationships among different inputs. In this paper, we propose a novel approach called Gated Filter Pruning based on Sample Manifold Relationships, which exploits and aligns the manifold relationships of all samples during training to obtain an optimal subnetwork. Firstly, we introduce a Gated Filter Normalization Module (GFNM) that excavates the manifold information of each sample, applicable to the operator level without adding many additional parameters. GFNM incorporates explainable control variables jointly optimized with convolutional weights, explicitly determining the competition and cooperation among filters during training. Subsequently, Manifold Regularized Pruning Module (MRPM) measures the manifold relationships between samples and subnetworks, efficiently regularizing the solution space of sample-network pairs. The manifold relationships between samples and subnetworks are aligned in training to derive an effective subnetwork for all input samples. Extensive experimental results validate the effectiveness of our method, demonstrating competitive performance in terms of accuracy and computational cost compared to state-of-the-art (SOTA) methods.},
  archive      = {J_APIN},
  author       = {Wu, Pingfan and Huang, Hengyi and Sun, Han and Liu, Ningzhong},
  doi          = {10.1007/s10489-024-05690-w},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9848-9863},
  shortjournal = {Appl. Intell.},
  title        = {Gated filter pruning via sample manifold relationships},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Behavior sessions and time-aware for multi-target sequential
recommendation. <em>APIN</em>, <em>54</em>(20), 9830–9847. (<a
href="https://doi.org/10.1007/s10489-024-05678-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sequentiality of sequences plays a crucial role in modeling the dynamic evolution of the user’s interests. Sequential recommendation models have significantly improved with the introduction of neural networks, offering users more personalized experiences. However, most models rely on a single type of behavior data and perform single-class target optimization on that type, overlooking the Click-Favorite-Purchase process that precedes a user’s final interaction with the item, and different behaviors in this process will have a significant impact on users’ interest. In this paper, we propose behavior sessions and time-aware for multi-targets sequential recommendation model (BTMT), which captures users’ interest changes from various behavior information. BTMT learns the influence factors of different behavior sessions as weights for each behavior. These weights introduce behavior information into a temporal attention network to dynamically model user’s interests in conjunction with time information. Furthermore, we distinguish the prediction of different users’ behaviors and perform multi-target joint optimization. Extensive experiments on four datasets demonstrate that BTMT’s prediction performance for each behavior target significantly outperforms various sequence models. These results validate the effectiveness of distinguishing behavior information in improving recommendation performance.},
  archive      = {J_APIN},
  author       = {Chen, Ruizhen and Zhang, Yihao and Hu, Jiahao and Wang, Xibin and Zhu, Junlin and Liao, Weiwen},
  doi          = {10.1007/s10489-024-05678-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9830-9847},
  shortjournal = {Appl. Intell.},
  title        = {Behavior sessions and time-aware for multi-target sequential recommendation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A real-time and lightweight driver fatigue detection model
using anchor-free and visual-attention mechanisms. <em>APIN</em>,
<em>54</em>(20), 9811–9829. (<a
href="https://doi.org/10.1007/s10489-024-05696-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fatigue driving poses a serious threat to road safety, and research on how to effectively perceive driver fatigue and provide friendly reminders under the limited computing resources of vehicle-mounted platforms has attracted much attention. This study aims to address this limitation by developing edge computing-friendly operators and lightweight network structures. The proposed model, EMFastDet, enhances the efficiency and accuracy of driver fatigue detection. It integrates an attention module within edge computing-friendly operation blocks to capture features of the mouth and eyes. Anchor-free methods and a single detection head layer are employed for position and category predictions. The eye and mouth states in video streams are evaluated based on the metrics of Percentage of Eye Closure (PERCLOS) and Percentage of Yawning (POY). Extensive experiments were conducted using the YFDMS dataset collected in a real driving cabin environment with an infrared camera. Testing on the Qualcomm Snapdragon SA8155P chip, the DSP-accelerated EMFastDet 0.5 $$\times $$ version achieved an inference time of 3.02 ms and a quantized model size of 0.91 MB. The model achieved an mAP0.5 accuracy of 66.1 $$\%$$ , meeting the deployment requirements of in-vehicle platforms.},
  archive      = {J_APIN},
  author       = {Wang, Ji and Li, Baoming and Li, Zhaoye and Xu, Peiquan and Li, Leijun},
  doi          = {10.1007/s10489-024-05696-4},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9811-9829},
  shortjournal = {Appl. Intell.},
  title        = {A real-time and lightweight driver fatigue detection model using anchor-free and visual-attention mechanisms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matching tasks to objectives: Fine-tuning and prompt-tuning
strategies for encoder-decoder pre-trained language models.
<em>APIN</em>, <em>54</em>(20), 9783–9810. (<a
href="https://doi.org/10.1007/s10489-024-05660-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt-based learning has emerged as a dominant paradigm in natural language processing. This study explores the impact of diverse pre-training objectives on the performance of encoder-decoder pre-trained language models across generation and question answering tasks, with a focus on commonsense knowledge retrieval and completion. We highlight the benefits of incorporating multiple objectives during both pre-training and fine-tuning stages. We introduce the Match Task to Objective (MTO) framework and methods for determining the appropriate objective for a given task. This framework offers automated methods to prepare task-related data for adaptation through unsupervised training, based on the identified objective. In the fine-tuning stage, we design novel templates that align with the objectives of the pre-training and adaptation stages. When aligned with task requirements, these strategies can achieve a performance gain of over 120% compared to conventional methods in few-shot settings. They significantly outperform related works in few-shot settings and exceed the baseline even in full-dataset scenarios. Furthermore, we extend this approach to include prompt-tuning methodologies, providing guidance for more effective soft prompt engineering and optimization. Our strategies significantly enhance prompt-tuning performance as well. These insights hold substantial value, precisely guiding the selection and optimization of models customized for specific tasks. Code is available at https://github.com/puraminy/MTO/},
  archive      = {J_APIN},
  author       = {Pouramini, Ahmad and Faili, Hesham},
  doi          = {10.1007/s10489-024-05660-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9783-9810},
  shortjournal = {Appl. Intell.},
  title        = {Matching tasks to objectives: Fine-tuning and prompt-tuning strategies for encoder-decoder pre-trained language models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-kernel partial label learning using graph contrast
disambiguation. <em>APIN</em>, <em>54</em>(20), 9760–9782. (<a
href="https://doi.org/10.1007/s10489-024-05639-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning (PLL) handles data classification problems by assigning a candidate label set to each sample. There is always one correct label in a candidate label set. Since the PLL can achieve classification without precise labels, it can reduce the cost of data annotation. However, the PLL suffers from challenges and difficulties caused by the ambiguity of the candidate labels. Most PLL algorithms eliminate the ambiguity in candidate label sets by treating each candidate label equally or iteratively identifying the ground-truth label without employing optimization kernels, whereas the optimal kernel can ensure better performance for PLL tasks. Moreover, there is no general framework to handle heterogeneous data classification in various applications. Inspired by the successful application of multi-kernel learning in machine learning, this paper integrates multi-kernel learning into the PLL framework to develop a new multi-kernel PLL (PL-MKL) algorithm, which adopts different kernels to map the original sample attributes to distinct nonlinear feature spaces. Accordingly, the model’s classification performance can be enhanced by joining the mapping capabilities of multiple feature spaces while fully exploring the intrinsic distribution of data. Furthermore, the PL-MKL combines similarity and dispersion graphs to develop an innovative method based on graph contrast disambiguation. This approach maintains the manifold characteristics of the data and reflects the differences in candidate labels, thus alleviating intra-class differences while gaining inter-class ones. An efficient optimization algorithm is proposed to attain the underlined objectives. Extensive experiments demonstrate the competitive or superior performance of the suggested PL-MKL over state-of-the-art approaches.},
  archive      = {J_APIN},
  author       = {Li, Hongyan and Wan, Zhonglin and Vong, Chi Man},
  doi          = {10.1007/s10489-024-05639-z},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9760-9782},
  shortjournal = {Appl. Intell.},
  title        = {Multi-kernel partial label learning using graph contrast disambiguation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-granularity facial extreme makeup transfer and
removal model with local-global collaboration. <em>APIN</em>,
<em>54</em>(20), 9741–9759. (<a
href="https://doi.org/10.1007/s10489-024-05692-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing face makeup transfer methods have limitations in accuracy, realism, and identity preservation. These methods cannot transfer extreme makeup with complex patterns, only light ones. To address these issues, we develop a multi-granularity facial makeup transfer and removal model with local-global collaboration. This model can apply and remove all makeup styles (i.e., light to extreme makeup) on a face image accurately. First, we design novel local discriminators for facial local patches divided by landmarks, in order to distinguish the accuracy of local makeup transfer. The local and global discriminators collaborate to effectively separate content and makeup style features, accurately handle transfer from coarse-grained global and fine-grained local perspectives, and adequately preserve facial identity. Then, we propose a novel loss function that ensures the consistency of local makeup styles, and maintains color, texture, and complex makeup patterns on the patches during the transfer process, generating a realistic appearance. Finally, we suggest dealing with an image’s facial and background regions independently, and separating them by introducing face parsing maps into both the generator and discriminators. This prevents the alteration of unrelated content and mitigates the negative impact of background information during makeup transfer and removal. Extensive experiments demonstrate our method’s effectiveness with light and extreme makeup styles.},
  archive      = {J_APIN},
  author       = {Chen, Yuyan and Chi, Jing and Shen, Tianshu and You, Bingyi and Wang, Yanbing and Zhang, Caiming},
  doi          = {10.1007/s10489-024-05692-8},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9741-9759},
  shortjournal = {Appl. Intell.},
  title        = {A multi-granularity facial extreme makeup transfer and removal model with local-global collaboration},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reusable AI-enabled defect detection system for railway
using ensembled CNN. <em>APIN</em>, <em>54</em>(20), 9723–9740. (<a
href="https://doi.org/10.1007/s10489-024-05676-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate defect detection is crucial for ensuring the trustworthiness of intelligent railway systems. Current approaches either rely on static ensembling of Convolutional Neural Networks (CNNs) or on single deep-learning CNN models. Traditional methods use a large volume of data to identify underlying patterns. However, training a new defect classifier with limited samples often results in overfitting and poor performance on unseen images. To overcome these challenges, we introduce a dynamic weight adaptation mechanism within an ensemble learning framework, enhanced by state-of-the-art transfer learning models (VGG-19, MobileNetV3, and ResNet50). We obtained a good test and validation accuracy of 99%, accompanied by a precision of 0.99, and recall and F1-score of 0.98. Unlike previous methods, our approach demonstrates consistency. Particularly, techniques that involve selecting predictions based on minimum loss previously required a significant number of epochs to stabilize. Data fusion techniques are even more demanding, requiring a substantially higher number of epochs for stabilization. Conversely, our proposed method achieves stable performance and rapid convergence within just 10 epochs, and it shows minimal fluctuation in the training curve (0–5 epochs). This visibly contrasts with earlier methods, which, despite reaching similar levels of accuracy, required significantly more epochs and exhibited greater fluctuations in their training curves. Through these findings, we anticipate that the proposed dynamic weight adaptation-based ensemble approach will further research and development of reusable AI-enabled solutions for rail defect classification.},
  archive      = {J_APIN},
  author       = {Ferdousi, Rahatara and Laamarti, Fedwa and Yang, Chunsheng and Saddik, Abdulmotaleb El},
  doi          = {10.1007/s10489-024-05676-8},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9723-9740},
  shortjournal = {Appl. Intell.},
  title        = {A reusable AI-enabled defect detection system for railway using ensembled CNN},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling topic evolution in public opinion events: An
unsupervised spatio-temporal graph attention approach. <em>APIN</em>,
<em>54</em>(20), 9706–9722. (<a
href="https://doi.org/10.1007/s10489-024-05684-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of online social media, Public Opinion Events (POEs) quickly propagate on the Internet, generating a vast amount of textual data centered around various discussed topics. The development of POEs is closely linked to the evolution of these topics. However, in developing of POEs, the key challenges lie in estimating the duration of different topics, dealing with their dynamic natures, and quantifying topic evolution to predict the number of topics in the future. In this paper, we propose an Unsupervised Spatio-Temporal Graph Attention approach (USTGAT-TT) to tackle these challenges. First, we introduce a topic evolution periods generation method without human intervention. Initially, POEs data undergoes pre-processing to establish initial periods and extract keywords. According to the persistence and hotness of keywords, new periods are reconstructed and keywords are clustered by their similarity to form topics. Then we analyze three pieces of knowledge to further learn the evolution of topics, macro properties, micro properties and dynamic topic network graphs via topics co-occurrence relationship. Finally, we design a Spatio-Temporal Graph Attention topic trend prediction model (STGAT-TT) by taking the mutual effect of topics and temporal dependencies into account. At the same time, attention mechanism and average method are employed to obtain the contribution of topics and Long Short-Term Memory (LSTM) is used to predict the number of topics in the next period to study the state of POEs. Experiments on five POEs show that the effectiveness of the proposed approach. It can estimate the duration of topics to form periods and quantify their features to learn evolution and predict the number of topics in the next period.},
  archive      = {J_APIN},
  author       = {Wang, Xi and Kong, Mingming and Chen, Jiexin and Wang, Xianjun and Pei, Zheng},
  doi          = {10.1007/s10489-024-05684-8},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9706-9722},
  shortjournal = {Appl. Intell.},
  title        = {Modeling topic evolution in public opinion events: An unsupervised spatio-temporal graph attention approach},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detecting camouflaged objects via cross-level context
supplement. <em>APIN</em>, <em>54</em>(20), 9685–9705. (<a
href="https://doi.org/10.1007/s10489-024-05694-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) is to distinguish the target objects with varied sizes and shapes from the low-contrast real-world scenarios. Although deep learning-based methods have made great progress, it is still challenging to accurately detect and segment the complete and edge-preserving camouflaged objects. In this paper, we propose a novel cross-level context supplement network (CCSNet) to effectively utilize cross-level features to provide additional information, which can compensate for the deficiencies of the current level potentials. Specifically, we develop a selective cross-level aggregation (SCA) module to fully explore the cross-level different but complementary cues to detect camouflaged objects with different scales. It makes each level of the network adaptively focus on the informative features with the assist of the channel dependencies and spatial relationship provided by the adjacent levels. Furthermore, considering that the camouflaged objects are hardly distinguishable from the backgrounds, we design a location and boundary supplement (LBS) module to directly incorporate the global and edge information to different levels, thus enhancing the spatial coherence of interior regions and reducing the uncertainty of boundary regions. Comprehensive experiments are conducted on four public datasets to demonstrate the effectiveness of our CCSNet. In addition, we apply our model to two other dense pixel prediction tasks to further demonstrate the effectiveness and generalization ability of our network. The code, trained model and predicted maps will be available upon acceptance of this paper for publication.},
  archive      = {J_APIN},
  author       = {Zhang, Qing and Yan, Weiqi and Zhao, Rui and Shi, Yanjiao and Zeng, Jian},
  doi          = {10.1007/s10489-024-05694-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9685-9705},
  shortjournal = {Appl. Intell.},
  title        = {Detecting camouflaged objects via cross-level context supplement},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cluster impurity-based hybrid resampling for imbalanced
classification problems. <em>APIN</em>, <em>54</em>(20), 9671–9684. (<a
href="https://doi.org/10.1007/s10489-024-05644-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the supervised learning techniques, classification plays a crucial role in categorizing and predicting the observations across a wide range of machine learning applications such as software defect detection, fraud detection in financial sector, fault and defect detection in manufacturing industry, medical diagnosis, etc. However, most classification algorithms have been developed with the assumption that the class distribution is balanced although unequal class distributions are quite common in many practical cases. When a class imbalance problem exists, in general, the classifier tends to become biased towards the majority class and thus the minority class instances are often misclassified to the majority class. Along with the class imbalance problem, the class overlap is also known as one of the sources that makes the learning task become difficult or sometimes deteriorates the classification performance, especially, when class imbalance problem also exists. Thus, in this research, we propose a cluster impurity-based hybrid resampling method including the partially balanced strategy to improve the classification performance of class imbalanced data with considering intra-cluster class imbalance and inter-cluster overlap problems. Specifically, several clustering methods are employed for identifying the groups (i.e., clusters) of all the instances and the cluster impurity of each instance is computed for measuring the degree of cluster overlap. Then, based on the cluster impurity, the instances are generated and eliminated recursively. To demonstrate the effectiveness of the proposed method, comprehensive experiments are conducted on forty imbalanced datasets and two non-parametric hypothesis tests are employed to show the statistical difference in classification performances between the proposed method and other traditional resampling methods.},
  archive      = {J_APIN},
  author       = {Park, You-Jin and Cheng, Ke-Yong},
  doi          = {10.1007/s10489-024-05644-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9671-9684},
  shortjournal = {Appl. Intell.},
  title        = {A cluster impurity-based hybrid resampling for imbalanced classification problems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High-speed, low-power, and configurable on-chip training
acceleration platform for spiking neural networks. <em>APIN</em>,
<em>54</em>(20), 9655–9670. (<a
href="https://doi.org/10.1007/s10489-024-05689-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spike timing-dependent plasticity (STDP) is crucial for training neural networks (SNNs), offering a hardware-compatible and energy-efficient alternative to backpropagation. Current STDP hardware platforms encounter significant challenges, such as slowness, high energy consumption, and limited configurability. To overcome these issues, this paper presents a high-performance SNN training platform. A parallel multi-ring first-in-first-out structure with event-driven processing for spike handling is proposed, which enhances training efficiency, and the flexible pre- and post-synaptic parallelism enhances speed and flexibility. A dataflow strategy that considers spike sparsity unifies spike representations by updating weights only upon spike arrival, thereby promoting logical symmetry and enabling parallelization. Additionally, three encoding strategies, including a hybrid encoding, are implemented to address diverse scenarios. Leveraging Xilinx field-programmable gate array and Jetson Xavier NX, the proposed platform achieved remarkable performance gains. On the MNIST dataset, the platform demonstrated a 22.51 $$\times $$ speedup, 2.13% accuracy boost, and 14.79 $$\times $$ reduction in energy consumption. On the Fashion-MNIST dataset, it improved accuracy by 10.74% and the training speed by 1.89 $$\times $$ . Thus, this platform can significantly advance the SNN training efficiency and performance.},
  archive      = {J_APIN},
  author       = {Liu, Yijun and Xu, Yujie and Ye, Wujian and Cui, Youfeng and Zhang, Boning and Lin, Wenjie},
  doi          = {10.1007/s10489-024-05689-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9655-9670},
  shortjournal = {Appl. Intell.},
  title        = {High-speed, low-power, and configurable on-chip training acceleration platform for spiking neural networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Consistency-oriented clustering ensemble via data
reconstruction. <em>APIN</em>, <em>54</em>(20), 9641–9654. (<a
href="https://doi.org/10.1007/s10489-024-05654-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study highlights that using different distance measures on the same dataset leads to varying clustering results, making the choice of distance measure a challenge when prior knowledge is lacking. To address this issue, a consistency-oriented clustering ensemble via data reconstruction is developed. This approach eliminates the need to select a specific distance measure and achieves higher consistency between the clustering ensemble and base clusterings while maintaining superior clustering performance. First, the base clustering is generated via the clustering with different distance measures and a consistency definition is introduced in the proposed method. Then the ensemble process updates the weights of base clusterings to ensure they reach the consistency. At the same time data reconstruction process is integrated into the ensemble process to guarantee a high convergence rate and efficient clustering. Finally, the clustering ensemble result is achieved with the higher consistency measure and improved clustering performance by balancing both factors. In the experiment, the effectiveness of the proposed method is verified and the specification of the parameters is advised through the various experimental outcomes.},
  archive      = {J_APIN},
  author       = {Zhang, Hengshan and Wang, Yun and Chen, Yanping and Sun, Jiaze},
  doi          = {10.1007/s10489-024-05654-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9641-9654},
  shortjournal = {Appl. Intell.},
  title        = {Consistency-oriented clustering ensemble via data reconstruction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised regression via embedding space mapping and
pseudo-label smearing. <em>APIN</em>, <em>54</em>(20), 9622–9640. (<a
href="https://doi.org/10.1007/s10489-024-05686-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-training is a semi-supervised algorithm that aims to improve prediction effects by exchanging confident instances and pseudo-labels among multiple learners. One central issue is how to mitigate the negative impact of low-quality pseudo-labels during training. In this paper, we propose semi-supervised regression via embedding space mapping and pseudo-label smearing (S2RMS) to ensure that unlabeled data contribute positively to the prediction process. First, a Triplet neural network is trained using pairwise data generated from labeled data. This network maps the training data to the embedding space to better separate dissimilar instances. Second, the embedded data are randomly partitioned into different subsets to train corresponding regression models (a.k.a. regressors). These regressors are integrated into the prediction process. Third, these subsets are augmented using unlabeled data with high similarity to the labeled data and high-confidence pseudo-labels. Here, the similarity and confidence are calculated using the network and the smearing technique, respectively. Experiments are conducted on fourteen datasets, and the results are compared to those of three excellent algorithms. The results show that S2RMS outperforms other co-training and metric semi-supervised regression algorithms. The source code is available at: https://github.com/BetaCatPro/S2RMS .},
  archive      = {J_APIN},
  author       = {Liu, Liyan and Zhang, Jin and Qian, Kun and Min, Fan},
  doi          = {10.1007/s10489-024-05686-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9622-9640},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised regression via embedding space mapping and pseudo-label smearing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From private to public: Benchmarking GANs in the context of
private time series classification. <em>APIN</em>, <em>54</em>(20),
9607–9621. (<a
href="https://doi.org/10.1007/s10489-024-05671-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has proven to be successful in various domains and for different tasks. However, when it comes to private data, several restrictions are making it difficult to use deep learning approaches in these application fields. Recent approaches try to generate data privately instead of applying a privacy-preserving mechanism directly, on top of the classifier. The solution is to create public data from private data in a manner that preserves the privacy of the data. In this work, two very prominent GAN-based architectures were evaluated in the context of private time series classification. In contrast to previous work, mostly limited to the image domain, the scope of this benchmark was the time series domain. The experiments show that especially GSWGAN performs well across various public datasets, outperforming the competitor DPWGAN. An analysis of the generated datasets further validates the superiority of GSWGAN in the context of time series generation. Shows the different techniques to perform classification on a private dataset, including direct classification and synthetic generation + classification. Highlights the effect on the privacy, accuracy, and explainability of the used classifier. Using a GAN that only modifies one component achieves the best results in all three measurements},
  archive      = {J_APIN},
  author       = {Mercier, Dominique and Dengel, Andreas and Ahmed, Sheraz},
  doi          = {10.1007/s10489-024-05671-z},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9607-9621},
  shortjournal = {Appl. Intell.},
  title        = {From private to public: Benchmarking GANs in the context of private time series classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GMLP-KGE: A simple but efficient MLPs with gating
architecture for link prediction. <em>APIN</em>, <em>54</em>(20),
9594–9606. (<a
href="https://doi.org/10.1007/s10489-024-05677-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing knowledge graphs (KGs) suffer from incompleteness, which will be detrimental to a variety of downstream applications. Link prediction is the task of predicting missing links in the KGs and can effectively address the issue of incompleteness by knowledge graph embedding (KGE). ConvE, a relatively popular KGE model based on convolutional neural networks, has shown superiority in link prediction. Some subsequent extension models of ConvE achieve state-of-the-art performance by increasing complexity and training time, which result in a high risk of overfitting and a limited performance due to the large number of parameters concentrated in the fully connected projection layer. To address these challenges, we for the first time innovatively introduce and extend a recently simple network architecture gMLP (based on multi-layer perceptrons MLPs with gating) in vision applications for link prediction. We propose a simple and efficient model called gMLP-KGE, which consists of an embedding layer, an input layer, an extended gMLP layer, and an output layer. Extensive experiments show that the number of parameters of gMLP-KGE is close to that of ConvE and less than other extension models, while gMLP-KGE consistently performs well on seven datasets of different scales under most evaluation metrics.},
  archive      = {J_APIN},
  author       = {Zhang, Fu and Qiu, Pengpeng and Shen, Tong and Cheng, Jingwei and Li, Weijun},
  doi          = {10.1007/s10489-024-05677-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9594-9606},
  shortjournal = {Appl. Intell.},
  title        = {GMLP-KGE: A simple but efficient MLPs with gating architecture for link prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Item-region-based style classification network (IRSN): A
fashion style classifier based on domain knowledge of fashion experts.
<em>APIN</em>, <em>54</em>(20), 9579–9593. (<a
href="https://doi.org/10.1007/s10489-024-05683-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion style is expressed through the way clothing and accessories are put together, as well as the silhouettes, textiles, colors, and shape details of each fashion item. The challenge of style classification lies in the wide visual variation within the same style and the existence of visually similar styles. Fashion experts categorize fashion styles not only by global appearance but also by the attributes of individual items and their combinations. We propose an item-region-based fashion style classification network (IRSN) that effectively classifies fashion styles by analyzing item-level features and their combinations. IRSN extracts item features using item region pooling (IRP), analyzes them separately, and aggregates them using gated feature fusion (GFF). In addition, IRSN applies a dual-backbone architecture that combines a domain-specific feature extractor and a general feature extractor pretrained with a large general image-text dataset. In the experiment, we evaluated IRSN variants based on six widely used backbones, including EfficientNet, ConvNeXt, and SwinTransformer. The IRSN models outperformed their baseline models by an average of 8.9% and a maximum of 16.7% on the FashionStyle14 dataset, and by an average of 9.4% and a maximum of 17.0% on the ShowniqV3 dataset. The visualization results support that the IRSN models are more effective than the baseline models in capturing differences between similar style classes.},
  archive      = {J_APIN},
  author       = {Choi, Jinyoung and Kwon, Youngchae and Kim, Injung},
  doi          = {10.1007/s10489-024-05683-9},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9579-9593},
  shortjournal = {Appl. Intell.},
  title        = {Item-region-based style classification network (IRSN): A fashion style classifier based on domain knowledge of fashion experts},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing 3D hand pose estimation using SHaF: Synthetic hand
dataset including a forearm. <em>APIN</em>, <em>54</em>(20), 9565–9578.
(<a href="https://doi.org/10.1007/s10489-024-05665-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, there is an increased need for training images in 3D hand pose estimation and a higher reliance on computationally intensive 3D mesh annotations for 3D coordinate estimations. Considering this, this study introduces a new hand image dataset called Synthetic Hand Dataset Including a Forearm (SHaF) and an efficient transformer-based three-dimensional (3D) hand pose estimation model tailored to extract hand postures from hand images. The proposed dataset comprises diverse synthetic hand posture images, across various cameras and environmental settings, which were generated using the Unity 3D hand model. It differs from existing artificial hand datasets in that it includes the forearm in its synthetic images. Given that real-world hand images often capture both the hand and forearm, our dataset bolsters the accuracy of hand pose estimation in practical scenarios. Regarding the proposed model, it uses the pose graph module (PGM) and auxiliary pose estimation module (APEM), thereby offering efficient 3D hand pose estimation without requiring 3D mesh information. Through comparative experiments with established datasets and models in hand pose estimation as well as various ablation studies, we confirmed the efficacy of our dataset and the superior performance of the estimation model over that of other methods.},
  archive      = {J_APIN},
  author       = {Lee, Jeongho and Kim, Jaeyun and Kim, Seon Ho and Choi, Sang-Il},
  doi          = {10.1007/s10489-024-05665-x},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9565-9578},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing 3D hand pose estimation using SHaF: Synthetic hand dataset including a forearm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning based adaptive ryu controller model for
quality of experience issues in multimedia streaming for software
defined vehicular networks. <em>APIN</em>, <em>54</em>(20), 9543–9564.
(<a href="https://doi.org/10.1007/s10489-024-05642-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular Ad Hoc Networks (VANETs) are becoming important with the advancement of connected technologies, yet they grapple with the pivotal challenge of ensuring quality of service (QoS) and quality of experience (QoE). This stems from the inherently erratic nature and huge data volumes. While reliability and efficiency remain paramount, the need to address QoS and QoE emerges as a critical motivation. Most current algorithms that address streaming data fall short in terms of QoS performance metrics. Thus this work strives to improve upon QoS metrics and further improve QoE. Our proposed method uses deep learning to address these problems in a realistic software-defined vehicular network (SDVN) based on the QoS and QoE. Our research aims to combine SDVN with a recurrent neural network (RNN) in Ryu SDVN controller. The RNN model encompasses a sophisticated architecture comprising multiple layers of recurrent units designed to capture temporal dependencies in data. Through a meticulously crafted training methodology utilizing techniques such as backpropagation through time, it learns to predict future network states based on historical data. Fine-tuning hyperparameters such as the number of epochs and the batch size enables optimal model convergence. We examine this method in a realistic simulation and compare its effectiveness with conventional approaches. The results show significant gains, i.e., marginal to 28% better than the nearest rival and far better than VANET. We also evaluate the network’s resilience by varying transmission rate and packet size. Our method functions well in high-density situations, suggesting that real-world deployments can benefit from it.},
  archive      = {J_APIN},
  author       = {Sarvade, Varun P. and Kulkarni, Shrirang Ambaji},
  doi          = {10.1007/s10489-024-05642-4},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {20},
  pages        = {9543-9564},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning based adaptive ryu controller model for quality of experience issues in multimedia streaming for software defined vehicular networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory planning with multiplatform spacetime RRT*.
<em>APIN</em>, <em>54</em>(19), 9524–9541. (<a
href="https://doi.org/10.1007/s10489-024-05650-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article presents a method of planning the flight trajectory of a swarm of drones using a modified RRT (Rapidly-exploring Random Tree) algorithm. The version of the RRT algorithm presented in the article is called Multiplatform Spacetime RRT*. The proposed modifications make it possible to determine the flight trajectory of UAVs taking into account time constraints related to the area occupied by each platform. Additionally, the proposed algorithm ensures the avoidance of potential collisions of platforms in the air by using a collision avoidance algorithm used in practice based on geometric methods. Two designed and tested modifications of RRT were presented, based on the basic RRT* and Informed RRT* algorithms. The algorithm used in both tested versions guarantees the determination of the optimal flight path for unmanned platforms in a finite, small number of steps, which solely depends on the number of UAVs involved. This algorithm takes into account the dynamic model of the fixed-wing UAV. The simulation results presented by planning the flight trajectory of a swarm, consisting of three and four UAVs using the Multiplatform Spacetime RRT* algorithm, are significantly better than the algorithms that were compared to achieve these results.},
  archive      = {J_APIN},
  author       = {Burzyński, Wojciech and Stecz, Wojciech},
  doi          = {10.1007/s10489-024-05650-4},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9524-9541},
  shortjournal = {Appl. Intell.},
  title        = {Trajectory planning with multiplatform spacetime RRT*},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized robust linear discriminant analysis for jointly
sparse learning. <em>APIN</em>, <em>54</em>(19), 9508–9523. (<a
href="https://doi.org/10.1007/s10489-024-05632-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear discriminant analysis (LDA) is a well-known supervised method that can perform dimensionality reduction and feature extraction effectively. However, traditional LDA-based methods need to be turned into the trace ratio form to compute the closed-form solution, in which the within-class scatter matrix should be nonsingular. In this article, we design a new model named generalized robust linear discriminant analysis (GRLDA) method to tackle this disadvantage and improve the robustness. GRLDA uses $${L}_{\mathrm{2,1}}$$ -norm on both loss functions to reduce the influence of outliers and on regularization term to obtain joint sparsity simultaneously. The intrinsic graph and the penalty graph are constructed to characterize the intraclass similarity and interclass separability, respectively. A novel optimization method is proposed to solve the proposed model, in which a quadratic problem on the Stiefel manifold is involved to avoid the inverse computation on a singular matrix. We also analyze the computational complexity rigorously. Finally, the experimental results on face, object, and medical images exhibit the superiority of GRLDA.},
  archive      = {J_APIN},
  author       = {Zhu, Yufei and Lai, Zhihui and Gao, Can and Kong, Heng},
  doi          = {10.1007/s10489-024-05632-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9508-9523},
  shortjournal = {Appl. Intell.},
  title        = {Generalized robust linear discriminant analysis for jointly sparse learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EFTNet: An efficient fine-tuning method for few-shot
segmentation. <em>APIN</em>, <em>54</em>(19), 9488–9507. (<a
href="https://doi.org/10.1007/s10489-024-05582-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) aims to segment novel classes given a small number of labeled samples. Most of the existing studies do not fine-tune the model during meta-testing, thus biasing the model towards the base classes and preventing the prediction of novel classes. Other studies only use support images for fine-tuning, which biases the model towards the support images rather than the target query images, especially when there is a large difference between the support and the query images. To alleviate these issues, we propose an $$\underline{{\textbf {e}}}$$ fficient $$\underline{{\textbf {f}}}$$ ine- $$\underline{{\textbf {t}}}$$ uning network (EFTNet) that uses unlabeled query images and predicted pseudo labels to fine-tune the trained model parameters during meta-testing, which can bias the model towards the target query images. In addition, we design a query-to-support module, a support-to-query module, and a discrimination module to evaluate which fine-tuning round the model achieves optimal results. Moreover, the query-to-support module also takes the query images and their pseudo masks as part of the support images and support masks, which causes the prototypes to contain query information and tend to obtain better predictions. As a new meta-testing scheme, our EFTNet can be easily combined with existing studies and greatly improve their model performance without repeating the meta-training phase. Many experiments on PASCAL- $$5^i$$ and COCO- $$20^i$$ prove the effectiveness of our EFTNet. The EFTNet also achieves new state-of-the-art performance. Codes are available at https://github.com/Jiaguang-NEU/EFTNet .},
  archive      = {J_APIN},
  author       = {Li, Jiaguang and Wang, Yubo and Gao, Zihan and Wei, Ying},
  doi          = {10.1007/s10489-024-05582-z},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9488-9507},
  shortjournal = {Appl. Intell.},
  title        = {EFTNet: An efficient fine-tuning method for few-shot segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatial-temporal multi-factor fusion graph neural network
for traffic prediction. <em>APIN</em>, <em>54</em>(19), 9464–9487. (<a
href="https://doi.org/10.1007/s10489-024-05656-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction, which provides dynamic data support for intelligent transportation systems, has always been a topic of great interest. Accurate prediction of traffic flow is vital for optimizing traffic management and planning and improving traffic efficiency. Existing traffic flow prediction models usually consider only a single influencing factor when modeling spatial-temporal correlation and fail to comprehensively consider the multiscale factors corresponding to each module, resulting in incomplete spatial-temporal modeling and thus affecting prediction accuracy. For this reason, this paper proposes a spatial-temporal multifactor fusion graph neural network (STMFGNN), which aims to characterize spatial-temporal features more comprehensively. First, in the spatial feature extraction module, we parallelly utilize dynamic similarity graphs and static adjacency graphs to perform graph convolution and introduce the gated fusion module to self-learn the dynamic influence weight so that our model can integrate the information of global hidden knowledge and local prior knowledge and capture the multiscale spatial dependencies between nodes. Second, the model combines gated tanh unit convolution with a multireceptive field and gated recurrent units in the temporal feature extraction module. Similarly, it utilizes the gated fusion module to adaptively and dynamically adjust the importance weights of the two components. This enables the acquisition of multiscale temporal dependency information at both short-term and long-term levels. In addition, we employ an improved generative adversarial imputation network for incomplete traffic flow data. The experimental results on four real-world datasets show that our proposed method consistently outperforms other baseline models, achieving state-of-the-art performance. The key source code and data are available at https://github.com/Keaiii3/STMFGNN .},
  archive      = {J_APIN},
  author       = {Jia, Hui and Yu, Zixuan and Chen, Yanping and Xia, Hong},
  doi          = {10.1007/s10489-024-05656-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9464-9487},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal multi-factor fusion graph neural network for traffic prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust multi-view clustering via collaborative constraints
and multi-layer concept factorization. <em>APIN</em>, <em>54</em>(19),
9446–9463. (<a
href="https://doi.org/10.1007/s10489-024-05652-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of effective multi-view clustering algorithms has recently garnered significant research attention. In this paper, we develop a robust multi-view clustering via collaborative constraints and multi-layer concept factorization (RMCCMCF) model to enhance clustering power and robustness by mining low-rank data and hierarchical information from multiple views. This approach adopts low rank (LR) and deep learning (DL) to explore the essential and hierarchical structures hidden in various views. The proposed approach applies multiple graph regularization constraints to extract manifold information from different views. Kernel technology is used for concept factorization in high-dimensional space to effectively distinguish different classes of sample points. Additionally, we design an alternating iterative optimization approach to solve the RMCCMCF algorithm and discuss its convergence. The results of extensive experiments conducted on the CBSR, HW2Sources, 3Sources, CUB, and UCI datasets demonstrate that the RMCCMCF approach outperforms several other recent multi-view clustering approaches in terms of recognition performance.},
  archive      = {J_APIN},
  author       = {Liu, Guoqing and Ge, Hongwei and Li, Ting and Su, Shuzhi and Gao, Penglian},
  doi          = {10.1007/s10489-024-05652-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9446-9463},
  shortjournal = {Appl. Intell.},
  title        = {Robust multi-view clustering via collaborative constraints and multi-layer concept factorization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online learning from capricious data streams via shared and
new feature spaces. <em>APIN</em>, <em>54</em>(19), 9429–9445. (<a
href="https://doi.org/10.1007/s10489-024-05681-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data streams refer to data sequences generated at a high rate over a continuous period, such as social media analysis, financial transaction monitoring, and sensor data processing. Most existing data stream mining methods make assumptions about the feature space, assuming it is either fixed or undergoes regular changes, such as trapezoidal or evolving data streams. However, these restrictions do not hold for real-world applications where data streams may exhibit arbitrary missing features. To address the issue of arbitrary missing features in the feature space, we propose the Online Learning from Capricious Data Streams (OLCDS) algorithm and its variant, OLCDS-I. Specifically, OLCDS first identifies the higher uncertainty features that can provide more information for the optimization model. Then, based on the shared and new feature space, we formulate the constrained optimization problem using the soft margin technique. We deduce the update rules and use model sparsity to retain the essential features for classifier learning. Compared to existing online learning approaches, our new method eliminates the need for feature space assumptions and avoids generating missing features. Extensive experiments compared with five state-of-the-art methods on ten real-world datasets demonstrate the effectiveness and efficiency of our new algorithms},
  archive      = {J_APIN},
  author       = {Zhou, Peng and Zhang, Shuai and Mu, Lin and Yan, Yuanting},
  doi          = {10.1007/s10489-024-05681-x},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9429-9445},
  shortjournal = {Appl. Intell.},
  title        = {Online learning from capricious data streams via shared and new feature spaces},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DMFusion: LiDAR-camera fusion framework with depth merging
and temporal aggregation. <em>APIN</em>, <em>54</em>(19), 9412–9428. (<a
href="https://doi.org/10.1007/s10489-024-05627-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal 3D object detection is an active research topic in the field of autonomous driving. Most existing methods utilize both camera and LiDAR modalities but fuse their features through simple and insufficient mechanisms. Additionally, these approaches lack reliable positional and temporal information due to their reliance on single-frame camera data. In this paper, a novel end-to-end framework for 3D object detection was proposed to solve these problems through spatial and temporal fusion. The spatial information of bird’s-eye view (BEV) features is enhanced by integrating depth features from point clouds during the conversion of image features into 3D space. Moreover, positional and temporal information is augmented by aggregating multi-frame features. This framework is named as DMFusion, which consists of the following components: (i) a novel depth fusion view transform module (referred to as DFLSS), (ii) a simple and easily adjustable temporal fusion module based on 3D convolution (referred to as 3DMTF), and (iii) a LiDAR-temporal fusion module based on channel attention mechanism. On the nuScenes benchmark, DMFusion improves mAP by 1.42% and NDS by 1.26% compared with the baseline model, which demonstrates the effectiveness of our proposed method. The code will be released at https://github.com/lilkeker/DMFusion .},
  archive      = {J_APIN},
  author       = {Yu, Xinyi and Lu, Ke and Yang, Yang and Ou, Linlin},
  doi          = {10.1007/s10489-024-05627-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9412-9428},
  shortjournal = {Appl. Intell.},
  title        = {DMFusion: LiDAR-camera fusion framework with depth merging and temporal aggregation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Existence and simulation of multiple solutions to an
optimization model for completing incomplete fuzzy preference relations.
<em>APIN</em>, <em>54</em>(19), 9395–9411. (<a
href="https://doi.org/10.1007/s10489-024-05667-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When addressing a decision making problem with incomplete preference relations, missing information could be estimated by proposing an optimization model. The previous studies always focus on a unique solution to optimization models through a software program. But theoretical and simulation investigations of multiple solutions are seldom considered. This paper investigates the existence of multiple solutions to an optimization model and proposes a simulation procedure. First, an optimization model is recalled for completing incomplete fuzzy preference relations. It is the first time to theoretically prove the existence of multiple solutions to the optimization model under various incomplete entries. The obtained results reveal that the optimal solution to an optimization model may be an interval value, which is dependent on the number and position of missing entries in an incomplete fuzzy preference relation. The idea of multiple solutions is further extended to the situation where an intransitive fuzzy preference relation should be adjusted to a weakly transitive matrix. Second, multiple solutions to the optimization model are simulated using the quantum-behaved particle swarm optimization algorithm. It is found that multiple solutions do appear under some conditions by only running the algorithm for multiple times. Finally, the impact of multiple solutions on the optimal alternative(s) of a decision making problem is analyzed by comparing with the existing studies. The result shows that the existence of multiple solutions reflects the uncertainty of optimization models, which is of concerns to propose an effective decision-making model.},
  archive      = {J_APIN},
  author       = {Zhang, Jiawei and Liu, Fang and Liu, Zulin and Pérez, Ignacio Javier and Cabrerizo, Francisco Javier},
  doi          = {10.1007/s10489-024-05667-9},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9395-9411},
  shortjournal = {Appl. Intell.},
  title        = {Existence and simulation of multiple solutions to an optimization model for completing incomplete fuzzy preference relations},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting experience replayable conditions. <em>APIN</em>,
<em>54</em>(19), 9381–9394. (<a
href="https://doi.org/10.1007/s10489-024-05685-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experience replay (ER) used in (deep) reinforcement learning is considered to be applicable only to off-policy algorithms. However, there have been some cases in which ER has been applied for on-policy algorithms, suggesting that off-policyness might be a sufficient condition for applying ER. This paper reconsiders more strict “experience replayable conditions” (ERC) and proposes the way of modifying the existing algorithms to satisfy ERC. In light of this, it is postulated that the instability of policy improvements represents a pivotal factor in ERC. The instability factors are revealed from the viewpoint of metric learning as i) repulsive forces from negative samples and ii) replays of inappropriate experiences. Accordingly, the corresponding stabilization tricks are derived. As a result, it is confirmed through numerical simulations that the proposed stabilization tricks make ER applicable to an advantage actor-critic, an on-policy algorithm. Moreover, its learning performance is comparable to that of a soft actor-critic, a state-of-the-art off-policy algorithm.},
  archive      = {J_APIN},
  author       = {Kobayashi, Taisuke},
  doi          = {10.1007/s10489-024-05685-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9381-9394},
  shortjournal = {Appl. Intell.},
  title        = {Revisiting experience replayable conditions},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-view graph convolutional network for multi-label text
classification. <em>APIN</em>, <em>54</em>(19), 9363–9380. (<a
href="https://doi.org/10.1007/s10489-024-05666-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label text classification refers to assigning multiple relevant category labels to each text, which has been widely applied in the real world. To enhance the performance of multi-label text classification, most existing methods only focus on optimizing document and label representations, assuming accurate label-document similarity is crucial. However, whether the potential relevance between labels and if the problem of the long-tail distribution of labels could be solved are also key factors affecting the performance of multi-label classification. To this end, we propose a multi-label text classification model called DV-MLTC, which is based on a dual-view graph convolutional network to predict multiple labels for text. Specifically, we utilize graph convolutional neural networks to explore the potential correlation between labels in both the global and local views. First, we capture the global consistency of labels on the global label graph based on existing statistical information and generate label paths through a random walk algorithm to reconstruct the label graph. Then, to capture relationships between low-frequency co-occurring labels on the reconstructed graph, we guide the generation of reasonable co-occurring label pairs within the local neighborhood by utilizing the local consistency of labels, which also helps alleviate the long-tail distribution of labels. Finally, we integrate the global and local consistency of labels to address the problem of highly skewed distribution caused by incomplete label co-occurrence patterns in the label co-occurrence graph. The Evaluation shows that our proposed model achieves competitive results compared to existing state-of-the-art methods. Moreover, our model achieves a better balance between efficiency and performance.},
  archive      = {J_APIN},
  author       = {Li, Xiaohong and You, Ben and Peng, Qixuan and Feng, Shaojie},
  doi          = {10.1007/s10489-024-05666-w},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9363-9380},
  shortjournal = {Appl. Intell.},
  title        = {Dual-view graph convolutional network for multi-label text classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discriminative shapelet learning via temporal clustering and
matrix factorization. <em>APIN</em>, <em>54</em>(19), 9345–9362. (<a
href="https://doi.org/10.1007/s10489-024-05672-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying discriminative patterns, known as shapelets, within time series is a critical step in many time series classification tasks. A major limitation of shapelet learning is that often hindered by their unsupervised methods, treating shapelet learning as an unsupervised subsequence clustering process and discovery based on pre-defined metric, which performed sequentially. This sequential procedure presents challenges, as it fails to establish a direct connection between shapelets and samples, and lacks the capacity to explicitly incorporate label information. In this paper, we proposed a novel shapelet learning algorithm called Discriminative Shapelet Learning via Temporal Clustering and Matrix Factorization (DSLMF). DSLMF introduced a joint framework that combines matrix factorization and coherent temporal clustering to discovery salient and coherent feature subsets. To further enhance discriminability and prevent arbitrary shapelet shapes, DSLMF integrates a label-specific shapelet regularization as a guiding mechanism enabling the learning of shapelets optimized for higher classification performance. The proposed algorithm has shown to be effective for capturing the temporal cluster structure and interpretability of shapelet-based method. The results of experiments showcased in this paper highlight DSLMF’s effectiveness in capturing temporal cluster structures and learning meaningful shapelets, ultimately leading to promising performance on benchmark datasets.},
  archive      = {J_APIN},
  author       = {Chen, Bo and Fang, Min and Wang, GuiZhi},
  doi          = {10.1007/s10489-024-05672-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9345-9362},
  shortjournal = {Appl. Intell.},
  title        = {Discriminative shapelet learning via temporal clustering and matrix factorization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Context-aware cross feature attentive network for
click-through rate predictions. <em>APIN</em>, <em>54</em>(19),
9330–9344. (<a
href="https://doi.org/10.1007/s10489-024-05659-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction aims to estimate the likelihood that a user will interact with an item. It has gained significant attention in areas such as online advertising and e-commerce. Existing studies have verified that feature interactions play a crucial role in CTR prediction, highlighting the need for efficient modeling of these interactions. However, most existing approaches in CTR prediction tend to overlook specific feature characteristics, relying instead on deep neural networks or advanced attention mechanisms to learn meaningful feature interactions. In real-world scenarios, features can be categorized into groups based on prior information, which motivates the explicit consideration of interactions between groups of features. For example, the unique context of an item often has a substantial correlation with a particular user, and a specific item often has a strong relationship with a particular user demographic. An efficient model, therefore, requires an appropriate inductive bias to learn these relationships. To address this issue, we present a Context-aware Cross Feature Attentive Network (CCFAN) that explicitly considers the relationship or association between items and users. We categorize input variables into four groups: user, item, user context, and item context, which allows learning significant interactions between (user)-(item context) and (item)-(user context) in an explicit way. These interactions are learned using a multi-head self-attention network that includes modules for user-item interaction and cross-feature interaction. To demonstrate the effectiveness of CCFAN, we conduct experiments on two public benchmark datasets, MovieLens1M and Frappe, and one real-world dataset from an educational service provider, WJTB. The experimental results show that CCFAN not only outperforms previous state-of-the-art CTR methods but also offers a high degree of explainability.},
  archive      = {J_APIN},
  author       = {Lee, Soojin and Hwang, Sangheum},
  doi          = {10.1007/s10489-024-05659-9},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9330-9344},
  shortjournal = {Appl. Intell.},
  title        = {Context-aware cross feature attentive network for click-through rate predictions},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel fusion feature imageization with improved extreme
learning machine for network anomaly detection. <em>APIN</em>,
<em>54</em>(19), 9313–9329. (<a
href="https://doi.org/10.1007/s10489-024-05673-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the complexity and quantity of network data continue to increase, accurate and efficient anomaly detection methods become critical. Deep learning-based methods are suitable for real-time detection because they leverage neural networks to efficiently process massive amounts of data. However, for complex network environments and unknown threats, it is difficult to acquire balanced datasets for training, resulting in low model accuracy. Moreover, in a large-scale network environment, the model training process is complicated and resource-consuming, ignoring the important information hidden behind the data and poor scalability. To address these issues, we develop a novel network anomaly detection method that integrates fused feature imageization with an enhanced extreme learning machine, termed GMD-DELM. The network data stream features are transformed into images by an adaptive transformation method, generating a feature representation with highly enhanced data recognition capability. In addition, a ResNeXt network embedded with an attention mechanism is used to extract high-level features from images, enhancing the ability of deep learning networks to extract important features from network streams. Finally, we implement a network anomaly detection method established on an improved adaptive differential evolution kernel extreme learning machine. The experimental results demonstrate that the proposed model achieves notable enhancements achieved by the proposed model in reducing feature redundancy and improving accuracy compared to existing network anomaly detection models. Furthermore, our model exhibits improved stability and robustness in detecting corrupted network data containing noise.},
  archive      = {J_APIN},
  author       = {Yang, Geying and Wu, Jinyu and Wang, Lina and Wang, Qinghao and Liu, Xiaowen and Fu, Jie},
  doi          = {10.1007/s10489-024-05673-x},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9313-9329},
  shortjournal = {Appl. Intell.},
  title        = {A novel fusion feature imageization with improved extreme learning machine for network anomaly detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning based mapless navigation for
industrial AMRs: Advancements in generalization via potential risk state
augmentation. <em>APIN</em>, <em>54</em>(19), 9295–9312. (<a
href="https://doi.org/10.1007/s10489-024-05679-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel Deep Reinforcement Learning (DRL)-based approach for mapless navigation in Industrial Autonomous Mobile Robots, emphasizing advancements in generalization through Potential Risk State Augmentation (PRSA) and an adaptive safety optimization reward function. Traditional LiDAR-based state representations often fail to capture environmental intricacies, leading to suboptimal performance. PRSA addresses this by improving the representation of high-dimensional LiDAR data, focusing on essential risk-related information to reduce redundancy and enhance the DRL agent’s generalization across various industrial settings. The adaptive reward function integrated with intrinsic reward mitigates the issue of sparse rewards in complex tasks, promoting faster learning and optimal policy convergence. Extensive experiments demonstrate that our method maintains a high success rate (over 90%) and low collision risk in narrow and dynamic environments compared to existing DRL-based methods. Meanwhile, compared with the classic navigation baseline, the proposed method improves the success rate by about 33% and reduces the mean navigation time by about 48% in real-world navigation tasks. The direct transfer of policies trained in simulations to real-world environments has demonstrated significant potential for enhancing both the efficacy and reliability of autonomous navigation.},
  archive      = {J_APIN},
  author       = {Xu, Degang and Chen, Peng and Zhou, Xianhan and Wang, Yizhi and Tan, Guanzheng},
  doi          = {10.1007/s10489-024-05679-5},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9295-9312},
  shortjournal = {Appl. Intell.},
  title        = {Deep reinforcement learning based mapless navigation for industrial AMRs: Advancements in generalization via potential risk state augmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Esophagogastroscopy for predicting endoscopic
ultrasonography t-stage by utilizing deep learning methods in esophageal
cancer. <em>APIN</em>, <em>54</em>(19), 9286–9294. (<a
href="https://doi.org/10.1007/s10489-024-05640-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Endoscopic ultrasonography (EUS) is commonly utilized in preoperative staging of esophageal cancer, however with additional pain and cost as well as adverse events. Meanwhile, the accuracy of EUS is highly depend on the training and practice of operators and not universally available. Different operators would lead to high inter-observer variability. Therefore, it is desirable to explore an alternative way to determine preoperative T stage in esophageal cancer. Whether conventional endoscopy possess the ability to predict EUS T stage has never been investigated yet. In current study, with the assistance of Artificial intelligence, we have developed a deep learning model to predict EUS T stage based on 9,714 images collected from 3,333 patients. ResNet-152 pre-trained on the ImageNet dataset was trained with the appropriate transfer learning and fine-tuning strategies on the conventional endoscopic images and their corresponding labels (e.g., T1, T2, T3, T4 and Normal). Meanwhile, augmentation strategies including rotation and flipping were performed to increase the number of images to improve the prediction accuracy. Finally, 4,382 T1, 243 T2, 3,985 T3, 1,102 T4, 14,302 controls images were obtained and split into training dataset, validation dataset and independent testing dataset with the ratio of 4:1:1. Our model could achieve a satisfied performance with an area under the receiver-operating curve (AUC) were 0.9767, 0.9637, 0.9597 and 0.9442 for T1, T2, T3 and T4, respectively in independent testing dataset. In conclusion, conventional gastroscopy combined with artificial intelligence have the great potential to predict EUS T stage.},
  archive      = {J_APIN},
  author       = {Zhang, Tiemei and Chen, Zhen and Wang, Zhuo-Zhi and Jia, Xiaoti and Meng, Shuai and Zhang, Ke and Zhou, Dejun and Zhang, Jun and Chen, Yong-Zi},
  doi          = {10.1007/s10489-024-05640-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9286-9294},
  shortjournal = {Appl. Intell.},
  title        = {Esophagogastroscopy for predicting endoscopic ultrasonography T-stage by utilizing deep learning methods in esophageal cancer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A real-time human bone fracture detection and classification
from multi-modal images using deep learning technique. <em>APIN</em>,
<em>54</em>(19), 9269–9285. (<a
href="https://doi.org/10.1007/s10489-024-05588-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human bone is an essential structure that allows the body to move. It is a common observation in contemporary society that bone fractures occur frequently. The doctors use X-rays, Computed Tomography scans, and Magnetic Resonance Imaging to determine the location of the broken bone. The previous method of evaluating broken bones in person was inefficient, often leading to errors. However, introducing new, advanced evaluation techniques has obliterated these issues. Consequently, it is essential to develop an automated system for identifying fractured bones. This research uses a new deep-learning model named &quot;You Only Look Once (version 8)&quot; to distinguish between healthy and broken bones from multi-modal images. We utilized a customized dataset named &quot;Human Bone Fractures Multi-modal Image Dataset&quot;, which includes 641 images representing ten different classes of bone fractures. The small data set leads to an over-fitting of the model. To increase the amount of data, we utilized a data augmentation technique. Three experiments were conducted to assess the effectiveness of the model. The findings of the experiments show that the proposed study effectively identifies and classifies different types of fractures in this area. Our system attained 95% precision, 93% recall, and 92% of mean average precision. The outcomes demonstrated that the method achieves cutting-edge performance.},
  archive      = {J_APIN},
  author       = {Parvin, Shahnaj and Rahman, Abdur},
  doi          = {10.1007/s10489-024-05588-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9269-9285},
  shortjournal = {Appl. Intell.},
  title        = {A real-time human bone fracture detection and classification from multi-modal images using deep learning technique},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). DGNN-MN: Dynamic graph neural network via memory regenerate
and neighbor propagation. <em>APIN</em>, <em>54</em>(19), 9253–9268. (<a
href="https://doi.org/10.1007/s10489-024-05500-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Graph Neural Network (DGNN) models have been widely used for modelling, prediction and recommendation tasks in domains such as e-commerce and social networks, due to their ability to capture node interaction features and temporal features. Current methods for dynamic graph representation learning mainly depend on querying K-hop neighbors and the triadic closure law to derive node representations. However, as the number of layers in neural networks increases, this can cause problems with over-smoothing and overly complex calculations. Additionally, current models cannot ensure that events arrive at adjacent nodes in chronological order according to timestamps. To address these problems, we propose a Dynamic Graph Neural Network via Memory Regenerate and Neighbor Propagation(DGNN-MN) model. The model presents a memory regeneration strategy for obtaining node time information features and a time edge-propagating method for obtaining neighbour information. By combining these two methods to fuse output vectors, it captures node feature representations. In addition, we present a strategy for the timestamp encoding of node messages, which effectively ensures that node messages propagate to neighboring nodes in an ordered manner according to timestamps, thereby better capturing the temporal characteristics of events in dynamic graphs. Extensive experiments conducted on five public datasets demonstrate the effectiveness of DGNN-MN for link prediction and node classification task. Furthermore, the method outperforms other state-of-the-art methods. The data and code are available on GitHub.},
  archive      = {J_APIN},
  author       = {Li, Chao and Liu, Runshuo and Fu, Jinhu and Zhao, Zhongying and Duan, Hua and Zeng, Qingtian},
  doi          = {10.1007/s10489-024-05500-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9253-9268},
  shortjournal = {Appl. Intell.},
  title        = {DGNN-MN: Dynamic graph neural network via memory regenerate and neighbor propagation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Achieving accurate and balanced regional electric vehicle
charging load forecasting with a dynamic road network: A case study of
lanzhou city. <em>APIN</em>, <em>54</em>(19), 9230–9252. (<a
href="https://doi.org/10.1007/s10489-024-05626-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial and temporal predictions of electric vehicle (EV) charging loads provide a basis for further research on synergistic operation of road-vehicle-electricity networks with different attributes, which is important for siting and capacity building of urban road networks and charging stations, as well as for long-term planning and operation of power systems. However, some of the variables in EV charging load prediction are often given as random variables or constants, and to enhance the modeling and prediction accuracy for EV charging loads, data- and model-driven concepts were combined, and a novel model was proposed to achieve accurate balanced regional EV charging load forecasting with dynamic road networks: a case study of Lanzhou city. First, a road-vehicle-grid integration model was constructed, and an EV was used as an intermediate medium to initially integrate the flexible domains of the two layers of the road network and grid for establishing the actual road network topology in the city and for comparing static and dynamic road network models. Second, particle swarm optimization (PSO) was employed to optimize the backpropagation (BP) neural network for predicting future regional EV ownership. In addition, the PSO-BP-Monte Carlo (MC) model was refined for obtaining accurate spatial and temporal predictions of regional short-term charging loads through the introduction of an EV real-time unit mileage power consumption model with the use of M/M/c queue theory for determining charging waiting times. Finally, a simulation was conducted in the urban area of Lanzhou city as an example of actual traffic roads, and the results showed that the proposed model could be applied to reasonably effectively and more accurately predict the regional load conditions. The average growth in the peak load within the region over the next five years will reach 21.07 $$\%$$ , and accurately balances the occupancy rate of each charging pile of the charging station, and the dynamic road network will experience a decrease in the peak-valley difference between the loads of the static network of 5.92 $$\%$$ . Compared to those obtained with other methods, the single-day load distribution was more balanced, and the road access time better conformed with the actual road access conditions, which verifies the effectiveness and feasibility of the proposed method and lays a foundation for the next step of research on synergistic operation of road-vehicle-grid networks with different attributes.},
  archive      = {J_APIN},
  author       = {Li, Hanting and Tang, Minan and Mu, Yunfei and Wang, Yueheng and Yang, Tong and Wang, Hongjie},
  doi          = {10.1007/s10489-024-05626-4},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9230-9252},
  shortjournal = {Appl. Intell.},
  title        = {Achieving accurate and balanced regional electric vehicle charging load forecasting with a dynamic road network: A case study of lanzhou city},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical contrastive representation for zero shot
learning. <em>APIN</em>, <em>54</em>(19), 9213–9229. (<a
href="https://doi.org/10.1007/s10489-024-05531-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning aims to identify unseen (novel) objects, using only labeled samples from seen (base) classes. Existing methods usually learn visual-semantic interactions or generate absent visual features of unseen classes to compensate for the data imbalance problem. However, existing methods ignore the representation quality of visual-semantic pairs, resulting in unsatisfactory alignment and prediction bias. To tackle these issues, we propose a Hierarchical Contrastive Representation learning paradigm, termed HCR, which fully exploits model representation capability and discriminative information. Specifically, we first propose a contrastive embedding, which preserves not only high quality representations but also discriminative enough information from class-level and instance-level supervision. Then, we introduce a regressor by valuable prior knowledge for conducting more desirable visual-semantic alignment for unseen classes. A pluggable calibrator is also aggregated to further alleviate prediction bias in contrastive embedding. Extensive experiments show that the proposed HCR can significantly outperform the state-of-the-arts on popular benchmarks under ZSL and challenging GZSL settings.},
  archive      = {J_APIN},
  author       = {Lu, Ziqian and Lu, Zheming and He, Zewei and Sun, Xuecheng and Luo, Hao and Zheng, Yangming},
  doi          = {10.1007/s10489-024-05531-w},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9213-9229},
  shortjournal = {Appl. Intell.},
  title        = {Hierarchical contrastive representation for zero shot learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label distribution feature selection based on label-specific
features. <em>APIN</em>, <em>54</em>(19), 9195–9212. (<a
href="https://doi.org/10.1007/s10489-024-05668-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning, where deal with label ambiguity by describing the degree of relevance of each label to a specific instance. As a novel machine learning paradigm, the curse of dimensionality is one of the prominent problems. Feature selection is a vital preprocessing step to reduce the high dimensionality of data. However, most existing label distribution feature selection methods focus on selecting a feature subset that has relevant capabilities for all labels, ignoring label-specific features with the maximum discriminatory power for each label. To tackle this issue, a label distribution feature selection algorithm based on label-specific features is proposed in this paper. Initially, we introduce a feature selection optimization model for label distribution data that simultaneously considers common and label-specific features, leveraging sparse learning to further investigate the intricate relationships between features and labels. Subsequently, the label correlation coefficient is employed to enhance the collaborative learning effect of labels. Finally, the relevance between features and labels is taken into account to guide the feature selection process, which can effectively eliminate the redundant features. Comprehensive experiments demonstrate the advantage of our proposed method over other well-established feature selection algorithms for selecting label-specific features to label distribution data.},
  archive      = {J_APIN},
  author       = {Shu, Wenhao and Xia, Qiang and Qian, Wenbin},
  doi          = {10.1007/s10489-024-05668-8},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9195-9212},
  shortjournal = {Appl. Intell.},
  title        = {Label distribution feature selection based on label-specific features},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Class feature sub-space for few-shot classification.
<em>APIN</em>, <em>54</em>(19), 9177–9194. (<a
href="https://doi.org/10.1007/s10489-024-05635-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning is used in the development of models that can acquire novel class concepts from limited training samples, facilitating rapid adaptation to novel, intricate, and varied tasks encountered in real-world scenarios. Compared to meta-training, traditional batch training exhibits superior efficiency. However, when addressing few-shot learning tasks, the features extracted by batch-trained models often struggle to effectively represent novel class concepts, resulting in unsatisfactory performance. This challenge arises from two primary issues. First, the models lack the capacity to autonomously map novel class features into an effective discriminant subspace, resulting in the interference of class-independent feature components during metric calculations. Second, the limited sample size hinders the ability of the model to accumulate valuable experience, leading to representations that deviate from the true class center. To address these issues, we introduce the Class Feature Sub-space (CFS-space) as an effective discriminant space for few-shot classification; it preserves class features and suppresses noise components by mapping the extracted features into the CFS-space. Furthermore, we incorporate empirical knowledge from the base set and calibrate the prototypes within the CFS-Space to enhance the class representations. Ablation studies affirm the efficacy of our approach. As evaluated in 5-way 1/5-shot tasks, our method achieves impressive accuracies of 66.42%/83.69% on mini-ImageNet, 72.07%/86.36% on tiered-ImageNet, and 79.34%/90.42% on CUB, significantly narrowing the performance gap between the batch-training and the meta-training paradigm.},
  archive      = {J_APIN},
  author       = {Song, Bin and Zhu, Hong and Wang, Bingxin and Bi, Yuandong},
  doi          = {10.1007/s10489-024-05635-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9177-9194},
  shortjournal = {Appl. Intell.},
  title        = {Class feature sub-space for few-shot classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning improvement of spiking neural networks with dynamic
adaptive hyperparameter neurons. <em>APIN</em>, <em>54</em>(19),
9158–9176. (<a
href="https://doi.org/10.1007/s10489-024-05629-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) which use spiking neurons as a component, have shown substantial promise in simulating biological neuron mechanisms and saving computing power. However, preset or suboptimal hyperparameters are still used for spiking neurons adopted in SNNs, and the heterogeneity of neurons is limited, limiting SNNs inference accuracy. Inspired by neuroscience observations that hyperparameters are related to the membrane potential in neurons, in this paper, a new module for implementing adaptive hyperparameters dynamically is proposed, enabling flexible hyperparameters to be obtained for spiking neurons. In addition, inspired by neuroscience observations that heterogeneity in current drive force of synaptic integration process, we propose a new module to distribute synaptic driving force factors in neurons to maximize synaptic integration rationalization. Utilizing these methods enables SNNs to have fast convergence capability and appropriate inference of neuron dynamics. Finally, the effects of the proposed adaptive hyperparameters and driving force distribution mechanism are evaluated on different datasets. The results show that SNNs with our methods have improved accuracy on all test datasets, exhibit robustness to different initial hyperparameters, and exhibit more realistic biological behavior.},
  archive      = {J_APIN},
  author       = {Liang, Jiakai and Wang, Chao and Ma, De and Li, Ruixue and Yue, Keqiang and Li, Wenjun},
  doi          = {10.1007/s10489-024-05629-1},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9158-9176},
  shortjournal = {Appl. Intell.},
  title        = {Learning improvement of spiking neural networks with dynamic adaptive hyperparameter neurons},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of blast-hole utilization rate using structured
nonlinear support vector machine combined with optimization algorithms.
<em>APIN</em>, <em>54</em>(19), 9136–9157. (<a
href="https://doi.org/10.1007/s10489-024-05614-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blasting is the primary method for ultra-deep roadway engineering, which is facing the challenge of low footage caused by unsatisfactory blasting effects. Among all the evaluation indicators, the blast-hole utilization rate is the most important index for measuring blasting effect. Consequently, accurately predicting this index is essential for improving roadway excavation efficiency. In recent decades, the field applications of artificial intelligence have emerged as the prime method, yet the issue of data loss and large errors in large-scale data processing remains unresolved. In this study, novel Structured Nonlinear Support Vector Machine (SNSVM) is introduced as the primary research tool. To enhance prediction performance and accuracy, Genetic Algorithm (GA), Particle Swarm Optimization (PSO) and Sparrow Search Algorithm (SSA) are utilized to optimize the hyperparameters of SNSVM. The prediction models comprise fourteen influencing factors, constituting the comprehensive blasting effect prediction system based on artificial intelligence. The principal criteria for assessing the performance of various models are the error correlation coefficients (Root Mean Square Error (RMSE), Mean Absolute Percentage Error (MAPE), R-Square (R2)) and the Receiver Operating Characteristic (ROC) curve (standard deviation rate (γ)). Among the models considered, SSA-SNSVM exhibited the greatest capability when the swarm size is 90. The RMSE, MAPE and R2 values of training datasets are 0.0070, 15.54% and 0.9295, respectively. The RMSE, MAPE and R2 values of testing datasets are 0.0086, 16.37% and 0.9490, respectively. Furthermore, the minimum standard deviation rate of SSA-SNSVM serves as the vital index for measuring the accuracy, with a value of 0.11. Subsequently, the sensitivity analysis results indicate that the most sensitive factor of blast-hole utilization rate is the surrounding rock itself. The comprehensive blasting effect evaluation is of significant importance for the dynamic adjustment of on-site blasting schemes, including roadway excavation, shaft excavation, or pressure-relief engineering.},
  archive      = {J_APIN},
  author       = {Yu, Bingbing and Wang, Bo and Li, Yi and Zhang, Yuantong and Wang, Guohao},
  doi          = {10.1007/s10489-024-05614-8},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9136-9157},
  shortjournal = {Appl. Intell.},
  title        = {Prediction of blast-hole utilization rate using structured nonlinear support vector machine combined with optimization algorithms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Better electrobiological markers and a improved automated
diagnostic classifier for schizophrenia—based on a new EEG effective
information estimation framework. <em>APIN</em>, <em>54</em>(19),
9105–9135. (<a
href="https://doi.org/10.1007/s10489-024-05669-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in AI techniques have fueled research on using EEG data for psychiatric disorder diagnosis. Despite EEG’s cost-effectiveness and high temporal resolution, low Signal-to-Noise Ratio (SNR) hampers critical marker extraction and model improvement, while denoising techniques will lead to a loss of effective information in EEG. The aim of this study is to employ AI methods for the processing of raw EEG data. The primary objectives of the processing are twofold: first, to acquire more reliable markers for schizophrenia, and second, to construct a superior automatic classification for schizophrenia. To remove the noises and retain task-related (classification tasks) effective information mostly, we introduce an Effective Information Estimation Framework (EIEF) based on three key principles: the task-centered approach, leveraging 1D-CNNs’ test metrics to gauge effective information proportion, and feedback. We address a theoretical foundation by integrating these principles into mathematical derivations to propose the mathematical model of EIEF. In experiments, we established a paradigm pool of 66 denoising paradigms, with EIEF successfully identifying the optimal paradigms (on two datasets) for restoring effective information. Utilizing the processed dataset, we trained a 3D-CNN for automatic schizophrenia diagnosis, achieving outstanding test accuracies of 99.94 $$\%$$ on dataset 1 and 98.02 $$\%$$ on dataset 2 in subject-dependent evaluations, and accuracies of 89.85 $$\%$$ on dataset 1 and 98.02 $$\%$$ on dataset 2 in subject-independent evaluations. Additionally, we extracted 38 features from each channel of both processed and raw datasets, revealing that 20.86 $$\%$$ (dataset 1) of feature distribution differences between the patients and the healthy exhibited significant changes after implementing the optimal paradigm. We enhance model performance and extract more reliable electrobiological markers. These findings have promising implications for advancing the field of the clinical diagnosis and pathological analysis of Schizophrenia.},
  archive      = {J_APIN},
  author       = {Jing, Tianyu and Wang, Jiao and Guo, Zhifen and Ma, Fengbin and Xu, Xindong and Fu, Longyue},
  doi          = {10.1007/s10489-024-05669-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9105-9135},
  shortjournal = {Appl. Intell.},
  title        = {Better electrobiological markers and a improved automated diagnostic classifier for schizophrenia—based on a new EEG effective information estimation framework},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring object reduction approaches for optimizing
decision-making in linguistic concept formal context. <em>APIN</em>,
<em>54</em>(19), 9088–9104. (<a
href="https://doi.org/10.1007/s10489-024-05583-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge reduction is a crucial research topic in formal concept analysis. Given the ability of three-way concept analysis to capture attribute information in a more comprehensive and detailed manner, this paper focuses on investigating object reduction methods and their applications based on three-way concept lattice. We achieve this by integrating necessity and possibility operators in a formal context containing linguistic data. Our proposed approach involves constructing an attribute-induced three-way object-oriented linguistic concept lattice to classify the object set into three regions based on three-way decision. Additionally, we introduce an approach of attribute-induced three-way object-oriented linguistic granular reduction, which employs granular concepts, granular discernibility functions, and granular consistent sets to enhance the efficiency of extracting uncertainty information. We obtain the relationships between the five consistent sets of attribute-induced three-way object-oriented linguistic concepts and further analyze the corresponding object reduction relations. To demonstrate the feasibility and validity of our proposed method, we apply it to address optimization decision-making challenges in corporate projects using different attribute-induced three-way object-oriented linguistic concepts.},
  archive      = {J_APIN},
  author       = {Cui, Hui and Deng, Ansheng and Hou, Tie and Zou, Li and Martinez, Luis},
  doi          = {10.1007/s10489-024-05583-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9088-9104},
  shortjournal = {Appl. Intell.},
  title        = {Exploring object reduction approaches for optimizing decision-making in linguistic concept formal context},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel dual-branch alzheimer’s disease diagnostic model
based on distinguishing atrophic patch localization. <em>APIN</em>,
<em>54</em>(19), 9067–9087. (<a
href="https://doi.org/10.1007/s10489-024-05663-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI), a non-ionizing radiation imaging method, is widely utilized in diagnosing Alzheimer’s disease (AD) due to its excellent imaging ability for brain soft tissues and high-resolution slice imaging. However, the enormous size of 3D MRI makes it difficult to process and analyze it. Therefore, a challenge is to accurately mine encephalatrophy patches from 3D MRI and build a patch-based diagnostic model. The existing patch-based methods mainly extract and fuse features of each patch in isolation, ignoring mutual information between patches, which makes the diagnosis performance unsatisfactory. We propose a novel dual-branch AD diagnostic model based on distinguishing atrophic patch localization. (1) We propose a Distinguishing Atrophic Patch Localization (DAPL) algorithm based on Distinguishing Index (DI) and Spatial Contact Ratio (SCR) to extract lesion areas that have significant impacts on diagnosis from 3D MRI. Meanwhile, we proposed a Discontinuity-voxel-based Dynamic Voxel Wrapping algorithm (DV $$^2$$ W) to calculate DI for each patch. (2) A dual-branch diagnostic network (DBDN) is constructed to obtain intra-patch and inter-patch features synchronously. The intra-feature extraction branch extracts feature from each patch through a parallel multi-channel network and fuse them. The Inter-feature extraction branch defines the Spatial Context Mixing matrix (SCM) and performs feature extraction on SCM to obtain mutual information. The performance evaluation demonstrates that our DBDN model has adequate diagnostic performance compared to state-of-the-art methods. In addition, the distinguishing pathological locations identified by our DAPL algorithm can effectively guide inexperienced clinical doctors to identify lesion areas and guide doctors in diagnosis quickly.},
  archive      = {J_APIN},
  author       = {Tu, Yue and Lin, Shukuan and Qiao, Jianzhong and Hao, Kuankuan and Zhuang, Yilin},
  doi          = {10.1007/s10489-024-05663-z},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9067-9087},
  shortjournal = {Appl. Intell.},
  title        = {A novel dual-branch alzheimer’s disease diagnostic model based on distinguishing atrophic patch localization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MBGNet: Multi-branch boundary generation network with
temporal context aggregation for temporal action detection.
<em>APIN</em>, <em>54</em>(19), 9045–9066. (<a
href="https://doi.org/10.1007/s10489-024-05664-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal action detection is an important and fundamental video understanding task that aims to locate the temporal regions where human actions or events may occur and to identify the classes of actions in untrimmed videos. The main challenge of temporal action detection is that videos are usually of different durations and untrimmed. Although existing methods have achieved better results in recent years, there are still some challenges, such as a lack of full utilisation of video context features, insufficient accuracy of generated action boundaries and failure to consider the relationship between proposals. To address the above issues, this paper proposes a Multi-branch Boundary Generation Network (MBGNet) with temporal context aggregation. It improves the performance of temporal action proposal generation by exploiting rich temporal context features and complementary boundary generators.First, we propose a multi-path temporal context feature aggregation (MTCA) module to exploit “local and global” contextual temporal features for the generation of temporal action proposals. Second, in order to generate accurate action boundaries, we design a multi-branch temporal boundary detector (MBG) to optimise the prediction results by exploiting the complementary relationship between the two boundary detectors.In addition, to accurately predict the confidence of densely distributed proposals, we design a proposal relation-aware module (PRAM) that exploits global correlation for proposal relationship modelling. Experiments on the popular datasets ActivityNet1.3, THUMOS14, and HACS demonstrate the effectiveness of the method proposed in this paper on the task of temporal action proposal generation, which can generate action proposals with high precision and recall. Moreover, combining with existing action classifiers can also achieve better performance in temporal action detection.These results demonstrate the effectiveness of the method in this paper in improving the accuracy of temporal action proposal generation and detection.},
  archive      = {J_APIN},
  author       = {Pan, Xiaoying and Zhang, Nijuan and Xie, Hewei and Li, Shoukun and Feng, Tong},
  doi          = {10.1007/s10489-024-05664-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9045-9066},
  shortjournal = {Appl. Intell.},
  title        = {MBGNet: Multi-branch boundary generation network with temporal context aggregation for temporal action detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedKGRec: Privacy-preserving federated knowledge graph aware
recommender system. <em>APIN</em>, <em>54</em>(19), 9028–9044. (<a
href="https://doi.org/10.1007/s10489-024-05634-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph(KG) aware recommendation generally incorporates KG as side information to enhance the user and item representations. Although effective in addressing data sparsity and cold start issues, these methods can raise privacy concerns and legal risks due to the centralized storage of user-item interactions. In order to solve this issue, a novel privacy-preserving framework for KG-aware recommendation named FedKGRec is introduced, which trains the recommendation model collaboratively with the orchestration of a central server. First, we design a local KG-aware Recommendation model (KGRec), crux of which are the user preference propagation module and the item neighbor expansion module, aiming to enhance the user and item representations simultaneously. Then, the local differential privacy (LDP) technique is applied to perturb the local model parameters before they are sent to the central server or aggregator, making it extremely difficult for malicious parties to extract individual sensitive information from the aggregated results. Extensive comparative experiments on three public datasets demonstrate that the proposed FedKGRec outperforms the state-of-the-art federated recommendation methods in terms of AUC, ACC and F1.},
  archive      = {J_APIN},
  author       = {Ma, Xiao and Zhang, Hongyu and Zeng, Jiangfeng and Duan, Yiqi and Wen, Xuan},
  doi          = {10.1007/s10489-024-05634-4},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9028-9044},
  shortjournal = {Appl. Intell.},
  title        = {FedKGRec: Privacy-preserving federated knowledge graph aware recommender system},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). QLDT: Adaptive query learning for HOI detection via
vision-language knowledge transfer. <em>APIN</em>, <em>54</em>(19),
9008–9027. (<a
href="https://doi.org/10.1007/s10489-024-05653-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-object interaction detection can be mainly categorized into two core problems, namely human-object association detection and interaction understanding. Firstly, for association detection, previous methods tend to directly detect obvious human-object interaction pairs, while ignoring some interaction pairs that may have potential interaction relationships, which is contrary to the actual situation. Secondly, for the interaction understanding problem, traditional methods face the challenges of long-tailed distribution and zero-shot detection, which cannot flexibly deal with complex and changing real-world scenarios. To this end, adaptive Query Learning for HOI Detection via vision-language knowledge Transfer(QLDT) is proposed. Specifically, a two-stage dynamic matching scoring algorithm based on dynamically changing thresholds and scores is designed to explore obscure H-O pairs and labeling to enlarge the sample size. Secondly, a visual-language pre-trained model GLIP (Grounded Language-Image Pre-training), is introduced to enhance the model’s interactive comprehension ability, extract the visual and linguistic features of the images through GLIP, minimize the gap with the predicted values using cross-entropy loss, and take the maximum value of the score with the obscure H-O pairs as the final prediction, which ensures the model’s positivity. The proposed method shows excellent performance on both HICO-DET and V-COCO datasets, for HICO-DET, QLDT achieved 35.37% mAP on the full category, 30.15% mAP on the rare category, and also improved on all five zero-shot metrics. For V-COCO, 62.74% mAP and 67.71% mAP were achieved under Scenario 1 and 2, respectively.},
  archive      = {J_APIN},
  author       = {Wang, Xincheng and Gao, Yongbin and Yu, Wenjun and Wu, Chenmou and Chen, Mingxuan and Ma, Honglei and Chen, Zhichao},
  doi          = {10.1007/s10489-024-05653-1},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {9008-9027},
  shortjournal = {Appl. Intell.},
  title        = {QLDT: Adaptive query learning for HOI detection via vision-language knowledge transfer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for computer vision based activity recognition
and fall detection of the elderly: A systematic review. <em>APIN</em>,
<em>54</em>(19), 8982–9007. (<a
href="https://doi.org/10.1007/s10489-024-05645-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the proportion of elderly individuals in developed countries continues to rise globally, addressing their healthcare needs, particularly in preserving their autonomy, is of paramount concern. A growing body of research focuses on Ambient Assisted Living (AAL) systems, aimed at alleviating concerns related to the independent living of the elderly. This systematic review examines the literature pertaining to fall detection and Human Activity Recognition (HAR) for the elderly, two critical tasks for ensuring their safety when living alone. Specifically, this review emphasizes the utilization of Deep Learning (DL) approaches on computer vision data, reflecting current trends in the field. A comprehensive search yielded 2,616 works from five distinct sources, spanning the years 2019 to 2023 (inclusive). From this pool, 151 relevant works were selected for detailed analysis. The review scrutinizes the employed DL models, datasets, and hardware configurations, with particular emphasis on aspects such as privacy preservation and real-world deployment. The main contribution of this study lies in the synthesis of recent advancements in DL-based fall detection and HAR for the elderly, providing insights into the state-of-the-art techniques and identifying areas for further improvement. Given the increasing importance of AAL systems in enhancing the quality of life for the elderly, this review serves as a valuable resource for researchers, practitioners, and policymakers involved in developing and implementing such technologies.},
  archive      = {J_APIN},
  author       = {Gaya-Morey, F. Xavier and Manresa-Yee, Cristina and Buades-Rubio, José M.},
  doi          = {10.1007/s10489-024-05645-1},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8982-9007},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning for computer vision based activity recognition and fall detection of the elderly: A systematic review},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised diffusion based anomaly detection for time
series. <em>APIN</em>, <em>54</em>(19), 8968–8981. (<a
href="https://doi.org/10.1007/s10489-024-05341-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised anomaly detection aims to construct a model that effectively detects invisible anomalies by training and reconstruct normal data. While a significant amount of reconstruction-based methods has made effective progress for time series anomaly detection, challenges still exist in aspects such as temporal feature extraction and generalization ability. Firstly, temporal features of data are subject to local information interference in reconstruction methods, which limits the long-term signal reconstruction methods. Secondly, the training dataset collector is subject to information nourishment such as collection methods, collection periods and locations, and data patterns are diverse, requiring the model to rebuild normal data according to different patterns. These issues hinder the anomaly detection capability of reconstruction-based methods. We propose an unsupervised anomaly detection model based on a diffusion model, which learns normal data pattern learning through noisy forward diffusion and reverse noise regression. By using a cascaded structure and combining it with a structured state space layer, long-term time series signal feature can be well extracted. Different collection signals are distinguished by introducing collector entity ID embedding. The method proposed in this article significantly improves performance in experimental tests on three public datasets. Innovative aspects: (1) Utilizing the S4 method to capture long-term dependencies; (2) Employing a diffusion model for reconstruction learning; (3) Leveraging embedding techniques to enhance different pattern learning.},
  archive      = {J_APIN},
  author       = {Zuo, Haiwei and Zhu, Aiqun and Zhu, Yanping and Liao, Yinping and Li, Shiman and Chen, Yun},
  doi          = {10.1007/s10489-024-05341-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8968-8981},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised diffusion based anomaly detection for time series},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel robust adaptive subspace learning framework for
dimensionality reduction. <em>APIN</em>, <em>54</em>(19), 8939–8967. (<a
href="https://doi.org/10.1007/s10489-024-05602-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data is characterized by its sparsity and noise, which can increase the likelihood of overfitting and compromise the model’s generalizability performance. In this paper, a novel robust subspace learning method based on stable adaptive spectral clustering is put forward for dimensionality reduction. Firstly, a robust estimator is used to distinguish the role of normal and abnormal samples in constructing the model, thereby small values are assigned to the outliers, then the influence of outliers on the construction of the learning models will be reduced. Secondly, the p-order of $$L_{2}$$ -norm distance is applied as the distance metric, replacing the square of $$L_{2}$$ -norm distance metric. The $$L_{2,p}$$ -norm often commendably tolerates the biases caused by the outliers in sample data, especially when the outliers are away from the normal data distributions. Thirdly, the adaptive stable spectral clustering based on the $$L_{2,p}$$ -norm is proposed to construct similarity matrix of the novel robust subspace to carry out reflexive embedding learning to learn the local and globe features of the raw data. In the subspace, the data is reconstructed to reduce the influence of noise and outliers, and the similarity matrix is structured by the new features, that is more conducive to subspace learning. Three main roles of the objective function of our model are: (1) preserving the consistency between the original data and the estimation; (2) achieving a &quot;clean&quot; subspace and further removing the outliers; (3) avoiding the trivial solution for each node in the graph. Finally, the random forest algorithm is used to classify and predict the learned subspace with different feature selections. Experimental results show that the proposed method is superior to other subspace learning methods in classification performance. The results of noise experiment and statistical analysis demonstrate the effectiveness of the proposed method once again.},
  archive      = {J_APIN},
  author       = {Xiong, Weizhi and Yu, Guolin and Ma, Jun and Liu, Sheng},
  doi          = {10.1007/s10489-024-05602-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8939-8967},
  shortjournal = {Appl. Intell.},
  title        = {A novel robust adaptive subspace learning framework for dimensionality reduction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Geometric relation-based feature aggregation for 3D small
object detection. <em>APIN</em>, <em>54</em>(19), 8924–8938. (<a
href="https://doi.org/10.1007/s10489-024-05342-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud-based 3D small object detection is crucial for autonomous driving and smart ships. The current 3D object detection mainly relies on object global features derived from 3D and 2D convolutional networks, inevitably leading to the loss of substantial object detail information. As large objects contain enough points to obtain sufficient global features, they are easy to identify. In contrast, small objects contain fewer points and their global features are weak, resulting in false classifications and inaccurate location estimates. Therefore, it is necessary to take into account the local geometric relation features of the object to develop adequate discriminative features. Moreover, the current two-stage 3D object detection speed is relatively slow due to the complex refinement structure, which is adverse to real-time detection. In this paper, an efficient 3D small object detection network with two novel modules is proposed. Firstly, the Geometric relation-based Feature Aggregation (GFA) module is designed to improve small object detection performance. This module flexibly aggregates the features of voxels and original points near the key points, for key points to aggregate more local discriminate features of objects, which is conducive to small object detection. Subsequently, the Key point Feature Abstraction (KFA) module is designed to improve the speed of small object detection, through which object global features can be rapidly obtained and the detection performance can be enhanced. Experimental results show that this method achieves state-of-the-art small object detection performance on both the KITTI dataset and the River Cargo Ship dataset.},
  archive      = {J_APIN},
  author       = {Yang, Wenbin and Yu, Hang and Luo, Xiangfeng and Xie, Shaorong},
  doi          = {10.1007/s10489-024-05342-z},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8924-8938},
  shortjournal = {Appl. Intell.},
  title        = {Geometric relation-based feature aggregation for 3D small object detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep context transformer: Bridging efficiency and contextual
understanding of transformer models. <em>APIN</em>, <em>54</em>(19),
8902–8923. (<a
href="https://doi.org/10.1007/s10489-024-05453-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the deep context transformer (DCT), which is a novel transformer model designed to enhance the efficiency and accuracy of processing contextually interlinked sequences in natural language processing (NLP) tasks, particularly in dialogue systems and code completion. Although they are powerful, traditional transformer models, struggle to manage extended sequences and complex data structures because of their fixed-length context window and uniform attention mechanism. DCT addresses these limitations by implementing a chunked transformer methodology, where sequences in a dialogue or code chunk are treated as standalone sequences and part of a broader context. This approach is complemented by decayed attention weighting, which scales down cross-attention weights based on the sequence age within the chunk, and an innovative positional encoding scheme that reflects both the token’s position within a sequence and the sequence’s position within a chunk. DCT was evaluated using the Schema-Guided Dialogue dataset from the Eighth Dialog System Technology Challenge and a subset of the IBM Project CodeNet for code completion, focusing on metrics such as character error rate, word error rate, and Bilingual Evaluation Understudy (BLEU) scores. The results revealed improvements in character error rate, word error rate, and BLEU scores compared to baseline models, with a notable increase in dialogue fluency and code completion accuracy. These achievements underscore the model’s advanced contextual understanding, which demonstrates its effectiveness in NLP and programming language tasks. Additionally, a variant of the model was explored using Bidirectional Encoder Representations from Transformers as the encoder, which demonstrates similar improvements in performance metrics; however, it tended to repeat responses due to missing positional encoding across encoder chunk sequences. The ability of DCT to maintain context over extended conversations and code chunks demonstrated its potential as a transformative tool in dialogue systems and code completion, with applications extending to document summarization, and language translation.},
  archive      = {J_APIN},
  author       = {Ghaith, Shadi},
  doi          = {10.1007/s10489-024-05453-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8902-8923},
  shortjournal = {Appl. Intell.},
  title        = {Deep context transformer: Bridging efficiency and contextual understanding of transformer models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of hill climbing method in position angle
compensation for SPMSM. <em>APIN</em>, <em>54</em>(19), 8889–8901. (<a
href="https://doi.org/10.1007/s10489-024-05594-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface-mounted permanent magnet synchronous motor (SPMSM) is widely used in the industrial field with excellent performance, and the rise of artificial intelligence has also promoted its development. In order to improve the estimation accuracy and response of speed and position angle in the SPMSM sensorless control system, a novel sliding mode control model reference adaptive system (NSMC-MRAS) observer based on variable step hill climbing method for online optimization is proposed. Firstly, an MRAS adaptive observer was constructed, and a conventional SMC controller is used instead of the PI regulator to improve the robustness of the SPMSM parameters. Aiming at the problem of chattering caused by the sign function sgn(s), an improved NSMC-MRAS sensorless control strategy using the continuous function sigmoid(s) is proposed, which effectively suppresses the chattering phenomenon. To address the position estimation errors caused by non ideal factors such as control delay, filtering phase shift, and parameter deviation, the artificial intelligence variable step hill climbing method is used for online optimization and adaptive compensation. The experimental results show that the proposed NSMC-MRAS sensorless control strategy based on variable step hill climbing method for online optimization can quickly and accurately estimate the speed and position angle of SPMSM, improved the control performance and intelligence level of the system.},
  archive      = {J_APIN},
  author       = {Song, Zhe and Zhou, Weihong and Xiao, Xi and Zhou, Jiayue},
  doi          = {10.1007/s10489-024-05594-9},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8889-8901},
  shortjournal = {Appl. Intell.},
  title        = {Application of hill climbing method in position angle compensation for SPMSM},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global k-means++: An effective relaxation of the global
k-means clustering algorithm. <em>APIN</em>, <em>54</em>(19), 8876–8888.
(<a href="https://doi.org/10.1007/s10489-024-05636-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-means algorithm is a prevalent clustering method due to its simplicity, effectiveness, and speed. However, its main disadvantage is its high sensitivity to the initial positions of the cluster centers. The global k-means is a deterministic algorithm proposed to tackle the random initialization problem of k-means but its well-known that requires high computational cost. It partitions the data to K clusters by solving all k-means sub-problems incrementally for all $${k=1,\ldots , K}$$ . For each k cluster problem, the method executes the k-means algorithm N times, where N is the number of datapoints. In this paper, we propose the global k-means++ clustering algorithm, which is an effective way of acquiring quality clustering solutions akin to those of global k-means with a reduced computational load. This is achieved by exploiting the center selection probability that is effectively used in the k-means++ algorithm. The proposed method has been tested and compared in various benchmark datasets yielding very satisfactory results in terms of clustering quality and execution speed.},
  archive      = {J_APIN},
  author       = {Vardakas, Georgios and Likas, Aristidis},
  doi          = {10.1007/s10489-024-05636-2},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8876-8888},
  shortjournal = {Appl. Intell.},
  title        = {Global k-means++: An effective relaxation of the global k-means clustering algorithm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OSTNet: Overlapping splitting transformer network with
integrated density loss for vehicle density estimation. <em>APIN</em>,
<em>54</em>(19), 8856–8875. (<a
href="https://doi.org/10.1007/s10489-024-05641-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle density estimation plays a crucial role in traffic monitoring, providing the traffic management department with the traffic volume and traffic flow to monitor traffic safety. Currently, all vehicle density estimation methods based on Convolutional Neural Network (CNN) fall short in extracting global information due to the limited receptive field of the convolution kernel, resulting in the loss of vehicle information. Vision Transformer can capture long-distance dependencies and establish global context information through the self-attention mechanism, and is expected to be applied to vehicle density estimation. However, directly using Vision Transformer will result in the discontinuity of vehicle information between patches. In addition, the completion of vehicle density estimation also faces challenges, such as vehicle multi-scale changes, occlusion, and background noise. To solve the above challenges, a novel Overlapping Splitting Transformer Network (OSTNet) tailored for vehicle density estimation is designed. Overlapping splitting is proposed so that each patch shares half of its area, ensuring the continuity of vehicle information between patches. Dilation convolution is introduced to remove fixed-size position codes in order to provide accurate vehicle localization information. Meanwhile, Feature Pyramid Aggregation (FPA) module is utilized to obtain different scale information, which can tackle the issue of multi-scale changes. Moreover, a novel loss function called integrated density loss is designed to address the existing vehicle occlusion and background noise problems. The extensive experimental results on four open source datasets have shown that OSTNet outperforms the SOTA methods and can help traffic management department to better estimate vehicle density. The source code and pre-trained models are available at: https://github.com/quyang-hub/vehicle-density-estimation.},
  archive      = {J_APIN},
  author       = {Qu, Yang and Yang, Liran and Zhong, Ping and Li, Qiuyue},
  doi          = {10.1007/s10489-024-05641-5},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8856-8875},
  shortjournal = {Appl. Intell.},
  title        = {OSTNet: Overlapping splitting transformer network with integrated density loss for vehicle density estimation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum a posteriori estimation and filtering algorithm for
numerical label noise. <em>APIN</em>, <em>54</em>(19), 8841–8855. (<a
href="https://doi.org/10.1007/s10489-024-05648-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data quality, especially label quality, may have a significant impact on the prediction accuracy in supervised learning. Training on datasets with label noise causes a degradation in performance and a reduction in prediction accuracy. To overcome the numerical label noise problem in regression, we estimate the posterior distribution of the true label through the Gaussian mixture model (GMM). Then, label noise estimation is proposed by integrating the idea of maximum a posteriori (MAP) estimation with the posterior distribution. Besides, a noise filtering algorithm with MAP estimation (MAPNF) is designed by combining the optimal sample selection framework with the estimator. Extensive experiments are carried out on benchmark datasets and an age estimation dataset to verify the effectiveness of MAPNF. The results on benchmark datasets show that MAPNF outperforms other latest filtering algorithms in improving the generalization performance of different regression models, including noise-sensitive models and noise-robust models. The model error can be reduced by 29.7% to 69.6%. Our proposed approach can also identify erroneous labels in an age estimation dataset (total of 18424). The model trained on the filtered dataset (19% of the data removed) achieves a reduced test error on the dataset by at least 2.68%. The results demonstrate a less-is-better effect by achieving lower prediction errors with fewer high-quality samples. It can be concluded that MAPNF can effectively identify label noise and optimize the data quality.},
  archive      = {J_APIN},
  author       = {Jiang, Gaoxia and Li, Zhengying and Wang, Wenjian},
  doi          = {10.1007/s10489-024-05648-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8841-8855},
  shortjournal = {Appl. Intell.},
  title        = {Maximum a posteriori estimation and filtering algorithm for numerical label noise},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning contextual representations for entity retrieval.
<em>APIN</em>, <em>54</em>(19), 8820–8840. (<a
href="https://doi.org/10.1007/s10489-024-05430-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce Contextual Entity Ranking (CoER) for the task of entity retrieval. CoER utilizes a textual knowledge graph to learn entities’ representations that are contextualized based on a given query. With these contextual representations and the query, CoER includes a set of models that learn to rank relevant entities. The introduced ranking models measure semantic relevance between entities’ contextual representations and the textual query, between entities’ contextual representations along with entities’ non-contextual and general descriptions and the textual query, and finally, between entities’ contextual representations and their relevance to the entities in the given query. We empirically illustrate that CoER is effective in retrieving and ranking entities across different benchmark datasets compared with state-of-the-art models. We also report ablation studies that investigate the impact of the contextual representation model and the ranking models on the final performance.},
  archive      = {J_APIN},
  author       = {Jafarzadeh, Parastoo and Amirmahani, Zahra and Ensan, Faezeh},
  doi          = {10.1007/s10489-024-05430-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8820-8840},
  shortjournal = {Appl. Intell.},
  title        = {Learning contextual representations for entity retrieval},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensemble based fully convolutional transformer network for
time series classification. <em>APIN</em>, <em>54</em>(19), 8800–8819.
(<a href="https://doi.org/10.1007/s10489-024-05649-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multivariate time series classification is widely used in various fields, including industrial process control, action recognition, and health monitoring. Due to their sequential modeling capabilities, Transformer networks with self-attention mechanisms have been successfully applied to multivariate time series classification tasks. However, the original transformer network can only calculate the relative dependence between two adjacent time steps, which makes it difficult to find local continuous dependence from scattered time steps. To address this issue, we propose an ensemble model called Ensemble Based Fully Convolutional Transformer Network (E-FCTN) that combines a gated transformer network (GTN) and a fully convolutional neural network (FCN). In the E-FCTN ensemble model, the GTN calculates the attention matrix between channels and time steps in a multivariate time series. Meanwhile, the FCN is also applied to extract local features to construct the basic belief assignment. Using the Proportional Conflict Redistribution rule no. 5 (PCR5) in the Dezert-Smarandache theory (DSmT), the output of the FCN and GTN are fused at the decision level, and the final decision is made according to the maximum plausibility. The information extracted by the FCN compensates for the deficiency of the GTN in local feature extraction. Finally, the proposed method is validated on eight publicly available datasets to demonstrate its effectiveness.},
  archive      = {J_APIN},
  author       = {Dong, Yilin and Xu, Yuzhuo and Zhou, Rigui and Zhu, Changming and Liu, Jin and Song, Jiamin and Wu, Xinliang},
  doi          = {10.1007/s10489-024-05649-x},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8800-8819},
  shortjournal = {Appl. Intell.},
  title        = {Ensemble based fully convolutional transformer network for time series classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). WSMOTER: A novel approach for imbalanced regression.
<em>APIN</em>, <em>54</em>(19), 8789–8799. (<a
href="https://doi.org/10.1007/s10489-024-05608-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the imbalanced learning problem is best known in the context of classification tasks, it also affects other areas of learning algorithms, such as regression. For regression, the problem is characterized by the existence of a continuous target variable domain and the need for models capable of making accurate predictions about rare events. Furthermore, such rare events with a real-value target are often the ones with greater interest in having models that can predict them. In this paper, we propose the novel approach WSMOTER (Weighting SMOTE for Regression) to tackle the imbalanced regression problem, which, according to the experimental work we present, outperforms currently available solutions to the problem.},
  archive      = {J_APIN},
  author       = {Camacho, Luís and Bacao, Fernando},
  doi          = {10.1007/s10489-024-05608-6},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8789-8799},
  shortjournal = {Appl. Intell.},
  title        = {WSMOTER: A novel approach for imbalanced regression},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive boundary-based selection many-objective
evolutionary algorithm with density estimation. <em>APIN</em>,
<em>54</em>(19), 8761–8788. (<a
href="https://doi.org/10.1007/s10489-024-05596-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective evolutionary algorithms often struggle to strike a balance between convergence and diversity when solving many-objective optimization problems. Consequently, an adaptive boundary-based selection many-objective evolutionary algorithm with density estimation, MaOEA/ABS-DE, is proposed. Specifically, the algorithm initially utilizes prior information regarding the adaptive estimation of the shape of the Pareto front to perform coordinate transformation on the population, thus guiding the population towards the approximate boundary of the current Pareto front. Subsequently, a novel approach for estimating the neighboring density of individuals is introduced by utilizing the distribution information of the transformed population. Furthermore, adaptive boundary-based selection and shifted-based density estimation selection strategies are designed for the environmental selection process. The environmental selection process is completed through a two-step selection. In the first step, a candidate pool is formed by selecting solutions with lower neighboring density, which aims to maintain a broad search for the population in the objective space. In the second step, the SDE is introduced to compare the convergence of individuals in the candidate pool, and those with the optimal SDE values are selected. Finally, extensive comparative experiments are conducted on two benchmark test suites, MaF (Many-objective Functions) and WFG (Walking Fish Group), as well as on two practical cases. The MaOEA/ABS-DE is compared with five representative many-objective evolutionary algorithms, including 1by1EA, NSGA-III, MaOEA-CSS, RVEA, and SPEA2 + SDE. Experimental results demonstrate that the proposed algorithm outperforms or at least matches the performance of the five algorithms on 87.04%, 92.59%, 87.04%, 88.89%, and 87.04% of the test instances, respectively.},
  archive      = {J_APIN},
  author       = {Luo, Jiale and Wang, Chenxi and Gu, Qinghua and Wang, Qian and Chen, Lu},
  doi          = {10.1007/s10489-024-05596-7},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {19},
  pages        = {8761-8788},
  shortjournal = {Appl. Intell.},
  title        = {An adaptive boundary-based selection many-objective evolutionary algorithm with density estimation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transformer-encoder-based multimodal multi-attention
fusion network for sentiment analysis. <em>APIN</em>, <em>54</em>(17),
8415–8441. (<a
href="https://doi.org/10.1007/s10489-024-05623-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature fusion for multimodal sentiment analysis is a challenging but worthwhile research topic. With the extension of the time dimension, there are interactions between multimodal signals and the lack of control over the target modal representations during the fusion process leads to erroneous shifts of vectors in the feature space. Moreover, ignoring the representation of target modal features under different fusion orders may lead to insufficient fusion of complementary information. To address the above issues, this paper proposes a transformer-encoder-based multimodal multi-attention fusion network model. The model constructs a multi-attention fusion transformer-encoder to learn inter-modal consistent features and enhance the representation of target modal features. Meanwhile, for each target modality, we construct multi-attention fusion transformer-encoder with different fusion orders in the model to capture the complementary features among the sequences with different fusion orders. Then, the three target modal representations containing consistent features and complementary features are fused with initial features through residual connections to guide the final sentiment analysis. We conduct extensive experiments on three public multimodal datasets. The results show that our approach outperforms the compared multimodal sentiment analysis methods on most metrics and can explain the contributions of inter- and intra-modal interactions in multiple modalities.},
  archive      = {J_APIN},
  author       = {Liu, Cong and Wang, Yong and Yang, Jing},
  doi          = {10.1007/s10489-024-05623-7},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8415-8441},
  shortjournal = {Appl. Intell.},
  title        = {A transformer-encoder-based multimodal multi-attention fusion network for sentiment analysis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-based spatial downscaling and
bias-correction framework for high-resolution temperature forecasting.
<em>APIN</em>, <em>54</em>(17), 8399–8414. (<a
href="https://doi.org/10.1007/s10489-024-05504-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution temperature forecasting plays a crucial role in various applications such as climate impact assessment, hydrological modeling, and localized weather forecasting. The existing low-resolution forecast data may not accurately capture the fine-grained temperature patterns required for localized predictions. These forecasts may contain biases that need to be corrected for accurate results. Therefore, there is a need for an effective framework that can downscale low-resolution forecast data and correct biases to generate high-resolution temperature forecasts. The paper proposes a machine learning-based spatial downscaling and bias-correction framework for high-resolution temperature forecasting. The framework utilizes low-resolution forecast data from the European Centre for Medium-Range Weather Forecasts and real-time 1km analysis product data from the National Meteorological Administration, to generate high-resolution 1km forecast temperature data. The framework consists of four modules: data acquisition module, data preprocessing module, downscaling and correction model module, and post-processing and visualization module. Through experiments, it demonstrated that the framework has superior performance and potential in meteorological data downscaling and correction and can be used to achieve real-time high-resolution temperature forecasting, which has important significance for various applications such as climate impact assessment, hydrological modeling, and localized weather forecasting.},
  archive      = {J_APIN},
  author       = {Meng, Xiangrui and Zhao, Huan and Shu, Ting and Zhao, Junhua and Wan, Qilin},
  doi          = {10.1007/s10489-024-05504-z},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8399-8414},
  shortjournal = {Appl. Intell.},
  title        = {Machine learning-based spatial downscaling and bias-correction framework for high-resolution temperature forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LExCI: A framework for reinforcement learning with embedded
systems. <em>APIN</em>, <em>54</em>(17), 8384–8398. (<a
href="https://doi.org/10.1007/s10489-024-05573-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in artificial intelligence (AI) have led to its application in many areas of everyday life. In the context of control engineering, reinforcement learning (RL) represents a particularly promising approach as it is centred around the idea of allowing an agent to freely interact with its environment to find an optimal strategy. One of the challenges professionals face when training and deploying RL agents is that the latter often have to run on dedicated embedded devices. This could be to integrate them into an existing toolchain or to satisfy certain performance criteria like real-time constraints. Conventional RL libraries, however, cannot be easily utilised in conjunction with that kind of hardware. In this paper, we present a framework named LExCI, the Learning and Experiencing Cycle Interface, which bridges this gap and provides end-users with a free and open-source tool for training agents on embedded systems using the open-source library RLlib. Its operability is demonstrated with two state-of-the-art RL-algorithms and a rapid control prototyping system.},
  archive      = {J_APIN},
  author       = {Badalian, Kevin and Koch, Lucas and Brinkmann, Tobias and Picerno, Mario and Wegener, Marius and Lee, Sung-Yong and Andert, Jakob},
  doi          = {10.1007/s10489-024-05573-0},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8384-8398},
  shortjournal = {Appl. Intell.},
  title        = {LExCI: A framework for reinforcement learning with embedded systems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Event-triggered cooperative robust formation control of
multi-agent systems via reinforcement learning. <em>APIN</em>,
<em>54</em>(17), 8367–8383. (<a
href="https://doi.org/10.1007/s10489-024-05631-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops an event-triggered cooperative robust formation control scheme for nonlinear multi-agent systems with dynamic uncertainties via reinforcement learning. By formulating a modified value function for each agent, the cooperative robust formation control problem of uncertain multi-agent systems is transformed into a cooperative optimal formation control problem of its nominal plant. To save communication and computing resources, a novel triggering condition is developed for each agent, and the controller is renovated only when an event occurs. Subsequently, the event-triggered optimal formation control law of each agent is derived by solving the coupled Hamilton-Jacobi-Bellman equation via single-critic structure. Furthermore, theoretical analysis indicates that the developed event-triggered cooperative robust formation control approach ensures the asymptotic stability of the formation error for each uncertain agent. Eventually, two simulation cases are adopted to confirm the effectiveness of the developed control approach.},
  archive      = {J_APIN},
  author       = {Zhang, Yongwei and Zhang, Jiantao and Xiong, Juntao},
  doi          = {10.1007/s10489-024-05631-7},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8367-8383},
  shortjournal = {Appl. Intell.},
  title        = {Event-triggered cooperative robust formation control of multi-agent systems via reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UTMGAT: A unified transformer with memory encoder and graph
attention networks for multidomain dialogue state tracking.
<em>APIN</em>, <em>54</em>(17), 8347–8366. (<a
href="https://doi.org/10.1007/s10489-024-05571-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spoken dialogue systems (SDS) heavily rely on dialogue state tracking (DST) for success. However, providing sufficient computational power for training proves challenging, given that DST involves tracking states from both user and system utterances. While machine learning approaches have improved DST, they have notable limitations. These approaches often overlook unseen slot values during training and use two separate modules to extract, generate, or match slot values, leading to high time and resource consumption. Moreover, learning and deducing relevant values for related slots remain understudied challenges. To address these gaps, this paper introduces UTMGAT-a Unified Transformer with Memory Encoder and Graph Attention Networks (GAT) for Multidomain DST. UTMGAT employs a BERT tokenizer to construct user utterances and a candidate sets vocabulary, reducing the need for constant retraining when dealing with unseen values. It utilizes a single transformer to gather dialogue context for slots and generate slot values, enhancing prediction accuracy while reducing memory and computation time. UTMGAT incorporates an embedding layer aggregator to filter out unnecessary values, identify required nodes for GAT, and establish relationships among relevant values associated with related slots. This approach simplifies graph representation and diminishes required computation power. The input to the GAT maintains equal size with batch sizes, generated through padding. Finally, we have experimentally evaluated our model against several models including LLM approaches over four popular datasets with our approach outperforming all competing models except two approaches on one dataset.},
  archive      = {J_APIN},
  author       = {Khan, Muhammad Asif and Prasad, Bhuyan Kaibalya and Qi, Guilin and Song, Wei and Ye, Fanghua and Ali, Zafar and Ullah, Irfan and Kefalas, Pavlos},
  doi          = {10.1007/s10489-024-05571-2},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8347-8366},
  shortjournal = {Appl. Intell.},
  title        = {UTMGAT: A unified transformer with memory encoder and graph attention networks for multidomain dialogue state tracking},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Social small group optimization algorithm for large-scale
economic dispatch problem with valve-point effects and multi-fuel
sources. <em>APIN</em>, <em>54</em>(17), 8296–8346. (<a
href="https://doi.org/10.1007/s10489-024-05517-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economic dispatch is an important issue in the management of power systems and is the current focus of specialists. In this paper, a new metaheuristic optimization algorithm is proposed, named Social Small Group Optimization (SSGO), inspired by the psychosocial processes that occur between members of small groups to solve real-life problems. The starting point of the SSGO algorithm is a philosophical conception similar to that of the social group optimization (SGO) algorithm. The novelty lies in the introduction of the small group concept and the modeling of individuals’ evolution based on the social influence between two or more members of the small group. This conceptual framework has been mathematically mapped through a set of heuristics that are used to update the solutions, and the best solutions are retained by employing a greedy selection strategy. SSGO has been applied to solve the economic dispatch problem by considering some practical aspects, such as valve-point loading effects, sources with multiple fuel options, prohibited operating zones, and transmission line losses. The efficiency of the SSGO algorithm was tested on several mathematical functions (unimodal, multimodal, expanded, and composition functions) and on power systems of varying sizes (ranging from 10-units to 1280-units). The SSGO algorithm was compared with SGO and other algorithms belonging to various categories (such as: evolution-based, swarm-based, human behavior-based, hybrid algorithms, etc.), and the results indicated that SSGO outperforms other algorithms applied to solve the economic dispatch problem in terms of quality and stability of the solutions, as well as computation time.},
  archive      = {J_APIN},
  author       = {Secui, Dinu Calin and Secui, Monica Liana},
  doi          = {10.1007/s10489-024-05517-8},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8296-8346},
  shortjournal = {Appl. Intell.},
  title        = {Social small group optimization algorithm for large-scale economic dispatch problem with valve-point effects and multi-fuel sources},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient perception, planning, and control algorithm for
vision-based automated vehicles. <em>APIN</em>, <em>54</em>(17),
8278–8295. (<a
href="https://doi.org/10.1007/s10489-024-05610-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles have limited computational resources and thus require efficient control systems. The cost and size of sensors have limited the development of self-driving cars. To overcome these restrictions, this study proposes an efficient framework for the operation of vision-based automatic vehicles; the framework requires only a monocular camera and a few inexpensive radars. The proposed algorithm comprises a multi-task UNet (MTUNet) network for extracting image features and constrained iterative linear quadratic regulator (CILQR) and vision predictive control (VPC) modules for rapid motion planning and control. MTUNet is designed to simultaneously solve lane line segmentation, the ego vehicle’s heading angle regression, road type classification, and traffic object detection tasks at approximately 40 FPS for 228 $$\times $$ 228 pixel RGB input images. The CILQR controllers then use the MTUNet outputs and radar data as inputs to produce driving commands for lateral and longitudinal vehicle guidance within only 1 ms. In particular, the VPC algorithm is included to reduce steering command latency to below actuator latency, preventing performance degradation during tight turns. The VPC algorithm uses road curvature data from MTUNet to estimate the appropriate correction for the current steering angle at a look-ahead point to adjust the turning amount. The inclusion of the VPC algorithm in a VPC-CILQR controller leads to higher performance on curvy roads than the use of CILQR alone. Our experiments demonstrate that the proposed autonomous driving system, which does not require high-definition maps, can be applied in current autonomous vehicles.},
  archive      = {J_APIN},
  author       = {Lee, Der-Hau},
  doi          = {10.1007/s10489-024-05610-y},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8278-8295},
  shortjournal = {Appl. Intell.},
  title        = {Efficient perception, planning, and control algorithm for vision-based automated vehicles},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust fingerprint reconstruction using attention mechanism
based autoencoders and multi-kernel autoencoders. <em>APIN</em>,
<em>54</em>(17), 8262–8277. (<a
href="https://doi.org/10.1007/s10489-024-05622-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprint recognition technology is widely employed for identity verification and access control across diverse domains in which the quality of fingerprint images is critical for accurate biometric identification. However, fingerprint images can be damaged or incomplete due to various factors such as sensor limitations, environmental conditions, or physical injuries. To address this, several approaches including attention mechanism based autoencoders, multi-kernel sequential and multi-kernel stacked autoencoders, and multi-kernel ensemble autoencoders are proposed to perform reconstruction of incomplete and damaged fingerprints. Attention mechanisms play a crucial role by selectively emphasizing important regions and details, further enhancing information capture. By utilizing different autoencoder models with varying kernel sizes, local details and global context can be effectively captured, resulting in more precise restoration. The adoption of multi-kernel sequential and multi-kernel stacked autoencoders enables the extraction of increasingly abstract features, enhancing the model’s ability to capture complex fingerprint characteristics. Utilizing autoencoder-based methods for the reconstruction of damaged or incomplete fingerprint images can enhance the accuracy and reliability of fingerprint identification systems leading to improved security and efficiency in real-world applications. Evaluation is conducted using image quality assessment metrics and feature-based matching is utilized to compute fingerprint matching accuracy. The multi-kernel ensemble autoencoder model produces the best reconstruction output with an average fingerprint matching accuracy of 93.81 %. The findings highlight the effectiveness of the proposed work in achieving high-quality reconstruction output and accurate fingerprint matching. The proposed work can be applied in various domains that include law enforcement, security, forensic analysis, and biometric authentication.},
  archive      = {J_APIN},
  author       = {J, Dhalia Sweetlin and R, Bhuvaneshwari and N, Bhagya and N, Bavya Dharshini},
  doi          = {10.1007/s10489-024-05622-8},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8262-8277},
  shortjournal = {Appl. Intell.},
  title        = {Robust fingerprint reconstruction using attention mechanism based autoencoders and multi-kernel autoencoders},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boiler furnace temperature and oxygen content prediction
based on hybrid CNN, biLSTM, and SE-net models. <em>APIN</em>,
<em>54</em>(17), 8241–8261. (<a
href="https://doi.org/10.1007/s10489-024-05609-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Furnace temperature and oxygen content are important parameters reflecting the combustion inside a circulating fluidized bed (CFB) boiler. Accurately predicting boiler output is a complex task due to the high noise and nonsmoothness of actual boiler input and output data. In this paper, a new hybrid convolutional neural network (CNN), bidirectional long short-term memory (biLSTM) network, and squeezing and excitation (SE) network prediction model is proposed to significantly improve the prediction accuracy of oxygen content and furnace temperature by combining the advantages of multiple deep learning networks. This network can extract spatiotemporal characteristics of input parameters such as coal feed to effectively predict boiler furnace temperature and oxygen content. CNNs can extract complex features such as dynamic and static nonlinearities between multiple variables affecting the furnace temperature and oxygen content, as well as high noise. The biLSTM network layer can efficiently handle the temporal information of irregular trends in modeling time series components; SE can extract the important information between channels through the feature relationships between channels for better overfeature extraction. The CNN-biLSTM-SE model can effectively solve the problem of nonlinear mapping complexity between inputs and outputs. Experiments show that the proposed CNN-biLSTM-SE model outperforms existing methods. The experimental results showed that the average MAPE errors for oxygen content prediction were CNN-biLSTM-SE (0.038), CNN-biLSTM with attention mechanism (AM) (0.043), CNN-biLSTM (0.051), CNN-LSTM (0.051), biLSTM (0.051), RNN (0.051), LSTM(0.0052), and CNN(0.0054). Extensive experiments in CFB boilers with oxygen content and furnace temperature show that the proposed CNN-biLSTM-SE model achieves better results in terms of goodness-of-fit, generalization ability and accuracy.},
  archive      = {J_APIN},
  author       = {Ji, Zhaoyu and Tao, Wenhua and Ren, Jiaming},
  doi          = {10.1007/s10489-024-05609-5},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8241-8261},
  shortjournal = {Appl. Intell.},
  title        = {Boiler furnace temperature and oxygen content prediction based on hybrid CNN, biLSTM, and SE-net models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concept factorization with adaptive graph learning on
stiefel manifold. <em>APIN</em>, <em>54</em>(17), 8224–8240. (<a
href="https://doi.org/10.1007/s10489-024-05606-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning and data mining, concept factorization (CF) has achieved great success for its powerful capability in data representation. To learn an adaptive inherent graph structure of data space, and to ease the burden brought by the explicit orthogonality constraint, we propose a concept factorization with adaptive graph learning on the Stiefel manifold (AGCF-SM). The method essentially integrates concept factorization and manifold learning into a unified framework. Therein the adaptive similarity graph is learned by iterative locally linear embedding, which is free from dependence on neighbor sets. An iterative updating algorithm is developed and the convergence and complexity analyses of the algorithm are provided. The numerical experiments on ten benchmark datasets have demonstrated that the proposed algorithm outperforms other state-of-the-art algorithms.},
  archive      = {J_APIN},
  author       = {Hu, Xuemin and Xiong, Dan and Chai, Li},
  doi          = {10.1007/s10489-024-05606-8},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8224-8240},
  shortjournal = {Appl. Intell.},
  title        = {Concept factorization with adaptive graph learning on stiefel manifold},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A continuous-time diffusion model for inferring multi-layer
diffusion networks. <em>APIN</em>, <em>54</em>(17), 8200–8223. (<a
href="https://doi.org/10.1007/s10489-024-05620-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring multilayer diffusion networks from observed cascades is both crucial and realistic. To infer multilayer diffusion networks, constructing continuous-time diffusion models that capture diffusion dynamics is a prerequisite. However, developing such models faces two main challenges: (1) reducing the number of learnable parameters for precise optimization with limited cascades while effectively modeling for accurate inference and (2) adapting the models to more realistic scenarios. In this paper, we propose a novel continuous-time diffusion model, namely the Embedding-based Continuous-time Diffusion (ECD) model, which employs an embedding method while modeling symmetric relationship strength, asymmetric relationship strength, and trust strength. Specifically, by leveraging the embedding method, the number of learnable parameters is significantly reduced compared with previous models. Then, by modeling symmetric relationship strength, our model can be used in scenarios where the relationships between nodes are symmetric. Subsequently, the trust strength can be inferred by our proposed efficient heuristic algorithm, making our model suitable for scenarios where time information is unavailable. Furthermore, we develop an optimization algorithm to optimize the proposed model and infer multilayer diffusion networks. The experimental results on synthetic and real datasets show that our model and algorithms outperform the comparison methods.},
  archive      = {J_APIN},
  author       = {Zhao, Yunpeng and Yao, Xiaopeng and Huang, Hejiao},
  doi          = {10.1007/s10489-024-05620-w},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8200-8223},
  shortjournal = {Appl. Intell.},
  title        = {A continuous-time diffusion model for inferring multi-layer diffusion networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterized multi-perspective graph learning network for
temporal sentence grounding in videos. <em>APIN</em>, <em>54</em>(17),
8184–8199. (<a
href="https://doi.org/10.1007/s10489-024-05618-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal sentence grounding in videos (TSGV) aims to retrieve video segments from untrimmed videos that semantically matched a given query. Although existing methods have made significant progress in fine-grained intra- and inter-modal representations, they failed to comprehensively consider the redundancy of the entire video relative to the target segment and the fact that interactions could obscure crucial intra-modal information, which leads to the degradation of model performance. In this paper, we proposed a novel Parameterized Multi-Perspective Graph Learning Network for Temporal Sentence Grounding in Videos. Specifically, to effectively handle redundant information in video graphs, the concept of a parameterized network is introduced to dynamically construct new video graphs. Parameterizing the graph structure, making it adaptable to various video scenes while suppressing unnecessary redundant information. Furthermore, we designed a dual-path attention gating module that delves into cross-modal relationships while fully considering intra-modal information. The mechanism simultaneously considers the association between video and query from both inter- and intra-modal perspectives. This method allowed the model to better balance the local and global semantic consistency, further enhancing its representation capability for multimodal data. Extensive experiments on the ActivityNet Captions and Tacos benchmark datasets demonstrate that the proposed method outperforms the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Wu, Guangli and Yang, Zhijun and Zhang, Jing},
  doi          = {10.1007/s10489-024-05618-4},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8184-8199},
  shortjournal = {Appl. Intell.},
  title        = {Parameterized multi-perspective graph learning network for temporal sentence grounding in videos},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing precision in breast cancer detection: A fusion of
vision transformers and CNNs for calcification mammography
classification. <em>APIN</em>, <em>54</em>(17), 8170–8183. (<a
href="https://doi.org/10.1007/s10489-024-05619-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer remains a substantial public health challenge, marked by a rising prevalence. Accurate early detection is paramount for effective treatment and improved patient outcomes in breast cancer. The diversity of breast tumors and the complexity of their microenvironment present significant challenges. Establishing a reliable breast calcification and micro-calcification detection approach is an ongoing issue that researchers must continue to investigate. The goal is to develop an effective methodology that contributes to increased patient survival. Therefore, this paper introduces a novel approach for classifying breast calcifications in mammography, aiming to distinguish between benign and malignant cases. Aiming to address these challenges, we proposed our hybrid approach for breast calcification classification in mammogram images. The proposed approach starts with an image pre-processing phase that includes noise reduction and enhancement filters. Afterward, we proposed our hybrid classification architecture. It includes two branches: First, the vision transformer (ViT++) branch for contextual features. Secondly, a CNN branch based on transfer learning techniques for visual features. Using the CBIS-DDSM dataset, the application of our proposed ViT++ architecture reached the maximum accuracy of 96.12%. Further, the application of the VGG16 as a single feature extractor had a much lower accuracy of 61.96%. Meanwhile, the combination of these techniques in the same architecture improved the accuracy to 99.22%. Three different pre-trained feature extractors were applied in the CNN branch: Xception, VGG16, and RegNetX002. However, the best-obtained outcomes were from the combination of the ViT++ and the VGG16. The experimental findings indicate that the proposed strategy for breast calcification detection has the potential to surpass the performance of currently top-ranked methods, particularly in terms of classification accuracy.},
  archive      = {J_APIN},
  author       = {Boudouh, Saida Sarra and Bouakkaz, Mustapha},
  doi          = {10.1007/s10489-024-05619-3},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8170-8183},
  shortjournal = {Appl. Intell.},
  title        = {Advancing precision in breast cancer detection: A fusion of vision transformers and CNNs for calcification mammography classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature ranking based consensus clustering for feature
subset selection. <em>APIN</em>, <em>54</em>(17), 8154–8169. (<a
href="https://doi.org/10.1007/s10489-024-05566-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature subset selection problem is an NP hard problem and there is a need for computationally efficient algorithms that find near optimal feature subsets which improve the performance of a classifier. Two major challenges for feature subset selection are high-dimensional data, that is, data with a large number of features and large datasets. Scalability of the feature selection algorithms in terms of accuracy for high dimensional data and the time taken for large datasets are important issues. We propose a consensus clustering based approach to feature selection that addresses these issues. There exist many greedy feature ranking algorithms in the literature that are computationally efficient. Each algorithm assigns a different ranking order to the features. A consensus among these rankings may provide a feature ranking that performs well with respect to time as well as accuracy. The goal of this work is to propose efficient algorithms that work on small as well as large datasets. The contributions of this work include: i. A fast and scalable approach for feature selection Feature ranking based on consensus clustering(FRCC), has been designed using the available feature ranking algorithms from the literature. ii. A parallelizable version of FRCC, namely, Hybrid Feature Selection(HFS), is proposed to address the feature reduction in large datasets. The implementation results show that FRCC clearly outperforms many recent algorithms in the literature on small as well as large dimensional data sets. HFS has been implemented on datasets with lakhs of instances and dimensionality in hundreds and thousands. HFS proves to be very effective in terms of feature reduction and accuracy in comparison to the results obtained by recent algorithms in the literature.},
  archive      = {J_APIN},
  author       = {D, Sandhya Rani and T, Sobha Rani and S, Durga Bhavani and G, Bala Krishna},
  doi          = {10.1007/s10489-024-05566-z},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8154-8169},
  shortjournal = {Appl. Intell.},
  title        = {Feature ranking based consensus clustering for feature subset selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random forest with differential privacy in federated
learning framework for network attack detection and classification.
<em>APIN</em>, <em>54</em>(17), 8132–8153. (<a
href="https://doi.org/10.1007/s10489-024-05589-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication networks are crucial components of the underlying digital infrastructure in any smart city setup. The increasing usage of computer networks brings additional cyber security concerns, and every organization has to implement preventive measures to protect valuable data and business processes. Due to the inherent distributed nature of the city infrastructures as well as the critical nature of its resources and data, any solution to the attack detection calls for distributed, efficient and privacy preserving solutions. In this paper, we extend the evaluation of our federated learning framework for network attacks detection and classification based on random forest. Previously the framework was evaluated only for attack detection using four well-known intrusion detection datasets (KDD, NSL-KDD, UNSW-NB15, and CIC-IDS-2017). In this paper, we extend the evaluation for attack classification. We also evaluate how adding differential privacy into random forest, as an additional protective mechanism, affects the framework performances. The results show that the framework outperforms the average performance of independent random forests on clients for both attack detection and classification. Adding differential privacy penalizes the performance of random forest, as expected, but the use of the proposed framework still brings benefits in comparison to the use of independent local models. The code used in this paper is publicly available, to enable transparency and facilitate reproducibility within the research community.},
  archive      = {J_APIN},
  author       = {Markovic, Tijana and Leon, Miguel and Buffoni, David and Punnekkat, Sasikumar},
  doi          = {10.1007/s10489-024-05589-6},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8132-8153},
  shortjournal = {Appl. Intell.},
  title        = {Random forest with differential privacy in federated learning framework for network attack detection and classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning strategy for automatic congestive heart
failure detection using novel bottleneck attention module.
<em>APIN</em>, <em>54</em>(17), 8120–8131. (<a
href="https://doi.org/10.1007/s10489-024-05364-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Congestive heart failure (CHF) is a sort of common cardiovascular disease. Artificial vision inspection on electrocardiogram (ECG) has turned into the mainstream diagnosis strategy for CHF detection, however it is strenuous and challenging. Motivated from bottleneck attention module (BAM), we construct an efficient architecture based on naive bidirectional gate recurrent unit (BGRU) for automatic CHF detection called BAM-BGRU. BAM-BGRU can refine the attention maps from both pathways: Channel attention and Spatial attention to enhance feature representation ability. To evaluate the effectiveness, we leverage naive GRU, BGRU and BAM as control groups with BIDMC congestive heart failure database (BCHFD) and congestive heart failure RR intervals database (CHFRID). The results achieve an obvious performance improvement than control groups and existing algorithms with an accuracy of 99.1% and 98.8%. Besides, we implement visualization analysis for multilevel derivative gradient flows of ECG episodes to strengthen model interpretability. To our knowledge, we first reformulate naive BGRU framework for consistent performance improvements showing promising potentials in diverse CNN backbones.},
  archive      = {J_APIN},
  author       = {Wang, Jibin and Guo, Xingtian},
  doi          = {10.1007/s10489-024-05364-7},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8120-8131},
  shortjournal = {Appl. Intell.},
  title        = {A deep learning strategy for automatic congestive heart failure detection using novel bottleneck attention module},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-level information fusion transformer with background
filter for fine-grained image recognition. <em>APIN</em>,
<em>54</em>(17), 8108–8119. (<a
href="https://doi.org/10.1007/s10489-024-05584-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional image recognition, Fine-Grained Image Recognition (FGIR) faces significant challenges due to the subtle distinctions among different categories and the notable variances within the same category. Furthermore, the complexity of backgrounds and the extraction of discriminative features limited to small local regions further exacerbate the difficulty. Recently, several studies have demonstrated the effectiveness of the Vision Transformer (ViT) in FGIR. However, these investigations have frequently overlooked critical information embedded within class tokens across different layers, while also neglecting the subtle local details hidden within patch tokens. To address these issues and enhance FGIR performance, we introduce a novel ViT-based network architecture MIFBF. The proposed model builds upon ViT by incorporating three modules: Complementary Class Tokens Combination module (CCTC), Patches Information Integration module (PII), and Attention Cropping Module (ACM). The CCTC module integrates multi-layer class tokens to capture complementary information, thereby enhancing the model’s representational capacity. The PII module delves into the rich local details encoded in patch tokens to improve classification accuracy. The ACM module generates regions of interest based on ViT’s self-attention weights and effectively filters background noise, thereby directing the model’s attention to the most relevant image areas. Experiments conducted on three different datasets validate the effectiveness of the proposed model, yielding state-of-the-art results and highlighting its superiority in FGIR tasks.},
  archive      = {J_APIN},
  author       = {Yu, Ying and Wang, Jinghui and Pedrycz, Witold and Miao, Duoqian and Qian, Jin},
  doi          = {10.1007/s10489-024-05584-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8108-8119},
  shortjournal = {Appl. Intell.},
  title        = {Multi-level information fusion transformer with background filter for fine-grained image recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-head multi-order graph attention networks.
<em>APIN</em>, <em>54</em>(17), 8092–8107. (<a
href="https://doi.org/10.1007/s10489-024-05601-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Graph Attention Network (GAT) is a type of graph neural network (GNN) that uses attention mechanisms to weigh the importance of nodes’ neighbors, demonstrating flexibility and power in representation learning. However, GAT and its variants still face common challenges in GNNs, such as over-smoothing and over-squashing. To address this, we propose Multi-Head Multi-Order Graph Attention Networks (MHMOGAT) as an enhanced GAT layer. MHMOGAT is built based on multi-head attention and adjacency matrices of different orders, aiming to expand the receptive field of GAT to effectively capture long-distance dependencies. Moreover, Bayesian optimization is employed to determine optimal hyperparameter combinations for different datasets. Experimental results on six prevailing datasets demonstrate that MHMOGAT improves GAT accuracy by approximately 2-5% across various datasets with different label rates, indicating its effectiveness. Additionally, MHMOGAT exhibits potential in handling large and complex graphs with low label rates.},
  archive      = {J_APIN},
  author       = {Ben, Jie and Sun, Qiguo and Liu, Keyu and Yang, Xibei and Zhang, Fengjun},
  doi          = {10.1007/s10489-024-05601-z},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8092-8107},
  shortjournal = {Appl. Intell.},
  title        = {Multi-head multi-order graph attention networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MHGNN: Multi-view fusion based heterogeneous graph neural
network. <em>APIN</em>, <em>54</em>(17), 8073–8091. (<a
href="https://doi.org/10.1007/s10489-024-05567-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph (HG) is a data structure composed of various types of nodes and rich relational information, which can accurately show complex application scenarios in the real world. Although heterogeneous graph neural networks (HGNNs) have been widely applied to model HGs, there are still some issues that need to be addressed. On the one hand, most of HGNNs ignore the fine-grained information when modeling HGs, such as attribute and topology overcoupling due to the accumulation of multi-source heterogeneous information in message passing. On the other hand, HGNNs are designed from a single view (based on metapath or relation awareness), which undoubtedly leads to information loss and makes it difficult to fully extract potential interactions in HGs. To tackle the aforementioned limitations, a Multi-view fusion based Heterogeneous Graph Neural Network (MHGNN) is proposed, which is modeled from node view, network schema view, and semantics view to mine the information from different granularity in HGs. MHGNN extracts the fine-gained information of nodes, heterogeneous interaction of neighboring nodes, and mutual influence between different semantics from three views respectively. Then, the model integrates these information as the final node representation. To prove the effectiveness of this work, extensive experiments are conducted on four real-world datasets, and comparisons are made with seven competitive baselines. The results demonstrate that the proposed MHGNN significantly outperforms state-of-the-art methods. Source codes are available at https://github.com/ZZY-GraphMiningLab/MHGNN.},
  archive      = {J_APIN},
  author       = {Li, Chao and Zhu, Xiangkai and Yan, Yeyu and Zhao, Zhongying and Su, Lingtao and Zeng, Qingtian},
  doi          = {10.1007/s10489-024-05567-y},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8073-8091},
  shortjournal = {Appl. Intell.},
  title        = {MHGNN: Multi-view fusion based heterogeneous graph neural network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KnowDT: Empathetic dialogue generation with knowledge
enhanced dependency tree. <em>APIN</em>, <em>54</em>(17), 8059–8072. (<a
href="https://doi.org/10.1007/s10489-024-05611-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A human-like dialogue system should prioritize expressing empathy towards others, which entails two crucial aspects: (1) semantic cognition and (2) emotion detection. Previous approaches mainly model semantic and emotional dependencies by capturing emotion signal or leveraging external commonsense knowledge. However, they often ignore the syntactic information inherent in the utterances, which is crucial to understanding the subtle differences in the semantic and emotional meaning of words in different contexts. In this paper, we propose a novel framework for empathetic dialogue generation with Knowledge enhanced Dependency Tree (KnowDT). Specifically, the KnowDT captures relationships between token-level emotions by comprehensively considering of dependency tree and external knowledge. To incorporate syntactic and semantic information into context encoding, we improve the relation attention mechanism for a joint representation of adjacent nodes in dependency tree, and design a flexible tree positional encoding scheme for a broad variety of topologies without affecting their syntactic constituents. Furthermore, we present a level-ordered attention mechanism that extracts emotional features by encoding recursively along the topological structure of a dependency tree. Experimental results demonstrate that our model outperforms the state-of-the-art models in both automatic and human evaluation, in which the accuracy of emotion classification and the perplexity of generated responses are significantly improved.},
  archive      = {J_APIN},
  author       = {Liu, Yuan and Han, Donghong and Wu, Gang and Qiao, Baiyou},
  doi          = {10.1007/s10489-024-05611-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8059-8072},
  shortjournal = {Appl. Intell.},
  title        = {KnowDT: Empathetic dialogue generation with knowledge enhanced dependency tree},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-branch and triple-attention network for pan-sharpening.
<em>APIN</em>, <em>54</em>(17), 8041–8058. (<a
href="https://doi.org/10.1007/s10489-024-05580-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pan-sharpening is a technique used to generate high-resolution multi-spectral (HRMS) images by merging high-resolution panchromatic (PAN) images with low-resolution multi-spectral (LRMS) images. Many existing methods face challenges in effectively balancing the trade-off between spectral and spatial information, leading to spectral and spatial structural distortion. In order to effectively tackle these issues, we propose a dual-branch and triple attention (DBTA) network. The proposed DBTA network consists of two essential modules: the Channel-spatial Attention (CSA) module and the Spectral Attention (SPA) module. The CSA module effectively captures the spatial structural information of the images by jointly using spatial and channel attention units. Meanwhile, the SPA module improves the expressive capacity of spectral information by dynamically adjusting channel weights. These two modules work in synergy to achieve comprehensive extraction and fusion of spectral and spatial information, thus resulting in more accurate and clearer reconstructed images. Extensive experiments have been conducted on various satellite datasets to evaluate the performance of the proposed DBTA method outperforms the state-of-the-art competitors in both qualitative and quantitative evaluations.},
  archive      = {J_APIN},
  author       = {Song, Wenhao and Gao, Mingliang and Chehri, Abdellah and Zhai, Wenzhe and Li, Qilei and Jeon, Gwanggil},
  doi          = {10.1007/s10489-024-05580-1},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8041-8058},
  shortjournal = {Appl. Intell.},
  title        = {Dual-branch and triple-attention network for pan-sharpening},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge and separating soft verbalizer based prompt-tuning
for multi-label short text classification. <em>APIN</em>,
<em>54</em>(17), 8020–8040. (<a
href="https://doi.org/10.1007/s10489-024-05599-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label Short Text Classification (MSTC) is a challenging subtask of Multi-Label Text Classification (MLTC) for tagging a short text with the most relevant subset of labels from a given set of labels. Recent studies have attempted to address MSTC task using MLTC methods and Pre-trained Language Models (PLM) based fine-tuning approaches, but suffering the low performance from the following three reasons, 1) failure to address the issue of data sparsity of short texts, 2) lack of adaptation to the long-tail distribution of labels in multi-label scenarios and 3) an implicit weakness in the encoding length for PLM, which limits the ability of the prompt learning paradigm. Therefore, in this paper, we propose KSSVPT, a Knowledge and Separating Soft Verbalizer based Prompt Tuning method for MSTC to address the above challenges. Firstly, to mitigate the sparsity issue in short texts, we propose a novel approach that enhances the semantic information of short texts by integrating external knowledge into the soft prompt template. Secondly, we construct a new soft prompt verbalizer for MSTC, called separating soft prompt verbalizer, to adapt to the long-tail distribution issue aggravated by multiple labels. Thirdly, we propose a mechanism of label cluster grouping in building a prompt template to directly alleviate limited encoding length and capture the label correlation. Extensive experiments conducted on six benchmark datasets demonstrate the superiority of our model compared to all competing models for MLTC and MSTC in the tackling of MSTC task.},
  archive      = {J_APIN},
  author       = {Chen, Zhanwang and Li, Peipei and Hu, Xuegang},
  doi          = {10.1007/s10489-024-05599-4},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {8020-8040},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge and separating soft verbalizer based prompt-tuning for multi-label short text classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HAMIATCM: High-availability membership inference attack
against text classification models under little knowledge.
<em>APIN</em>, <em>54</em>(17), 7994–8019. (<a
href="https://doi.org/10.1007/s10489-024-05495-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Membership inference attack opens up a newly emerging and rapidly growing research to steal user privacy from text classification models, a core problem of which is shadow model construction and members distribution optimization in inadequate members. The textual semantic is likely disrupted by simple text augmentation techniques, which weakens the correlation between labels and texts and reduces the precision of member classification. Shadow models trained exclusively with cross-entropy loss have little differentiation in embeddings among various classes, which deviates from the distribution of target models, then impacts the embeddings of members and reduces the F1 score. A competitive and High-Availability Membership Inference Attack against Text Classification Model (HAMIATCM) is proposed. At the data level, by selecting highly significant words and applying text augmentation techniques such as replacement or deletion, we expand knowledge of attackers, preserving vulnerable members to enhance the sensitive member distribution. At the model level, constructing contrastive loss and adaptive boundary loss to amplify the distribution differences among various classes, dynamically optimize the boundaries of members, enhancing the text representation capability of the shadow model and the classification performance of the attack classifier. Experimental results demonstrate that HAMIATCM achieves new state-of-the-art, significantly reduces the false positive rate, and strengthens the capability of fitting the output distribution of the target model with less knowledge of members.},
  archive      = {J_APIN},
  author       = {Cheng, Yao and Luo, Senlin and Pan, Limin and Wan, Yunwei and Li, Xinshuai},
  doi          = {10.1007/s10489-024-05495-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7994-8019},
  shortjournal = {Appl. Intell.},
  title        = {HAMIATCM: High-availability membership inference attack against text classification models under little knowledge},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight CNN-transformer model for learning traveling
salesman problems. <em>APIN</em>, <em>54</em>(17), 7982–7993. (<a
href="https://doi.org/10.1007/s10489-024-05603-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several studies have attempted to solve traveling salesman problems (TSPs) using various deep learning techniques. Among them, Transformer-based models show state-of-the-art performance even for large-scale Traveling Salesman Problems (TSPs). However, they are based on fully-connected attention models and suffer from large computational complexity and GPU memory usage. Our work is the first CNN-Transformer model based on a CNN embedding layer and partial self-attention for TSP. Our CNN-Transformer model is able to better learn spatial features from input data using a CNN embedding layer compared with the standard Transformer-based models. It also removes considerable redundancy in fully-connected attention models using the proposed partial self-attention. Experimental results show that the proposed CNN embedding layer and partial self-attention are very effective in improving performance and computational complexity. The proposed model exhibits the best performance in real-world datasets and outperforms other existing state-of-the-art (SOTA) Transformer-based models in various aspects. Our code is publicly available at https://github.com/cm8908/CNN_Transformer3 .},
  archive      = {J_APIN},
  author       = {Jung, Minseop and Lee, Jaeseung and Kim, Jibum},
  doi          = {10.1007/s10489-024-05603-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7982-7993},
  shortjournal = {Appl. Intell.},
  title        = {A lightweight CNN-transformer model for learning traveling salesman problems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A binarization approach to model interactions between
categorical predictors in generalized linear models. <em>APIN</em>,
<em>54</em>(17), 7969–7981. (<a
href="https://doi.org/10.1007/s10489-024-05576-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, our goal is to enhance the interpretability of Generalized Linear Models by identifying the most relevant interactions between categorical predictors. Searching for interaction effects can quickly become a highly combinatorial, and thus computationally costly, problem when we have many categorical predictors or even a few of them but with many categories. Moreover, the estimation of coefficients requires large training samples with enough observations for each interaction between categories. To address these bottlenecks, we propose to find a reduced representation for each categorical predictor as a binary predictor, where categories are clustered based on a dissimilarity. We provide a collection of binarized representations for each categorical predictor, where the dissimilarity takes into account information from the main effects and the interactions. The choice of the binarized predictors representing the categorical predictors is made with a novel heuristic procedure that is guided by the accuracy of the so-called binarized model. We test our methodology on both real-world and simulated data, illustrating that, without damaging the out-of-sample accuracy, our approach trains sparse models including only the most relevant interactions between categorical predictors.},
  archive      = {J_APIN},
  author       = {Carrizosa, Emilio and Galvis Restrepo, Marcela and Romero Morales, Dolores},
  doi          = {10.1007/s10489-024-05576-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7969-7981},
  shortjournal = {Appl. Intell.},
  title        = {A binarization approach to model interactions between categorical predictors in generalized linear models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Curriculum pre-training for stylized neural machine
translation. <em>APIN</em>, <em>54</em>(17), 7958–7968. (<a
href="https://doi.org/10.1007/s10489-024-05586-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stylized neural machine translation (NMT) aims to translate sentences of one style into sentences of another style, it is essential for the application of machine translation in a real-world scenario. Most existing methods employ an encoder-decoder structure to understand, translate, and transform style simultaneously, which increases the learning difficulty of the model and leads to poor generalization ability. To address these issues, we propose a curriculum pre-training framework to improve stylized NMT. Specifically, we design four pre-training tasks of increasing difficulty to assist the model to extract more features essential for stylized translation. Then, we further propose a stylized-token aligned data augmentation method to expand the scale of pre-training corpus for alleviating the data-scarcity problem. Experiments show that our method achieves competitive results on MTFC and Modern-Classical translation dataset.},
  archive      = {J_APIN},
  author       = {Zou, Aixiao and Wu, Xuanxuan and Li, Xinjie and Zhang, Ting and Cui, Fuwei and Xu, Jinan},
  doi          = {10.1007/s10489-024-05586-9},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7958-7968},
  shortjournal = {Appl. Intell.},
  title        = {Curriculum pre-training for stylized neural machine translation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nia-GNNs: Neighbor-imbalanced aware graph neural networks
for imbalanced node classification. <em>APIN</em>, <em>54</em>(17),
7941–7957. (<a
href="https://doi.org/10.1007/s10489-024-05590-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been proven that Graph Neural Networks focus more on the majority class instances and ignore minority class instances when the class distribution is imbalanced. To address the class imbalance problems on graphs, most of the existing approaches rely on the availability of minority nodes in the training set, which may be scarce in extremely imbalanced situations and lead to overfitting. To tackle this issue, this paper proposes a novel oversampling-based Neighbor imbalanced-aware Graph Neural Networks, abbreviated as Nia-GNNs. Specifically, we propose a novel interpolation method that selects interpolated minority nodes from the entire dataset according to their predicted labels and similarity. Meanwhile, a class-wise interpolation ratio is applied to prevent the generation of out-of-domain nodes. Additionally, the generated minority nodes are inserted into the neighbor of minority nodes according to their neighbor distribution to balance the graph both neighborly and globally. Numerous experiments on different imbalanced datasets demonstrate the superiority of our method in classifying imbalanced nodes.},
  archive      = {J_APIN},
  author       = {Sun, Yanfeng and Wang, Yujia and Wang, Shaofan},
  doi          = {10.1007/s10489-024-05590-z},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7941-7957},
  shortjournal = {Appl. Intell.},
  title        = {Nia-GNNs: Neighbor-imbalanced aware graph neural networks for imbalanced node classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced feature pyramid for multi-view stereo with adaptive
correlation cost volume. <em>APIN</em>, <em>54</em>(17), 7924–7940. (<a
href="https://doi.org/10.1007/s10489-024-05574-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-level features are commonly employed in the cascade network, which is currently the dominant framework in multi-view stereo (MVS). However, there is a potential issue that the recent popular multi-level feature extractor network overlooks the significance of fine-grained structure features for coarse depth inferences in MVS task. Discriminative structure features play an important part in matching and are helpful to boost the performance of depth inference. In this work, we propose an effective cascade-structured MVS model named FANet, where an enhanced feature pyramid is built with the intention of predicting reliable initial depth values. Specifically, the features from deep layers are enhanced with affluent spatial structure information in shallow layers by a bottom-up feature enhancement path. For the enhanced topmost features, an attention mechanism is additionally employed to suppress redundant information and select important features for subsequent matching. To ensure the lightweight and optimal performance of the entire model, an efficient module is built to construct a lightweight and effective cost volume, representing viewpoint correspondence reliably, by utilizing the average similarity metric to calculate feature correlations between reference view and source views and then adaptively aggregating them into a unified correlation cost volume. Extensive quantitative and qualitative comparisons on the DTU and Tanks &amp;Temple benchmarks illustrate that the proposed model exhibits better reconstruction quality than state-of-the-art MVS methods.},
  archive      = {J_APIN},
  author       = {Han, Ming and Yin, Hui and Chong, Aixin and Du, Qianqian},
  doi          = {10.1007/s10489-024-05574-z},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7924-7940},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced feature pyramid for multi-view stereo with adaptive correlation cost volume},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RoDAL: Style generation in robot calligraphy with deep
adversarial learning. <em>APIN</em>, <em>54</em>(17), 7913–7923. (<a
href="https://doi.org/10.1007/s10489-024-05597-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative art has drawn increased attention in recent AI applications. Traditional approaches of robot calligraphy have faced challenges in achieving style consistency, line smoothness and high-quality structural uniformity. To address the limitation of existing methods, we propose a dual generator framework based on deep adversarial networks for robotic calligraphy reproduction. The proposed model utilizes a encoder-decoder module as one generator for style learning and a robot arm as the other generator for motion learning to optimize the networks and obtain the best robot calligraphy works. Based on the enhanced datasets, multiple evaluation metrics including coverage rate, structural similarity index measure, intersection over union and Turing test are employed to perform the experimental validation. The evaluations demonstrate that the proposed method is highly effective and applicable in robot calligraphy and achieves state-of-the-art results with the average structural similarity index measure 75.91% , coverage rate 70.25%, and intersection over union 80.68%, which provides a paradigm for evaluation in the field of art.},
  archive      = {J_APIN},
  author       = {Wang, Xiaoming and Gong, Zhiguo},
  doi          = {10.1007/s10489-024-05597-6},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7913-7923},
  shortjournal = {Appl. Intell.},
  title        = {RoDAL: Style generation in robot calligraphy with deep adversarial learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Will senior adults accept being cognitively assessed by a
conversational agent? A user-interaction pilot study. <em>APIN</em>,
<em>54</em>(17), 7897–7912. (<a
href="https://doi.org/10.1007/s10489-024-05558-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: early detection of dementia and Mild Cognitive Impairment (MCI) have an utmost significance nowadays, and smart conversational agents are becoming more and more capable. DigiMoCA, an Alexa-based voice application for the screening of MCI, was developed and tested. Objective: to evaluate the acceptability and usability of DigiMoCA, considering the perception of end-users and cognitive assessment administrators, through standard evaluation questionnaires. Method: a sample of 46 individuals and 24 evaluators participated in this study. End-users were fairly heterogeneous considering demographic and neuro-psychological characteristics. Evaluators were mostly health and social care professionals, relatively well-balanced in terms of gender, career background and years of experience. Results: end-users acceptability ratings were generally positive (rating above 3 in a 5-point scale for all dimensions) and it improved significantly after the interaction with DigiMoCA. Administrators also rated the usability of DigiMoCA, with an average score of 5.86/7 and with high internal consistency ( $$\alpha $$ = 0.95). Conclusion: although there is still room for improvement in terms of user satisfaction and voice interface, DigiMoCA is perceived as an acceptable, accessible and usable cognitive screening tool, both by individuals being tested and test administrators.},
  archive      = {J_APIN},
  author       = {Pacheco-Lorenzo, Moisés R. and Anido-Rifón, Luis E. and Fernández-Iglesias, Manuel J. and Valladares-Rodríguez, Sonia M.},
  doi          = {10.1007/s10489-024-05558-z},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7897-7912},
  shortjournal = {Appl. Intell.},
  title        = {Will senior adults accept being cognitively assessed by a conversational agent? a user-interaction pilot study},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised deep learning for geometric feature detection
and multilevel-multimodal image registration. <em>APIN</em>,
<em>54</em>(17), 7878–7896. (<a
href="https://doi.org/10.1007/s10489-024-05585-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image registration is a crucial step in computer-assisted medical diagnosis, and has seen significant progress with the adoption of deep learning methods like convolutional neural networks (CNN). Creating a deep learning network for image registration is complex because humans can’t easily prepare or supervise the training data unless it’s very basic. This article presents an innovative approach to unsupervised deep learning-based multilevel image registration approach. We propose to develop a CNN to detect the geometric features, such as edges and thin structures, from images using a loss function derived from the Blake-Zisserman energy. This method enables the detection of discontinuities at different scales without relying on labeled data. Subsequently, we use this geometric information extracted from the input images, to define a second loss function and to perform our multimodal image registration process. Furthermore, we introduce a novel deep neural network architecture for multilevel image registration, offering enhanced precision and efficiency compared to traditional methods. Numerical simulations are employed to demonstrate the accuracy and relevance of our approach. We perform some numerical simulations to show the accuracy and the relevance of our approach for multimodal registration and its multilevel implementation.},
  archive      = {J_APIN},
  author       = {Lajili, Mohamed and Belhachmi, Zakaria and Moakher, Maher and Theljani, Anis},
  doi          = {10.1007/s10489-024-05585-w},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7878-7896},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised deep learning for geometric feature detection and multilevel-multimodal image registration},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EpiRiskNet: Incorporating graph structure and static data as
prior knowledge for improved time-series forecasting. <em>APIN</em>,
<em>54</em>(17), 7864–7877. (<a
href="https://doi.org/10.1007/s10489-024-05514-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EpiRiskNet combines time-series data with graph and static information to enhance forecasting accuracy. This model features the SCI-Block for improved feature extraction and interaction learning, leveraging the capabilities of SCINet and Triformer to manage diverse feature scales. The model’s standout attribute, scalability, is driven by Triformer’s Patch Attention mechanism, ensuring efficient processing of large-scale data. EpiRiskNet was tested across several locations, including Liaoning, Chongqing, Heilongjiang, and Guangxi, where it demonstrated greater accuracy than other methods. This accuracy is crucial for effectively forecasting disease risks. The model’s adaptability to various regional conditions underscores its significance in public health and epidemiology. Moreover, its modular and flexible design makes EpiRiskNet suitable for a wide range of applications that require advanced data processing and predictive analytics.},
  archive      = {J_APIN},
  author       = {Shi, Yayong and Chen, Qiao and Li, Qiongxuan and Luan, Hengyu and Wang, Qiao and Hu, Yeyuan and Gao, Feng and Sai, Xiaoyong},
  doi          = {10.1007/s10489-024-05514-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7864-7877},
  shortjournal = {Appl. Intell.},
  title        = {EpiRiskNet: Incorporating graph structure and static data as prior knowledge for improved time-series forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FMDADA: Federated multi-discriminative adversarial domain
adaptation. <em>APIN</em>, <em>54</em>(17), 7849–7863. (<a
href="https://doi.org/10.1007/s10489-024-05592-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated domain adaptation system aims to address the problem of domain shift in a federated learning (FL) framework, where knowledge learned from distributed source domains can be readily transferred to the target domain. However, federated domain adaptation suffers from two challenges: (1) Inefficient assignment of source domain weights. (2) The joint distributions of feature and category across domains are poorly aligned. To solve the above problems, we propose a novel unsupervised federated domain adaptation (UFDA) approach called Federated Multi-Discriminative Adversarial Domain Adaptation (FMDADA). Firstly, we propose a FL aggregation scheme (F-DIS), which assigns weights to distributed source domains with different contribution rates based on a measure of cross-domain discrepancy. Secondly, we facilitate the joint distribution alignment of feature and category by designing multiple tightly coupled joint classifiers, which facilitates the positive transfer of source domain knowledge. Finally, extensive experimental results on three datasets demonstrate the effectiveness of FMDADA for UFDA problem. Compared to the currently advanced comparison approaches, the accuracy of FMDADA is significantly improved, reaching 54.7% and achieving an improvement of 5.9% on the large-scale dataset DomainNet.},
  archive      = {J_APIN},
  author       = {Chi, Hao and Xia, Hui and Xu, Shuo and He, Yusheng and Hu, Chunqiang},
  doi          = {10.1007/s10489-024-05592-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7849-7863},
  shortjournal = {Appl. Intell.},
  title        = {FMDADA: Federated multi-discriminative adversarial domain adaptation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RPV-CASNet: Range-point-voxel integration with channel
self-attention network for lidar point cloud segmentation.
<em>APIN</em>, <em>54</em>(17), 7829–7848. (<a
href="https://doi.org/10.1007/s10489-024-05553-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing the advantages of different views and mitigating their respective disadvantages in fine-grained segmentation tasks are an important challenge in the field of point cloud multi-view fusion. Traditional multi-view fusion methods ignore two fatal problems: 1. the loss of depth and quantization information due to mapping and voxelization operations, resulting in “anomalies” in the extracted features; 2. how to pay attention to the large differences in object sizes among different views during point cloud learning, and fine-tune the fusion efficiency in order to improve the performance of network. In this paper, we propose a new algorithm that uses channel self-attention to fuse range-point-voxel, abbreviated as RPV-CASNet. RPV-CASNet integrates the three different views: range, point and voxel in a more subtle way through an interactive structure (range-point-voxel cross-adaptive layer known as RPVLayer for short), to take full advantage of the differences among them. The RPVLayer contains two key designs: the Feature Refinement Module (FRM) and the Multi-Fine-Grained Feature Self-Attention Module(MFGFSAM). Specifically, the FRM allows for a re-inference representation of points with entrained anomalous features, correcting the features. The MFGFSAM addresses two challenges: efficiently aggregating tokens from distant regions and preserving multiscale features within a single attention layer. In addition, we design a Dynamic Feature Pyramid Extractor (DFPE) for network deployment, which is used to extract rich features from spherical range images. Our method achieves impressive mIoU scores of 69.8% and 77.1% on the SemanticKITTI and nuScenes datasets, respectively.},
  archive      = {J_APIN},
  author       = {Li, Jiajiong and Wang, Chuanxu and Wang, Chenyang and Zhao, Min and Jiang, Zitai},
  doi          = {10.1007/s10489-024-05553-4},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7829-7848},
  shortjournal = {Appl. Intell.},
  title        = {RPV-CASNet: Range-point-voxel integration with channel self-attention network for lidar point cloud segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural-network-based safe learning control for non-zero-sum
differential games of nonlinear systems with asymmetric input
constraints. <em>APIN</em>, <em>54</em>(17), 7810–7828. (<a
href="https://doi.org/10.1007/s10489-024-05593-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper primarily investigates a neural-network-based safe control scheme for solving the optimal control problem of continuous-time (CT) nonlinear systems with asymmetric input constraints under non-zero-sum (NZS) differential game scenarios. Initially, by constructing a novel non-quadratic function, the issue of asymmetric input constraints in the non-zero-sum differential game controllers is addressed. Subsequently, the safe Hamilton-Jacobi-Bellman (HJB) equation is derived from the direct integration of the control barrier function (CBF) into the traditional cost function, ensuring that the system states remain within a safe region. Then, the safe learning control scheme based on single critic neural network (NN) and adaptive dynamic programming (ADP) is proposed to approximate the optimal control strategy, differing from the dual-network update method commonly used in traditional ADP. Based on the constructed neural network weight adjustment rules, the optimal solution to the HJB equation can be derived within the safe learning control framework. Following this, Lyapunov’s stability theory demonstrates that the errors in neural network weights and all signals within the closed-loop system are uniformly ultimately bounded (UUB). Finally, the effectiveness of the developed neural-network-based safe learning control method is validated through two simulation results.},
  archive      = {J_APIN},
  author       = {Qin, Chunbin and Zhu, Tianzeng and Jiang, Kaijun and Wu, Yinliang and Zhang, Jishi},
  doi          = {10.1007/s10489-024-05593-w},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7810-7828},
  shortjournal = {Appl. Intell.},
  title        = {Neural-network-based safe learning control for non-zero-sum differential games of nonlinear systems with asymmetric input constraints},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lightweight convolutional swin transformer with cutmix
augmentation and CBAM attention for compound emotion recognition.
<em>APIN</em>, <em>54</em>(17), 7793–7809. (<a
href="https://doi.org/10.1007/s10489-024-05598-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial emotion recognition has become a complicated task due to individual variations in facial characteristics, as well as racial and cultural variances. Different psychological studies show that there are complex expressions other than basic emotions which are made up of two basic emotions like“Happily Disgusted”, “Happily Surprised”, “Sadly Surprised”, etc. Compound emotion recognition is challenging due to very less publicly available compound emotion datasets which are imbalanced too. In this paper, we have proposed an LSwin-CBAM for the classification of compound emotions. To address the problem of the imbalanced dataset, the proposed model exploits the cutmix augmentation technique for data augmentation. It also incorporates the CBAM attention mechanism to emphasize the relevant features in an image and swin transformer with fewer swin transformer blocks which leads to less computational complexity in terms of trainable parameters and improves the overall classification accuracy as well. The experimental results of LSwin-CBAM on RAF-DB and EmotioNet datasets show that the proposed transformer-based network can well recognize compound emotions.},
  archive      = {J_APIN},
  author       = {Nidhi and Verma, Bindu},
  doi          = {10.1007/s10489-024-05598-5},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7793-7809},
  shortjournal = {Appl. Intell.},
  title        = {A lightweight convolutional swin transformer with cutmix augmentation and CBAM attention for compound emotion recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MPF-net: Multi-projection filtering network for few-shot
object detection. <em>APIN</em>, <em>54</em>(17), 7777–7792. (<a
href="https://doi.org/10.1007/s10489-024-05556-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based object detection has made tremendous progress in the field of intelligent vision systems. However, one of its major complaints is the high demand for large amounts of experimental data. Few-shot object detection (FSOD) aims to identify novel objects with only a few training samples. Existing techniques don’t fully explore the potential mapping relationships between support and query features due to the limitation of global matching contrast. In this work, we propose a multi-projection filtering network (MPF-Net) to exploit feature relevance and aggregate the information between multiple scales, ensuring an optimal global representation. Furthermore, we take the lead in proposing a feature contrast filtering paradigm for the classification and regression subtasks in order to fully utilize fine-grained features for contrastive match. The multi-visual contrast approach motivates our model to gracefully handle a variety of difficult detection challenges such as scale discrepancies, occlusions, and feature confusions. MPF-Net accurately perceives features at various scales and adaptively excavates category information. Extensive experiments on PASCAL VOC and MS COCO datasets have demonstrated that our detectors significantly improve upon baseline detectors, especially for extremely low-shot settings (average accuracy improvement is up to 3.5% in 1-shot scenarios and 2.5% in 2-shot scenarios). In general, we propose a novel strategy to construct the few-shot feature space and achieve remarkable results.},
  archive      = {J_APIN},
  author       = {Chen, Han and Wang, Qi and Xie, Kailin and Lei, Liang and Wu, Xue},
  doi          = {10.1007/s10489-024-05556-1},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7777-7792},
  shortjournal = {Appl. Intell.},
  title        = {MPF-net: Multi-projection filtering network for few-shot object detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph analysis using a GPU-based parallel algorithm: Quantum
clustering. <em>APIN</em>, <em>54</em>(17), 7765–7776. (<a
href="https://doi.org/10.1007/s10489-024-05587-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article introduces a new method for applying Quantum Clustering to graph structures. Quantum Clustering (QC) is a density-based unsupervised learning method that determines cluster centers by constructing a potential function. In this method, we develop the Graph Gradient Descent algorithm to find the centers of clusters for graph analysis. GPU parallelization is utilized for computing potential values. We also conducted comparative experiments on five widely used datasets and evaluated them using four indicators. The results show superior performance of our method. Finally, we discuss the influence of the crucial parameter $$\sigma $$ on the experimental results.},
  archive      = {J_APIN},
  author       = {Wang, Zhe and He, Zhijie and Liu, Ding},
  doi          = {10.1007/s10489-024-05587-8},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7765-7776},
  shortjournal = {Appl. Intell.},
  title        = {Graph analysis using a GPU-based parallel algorithm: Quantum clustering},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised feature selection by minimum neighborhood
redundancy and maximum neighborhood relevancy. <em>APIN</em>,
<em>54</em>(17), 7750–7764. (<a
href="https://doi.org/10.1007/s10489-024-05578-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of machine learning, feature selection emerges as a prevalent data preprocessing technique, playing a crucial role in enhancing model performance across diverse downstream tasks such as fault diagnosis, biological recognition, and object detection. Nevertheless, the challenge of incomplete supervision, stemming from limited labeled data availability, poses a formidable obstacle in acquiring the optimal feature subset for model input. To address the problem that label scarcity may deteriorate the feature evaluation and selection, we introduce a novel semi-supervised feature selection algorithm termed Semi2MNR integrating the principles of Minimum Neighborhood Redundancy and Maximum Neighborhood Relevancy. Firstly, k-nearest neighborhood granulation is leveraged to construct a collection of neighborhood uncertainty measures from the perspective of information theory. Then, the neighborhood mutual information is expressed to assess the feature-to-label relevance based on labeled samples and feature-to-feature redundance based on unlabeled samples. Finally, as the evaluation criterion of min-neighborhood-redundancy and max-neighborhood-relevancy is constrained, a forward sequential searching algorithm is devised to identify the min-redundant and max-relevant features. The empirical findings from our experiments on 12 UCI data sets unequivocally demonstrate the superiority of Semi2MNR in the presence of partially labeled data with varying labeling rates. Comparative analysis against other feature selection algorithms suggests that CART, KNN, and SVM classifiers fed with features selected by Semi2MNR consistently yield optimal accuracies.},
  archive      = {J_APIN},
  author       = {Qian, Damo and Liu, Keyu and Zhang, Shiming and Yang, Xibei},
  doi          = {10.1007/s10489-024-05578-9},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7750-7764},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised feature selection by minimum neighborhood redundancy and maximum neighborhood relevancy},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Many-objective emergency aided decision making based on
knowledge graph. <em>APIN</em>, <em>54</em>(17), 7733–7749. (<a
href="https://doi.org/10.1007/s10489-024-05557-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After emergencies occur, decision-makers can reference historical cases with similar causes to take similar emergency response measures. However, information about emergencies is usually recorded and stored in textual form, and it is difficult for decision-makers to obtain effective information from large amounts of textual data and make decisions that balance various factors. To address these issues, this paper presents an emergency assisted decision-making model based on a knowledge graph and many-objective optimization. First, we preprocess the information by extracting entities to construct a knowledge graph of emergencies to make the event information more structured and easier to use. A knowledge graph is also used to narrow the range of matching historical events. Second, we construct a many-objective model with four objectives: similarity, diversity, processing time, and resource cost. Finally, combining the model characteristics, we design genetic operations for duplicate location matching and substitution removal strategies to obtain the nonrepetitive VaEA algorithm. This algorithm is used to optimize the model and generate a list of reference cases in the reduced matching range to provide rescue strategy suggestions for the current situation. The experimental results show that the algorithm outperforms the comparison algorithms under all four evaluation metrics. This indicates that the method in this paper can match the higher-quality historical emergency solutions applicable to the current decision-making situation in the case base and provide support for decision-makers to respond reasonably in emergencies.},
  archive      = {J_APIN},
  author       = {Li, Xiaoxuan and Zhao, Tianhao and Wen, Jie and Cai, Xingjuan},
  doi          = {10.1007/s10489-024-05557-0},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7733-7749},
  shortjournal = {Appl. Intell.},
  title        = {Many-objective emergency aided decision making based on knowledge graph},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multiscale dilated convolution and swin-transformer for
small sample gearbox fault diagnosis. <em>APIN</em>, <em>54</em>(17),
7716–7732. (<a
href="https://doi.org/10.1007/s10489-024-05530-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical equipment usually operates in noisy and variable load environments, which presents serious challenges for existing intelligent diagnostic models. In addition, there are few labelled fault samples in real engineering scenarios, which makes it difficult to perform accurate fault identification for mechanical equipment. Thus, to solve the problem of diagnostic model performance degradation under small sample, noisy and variable load environments, this paper proposes a Multiscale Dilated Convolution and Swin-Transformer (MSDC-Swin-T) method for small sample gearbox fault diagnosis. First, we design the Coordinate Reconstruction Attention Mechanism (CRAM), which enhances the capture of impulse information by coordinate reconstruction. In addition, a multiscale convolutional token embedding module is constructed to extract local features at different scales, and its ability for capturing important features is adaptively enhanced by CRAM. Then, Swin-Transformer is utilized for modeling global dependencies, thus mining more subtle fault features. Finally, the effectiveness and stability of the MSDC-Swin-T is proved on two gearbox datasets. The experiments show that MSDC-Swin-T has superior diagnostic performance under small sample with noise and variable load environments. The diagnostic accuracy is better than the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Zhang, Yazhou and Zhao, Xiaoqiang and Liang, Haopeng and Chen, Peng},
  doi          = {10.1007/s10489-024-05530-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7716-7732},
  shortjournal = {Appl. Intell.},
  title        = {Multiscale dilated convolution and swin-transformer for small sample gearbox fault diagnosis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The variable precision fuzzy rough set based on overlap and
grouping functions with double weight method to MADM. <em>APIN</em>,
<em>54</em>(17), 7696–7715. (<a
href="https://doi.org/10.1007/s10489-024-05554-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable precision fuzzy rough set (VPFRS) is widely utilized for handling various forms of uncertain information due to its fault-tolerant capability. However, a significant number of these rough sets fail to satisfy the inclusion property (lower approximation included in the upper approximation), posing potential risks in applications. Moreover, a common method of constructing the VPFRS is through triangular norms and triangular conorms. But in certain practical applications, the associative law of triangular norms and triangular conorms may not be essential. Overlap functions and grouping functions can effectively avoid this issue. Therefore, to address the limitations of existing models, we introduce the concept of VPFRS based on overlap and grouping functions, and apply it to a real multi-attribute decision-making problem. Firstly, we propose a novel VPFRS leveraging overlap and grouping functions, and demonstrate that it satisfies the generalized inclusion property. This solves the deficiency in VPFRSs not meeting the inclusion property to some extent. Additionally, with the help of the generalized inclusion property, we introduce a new objective method for computing attribute weights. Subsequently, by integrating the merits of the proposed VPFRS model and the PROMETHEE method, we develop a multi-attribute decision-making method with double weight. Finally, the validity of our decision-making method and weight calculation approach is substantiated through comparison and experimental analysis.},
  archive      = {J_APIN},
  author       = {Shi, Zhengqi and Li, Lingqiang and Xie, Shurui and Xie, Jialiang},
  doi          = {10.1007/s10489-024-05554-3},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7696-7715},
  shortjournal = {Appl. Intell.},
  title        = {The variable precision fuzzy rough set based on overlap and grouping functions with double weight method to MADM},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ELM: A novel ensemble learning method for multi-target
regression and multi-label classification problems. <em>APIN</em>,
<em>54</em>(17), 7674–7695. (<a
href="https://doi.org/10.1007/s10489-024-05570-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new Ensemble Learning Method (ELM) is proposed to deal with multi-target regression and multi-label classification problems. In ELM, the output of each regressor or classifier unit is ensembled to the final multi-target regression or multi-label classification stage by utilizing the threshold strategy. In the final learning stage, a sorted-by-score scheme is specially tailored to generate the regression or classification results. The proposed method is numerically implemented and applied to twenty-nine benchmark data-sets. The average relative root mean squared error is employed to quantify the accuracy of multi-target regression methods. Meanwhile, metrics such as the hamming loss, the macro-precision, the macro-recall, the macro-F1, the micro-precision, and the micro-F1 are utilized to evaluate multi-label classification methods. Furthermore, the Bonferroni-Dunn post-hoc test is employed to illustrate the relative performance of existing methods. Overall, the corresponding regression or classification results show that the proposed ELM generally quantitatively outperforms the other nineteen existing multi-target regression or multi-label classification methods.},
  archive      = {J_APIN},
  author       = {Wu, Yuxuan and Guo, Guikai and Gao, Huanhuan},
  doi          = {10.1007/s10489-024-05570-3},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7674-7695},
  shortjournal = {Appl. Intell.},
  title        = {ELM: A novel ensemble learning method for multi-target regression and multi-label classification problems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Development of an expert-informed rig state classifier using
naive bayes algorithm for invisible loss time measurement.
<em>APIN</em>, <em>54</em>(17), 7659–7673. (<a
href="https://doi.org/10.1007/s10489-024-05560-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rig state plays a crucial role in recognizing the operations carried out by the drilling crew and quantifying Invisible Lost Time (ILT). This lost time, often challenging to assess and report manually in daily reports, results in delays to the scheduled timeline. In this paper, the Naive Bayes algorithm was used to establish a novel rig state. Training data, consisting of a large set of rules, was generated based on drilling experts’ recommendations. This dataset was then employed to build a Naive Bayes classifier capable of emulating the cognitive processes of skilled drilling engineers and accurately recognizing the actual drilling operation from surface data. The developed model was used to process high-frequency drilling data collected from three wells, aiming to derive the Key Performance Indicators (KPIs) related to each drilling crew’s efficiency and quantify the ILT during the drilling connections. The obtained results revealed that the established rig state excelled in automatically recognizing drilling operations, achieving a high success rate of 99.747%. The findings of this study offer valuable insights for drillers and rig supervisors, enabling real-time visual assessment of efficiency and prompt intervention to reduce ILT.},
  archive      = {J_APIN},
  author       = {Youcefi, Mohamed Riad and Boukredera, Farouk Said and Ghalem, Khaled and Hadjadj, Ahmed and Ezenkwu, Chinedu Pascal},
  doi          = {10.1007/s10489-024-05560-5},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7659-7673},
  shortjournal = {Appl. Intell.},
  title        = {Development of an expert-informed rig state classifier using naive bayes algorithm for invisible loss time measurement},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multivariate time series anomaly detection via dynamic graph
attention network and informer. <em>APIN</em>, <em>54</em>(17),
7636–7658. (<a
href="https://doi.org/10.1007/s10489-024-05575-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the industrial Internet, industrial software plays a central role in enhancing the level of intelligent manufacturing. It enables the promotion of digital collaborative services. Effective anomaly detection of multivariate time series can ensure the quality of industrial software. Extensive research has been conducted on time series anomaly detection to identify abnormal data. However, detecting anomalies in multivariate time series, which consist of high-dimensional, high-noise, and random data, poses significant challenges. The states of different timestamps within a time series sample can influence the overall correlation of sensor features. Unfortunately, existing methods often overlook this impact, making it difficult to capture subtle variations in the delayed response of attacked sensors.Consequently, there are false alarms and abnormal omissions. To address these limitations, this paper proposes an anomaly detection method called DGINet. DGINet leverages a dynamic graph attention network and Informer to capture and integrate feature correlation across different time states. By combining GRU and Informer, DGINet effectively captures continuous correlations in long time series. Moreover, DGINet simultaneously optimizes the reconstruction and forecasting modules, enhancing its overall performance. Experimental results on four benchmark datasets demonstrate that DGINet outperforms state-of-the-art methods by achieving up to a 2 $$\%$$ improvement in accuracy. Further analysis reveals that DGINet excels in accurately detecting anomalies in long time series and locating candidate abnormal attack points.},
  archive      = {J_APIN},
  author       = {Huang, Xiangheng and Chen, Ningjiang and Deng, Ziyue and Huang, Suqun},
  doi          = {10.1007/s10489-024-05575-y},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7636-7658},
  shortjournal = {Appl. Intell.},
  title        = {Multivariate time series anomaly detection via dynamic graph attention network and informer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Priori separation graph convolution with long-short term
temporal modeling for skeleton-based action recognition. <em>APIN</em>,
<em>54</em>(17), 7621–7635. (<a
href="https://doi.org/10.1007/s10489-024-05544-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition from skeleton motion sequences is widely applied in various fields such as virtual reality, human-computer interaction and kinematic rehabilitation. With the wide use of graph neural networks for extracting spatial features from skeleton anatomy connectivity, spatial-temporal extension of single graph models on human skeleton may improve the network performance. In this paper, we propose a priori separation graph convolution (PS-GCN) network composition with a priori mixed GCN by introducing a hypergraph representation of the skeleton spatial features, and a dynamic adaptive GCN to describe the respective graph model for each sample at each layer of the network of spatial features. For temporal feature analysis, a global attention unit is added to describe the long-term relationship. Moreover, a feature fusion structure is applied for short-term temporal features in the input of the network. The proposed model is evaluated on the NTU-RGB+D, NTU-RGB+D 120 and NW-UCLA datasets via a comprehensive ablative study. The results show that our model is comparable in accuracy to the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Zang, Tuo and Tu, Jianfeng and Duan, Mengran and Chen, Zhipeng and Cheng, Hao and Jiang, Hanrui and Zhao, Jiahui and Liu, Lingfeng},
  doi          = {10.1007/s10489-024-05544-5},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7621-7635},
  shortjournal = {Appl. Intell.},
  title        = {Priori separation graph convolution with long-short term temporal modeling for skeleton-based action recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transfer-learning-based windspeed estimation on the ocean
surface: Implication for the requirements on the spatial-spectral
resolution of remote sensors. <em>APIN</em>, <em>54</em>(17), 7603–7620.
(<a href="https://doi.org/10.1007/s10489-024-05523-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The windspeed on the sea surface is an important factor affecting the process of detecting sea surface targets, as it affects the reflection and radiation intensity, posing challenges for precise detection of optical remote sensing targets. This study collects and obtains ultra-high-resolution hyperspectral data using a push-broom hyperspectral sensor, and employs a novel data processing approach to process the raw data and extract significant features related to sea surface windspeed. Based on this foundation, further exploration is conducted into the practical requirements of the spatial dimension and spectral resolution of remote sensing sensors. Dimensionality reduction processing is applied to the hyperspectral data in both spatial and spectral dimensions. It is noteworthy that certain low-resolution spectral extractions will be derived from the central wavelengths of AVIRIS and Landsat satellites, and generate spatial-spectral joint heatmaps (SSHMs) capable of depicting sea surface windspeeds, so as to assess the potential of windspeed estimation utilizing these sensors. Moreover, four kinds of convolutional neural network (CNN) architectures, in conjunction with transfer learning techniques, are utilized to achieve precise estimation of sea surface windspeed. The final estimation results show that CNN models achieve reliable performance until the spectral dimension is reduced to 8 or below, and the spatial dimension is reduced to 25; The lightweight framework effectively employs coarse-resolution SSHMs to extract windspeed and achieve accurate recognition results. This paper introduces a feasibility study for windspeed estimation utilizing the optical sensors that meet the spatial and spectral resolution requirements.},
  archive      = {J_APIN},
  author       = {Dong, Shuang and Li, Ying and Zhang, Zhaoyi and Gou, Tao and Xie, Ming},
  doi          = {10.1007/s10489-024-05523-w},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7603-7620},
  shortjournal = {Appl. Intell.},
  title        = {A transfer-learning-based windspeed estimation on the ocean surface: Implication for the requirements on the spatial-spectral resolution of remote sensors},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic-alignment transformer and adversary hashing for
cross-modal retrieval. <em>APIN</em>, <em>54</em>(17), 7581–7602. (<a
href="https://doi.org/10.1007/s10489-024-05501-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Cross-Modal Hashing (DCMH) has garnered significant attention in the field of cross-modal retrieval due to its advantages such as high computational efficiency and small storage space. However, existing DCMH methods still face certain limitations: (1) they neglect the correlation between labels, while label features exhibit high sparsity; (2) they lack fine-grained semantic alignment; (3) they fail to effectively address data imbalance. In order to tackle these issues, this paper introduces a framework named Semantic-Alignment Transformer and Adversary Hashing for Cross-modal Retrieval (SATAH). To the best of our knowledge, this is the first attempt at the Semantic-Alignment Transformer algorithm. Specifically, this paper first designs a label learning network that utilizes a crafted transformer module to extract label information, guiding adversarial learning and hash function learning accordingly. Subsequently, a Balanced Conditional Generative Adversarial Network (BCGAN) is constructed, marking the first instance of adversarial training guided by label information. Furthermore, a Weighted Semi-Hard Cosine Triplet Constraint is proposed to better ensure high-ranking similarity relationships among all items. Lastly, considering the correlation between labels, a semantic-alignment constraint is introduced to handle label correlation from a fine-grained perspective, capturing similarity on a global scale more effectively. Extensive experiments are conducted on multiple representative cross-modal datasets. In experiments with 64-bit hash code length, SATAH achieves average mAP values of 84.75%, 68.87%, and 68.73% on MIR Flickr, NUS-WIDE, and MS COCO datasets, respectively, outperforming state-of-the-art methods. The code is available at https://github.com/Daydaylight/SATAH.},
  archive      = {J_APIN},
  author       = {Sun, Yajun and Wang, Meng and Ma, Ying},
  doi          = {10.1007/s10489-024-05501-2},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7581-7602},
  shortjournal = {Appl. Intell.},
  title        = {Semantic-alignment transformer and adversary hashing for cross-modal retrieval},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for higher-order nonparametric spatial
autoregressive model. <em>APIN</em>, <em>54</em>(17), 7570–7580. (<a
href="https://doi.org/10.1007/s10489-024-05541-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning technology has been successfully applied in more and more fields. In this paper, the application of deep neural networks in higher-order nonparametric spatial autoregressive models is studied. For spatial model, we propose the higher-order nonparametric spatial autoregressive neural network (HNSARNN) to fit the model. This method offers both good interpretability and prediction performance, and solves the black box problem in deep learning models to some degree. In various scenarios of spatial data distribution, the proposed method demonstrates superior performance compared to traditional approaches for handling nonparametric functions (such as the B-spline method). Simulation results show the effectiveness of the proposed model.},
  archive      = {J_APIN},
  author       = {Li, Zitong and Song, Yunquan and Jian, Ling},
  doi          = {10.1007/s10489-024-05541-8},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7570-7580},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning for higher-order nonparametric spatial autoregressive model},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A belief interval euclidean distance entropy of the mass
function and its application in multi-sensor data fusion. <em>APIN</em>,
<em>54</em>(17), 7545–7569. (<a
href="https://doi.org/10.1007/s10489-024-05563-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer (D-S) evidence theory has extensive applications in the field of data fusion. It uses the mass function to replace the probability distribution in Bayesian Probability theory, which has the advantages of weak constraints and representing uncertainty. However, many existing uncertainty measures can not be well applied to the mass function, leading to many defects in some scenarios. For example, many methods can not fully reflect the relationship between focal elements. Therefore, how to improve the uncertainty measurement, and make full use of the advantages of the mass function, so as to further accurately express the system state, is still a hot topic worth studying. To solve this problem, we propose a Belief Interval Euclidean Distance (BIED) entropy of the mass function. This method combines nonspecificity and discord measurement of the mass function and is suitable for various situations. In this paper, we introduce a large number of numerical examples to demonstrate the practicality of the BIED entropy. Compared with existing advanced methods, the BIED entropy can better identify the quantity relationship and similarity relationship between focal elements, and exhibit a linear trend with the changing cardinality of focal elements. Finally, we implement a BIED entropy-based multi-sensor data fusion on various kinds of datasets. The experimental results indicate that BIED entropy has relatively high robustness, with the target recognition accuracy close to 79.33% and the F1-Score close to 77.29%.},
  archive      = {J_APIN},
  author       = {Zhang, Fuxiao and Chen, Zichong and Cai, Rui},
  doi          = {10.1007/s10489-024-05563-2},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {17},
  pages        = {7545-7569},
  shortjournal = {Appl. Intell.},
  title        = {A belief interval euclidean distance entropy of the mass function and its application in multi-sensor data fusion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two guidance joint network based on coarse map and edge map
for camouflaged object detection. <em>APIN</em>, <em>54</em>(15),
7531–7544. (<a
href="https://doi.org/10.1007/s10489-024-05559-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) entails identifying objects in an image that blend with the background. However, most traditional COD methods have not comprehensively considered the information provided by the overall region and edges of the objects. To address this problem, a new two-guidance joint network based on coarse and edge maps is proposed for COD. Particularly, an information guidance module is designed to inject edges and overall information into the network’s backbone features. Meanwhile, a feature observation model based on skip connections and multi-scale perception is designed to capture multi-scale image details and structures. To avoid the loss of semantic information in low-level features, a full-image attention mechanism is designed to integrate high-level features into low-level features, thereby improving the resolution of the object masks. We compared the proposed network with state-of-the-art models on three well-known datasets, and the experimental results show the proposed network has significant improvement. By exploring valuable boundary information and overall object information, the proposed network can segment object edges while also considering the segmentation effect of the entire object. Our code has been open-sourced at https://github.com/Huah2019/TJNet .},
  archive      = {J_APIN},
  author       = {Tang, Zhe and Tang, Jing and Zou, Dengpeng and Rao, Junyi and Qi, Fang},
  doi          = {10.1007/s10489-024-05559-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7531-7544},
  shortjournal = {Appl. Intell.},
  title        = {Two guidance joint network based on coarse map and edge map for camouflaged object detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TAENet: Transencoder-based all-in-one image enhancement with
depth awareness. <em>APIN</em>, <em>54</em>(15), 7509–7530. (<a
href="https://doi.org/10.1007/s10489-024-05569-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, CNN-based all-in-one image enhancement methods have been proposed to solve multiple image degradation tasks. However, these CNN-based methods usually have two limitations. One limitation is that they usually design a specific encoder for each image enhancement task, lacking of a unified and simple framework. The other limitation is that they can not effectively capture global image degradation information, as use of the CNN-based encoders has a limited local receptive field. In this work, we propose a TransEncoder-based All-in-one Image Enhancement Network (TAENet), with a single encoder and a decoder, for simultaneously handling multiple image enhancement tasks. Specifically, we propose a Transformer-based Encoder (TransEncoder), which introduces instance normalization to transformer for color recovery. The TransEncoder model global degradation information by using the transformer’s global self-attention mechanism. Additionally, inspired by the Mie scattering model, we propose a novel depth loss function for perceiving image depth information by minimizing the depth difference between the enhanced image and the ground-truth, thus further improving model performance. Moreover, a novel contrastive loss is introduced to strengthen task-generalization performance by enhancing the model’s representation capability. Experiments show that the TAENet outperforms 24 state-of-the-art methods on image dehazing, image deraining, and low-light image enhancement.},
  archive      = {J_APIN},
  author       = {Fang, Wanchuan and Wang, Chuansheng and Li, Zuoyong and Grau, Antoni and Lai, Taotao and Chen, Jianzhang},
  doi          = {10.1007/s10489-024-05569-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7509-7530},
  shortjournal = {Appl. Intell.},
  title        = {TAENet: Transencoder-based all-in-one image enhancement with depth awareness},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive image compression for gaussian mixture model
quartile intervals. <em>APIN</em>, <em>54</em>(15), 7493–7508. (<a
href="https://doi.org/10.1007/s10489-024-05577-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we proposed a novel deep image coding and decoding model for GMMQI (Gaussian mixture model quartile intervals, GMMQI) and a variable rate bit allocation method to optimize the rate distortion performance and prioritize the transmissions of more significant information. First, to address the problem of bit streams leading to ambiguity during encoding and decoding, we convert the image into a potential tensor, each element of which uses a four-bit parameter dictionary to preserve the parameter bits. Then, the variable rate is calculated using quaternions based on the parameter dictionary, and a hybrid CLM &amp;BAM (Channel latent map &amp; Bit allocation map) approach is designed to assign bits to the potential tensor and encode it, which transforms the problem of finding the optimal encoder-decoder into finding the optimal hyper-parameters in the model and reduces the complexity of the GMMQI model. Finally, a GMMQI approach with variable rate bit allocation is developed in combination with CLM &amp;BAM, to be able to prioritize the transmission of more significant information. The experimental results show that the GMMQI method reaches an advanced level compared to the traditional image compression standards BPG, JPEG2000, and JPEG, and is comparable to the most advanced level compared to the existing deep learning based compression methods.},
  archive      = {J_APIN},
  author       = {Kong, Weiheng and Sun, Minghui},
  doi          = {10.1007/s10489-024-05577-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7493-7508},
  shortjournal = {Appl. Intell.},
  title        = {Progressive image compression for gaussian mixture model quartile intervals},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multistep traffic speed prediction from multiple time-scale
spatiotemporal features using graph attention network. <em>APIN</em>,
<em>54</em>(15), 7479–7492. (<a
href="https://doi.org/10.1007/s10489-024-05503-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting using deep learning represents a crucial aspect of intelligent transportation systems, carrying substantial implications for congestion reduction and efficient route planning. Despite its significance, accurately predicting traffic states remains a challenge. Existing methodologies focus on capturing the temporal trends of traffic states and the spatial dependencies between roads to enhance prediction accuracy. However, two noteworthy limitations persist in these approaches: (1) Many models neglect the interaction between spatiotemporal features across varying time spans, hindering their ability to utilize traffic state information effectively for predicting future conditions. (2) Genuine correlations between roads are time-varying, making it inadequate to rely on static graphs or static pre-trained node embeddings to model dynamic correlations between roads. To address these challenges, we propose the Multiple Time-Scale Graph Attention Network (MTS-GATN), which comprises two key modules: the Multiple Time-Scale Spatiotemporal Features Extraction Module and the Feature Augmentation Module. The first module involves stacking multiple spatiotemporal extraction layers to discern traffic state information at different time scales. In the second module, we employ dynamic spatial semantic embedding for feature augmentation, providing nodes with dynamic representations over time. Subsequently, we leverage a multi-head spatiotemporal attention mechanism to comprehensively consider location information and real-time semantic data, facilitating the interaction of traffic state information across multiple time scales. Experimental results on two distinct traffic datasets validate the superior performance of MTS-GATN in medium-term and long-term forecasting scenarios.},
  archive      = {J_APIN},
  author       = {Fang, Jie and Wu, Zhichao and Xu, Mengyun and Chen, Hongting},
  doi          = {10.1007/s10489-024-05503-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7479-7492},
  shortjournal = {Appl. Intell.},
  title        = {Multistep traffic speed prediction from multiple time-scale spatiotemporal features using graph attention network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SMoTeF: Smurf money laundering detection using temporal
order and flow analysis. <em>APIN</em>, <em>54</em>(15), 7461–7478. (<a
href="https://doi.org/10.1007/s10489-024-05545-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smurfing in financial networks is a popular fraud technique in which fraudsters inject their illegal money into the legitimate financial system. This activity is performed within a short period of time, with recurring transactions and multiple intermediaries. A major problem of existing graph-based methods for detecting smurfing is that they fall short of retrieving accurate fraud patterns. Consequently, the result is numerous non-fraudulent patterns alongside a few fraud patterns, causing a high false-positive rate. To alleviate this problem, we propose SMoTeF, a framework that extends existing graph-based smurf detection methods by distinguishing fraudulent smurfing patterns from non-fraudulent ones, thus significantly reducing the false-positive ratio. The core of the approach is a novel algorithm based on computing maximum temporal flow within temporal order of events. In order to evaluate the approach, a framework for injecting various smurfing patterns is developed, and experimental results on three real-world datasets from different domains show that SMoTeF significantly improves on the effectiveness of the state-of-the-art baseline, with only marginal runtime overhead.},
  archive      = {J_APIN},
  author       = {Shadrooh, Shiva and Nørvåg, Kjetil},
  doi          = {10.1007/s10489-024-05545-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7461-7478},
  shortjournal = {Appl. Intell.},
  title        = {SMoTeF: Smurf money laundering detection using temporal order and flow analysis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic load forecasting based on quantile regression
parallel CNN and BiGRU networks. <em>APIN</em>, <em>54</em>(15),
7439–7460. (<a
href="https://doi.org/10.1007/s10489-024-05540-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the dynamic smart grid landscape, accurate probabilistic forecasting of electric load is critical. This paper presents a novel 24-hour-ahead probabilistic load forecasting model by integrating quantile regression with a parallel convolutional neural network (CNN) and bidirectional gated recurrent unit (BiGRU) architecture. Carefully tuning hyperparameters can enhance model performance and generalization capability. Consequently, we propose an improved whale optimization algorithm for automatic hyperparameter tuning of the forecasting model. Case studies demonstrate the proposed method’s superior performance over benchmark models in terms of average interval score and pinball loss. In addition, it exhibits valid coverage and tight interval bandwidths. The model provides precise short-term load forecasts to support robust smart grid planning and operations.},
  archive      = {J_APIN},
  author       = {Lu, Yuting and Wang, Gaocai and Huang, Xianfei and Huang, Shuqiang and Wu, Man},
  doi          = {10.1007/s10489-024-05540-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7439-7460},
  shortjournal = {Appl. Intell.},
  title        = {Probabilistic load forecasting based on quantile regression parallel CNN and BiGRU networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A new uncertainty processing method for trajectory
prediction. <em>APIN</em>, <em>54</em>(15), 7418–7438. (<a
href="https://doi.org/10.1007/s10489-024-05527-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many domains, trajectory prediction a crucial task. Uncertain information, such as complementary and correlated information between multiple features, complex interactive information, weather and temperature, increases the difficulty of trajectory prediction. In real life scenarios, multi-feature information often interact and complement each other. It is difficult to isolate multi-feature information and consider their effects separately. At present, many trajectory prediction methods based on multi-feature information fusion often ignore the correlation impact information between multiple features. This may lead to insufficient utilization of multi-feature information, which limits the improvement of prediction accuracy. In this paper, a new information fusion method based on uncertain information processing is proposed. To begin with, the local support impact between multi-feature information is modeled by the local support function of power average (P-A) operator. The global support impact between them is modeled by the global support function of P-A. Then, through the local support impact and global support impact, the weight of each feature information is obtained respectively. The nonlinear fusion is performed to make full use of multi-feature information. What is more, in the discriminator, a new fuzzy soft discrimination state is added. The fuzzy soft discrimination state improves the flexibility of the discriminator. At last, based on the soft discrimination, a new loss function is proposed by combining the belief entropy and cross entropy. With the uncertain information processing, compared to some baselines, the proposed method achieves higher accuracy in some parts of the ETH/UCY dataset.},
  archive      = {J_APIN},
  author       = {Yang, Tian and Wang, Gang and Lai, Jian and Wang, Yang},
  doi          = {10.1007/s10489-024-05527-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7418-7438},
  shortjournal = {Appl. Intell.},
  title        = {A new uncertainty processing method for trajectory prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMEFS: Chaotic mapping-based mayfly optimization with fuzzy
entropy for feature selection. <em>APIN</em>, <em>54</em>(15),
7397–7417. (<a
href="https://doi.org/10.1007/s10489-024-05555-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence algorithms availably settle the issue of feature selection for classification, whereas the Mayfly Optimization Algorithm (MOA) proposed in recent years has the superiority of high precision, concise structure, and effortless enforcement; but it is still caught in local optimum, and the convergence speed needs to be optimized. Then, this work studies a new MOA and further develops a binary MOA to solve feature selection problems. Initially, based on two mapping mechanisms of Logistic-Tent and Cubic chaotic, the male and female populations of MOA are mapped respectively to enhance the variety of MOA populations in the exploration stage, and the Cubic chaotic mapping scheme is cited to dynamically disturb the global optimum to eliminate the limitation of easily getting into local optimum and promote local exploration ability for MOA. Secondly, the parameter fuzzy entropy is proposed to improve MOA, and then an adaptive function based on the parameter fuzzy entropy is constructed by using the historical optimal result of mayfly in the population of MOA. The parameter fuzzy entropy is used as an impact factor to variously adapt the inertia weight, balance global optimization and local exploration capability of population, and increase the variety of population and uniformity of distribution. Further, the contraction factor is improved to be introduced into MOA, and two learning factors are restricted by parameters, so that the velocity of mayfly individuals is not too large, and the convergence performance of MOA is effectively improved. Finally, the binary MOA is constructed based on the S-type transfer function, so that it can process those continuous data, and the optimal feature subset is selected by employing the fitness function. Simulation experimental results on 16 benchmark functions and 12 public datasets show that the binary MOA has great optimization performance, and the effectiveness of the designed feature selection algorithm has been verified.},
  archive      = {J_APIN},
  author       = {Sun, Lin and Liang, Hanbo and Ding, Weiping and Xu, Jiucheng and Chang, Baofang},
  doi          = {10.1007/s10489-024-05555-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7397-7417},
  shortjournal = {Appl. Intell.},
  title        = {CMEFS: Chaotic mapping-based mayfly optimization with fuzzy entropy for feature selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improvement of robust tensor principal component analysis
based on generalized nonconvex approach. <em>APIN</em>, <em>54</em>(15),
7377–7396. (<a
href="https://doi.org/10.1007/s10489-024-05529-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of nonconvex robust tensor principal component analysis consists of recovering the low-rank and sparse part from a tensor corrupted by noise, which attracts a great deal of attention in a wide range of practical situations. However, existing nonconvex methods face a number of problems, the two most important of which are the restrictions on specific nonconvex functions and the information loss in low-rank part. In this paper, we propose a generalized nonconvex robust tensor principal component analysis model that includes some of the most popular nonconvex functions. Furthermore, we propose a partial weighted tensor nuclear norm and the corresponding partial weighted singular value thresholding operator to improve the generalized model, further reducing the loss of underlying tensor information while recovering the low rank tensor. Besides, two ADMM-based nonconvex algorithms are proposed to the generalized nonconvex model and the improved model respectively. We also analyze the convergence of the algorithms, the computational complexity, and the theoretical guarantee of the proposed models. Numerical experimental results on image data and video data show that our proposed models has superior performance compared to several state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Tang, Kaiyu and Fan, Yali and Song, Yan},
  doi          = {10.1007/s10489-024-05529-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {15},
  pages        = {7377-7396},
  shortjournal = {Appl. Intell.},
  title        = {Improvement of robust tensor principal component analysis based on generalized nonconvex approach},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust fisher-regularized extreme learning machine with
asymmetric welsch-induced loss function for classification.
<em>APIN</em>, <em>54</em>(13), 7352–7376. (<a
href="https://doi.org/10.1007/s10489-024-05528-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, it is a worth challenging problem to build a robust classifier for data sets with noises or outliers. Establishing a robust classifier is a more difficult problem for datasets with asymmetric noise distribution. The Fisher-regularized extreme learning machine (Fisher-ELM) considers the statistical knowledge of the data, however, it ignores the impact of noises or outliers. In this paper, to reduce the negative influence of noises or outliers, we first put forward a novel asymmetric Welsch loss function named AW-loss based on asymmetric $$L_{2}$$ -loss function and Welsch loss function. Based on the AW-loss function, we then present a new robust Fisher-ELM called AWFisher-ELM. The proposed AWFisher-ELM not only takes into account the statistical information of the data, but also considers the impact of asymmetric distribution noises. We utilize concave-convex procedure (CCCP) and dual method to solve the non-convexity of the proposed AWFisher-ELM. Simultaneously, an algorithm for AWFisher-ELM is given and a theorem about the convergence of the algorithm is proved. To validate the effectiveness of our algorithm, we compare our AWFisher-ELM with the other state-of-the-art methods on artificial data sets, UCI data sets, NDC large data sets and image data sets by setting different ratios of noises. The experimental results are as follows, the accuracy of AWFisher-ELM is the highest in the artificial data sets, reaching 98.9%. For the large-scale NDC data sets and the image data sets, the accuracy of AWFisher-ELM is also the highest. For the ten UCI data sets, the accuracy and $$F_{1}$$ value of AWFisher-ELM are the highest in most data sets expect for Diabetes. In terms of training time, our AWFisher-ELM has almost the same training time with RHELM and CHELM, but it takes longer time than OPT-ELM, WCS-SVM, Fisher-SVM, Pinball-FisherSVM, and Fisher-ELM. This is because AWFisher-ELM, RHELM, and CHELM need to solve a convex quadratic subprogramming problem in each iteration. In conclusion, our method exhibits excellent generalization performance expect for the longer training time.},
  archive      = {J_APIN},
  author       = {Xue, Zhenxia and Zhao, Chongning and Wei, Shuqing and Ma, Jun and Lin, Shouhe},
  doi          = {10.1007/s10489-024-05528-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7352-7376},
  shortjournal = {Appl. Intell.},
  title        = {Robust fisher-regularized extreme learning machine with asymmetric welsch-induced loss function for classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UnseenSignalTFG: A signal-level expansion method for unseen
acoustic data based on transfer learning. <em>APIN</em>,
<em>54</em>(13), 7317–7351. (<a
href="https://doi.org/10.1007/s10489-024-05568-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a transfer learning-based approach for signal-level expansion of unseen acoustic signal data, aiming to address the scarcity of acoustic signal data in a specific domain. By establishing connections and sharing knowledge between the source and target domains, the method successfully mitigates cross-domain disparities, overcoming challenges posed by unavailable data in the target domain, thereby elevating the quality and precision of data expansion. Diverging from conventional methods that predominantly emphasize feature-level expansion, the proposed approach accentuates the preservation of data signal integrity and effectively achieves the expansion of unseen class samples within the target domain.The effectiveness of this method has been validated across four different types of signal datasets. In the bearing dataset, the expansion of unseen data achieved accuracies of 99% at the signal level and 95% at the spectral level. These experimental results not only demonstrate the method’s advantages in augmenting both seen and unseen data but also highlight its effectiveness and application potential in achieving comprehensive expansion of target signals.},
  archive      = {J_APIN},
  author       = {Pan, Xiaoying and Sun, Jia and Lei, MingZhu and Wang, YiFan and Zhang, Jie},
  doi          = {10.1007/s10489-024-05568-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7317-7351},
  shortjournal = {Appl. Intell.},
  title        = {UnseenSignalTFG: A signal-level expansion method for unseen acoustic data based on transfer learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GAN-GA: Infrared and visible image fusion generative
adversarial network based on global awareness. <em>APIN</em>,
<em>54</em>(13), 7296–7316. (<a
href="https://doi.org/10.1007/s10489-024-05561-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current generative adversarial network (GAN)-based methods for infrared and visible image fusion often overlook global information, leading to inappropriate distribution of fused images in terms of infrared intensity and an overall incongruous presentation. In order to tackle this issue, in this paper, a new global awareness fusion network based on GAN is proposed, termed as GAN-GA. The proposed method comprises a generator and two discriminators. The generator consists of three series-connected global awareness blocks (GABlock), namely detail branch, content branch and feature aggregation block. The detail branch employs a convolutional network and max pooling to extract local detailed information, while the content branch utilizes Transformer to obtain global information. The local details and global information are then passed through the feature aggregation block to focus attention on distinct spatial locations and assign weights based on information importance, resulting in the final fused image. Moreover, the primary and auxiliary concepts are introduced in content loss, incorporating the difference images of infrared and visible as supplementary information into the loss function to fully leverage the information in the source images. For the discriminator, the WGAN-LP loss is employed to constrain its training, which introduces a new gradient penalty based on WGAN-GP to enhance the capability of discriminator. With these enhancements, GAN-GA effectively captures the global features of the source image while preserving the local texture and infrared intensity, which obtains an overall more coordinated fused image.},
  archive      = {J_APIN},
  author       = {Wu, Jiacheng and Liu, Gang and Wang, Xiao and Tang, Haojie and Qian, Yao},
  doi          = {10.1007/s10489-024-05561-4},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7296-7316},
  shortjournal = {Appl. Intell.},
  title        = {GAN-GA: Infrared and visible image fusion generative adversarial network based on global awareness},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised feature selection based on discernibility
matrix and mutual information. <em>APIN</em>, <em>54</em>(13),
7278–7295. (<a
href="https://doi.org/10.1007/s10489-024-05481-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a vital technique for reducing data dimensionality. While many granular computing-based feature selection algorithms have been proposed, most have been regarded as a supervised learning task requiring a large number of labeled instances. However, obtaining sufficient labeled data is expensive and time-consuming. To address this limitation, a novel semi-supervised feature selection framework is developed by leveraging both labeled and unlabeled data. Specifically, the discernibility matrix is used to measure feature relevance on the labeled data. Moreover, mutual information is employed to evaluate the feature significance on the unlabeled data. By combining these supervised and unsupervised metrics, a greedy feature selection algorithm is proposed for the semi-supervised learning scenarios. The proposed discernibility matrix and mutual information-based feature measurement can select more discriminative features to improve the generalization performance of learning model. Finally, experiments conducted on ten UCI semi-supervised datasets demonstrate that the proposed approach achieves superior performance over five state-of-the-art semi-supervised feature selection methods.},
  archive      = {J_APIN},
  author       = {Qian, Wenbin and Wan, Lijuan and Shu, Wenhao},
  doi          = {10.1007/s10489-024-05481-3},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7278-7295},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised feature selection based on discernibility matrix and mutual information},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear crossing strategy-based particle swarm
optimizations with time-varying acceleration coefficients.
<em>APIN</em>, <em>54</em>(13), 7229–7277. (<a
href="https://doi.org/10.1007/s10489-024-05502-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contemporary particle swarm optimization (PSO) algorithms, to efficiently explore global optimum solutions, it is common practice to set the inertia weight to monotonically decrease over time for stability, while allowing the two acceleration coefficients, representing cognitive and social factors, to adopt decreasing or increasing functions over time, including random variations. However, there has been little discussion on a unified design approach for these time-varying acceleration coefficients. This paper presents a unified methodology for designing monotonic decreasing or increasing functions to construct nonlinear time-varying inertia weight and two acceleration coefficients in PSO, along with a control strategy for exploring global optimum solutions. We first construct time-varying coefficients by linearly amplifying well-posed monotonic functions that decrease or increase over normalized time. Here, well-posed functions ensure satisfaction of specified conditions at the initial and terminal points of the search process. However, many of the functions employed thus far only satisfy well-posedness at either the initial or terminal points of the search time, prompting the proposal of a method to adjust them to virtually meet specified initial or terminal points. Furthermore, we propose a crossing strategy where the developed cognitive and social acceleration coefficients intersect within the search time interval, effectively guiding the search process by pre-determining crossing values and times. The performance of our Nonlinear Crossing Strategy-based Particle Swarm Optimization (NCS-PSO) is evaluated using the CEC2014 (Congress on Evolutionary Computation in 2014) benchmark functions. Through comprehensive numerical comparisons and statistical analyses, we demonstrate the superiority of our approach over seven conventional algorithms. Additionally, we validate our approach, particularly in a drone navigation scenario, through an example of optimal 3D path planning. These contributions advance the field of PSO optimization techniques, providing a robust approach to addressing complex optimization problems.},
  archive      = {J_APIN},
  author       = {Watanabe, Keigo and Xu, Xiongshi},
  doi          = {10.1007/s10489-024-05502-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7229-7277},
  shortjournal = {Appl. Intell.},
  title        = {Nonlinear crossing strategy-based particle swarm optimizations with time-varying acceleration coefficients},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SGD method for entropy error function with smoothing <span
class="math display"><em>l</em><sub>0</sub></span> regularization for
neural networks. <em>APIN</em>, <em>54</em>(13), 7213–7228. (<a
href="https://doi.org/10.1007/s10489-024-05564-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The entropy error function has been widely used in neural networks. Nevertheless, the network training based on this error function generally leads to a slow convergence rate, and can easily be trapped in a local minimum or even with the incorrect saturation problem in practice. In fact, there are many results based on entropy error function in neural network and its applications. However, the theory of such an algorithm and its convergence have not been fully studied so far. To tackle the issue, this works proposes a novel entropy function with smoothing $$l_0$$ regularization for feed-forward neural networks. An empirical evaluation has been conducted on real-world datasets to demonstrate that the newly conceived algorithm allows us to substantially improve the prediction performance of the considered neural networks. More importantly, the experimental results also show that the proposed function brings in more precise classifications, compared to well-founded baselines. The work is novel as it enables neural networks to learn effectively, producing more accurate predictions compared to state-of-the-art algorithms. In this respect, it is expected that the algorithm will contribute to existing studies in the field, advancing research in Machine Learning and Deep Learning.},
  archive      = {J_APIN},
  author       = {Nguyen, Trong-Tuan and Thang, Van-Dat and Nguyen, Van Thin and Nguyen, Phuong T.},
  doi          = {10.1007/s10489-024-05564-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7213-7228},
  shortjournal = {Appl. Intell.},
  title        = {SGD method for entropy error function with smoothing $$l_0$$ regularization for neural networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The error sample feature compensation method for improving
the robustness of underwater classification and recognition models.
<em>APIN</em>, <em>54</em>(13), 7201–7212. (<a
href="https://doi.org/10.1007/s10489-024-05397-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the intensification of ocean exploration and development in recent years, the navigation equipment in the marine environment has become increasingly diversified, making the marine environment more complex. Traditional methods for underwater target recognition are gradually becoming less applicable and unable to achieve better results. With the application of deep learning in underwater target recognition, the robustness of deep learning models used for underwater target recognition is crucial due to the significant environmental interference in underwater target data and the susceptibility of deep learning models to adversarial samples. This paper proposes an error sample feature compensation method for improving the robustness of deep learning models for underwater target recognition, focusing on the problem of the significant impact of sample data quality on the robustness of deep learning models for underwater target recognition. The method innovatively divides error samples into difficult-to-improve samples and easy-to-improve samples and proposes an adversarial training method combined with classification conditions. At the same time, the method uses a weighted index of model accuracy to combine adversarial training models with feature compensation methods, further improving the robustness of deep learning models for underwater target recognition tasks. Finally, the method is validated on an underwater dataset, and the results show that the proposed method improves the robustness of deep learning models used for underwater target recognition.},
  archive      = {J_APIN},
  author       = {He, Ming and Wang, Jinman and Wang, Hongbin and Jiang, Tianshu and Shi, Leibo},
  doi          = {10.1007/s10489-024-05397-y},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7201-7212},
  shortjournal = {Appl. Intell.},
  title        = {The error sample feature compensation method for improving the robustness of underwater classification and recognition models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Q-learning based on strategic artificial potential field for
path planning enabling concealment and cover in ground battlefield
environments. <em>APIN</em>, <em>54</em>(13), 7170–7200. (<a
href="https://doi.org/10.1007/s10489-024-05436-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning in battlefield environments differs from typical path planning because it may not always involve obstacle avoidance. In fact, obstacles can be utilized to hide from enemies or facilitate troop advancement through destruction and relocation. Therefore, path planning in such environments requires specificity. One widely used method for obstacle avoidance is the artificial potential field (APF) method. This study proposes a strategic artificial potential field (SAPF) algorithm that utilizes obstacles for path planning. The Q-learning algorithm is also being researched for its application in learning methods involving path planning and obstacle avoidance. This study proposes a path planning algorithm utilizing SAPF-based Q-learning that takes into account concealment and cover in various terrains. The proposed Q-SAPF algorithm was compared to Q-learning based on the results of repeated experiments and analysis of variance (ANOVA) and the post hoc Tukey technique to examine the statistical significance and differences between the algorithms, respectively. Q-SAPF outperformed Q-learning by generating shorter path plans with differences in path lengths of 1.96–8.77. It further achieved faster learning times of approximately 14.57–69.29 s and path scores that were higher by approximately 2.73–47.96. Specifically, its success rate was 13.73–54.89% higher than that of Q-learning. The achieved outcome demonstrated the superior learning ability of the Q-SAPF. The study results confirm the feasibility of path planning that incorporates concealment and cover by utilizing obstacles. The findings of this study can contribute to path planning in various situations beyond wartime environments.},
  archive      = {J_APIN},
  author       = {Lee, Jisun and Seo, Yoonho},
  doi          = {10.1007/s10489-024-05436-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7170-7200},
  shortjournal = {Appl. Intell.},
  title        = {Q-learning based on strategic artificial potential field for path planning enabling concealment and cover in ground battlefield environments},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-task recommendation based on dynamic knowledge graph.
<em>APIN</em>, <em>54</em>(13), 7151–7169. (<a
href="https://doi.org/10.1007/s10489-024-05548-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introducing knowledge graphs into recommender systems effectively solves sparsity and cold start problems. However, existing KG recommendation methods such as MKR mostly rely on static knowledge graphs, ignoring that nodes and edges in the graph dynamically change over time, leading to problems such as insufficient timeliness, inability to describe context dependencies, data redundancy, and noise. We propose a multi-task learning method for recommendation enhancement based on dynamic knowledge graphs, MTRDKG, which models the dynamic knowledge graph as a series of continuous time events. Specifically, after node events (node-level or interactions between nodes) occur, the memory state of the nodes is updated through a temporal graph network (TGN), and node temporal embeddings are generated to capture the nodes’ attributes, contextual relationships, and dynamic change information. We use the node embeddings generated by TGN in conjunction with the recommended items as a shared part, aiming to integrate dynamic knowledge graph information into the recommendation task, thereby improving the recommendation effect. Extensive experiments were conducted with four real-world datasets and state-of-the-art baseline methods. The results show that MTRDKG outperforms existing methods in terms of recommendation accuracy and knowledge graph embedding quality, especially in dealing with datasets of different sparsity levels.},
  archive      = {J_APIN},
  author       = {Wen, Minwei and Mei, Hongyan and Wang, Wei and Xue, Xiaorong and Zhang, Xing},
  doi          = {10.1007/s10489-024-05548-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7151-7169},
  shortjournal = {Appl. Intell.},
  title        = {Multi-task recommendation based on dynamic knowledge graph},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Uncertainty-aware enhanced dark experience replay for
continual learning. <em>APIN</em>, <em>54</em>(13), 7135–7150. (<a
href="https://doi.org/10.1007/s10489-024-05488-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The replay-based approaches are a notable family of methods among many efforts on Continual Learning, where memory sampling strat- egy and rehearsal mode are two fundamental aspects to alleviate the catastrophic forgetting. However, most existing replay-based approaches focus primarily on exploring the rehearsal mode but neglect the sig- nificant influence of the sampling strategy, especially failing to ade- quately utilize the inherent attributes in samples and the information provided by the old task model. To this end, we propose a novel sam- pling strategy dubbed Uncertainty-Aware Sampling (UAS) strategy, which employs model and data uncertainties as criteria to select sam- ples that are stable to the model and have low noise for rehearsal. Further, we design a dual network to acquire new knowledge while maintaining old knowledge, in which a Convolutional Neural Network (CNN) is applied to continuously learn and consolidate knowledge, and a Bayesian Neural Network (BNN) is employed as a comple- ment to capture the uncertainty while providing additional information for the CNN. Besides, we incorporate a data uncertainty loss into Dark Experience Replay as rehearsal mode to alleviate the catas- trophic forgetting in both CNN and BNN, called Uncertainty-Aware Replay (UAR). Extensive experiments on four benchmark datasets demonstrate that the proposed framework is competitive with state- of-the-art methods under three different continual learning settings.},
  archive      = {J_APIN},
  author       = {Wang, Qiang and Ji, Zhong and Pang, Yanwei and Zhang, Zhongfei},
  doi          = {10.1007/s10489-024-05488-w},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {13},
  pages        = {7135-7150},
  shortjournal = {Appl. Intell.},
  title        = {Uncertainty-aware enhanced dark experience replay for continual learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modelling flight trajectories with multi-modal generative
adversarial imitation learning. <em>APIN</em>, <em>54</em>(11),
7118–7134. (<a
href="https://doi.org/10.1007/s10489-024-05519-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models of aircraft trajectories become important components of systems supporting the trajectory based operations paradigm: trajectory predictability is considered to be the main driver to enhance operational key performance areas, such as capacity of the airspace, effectiveness regarding all stakeholders’ objectives, and, of course, safety. This article formulates the trajectory modelling problem as a data-driven imitation learning problem addressing multi-modality. To solve this problem we study the use of state-of-the-art multi-modal imitation learning methods Info-GAIL and Triple-GAIL operating in a supervised way, with the aim of (a) disentangling modalities representing patterns of trajectory evolution, and (b) predicting trajectories. Experiments are performed using a real-world dataset of long flights with origin Paris and destination Istanbul. Results show the potential of imitation learning methods to disentangle multi-modal trajectories in real-world settings and predict trajectories with high accuracy.},
  archive      = {J_APIN},
  author       = {Spatharis, Christos and Blekas, Konstantinos and Vouros, George A.},
  doi          = {10.1007/s10489-024-05519-6},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {7118-7134},
  shortjournal = {Appl. Intell.},
  title        = {Modelling flight trajectories with multi-modal generative adversarial imitation learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WalkNAR: A neighborhood rough sets-based attribute reduction
approach using random walk. <em>APIN</em>, <em>54</em>(11), 7099–7117.
(<a href="https://doi.org/10.1007/s10489-024-05533-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood rough sets, as an effective tool for processing numerical data, is widely used in many fields, such as data mining, machine learning and decision-making system. However, most of the existing neighborhood rough set-based attribute reduction algorithms have low efficiency. To address the limitation, this paper has proposed an efficient positive region search algorithm based on multiple hash buckets and multiple granularity mechanisms. This algorithm achieves a more accurate neighborhood extent by superimposing the effects of multiple hash buckets, and accelerates positive region searching through the idea of multiple granularity. In addition, on the foundation the positive region search algorithm, we improved the existing algorithm and proposed an attribute reduction algorithm based on multi-hash bucket and multi-granularity. To further remove the redundant attributes, the two algorithms mentioned above are applied into a novel attribute reduction approach based on random walk. Experiments conducted on UCI datasets show that our attribute reduction algorithm has high efficiency. Moreover, attribute reduction approach we proposed can further compress the reduced attribute set, and the results maintain similar or even better classification accuracy.},
  archive      = {J_APIN},
  author       = {Li, Haibo and Xiong, Wuyang and Li, Yanbin and Xie, Xiaojun},
  doi          = {10.1007/s10489-024-05533-8},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {7099-7117},
  shortjournal = {Appl. Intell.},
  title        = {WalkNAR: A neighborhood rough sets-based attribute reduction approach using random walk},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multimodal attention-fusion convolutional neural network
for automatic detection of sleep disorders. <em>APIN</em>,
<em>54</em>(11), 7086–7098. (<a
href="https://doi.org/10.1007/s10489-024-05499-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep is essential for human physical and mental health. Sleep disorders are a significant threat to human health, and a large number of people in the world suffer from sleep disorders. Effective detection of sleep disorders is essential for the treatment of sleep disorders. Questionnaires and scale assessments are traditional methods of sleep disorder detection, which are subjective, time-consuming and prone to misdiagnosis. To detect sleep disorders quickly and accurately, a Multimodal Attention-Fusion Convolutional Neural Network is proposed in this paper. The network uses electroencephalography, electrooculography, electrocardiography, and electromyography signals to automatically identify healthy and five sleep disorders, namely insomnia, narcolepsy, periodic leg movement, rapid eye movement behaviour disorder and nocturnal frontal lobe epilepsy. First, multiple convolutional neural network branches are used to extract time-invariant features of multimodal signals. Then, a multi-scale attention module based on dilated convolutional networks and a squeeze and excite block is proposed for further extracting features with different scales and fusing feature information. Finally, a prediction module consisting of fully connected layers is used to detect sleep disorders. The accuracy, F1 score, and Kappa coefficient obtained on the Cyclic Alternating Pattern sleep dataset are 99.56%, 99.49% and 0.9942, respectively. Compared to the existing state-of-the-art studies, the method proposed in this paper has higher performance in sleep disorder detection.},
  archive      = {J_APIN},
  author       = {Wang, Weibo and Li, Junwen and Fang, Yu and Zheng, Yongkang and You, Fang},
  doi          = {10.1007/s10489-024-05499-7},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {7086-7098},
  shortjournal = {Appl. Intell.},
  title        = {A multimodal attention-fusion convolutional neural network for automatic detection of sleep disorders},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic spatio-temporal graph convolutional network
for traffic forecasting. <em>APIN</em>, <em>54</em>(11), 7070–7085. (<a
href="https://doi.org/10.1007/s10489-024-05562-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting traffic flow is crucial for Intelligent Traffic Systems (ITS), traffic control, and traffic management systems. Complex spatial and temporal interactions of traffic networks make traffic forecasting tasks challenging. Recently, Graph Convolutional Network (GCN) has attracted researchers’ attention as it can better represent graph-shaped road networks and extract spatial features of traffic. However, traditional GCN has some drawbacks since it uses a static adjacency matrix which is unable to capture the time-varying features of traffic propagation. To overcome this, we represent the traffic road network as a dynamic graph and use a probabilistic spatiotemporal adjacency matrix to identify the time-varying impacts of adjacent roads on target roads in GCN. In addition, to find the similarity among the nonadjacent nodes, we have employed node-specific learning in GCN rather than sharing parameters in traditional GCN. This node-specific learning helps our model to learn detailed characteristics of road networks. For temporal feature extractions, we used a Gated Recurrent Unit (GRU) that captures the local trend of traffic flow and an attention mechanism to capture the global trend of traffic flow. We compared the performance of our model with baseline models using two real-world datasets. Experimental results show that our model is effective in forecasting both short and long-term traffic flow. Source code of our model is available at https://github.com/atkia/PSTGCN},
  archive      = {J_APIN},
  author       = {Karim, Atkia Akila and Nower, Naushin},
  doi          = {10.1007/s10489-024-05562-3},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {7070-7085},
  shortjournal = {Appl. Intell.},
  title        = {Probabilistic spatio-temporal graph convolutional network for traffic forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unveiling hidden factors: Explainable AI for feature
boosting in speech emotion recognition. <em>APIN</em>, <em>54</em>(11),
7046–7069. (<a
href="https://doi.org/10.1007/s10489-024-05536-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER) has gained significant attention due to its several application fields, such as mental health, education, and human-computer interaction. However, the accuracy of SER systems is hindered by high-dimensional feature sets that may contain irrelevant and redundant information. To overcome this challenge, this study proposes an iterative feature boosting approach for SER that emphasizes feature relevance and explainability to enhance machine learning model performance. Our approach involves meticulous feature selection and analysis to build efficient SER systems. In addressing our main problem through model explainability, we employ a feature evaluation loop with Shapley values to iteratively refine feature sets. This process strikes a balance between model performance and transparency, which enables a comprehensive understanding of the model’s predictions. The proposed approach offers several advantages, including the identification and removal of irrelevant and redundant features, leading to a more effective model. Additionally, it promotes explainability, facilitating comprehension of the model’s predictions and the identification of crucial features for emotion determination. The effectiveness of the proposed method is validated on the SER benchmarks Toronto emotional speech set (TESS), Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion (SAVEE) dataset, outperforming state-of-the-art methods. These results highlight the potential of the proposed technique in developing accurate and explainable SER systems. To the best of our knowledge, this is the first work to incorporate model explainability into an SER framework. The source code of this paper is publicly available via this https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition .},
  archive      = {J_APIN},
  author       = {Nfissi, Alaa and Bouachir, Wassim and Bouguila, Nizar and Mishara, Brian},
  doi          = {10.1007/s10489-024-05536-5},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {7046-7069},
  shortjournal = {Appl. Intell.},
  title        = {Unveiling hidden factors: Explainable AI for feature boosting in speech emotion recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applied artificial intelligence framework for smart
evacuation in industrial disasters. <em>APIN</em>, <em>54</em>(11),
7030–7045. (<a
href="https://doi.org/10.1007/s10489-024-05550-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human evacuation is a critical process during disasters, whether arising from natural events, intentional acts of aggression, or other calamities. The incorporation of diverse computational approaches such as the Internet of Things (IoT) technology and Edge-empowered Cloud platforms has the capability to improve the effectiveness of route recommendation procedures significantly. Conspicuously, this research (i) proposes a sophisticated evacuation framework that integrates the IoT-Edge-Cloud (IEC) computing platform for human evacuation during a disaster; (ii) employs an Artificial Intelligence-based Support Vector Machine (SVM) to detect emergencies in real-time; (iii) facilitates the cloud-based evacuation by computing a safe and swift route using the proposed Markov Decision process. A simulated environment comprising 120,002 data segments is utilized to evaluate the proposed framework. Compared to existing state-of-the-art techniques, improvements in terms of Overall Temporal Delay (37.80 seconds), Energy Efficiency (0.13% per minute), Event Determination Analysis (Accuracy (94.32%)), Route Recommendation Performance (Precision (96.26%), Sensitivity (90.86%), Coverage (96.66%), and Specificity (93.00%)), and Reliability (94.46%) are registered.},
  archive      = {J_APIN},
  author       = {Alqahtani, Abdullah and Alsubai, Shtwai and Bhatia, Munish},
  doi          = {10.1007/s10489-024-05550-7},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {7030-7045},
  shortjournal = {Appl. Intell.},
  title        = {Applied artificial intelligence framework for smart evacuation in industrial disasters},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subgraph representation learning with self-attention and
free adversarial training. <em>APIN</em>, <em>54</em>(11), 7012–7029.
(<a href="https://doi.org/10.1007/s10489-024-05542-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its capacity to capture subgraph information within graph data, subgraph representation learning has garnered considerable attention in recent years. However, current subgraph representation learning methods neglect the relational information among the subgraphs and noise interference from the subgraph nodes. To address these issues, this paper proposes a method of subgraph representation learning with self-attention and free adversarial training (SGSFA). Specifically, this method employs a self-attention mechanism to calculate the similarity among the subgraphs and then captures the relational information among the subgraphs based on this similarity. Additionally, this method utilizes an improved free adversarial training approach to generate iterative perturbations. These iterative perturbations can eliminate the noise that hampers subgraph representation. Simultaneously, an iterative perturbation is applied to the subgraph nodes to enhance the subgraph’s node features. Extensive results on four real-world subgraph datasets demonstrate that the proposed method outperforms state-of-the-art baselines. The source code of SGSFA is publicly available at https://github.com/denggaoqin/SGSFA .},
  archive      = {J_APIN},
  author       = {Qin, Denggao and Tang, Xianghong and Lu, Jianguang},
  doi          = {10.1007/s10489-024-05542-7},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {7012-7029},
  shortjournal = {Appl. Intell.},
  title        = {Subgraph representation learning with self-attention and free adversarial training},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Noise cleaning for nonuniform ordinal labels based on
inter-class distance. <em>APIN</em>, <em>54</em>(11), 6997–7011. (<a
href="https://doi.org/10.1007/s10489-024-05551-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise poses a significant challenge to supervised learning algorithms. Extensive research has been conducted on classification and regression tasks, but label noise filtering methods specifically designed for ordinal regression are lacking. In this paper, we propose a set of ordinal label noise filtering frameworks by theoretically exploring the generalization error bound in noisy environments. Besides, we present a robust label noise estimation method voted by inter-class distance. It takes into account the nonuniformity of ordinal labels and the reliability of the base model. This estimator is integrated into our framework in the proposed Inter-Class Distance-based Filtering (ICDF) algorithm. We empirically demonstrate the effectiveness of ICDF in identifying label noise and achieving improved generalization performance. Our experiments conducted on benchmark and real age estimation datasets show the superiority of ICDF over the existing filters in ordinal label noise cleaning.},
  archive      = {J_APIN},
  author       = {Jiang, Gaoxia and Wang, Fei and Wang, Wenjian},
  doi          = {10.1007/s10489-024-05551-6},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {6997-7011},
  shortjournal = {Appl. Intell.},
  title        = {Noise cleaning for nonuniform ordinal labels based on inter-class distance},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scaled dirichlet-based predictive model for occupancy
estimation in smart buildings. <em>APIN</em>, <em>54</em>(11),
6981–6996. (<a
href="https://doi.org/10.1007/s10489-024-05543-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we introduce a predictive model leveraging the scaled Dirichlet mixture model (SDMM). This data-driven approach offers enhanced accuracy in predictions, especially with a limited training dataset, surpassing traditional point estimation methods. Recent research has highlighted the flexibility of the Dirichlet distribution in modelling multivariate proportional data. Our research extends this by employing a scaled Dirichlet distribution, which incorporates additional parameters, to construct our predictive model. Furthermore, we address the challenge of data imbalance through a novel approach centred on data spread rate, effectively balancing the dataset to optimize model performance. Empirical evaluations demonstrate the model’s efficacy with both synthetic and real datasets, particularly in estimating occupancy in smart buildings.},
  archive      = {J_APIN},
  author       = {Guo, Jiaxun and Amayri, Manar and Fan, Wentao and Bouguila, Nizar},
  doi          = {10.1007/s10489-024-05543-6},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {11},
  pages        = {6981-6996},
  shortjournal = {Appl. Intell.},
  title        = {A scaled dirichlet-based predictive model for occupancy estimation in smart buildings},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A segmentation method based on boundary fracture correction
for froth scale measurement. <em>APIN</em>, <em>54</em>(9), 6959–6980.
(<a href="https://doi.org/10.1007/s10489-024-05552-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the mineral flotation process, the size characteristics of the surface froth significantly influence the production indicators of the flotation process. However, the information within froth images is intricate, with occurrences of froth stacking and bubble adhesion, resulting in indistinct boundary information. Existing methods struggle to accurately and comprehensively segment bubble boundaries. This paper aims to devise a segmentation method that precisely delineates bubble boundaries, enabling the measurement of bubble size characteristics and an assessment of both average bubble size and bubble count status. A cascaded decoding branch incorporating omni-dimensional convolutional point rendering is designed, leveraging the rendering concept to reanalyze and categorize misclassified pixels. This recalibration process enhances segmentation accuracy by addressing these inaccuracies. Experiments were performed using an on-site froth industrial dataset, demonstrating the substantial advantage of the proposed method in segmenting and measuring flotation froth scenes. Specifically, the segmentation accuracy reached 92.86%. Additionally, the measurement errors for the average bubble size and bubble count were only 10.3% and 8.6%, respectively.},
  archive      = {J_APIN},
  author       = {Gan, Yongqi and Liu, Wenzhuo and Gan, Jianwang and Zhang, Guoying},
  doi          = {10.1007/s10489-024-05552-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6959-6980},
  shortjournal = {Appl. Intell.},
  title        = {A segmentation method based on boundary fracture correction for froth scale measurement},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-attention-transformer-based semantic reranking for
large-scale image localization. <em>APIN</em>, <em>54</em>(9),
6946–6958. (<a
href="https://doi.org/10.1007/s10489-024-05539-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large-scale image-based localization (IBL) problem involves matching a query image with a database image to determine the geolocation of the query. A major challenge in this problem stems from significant variations between images captured at the same location, including different viewpoints, illumination conditions, and seasonal changes. To address this issue, we recognize the potential advantages of integrating difficult positive samples into the training process. Consequently, we introduce a novel retrieval-based framework meticulously designed to harness the advantages presented by these difficult positive samples. A pivotal component is the proposed dual-attention-transformer-based semantic reranking module, which leverages semantic segmentation to preserve local feature points. This module, powered by the dual-attention-transformer, extracts nuanced global-to-local information via channel self-attention and window self-attention, thereby facilitating sample augmentation and final reranking. Additionally, we introduce the adaptive triplet loss, a dynamic mechanism incorporating weighted difficult positive samples into supervised information, which strengthens the model’s robustness. We extensively evaluate our framework on various city-level datasets and demonstrate its superiority over state-of-the-art methods. Furthermore, an exhaustive ablation study systematically validates the effectiveness of each individual component, underscoring their contributions to the proposed methodology.},
  archive      = {J_APIN},
  author       = {Xiao, Yilin and Du, Siliang and Chen, Xu and Liu, Mingzhong and Sun, Mingwei},
  doi          = {10.1007/s10489-024-05539-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6946-6958},
  shortjournal = {Appl. Intell.},
  title        = {Dual-attention-transformer-based semantic reranking for large-scale image localization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DermSegNet: Smart IoT model for multi-class dermatological
lesion diagnosis using adaptive segmentation and improved
EfficientNetB3. <em>APIN</em>, <em>54</em>(9), 6930–6945. (<a
href="https://doi.org/10.1007/s10489-024-05520-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subjective visual examination by human dermatologists is associated with inter-observer variability and error. To address this problem, we present a method to accurately diagnose the 23 most common skin conditions, using an adaptive GrabCut approach with the EfficientNetB3 model, for accurate segmentation and classification, respectively. Using a custom loss function, this strategy is combined with data-level preprocessing employing algorithm-level approaches. The unbalanced Dermnet dataset, which includes 19,500 images of skin lesions representing the 23 most common skin conditions, was corrected by downsampling the major classes and enhancing the minor classes. The custom loss function and ADG significantly enhanced model accuracy by accurately segmenting regions of interest in the images, retaining the most relevant diagnostic information. The MSE, PSNR and Jacquard index support the best segmentation result with values 32.94, 70.23, 0.71 respectively. The results demonstrated very high accuracy, with top-5 and top-1 accuracy rates of 95% and 80.02%, respectively. The diagnoses of acne and nail fungi were exceptionally good, with precision rates exceeding 0.80 and 0.856, respectively. Our Dermnet-trained model is the most accurate of all state-of-the-art models published to date.},
  archive      = {J_APIN},
  author       = {Shinde, Rupali Kiran and Hossain, Md.Biddut and Rizvi, Syed Naheel Raza and Imtiaz, Shariar Md and Kwon, Ki-Chul and Kim, Nam},
  doi          = {10.1007/s10489-024-05520-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6930-6945},
  shortjournal = {Appl. Intell.},
  title        = {DermSegNet: Smart IoT model for multi-class dermatological lesion diagnosis using adaptive segmentation and improved EfficientNetB3},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fitting and sharing multi-task learning. <em>APIN</em>,
<em>54</em>(9), 6918–6929. (<a
href="https://doi.org/10.1007/s10489-024-05549-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Task Learning is an effective method for learning cross-task knowledge. However, existing methods cannot fairly treat each task, their public parts are prone to continuously fit new tasks and decrease the performances of previous tasks. In this paper, we propose the Fitting-sharing Multi-Task Learning method to address this problem. In the Fitting step, a group of indicator parameters are trained to extract task-specific features and store them into an in-task template matrix. After all models converge, the indicators and templates are frozen to protect the learned knowledge. In the Sharing step, a group of connector parameters are trained to acquire information from other templates and to reason cross-task knowledge. Since the learning and sharing processes are separate, each model can acquire the learned knowledge from other tasks without affect them, and the imbalanced cross-task knowledge problem can be naturally avoided. Experimental results on public datasets illustrate that the proposed method can insistently improve the performance compared with existing methods.},
  archive      = {J_APIN},
  author       = {Piao, Chengkai and Wei, Jinmao},
  doi          = {10.1007/s10489-024-05549-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6918-6929},
  shortjournal = {Appl. Intell.},
  title        = {Fitting and sharing multi-task learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ensemble algorithm based on adaptive chaotic
quantum-behaved particle swarm optimization with weibull distribution
and hunger games search and its financial application in parameter
identification. <em>APIN</em>, <em>54</em>(9), 6888–6917. (<a
href="https://doi.org/10.1007/s10489-024-05537-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum-behaved Particle Swarm Optimization (QPSO) is a meta-heuristic optimization algorithm, which is widely used in many research fields and practical problems due to its flexibility and low computational cost. However, the existing QPSO algorithms and their variants still have problems such as insufficient search capabilities, lack of adaptivity, and prone to stagnation. This paper proposes a novel ensemble algorithm, ACQPSOW-HGS, based on Quantum-behaved Particle Swarm Optimization (QPSO) and Hunger Games Search (HGS). By combining three improvements and introducing three hybrid strategies, our algorithm has made a comprehensive development, effectively improving the stability and solution accuracy in a large number of test functions and the parameter identification application, which is superior compared with many existing algorithms. First, we design the Weibull distribution random number generation operator, the distance-guided adaptive control technique, and the chaotic update mechanism to deal with the weak randomness, insufficient adaptability, and susceptibility to stagnation of the original QPSO algorithm, respectively. Integrating the above improvements, ACQPSOW is proposed as an improved variant of QPSO. Second, the proposed ensemble algorithm ACQPSOW-HGS is built on ACQPSOW and HGS and combined with specific hybrid strategies to add population diversity and improve search efficiency, including the Selection-Crossover-Mutation mechanism, the elite local search mechanism, and the information exchange mechanism. Finally, the experiments, on 23 benchmark functions and the IEEE CEC 2017 test suite, demonstrate that ACQPSOW-HGS outperforms comparison algorithms in terms of convergence speed and solution accuracy through non-parametric statistical tests. Moreover, ACQPSOW-HGS was applied to the fractional-order hyper-chaotic financial system for parameter identification to illustrate the applicability and robustness in solving real-world problems.},
  archive      = {J_APIN},
  author       = {Ye, Hanqiu and Dong, Jianping},
  doi          = {10.1007/s10489-024-05537-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6888-6917},
  shortjournal = {Appl. Intell.},
  title        = {An ensemble algorithm based on adaptive chaotic quantum-behaved particle swarm optimization with weibull distribution and hunger games search and its financial application in parameter identification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep reinforcement learning hyper-heuristic to solve order
batching problem with mobile robots. <em>APIN</em>, <em>54</em>(9),
6865–6887. (<a
href="https://doi.org/10.1007/s10489-024-05532-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In e-commerce logistics, it is critical to enhance the efficiency of the order-picking system. Motivated by applications of automatic logistics, we consider the mobile robot based order batching problem. In this problem, mobile robots carry shelves to the picking station for order picking and then return them. The objective is to reduce shelf movements while minimizing the number of delayed orders. We introduce a hyper-heuristic method based on deep reinforcement learning to optimize the order batching strategy in the system. The proposed method adaptively selects the order batching strategy, significantly improving the sequential decision-making process in order picking. Through extensive tests, we demonstrate the superiority of the proposed method over several existing heuristic methods in a range of test scenarios. The results show that the proposed method outperforms other existing heuristic methods in a range of test scenarios, offering more stable and effective solutions. This study is a pioneer in the application of deep reinforcement learning to the mobile robot based order batching problem, offering a novel perspective and methodology to overcome the challenges of sequential decision-making optimization in order picking systems.},
  archive      = {J_APIN},
  author       = {Cheng, Bayi and Wang, Lingjun and Tan, Qi and Zhou, Mi},
  doi          = {10.1007/s10489-024-05532-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6865-6887},
  shortjournal = {Appl. Intell.},
  title        = {A deep reinforcement learning hyper-heuristic to solve order batching problem with mobile robots},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Understanding and improving zero-reference deep curve
estimation for low-light image enhancement. <em>APIN</em>,
<em>54</em>(9), 6846–6864. (<a
href="https://doi.org/10.1007/s10489-024-05534-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Reference Deep Curve Estimation (Zero-DCE) pioneers a new idea for Low-Light Image Enhancement (LLIE), which is to formulate LLIE as a task of image-specific curve estimation with a deep network. Despite its success, the underlying mechanisms of Zero-DCE still remain under-explored, which prevents the further development of curve estimation methods for LLIE. In this paper, we take a step further in understanding Zero-DCE and provide an in-depth analysis from the perspective of the curve formula design and the loss function balance. Inspired by our analysis, we make effective modifications to Zero-DCE in terms of the curve formula, the curve estimation network and the loss terms, and propose Zero-Reference Exposure Adjusting Curve Estimation (Zero-EACE). A novel curve formula named EAC, a novel curve estimation network named HGNet, and a novel loss function named HE Loss are proposed. Extensive experimental results show that the proposed Zero-EACE achieves comparable performance to state-of-the-art methods both qualitatively and quantitatively. Moreover, experimental results on multiple exposure images demonstrate the capability of our method to simultaneously tackle over- and under-exposure correction, which expands the practical application scenarios of unsupervised curve estimation-based LLIE methods.},
  archive      = {J_APIN},
  author       = {Wu, Jiahao and Zhan, Dandan and Jin, Zhi},
  doi          = {10.1007/s10489-024-05534-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6846-6864},
  shortjournal = {Appl. Intell.},
  title        = {Understanding and improving zero-reference deep curve estimation for low-light image enhancement},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised sparse subspace clustering with manifold
regularization. <em>APIN</em>, <em>54</em>(9), 6836–6845. (<a
href="https://doi.org/10.1007/s10489-024-05535-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For sparse subspace clustering methods, it is crucial to develop a good representation matrix to capture the data structure. In this paper, we incorporated the label information into sparse representation and proposed a new semi-supervised sparse subspace clustering method, named semi-supervised sparse subspace clustering with manifold regularization (S $$^4$$ CMR). When developing the sparse self-expressive matrix, the S $$^4$$ CMR method utilized the label information to constrain the development of expressiveness coefficients. The local manifold regularization was also integrated to enhance clustering stability and local consistency. By utilizing the Alternating Direction Method of Multipliers (ADMM), the convex optimization problem associated with linear constraints can be easily resolved. The developed similarity matrix can provide strong discriminant information, making it more effective for semi-supervised tasks. The effectiveness of the proposed algorithm is demonstrated through experiments on benchmark data sets, such as motion segmentation and image clustering.},
  archive      = {J_APIN},
  author       = {Xing, Zhiwei and Peng, Jigen and He, Xingshi and Tian, Mengnan},
  doi          = {10.1007/s10489-024-05535-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6836-6845},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised sparse subspace clustering with manifold regularization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). FLCP: Federated learning framework with
communication-efficient and privacy-preserving. <em>APIN</em>,
<em>54</em>(9), 6816–6835. (<a
href="https://doi.org/10.1007/s10489-024-05521-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the federated learning (FL) framework, the client collaboratively trains the model in coordination with a central server, while the training data can be kept locally on the client. Thus, the FL framework mitigates the privacy disclosure and costs related to conventional centralized machine learning. Nevertheless, current surveys indicate that FL still has problems in terms of communication efficiency and privacy risks. In this paper, to solve these problems, we develop an FL framework with communication-efficient and privacy-preserving (FLCP). To realize the FLCP, we design a novel compression algorithm with efficient communication, namely, adaptive weight compression FedAvg (AWC-FedAvg). On the basis of the non-independent and identically distributed (non-IID) and unbalanced data distribution in FL, a specific compression rate is provided for each client, and homomorphic encryption (HE) and differential privacy (DP) are integrated to provide demonstrable privacy protection and maintain the desirability of the model. Therefore, our proposed FLCP smoothly balances communication efficiency and privacy risks, and we prove its security against “honest-but-curious” servers and extreme collusion under the defined threat model. We evaluate the scheme by comparing it with state-of-the-art results on the MNIST and CIFAR-10 datasets. The results show that the FLCP performs better in terms of training efficiency and model accuracy than the baseline method.},
  archive      = {J_APIN},
  author       = {Yang, Wei and Yang, Yuan and Xi, Yingjie and Zhang, Hailong and Xiang, Wei},
  doi          = {10.1007/s10489-024-05521-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6816-6835},
  shortjournal = {Appl. Intell.},
  title        = {FLCP: Federated learning framework with communication-efficient and privacy-preserving},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal transport strategy-based meta-attention network for
fault diagnosis of rotating machinery with zero sample. <em>APIN</em>,
<em>54</em>(9), 6799–6815. (<a
href="https://doi.org/10.1007/s10489-024-05524-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based methods are widely applied to fault diagnostics, which depend on adequate samples. However, fault samples are often limited and even not available in industrial applications. To solve this problem, an optimal transport strategy-based meta-attention network (OTS-MAN) is proposed for the fault diagnosis by exploiting the fault knowledge learned from few source domains to diagnose the target domain with zero sample. Firstly, a new meta-attention network is built to mine discriminative features of each class from the source domain. Then, an optimal transport strategy is designed to align the feature distribution of each category between known fault in the source domain and unknown fault in the target domain. Finally, the similarity scores are obtained to assess the health status of the target domain. The proposed OTS-MAN is trained only with known source domain data and can diagnose unknown faults without previous access to target domain data. The validity of the proposed method is implemented through using two cases. The results indicate that the OTS-MAN has a better fault diagnosis accuracy than existing methods, and its noise immunity is also improved.},
  archive      = {J_APIN},
  author       = {Wu, Ke and Yu, Kaiwei and Chen, Chong and Wu, Jun and Liu, Yan},
  doi          = {10.1007/s10489-024-05524-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {9},
  pages        = {6799-6815},
  shortjournal = {Appl. Intell.},
  title        = {Optimal transport strategy-based meta-attention network for fault diagnosis of rotating machinery with zero sample},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Deep single image deraining using an asymmetric cyclic
generative and adversarial framework. <em>APIN</em>, <em>54</em>(8),
6776–6798. (<a
href="https://doi.org/10.1007/s10489-024-05494-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reality, rain and fog are often present simultaneously, which can greatly reduce the clarity and quality of scene images. However, most unsupervised single image deraining methods primarily concentrate on removing rain streaks and disregard the presence of fog, which often leads to low deraining performance. In addition, these methods generate samples that are too similar and lack diversity, resulting in poor performance when dealing with complex rain scenes. To address the above issues, we propose a novel Asymmetric Cyclic Generative and Adversarial Framework (ACGF) for single image deraining in which the deraining model, which consists of a Rain-fog2Clean (R2C) transformation block and a Clean2Rain-fog (C2R) transformation block, is trained on both synthetic and real rainy images to simultaneously capture both rain streaks and fog features. To better characterize combined rain–fog features in the R2C block, we propose an attention-based rain–fog feature extraction (ARFE) network to exploit the self-similarity of global and local rain–fog information by learning spatial feature correlations. Furthermore, to improve the translational capacity of the C2R block and the diversity of the model on the synthetic rain conversion path, we design a rain–fog feature decoupling and reorganization (RFDR) network by embedding a rainy image degradation model and a mixed discriminator to preserve richer texture details. Extensive experiments on benchmark rain–fog, rain and fog datasets show that our ACGF outperforms state-of-the-art deraining methods.},
  archive      = {J_APIN},
  author       = {Liu, Wei and Zhang, Caiwang and Chen, Cheng and Huang, Xiaoyu and Li, Minghui},
  doi          = {10.1007/s10489-024-05494-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6776-6798},
  shortjournal = {Appl. Intell.},
  title        = {Deep single image deraining using an asymmetric cyclic generative and adversarial framework},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Disentangled causal representation learning for debiasing
recommendation with uniform data. <em>APIN</em>, <em>54</em>(8),
6760–6775. (<a
href="https://doi.org/10.1007/s10489-024-05497-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, learning representations of users and items is a crucial task for predicting user preferences. However, observational data suffer from inherent bias problems. Various confounding factors are present and lead to data biases, which result in incomplete and skewed representations and make it difficult to accurately determine a user’s true preference. Recent studies have utilized unbiased data to alleviate the bias problem, but these methods do not learn about the representations of user interests, which are not affected by confounding factors. To address this gap, we propose a general disentangled framework, named DCRL, to learn causal representations for obtaining unbiased recommendations. We first analyze the interaction process in a recommender system based on causal graphs and propose that disentanglement can be achieved through intervening embeddings. DCRL leverages unbiased data as supervision signals to guide the disentanglement process, enabling causal representations to learn unbiased features and eliminate the effects of confounding factors. This approach is a model-agnostic solution because disentanglement is an additional task that can be implemented on basic recommendation models. Extensive experiments conducted on two real-world datasets demonstrate the effectiveness of DCRL in comparison with the state-of-the-art baselines.},
  archive      = {J_APIN},
  author       = {Yang, Xinxin and Li, Xinwei and Liu, Zhen and Wang, Yannan and Lu, Sibo and Liu, Feng},
  doi          = {10.1007/s10489-024-05497-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6760-6775},
  shortjournal = {Appl. Intell.},
  title        = {Disentangled causal representation learning for debiasing recommendation with uniform data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning method for efficient cloud IDS utilizing
combined behavior and flow-based features. <em>APIN</em>,
<em>54</em>(8), 6738–6759. (<a
href="https://doi.org/10.1007/s10489-024-05505-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Intrusion Detection System (IDS) distinguishes the harmful entries from the normal ones in network traffic data and aids in network security. Due to the emergence of new and unknown network-connected devices, a lot of modern systems were penetrated. As a result, it is critical to improve information security and to detect new cyber-attacks exploiting various application protocols such as Hyper Text Transfer Protocol (HTTP) and Domain Name System (DNS). Therefore, this paper introduced an Optimized Bidirectional Convolutional Neural Network and Long-Short term Memory (OBCLSTM) method to detect whether the protocol HTTP and DNS is attacked or not. Initially, the records are fed to data normalization and data encoding. After pre-processing, the vectors are fed to the OBCLSTM model. The Bidirectional Channel Pooling (BiCP) layer is used to learn behavior-based features (which show interactions among hosts based on ports, destinations and behavior) and flow-based features (which identify basic flows, such as IP addresses of source-destination and ports), which improves the accuracy of detecting malicious attacks. In the OBCLSTM model, the best hyper parameter configuration for Convolutional Neural Network (CNN) to learn features is tuned using Enhanced Red Fox Optimization (ERFO). Then, bidirectional long short-term memory (BiLSTM) is used to extract features in the time domain and has the ability to preserve the long-term of the information from historical context, allowing attackers to be detected early before causing widespread damage to networks. Finally, the fully connected layer utilizes these features to classify the network data as attacks (types of attacks) or normal. Tests are conducted on the NSL-KDD99, TUIDS, UNSW-NB15 and BoT-IoT datasets. The proposed OBCLSTM method attains better performance in terms of precision, accuracy, recall, and F-measure.},
  archive      = {J_APIN},
  author       = {T V, Geetha and A J, Deepa and M, Mary Linda},
  doi          = {10.1007/s10489-024-05505-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6738-6759},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning method for efficient cloud IDS utilizing combined behavior and flow-based features},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flexible asymmetric convolutional attention network for
LiDAR semantic. <em>APIN</em>, <em>54</em>(8), 6718–6737. (<a
href="https://doi.org/10.1007/s10489-024-05525-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR semantic segmentation is an essential task in understanding 3D semantic information. Currently, the most efficient approach to LiDAR data segmentation is to project the point cloud into the 2D plane and process it using 2D convolution. The results of this approach are encouraging. However, the elevation angle of LiDAR is larger than the azimuth angle, resulting in the range map being vertically elongated in the 3D space captured per unit pixel area. If a square convolution kernel is used, the extracted features will be distorted. To address these limitations, we propose the flexible asymmetric convolutional attention network (FACANet), built from flexible asymmetric convolution and lightweight decoding modules. In this encoder structure, a meta-kernel accounts for the geometric information in 3D space, which helps encode the input range image features effectively. Moreover, a flexible asymmetric convolutional attention block (FACAB) is proposed to capture elongated features in the range image. To facilitate lightweight decoding, the channel uniform interpolation block (CUIB) uses $$1\times 1$$ convolutions to reduce channels and bilinear interpolation to upsample features at each resolution. Furthermore, the continuous multiscale feature fusion block (CMFB) is proposed to fuse features at different resolutions. Finally, a convolutional spatial propagation network (CSPN)-based segmentation head is introduced to improve the accuracy of the segmentation results. Quantitative and qualitative experiments are conducted on the public datasets SemanticKITTI and SemanticPOSS, and our approach achieves better accuracy than advanced models.},
  archive      = {J_APIN},
  author       = {Gan, Jianwang and Zhang, Guoying and Kou, Kangkang and Xiong, Yijing},
  doi          = {10.1007/s10489-024-05525-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6718-6737},
  shortjournal = {Appl. Intell.},
  title        = {Flexible asymmetric convolutional attention network for LiDAR semantic},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A geometry-aware multi-coordinate transformation fusion
network for optic disc and cup segmentation. <em>APIN</em>,
<em>54</em>(8), 6701–6717. (<a
href="https://doi.org/10.1007/s10489-024-05507-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The determination of potential glaucoma cases often relies on the vertical cup-to-disc ratio, which is directly derived from segmentation results. This study introduces an approach that leverages the geometric attributes of the optic disc (OD) and optic cup (OC) by employing a sector-based segmentation method to generate accurate segmentation results. This technique treats the OD and OC as approximate ellipses, partitioned into sectors. We propose a deep learning architecture named Sector Association and Multi-Coordinate Transformation Fusion (SAMF) network to address the problems that Convolutional Neural Networks struggle to learn long-range features. Meanwhile, our network possesses the capability to reduce the discontinuity of the boundaries of the OD and OC when inputs are images transformed into polar coordinates. The proposed SAMF network mainly consists of a Sector Association Layer and a Multi-Coordinate Transformation Fusion module. The Sector Association Layer models the interrelationships among sectors, especially the first and the last sectors, which are not contiguous in the polar transformed image. While the Multi-Coordinate Transformation Fusion module considers complementary representations in different coordinate systems, and it should be noted that the Multi-Coordinate Transformation Fusion component for various segmentation tasks. We perform experiments on the public datasets of REFUGE, Drishti-GS1 and a private dataset. Experimental results indicate that our SAMF network provides a significant boost to the performance of neural networks. The proposed method exhibits remarkable advancements in glaucoma screening through improved segmentation outcomes. The key code can be accessed at https://github.com/JieGenius/SAMFNetwork .},
  archive      = {J_APIN},
  author       = {Yang, Yajie and Yang, Gang and Wang, Yanni and Liu, Xinyue and Zhao, Jianchun and Ding, Dayong},
  doi          = {10.1007/s10489-024-05507-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6701-6717},
  shortjournal = {Appl. Intell.},
  title        = {A geometry-aware multi-coordinate transformation fusion network for optic disc and cup segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BNN-SAM: Improving generalization of binary object detector
by seeking flat minima. <em>APIN</em>, <em>54</em>(8), 6682–6700. (<a
href="https://doi.org/10.1007/s10489-024-05512-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary Neural Network (BNN) exhibits substantial potential for low-cost and energy-efficient deployment, notably in the application of BNN-facilitated object detection on embedded devices. Despite its high compression ratio, the optimization of BNN encounters a significant challenge due to the discrete nature of binary weights and activations. Achieving good generalization performance poses a notable obstacle in this regard. Previous BNN training schemes that only focus on minimizing the empirical loss can easily suffer from overfitting problem, yielding poor generalization capacity when being exposed to unseen data. Sharpness-Aware Minimization (SAM), which simultaneously minimizes the loss value and sharpness of the loss landscape, has emerged as an effective approach for enhancing the generalization ability of neural networks, and has been demonstrated to be effective in improving the performance of BNNs designed for classification tasks. However, their work does not address the optimization challenge of applying SAM to models that handle multiple tasks, such as binary object detection, which involves both classification and location tasks. To address this issue, we propose a modified SAM scheme, denoted as BNN-SAM, which introduces a new objective allowing for the direct calculation of the optimal update vector. Moreover, the proposed scheme fosters multi-task optimization by establishing a common global flat minima for all the concerned tasks. This attribute renders it particularly fitting for scenarios such as object detection, inherently necessitating the joint optimization of both classification and localization. Comprehensive experiments on the PASCAL VOC and MS COCO datasets have shown that BNN-SAM can easily improve the performance of a baseline binary SSD300 detector to outperform state-of-the-art binary detectors, including BiDet, AutoBiDet and LWS-Det, by 6.5%, 5.0%, 1.1%, respectively, without the need of extra optimization approaches. Code is available at https://github.com/Anonymous2740/BNN-SAM.},
  archive      = {J_APIN},
  author       = {Pu, Han and Zhang, Dezheng and Xu, Ke and Mo, RuChan and Yan, ZhiHong and Wang, Dong},
  doi          = {10.1007/s10489-024-05512-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6682-6700},
  shortjournal = {Appl. Intell.},
  title        = {BNN-SAM: Improving generalization of binary object detector by seeking flat minima},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning using granularity statistical invariants for
classification. <em>APIN</em>, <em>54</em>(8), 6667–6681. (<a
href="https://doi.org/10.1007/s10489-024-05506-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning using statistical invariants (LUSI) is a new learning paradigm, which adopts weak convergence mechanism, and can be applied to a wider range of classification problems. However, the computation cost of invariant matrices in LUSI is high for large-scale datasets during training. To settle this issue, this paper introduces a granularity statistical invariant for LUSI, and develops a new learning paradigm called learning using granularity statistical invariants (LUGSI). LUGSI employs both strong and weak convergence mechanisms, taking a perspective of minimizing expected risk. As far as we know, it is the first time to construct granularity statistical invariants. Compared to LUSI, the introduction of this new statistical invariant brings two advantages. Firstly, it enhances the structural information of the data. Secondly, LUGSI transforms a large invariant matrix into a smaller one by maximizing the distance between classes, achieving feasibility for large-scale datasets classification problems and significantly enhancing the training speed of model operations. Experimental results indicate that LUGSI not only exhibits improved generalization capabilities but also demonstrates faster training speed, particularly for large-scale datasets.},
  archive      = {J_APIN},
  author       = {Zhu, Ting-Ting and Li, Chun-Na and Liu, Tian and Shao, Yuan-Hai},
  doi          = {10.1007/s10489-024-05506-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6667-6681},
  shortjournal = {Appl. Intell.},
  title        = {Learning using granularity statistical invariants for classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relationship constraint deep metric learning. <em>APIN</em>,
<em>54</em>(8), 6654–6666. (<a
href="https://doi.org/10.1007/s10489-024-05425-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep metric learning (DML) models aim to learn semantically meaningful representations in which similar samples are pulled together and dissimilar samples are pushed apart. However, the classification effect is limited due to the high time complexity of previous models and their poor performance in extracting data relationships. This paper presents a novel relationship constraint deep metric learning (RCDML) approach, including proxy relationship constraint (PRC) and sample relationship constraint (SRC) for inter-class separability and intra-class compactness, to solve the above problems and improve the classification effect. The PRC combines the proxy-to-proxy relationship loss term with the proxy-to-sample relationship loss function to maximize the proxy features, hence enhancing inter-class separability by decreasing proxy similarity. Additionally, the SRC combines the sample-to-sample relationship loss term with the proxy-to-sample relationship loss function to maximize the sample features, which promotes intra-class compactness by increasing the similarity between the most different samples of the same class. Unlike existing proxy-based and pair-based methods, the relationship constraint framework uses a diverse range of proxy and sample data relationships. In addition, the proxy correction (PC) module is used to optimize the proxy. Extensive tests conducted on the widely popular CUB-200-2011, CARS-196, and SOP datasets show that the framework is effective and attains state-of-the-art performance.},
  archive      = {J_APIN},
  author       = {Zhang, Yanbing and Xiao, Ting and Wang, Zhe and Wang, Xinru and Feng, Wenyi and Fu, Zhiling and Yang, Hai},
  doi          = {10.1007/s10489-024-05425-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6654-6666},
  shortjournal = {Appl. Intell.},
  title        = {Relationship constraint deep metric learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analyzing the robustness of decentralized horizontal and
vertical federated learning architectures in a non-IID scenario.
<em>APIN</em>, <em>54</em>(8), 6637–6653. (<a
href="https://doi.org/10.1007/s10489-024-05510-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables participants to collaboratively train machine and deep learning models while safeguarding data privacy. However, the FL paradigm still has drawbacks that affect its trustworthiness, as malicious participants could launch adversarial attacks against the training process. Previous research has examined the robustness of horizontal FL scenarios under various attacks. However, there is a lack of research evaluating the robustness of decentralized vertical FL and comparing it with horizontal FL architectures affected by adversarial attacks. Therefore, this study proposes three decentralized FL architectures: HoriChain, VertiChain, and VertiComb. These architectures feature different neural networks and training protocols suitable for horizontal and vertical scenarios. Subsequently, a decentralized, privacy-preserving, and federated use case with non-IID data to classify handwritten digits is deployed to assess the performance of the three architectures. Finally, a series of experiments computes and compares the robustness of the proposed architectures when they are affected by different data poisoning methods, including image watermarks and gradient poisoning adversarial attacks. The experiments demonstrate that while specific configurations of both attacks can undermine the classification performance of the architectures, HoriChain is the most robust one.},
  archive      = {J_APIN},
  author       = {Sánchez Sánchez, Pedro Miguel and Huertas Celdrán, Alberto and Martínez Pérez, Enrique Tomás and Demeter, Daniel and Bovet, Gérôme and Martínez Pérez, Gregorio and Stiller, Burkhard},
  doi          = {10.1007/s10489-024-05510-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6637-6653},
  shortjournal = {Appl. Intell.},
  title        = {Analyzing the robustness of decentralized horizontal and vertical federated learning architectures in a non-IID scenario},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image classification based on tensor network DenseNet model.
<em>APIN</em>, <em>54</em>(8), 6624–6636. (<a
href="https://doi.org/10.1007/s10489-024-05472-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification, the primary domain where deep neural networks significantly contribute to image analysis, requires a substantial amount of computer memory to train. This is particularly true in the fully connected layer, which accounts for 90% of the total memory. Moreover, the flattening operation could potentially result in the loss of the multi-linear structure of the image data. The tensor regression network, however, minimally impacts the performance of the neural network while achieving a high compression rate. This effectively mitigates the issue of large memory occupation in the neural network model. The DenseNet model, in particular, can alleviate the vanishing-gradient problem and strengthen feature propagation and outperform other existing networks. This article proposes a novel tensor network model that embeds the tensor regression layer into the DenseNet model. The framework of this tensor DenseNet model has been established, and its estimation procedure is developed. Tensor network model is applied to the classification of the following datasets: Fruits 360, 100 Sports Image, ASL Alphabet, and Mini-ImageNet. The experimental results indicate that the combination of the DenseNet model with the tensor regression layer not only conserves a significant amount of memory but also maintains a high accuracy of classification, compared with existing tensor network models.},
  archive      = {J_APIN},
  author       = {Zhu, Chunyang and Wang, Lei and Zhao, Weihua and Lian, Heng},
  doi          = {10.1007/s10489-024-05472-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6624-6636},
  shortjournal = {Appl. Intell.},
  title        = {Image classification based on tensor network DenseNet model},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DDTCN: Decomposed dimension time-domain convolutional neural
network along spatial dimensions for multiple long-term series
forecasting. <em>APIN</em>, <em>54</em>(8), 6606–6623. (<a
href="https://doi.org/10.1007/s10489-024-05526-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series analysis is widely applied in action recognition, anomaly detection, and weather forecasting. Time series forecasting remains a key challenge due to the complexity of temporal patterns, overlapping changes within sequences, and the need for advanced predictive models to forecast longer sequences in many scenarios. In this study, a model named the decomposed dimension time-domain convolutional neural network (DDTCN) is proposed. This model is specifically designed to address the challenges associated with long time series data. This paper presents a dimension temporal convolutional network (DTCN) module, which has a strong ability to capture variable correlations, and an adaptive strategy is introduced. Specifically, the model proposed in this paper first decomposes time series trends and is combined with the DTCN to extract variable correlations, thus achieving accurate predictions for complex time series and providing a powerful solution for long-term series forecasting. Experiments are conducted on multiple long-term series datasets covering five practical applications: energy, transportation, economics, weather, and health care . The proposed model is extensively evaluated and compared with traditional time series prediction methods and several benchmarks. The experimental results demonstrate that the proposed model outperforms state-of-the-art methods in most tasks involving multiple long-term series forecasting. Additionally, a pig price dataset is generated to predict agricultural economic trends, where compared to that of state-of-the-art methods, the DDTCN achieves a reduction in prediction error of 25.36%. Hence, this model holds promising prospects for wide-ranging applications.},
  archive      = {J_APIN},
  author       = {Zheng, Kaihong and Wang, Jinfeng and Chen, Yunqiang and Jiang, Rongjin and Wang, Wenzhong},
  doi          = {10.1007/s10489-024-05526-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6606-6623},
  shortjournal = {Appl. Intell.},
  title        = {DDTCN: Decomposed dimension time-domain convolutional neural network along spatial dimensions for multiple long-term series forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A conditioned feature reconstruction network for few-shot
classification. <em>APIN</em>, <em>54</em>(8), 6592–6605. (<a
href="https://doi.org/10.1007/s10489-024-05516-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot classification is one of the most daunting challenges in deep learning. The complexities of this task arise from the fact that category targets are often embedded within intricate and diverse background pixels, resulting in inconspicuous category features. Moreover, obtaining common category characteristics from a limited number of samples is difficult. Compounding the issue, models encounters categories that they have never seen before, rendering the prior guarantee of interclass variance infeasible. To address these dilemmas, this paper leverages the apriori conditioned information of few-shot tasks and introduces a Conditioned Feature Reconstruction Network (CFRN). The CFRN employs prototype reconstruction to minimize the prototype similarity among different classes and query reconstruction to maximize the similarity of (query, prototype) feature pairs. This approach increases the interclass variance while decreasing the intraclass variance, thereby enhancing separability and improving the saliency of the target features. An experimental validation demonstrates the effectiveness of the CFRN, which obtains state-of-the-art results on the mini-ImageNet, tiered-ImageNet, and CUB datasets.},
  archive      = {J_APIN},
  author       = {Song, Bin and Zhu, Hong and Bi, Yuandong},
  doi          = {10.1007/s10489-024-05516-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6592-6605},
  shortjournal = {Appl. Intell.},
  title        = {A conditioned feature reconstruction network for few-shot classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gesture recognition with a 2D low-resolution embedded camera
to minimise intrusion in robot-led training of children with autism
spectrum disorder. <em>APIN</em>, <em>54</em>(8), 6579–6591. (<a
href="https://doi.org/10.1007/s10489-024-05477-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growing evidence shows the potential benefits of robot-assisted therapy for children with Autism Spectrum Disorder (ASD). However, when developing new robotics technologies, it must be considered that this condition often causes increased anxiety in unfamiliar settings. Indeed, children with ASD have difficulties accepting changes like introducing multiple new technological devices in their routines, therefore, embedded solutions should be preferred. Also, in this context, robots should be small as children find the bigger ones scary. This leads to limited computing resources onboard as small batteries power them. This article presents a study on gesture recognition using video recorded only by the camera embedded in a NAO robot, while it was leading a clinical procedure. The video is 2D and low quality because of the limits of the NAO-embedded computing resources. The recognition is made more challenging by robot movements, which alter the vision by moving the camera and sometimes by obstructing it with the robot’s arms for short periods. Despite these challenging real-world conditions, in our experiments, we have tuned and improved state-of-the-art algorithms to yield an accuracy higher than $$90\%$$ in the gesture classification, with the best accuracy being $$94\%$$ . This level of accuracy is suitable for evaluating the children’s performance and providing information for the diagnosis and continuous assessment of the therapy. We have also considered the performance improvement of using a low-power GPU-AI accelerator embedded system, which could be included in future robots, to enable gesture analysis during the therapy, which could be adapted to the child’s performance.},
  archive      = {J_APIN},
  author       = {Ercolano, Giovanni and Rossi, Silvia and Conti, Daniela and Di Nuovo, Alessandro},
  doi          = {10.1007/s10489-024-05477-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6579-6591},
  shortjournal = {Appl. Intell.},
  title        = {Gesture recognition with a 2D low-resolution embedded camera to minimise intrusion in robot-led training of children with autism spectrum disorder},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised image-to-image translation with multiscale
attention generative adversarial network. <em>APIN</em>, <em>54</em>(8),
6558–6578. (<a
href="https://doi.org/10.1007/s10489-024-05522-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised image-to-image translation refers to translating images from the source domain to the target domain, assuring that the translated images have the style of the target domain while retaining the content of the source domain. Although existing image-to-image translation methods can map an image from the source domain to the target domain, the translation results are prone to visual artifacts, and the texture and shape of the input image cannot match the target domain well. The reason for this phenomenon is that the generator ignores the most differential information between the source and target domains, preventing the extraction of the rich image feature information. In this paper, we propose a multiscale attention-generative adversarial network (MSA-GAN) for unsupervised image-to-image translation. In MSA-GAN, we design a multiscale attention network (MSANet) as the backbone of the generator, which consists of the Res2Net block and convolutional block attention module (CBAM). MSANet can extract global and local features and effectively alleviate the detail missing and blurry problems in image translation. It also focuses on the important image features and improves the ability of the network to extract features from the most distinguishing regions between the source and target domains, which allows it to better translate the texture details and object shape. In addition, to generate high-quality images, we introduce the perceptual loss to constrain high-level feature information. Extensive experimental results show that the proposed MSA-GAN achieves competitive performance in image-to-image translation. Our model outperforms several advanced models on several public benchmark datasets.},
  archive      = {J_APIN},
  author       = {Wang, Fasheng and Zhang, Qing and Zhao, Qianyi and Wang, Mengyin and Sun, Fuming},
  doi          = {10.1007/s10489-024-05522-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6558-6578},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised image-to-image translation with multiscale attention generative adversarial network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TransDiff: Medical image segmentation method based on swin
transformer with diffusion probabilistic model. <em>APIN</em>,
<em>54</em>(8), 6543–6557. (<a
href="https://doi.org/10.1007/s10489-024-05496-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation can provide a reliable basis for clinical analysis and diagnosis. However, this task is challenging due to the low contrast, boundary ambiguity between organs or lesions and surrounding tissues, and noise interference of images. To address this challenge, which is unique to medical images, and further improve the segmentation accuracy and precision, a medical image segmentation model (TransDiff) is proposed from the perspective of improving model robustness and enriching semantic information. TransDiff comprises three parts: a variational autoencoder (VAE), a diffusion transformer model and a Swin Transformer. The VAE constructs a latent space to provide an environment for fully extracting and fusing features. The diffusion model predicts and removes noise by inferring semantics through the propagation of information between nodes. The Swin Transformer enriches discriminative features as a conditional part. TransDiff inherits the robustness to noise and missing data of the diffusion model and the feature enrichment of the Swin Transformer, thus exhibiting a higher understanding of semantic information. It performs well on medical datasets with three different image modalities, outperforms existing medical image segmentation methods in terms of segmentation precision and accuracy, and has good generalizability. The codes and trained models will be publicly available at https://github.com/xiaoxiao1997/TransDiff .},
  archive      = {J_APIN},
  author       = {Liu, Xiaoxiao and Zhao, Yan and Wang, Shigang and Wei, Jian},
  doi          = {10.1007/s10489-024-05496-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6543-6557},
  shortjournal = {Appl. Intell.},
  title        = {TransDiff: Medical image segmentation method based on swin transformer with diffusion probabilistic model},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Mitigating selection bias in counterfactual prediction
through self-supervised domain embedding learning with virtual samples.
<em>APIN</em>, <em>54</em>(8), 6529–6542. (<a
href="https://doi.org/10.1007/s10489-024-05518-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Treatment effect estimation (TEE) is widely adopted in various domains such as machine learning, dvertising and marketing, and medicine. During the TEE, there normally exist selection bias on counterfactual prediction, which results in different distributions of covariates between the treated and control groups. One important challenge in TEE is to mitigate the impact of selection bias, which has attracted a lot of research in recent years. To address this challenge, existing neural network-based methods generally aim to minimize the distribution differences using integral probability metrics. However, minimizing the distribution differences may inadvertently remove outcome-related information during the balancing procedure, which has negative impact on the accuracy of TEE. In this paper, we propose a novel self-supervised learning approach to conduct TEE. Rather than minimizing the distribution differences, we first introduce the concept of virtual samples which have identical covariates as observed samples but with different treatments. In this way, we aim to simulate the scenario where each sample receives both treatment and control. Next, we propose a self-supervised domain embedding learning (SDEL) approach to conduct TEE. In SDEL, we propose to learn both treated and control embeddings for observed and virtual samples, thereby learning the effects of different treatments. To the best of our knowledge, we are the first to introduce the concept of virtual samples and the first to conduct embedding learning in TEE. Building upon SDEL, we propose a feature extraction counterfactual regression network (FE-CFR), in which we propose a feature extraction module (FEM) to estimate the importance of different covariates. Compared with existing TEE methods, our proposed self-supervised learning approach to could improve the accuracy of TEE. Extensive experiments have been conducted on benchmark datasets for TEE, and the results demonstrate that our proposed approach outperforms the compared baseline approaches.},
  archive      = {J_APIN},
  author       = {Zhu, Qianyang and Sun, Heyuan and Yang, Bo},
  doi          = {10.1007/s10489-024-05518-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6529-6542},
  shortjournal = {Appl. Intell.},
  title        = {Mitigating selection bias in counterfactual prediction through self-supervised domain embedding learning with virtual samples},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum mechanics-based deep learning framework considering
near-zero variance data. <em>APIN</em>, <em>54</em>(8), 6515–6528. (<a
href="https://doi.org/10.1007/s10489-024-05465-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of automation technology, big data is collected during operation processes, and among various machine learning analysis techniques using such data, deep neural network (DNN) has high analysis performance. However, most industrial data has low-variance or near-zero variance data from the refined processes in the collected data itself. This reduces deep learning analysis performance, which is affected by data quality. To overcome this, in this study, the weight learning pattern of an applied DNN is modeled as a stochastic differential equation (SDE) based on quantum mechanics. Through the drift and diffuse terms of quantum mechanics, the patterns of the DNN and data are quickly acquired, and the data with near-zero variance is effectively analyzed simultaneously. To demonstrate the superiority of the proposed framework, DNN analysis was performed using data with near-zero variance issues, and it was proved that the proposed framework is effective in processing near-zero variance data compared with other existing algorithms.},
  archive      = {J_APIN},
  author       = {Oh, Eunseo and Lee, Hyunsoo},
  doi          = {10.1007/s10489-024-05465-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6515-6528},
  shortjournal = {Appl. Intell.},
  title        = {Quantum mechanics-based deep learning framework considering near-zero variance data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A survey of explainable knowledge tracing. <em>APIN</em>,
<em>54</em>(8), 6483–6514. (<a
href="https://doi.org/10.1007/s10489-024-05509-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the long-term accumulation of high-quality educational data, artificial intelligence (AI) has shown excellent performance in knowledge tracing (KT). However, due to the lack of interpretability and transparency of some algorithms, this approach will result in reduced stakeholder trust and a decreased acceptance of intelligent decisions. Therefore, algorithms need to achieve high accuracy, and users need to understand the internal operating mechanism and provide reliable explanations for decisions. This paper thoroughly analyzes the interpretability of KT algorithms. First, the concepts and common methods of explainable artificial intelligence (xAI) and knowledge tracing are introduced. Next, explainable knowledge tracing (xKT) models are classified into two categories: transparent models and “black box” models. Then, the interpretable methods used are reviewed from three stages: ante-hoc interpretable methods, post-hoc interpretable methods, and other dimensions. It is worth noting that current evaluation methods for xKT are lacking. Hence, contrast and deletion experiments are conducted to explain the prediction results of the deep knowledge tracing model on the ASSISTment2009 by using three xAI methods. Moreover, this paper offers some insights into evaluation methods from the perspective of educational stakeholders. This paper provides a detailed and comprehensive review of the research on explainable knowledge tracing, aiming to offer some basis and inspiration for researchers interested in the interpretability of knowledge tracing.},
  archive      = {J_APIN},
  author       = {Bai, Yanhong and Zhao, Jiabao and Wei, Tingjiang and Cai, Qing and He, Liang},
  doi          = {10.1007/s10489-024-05509-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6483-6514},
  shortjournal = {Appl. Intell.},
  title        = {A survey of explainable knowledge tracing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple stocks recommendation: A spatio-temporal hypergraph
learning approach. <em>APIN</em>, <em>54</em>(8), 6466–6482. (<a
href="https://doi.org/10.1007/s10489-024-05491-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stocks do not exist in isolation in the financial markets, but there are complex relationships among them, which leads to the fluctuations in the stock prices have the properties of synchronism, systematic linkage and conductivity. From the relevancy-based perspective, a group of stocks with distinct degrees of correlation constitute the spatial structure of hypergraph, which combines with temporal information together to provide the important basis for the analysis of financial market behaviors. However, how to effectively learn the intrinsic relevancies of stocks is still an open problem. In this article, we proposed the Multiple Stock Recommendation system based on a novel Spatio-Temporal Hypergraph Learning framework (MSR-STHL). Firstly, inspired by the existing works, LSTM-attention module is applied to learn the temporal features of stocks, where Hawkes process is involved to enhance the attention mechanism in the long-term time scale. Secondly, by means of the prior knowledge and data-driven methods, the relevancy-based spatial structures among stocks are modeled from several aspects, where data-driven way can provide the potential relations among stocks and make up the disadvantage of untimely change of prior knowledge. Thirdly, graph attention networks and hypergraph convolution operations are used to achieve the fusion learning of multiple graphs/hypergraphs. Finally, the recommended stocks on the return prediction are provided. The proposed model is evaluated on three stock market datasets, i.e. NASDAQ, NYSE, and China A-share, respectively. In comparison with state-of-the-art methods, the proposed model can outperform the existing methods and the validity is confirmed.},
  archive      = {J_APIN},
  author       = {Xin, Kong and Chao, Luo and Baozhong, Gao},
  doi          = {10.1007/s10489-024-05491-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6466-6482},
  shortjournal = {Appl. Intell.},
  title        = {Multiple stocks recommendation: A spatio-temporal hypergraph learning approach},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Importance and challenges of handwriting recognition with
the implementation of machine learning techniques: A survey.
<em>APIN</em>, <em>54</em>(8), 6444–6465. (<a
href="https://doi.org/10.1007/s10489-024-05487-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ancient manuscripts store historical, literary, cultural, and geographical information. Therefore, the automatic analysis of manuscripts is of great interest in heritage culture and history preservation. Different approaches to handwriting recognition using images have been applied to analyze manuscripts. However, reliable handwriting recognition is a considerable challenge due to different factors related to the writer, the design, the script, the manuscript, and the economy. This paper presents the most relevant works in handwriting recognition using machine learning techniques. The contributions are: i) provide a review of previous research addressing handwriting recognition, ii) depict the general methodology using machine learning in handwriting recognition, iii) highlight relevant works at different levels of analysis (character, word, text line, and text block), iv) present handwriting datasets including the type of content they have, script and language, and v) present the importance and challenges in handwriting recognition. We are confident that the insights and reflections from this review will have a positive impact on the gaps for future research in handwriting recognition.},
  archive      = {J_APIN},
  author       = {Sánchez-DelaCruz, Eddy and Loeza-Mejía, Cecilia-Irene},
  doi          = {10.1007/s10489-024-05487-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6444-6465},
  shortjournal = {Appl. Intell.},
  title        = {Importance and challenges of handwriting recognition with the implementation of machine learning techniques: A survey},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implicit relational attention network for few-shot knowledge
graph completion. <em>APIN</em>, <em>54</em>(8), 6433–6443. (<a
href="https://doi.org/10.1007/s10489-024-05511-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs can not contain all the knowledge during the construction process, so needs to be completed to enhance its integrity. In real knowledge graphs, different relationships often show apparent long-tail distributions, i.e., many relationships have only a small number of entity pairs. Therefore, it is an urgent need to study few-shot knowledge graph completion. Existing methods generally complete the knowledge graph by learning representations of entities and relationships, but ignore the impact of the similarity of neighbor relations between triple entity pairs on completion. In this paper, we propose an implicit relational attention network to address this limitation. First, we propose a heterogeneous entity and relational encoder to mine one-hop neighbor information and enhance entity and relational representations through attention mechanism and convolution. Next, we propose an implicit relationship aware encoder to mine the neighbor relationship similarity information of triple entity pairs and obtain the triple dynamic relationship representation. Then we propose an adaptive relationship fusion network, which fuses the triple dynamic relationship representation and the original information of the neighbor relationship similarity of entity pairs, enhances the relationship representation of the query set to the reference set, so as to improve the accuracy of the few-shot knowledge graph completion. On two benchmark datasets, by comparing with well-known completion methods, the experimental results show that the proposed method achieves very competitive performance.},
  archive      = {J_APIN},
  author       = {Yang, Xu-Hua and Li, Qi-Yao and Wei, Dong and Long, Hai-Xia},
  doi          = {10.1007/s10489-024-05511-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6433-6443},
  shortjournal = {Appl. Intell.},
  title        = {Implicit relational attention network for few-shot knowledge graph completion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aspect based sentiment analysis with instruction tuning and
external knowledge enhanced dependency graph. <em>APIN</em>,
<em>54</em>(8), 6415–6432. (<a
href="https://doi.org/10.1007/s10489-024-05492-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Sentiment Analysis (ABSA) is generally defined as a fine-grained task in Natural Language Processing (NLP). Recently, the integration of the Large Language Model (LLM) and Graph Convolutional Network (GCN) has been widely studied to excavate the underlying contextual information and support the sentiment polarity prediction. However, in existing research, the LLM is usually employed directly to generate the contextual feature representation without any specific instructions, which is not suitable for learning the domain language corpus. In addition, the existing works usually fuse the contextual feature and graph feature by GCN simply, and it ignores further specific processing to highlight the sentiment representations before the model’s final outputting. To tackle these two imperfections, this work proposes a novel ABSA model Instruction Tuning-based Graph Convolutional Network (ITGCN) to implement the subtask of predicting sentiment polarities $$^\textrm{R2}$$ , which leverages the instructed LLM to generate the task-oriented contextual representation and the GCN to exploit the external affective knowledge-assisted syntactic features. In the proposed ITGCN, firstly, the inputting sentence is reconstructed with the designed task-specific instructions, which tell the LLM what is the target in the input. Secondly, this work’s dependency graph, before being processed by GCN, is weighted by the affective knowledge extracted from SenticNet. This kind of dependency graph is endowed with affective information, which is closer to the intention of the related study. Finally, to learn more structured knowledge, a bi-layer sentiment representation module is proposed and utilized to enhance the feature representation. To validate the effectiveness of the proposed ITGCN, extensive experiments have been conducted on five public and available datasets. The proposed ITGCN achieves competitive performance and outperforms the selected state-of-the-art baselines, obviously.},
  archive      = {J_APIN},
  author       = {Shi, Xuefeng and Hu, Min and Ren, Fuji and Shi, Piao and Nakagawa, Satoshi},
  doi          = {10.1007/s10489-024-05492-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6415-6432},
  shortjournal = {Appl. Intell.},
  title        = {Aspect based sentiment analysis with instruction tuning and external knowledge enhanced dependency graph},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-based multi agent reinforcement learning for on-ramp
merging in mixed traffic. <em>APIN</em>, <em>54</em>(8), 6400–6414. (<a
href="https://doi.org/10.1007/s10489-024-05478-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Deep Reinforcement Learning (DRL) has significantly impacted the development of autonomous driving technology in the field of intelligent transportation. However, in mixed traffic scenarios involving both human-driven vehicles (HDVs) and connected and autonomous vehicles (CAVs), challenges arise, particularly concerning information sharing and collaborative control among multiple intelligent agents using DRL. To address this issue, we propose a novel framework, namely Spatial-Temporal Deep Reinforcement Learning (ST-DRL), that enables collaborative control among multiple CAVs in mixed traffic scenarios. Initially, the traffic states involving multiple agents are constructed as graph-formatted data, which is then sequential created to represent continuous time intervals. With the data representation, interactive behaviors and dynamic characteristics among multiple intelligent agents are implicitly captured. Subsequently, to better represent the spatial relationships between vehicles, a graph enabling network is utilize to encode the vehicle states, which can contribute to the improvement of information sharing efficiency among multiple intelligent agents. Additionally, a spatial-temporal feature fusion network module is designed, which integrates graph convolutional networks (GCN) and gated recurrent units (GRU). It can effectively fuse independent spatial-temporal features and further enhance collaborative control performance. Through extensive experiments conducted in the SUMO traffic simulator and comparison with baseline methods, it is demonstrated that the ST-DRL framework achieves higher success rates in mixed traffic scenarios and exhibits better trade-offs between safety and efficiency. The analysis of the results indicates that ST-DRL has increased the success rate of the task by $$15.6\%$$ compared to the baseline method, while reducing model training and task completion times by $$26.6\%$$ respectively.},
  archive      = {J_APIN},
  author       = {Xu, Dongwei and Zhang, Biao and Qiu, Qingwei and Li, Haijian and Guo, Haifeng and Wang, Baojie},
  doi          = {10.1007/s10489-024-05478-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6400-6414},
  shortjournal = {Appl. Intell.},
  title        = {Graph-based multi agent reinforcement learning for on-ramp merging in mixed traffic},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A rehearsal framework for computational efficiency in online
continual learning. <em>APIN</em>, <em>54</em>(8), 6383–6399. (<a
href="https://doi.org/10.1007/s10489-024-05493-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of online continual learning, models are expected to adapt to an ever-changing environment. One of the most persistent hurdles in this adaptation is the mitigation of a phenomenon called &quot;Catastrophic Forgetting&quot; (CF). This critical condition occurs when models trained on non-identically distributed data lose performance in previously learned tasks. Rehearsal methods, leveraging the ability to replay older samples, aim to address this challenge by incorporating a buffer of past training samples. However, the absence of known task boundaries complicates the adaptation of current CF mitigation methods. This paper proposes a method attuned to data stream characteristics and online model performance in a resource-constrained environment. The number of training iterations and learning rate emerges as crucial hyperparameters, impacting the efficacy and efficiency of online continual learning. Up to this point, we propose a combination of Experience Replay methodologies, a Drift Detector, and various training convergence policies, specially tailored for scenarios with unknown task boundaries. Experimental results demonstrate the effectiveness of our approach, maintaining or enhancing performance compared to baseline methods, while significantly improving computational efficiency.},
  archive      = {J_APIN},
  author       = {Davalas, Charalampos and Michail, Dimitrios and Diou, Christos and Varlamis, Iraklis and Tserpes, Konstantinos},
  doi          = {10.1007/s10489-024-05493-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6383-6399},
  shortjournal = {Appl. Intell.},
  title        = {A rehearsal framework for computational efficiency in online continual learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generating probabilistic forecasts from arbitrary point
forecasts using a conditional invertible neural network. <em>APIN</em>,
<em>54</em>(8), 6354–6382. (<a
href="https://doi.org/10.1007/s10489-024-05346-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In various applications, probabilistic forecasts are required to quantify the inherent uncertainty associated with the forecast. However, many existing forecasting methods still only generate point forecasts. Although methods exist to generate probabilistic forecasts from these point forecasts, these are often limited to prediction intervals or must be trained together with a specific point forecast. Therefore, the present article proposes a novel approach for generating probabilistic forecasts from arbitrary point forecasts. In order to implement this approach, we apply a conditional Invertible Neural Network (cINN) to learn the underlying distribution of the data and then combine the uncertainty from this distribution with an arbitrary point forecast to generate probabilistic forecasts. We evaluate our approach by generating probabilistic forecasts from multiple point forecasts and comparing these forecasts to six probabilistic benchmarks on four data sets. We show that our approach generally outperforms all benchmarks with regard to CRPS and Winkler scores and generates probabilistic forecasts with the narrowest prediction intervals whilst remaining reasonably calibrated. Furthermore, our approach enables simple point forecasting methods to rank highly in the Global Energy Forecasting Competition 2014.},
  archive      = {J_APIN},
  author       = {Phipps, Kaleb and Heidrich, Benedikt and Turowski, Marian and Wittig, Moritz and Mikut, Ralf and Hagenmeyer, Veit},
  doi          = {10.1007/s10489-024-05346-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6354-6382},
  shortjournal = {Appl. Intell.},
  title        = {Generating probabilistic forecasts from arbitrary point forecasts using a conditional invertible neural network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal operation of reverse osmosis desalination process
with deep reinforcement learning methods. <em>APIN</em>, <em>54</em>(8),
6333–6353. (<a
href="https://doi.org/10.1007/s10489-024-05452-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reverse osmosis (RO) process is a well-established desalination technology, wherein energy-efficient techniques and advanced process control methods significantly reduce production costs. This study proposes an optimal real-time management method to minimize the total daily operation cost of an RO desalination plant, integrating a storage tank system to meet varying daily freshwater demand. Utilizing the dynamic model of the RO process, a cascade structure with two reinforcement learning (RL) agents, namely the deep deterministic policy gradient (DDPG) and deep Q-Network (DQN), is developed to optimize the operation of the RO plant. The DDPG agent, manipulating the high-pressure pump, controls the permeate flow rate to track a reference setpoint value. Simultaneously, the DQN agent selects the optimal setpoint value and communicates it to the DDPG controller to minimize the plant’s operation cost. Monitoring storage tanks, permeate flow rates, and water demand enables the DQN agent to determine the required amount of permeate water, optimizing water quality and energy consumption. Additionally, the DQN agent monitors the storage tank’s water level to prevent overflow or underflow of permeate water. Simulation results demonstrate the effectiveness and practicality of the designed RL agents.},
  archive      = {J_APIN},
  author       = {Golabi, Arash and Erradi, Abdelkarim and Qiblawey, Hazim and Tantawy, Ashraf and Bensaid, Ahmed and Shaban, Khaled},
  doi          = {10.1007/s10489-024-05452-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6333-6353},
  shortjournal = {Appl. Intell.},
  title        = {Optimal operation of reverse osmosis desalination process with deep reinforcement learning methods},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BTD-RF: 3D scene reconstruction using block-term tensor
decomposition. <em>APIN</em>, <em>54</em>(8), 6319–6332. (<a
href="https://doi.org/10.1007/s10489-024-05476-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Neural Radiance Field (NeRF) exhibits excellent performance for view synthesis tasks, but it requires a large amount of memory and model parameters during three-dimensional (3D) scene reconstruction. This paper proposes a block-term tensor decomposition radiance field (BTD-RF), which is a novel approach that achieves significant model compression while preserving reconstruction quality. BTD-RF decomposes high-dimensional radiance fields into low-dimensional tensor blocks, resulting in a value 2.21 times smaller than the baseline method. Decomposing the model into low-dimensional tensor blocks allows substituting the standard multi-head attention of transformers with a lightweight multi-linear attention mechanism, employing element-wise products and sharing parameters. This significantly reduces the model complexity without compromising performance. Extensive evaluations on various datasets demonstrate that BTD-RF achieves superior image reconstruction quality compared to prior methods. Quantitative metrics and qualitative assessments confirm that BTD-RF generates images that are structurally and perceptually close to ground truth, showcasing exceptional performance despite its lightweight design. BTD-RF offers a compelling trade-off between model size and reconstruction quality for three-dimensional (3D) scene reconstruction. Its efficient design makes it suitable for resource-constrained applications while delivering high-fidelity results, paving the way for broader NeRF utilization. The code is available at https://github.com/seonbin-kim/BTDRF},
  archive      = {J_APIN},
  author       = {Kim, Seon Bin and Kim, Sangwon and Ahn, Dasom and Ko, Byoung Chul},
  doi          = {10.1007/s10489-024-05476-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6319-6332},
  shortjournal = {Appl. Intell.},
  title        = {BTD-RF: 3D scene reconstruction using block-term tensor decomposition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale iterative domain adaptation for specific emitter
identification. <em>APIN</em>, <em>54</em>(8), 6299–6318. (<a
href="https://doi.org/10.1007/s10489-024-05484-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific emitter identification (SEI) is a technology that identifies different emitters through their unique characteristics. Research on traditional specific emitter identification systems focuses on general feature extraction. However, its effectiveness significantly decreases when faced with various influencing factors, such as time changes. Existing domain adaptation SEI methods also suffer from limitations such as the single domain scale and the poor performance against unpredictable changing factors. In this paper, we propose a multi-scale iterative domain adaptation (MSIDA) method for SEI based on domain adaptation, targeting the time variation factor specifically. The proposed method collects signals across different domain scales (seconds and days) and uses an improved domain adaptation method to align signals based on their domain characteristics and source properties at different scales, thereby eliminating the influence of the time factor. Given that the impact of certain factors such as time on SEI is unpredictable and irregular, our proposed method continuously tracks the influence of these factors through iterative domain adaptation, thereby improving the model’s generalization ability to these influencing factors. Furthermore, considering the difficulty of labeling data, our proposed flexible loss function can effectively mine the available information from both unlabeled and labeled data. Whether compared with traditional SEI methods or existing domain adaptation SEI methods, experimental results show that our proposed MSIDA method achieved at least a 6% increase in recognition accuracy, which have demonstrated that our proposed method is more robust to temporal variation factors.},
  archive      = {J_APIN},
  author       = {Liu, Jiaxu and Wang, Jiao and Huang, Hao and Li, Jianqing},
  doi          = {10.1007/s10489-024-05484-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6299-6318},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale iterative domain adaptation for specific emitter identification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative learning of supervision and correlation for
generalized zero-shot extreme multi-label learning. <em>APIN</em>,
<em>54</em>(8), 6285–6298. (<a
href="https://doi.org/10.1007/s10489-024-05498-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot extreme multi-label learning (GZXML) aims to predict relevant labels for unknown instances from a set of seen and unseen labels and is widely used in engineering applications. Since the supervisory information of the instances is incomplete in this task, the existing methods classify such instances based on the semantic relationships between the instances and labels. However, the supervisory information of the seen labels is also crucial for achieving high prediction performance. To bridge this gap, we propose collaborative learning of supervision and correlations for GZXML (CLSC-XML). CLSC-XML leverages both the semantic relationships between instances and labels and the supervisory information of the seen labels to enhance the prediction results for unseen labels. Specifically, CLSC-XML extracts discriminative and representational features, which are then fed into classification and correlation modules for collaborative learning. Furthermore, to enrich the incomplete supervised information, we propose the generation of features for unseen labels (GFUL) algorithm. The classifier is trained alternately with the GFUL algorithm. The classifier provides semantic guidance to the GFUL algorithm, and in turn, the GFUL algorithm helps the classification model enrich the supervised information. Experimental results show that CLSC-XML outperforms the state-of-the-art methods and requires less training time.},
  archive      = {J_APIN},
  author       = {Zhao, Fei and Tao, Ran and Wang, Wenhui and Cui, Bo and Xu, Yuting and Ai, Qing},
  doi          = {10.1007/s10489-024-05498-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6285-6298},
  shortjournal = {Appl. Intell.},
  title        = {Collaborative learning of supervision and correlation for generalized zero-shot extreme multi-label learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TAE: Topic-aware encoder for large-scale multi-label text
classification. <em>APIN</em>, <em>54</em>(8), 6269–6284. (<a
href="https://doi.org/10.1007/s10489-024-05485-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks, recurrent neural networks, and transformers have excelled in representation learning for large-scale multi-label text classification. However, there have been very few works that have incorporated topic information in the process of encoding textual sequential semantics, partly because the text’s topic needs to be modeled separately. To address this, we introduce the latent topic-aware encoder (TAE), designed for large-scale multi-label text classification. The TAE features two key components: a latent topic attention module that correlates latent topic vectors with word hidden vectors and a topic-fused channel attention module that processes topic-specific text representations to produce a refined final text representation. Our experiments demonstrate that TAE seamlessly integrates with existing deep models, significantly enhancing their classification accuracy and convergence speed across various datasets.},
  archive      = {J_APIN},
  author       = {Qin, Shaowei and Wu, Hao and Zhou, Lihua and Zhao, Yiji and Zhang, Lei},
  doi          = {10.1007/s10489-024-05485-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6269-6284},
  shortjournal = {Appl. Intell.},
  title        = {TAE: Topic-aware encoder for large-scale multi-label text classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 2M-NER: Contrastive learning for multilingual and multimodal
NER with language and modal fusion. <em>APIN</em>, <em>54</em>(8),
6252–6268. (<a
href="https://doi.org/10.1007/s10489-024-05490-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying entities in sentences into pre-defined types. It plays a crucial role in various research fields, including entity linking, question answering, and online product recommendation. Recent studies have shown that incorporating multilingual and multimodal datasets can enhance the effectiveness of NER. This is due to language transfer learning and the presence of shared implicit features across different modalities. However, the lack of a dataset that combines multilingualism and multimodality has hindered research exploring the combination of these two aspects, as multimodality can help NER in multiple languages simultaneously. In this paper, we aim to address a more challenging task: multilingual and multimodal named entity recognition (MMNER), considering its potential value and influence. Specifically, we construct a large-scale MMNER dataset with four languages (English, French, German and Spanish) and two modalities (text and image). To tackle this challenging MMNER task on the dataset, we introduce a new model called 2M-NER, which aligns the text and image representations using contrastive learning and integrates a multimodal collaboration module to effectively depict the interactions between the two modalities. Extensive experimental results demonstrate that our model achieves the highest F1 score in multilingual and multimodal NER tasks compared to some comparative and representative baselines. Additionally, in a challenging analysis, we discovered that sentence-level alignment interferes a lot with NER models, indicating the higher level of difficulty in our dataset.},
  archive      = {J_APIN},
  author       = {Wang, Dongsheng and Feng, Xiaoqin and Liu, Zeming and Wang, Chuan},
  doi          = {10.1007/s10489-024-05490-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6252-6268},
  shortjournal = {Appl. Intell.},
  title        = {2M-NER: Contrastive learning for multilingual and multimodal NER with language and modal fusion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive controller based on quantum computation and
coherent superposition fuzzy rules network with unknown nonlinearities.
<em>APIN</em>, <em>54</em>(8), 6238–6251. (<a
href="https://doi.org/10.1007/s10489-024-05446-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of control engineering applications, compensating for unknown dynamics and nonlinearities is of paramount importance for shaping closed-loop performance. This paper introduces a novel solution to this challenge: the adaptive controller based on Quantum-Inspired Fuzzy Rules Emulated Network (QFREN). Leveraging its intrinsic learning capacity, QFREN assimilates human knowledge through a series of IF-THEN rules based on quantum computation principles. By defining quantum states for membership functions, the concept of coherent superposition of tracking errors is employed to effectively mitigate the effects of disturbances and nonlinearities. Learning laws are derived to finely calibrate all network and quantum computation parameters, accompanied by a thorough analysis of closed-loop performance to ensure robustness. Experimental validation and comparative assessments substantiate the efficacy of the proposed scheme, showcasing a reduction in tracking error of at least $$20\%$$ compared to recent comparative controllers based on data-driven and quantum-neural network schemes.},
  archive      = {J_APIN},
  author       = {Treesatayapun, Chidentree},
  doi          = {10.1007/s10489-024-05446-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6238-6251},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive controller based on quantum computation and coherent superposition fuzzy rules network with unknown nonlinearities},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved normal wiggly hesitant fuzzy FMEA model and its
application to risk assessment of electric bus systems. <em>APIN</em>,
<em>54</em>(8), 6213–6237. (<a
href="https://doi.org/10.1007/s10489-024-05458-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly dynamic nature of the real-world environment poses significant challenges for electric bus system operations (EBSOs), which are prone to serious accidents due to their complexity and a wide variety of risk factors. The accidents are often the result of ignoring the most serious risk sources because of a lack of comprehensive risk assessments. Therefore, this paper proposes an improved failure mode and effects analysis (FMEA) multicriteria group decision-making model to ensure the reliability and safety of EBSOs. First, an expert group is invited to evaluate the risk failure modes (FMs) of the EBSOs and transform them into a normal wiggly hesitant fuzzy set (NWHFS) form. Because the risk assessment process involves a large number of team members with different backgrounds, the experts are grouped based on scoring function values using the K-medoids clustering technique. Then, the evaluation values of the expert group are integrated using the normal hesitant fuzzy weighted geometric (NWHFWG) aggregation operator to obtain the final aggregation matrix, and the weights of the three criteria of occurrence (O), severity (S) and detection (D) are determined for each FM via the CCSD method. Finally, considering the cross-correlation between factors within the system, the relationships between FMs are analyzed, and their impact and importance are quantified using the gray correlation-based DEMATEL method, followed by the final ranking of the FMs using regret theory and the PROMETHEE II methodology to achieve a rational allocation of resources. The results are analyzed with sensitivity and comparative analyses to illustrate the superiority of the model.},
  archive      = {J_APIN},
  author       = {Zhang, Pei and Zhang, Zhenji and Gong, Daqing},
  doi          = {10.1007/s10489-024-05458-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6213-6237},
  shortjournal = {Appl. Intell.},
  title        = {An improved normal wiggly hesitant fuzzy FMEA model and its application to risk assessment of electric bus systems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustering-based multi-featured self-supervised learning for
human activities and video retrieval. <em>APIN</em>, <em>54</em>(8),
6198–6212. (<a
href="https://doi.org/10.1007/s10489-024-05460-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-centric content-based video retrieval has emerged as a prominent area of research due to its diverse applications. However, this task presents several inherent challenges, including end-to-end image classification and data sampling. Despite the significant progress made by self-supervised learning methods in addressing these challenges, there are still some issues that need to be addressed. Among those, one major concern is the generation of randomly sampled inverse-complementary pairs. The process of generating such pairs requires careful handling to avoid false positives. Moreover, a common assumption that the similarity between video clips is solely temporal neglects the role of other factors, such as motion. To address this issue, a clustering-based multi-featured self-supervised learning model called CMS2L is proposed in this paper. Our model introduces a fundamental improvement by fixing intra-class positive sampling to avoid false labeling during stage training due to looping clusters. Additionally, it employs a second stream with an expanded range of features to achieve a more comprehensive representation of actions. Experimental results on benchmark datasets demonstrate the superiority of our proposed model.},
  archive      = {J_APIN},
  author       = {Javed, Muhammad Hafeez and Yu, Zeng and Rajeh, Taha M. and Rafique, Fahad and Li, Tianrui},
  doi          = {10.1007/s10489-024-05460-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6198-6212},
  shortjournal = {Appl. Intell.},
  title        = {Clustering-based multi-featured self-supervised learning for human activities and video retrieval},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Study regarding the influence of a student’s personality and
an LMS usage profile on learning performance using machine learning
techniques. <em>APIN</em>, <em>54</em>(8), 6175–6197. (<a
href="https://doi.org/10.1007/s10489-024-05483-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic performance (AP) is crucial for lifelong success. Unfortunately, many students fail to meet expected academic benchmarks, leading to altered career paths or university dropouts. This issue is particularly pronounced in the early stages of higher education, highlighting the need for the instructors of these foundational courses to have access to simple yet effective tools for the early identification of students at high risk of academic failure. In this study, we propose a streamlined conceptual model inspired by the Model of Human Behavior (MHB) to which we have incorporated two dimensions: capacity and willingness. These dimensions are assessed through the definition of three variables: Prior Academic Performance (PAP), Personality and Academic Engagement, whose measurements can easily be obtained by the instructors. Furthermore, we outline a Machine Learning (ML) process that higher education instructors can use to create their own tailored models in order to predict AP and identify risk groups with high levels of transparency and interpretability. The application of our approach to a sample of 322 Spanish undergraduates studying two mathematical subjects at a Spanish university demonstrates its potential to detect failure early in the semester with a precision that is comparable with that of more complex models found in literature. Our tailored model identified that capacity was the primary predictor of AP, with a gain-to-baseline improvement of 21%, and the willingness variables increasing this to 27%. This approach is consistent over time. Implications for instructors are discussed and an open prediction and analysis tool is developed.},
  archive      = {J_APIN},
  author       = {Rico-Juan, Juan Ramón and Cachero, Cristina and Macià, Hermenegilda},
  doi          = {10.1007/s10489-024-05483-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6175-6197},
  shortjournal = {Appl. Intell.},
  title        = {Study regarding the influence of a student’s personality and an LMS usage profile on learning performance using machine learning techniques},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatiotemporal smoothing aggregation enhanced multi-scale
residual deep graph convolutional networks for skeleton-based gait
recognition. <em>APIN</em>, <em>54</em>(8), 6154–6174. (<a
href="https://doi.org/10.1007/s10489-024-05422-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition has a variety of development potentials, such as noncontact potential. The preference for skeleton-based recognition arises due to challenges posed by self-occlusion and environmental factors affecting silhouette-based methods. Addressing the discriminative properties of long-term and short-term temporal cues, we propose spatiotemporal smoothing aggregation enhanced multiscale residual deep graph convolutional networks. This paper considers both long and short gait feature time series, enabling the learning of discriminative multiscale representations. In the baseline network, three scale features are sequentially extracted, followed by a reverse process to extract and fuse multiscale features. This method significantly bolsters the ability of graph convolution to effectively model the context knowledge of human poses effectively. This study investigated multiscale gait feature aggregation, which significantly mitigates oversmoothing effects. A spatiotemporal smoothing aggregation module with an embedded attention mechanism is introduced to hierarchically aggregate and enhance multiscale key joint features. This module alleviates oversmoothing in deep graph convolutional networks. The method underwent rigorous testing on the Chinese Academy of Sciences Institute of Automation(CASIA-B) dataset, achieving an average accuracy of 78.2%, ranking as the second highest performing skeletal-based gait recognition model currently available, and attaining rank-1 accuracies of 14.7 and 8.19 on Gait Recognition in the wild (GREW) and Gait3D datasets, respectively.},
  archive      = {J_APIN},
  author       = {Chen, Guanghai and Chen, Xin and Zheng, Chengzhi and Wang, Junshu and Liu, Xinchao and Han, Yuxing},
  doi          = {10.1007/s10489-024-05422-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6154-6174},
  shortjournal = {Appl. Intell.},
  title        = {Spatiotemporal smoothing aggregation enhanced multi-scale residual deep graph convolutional networks for skeleton-based gait recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning spatiotemporal relationships with a unified
framework for video object segmentation. <em>APIN</em>, <em>54</em>(8),
6138–6153. (<a
href="https://doi.org/10.1007/s10489-024-05486-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video object segmentation (VOS) has made significant progress with matching-based methods, but most approaches still show two problems. Firstly, they apply a complicated and redundant two-extractor pipeline to use more reference frames for cues, increasing the models’ parameters and complexity. Secondly, most of these methods neglect the spatial relationships (inside each frame) and do not fully model the temporal relationships (among different frames), i.e., they need adequate modeling of spatial-temporal relationships. In this paper, to address the two problems, we propose a unified transformer-based framework for VOS, a compact and unified single-extractor pipeline with strong spatial and temporal interaction ability. Specifically, to slim the common-used two-extractor pipeline while keeping the model’s effectiveness and flexibility, we design a single dynamic feature extractor with an ingenious dynamic input adapter to encode two significant inputs, i.e., reference sets (historical frames with predicted masks) and query frame (current frame), respectively. Moreover, the relationships among different frames and inside every frame are crucial for this task. We introduce a vision transformer to exploit and model both the temporal and spatial relationships simultaneously. By the cascaded design of the proposed dynamic feature extractor, transformer-based relationship module, and target-enhanced segmentation, our model implements a unified and compact pipeline for VOS. Extensive experiments demonstrate the superiority of our model over state-of-the-art methods on both DAVIS and YouTube-VOS datasets. We also explore potential solutions, such as sequence organizers, to improve the model’s efficiency. On DAVIS17 validation, we achieve $$\sim $$ 50% faster inference speed with only a slight 0.2% ( $$ J \&amp; F$$ ) drop in segmentation quality. Codes are available at https://github.com/sallymmx/TransVOS.git .},
  archive      = {J_APIN},
  author       = {Mei, Jianbiao and Wang, Mengmeng and Yang, Yu and Li, Zizhang and Liu, Yong},
  doi          = {10.1007/s10489-024-05486-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6138-6153},
  shortjournal = {Appl. Intell.},
  title        = {Learning spatiotemporal relationships with a unified framework for video object segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An evolution strategy with tailor-made mutation operator for
colored balanced traveling salesman problem. <em>APIN</em>,
<em>54</em>(8), 6125–6137. (<a
href="https://doi.org/10.1007/s10489-024-05473-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with an $$\mathcal{N}\mathcal{P}$$ -hard problem called the colored balanced traveling salesman problem (CBTSP), which is a variation of colored traveling salesman problem (CTSP) which in turn is a variation of multiple traveling salesman problem. To effectively solve this problem, an approach based on evolution strategy is proposed where mutation operator is designed taking into consideration the characteristics of CBTSP. The results obtained through our approach have been compared with the results of the novel genetic algorithm (NGA) which is the best approach available in the literature. The results show that our approach surpasses the results reported in the literature for majority of the instances in shorter amount of time.},
  archive      = {J_APIN},
  author       = {Majumder, Sebanti and Singh, Alok},
  doi          = {10.1007/s10489-024-05473-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6125-6137},
  shortjournal = {Appl. Intell.},
  title        = {An evolution strategy with tailor-made mutation operator for colored balanced traveling salesman problem},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DePAint: A decentralized safe multi-agent reinforcement
learning algorithm considering peak and average constraints.
<em>APIN</em>, <em>54</em>(8), 6108–6124. (<a
href="https://doi.org/10.1007/s10489-024-05433-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The domain of safe multi-agent reinforcement learning (MARL), despite its potential applications in areas ranging from drone delivery and vehicle automation to the development of zero-energy communities, remains relatively unexplored. The primary challenge involves training agents to learn optimal policies that maximize rewards while adhering to stringent safety constraints, all without the oversight of a central controller. These constraints are critical in a wide array of applications, including collision avoidance in autonomous systems, adherence to traffic and resource management laws in drone delivery, vehicle automation, and ensuring energy efficiency and sustainability in zero-energy communities. Moreover, ensuring the privacy of sensitive information in decentralized settings introduces an additional layer of complexity, necessitating innovative solutions that uphold privacy while achieving the system’s safety and efficiency goals. In this paper, we address the problem of multi-agent policy optimization in a decentralized setting, where agents communicate with their neighbors to maximize the sum of their cumulative rewards while also satisfying each agent’s safety constraints. We consider both peak and average constraints. In this scenario, there is no central controller coordinating the agents and both the rewards and constraints are only known to each agent locally/privately. We formulate the problem as a decentralized constrained multi-agent Markov Decision Problem and propose a momentum-based decentralized policy gradient method, DePAint, to solve it. To the best of our knowledge, this is the first privacy-preserving fully decentralized multi-agent reinforcement learning algorithm that considers both peak and average constraints. We then provide theoretical analysis and empirical evaluation of our algorithm in a number of scenarios and compare its performance to centralized algorithms that consider similar constraints.},
  archive      = {J_APIN},
  author       = {Hassan, Raheeb and Wadith, K.M. Shadman and Rashid, Md. Mamun or and Khan, Md. Mosaddek},
  doi          = {10.1007/s10489-024-05433-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6108-6124},
  shortjournal = {Appl. Intell.},
  title        = {DePAint: A decentralized safe multi-agent reinforcement learning algorithm considering peak and average constraints},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic- and relation-based graph neural network for
knowledge graph completion. <em>APIN</em>, <em>54</em>(8), 6085–6107.
(<a href="https://doi.org/10.1007/s10489-024-05482-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) refines missing entities, relationships, or attributes from a knowledge graph, which is significant for referral systems, biological informatics, and search engines. As an effective KGC approach, a graph neural network (GNN) learns to aggregate information from neighboring nodes by iteratively passing messages between them. However, the semantic and relational information contained in knowledge graphs is rarely used in the existing GNN-based approaches for KGC (i.e., only structure information is used). Hence, a semantic- and relation-based GNN (SR-GNN) model, which combines the semantic similarity information between neighboring entities and the relational features of knowledge graphs, is proposed. First, we develop an entity semantic aggregation module that learns semantic similarity information among neighboring entities connected to the same central entity via an RNN. Second, we propose a relational aggregation module that captures the different semantics among different types of relations through a GRU. This enables the model to better comprehend semantic relationships and be applied to KGC tasks requiring relationship embedding vectors. Extensive studies conducted on the FB15k-237, WN18RR, WN18 and YAGO3-10 datasets reveal that, when compared to 17 baseline models, the SR-GNN exhibits state-of-the-art performance in terms of the MRR and H@n metrics. Significantly, the MRR metric improves by $$10.2 \%$$ on the FB15K-237 dataset and by $$4.2 \%$$ on the WN18RR dataset over those of the rival models.},
  archive      = {J_APIN},
  author       = {Li, Xinlu and Tian, Yujie and Ji, Shengwei},
  doi          = {10.1007/s10489-024-05482-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6085-6107},
  shortjournal = {Appl. Intell.},
  title        = {Semantic- and relation-based graph neural network for knowledge graph completion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). SCATT: Transformer tracking with symmetric cross-attention.
<em>APIN</em>, <em>54</em>(8), 6069–6084. (<a
href="https://doi.org/10.1007/s10489-024-05467-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the popular Siamese network tracker, cross-correlation is based on the similarity to find the exact location of the template in the search region. However, due to cross-correlation primarily focuses on the spatial neighborhoods, so it often falls into local optimum. Additionally, multiple fusions of features results in a degrade of the target position information. To address these issues, we purpose a novel transformer-variant tracker. We make cross-attention play a central role in our tracker, and thus propose a novel symmetric cross-attention that effectively fuses the features of the template and the search region. The symmetric cross-attention only uses the cross-attention mechanism so as to get rid of the cross-correlation operation, which avoids local optimum and captures more global information. We also propose a position information enhancement module preserving more horizontal and vertical position information, which avoids the loss of position information caused by multiple fusions of features and helps the tracker to locate the target more accurately. Our proposed tracker achieves state-of-the-art performance on six benchmarks including GOT-10k, TrackingNet, LaSOT, UAV123, OTB100, and VOT2020, and is able to run at real-time speed.},
  archive      = {J_APIN},
  author       = {Zhang, Jianming and Chen, Wentao and Dai, Jiangxin and Zhang, Jin},
  doi          = {10.1007/s10489-024-05467-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6069-6084},
  shortjournal = {Appl. Intell.},
  title        = {SCATT: Transformer tracking with symmetric cross-attention},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A machine learning approach for package size estimation
using UHF RFID interrogation signature. <em>APIN</em>, <em>54</em>(8),
6053–6068. (<a
href="https://doi.org/10.1007/s10489-024-05412-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new approach for performing package classification and sizing using Radio-Frequency Identification (RFID) systems. This technique is applicable when packages are labeled with or contain multiple RFID-tagged items. During the interrogation of the tags, received signal strength (RSS) statistics and other information, such as the frame count or the reading time, are collected by the reader and used to predict the package type from a set of candidate classes using an Artificial Neural Network (ANN). The primary challenge lies in acquiring sufficient training data for a target scenario to ensure reliable predictions. To address this, a two-phase training process based on transfer learning is adopted. Initially, a base model is developed using synthetic data generated from a detailed RFID simulator, designed to suit diverse scenarios, establish detailed link budgets, and comprehensively simulate the communication protocols. This model is then refined using a small dataset collected experimentally in the actual scenario. This method was validated in a real testbed with four different package types. The base model was trained using 1000 synthetic samples per package type (4000 in total), whereas the refined model was trained with a dataset consisting of only 25 real interrogation traces (samples) per package type (100 in total). The experimental samples were obtained using a software-defined radio unit, the Ettus B210 Universal Software Radio Peripheral (USRP) platform. This experiment achieved an accuracy of over 92%. In summary, this approach introduces a new feature to existing RFID setups, demonstrating potential for advanced package handling and cost optimization in the logistics sector.},
  archive      = {J_APIN},
  author       = {Vales-Alonso, Javier and López-Matencio, Pablo},
  doi          = {10.1007/s10489-024-05412-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6053-6068},
  shortjournal = {Appl. Intell.},
  title        = {A machine learning approach for package size estimation using UHF RFID interrogation signature},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving visual analysis: Training video
obfuscation models without sensitive labels. <em>APIN</em>,
<em>54</em>(8), 6041–6052. (<a
href="https://doi.org/10.1007/s10489-024-05489-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual analysis tasks, including crowd management, often require resource-intensive machine learning models, posing challenges for deployment on edge hardware. Consequently, cloud computing emerges as a prevalent solution. To address privacy concerns associated with offloading video data to remote cloud platforms, we present a novel approach using adversarial training to develop a lightweight obfuscator neural network. Our method focuses on pedestrian detection as an example of visual analysis, allowing the transformation of video frames on the camera itself to retain only essential information for pedestrian detection while preserving privacy. Importantly, the obfuscated data remains compatible with publicly available object detectors, requiring no modifications or significant loss in accuracy. Additionally, our technique overcomes the common limitation of relying on labeled sensitive attributes for privacy preservation. By demonstrating the inability of pedestrian attribute recognition models to detect attributes in obfuscated videos, we validate the efficacy of our privacy protection method. Our results suggest that this scalable approach holds promise for enabling camera usage in video analytics while upholding personal privacy.},
  archive      = {J_APIN},
  author       = {De Coninck, Sander and Wang, Wei-Cheng and Leroux, Sam and Simoens, Pieter},
  doi          = {10.1007/s10489-024-05489-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6041-6052},
  shortjournal = {Appl. Intell.},
  title        = {Privacy-preserving visual analysis: Training video obfuscation models without sensitive labels},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embedding residuals in graph-based solutions: The e-ResSAGE
and e-ResGAT algorithms. A case study in intrusion detection.
<em>APIN</em>, <em>54</em>(8), 6025–6040. (<a
href="https://doi.org/10.1007/s10489-024-05404-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network architectures have been used to address multiple real-world problems with high success. Their extension to graph-structured data started recently to be explored. Graph-neural network (GNN) achieved state-of-the-art performance in multiple problems. In highly imbalanced application domains, such as network intrusion problems, GNN was used to model the network topology. However, in this scenario, the class imbalance problem still affects the performance. Another graph-based solution, the graph attention network (GAT) has also been applied to multiple predictive tasks. Although being a promising avenue, graph-based solutions are still under-explored in imbalanced scenarios. This paper proposes two novel graph-based algorithms, the E-ResSAGE and E-ResGAT algorithms, which build on top of the established GraphSAGE and GAT algorithms, respectively. The key idea is to integrate residual learning into the GNN leveraging the available graph information. Residual connections are added as a strategy to deal with the high class imbalance, aiming at retaining the original information and improving the minority classes’ performance. A case study on intrusion detection is provided. Extensive experiments on four recent intrusion detection datasets show the excellent performance of our proposed approaches, especially when predicting minority classes. We demonstrate that embedding residuals in graph-based algorithms presents a strong advantage when learning under imbalanced domains.},
  archive      = {J_APIN},
  author       = {Chang, Liyan and Branco, Paula},
  doi          = {10.1007/s10489-024-05404-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {6025-6040},
  shortjournal = {Appl. Intell.},
  title        = {Embedding residuals in graph-based solutions: The E-ResSAGE and E-ResGAT algorithms. a case study in intrusion detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Insights into bitcoin and energy nexus. A bitcoin price
prediction in bull and bear markets using a complex meta model and SQL
analytical functions. <em>APIN</em>, <em>54</em>(8), 5996–6024. (<a
href="https://doi.org/10.1007/s10489-024-05474-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptocurrencies are in the center of attention of investors, public authorities and researchers, but the interest has shifted from purely financial aspects regarding the way of trading, lack of regulation and supervision of transactions, volatility, correlation with other assets to aspects related to sustainability taking in account the high energy consumption generated by the mining process and the impact on environmental pollution. Bitcoin was chosen for the research considering the dominance that this financial asset has on the cryptocurrency market and its position as alpha currency.The article focuses on the relationship between Bitcoin transactions and energy consumption, for period 1st January 2019—31st of May 2022, this interval having significant price movements. The authors made a prediction of the Bitcoin price using a complex meta-model and SQL analytical functions. The analysis is based on 15 fundamental variables in order to forecast the price: Bitcoin data (prices and volume), electricity price and traded quantity on day-ahead market (DAM), gas price and traded quantity on DAM, inflation in EU, EU-ETS emissions certificates and oil prices. The study reveals the importance of the relationship Bitcoin—energy—carbon emissions, elements that capture the impact of the mining process on the environment from the perspective of energy consumption. Investors on the Bitcoin market must be aware not only of the importance of financial aspects on the price of cryptocurrencies (inflation, demand, offer), but also of other elements related to the evolution of energy prices (electricity, oil, gas, renewable energy) and the evolution of emissions certificates prices. Considering the promotion of the principles of sustainable development on the capital market, portfolio investors have become increasingly attentive to the social and environmental performance of financial assets. This study aims to make financial market players aware of the non-financial implications of their transactions. In addition, the energy transition and the reconfiguration of the energy mix are elements of impact on the cryptocurrency market through the technical levers involved in the mining process.},
  archive      = {J_APIN},
  author       = {Bâra, Adela and Oprea, Simona-Vasilica and Panait, Mirela},
  doi          = {10.1007/s10489-024-05474-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {5996-6024},
  shortjournal = {Appl. Intell.},
  title        = {Insights into bitcoin and energy nexus. a bitcoin price prediction in bull and bear markets using a complex meta model and SQL analytical functions},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAAC: An effective reinforcement learning algorithm for
sparse reward in automatic control systems. <em>APIN</em>,
<em>54</em>(8), 5976–5995. (<a
href="https://doi.org/10.1007/s10489-024-05464-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, reinforcement learning (RL) is increasingly being employed to optimize automatic control systems. This allows these systems to autonomously learn and improve their operations, enhancing their ability to adapt to changing environments and conditions. However, RL heavily relies on reward signals to guide learning, and in practical tasks, these signals are often sparse. This sparsity hinders the learning procedure as only a small amount of feedback signals are available. Most of the current methods to solve the sparse reward problem need to introduce a lot of hyperparameters, and the sample data utilization is relatively low. To address the issue of sparse rewards in RL-based automatic control systems, we propose the Cosine Attenuation Monte Carlo Augmented Actor-Critic (CAAC) algorithm. CAAC uses a cosine decay function to adjust the Q-value during training, optimizing the effect of final rewards and improving RL algorithm performance in the area of automatic control systems. In addition, we conduct experiments in three simulation environments to validate the proposed approach. The results demonstrate that CAAC outperforms the baseline algorithms in terms of learning speed and obtains 10% to 44.3% higher final reward.},
  archive      = {J_APIN},
  author       = {Liu, Kun and Wu, Libing and Zhang, Zhuangzhuang and Hu, Xinrong and Lu, Na and Wei, Xuejiang},
  doi          = {10.1007/s10489-024-05464-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {5976-5995},
  shortjournal = {Appl. Intell.},
  title        = {CAAC: An effective reinforcement learning algorithm for sparse reward in automatic control systems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Task-related network based on meta-learning for few-shot
knowledge graph completion. <em>APIN</em>, <em>54</em>(8), 5961–5975.
(<a href="https://doi.org/10.1007/s10489-024-05480-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) is a powerful tool in many areas, but it is impossible to take in all knowledge during construction for the complexity of relations among natural entities. In practical terms, many relations within KG have few samples to learn from, so few-shot KG completion matters. Existing approaches generally complete KGs by learning either static representations of entities and relations or the dynamic representations of fixed model parameters, while ignoring the importance of dynamic fine-tuning of model parameters for rapidly mining task-related information. In this paper, we propose a novel task-related network based on meta-learning (MTRN) for few-shot knowledge graph completion. Firstly, a task-related neighbor-aware encoder, which can distinguish the contributions of different neighbors, is designed to mine the task-related information of neighbors from the heterogeneous background graph and to enhance task entity representations. Secondly, a self-attention entity-pair encoder is proposed to generate the representations of references by modeling the interaction of head and tail entities. Then MTRN models references, that is entity pairs in the reference set, through a matching network to differentiate the contributions of different entity pairs to task relations and obtain the task-related representations with fine-grained semantics. When performing different knowledge graph completion tasks, MTRN can extract the features of few-shot references in a meta-learning way to dynamically fine-tune model parameters, making MTRN quickly adapt to diverse tasks in few-shot setting. The evaluation on two public datasets of knowledge graph completion shows that MTRN achieves competitive completion performance under different few-shot sizes.},
  archive      = {J_APIN},
  author       = {Yang, Xu-Hua and Wei, Dong and Zhang, Lian and Ma, Gang-Feng and Xu, Xin-Li and Long, Hai-Xia},
  doi          = {10.1007/s10489-024-05480-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {5961-5975},
  shortjournal = {Appl. Intell.},
  title        = {Task-related network based on meta-learning for few-shot knowledge graph completion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple remote sensing image encryption scheme based on
saliency extraction and magic cube circular motion. <em>APIN</em>,
<em>54</em>(8), 5944–5960. (<a
href="https://doi.org/10.1007/s10489-024-05447-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the salient region security and transmission efficiency of remote sensing images, a multiple remote sensing image (MRSIs) encryption scheme based on saliency extraction and magic cube circular motion is proposed in this paper. The scheme provides two tiers of privacy protection for salient regions (airport locations) in remote sensing images. First, a 4D improved discrete tabu learning neuron (4D-IDTLN) chaotic system is proposed. The analysis of phase diagrams, the Lyapunov exponents (LEs) spectrum and bifurcation diagrams of the system show that the system exhibits rich dynamic behaviors. Second, the salient regions of remote sensing images are classified and extracted via knowledge-oriented saliency (KOS) and vision-oriented saliency (VOS) techniques to create a mask contour positioning model (MCPM) for the salient regions, which is then encrypted. Then, the MRSIs are fused into a cube, which is encrypted using magic cube circular motion and chaotic sequences and further encrypted using closed-loop diffusion. Finally, the security of the proposed encryption scheme is evaluated. The results indicate that the scheme provides higher security and better transmission efficiency for MRSIs.},
  archive      = {J_APIN},
  author       = {Cai, Chang and Wang, Yu and Cao, Yinghong and Sun, Bo and Mou, Jun},
  doi          = {10.1007/s10489-024-05447-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {5944-5960},
  shortjournal = {Appl. Intell.},
  title        = {Multiple remote sensing image encryption scheme based on saliency extraction and magic cube circular motion},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scene text image super-resolution using multi-scale
convolutional neural network with skip connections. <em>APIN</em>,
<em>54</em>(8), 5931–5943. (<a
href="https://doi.org/10.1007/s10489-024-05471-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution is an interesting and challenging task which aims to enhance the spatial resolution of low-resolution text images in the wild, and consequently improve the image visual quality and boost the performance of real-world text-related applications. However, most of previous super-resolution methods ignore the important specific characteristics of text patterns and regard scene text images as natural scene images. In this paper, a novel deep convolutional-based architecture is specifically proposed for the super-resolution of scene text images. In order to recover fine details of low-resolution characters, the proposed architecture has been carefully designed and its main specificities are three-fold: (1) the introduction of multi-scale features extraction by incorporating parallel convolutional layers in order to preserve both local and global high-frequency components that encapsulate the intricate details of characters’ patterns. This strategy allows the proposed method to capture fine nuances in the visual representation of characters, enhancing the richness of extracted features. (2) the integration of skip connections through convolutional layers. This strategic design choice facilitates the seamless flow of information from lower to higher layers of the deep architecture, allowing sequential information about text patterns to be preserved more effectively. (3) the proposition of a specialized network in network-based reconstruction within our architecture to recover high-resolution text details from the collected features. Such a network paradigm minimizes information loss and enhances the proposed method’s ability to discern and reconstruct fine textual details. These design elements collectively empower our super-resolution method to excel in analyzing fine text patterns for effective high-resolution reconstruction, providing a comprehensive solution for the challenging task of recovering fine details in low-resolution characters. Quantitative and qualitative evaluations on four well-known benchmarks, including the SVT, IIIT5k, IC03 and ICDAR2015-TextSR datasets, prove the efficiency of our proposal whose performance surpasses those of different state-of-the-art super-resolution methods.},
  archive      = {J_APIN},
  author       = {Walha, Rim and Aouini, Amal},
  doi          = {10.1007/s10489-024-05471-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {8},
  pages        = {5931-5943},
  shortjournal = {Appl. Intell.},
  title        = {Scene text image super-resolution using multi-scale convolutional neural network with skip connections},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature extraction of multimodal medical image fusion using
novel deep learning and contrast enhancement method. <em>APIN</em>,
<em>54</em>(7), 5907–5930. (<a
href="https://doi.org/10.1007/s10489-024-05431-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of multimodal medical images has garnered painstaking attention for clinical diagnosis and surgical planning. Although various scholars have designed numerous fusion methods, the challenges of extracting substantial features without introducing noise and non-uniform contrast hindered the overall quality of fused photos. This paper presents a multimodal medical image fusion (MMIF) using a novel deep convolutional neural network (D-CNN) along with preprocessing schemes to circumvent the mentioned issues. A non-linear average median filtering (NL-AMF) and multiscale improved top-hat (MI-TH) approach are utilized at the preprocessing stage to remove noise and improve the contrast of images. The non-linear anisotropic diffusion (NL-AD) scheme is employed to split the photos into base and detailed parts. The fusion of base parts is accomplished by a dimension reduction method to retain the energy information. In contrast, the detailed parts are fused by novel D-CNN to preserve the enriched detailed features effectively. The simulation results demonstrate that the proposed method produces better brightness contrast and more image details than existing methods by acquiring 0.7649 to 0.8986, 0.3520 to 0.4783, 0.7639 to 0.9056, 68.8932 to 81.0487 gain for quality transfer ratio from source photo to a generated photo ( $$Q_{G}^{AB}$$ ), feature mutual information (FMI), structural similarity index (SSIM), and average pixel intensity (API) respectively.},
  archive      = {J_APIN},
  author       = {Bhutto, Jameel Ahmed and Guosong, Jiang and Rahman, Ziaur and Ishfaq, Muhammad and Sun, Zhengzheng and Soomro, Toufique Ahmed},
  doi          = {10.1007/s10489-024-05431-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5907-5930},
  shortjournal = {Appl. Intell.},
  title        = {Feature extraction of multimodal medical image fusion using novel deep learning and contrast enhancement method},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MODE: A multimodal open-domain dialogue dataset with
explanation. <em>APIN</em>, <em>54</em>(7), 5891–5906. (<a
href="https://doi.org/10.1007/s10489-024-05479-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for high-quality data has been a key issue hindering the research of dialogue tasks. Recent studies try to build datasets through manual, web crawling and so on. However, man-made data is expensive and data collected from the internet often includes generic responses, meaningless statements even toxic information. With the development of LLM (large language models), generating data through LLM has broad application potential. For open-domain multimodal dialogue tasks, there are still three drawbacks: 1) There is currently a lack of a unified and effective framework for collecting high-quality multimodal dialogue data; 2) The output of LLM in Multimodal dialogue generation lacks scene explanation, affecting human understanding; 3) Previous work has not quantitatively examined the impact of data quality on model performance. To improve data quality and reduce expenditure in the data collection process, we propose the Multimodal Data Construction Framework (MDCF). MDCF utilizes the modal conversion module and designs proper prompts to the LLM to generate well-formed and high-quality content. It also provides explanation for the multimodal dialogue, helping to understand conversation scenarios and facilitate manual subsequent quality inspection. Based on this, we release a Multimodal Open-domain Dialogue dataset with Explanation(MODE). We mainly compared open domain datasets such as Image-Chat. Both human evaluation and experiments show that high-quality datasets enable models to have greater understanding and generation capabilities.},
  archive      = {J_APIN},
  author       = {Yin, Hang and Lu, Pinren and Li, Ziang and Sun, Bin and Li, Kan},
  doi          = {10.1007/s10489-024-05479-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5891-5906},
  shortjournal = {Appl. Intell.},
  title        = {MODE: A multimodal open-domain dialogue dataset with explanation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Detection of advanced persistent threats using hashing and
graph-based learning on streaming data. <em>APIN</em>, <em>54</em>(7),
5879–5890. (<a
href="https://doi.org/10.1007/s10489-024-05475-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many activities in the cybersecurity realm can be represented using graphs stream, such as call graphs. In this paper, we introduce an innovative method to detect Advanced Persistent Threats (APTs) from their onset. Unique to our approach is the ability to assimilate both structural and temporal aspects, crucial for differentiating between benign and malicious activities. To overcome challenges presented by streaming data processing, we leverage hashing techniques for a compact data representation. This method, when combined with a dynamic machine learning framework, facilitates swift, incremental detection and ensures minimal memory usage. Empirical evaluations underscore the efficacy of our approach, allowing a real-time response by pinpointing APTs at the initial stages of their activity},
  archive      = {J_APIN},
  author       = {Megherbi, Walid and Kiouche, Abd Errahmane and Haddad, Mohammed and Seba, Hamida},
  doi          = {10.1007/s10489-024-05475-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5879-5890},
  shortjournal = {Appl. Intell.},
  title        = {Detection of advanced persistent threats using hashing and graph-based learning on streaming data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental and sequence learning algorithms for weighted
regularized extreme learning machines. <em>APIN</em>, <em>54</em>(7),
5859–5878. (<a
href="https://doi.org/10.1007/s10489-024-05470-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of weighted regularized extreme learning machines (WR-ELMs) has been recognized as an effective approach to addressing class imbalance by differentially weighting sample classes. Traditional batch learning methodologies, however, falter due to their inefficiency in adapting to network restructuring and their inability to process streaming data. By introducing incremental and sequential learning, the incremental weighted regularized extreme learning machine (IWR-ELM) and the online weighted regularized extreme learning machine (OWR-ELM) are proposed in this paper to enhance WR-ELM’s flexibility and responsiveness. Specifically, the IWR-ELM facilitates optimal hidden layer node selection, thereby enhancing model adaptability without necessitating full retraining. Conversely, the OWR-ELM is engineered for real-time data stream processing, enabling continuous learning from new data segments without retaining outdated information. We also address the concurrent challenges of concept drift and class imbalance by presenting an enhanced online weighted regularized extreme learning machine, which incorporates enhancement factors to elevate the significance of recent data. Finally, the competitiveness of our proposed algorithm is demonstrated in terms of its training time and performance through extensive experiments conducted on class-imbalanced datasets. Our comprehensive evaluations on diverse class-imbalanced datasets affirm the superior efficiency and performance of our proposed solutions in terms of training speed and accuracy.},
  archive      = {J_APIN},
  author       = {Zhang, Yuao and Dai, Yunwei and Li, Jing},
  doi          = {10.1007/s10489-024-05470-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5859-5878},
  shortjournal = {Appl. Intell.},
  title        = {Incremental and sequence learning algorithms for weighted regularized extreme learning machines},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Forecasting model for the number of breeding sows based on
pig’s months of age transfer and improved flower pollination
algorithm-back propagation neural network. <em>APIN</em>,
<em>54</em>(7), 5826–5858. (<a
href="https://doi.org/10.1007/s10489-024-05413-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regulating the number of breeding sows (NBS) is crucial for pork supply–demand balance. Current forecasting methods for NBS fail to consider the principle of pig’s months of age (MOA) transfer and the impact of factors like diseases and policies on NBS fluctuations, leading to unsatisfactory accuracy. To bridge the research gap, a two-part forecasting model for the NBS was developed. In the first part, a recurrence forecasting model was established according to the growth characteristics of pigs and the principle of pig’s MOA transfer. In the second part, the random disturbance term was introduced to consider the influence of plague, policy and other factors on the NBS, and a forecasting method for random disturbance term based on Improved Flower Pollination Algorithm-Back Propagation Neural Network (IFPA-BPNN) was given. Subsequently, the proposed IFA and other newer optimization algorithms were evaluated on CEC 2017 test suite to verify the effectiveness and superiority of IFA. Lastly, the proposed model was employed to forecast the NBS in Heilongjiang Province and Anhui Province of China from 2009 to 2021. Compared to other time series forecasting models, the proposed model showed superior accuracy, confirming its scientific and effective nature. Relevant managerial insights were provided at the end of this paper.},
  archive      = {J_APIN},
  author       = {Song, Haohao and Zhang, Hongyu and Yang, Jingnan and Wang, Jiquan},
  doi          = {10.1007/s10489-024-05413-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5826-5858},
  shortjournal = {Appl. Intell.},
  title        = {Forecasting model for the number of breeding sows based on pig’s months of age transfer and improved flower pollination algorithm-back propagation neural network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning for prediction of energy consumption: An
applied use case in an office building. <em>APIN</em>, <em>54</em>(7),
5813–5825. (<a
href="https://doi.org/10.1007/s10489-024-05451-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-residential buildings are responsible for more than a third of global energy consumption. Estimating building energy consumption is the first step towards identifying inefficiencies and optimizing energy management policies. This paper presents a study of Deep Learning techniques for time series analysis applied to building energy prediction with real environments. We collected multisource sensor data from an actual office building under normal operating conditions, pre-processed them, and performed a comprehensive evaluation of the accuracy of feed-forward and recurrent neural networks to predict energy consumption. The results show that memory-based architectures (LSTMs) perform better than stateless ones (MLPs) even without data aggregation (CNNs), although the lack of ample usable data in this type of problem avoids making the most of recent techniques such as sequence-to-sequence (Seq2Seq).},
  archive      = {J_APIN},
  author       = {Morcillo-Jimenez, Roberto and Mesa, Jesús and Gómez-Romero, Juan and Vila, M. Amparo and Martin-Bautista, Maria J.},
  doi          = {10.1007/s10489-024-05451-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5813-5825},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning for prediction of energy consumption: An applied use case in an office building},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised dehazing network using multiple scattering
model and fuzzy image prior. <em>APIN</em>, <em>54</em>(7), 5794–5812.
(<a href="https://doi.org/10.1007/s10489-024-05443-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In haze scenes, light is scattered and absorbed thus affecting the acquisition of information. However, existing image enhancement methods have limited capabilities and it is challenging to truly eliminate haze. As a result, their application to advanced vision is seriously hindered. The advantages of a prior based methods and physical models are ignored by existing deep learning-based methods. To address this problem, a novel semi-supervised learning architecture is proposed. Supervised and unsupervised branches are used simultaneously by this semi-supervised defogging network and trained on both labelled and unlabeled datasets. The contribution of this algorithm is the use of atmospheric multiple scattering model in the semi-supervised de-fogging network, which can well solve the blurring and haloing caused by multiple scattering of light. A blurred image prior is proposed for the first time, and the blurring kernel of the fogged image is solved by this prior information, which simplified the application of atmospheric multiple scattering models. In the semi-supervised defogging algorithm, a supervised loss function is used to constrain the supervised branch and an unsupervised loss is used to constrain the unsupervised branch. Some weights in the supervised and unsupervised branches are shared in order for the network model to learn the feature information of both synthetic and real images. The experiment shows that compared with the latest nine algorithms, the proposed method achieves better results on synthetic and real images.},
  archive      = {J_APIN},
  author       = {An, Shunmin and Wang, Linling and Wang, Le},
  doi          = {10.1007/s10489-024-05443-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5794-5812},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised dehazing network using multiple scattering model and fuzzy image prior},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Applying social media in emergency response: An
attention-based bidirectional deep learning system for location
reference recognition in disaster tweets. <em>APIN</em>, <em>54</em>(7),
5768–5793. (<a
href="https://doi.org/10.1007/s10489-024-05462-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms like Twitter have been recognized as a reliable real-time information dissemination and collection medium, especially during disasters when traditional communication media fail. Information access improves situational awareness and is essential for successful disaster management. The response team primarily requires information about the people in danger and the need for and availability of resources, such as food, shelter, and medical supplies. These details can only be actionable with the location information. People’s tweets during disasters will be informal and not adhere to standard linguistic rules, causing traditional NLP methods to fail. This study focuses on location reference recognition, in which the system must identify any locations mentioned in tweets. Most existing solutions focus on rule-based systems and gazetteers, which depend on the completeness of the gazetteers and manually defined rules. Since people’s writing styles differ significantly, manually defining rules will be complex. This paper introduces a neural network architecture based on BiLSTM, CRF, and attention mechanisms. It exploits statistical linguistic properties also. Compared to state-of-the-art methods, the model demonstrated superior results in both in- and cross-domain scenarios on tweet datasets representing diverse disaster types from different regions and times. Empirical results demonstrate that supervised systems can replace gazetteer-based solutions. BiLSTM and CRF, in conjunction with attention mechanism, improve the sequential modelling in informal text. Our system excels in non-English tweets also. The observations have applications in location-based services like tracking news events, traffic management, and event localization.},
  archive      = {J_APIN},
  author       = {Koshy, Rani and Elango, Sivasankar},
  doi          = {10.1007/s10489-024-05462-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5768-5793},
  shortjournal = {Appl. Intell.},
  title        = {Applying social media in emergency response: An attention-based bidirectional deep learning system for location reference recognition in disaster tweets},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Granular computing based segmentation and textural analysis
(GrCSTA) framework for object-based LULC classification of fused remote
sensing images. <em>APIN</em>, <em>54</em>(7), 5748–5767. (<a
href="https://doi.org/10.1007/s10489-024-05469-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning(ML) based techniques for Land Use Land Cover(LULC) classification is crucial for extracting valuable insights from satellite imagery. The impact of severe class imbalance problems on LULC datasets, added to the limited temporal coverage, incomplete spectral information, spatial resolution constraints, and limitations due to sensor characteristics of a single satellite, hinder the efficient capturing of complex image features. The object-based classification using Gray-level co-occurrence matrix(GLCM) and Simple Non-Iterative Clustering(SNIC) captures the textural and spectral information, respectively, to enhance the accuracy in heterogeneous landscapes and overcome the limitations of pixel-based classification, such as the sensitivity towards noise and spectral confusion in mixed pixels at the cost of increased additional computational steps. In this context, the proposed study leverages high-quality fused images with diverse temporal, spectral, and spatial information obtained by fusing Landsat-8 and Sentinel-2 satellite imageries using Spatial-and-Temporal-Adaptive-Reflectance-Fusion-Model(STARFM). Further, to solve the class imbalance problem, a Granular Computing(GrC) based Segmentation and Textural Analysis(GrCSTA) framework is proposed for reducing the number of image primitives and computations required for subsequent image analysis processes in the object-based classification. The GrCSTA framework focuses on extracting the Spatial Granules(Gs) from the fused imagery using Spatial neighborhood Granulation(SNGr), textural indices of the Gs using GLCM, and reduced textural indices using Principal Component Analysis(PCA). Gs and its reduced textural indices are input features to train the Random Forest(RF) classifier. Experimental results demonstrate that the proposed GrCSTA framework achieves comparably higher accuracy than the state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Pinheiro, Greetta and Minz, Sonajharia},
  doi          = {10.1007/s10489-024-05469-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5748-5767},
  shortjournal = {Appl. Intell.},
  title        = {Granular computing based segmentation and textural analysis (GrCSTA) framework for object-based LULC classification of fused remote sensing images},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A local multi-granularity fuzzy rough set method for
multi-attribute decision making based on MOSSO-LSTM and its application
in stock market. <em>APIN</em>, <em>54</em>(7), 5728–5747. (<a
href="https://doi.org/10.1007/s10489-024-05468-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute decision-making, based on historical data of attributes, considers multiple attributes and strives to find the optimal solution among numerous possible choices. Historical data cannot accurately reflect future situations of the attributes. To address this issue, this paper proposes a local multi-granularity fuzzy rough set (LMGFRS) method for multi-attribute decision making based on long short-term memory (LSTM) neural networks. Firstly, the LSTM is conducted to forecast the future trends of key attributes. And an algorithm of multi-objective salp swarm optimization (MOSSO) is employed to optimize the hyper-parameters of the LSTM. Then, based on the MOSSO-LSTM forecasting attribute trends, the prospect theory and grey relation analysis are utilized to construct different prospect value matrices and the objective concept. The risk preference, risk aversion, and risk neutral of decision-makers in the actual decision-making process are characterized. Next, by integrating the local rough set and multi-granularity fuzzy rough set, a LMGFRS method is constructed. The calculation of approximations of the LMGFRS based on the information granules of the objective concept can greatly reduce calculation complexity. Additionally, the overfitting problems are avoided by tuning the values of $$(\alpha , \beta )$$ . Finally, the proposed LMGFRS decision-making method is applied to stock market. The results indicate that the LMGFRS method enriches rough set theory and decision-making methodology, and provides a feasible decision-making solution for investment institutions in practice.},
  archive      = {J_APIN},
  author       = {Bai, Juncheng and Sun, Bingzhen and Ye, Jin and Xie, Dehua and Guo, Yuqi},
  doi          = {10.1007/s10489-024-05468-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5728-5747},
  shortjournal = {Appl. Intell.},
  title        = {A local multi-granularity fuzzy rough set method for multi-attribute decision making based on MOSSO-LSTM and its application in stock market},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OmiQnet: Multiscale feature aggregation convolutional neural
network for omnidirectional image assessment. <em>APIN</em>,
<em>54</em>(7), 5711–5727. (<a
href="https://doi.org/10.1007/s10489-024-05421-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning-based methods for quality assessment of omnidirectional images (OIs) have gained widespread attention. However, existing methods face challenges because most omnidirectional image quality assessment (OIQA) methods inadequately consider projection distortions and visual complexity. In response, a multiscale feature aggregation convolutional neural network is proposed for OIQA to explore the feasibility of using multiscale features to strengthen the perception of projection distortion information. Specifically, cubemap projection (CMP) is employed to generate viewport images from equirectangular projection (ERP) images to effectively preserve more omnidirectional information. Subsequently, a multiscale feature extraction (MFE) module is designed to extract features at different levels and enhance the representation of distortion information. Additionally, a feature aggregation (FA) module is introduced to fuse multiscale features and fully improve the interconnection capability of the network. Finally, a quality regression (QR) module is employed to map the features to a quality score. Extensive experiments demonstrate the effectiveness and superiority of the proposed network over other state-of-the-art methods for accurately assessing OI quality.},
  archive      = {J_APIN},
  author       = {Fan, Yu and Chen, Chunyi},
  doi          = {10.1007/s10489-024-05421-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5711-5727},
  shortjournal = {Appl. Intell.},
  title        = {OmiQnet: Multiscale feature aggregation convolutional neural network for omnidirectional image assessment},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UNSURE - a machine learning approach to cryptocurrency
trading. <em>APIN</em>, <em>54</em>(7), 5688–5710. (<a
href="https://doi.org/10.1007/s10489-024-05407-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although cryptocurrency trading can be highly profitable, it carries significant risks due to extreme price fluctuations and high degree of market noise. To increase profits and minimize risks, traders typically use various forecasting methods, such as technical analysis and Machine Learning (ML), but developing effective trading strategies in noisy markets still remains a challenging task. Recently, Deep Reinforcement Learning (DRL) agents have achieved high performance on challenging tasks, including algorithmic trading, however it requires significant amount of time and high-quality data to train effectively. Additionally, DRL agents lack explainability, making them a less popular option for traders. The purpose of this paper is to address these challenges by proposing a reliable trading framework. Our framework, named UNSURE, generates high-quality features from candlestick data using technical analysis along with a novel parameterization method, and then exploits high price fluctuations by combining three ML components: A) Unsupervised component, which further improves feature quality by clustering market data; B) DRL component, which is responsible for training agents that open Buy or Short positions; C) Supervised component, which estimates price fluctuations in order to open and close positions efficiently, while reducing trading uncertainty. We demonstrate the effectiveness of this approach on nine cryptocurrency markets using several risk-adjusted performance metrics.},
  archive      = {J_APIN},
  author       = {Kochliaridis, Vasileios and Papadopoulou, Anastasia and Vlahavas, Ioannis},
  doi          = {10.1007/s10489-024-05407-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5688-5710},
  shortjournal = {Appl. Intell.},
  title        = {UNSURE - a machine learning approach to cryptocurrency trading},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive data augmentation for mandarin automatic speech
recognition. <em>APIN</em>, <em>54</em>(7), 5674–5687. (<a
href="https://doi.org/10.1007/s10489-024-05381-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio data augmentation is widely adopted in automatic speech recognition (ASR) to alleviate the overfitting problem. However, noise-based data augmentation converts an over-fitting problem into an under-fitting problem which increases the training time severely. With noise-based data augmentation, informative features are not be persisted during the generating process and generated audio clips would become noise data for the acoustic model. To face the challenge, we propose an Adaptive audio Data Augmentation method called ADA with deep clustering. The proposed ADA could automatically select the most informative augmented sample for each generation. Moreover, two sample selection strategies called RM and RS are proposed. The proposed RM removes samples whose embedding are far away from the cluster center, while the proposed RS maintains the diversity of augmentation samples by sampling in each cluster. Experiments on Aishell-1 demonstrate that the proposed ADA method could improve the data efficiency of end-to-end ASR model in both CNN-based and Transformer-based networks. The proposed ADA obtains an 11.28% and 5.95% relative improvement on SS-CNN and LS-CNN, and a 4.35% improvement on S-Transformer compared with the state-of-the-art audio data augmentation method. Meanwhile, the proposed ADA method decreases the demand of augmented samples by 2.7 times in SS-CNN, LS-CNN and S-Transformer. The qualitative and quantitative analysis proves the effectiveness and efficiency of the proposed ADA method.},
  archive      = {J_APIN},
  author       = {Ding, Kai and Li, Ruixuan and Xu, Yuelin and Du, Xingyue and Deng, Bin},
  doi          = {10.1007/s10489-024-05381-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5674-5687},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive data augmentation for mandarin automatic speech recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Global and edge enhanced transformer for semantic
segmentation of remote sensing. <em>APIN</em>, <em>54</em>(7),
5658–5673. (<a
href="https://doi.org/10.1007/s10489-024-05457-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global context information and edge information are the keys to remote sensing (RS) image semantic segmentation. However, the existing methods have limited ability to obtain global and edge information, and category edge blurring and efficiency problems in small-scale object recognition in remote sensing image semantic segmentation tasks. In this work, we propose a global and edge enhanced Transformer (GE-Swin) for the semantic segmentation of remote sensing images. To improve the sensitivity to edge information, we design dual decoders based on the parallel model. One is the main decoder, which extracts multi-level semantic information from multi-scale features. The other is an auxiliary decoder related to low-layer features with low resolution. Thus, the auxiliary decoder has better sensitivity to edge information. Then, the feature fusion module (FFM) is designed between the encoder and decoder to fuse the multilevel features, enhancing the model’s ability to obtain global features. Finally, to verify the performance of the proposed approach, we perform extensive experiments with the ISPRS and LoveDA datasets. The experimental results illustrate that the proposed model achieves superior performance compared to state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Wang, Hengyou and Li, Xiao and Huo, Lianzhi and Hu, Changmiao},
  doi          = {10.1007/s10489-024-05457-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5658-5673},
  shortjournal = {Appl. Intell.},
  title        = {Global and edge enhanced transformer for semantic segmentation of remote sensing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SSGait: Enhancing gait recognition via semi-supervised
self-supervised learning. <em>APIN</em>, <em>54</em>(7), 5639–5657. (<a
href="https://doi.org/10.1007/s10489-024-05385-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is a challenging biometric technology field due to the complexity of integrating static appearance and dynamic movement patterns in walking videos and the need for extensive labeled data. To address these challenges, we propose an effective self-supervised semi-supervised gait recognition (SSGait) method for learning spatiotemporal representations. Specifically, SSGait contains two main branches: the semi-supervised branch varies the edge morphology of the gait silhouette by introducing sequence-level morphological perturbations in the input, and it learns robust representations using the mean teacher architecture. In the self-supervised branch, we devise two pretexts closely aligned with the gait recognition task: tube-masked reconstruction and clip order prediction. In this way, SSGait can improve the accuracy of recognition tasks by utilizing features extracted from a substantial volume of unlabeled gait data. Finally, we extensively evaluate the proposed SSGait algorithm on two widely used cross-view gait datasets, namely, CASIA-B and OU-MVLP. The experimental results show that SSGait outperforms the best fully supervised methods by 4.84% when using only 20% of the labeled data. When using only 80% of the labeled data, SSGait does match the performance of fully supervised methods trained with 100% labeled data. This highlights SSGait’s ability to use fewer labeled data effectively for improved gait recognition.},
  archive      = {J_APIN},
  author       = {Xi, Hao and Ren, Kai and Lu, Peng and Li, Yongqiang and Hu, Chuanping},
  doi          = {10.1007/s10489-024-05385-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5639-5657},
  shortjournal = {Appl. Intell.},
  title        = {SSGait: Enhancing gait recognition via semi-supervised self-supervised learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the uncapacitated facility location problem under
uncertainty: A hybrid tabu search with path-relinking simheuristic
approach. <em>APIN</em>, <em>54</em>(7), 5617–5638. (<a
href="https://doi.org/10.1007/s10489-024-05441-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncapacitated facility location problem (UFLP) is a well-known combinatorial optimization problem that finds practical applications in several fields, such as logistics and telecommunication networks. While the existing literature primarily focuses on the deterministic version of the problem, real-life scenarios often involve uncertainties like fluctuating customer demands or service costs. This paper presents a novel algorithm for addressing the UFLP under uncertainty. Our approach combines a tabu search metaheuristic with path-relinking to obtain near-optimal solutions in short computational times for the determinisitic version of the problem. The algorithm is further enhanced by integrating it with simulation techniques to solve the UFLP with random service costs. A set of computational experiments is run to illustrate the effectiveness of the solving method.},
  archive      = {J_APIN},
  author       = {Peidro, David and Martin, Xabier A. and Panadero, Javier and Juan, Angel A.},
  doi          = {10.1007/s10489-024-05441-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5617-5638},
  shortjournal = {Appl. Intell.},
  title        = {Solving the uncapacitated facility location problem under uncertainty: A hybrid tabu search with path-relinking simheuristic approach},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving transfer learning for software cross-project
defect prediction. <em>APIN</em>, <em>54</em>(7), 5593–5616. (<a
href="https://doi.org/10.1007/s10489-024-05459-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software cross-project defect prediction (CPDP) makes use of cross-project (CP) data to overcome the lack of data necessary to train well-performing software defect prediction (SDP) classifiers in the early stage of new software projects. Since the CP data (known as the source) may be different from the new project’s data (known as the target), this makes it difficult for CPDP classifiers to perform well. In particular, it is a mismatch of data distributions between source and target that creates this difficulty. Transfer learning-based CPDP classifiers are designed to minimize these distribution differences. The first Transfer learning-based CPDP classifiers treated these differences equally, thereby degrading prediction performance. To this end, recent research has the Weighted Balanced Distribution Adaptation (W-BDA) method to leverage the importance of both distribution differences to improve classification performance. Although W-BDA has been shown to improve model performance in CPDP and tackle the class imbalance by balancing the class proportion of each domain, research to date has failed to consider model performance in light of increasing target data. We provide the first investigation studying the effects of increasing the target data when leveraging the importance of both distribution differences. We extend the initial W-BDA method and call this extension the W-BDA $$\mathbf {^{+}}$$ method. To evaluate the effectiveness of W-BDA $$\mathbf {^{+}}$$ for improving CPDP performance, we conduct eight experiments on 18 projects from four datasets, where data sampling was performed with different sampling methods. Data sampling was only performed on the baseline methods and not on our proposed W-BDA $$\mathbf {^{+}}$$ and the original W-BDA because data sampling issues do not exist for these two methods. We evaluate our method using four complementary indicators (i.e., Balanced Accuracy, AUC, F-measure and G-Measure). Our findings reveal an average improvement of 6%, 7.5%, 10% and 12% for these four indicators when W-BDA $$\mathbf {^{+}}$$ is compared to the original W-BDA and five other baseline methods (for all four of the sampling methods used). Also, as the target to source ratio is increased with different sampling methods, we observe a decrease in performance for the original W-BDA, with our W-BDA $$\mathbf {^{+}}$$ approach outperforming the original W-BDA in most cases. Our results highlight the importance of having an awareness of the effect of the increasing availability of target data in CPDP scenarios when using a method that can handle the class imbalance problem.},
  archive      = {J_APIN},
  author       = {Omondiagbe, Osayande P. and Licorish, Sherlock A. and MacDonell, Stephen G.},
  doi          = {10.1007/s10489-024-05459-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5593-5616},
  shortjournal = {Appl. Intell.},
  title        = {Improving transfer learning for software cross-project defect prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Requirements elicitation and response generation for
conversational services. <em>APIN</em>, <em>54</em>(7), 5576–5592. (<a
href="https://doi.org/10.1007/s10489-024-05454-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, cognitive services provide a more interactive method for understanding users’ requirements via human-machine conversations. In other words, it has to capture users’ requirements from their utterances and respond to them with relevant and suitable service resources. To this end, two phases must be applied: I.sequence planning and real-time detection of user requirements, and II.service resource selection and response generation. The existing works ignore the potential connection between these two phases. To model their connection, the two-phase requirement elicitation method is proposed. In Phase I, this paper proposes a user requirement elicitation framework (URef) to plan a potential requirement sequence grounded on the user profile and personal knowledge base before the conversation. It can also predict user’s true requirement and judge whether the requirement is completed based on the user’s utterance during the conversation. In Phase II, this paper proposes a response generation model based on attention, SaRSNet. It can select the appropriate resource (i.e., knowledge triple) in line with the requirement predicted by URef, and then generates a suitable response for recommendation. The experimental results on the open dataset DuRecDial have been significantly improved compared to the baseline, which proves the effectiveness of the proposed methods. (This Manuscript based partly on work [1] presented at conference (ICWS 2021).)},
  archive      = {J_APIN},
  author       = {Zhang, Bolin and Tu, Zhiying and Wang, Can and Sun, Hongliang and Chu, Dianhui},
  doi          = {10.1007/s10489-024-05454-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5576-5592},
  shortjournal = {Appl. Intell.},
  title        = {Requirements elicitation and response generation for conversational services},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Auto-metric distribution propagation graph neural network
with a meta-learning strategy for diagnosis of otosclerosis.
<em>APIN</em>, <em>54</em>(7), 5558–5575. (<a
href="https://doi.org/10.1007/s10489-024-05449-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Otosclerosis is a multifactorial bone disorder that affects the otic capsule; otosclerosis is a significant cause of deafness in adults. Since the lesion areas are frequently subtle, the diagnosis of otosclerosis on temporal bone CT images tends to be difficult, especially for fenestral otosclerosis. We design a deep learning model for diagnosing otosclerosis on CT scans in the case of limited samples. That is, we design a dual graph network, namely, ADP-GNN, for predicting otosclerosis-positive and otosclerosis-negative samples; the network consists of point graphs and distribution graphs. More specifically, the point graph is used to model the instance-level relation between nodes, and the risk factors are integrated into it for multimodal diagnosis. The distribution graph is used to model the distribution-level relation between samples, and the copula function is introduced to better measure the dependency between nodes. The autometric strategy is also used to make the model more flexible and to enable the sample to be evaluated independently. Through the propagation between the two graphs and metatraining, the labels of unknown nodes can be predicted. Test experiments on otosclerosis datasets show that the performance of our model achieves accuracies of 98.15% and 97.69% for diagnosis in the left and right ears, respectively, and outperforms the other models. This verifies the advantage of our model in the case of limited samples. We also conduct experiments on a public dataset. The results demonstrate the stability of our model and that it achieves better performance when compared with existing studies. This work offers a new approach for the diagnosis of otosclerosis and facilitates the development of computer-aided diagnosis in clinical practice.},
  archive      = {J_APIN},
  author       = {Wang, Jiaoju and Song, Jian and Wang, Zheng and Mao, Shuang and Kong, Mengli and Mao, Yitao and Hou, Muzhou and Wu, Xuewen},
  doi          = {10.1007/s10489-024-05449-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5558-5575},
  shortjournal = {Appl. Intell.},
  title        = {Auto-metric distribution propagation graph neural network with a meta-learning strategy for diagnosis of otosclerosis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning workflow enhanced with optical flow fields
for flood risk estimation. <em>APIN</em>, <em>54</em>(7), 5536–5557. (<a
href="https://doi.org/10.1007/s10489-024-05466-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the physical and economic impacts of urban flooding, effective flood risk management is of crucial importance. Thus, it is essential to employ reliable techniques for monitoring water levels in urban creeks and detecting abrupt fluctuations in weather patterns. Ground-based cameras alongside a creek offer a cost-effective solution, since they can be deployed for determining water levels through image-based analysis. Previous research has examined the benefits of image processing and artificial intelligence techniques to achieve this goal. However, the current methods only analyze static image features and ignore the valuable motion information that may exist in adjacent frames that are captured minutes apart. In addressing this limitation, our approach involves computing dense optical flow fields from consecutive images taken by a stationary camera and integrating these representations into a deep-learning workflow. We evaluated the capacity of both our method and alternative approaches to measure not only the absolute water level (i.e., whether the water height is low, medium, high, or flooding) but also the relative water level (i.e., whether the water level is rising or falling). The results showed that optical flow-based representations significantly improved the ability to measure the relative water level, while pairs of successive grayscale images effectively determined the absolute water level.},
  archive      = {J_APIN},
  author       = {Ranieri, Caetano Mazzoni and Souza, Thaís Luiza Donega e and Nishijima, Marislei and Krishnamachari, Bhaskar and Ueyama, Jó},
  doi          = {10.1007/s10489-024-05466-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5536-5557},
  shortjournal = {Appl. Intell.},
  title        = {A deep learning workflow enhanced with optical flow fields for flood risk estimation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). F-DQN: An optimized DQN for decision-making of generator
start-up sequence after blackout. <em>APIN</em>, <em>54</em>(7),
5521–5535. (<a
href="https://doi.org/10.1007/s10489-024-05392-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decision-making of generator start-up sequence plays a pivotal role in the power system restoration process following the blackout. In this paper, an optimized deep Q-learning network (DQN) algorithm is proposed to address this challenge. The generator start-up process is modeled as a Markov Decision Process (MDP) based on its characteristics. The DQN is tasked with deciding both the generator start-up sequence and the corresponding restoration path. To address the limitations of DQN, such as low exploration efficiency and slow convergence, the study incorporates the Artificial Potential Field (APF) algorithm to refine the reward function of it. This integration results in the development of the F-DQN (APF-DQN) algorithm, which enhances training efficiency. The effectiveness of this proposed method is demonstrated through the IEEE 39-bus test system. The results reveal that the DQN algorithm is capable of efficiently solving the model of the generator start-up sequence after the blackout. Moreover, the F-DQN algorithm exhibits superior learning efficiency, faster convergence, and higher-quality optimal solutions compared to the DQN. This paper also discusses the applicability of this method under partial blackouts. When compared to other decision-making algorithms, the proposed method offers a restoration scheme that is both time-efficient and results in increased electricity generation.},
  archive      = {J_APIN},
  author       = {Li, Changcheng and Wu, Zirui},
  doi          = {10.1007/s10489-024-05392-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5521-5535},
  shortjournal = {Appl. Intell.},
  title        = {F-DQN: An optimized DQN for decision-making of generator start-up sequence after blackout},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformer based composite network for autonomous driving
trajectory prediction on multi-lane highways. <em>APIN</em>,
<em>54</em>(7), 5486–5520. (<a
href="https://doi.org/10.1007/s10489-024-05461-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to navigate through complex traffic scenarios safely and efficiently, the autonomous vehicle (AV) predicts its own behavior and future trajectory based on the predicted trajectories of surrounding vehicles to avoid potential collisions. Further, the predicted trajectories of surrounding vehicles (target vehicles) are greatly influenced by their driving behavior and prior trajectory. In this article, we propose a novel Transformer-based composite network to predict both driver behavior and future trajectory of a target vehicle in a highway driving scenario. The powerful multi-head attention mechanism of the transformer is exploited to extract social-temporal interaction between target vehicle and its surrounding vehicles. The prediction of both lateral and longitudinal behavior is carried out within the behavior prediction module, and this additional information is further utilized by the trajectory predictor module to ensure precise trajectory prediction. Furthermore, mixture density network is augmented in the model to handle uncertainties in the predicted trajectories. The proposed model’s performance is compared with several state-of-the-art models on real-world Next Generation Simulation (NGSIM) dataset. The results indicate the superiority of the proposed model over all contemporary state-of-the-art models, as evaluated using Root Mean Square Error (RMSE) metric. The proposed model predicts a 5s long trajectory with an 11% lower RMSE than the state-of-the-art model.},
  archive      = {J_APIN},
  author       = {Sharma, Omveer and Sahoo, N. C. and Puhan, Niladri B.},
  doi          = {10.1007/s10489-024-05461-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5486-5520},
  shortjournal = {Appl. Intell.},
  title        = {Transformer based composite network for autonomous driving trajectory prediction on multi-lane highways},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A novel selective ensemble point and interval prediction
system for energy futures price: Forming a new multi-objective modeling
paradigm. <em>APIN</em>, <em>54</em>(7), 5465–5485. (<a
href="https://doi.org/10.1007/s10489-024-05450-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the price prediction of reliable energy is of considerable economic significance, it remains a challenge owing to sophisticated economic characteristics. The methods proposed in previous studies generally overlook the importance of selective ensemble and multi-objective modeling, which might not always achieve the expected point and interval prediction results. In this study, we formed a new multi-objective modeling paradigm to develop a novel selective ensemble point and interval prediction system composed of modules for data preprocessing, multiple predictor pretraining, optimal model selection and prediction, and multi-objective modeling. Specifically, the data preprocessing module decomposes the overall prediction task into a series of subtasks, and the multiple predictor pretraining module obtains candidate models for each subtask. Subsequently, the optimal model selection and prediction module employs a new comprehensive metric to allocate the optimal model for each subtask, thereby ensuring optimal results. Finally, the multi-objective modeling module simultaneously realizes the prediction results of points and intervals by integrating the optimal prediction results of each subtask. Based on the futures price of crude oil and natural gas, the mean absolute percentage error values of the proposed system in point prediction were 0.14801% and 0.35213%, respectively, whereas the corresponding prediction interval normalized average width values for interval prediction were 1.25319 and 1.03589 at a confidence level of 90%. These empirical results demonstrate that the proposed system outperforms baseline models in both point and interval prediction, and has practical applicability toward formulating energy policies and investment.},
  archive      = {J_APIN},
  author       = {Wang, Jingyi},
  doi          = {10.1007/s10489-024-05450-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5465-5485},
  shortjournal = {Appl. Intell.},
  title        = {A novel selective ensemble point and interval prediction system for energy futures price: Forming a new multi-objective modeling paradigm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Moment balanced machine: A new supervised inference engine
for on-site construction productivity prediction. <em>APIN</em>,
<em>54</em>(7), 5441–5464. (<a
href="https://doi.org/10.1007/s10489-024-05419-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting construction productivity is challenging because of the complexity involved in the construction process and the variability in factors that regularly affect these projects. Machine learning models have the potential to improve the accuracy of construction productivity predictions. This study introduces a model for generating accurate predictions of construction productivity using an AI-based inference engine called Moment Balanced Machine (MBM). Instead of identifying the hyperplane of SVM, MBM considers moments to determine the optimal moment hyperplane. MBM balances the moments, which are the product of force and distance, with force representing the weight assigned to a datapoint and distance indicating its position relative to the moment hyperplane. To obtain the weights for each datapoint within the MBM framework, Backpropagation Neural Network (BPNN) is employed. Moreover, the performance of MBM is benchmarked against five other machine learning models, including SVM, BPNN, K-Nearest Neighbor (KNN), Decision Tree (DT), and Linear Regression (LR). According to the results of the 10-fold cross-validation, MBM consistently outperformed the other models across five evaluation metrics, including RMSE (0.068), MAE (0.054), MAPE (3.42%), R (0.982), and R2 (0.965). The comprehensive assessment, summarized by the Reference Index (RI), indicates that MBM achieved the highest RI score of 1.000, emphasizing its superior performance. Furthermore, MBM exhibits robustness against data imperfections, including incomplete and noisy datasets. Given these findings, the proposed model could serve as an advanced machine learning decision-support system that improves the prediction accuracy of construction productivity. This reinforces the data-driven approach for improving the efficiency of construction projects.},
  archive      = {J_APIN},
  author       = {Cheng, Min-Yuan and Khasani, Riqi Radian},
  doi          = {10.1007/s10489-024-05419-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5441-5464},
  shortjournal = {Appl. Intell.},
  title        = {Moment balanced machine: A new supervised inference engine for on-site construction productivity prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-factor stock trading strategy based on DQN with
multi-BiGRU and multi-head ProbSparse self-attention. <em>APIN</em>,
<em>54</em>(7), 5417–5440. (<a
href="https://doi.org/10.1007/s10489-024-05463-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is widely used in financial markets to assist investors in developing trading strategies. However, most existing models primarily focus on simple volume-price factors, and there is a need for further improvement in the returns of stock trading. To address these challenges, a multi-factor stock trading strategy based on Deep Q-Network (DQN) with Multi-layer Bidirectional Gated Recurrent Unit (Multi-BiGRU) and multi-head ProbSparse self-attention is proposed. Our strategy comprehensively characterizes the determinants of stock prices by considering various factors such as financial quality, valuation, and sentiment factors. We first use Light Gradient Boosting Machine (LightGBM) to classify turning points for stock data. Then, in the reinforcement learning strategy, Multi-BiGRU, which holds the bidirectional learning of historical data, is integrated into DQN, aiming to enhance the model’s ability to understand the dynamics of the stock market. Moreover, the multi-head ProbSparse self-attention mechanism effectively captures interactions between different factors, providing the model with deeper market insights. We validate our strategy’s effectiveness through extensive experimental research on stocks from Chinese and US markets. The results show that our method outperforms both temporal and non-temporal models in terms of stock trading returns. Ablation studies confirm the critical role of LightGBM and multi-head ProbSparse self-attention mechanism. The experiment section also demonstrates the significant advantages of our model through the presentation of box plots and statistical tests. Overall, by fully considering the multi-factor data and the model’s feature extraction capabilities, our work is expected to provide investors with more precise trading decision support.},
  archive      = {J_APIN},
  author       = {Liu, Wenjie and Gu, Yuchen and Ge, Yebo},
  doi          = {10.1007/s10489-024-05463-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5417-5440},
  shortjournal = {Appl. Intell.},
  title        = {Multi-factor stock trading strategy based on DQN with multi-BiGRU and multi-head ProbSparse self-attention},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AFSRNet: Learning local descriptors with adaptive
multi-scale feature fusion and symmetric regularization. <em>APIN</em>,
<em>54</em>(7), 5406–5416. (<a
href="https://doi.org/10.1007/s10489-024-05418-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-scale feature fusion has been widely used in handcrafted descriptors, but has not been fully explored in deep learning-based descriptor extraction. Simple concatenation of descriptors of different scales has not been successful in significantly improving performance for computer vision tasks. In this paper, we propose a novel convolutional neural network, based on center-surround adaptive multi-scale feature fusion. Our approach enables the network to focus on different center-surround scales, resulting in improved performance. We also introduce a novel regularization technique that uses second-order similarity to constrain the learning of local descriptors, based on the symmetric property of the similarity matrix. The proposed method outperforms single-scale or simple-concatenation descriptors on two datasets and achieves state-of-the-art results on the Brown dataset. Furthermore, our method demonstrates excellent generalization ability on the HPatches dataset. Our code is released on GitHub: https://github.com/Leung-GD/AFSRNet/tree/main .},
  archive      = {J_APIN},
  author       = {Li, Dong and Liang, Haowen and Lam, Kin-Man},
  doi          = {10.1007/s10489-024-05418-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5406-5416},
  shortjournal = {Appl. Intell.},
  title        = {AFSRNet: Learning local descriptors with adaptive multi-scale feature fusion and symmetric regularization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-domain fisher discrimination criterion: A domain
adaptive method based on the nature of classifier. <em>APIN</em>,
<em>54</em>(7), 5389–5405. (<a
href="https://doi.org/10.1007/s10489-024-05376-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most domain adaptive methods enhance the classification performance of target domain via overcoming the distribution difference between source and target domains while ignoring the nature of classifier, i.e., the data being correctly classified by classifier is due to the high separability of data. Therefore, inspired by this, we propose a simple yet effective domain adaptive method in accordance with the property of classifier, namely cross-domain Fisher discrimination criterion (CFDC). CDFC is intended to upgrade the inter-class discrimination and intra-class compactness of samples for the scenario where the target domain has few labeled samples. Specifically, we reconstruct the intra- and inter- class scatter matrices of Fisher&#39;s criterion from a geometrically intuitive perspective, enabling it to extract highly discriminative features from cross-domain samples. The reconstructed between-class scatter matrix aims to maximize the class separation of target samples, while the redefined within-class scatter matrix seeks to have samples from different domains densely clustered around the class center of target samples. Six widely used image datasets are involved to verify the effectiveness and efficiency of CFDC. Experimental results demonstrate that the performance of CFDC is significantly superior to similar methods and conventional unsupervised domain adaptation methods, comparable to non-deep semi-supervised domain adaptation methods, but with a significantly lower time consumption. Even compared with state-of-the-art deep semi-supervised domain adaptation methods, CFDC exhibits performance advantages on certain datasets.},
  archive      = {J_APIN},
  author       = {Liu, Yuchuan and Li, Lianzhi and Tan, Jia and Rao, Yu and Tan, Xiaoheng and Li, Yongsong},
  doi          = {10.1007/s10489-024-05376-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5389-5405},
  shortjournal = {Appl. Intell.},
  title        = {Cross-domain fisher discrimination criterion: A domain adaptive method based on the nature of classifier},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supporting ANFIS interpolation for image super resolution
with fuzzy rough feature selection. <em>APIN</em>, <em>54</em>(7),
5373–5388. (<a
href="https://doi.org/10.1007/s10489-024-05445-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image Super-Resolution (ISR) is utilised to generate a high-resolution image from a low-resolution one. However, most current techniques for ISR confront three main constraints: i) the assumption that there is sufficient data available for training, ii) the presumption that areas of the images concerned do not involve missing data, and iii) the development of a computationally efficient model that does not compromise performance. In addressing these issues, this study proposes a novel lightweight approach termed Fuzzy Rough Feature Selection-based ANFIS Interpolation (FRFS-ANFISI) for ISR. Popular feature extraction algorithms are employed to extract the potentially significant features from images, and population-based search mechanisms are utilised to implement effective FRFS methods that assist in selecting the most important features among them. Subsequently, the processed data is entered into the ANFIS interpolation model to execute the ISR operation. To tackle the sparse data challenge, two adjacent ANFIS models are trained with sufficient data where appropriate, intending to position the ANFIS model of sparse data in the middle. This enables the two neighbouring ANFIS models to be interpolated to produce the otherwise missing knowledge or rules for the model in between, thereby estimating the corresponding outcomes. Conducted on standard ISR benchmark datasets while considering both sufficient and sparse data scenarios, the experimental studies demonstrate the efficacy of the proposed approach in helping deal with the aforementioned challenges facing ISR.},
  archive      = {J_APIN},
  author       = {Ismail, Muhammad and Shang, Changjing and Yang, Jing and Shen, Qiang},
  doi          = {10.1007/s10489-024-05445-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5373-5388},
  shortjournal = {Appl. Intell.},
  title        = {Supporting ANFIS interpolation for image super resolution with fuzzy rough feature selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural networks with selective attention and path
reasoning for document-level relation extraction. <em>APIN</em>,
<em>54</em>(7), 5353–5372. (<a
href="https://doi.org/10.1007/s10489-024-05448-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level Relation Extraction (DocRE) aims to extract relations from multiple sentences simultaneously. Existing graph-based methods adopt static graphs to represent the document structure, which is unable to capture complex interactions. Besides, they take all sentences in the document as the scope of relation extraction (RE) while introducing noise by irrelevant sentences. Furthermore, they do not explicitly model the reasoning chain, leading to a lack of explainability in the reasoning results. These limitations may significantly hinder their performance in practical applications. In this paper, we propose a model based on selective attention and path reasoning for DocRE. Firstly, we adopt hierarchical heterogeneous graph neural networks and recurrent neural networks to realize document modeling and capture complex interactions in the document. Secondly, we adopt selective attention to select sentences related to the entity pair to generate document subgraphs as the scope of RE. Lastly, we adopt path reasoning to explicitly model the reasoning chain between multiple entities in the document subgraph, infer the relations between entities and provide corresponding supporting evidence. Extensive experiment results on three benchmark datasets show that the proposed framework is effective and achieves superior performance compared to most methods. Further analysis demonstrates that selective attention and path reasoning can discover more accurate inter-sentence relations and supporting evidence.},
  archive      = {J_APIN},
  author       = {Hang, Tingting and Feng, Jun and Wang, Yunfeng and Yan, Le},
  doi          = {10.1007/s10489-024-05448-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5353-5372},
  shortjournal = {Appl. Intell.},
  title        = {Graph neural networks with selective attention and path reasoning for document-level relation extraction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-local self-attention network for image super-resolution.
<em>APIN</em>, <em>54</em>(7), 5336–5352. (<a
href="https://doi.org/10.1007/s10489-024-05343-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of self-attention mechanisms in Transformer-based methods has shown great potential in addressing the image super-resolution (SR) task by capturing long-range dependencies. However, many existing Transformer-based methods for SR extract features locally within a small window and rely on shifted window self-attention to gradually incorporate long-range dependencies. These methods may not effectively exploit non-local image information for SR. To overcome this limitation, we propose a novel non-local self-attention (NLSA) mechanism that directly models non-local dependencies. Firstly, NLSA utilizes locality-sensitive hashing to identify similar pixel-wise features with minimal computational cost. Next, a pixel-shuffling operation is applied to gather similar features within the same window. This pixel-shuffling technique effectively expands the receptive field beyond the window size. Furthermore, we introduce a simplified window self-attention (SiWSA) that operates within each window to capture intrinsic long-term dependencies among the shuffled features, regardless of the position information. Finally, after the SiWSA calculation, the features are shuffled back to their original positions to maintain data consistency. This overall NLSA mechanism enables the capture of non-local information without the need for excessively deep networks to enlarge the receptive field. Based on NLSA, we propose a non-local self-attention network (NLSAN) designed explicitly for the SR task. Through extensive experimental evaluations, we demonstrate the superior performance of NLSAN compared to several state-of-the-art SR methods in quantitative and qualitative assessments. The code of the proposed method is available at https://github.com/zengkun301/NLSAN .},
  archive      = {J_APIN},
  author       = {Zeng, Kun and Lin, Hanjiang and Yan, Zhiqiang and Fang, Jinsheng and Lai, Taotao},
  doi          = {10.1007/s10489-024-05343-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5336-5352},
  shortjournal = {Appl. Intell.},
  title        = {Non-local self-attention network for image super-resolution},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outlier detection for incomplete real-valued data via
information entropy and class-consistent technology. <em>APIN</em>,
<em>54</em>(7), 5317–5335. (<a
href="https://doi.org/10.1007/s10489-024-05428-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection aims to find data points that are significantly different from other observed values. It has been widely used in fraud detection, network security, and medical fields. Most of the existing outlier detection methods do not fully consider the problem of missing values in data sets. This paper studies outlier detection for incomplete real-valued data via information entropy and rough set theory (RST). First, a tolerance relation based on class-consistent technology is introduced to describe the similarity between information values in an incomplete real-valued information system (IRVIS). Then, the tolerance classes are formed according to the tolerance relation, and are used to calculate information entropy and other metrics. Next, an outlier factor is defined for each object in an IRVIS to describe its uncertainty and degree of outlier. Finally, an outlier detection method for an IRVIS is proposed, and the corresponding algorithm (CIEOD) is designed. The proposed method is compared with five other detection methods by numerical experiments based on UCI data. The experimental results show that the CIEOD algorithm is more efficient. It is worth mentioning that in order to make comprehensive comparison, Precision, Recall, F1-measure and ROC curve are used to describe the strengths of the proposed method.},
  archive      = {J_APIN},
  author       = {Cai, Xiaopeng and Li, Zhaowen},
  doi          = {10.1007/s10489-024-05428-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5317-5335},
  shortjournal = {Appl. Intell.},
  title        = {Outlier detection for incomplete real-valued data via information entropy and class-consistent technology},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel deep learning approach for intelligent bearing fault
diagnosis under extremely small samples. <em>APIN</em>, <em>54</em>(7),
5306–5316. (<a
href="https://doi.org/10.1007/s10489-024-05429-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotor bearing health is crucial for ensuring the operational stability of rotating equipment. Deep learning-based fault diagnosis methods have achieved widespread success due to their superior fault identification capability. However, conventional deep learning methods that rely on large quantities of data are not feasible for most important mechanical equipment since obtaining fault data is difficult. To address this problem, we propose channel attention siamese networks (CASN) with metric learning for intelligent bearing fault diagnosis with extremely small samples. First, in the feature learning phase, pairs of sample inputs are constructed, and feature extraction is performed by a shared encoder. Then, in the disparity learning phase, the differences between features of sample pairs are mapped as metric distances. Based on the metric distance between the unlabeled and labeled data, the fault type of the unlabeled data can be predicted in the test phase. The experimental results show that CASN achieves over 97% accuracy when the sample size is extremely small. In addition, even under the conditions of noise interference and signal transmission distortion, our model still has reliable diagnostic ability.},
  archive      = {J_APIN},
  author       = {Ding, Peixuan and Xu, Yi and Qin, Pan and Sun, Xi-Ming},
  doi          = {10.1007/s10489-024-05429-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5306-5316},
  shortjournal = {Appl. Intell.},
  title        = {A novel deep learning approach for intelligent bearing fault diagnosis under extremely small samples},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting clustering for efficient unsupervised dialogue
structure induction. <em>APIN</em>, <em>54</em>(7), 5278–5305. (<a
href="https://doi.org/10.1007/s10489-024-05455-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the development of a task-oriented dialogue system, defining the dialogue structure is a time-consuming task. Hence, several works have looked into automatically inferring it from data, e.g., actual conversations between a customer and a support agent. To recover such dialogue structure, recent methods based on discrete variational models learn to jointly encode and cluster utterances in dialogue states, but (i) represent utterances by only considering preceding dialogue context, and (ii) are slow to train since they are optimized with a compute-expensive decoding objective. We revisit and improve upon an existing efficient pipeline approach, commonly adopted as a baseline, that first encodes utterances and then clusters them with k-means to induce the dialogue structure. However, the existing approach represents utterances as bag-of-words or skip-thought vectors, which have been shown to perform poorly in semantic similarity tasks, and without considering dialogue context. We therefore first investigate the use of more powerful transformer-based encoders for encoding utterances. Next, we propose ellodar, a method for learning representations that capture both preceding and subsequent dialogue context, inspired by word-to-vec training strategies. ellodar is efficient since representations are learned directly in the encoding space by finetuning just a single linear layer on top of a frozen sentence encoder with a vector-to-vector regression training objective. Extensive experiments on representative datasets for dialogue structure induction (SimDial, Schema Guided Dialogues, DSTC2, and CamRest676) demonstrate that in terms of effectiveness to induce the correct dialogue structure, (i) clustering utterances represented by transformed-based encoders improves recent joint models by 13%–32% on standard cluster metrics, and (ii) clustering ellodar’s representations yields additional improvements ranging from +20% to +26%, with speedups of $$\times $$ $$\textbf{10}$$ – $$\textbf{10}^{\textbf{4}}$$ compared to the recent joint models.},
  archive      = {J_APIN},
  author       = {Raedt, Maarten De and Godin, Fréderic and Develder, Chris and Demeester, Thomas},
  doi          = {10.1007/s10489-024-05455-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5278-5305},
  shortjournal = {Appl. Intell.},
  title        = {Revisiting clustering for efficient unsupervised dialogue structure induction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond traditional steganography: Enhancing security and
performance with spread spectrum image steganography. <em>APIN</em>,
<em>54</em>(7), 5253–5277. (<a
href="https://doi.org/10.1007/s10489-024-05415-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the innovative application of Direct Sequence Spread Spectrum (DSSS) technology in the realm of image steganography, known as Spread Spectrum Image Steganography (SSIS). By interpreting the cover image as noise in the communication channel, SSIS capitalizes on the noise-resistant properties of broadband communication systems to effectively conceal information within images. We focus on the development of new classes of spreading sequences with desirable ensemble and correlation properties, which significantly impact the performance of SSIS. We propose a data hiding method that directly addresses spreading sequences, resulting in minimized cover image distortion and heightened resistance to message detection. Furthermore, we explore adaptive spreading sequences that consider the statistical properties of the cover image, substantially reducing error intensity in recovered messages and improving the overall steganographic system performance. Our experiments confirm the advantages of the proposed system and support the theoretical arguments. In addition, we employ artificial neural networks for steganalysis, generating several datasets with varying SSIS payloads and examining the detectability of embedded data using a specially designed convolutional neural network (CNN). While this model demonstrates high effectiveness on other datasets, the detection error probability for SSIS is considerably higher, indicating greater reliability and security even when advanced steganalysis techniques are employed. The findings highlight the potential of SSIS in developing robust and secure communication systems capable of functioning effectively in high-noise environments while preserving the integrity of the cover image.},
  archive      = {J_APIN},
  author       = {Kuznetsov, Oleksandr and Frontoni, Emanuele and Chernov, Kyrylo},
  doi          = {10.1007/s10489-024-05415-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5253-5277},
  shortjournal = {Appl. Intell.},
  title        = {Beyond traditional steganography: Enhancing security and performance with spread spectrum image steganography},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lifelong learning gets better with MixUp and unsupervised
continual representation. <em>APIN</em>, <em>54</em>(7), 5235–5252. (<a
href="https://doi.org/10.1007/s10489-024-05434-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning enables learning systems to adapt to evolving data distributions by sequentially acquiring knowledge from a series of tasks. Unsupervised lifelong learning refers to the ability to learn over time while memorizing previous patterns without supervision. However, the prior methods in this field heavily rely on supervised or reinforcement learning, which necessitates annotated data, thereby limiting their scalability in real-world applications where data is often biased and lacks annotations. To overcome these challenges, this work introduces a novel approach called Lifelong Learning gets better with MixUp and Unsupervised Continual Representation (LL-UCR). LL-UCR aims to learn feature representations from unlabeled tasks, eliminating the need for annotated data. Within the LL-UCR framework, two innovative techniques are introduced: LL-MixUp, which mitigates catastrophic forgetting by interpolating samples between current and previous tasks, and Dark Experience Replay (DER) Buzzega et al. (Adv Neural Inf Process Syst, 33, 15920–15930 2020) adapted for UCR, aligning network logits across tasks. To overcome buffer size limitations in replay-based methods, the Retrospective Adversarial Replay (RAR) framework is incorporated, facilitating diverse replay sample generation. Through systematic analysis, we demonstrate that unsupervised visual representations exhibit remarkable resilience to catastrophic forgetting, consistently outperforming supervised methods in terms of performance and generalization on out-of-distribution tasks. Furthermore, our qualitative analysis reveals that LL-UCR fosters a smoother loss landscape and acquires meaningful feature representations. Extensive experimental evaluations conducted on diverse datasets validate the superior performance of LL-UCR compared to state-of-the-art supervised continual learning methods and the unsupervised LUMP Madaan et al. (International conference on learning representations, 2020) method, effectively mitigating catastrophic forgetting.},
  archive      = {J_APIN},
  author       = {kumar, Prashant and Toshniwal, Durga},
  doi          = {10.1007/s10489-024-05434-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5235-5252},
  shortjournal = {Appl. Intell.},
  title        = {Lifelong learning gets better with MixUp and unsupervised continual representation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CA-PDBPR: Category-aware privacy preserving POI
recommendation using decentralized bayesian personalized ranking.
<em>APIN</em>, <em>54</em>(7), 5216–5234. (<a
href="https://doi.org/10.1007/s10489-024-05426-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-of-interest (POI) recommendation has gained significant traction recently due to the rising trend of location-based networks. Traditional approaches rely on a centralized collection of user data. Concerning privacy protection, decentralized federated learning employs model training on each user’s device with nearby collaborative training techniques. However, existing decentralized federated recommendations suffer from two major problems: (1) Privacy risks: existing approaches expose geographical location or co-rated items information when constructing user neighborhoods. (2) Performance limitations: existing approaches adopt a simple model without incorporating auxiliary information. To solve these, we propose CA-PDBPR (category-aware privacy preserving POI recommendation using decentralized Bayesian personalized ranking) to address the above challenges. Specifically, we introduce a novel privacy-enhanced neighborhood creation method utilizing POI category preferences to calculate decentralized user similarity through secret sharing technology, ensuring a higher level of privacy. Moreover, we integrate POI category information with a refined Bayesian personalized ranking (BPR) loss function to enhance recommendation performance. Experimental evaluations conducted on real-world datasets validate the effectiveness of the CA-PDBPR model, demonstrating enhanced recommendation quality while minimizing data exposure compared with state-of-the-art alternatives.},
  archive      = {J_APIN},
  author       = {Gao, Qinyun and Yu, Shenbao and Chen, Bilian and Cao, Langcai},
  doi          = {10.1007/s10489-024-05426-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5216-5234},
  shortjournal = {Appl. Intell.},
  title        = {CA-PDBPR: Category-aware privacy preserving POI recommendation using decentralized bayesian personalized ranking},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). F2D-SIFPNet: A frequency 2D slow-i-fast-p network for faster
compressed video action recognition. <em>APIN</em>, <em>54</em>(7),
5197–5215. (<a
href="https://doi.org/10.1007/s10489-024-05408-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent video action recognition methods directly use RGB pixels in the compressed domain. The cumbersome decoding process of traditional methods is avoided, enabling efficient recognition. However, these methods require converting the discrete cosine transform (DCT) frequency to an extended RGB pixel representation with heavy time consuming. To alleviate this drawback, a novel frequency 2D Slow-I-Fast-P network (F2D-SIFPNet) is proposed that significantly enhances the speed of action recognition. Initially, a new Frequency-Domain Partial Decompression (FPDec) method was designed for extracting the frequency domain DCT coefficients directly from the compressed video, eliminating the last time-consuming decoding process in FFmpeg. Subsequently, the Frequency-Domain Channel Selection (FCS) strategy was introduced for down-sampling the frequency-domain data, thereby augmenting the saliency of the input. Additionally, the Frequency Slow-I-Fast-P path (FSIFP) and the Adaptive Motion Excitation (AME) module were presented to emphasize the significant frequency components. FSIFP efficiently models slow spatial features and fast temporal changes simultaneously, while the AME generates an adaptive convolution kernel that captures both long-term and short-term motion cues. Extensive experiments were conducted on four public datasets: Kinetics-700, Kinetics-400, UCF-101, and HMDB-51. The results showed superior accuracies of 55.6 $$\%$$ , 74.0 $$\%$$ , 96.3 $$\%$$ and 74.6 $$\%$$ respectively, with preprocessing times being 6.31 times faster.},
  archive      = {J_APIN},
  author       = {Ming, Yue and Zhou, Jiangwan and Jia, Xia and Zheng, Qingfang and Xiong, Lu and Feng, Fan and Hu, Nannan},
  doi          = {10.1007/s10489-024-05408-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {7},
  pages        = {5197-5215},
  shortjournal = {Appl. Intell.},
  title        = {F2D-SIFPNet: A frequency 2D slow-I-fast-P network for faster compressed video action recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient center-based method for real-time pig posture
recognition and tracking. <em>APIN</em>, <em>54</em>(6), 5183–5196. (<a
href="https://doi.org/10.1007/s10489-024-05439-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting, tracking, and recognizing the posture of individual pigs are the primary computer vision tasks of many camera-based decision support tools for precise livestock monitoring. Recently, the use of deep learning approaches in computer vision, particularly convolutional neural networks (CNNs), has led to performance never before possible. However, the heavy constraints of pig environments such as instinctive grouping and similar animal appearance limit the effectiveness of state-of-the-art approaches popular in other application fields. To tackle these problems, we propose a fully anchor-free center-based CNN framework that detects pigs, classifies their postures, and tracks them throughout an image sequence. Input images are first fed into two sub-networks that detect pig posture and generate a global appearance map from which local appearance vectors corresponding to the detected pig centers can be extracted. Next, an assignment strategy uses spatial and appearance metrics to associate each pig detected in the frame with one of the tracked pig trajectories in a video sequence. As shown by the experiments, our real-time method significantly outperforms state-of-the-art approaches for pig detection, posture recognition, and tracking.},
  archive      = {J_APIN},
  author       = {Mattina, Morann and Benzinou, Abdesslam and Nasreddine, Kamal and Richard, Francis},
  doi          = {10.1007/s10489-024-05439-5},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5183-5196},
  shortjournal = {Appl. Intell.},
  title        = {An efficient center-based method for real-time pig posture recognition and tracking},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IMCN: Improved modular co-attention networks for visual
question answering. <em>APIN</em>, <em>54</em>(6), 5167–5182. (<a
href="https://doi.org/10.1007/s10489-024-05456-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing Visual Question Answering (VQA) methods use traditional attention mechanisms to focus on each region of the input image and each word of the input question and achieve well performance. However, the most obvious limitation of traditional attention mechanisms is that the module always generates a weighted average based on a specific query. When all regions and words are unsatisfied with the query, the generated vectors, which are noisy information, may lead to incorrect predictions. In this paper, we propose an Improved Modular Co-attention Network (IMCN) by incorporating the Attention on Attention (AoA) module into the self-attention module and the co-attention module to solve this problem. AoA adds another attention process by using element-wise multiplication on the information vector and the attention gate, which are both generated from the attention result and the current context. With AoA, the attended information obtained by the model is more useful. We also introduce an Improved Multimodal Fusion Network (IMFN), which leverages various branches to achieve hierarchical fusion, to fuse visual features and textual features for further improvements. We conduct extensive experiments on the VQA-v2 dataset to verify the effectiveness of the proposed modules and experimental results demonstrate our model outperforms the existing methods.},
  archive      = {J_APIN},
  author       = {Liu, Cheng and Wang, Chao and Peng, Yan},
  doi          = {10.1007/s10489-024-05456-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5167-5182},
  shortjournal = {Appl. Intell.},
  title        = {IMCN: Improved modular co-attention networks for visual question answering},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A highly efficient ADMM-based algorithm for outlier-robust
regression with huber loss. <em>APIN</em>, <em>54</em>(6), 5147–5166.
(<a href="https://doi.org/10.1007/s10489-024-05370-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Huber robust regression (HRR) has attracted much attention in machine learning due to its greater robustness to outliers compared to least-squares regression. However, existing algorithms for HRR are computationally much less efficient than those for least-squares regression. Based on a maximally split alternating direction method of multipliers (MS-ADMM) for model fitting, a highly computationally efficient algorithm referred to as the modified MS-ADMM is derived in this article for HRR. After analyzing the convergence of the modified MS-ADMM, a parameter selection scheme is presented for the algorithm. With the parameter values calculated via this scheme, the modified MS-ADMM converges very rapidly, much faster than several typical HRR algorithms. Through applications in the training of stochastic neural networks and comparisons with existing algorithms, the modified MS-ADMM is shown to be computationally much more efficient than the convex quadratic programming method, the Newton method, the iterative reweighted least-squares method, and Nesterov’s accelerated gradient method. Implementation of the proposed algorithm on a GPU-based parallel computing platform demonstrates its higher GPU acceleration ratio compared to the competing methods and, thus, its greater superiority in computational efficiency over the competing methods.},
  archive      = {J_APIN},
  author       = {Wang, Tianlei and Lai, Xiaoping and Cao, Jiuwen},
  doi          = {10.1007/s10489-024-05370-9},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5147-5166},
  shortjournal = {Appl. Intell.},
  title        = {A highly efficient ADMM-based algorithm for outlier-robust regression with huber loss},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Graph attention autoencoder model with dual decoder for
clustering single-cell RNA sequencing data. <em>APIN</em>,
<em>54</em>(6), 5136–5146. (<a
href="https://doi.org/10.1007/s10489-024-05442-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell ribonucleic acid sequencing (scRNA-seq) allows researchers to study cell heterogeneity and diversity at the individual cell level. Cell clustering is an essential component of scRNA-seq data processing. However, the high dimensionality and high noise characteristics of scRNA-seq data may pose problems during data processing. Although many methods are available for scRNA-seq clustering analysis, most of them ignore the topological relationships of scRNA-seq data and do not fully utilize the potential associations between cells. In this study, we present scGAD, a graph attention autoencoder model with a dual decoder structure for clustering scRNA-seq data. We utilize a graph attention autoencoder with two decoders to learn feature representations of cells in latent space. To ensure that the learned latent feature representation maintains node properties and graph structure, we use an inner product decoder and a learnable graph attention decoder to reconstruct graph structure and node properties, respectively. On the 12 real scRNA-seq datasets, the average NMI and ARI scores of scGAD are 0.762 and 0.695, respectively, outperforming state-of-the-art single-cell clustering approaches. Biological analysis shows that the cell labels predicted by scGAD can assist in the downstream analysis of scRNA-seq data.},
  archive      = {J_APIN},
  author       = {Wang, Shudong and Zhang, Yu and Zhang, Yuanyuan and Zhang, Yulin and Pang, Shanchen and Su, Jionglong and Liu, Yingye},
  doi          = {10.1007/s10489-024-05442-w},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5136-5146},
  shortjournal = {Appl. Intell.},
  title        = {Graph attention autoencoder model with dual decoder for clustering single-cell RNA sequencing data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SPROSAC: Streamlined progressive sample consensus for
coarse–fine point cloud registration. <em>APIN</em>, <em>54</em>(6),
5117–5135. (<a
href="https://doi.org/10.1007/s10489-024-05400-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of 3D matching technology, point cloud registration (PCR) based on corresponding points has received increasing attention in the field of computer vision. Unfortunately, 3D keypoint technology inevitably produces a large number of outliers. To solve the problems of poor stability, low efficiency and the high number of iterations required to calculate the accepted solution of random sampling consistency (RANSAC) and its variants under a high outlier rate, a streamlined progressive sample consensus (SPROSAC) algorithm is proposed in this paper. SPROSAC is an improved estimator of progressive sample consensus that guides the sampling process by increasing the use of 3D point cloud surface information and optimizes the model verification process based on registration error decision acceptance. Compared to classic RANSAC-family algorithms, SPROSAC has a greater probability of obtaining an accepted solution more quickly. The experiments demonstrate that SPROSAC achieves significantly smaller and more stable registration errors with fewer iterations across three datasets. In the performance experiments based on evaluation metrics such as recall, 1-precision, and F1 score for inlier classification, SPROSAC demonstrates the best performance across the three datasets, with outlier rates exceeding 95%. Furthermore, we propose a coarse–fine PCR algorithm based on SPROSAC and ICP to address the issues of high initialization requirements, susceptibility to local optima, and low efficiency in traditional ICP algorithms. The experimental results of coarse–fine registration show that our algorithm provides initial values for the ICP, which can reduce the number of iterations of the ICP by 50%, 64.4%, and 57.4%.},
  archive      = {J_APIN},
  author       = {Liu, Zeyuan and Yue, Xiaofeng and Zhu, Juan},
  doi          = {10.1007/s10489-024-05400-6},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5117-5135},
  shortjournal = {Appl. Intell.},
  title        = {SPROSAC: Streamlined progressive sample consensus for coarse–fine point cloud registration},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). BiLSTM-TANet: An adaptive diverse scenes model with context
embeddings for few-shot learning. <em>APIN</em>, <em>54</em>(6),
5097–5116. (<a
href="https://doi.org/10.1007/s10489-024-05440-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning is a critical task in computer vision processing that helps reduce deep learning’s reliance on large datasets. This paper aims to establish a few-shot learning network that is adaptive to diverse scenes. A novel approach referred to as task-adapted network with bi-directional long short-term memory network (BiLSTM-TANet) is proposed in this paper. BiLSTM-TANet is an end-to-end approach based on deep metric learning and designed to use the information from finite samples as much as possible. It fuses the context embeddings and structure information of the images and adaptively adjusts the features several times during the feature extraction of task to achieve task-specific embedding and quickly adapt to different distributed tasks, improves the feature extraction performance, and strikes a balance between model stability and generality. The model employs Euclidean distance as the classifier to reduce the number of model parameters and enhance the classification performance. Experiments conducted on miniImageNet, TieredImageNet, CUB200_2011 and CIFAR-FS datasets demonstrate the performance of the proposed BiLSTM-TANet. Furthermore, the effects of different few-shot learning parameters on the model’s performance are explored, providing a helpful reference for the future study of few-shot learning. Finally, a series of ablation studies are performed to analyze the performance of BiLSTM-TANet.},
  archive      = {J_APIN},
  author       = {Zhang, He and Liu, Han and Liang, Lili and Ma, Wenlu and Liu, Ding},
  doi          = {10.1007/s10489-024-05440-y},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5097-5116},
  shortjournal = {Appl. Intell.},
  title        = {BiLSTM-TANet: An adaptive diverse scenes model with context embeddings for few-shot learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PD-GATv2: Positive difference second generation graph
attention network based on multi-granularity in information systems to
classification. <em>APIN</em>, <em>54</em>(6), 5081–5096. (<a
href="https://doi.org/10.1007/s10489-024-05432-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Graph Attention Network (GAT) is a widely recognized architecture in the field of Graph Neural Networks (GNNs). It is considered the state-of-the-art approach for graph representation learning. In recent years, several researchers have successfully applied GAT to structured Euclidean data, including images and languages. Additionally, the Graph Convolutional Network (GCN) has also been adopted in information systems, such as PN-GCN, which establishes undirected graphs for classification. However, compared to undirected graphs, directed graphs contain directional information that more comprehensively describes the relations between objects in the graph. Therefore, we establish a directed graph in the information system and further analyze it using GAT. As a first step, this article introduces the concept of multi-granularity object directed weighted graphs. Then, we construct the second generation of the residual edge-weighted graph attention neural network model (PD-GATv2) based on these directed graphs. Finally, we verify the effectiveness and generalizability of the PD-GATv2 algorithm through experiments, and its effectiveness is further demonstrated through ablation experiments.},
  archive      = {J_APIN},
  author       = {Fu, Yu and Liu, Xindi and Yu, Bin},
  doi          = {10.1007/s10489-024-05432-y},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5081-5096},
  shortjournal = {Appl. Intell.},
  title        = {PD-GATv2: Positive difference second generation graph attention network based on multi-granularity in information systems to classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relational reasoning and adaptive fusion for visual question
answering. <em>APIN</em>, <em>54</em>(6), 5062–5080. (<a
href="https://doi.org/10.1007/s10489-024-05437-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual relationship modeling plays an indispensable role in visual question answering (VQA). VQA models need to fully understand the visual scene and positional relationships within the image to answer complex reasoning questions involving visual object relationships. Accurate reasoning and an understanding of the relationships between different visual objects are particularly crucial. However, most reasoning models used in current VQA tasks only use simple attention mechanisms to model visual object relationships and ignore the potential for effective modeling using rich visual object features during the learning process. This work proposes an effective visual object Relationship Reasoning and Adaptive Fusion (RRAF) model to address the shortcomings of existing VQA model research. RRAF can simultaneously model visual objects’ position, appearance, and semantic features and uses an adaptive fusion mechanism to achieve fine-grained multimodal reasoning and fusion. Specifically, we designed an effective image encoder to model and learn the relationship between the position and appearance features of visual objects. In addition, in the co-attention module, we employ semantic information from the question to focus on critical visual objects. Finally, we use an adaptive fusion mechanism to reassign weights and fuse different modalities of features to effectively predict the answer. Experimental results show that the RRAF model outperforms current state-of-the-art methods on the VQA 2.0 and GQA datasets, especially in visual object counting problems. We also conducted extensive ablation experiments to demonstrate the effectiveness of the RRAF model, achieving an overall accuracy of 71.33% and 57.83% on the VQA 2.0 and GQA datasets, respectively. Code is available at https://github.com/shenxiang-vqa/RRAF .},
  archive      = {J_APIN},
  author       = {Shen, Xiang and Han, Dezhi and Zong, Liang and Guo, Zihan and Hua, Jie},
  doi          = {10.1007/s10489-024-05437-7},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5062-5080},
  shortjournal = {Appl. Intell.},
  title        = {Relational reasoning and adaptive fusion for visual question answering},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robot grasping detection network based on flexible
selection of multi-modal feature fusion structure. <em>APIN</em>,
<em>54</em>(6), 5044–5061. (<a
href="https://doi.org/10.1007/s10489-024-05427-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unstructured scenarios, objects usually have unique shapes, poses, and other uncertainties, which put forward higher requirements for the robot’s planar grasping detection ability. Most previous methods use single-modal data or simply fused multi-modal data to predict gripper configurations. Single-modal data is not conducive to comprehensively describe the diversity of objects, and the simple fusion method may also ignore the dependencies between multi-modal data. Based on the above considerations, we propose a Multi-modal Dynamic Cooperative Fusion Network (MDCNet), in which a Multilevel Semantic Guided Fusion Module (MSG) is designed, through which enhanced semantic guidance vectors are used to suppress the undesired influence factors produced by different fusion structures. In addition, we also design a general Enhanced Feature Pyramid Nets Structure (EFPN) to learn the dependencies between fine-grained features and coarse-grained features and improve the robustness of the encoder in unstructured scenarios. The results show that the proposed method has an accuracy rate of 98.9% on the Jacquard dataset and 99.6% on the Cornell dataset. In over 2000 robotic grasp trials, our structure achieves a grasp success rate of 98.8% in single-object scenarios and 93.5% in cluttered scenarios. The proposed method in this paper is superior to previous grasp detection methods in both speed and accuracy, and has strong real-time performance.},
  archive      = {J_APIN},
  author       = {Wang, Yuhan and Guo, Zhibo and Chen, Yu and Guo, Chaiqi and Xia, Meizhen and Qi, Tingyue},
  doi          = {10.1007/s10489-024-05427-9},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5044-5061},
  shortjournal = {Appl. Intell.},
  title        = {A robot grasping detection network based on flexible selection of multi-modal feature fusion structure},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SS-MVMETRO: Semi-supervised multi-view human mesh recovery
transformer. <em>APIN</em>, <em>54</em>(6), 5027–5043. (<a
href="https://doi.org/10.1007/s10489-024-05435-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parametric methods are widely utilized in RGB-based human mesh recovery, relying on precise statistical human body model parameters that are challenging to obtain. In contrast, non-parametric transformer-based approaches excel but are applied only to monocular RGB tasks. To address these limitations, this paper presents Semi-Supervised Multi-View Human Mesh Recovery Transformer (SS-MVMETRO), which combines multi-view information with non-parametric methods for the first time. Our model encodes different images according to their respective view directions, fusing local features around key points of joints and vertices. Then, a residual-like structure is proposed to integrate the fused features in the mesh recovery transformer, which subsequently predicts the 3D coordinates of the human mesh vertices. Additionally, we divide different views into the main view and auxiliary views and propose a semi-supervised training approach that requires fewer matching labels. The efficacy of our work is validated on two datasets, Human3.6M and Mpi_inf_3dph, through quantitative and qualitative experiments. The results indicate that SS-MVMETRO improves the reconstruction accuracy, surpassing previous image-based methods by at least 8.9% in terms of Procrustes Analysis Mean-Per-Joint-Position-Error (PA-MPJPE).},
  archive      = {J_APIN},
  author       = {Sheng, Silong and Zheng, Tianyou and Ren, Zhijie and Zhang, Yang and Fu, Weiwei},
  doi          = {10.1007/s10489-024-05435-9},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5027-5043},
  shortjournal = {Appl. Intell.},
  title        = {SS-MVMETRO: Semi-supervised multi-view human mesh recovery transformer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polyphonic sound event localization and detection using
channel-wise FusionNet. <em>APIN</em>, <em>54</em>(6), 5015–5026. (<a
href="https://doi.org/10.1007/s10489-024-05438-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sound Event Localization and Detection (SELD) is the task of spatial and temporal localization of various sound events and their classification. Commonly, multitask models are used to perform SELD. In this work, a deep learning network model named channel-wise ‘FusionNet’ is designed to perform the SELD task. The novel fusion layer is introduced into the regular Deep Neural Network (DNN), where the input is fed channel-wise, and the outputs of all channels are fused to form a new feature representation. The key contribution of this work is the neural network model which helps to retain the channel-wise information from the multichannel input along with the spatial and temporal information. The proposed network utilizes separable convolution blocks in the convolution layers, therefore, the complexity of the model is low in terms of both time and space. The features used as input are Mel-band energies for Sound Event Detection (SED) and intensity vectors for the Direction-of-Arrival (DOA) estimation. The proposed network’s fusion layer provides a better representation of features for both SED and DOA estimation tasks. Experiments are performed on the recordings of the First-order Ambisonic (FOA) array format of the TAU-NIGENS Spatial Sound Events 2020 dataset. An improved performance is achieved in terms of Error Rate (ER), DOA error, and Frame Recall (FR) has been observed in comparison to the state-of-the-art SELD systems.},
  archive      = {J_APIN},
  author       = {V., Spoorthy and Kooolagudi, Shashidhar G.},
  doi          = {10.1007/s10489-024-05438-6},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {5015-5026},
  shortjournal = {Appl. Intell.},
  title        = {Polyphonic sound event localization and detection using channel-wise FusionNet},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-knowledge distillation enhanced binary neural networks
derived from underutilized information. <em>APIN</em>, <em>54</em>(6),
4994–5014. (<a
href="https://doi.org/10.1007/s10489-024-05444-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binarization efficiently compresses full-precision convolutional neural networks (CNNs) to achieve accelerated inference but with substantial performance degradations. Self-knowledge distillation (SKD) can significantly improve the performance of a network by inheriting its own advanced knowledge. However, SKD for binary neural networks (BNNs) remains underexplored because the binary characteristics of weak BNNs limit their ability to act as effective teachers, hindering their ability to learn as students. In this study, a novel SKD-BNN framework is proposed by using two pieces of underutilized information. Full-precision weights, which are applied for gradient transfer, concurrently distill the feature knowledge of the teacher with high-level semantics. A value-swapping strategy minimizes the knowledge capacity gap, while the channel-spatial difference distillation loss promotes feature transfer. Moreover, historical output predictions generate a concentrated soft-label bank, providing abundant intra- and inter-category similarity knowledge. Dynamic filtering ensures the correctness of the soft labels during training, and the label-cluster loss enhances the summarization ability of the soft-label bank within the same category. The developed methods excel in extensive experiments, achieving state-of-the-art accuracy of 93.0% on the CIFAR-10 dataset, which is equivalent to that of full-precision CNNs. On the ImageNet dataset, the accuracy improves by 1.6% with the widely adopted IR-Net. It is emphasized that for the first time, the proposed method fully explores the underutilized information contained in BNNs and conducts an effective SKD process, enabling weak BNNs to serve as competent self-teachers and proficient students.},
  archive      = {J_APIN},
  author       = {Zeng, Kai and Wan, Zixin and Gu, HongWei and Shen, Tao},
  doi          = {10.1007/s10489-024-05444-8},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4994-5014},
  shortjournal = {Appl. Intell.},
  title        = {Self-knowledge distillation enhanced binary neural networks derived from underutilized information},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling essay grading with pre-trained BERT features.
<em>APIN</em>, <em>54</em>(6), 4979–4993. (<a
href="https://doi.org/10.1007/s10489-024-05410-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writing essays is an important skill which enables one to clearly write the ideas and understanding of certain topic with the help of language articulation and examples. Writing essay is a skill so is the grading of those essays. It requires a lot of efforts to grade these essays and the task becomes tedious and repetitive when the student to teacher ratio is high. As with any other repetitive task, the intervention of technology for automated essay grading has been thought of long back. However, the main challenge in automated essay grading lies in the understanding of language construction, word usage and presentation of idea/ argument/ narration. Language complexity makes natural language understanding a challenging task. In this work, we show our experiments with pre-trained static word embeddings like GloVe, fastText and pre-trained contextual model Bidirectional Encoder Representations from Transformers (BERT) for the task of automated essay grading. For the regression task, we have used Long Short-Term Memory (LSTM) and Support Vector Regression (SVR) models under various feature settings framed from the learnt embeddings. The results are shown with the ASAP-AES dataset on all 8 prompts. Our work shows average Quadratic Weighted Kappa (QWK) of 0.81 and 0.71 with SVR and LSTM on in-domain test set essays, respectively. The SVR model shows a better QWK than the human-human agreement of 0.75. To the best of our knowledge, our SVR model with pre-trained BERT embeddings achieve the highest average QWK reported on ASAP-AES data set. We further show the performance of our approach with adversary samples generated using permuted essays and off-topic essays. We experimentally show that our LSTM model though does not show high QWK score with human assigned grade but is robust against the adversarial settings considered.},
  archive      = {J_APIN},
  author       = {Sharma, Annapurna and Jayagopi, Dinesh Babu},
  doi          = {10.1007/s10489-024-05410-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4979-4993},
  shortjournal = {Appl. Intell.},
  title        = {Modeling essay grading with pre-trained BERT features},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple reference points-based multi-objective feature
selection for multi-label learning. <em>APIN</em>, <em>54</em>(6),
4952–4978. (<a
href="https://doi.org/10.1007/s10489-024-05387-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, data often exhibits high-dimensional and complex characteristics. In addition, an object may correspond to multiple class labels. Therefore, filtering and processing such data has become a hot research topic. Multi-label feature selection is one of the key preprocessing techniques for effectively solving redundant information. However, due to the high complexity of multi-label learning feature selection and involving optimization of multiple objectives, careful consideration is required to achieve effective optimization. To address these issues, this paper proposes a multiple reference points-based multi-objective feature selection for multi-label learning. Firstly, the neighborhood crossover strategy utilizes individuals in the same neighborhood for crossover, thereby enhancing the search effect within that decision space. The distribution-based mutation strategy adjusts the mutation probability of different features based on their distribution in selected candidate solutions to increase the likelihood of potentially useful features being selected. Secondly, the multiple reference points-based selection strategy uses a scalar function to uniformly evaluate offspring individuals and control their distance from each other through multiple reference points. This approach helps in selecting convergent solutions with balanced diversity. Finally, experimental results demonstrate that the proposed algorithm attains an optimal performance of 83% across fourteen widely used datasets, outperforming ten state-of-the-art algorithms in terms of effectiveness and performance in multi-label feature selection.},
  archive      = {J_APIN},
  author       = {Chen, Yangtao and Qian, Wenbin},
  doi          = {10.1007/s10489-024-05387-0},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4952-4978},
  shortjournal = {Appl. Intell.},
  title        = {Multiple reference points-based multi-objective feature selection for multi-label learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-object behaviour recognition based on object detection
cascaded image classification in classroom scenes. <em>APIN</em>,
<em>54</em>(6), 4935–4951. (<a
href="https://doi.org/10.1007/s10489-024-05409-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multi-object behaviour recognition in classroom scenes, crowded objects have heavy occlusion, invisible keypoints, scale variation, which directly overwhelms the recognition performance. Due to the dense student objects and similar student behaviours, multi-object behaviour recognition brings great challenges. Therefore, we proposed multi-object behaviour recognition based on object detection cascaded image classification. Specifically, object detection extracts student objects, followed by Vision Transformer (ViT) classification of student behaviour. To ensure the accuracy of behaviour recognition, it is first necessary to improve the detection performance of object detection. This paper proposes the Shallow Auxiliary Module for object detection to assist the backbone network in extracting hybrid multi-scale feature information. The multi-scale and multi-channel feature information is fused to alleviate object overlap and scale variation. We propose a Scale Assignment Fusion Mechanism that non-heuristically guides objects to learn the optimal feature layer. Furthermore, the Anchor-free Dynamic Label Assignment can suppress the prediction of low-quality bounding boxes, stabling training and improving detection performance. The proposed student object detector achieves the state-of-the-art mAP $$^{50}$$ of 88.03 and AP $$_l$$ of 57.64, outperforming state-of-the-art object detection methods. Our multi-object behaviour recognition method achieves the recognition of four behaviour classes, which is significantly better than the results of other comparison methods.},
  archive      = {J_APIN},
  author       = {Dang, Min and Liu, Gang and Li, Hao and Xu, Qijie and Wang, Xu and Pan, Rong},
  doi          = {10.1007/s10489-024-05409-x},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4935-4951},
  shortjournal = {Appl. Intell.},
  title        = {Multi-object behaviour recognition based on object detection cascaded image classification in classroom scenes},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Causal inference in the medical domain: A survey.
<em>APIN</em>, <em>54</em>(6), 4911–4934. (<a
href="https://doi.org/10.1007/s10489-024-05338-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference is considered a crucial topic in the medical field, as it enables the determination of causal effects for medical treatments through data analysis. However, the vast volume and complexity of medical data present significant challenges for traditional machine learning methods in accurately assessing treatment effects. Issues such as noise in the data, unstructured information, and label sparsity can lead to unstable causal identification and erroneous correlation inference. To address these challenges, we propose a systematic survey of causal inference in the medical field, which encompasses studies utilizing observational data, aimed at organizing and summarizing the key concepts, methods, and applications of causal inference. Moreover, the causal inference applications are presented across various types of medical data, including medical images and Electronic Medical Records (EMR), using specific medical cases as examples. The thorough review not only emphasizes the theoretical and practical significance of causal inference methods but also highlights potential research directions in the medical domain.},
  archive      = {J_APIN},
  author       = {Wu, Xing and Peng, Shaoqi and Li, Jingwen and Zhang, Jian and Sun, Qun and Li, Weimin and Qian, Quan and Liu, Yue and Guo, Yike},
  doi          = {10.1007/s10489-024-05338-9},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4911-4934},
  shortjournal = {Appl. Intell.},
  title        = {Causal inference in the medical domain: A survey},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental feature selection approach to multi-dimensional
variation based on matrix dominance conditional entropy for ordered data
set. <em>APIN</em>, <em>54</em>(6), 4890–4910. (<a
href="https://doi.org/10.1007/s10489-024-05411-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory is a mathematical tool widely employed in various fields to handle uncertainty. Feature selection, as an essential and independent research area within rough set theory, aims to identify a small subset of important features by eliminating irrelevant, redundant, or noisy ones. In human life, data characteristics constantly change over time and other factors, resulting in ordered datasets with varying features. However, existing feature extraction methods are not suitable for handling such datasets since they do not consider previous reduction results when features change and need to be recomputed, leading to significant time consumption. To address this issue, the incremental attribute reduction algorithm utilizes prior reduction results effectively reducing computation time. Motivated by this approach, this paper investigates incremental feature selection algorithms for ordered datasets with changing features. Firstly, we discuss the dominant matrix and the dominance conditional entropy while introducing update principles for the new dominant matrix and dominance diagonal matrix when features change. Subsequently, we propose two incremental feature selection algorithms for adding (IFS-A) or deleting (IFS-D) features in ordered data set. Additionally, nine UCI datasets are utilized to evaluate the performance of our proposed algorithm. The experimental results validate that the average classification accuracy of IFS-A and IFS-D under four classifiers on twelve datasets is 82.05% and 80.75%, which increases by 5.48% and 3.68% respectively compared with the original data.},
  archive      = {J_APIN},
  author       = {Xu, Weihua and Yang, Yifei and Ding, Yi and Chen, Xiyang and Lv, Xiaofang},
  doi          = {10.1007/s10489-024-05411-3},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4890-4910},
  shortjournal = {Appl. Intell.},
  title        = {Incremental feature selection approach to multi-dimensional variation based on matrix dominance conditional entropy for ordered data set},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Domain generalization based on domain-specific adversarial
learning. <em>APIN</em>, <em>54</em>(6), 4878–4889. (<a
href="https://doi.org/10.1007/s10489-024-05423-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models often suffer from degraded performance when the distributions of the training and testing data differ (i.e., domain shift). Domain generalization (DG) techniques can help improve the generalization performance for unseen target domains by using multiple source domains. The recently developed domain generalization methods focus on extracting domain-invariant features from all source domains. However, some task-relevant discriminative information can be removed during this process. In addition, the various source domains are treated equally ignoring the negative impacts of distant source domains. Both problems can lead to unsatisfactory performance. This paper proposed a domain-specific adversarial neural network (DSANN) based on adversarial learning to learn effective feature representations and reduce the influence of distantsource domains. The DSANN introduces a reference distribution that is adaptively generated during training. Additionally, domain-invariant features are extracted through a domain-specific adversarial learning process , in which each source domain distribution is aligned only with the reference distribution instead of all the other source domains. Moreover, the DSANN also aligns the outputs of multiple classifiers and adopts the weighted average of the predictions; thus, the employed label classifiers can become more robust to unknown domain shifts. Experiments conducted on popular benchmark datasets demonstrate that our proposed method can achieve remarkable generalization performance and has better classification accuracy than the existing DG algorithms.},
  archive      = {J_APIN},
  author       = {Wang, Ziping and Zhang, Xiaohang and Li, Zhengren and Chen, Fei},
  doi          = {10.1007/s10489-024-05423-z},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4878-4889},
  shortjournal = {Appl. Intell.},
  title        = {Domain generalization based on domain-specific adversarial learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resource allocation in heterogeneous network with node and
edge enhanced graph attention network. <em>APIN</em>, <em>54</em>(6),
4865–4877. (<a
href="https://doi.org/10.1007/s10489-024-05391-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless networks, the effectiveness of beamforming and power allocation strategies is crucial in meeting the increasing data demands of users and ensuring rapid data transmission. Graph learning approaches have been developed to tackle complex challenges in wireless communications and have shown promising results. However, most existing graph learning methods primarily focus on node features, neglecting the potential benefits of leveraging rich information from edge features. This study addresses this limitation and proposes a novel framework called Heterogeneous Node and Edge Graph Neural Network (HNENN). Specifically designed for heterogeneous networks, HNENN incorporates node-level and edge-level attention layers to learn and aggregate node and edge embeddings. The alternating stacking of these two layers facilitates the mutual enhancement of node and edge embeddings. Simulations show that the proposed framework works better than state-of-the-art approaches, getting a higher sum rate in different scenarios with different numbers of D2D pairs, training samples, interference levels, and transmit power budgets.},
  archive      = {J_APIN},
  author       = {Sun, Qiushi and He, Yang and Petrosian, Ovanes},
  doi          = {10.1007/s10489-024-05391-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4865-4877},
  shortjournal = {Appl. Intell.},
  title        = {Resource allocation in heterogeneous network with node and edge enhanced graph attention network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FeSTGCN: A frequency-enhanced spatio-temporal graph
convolutional network for traffic flow prediction under adaptive signal
timing. <em>APIN</em>, <em>54</em>(6), 4848–4864. (<a
href="https://doi.org/10.1007/s10489-024-05401-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is the fundamental cornerstone of intelligent urban transportation systems. However, existing research has predominantly focused on exploring spatiotemporal dependencies within the spatial and temporal domains, often overlooking the frequency information present in traffic data. This study aims to address this limitation by simultaneously modelling the temporal, spatial, and frequency domain dependencies of traffic flow, thereby proposing a novel model called the frequency-enhanced spatiotemporal graph convolutional network (FeSTGCN) for enhanced accuracy and interpretability in traffic flow prediction. Specifically, this study devises an approach that utilises a time–frequency transformation method to extract frequency-domain information from traffic flow. Spatiotemporal domain dependencies were captured using an attention-based diffusion graph and temporal convolutions. Extensive experiments were conducted on a real-world road network using adaptive signal timing. The results demonstrate that the FeSTGCN is highly competitive compared with state-of-the-art models. Furthermore, the FeSTGCN exhibits excellent interpretability as frequency information provides novel insights into the composition and intrinsic patterns of traffic flow.},
  archive      = {J_APIN},
  author       = {Huang, Hai-chao and Chen, Zhi-heng and Li, Bo-wen and Ma, Qing-hai and He, Hong-di},
  doi          = {10.1007/s10489-024-05401-5},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4848-4864},
  shortjournal = {Appl. Intell.},
  title        = {FeSTGCN: A frequency-enhanced spatio-temporal graph convolutional network for traffic flow prediction under adaptive signal timing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Network traffic grant classification based on 1DCNN-TCN-GRU
hybrid model. <em>APIN</em>, <em>54</em>(6), 4834–4847. (<a
href="https://doi.org/10.1007/s10489-024-05375-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate grant classification of network traffic not only assists service providers in making acceptable allocations based on actual business demands, but also ensures service quality. To further improve the accuracy of traffic classification, we propose a hybrid method of 1DCNN-TCN-GRU for traffic data authorized classification. The proposed hybrid model extracts more complex features by combining the advantages of one-dimensional convolutional neural network (1DCNN), temporal convolutional network (TCN) and gated recurrent unit (GRU). 1DCNN is used to extract the spatial features of the original data. TCN is used to further extract the temporal features. GRU is used to extract the long term dependencies and classify them. We conducted experiments on two datasets Huya live data and WeChat voice data. A comparison against various other algorithms is carried out to show the superiority of the proposed hybrid approach. Therefore, four evaluation metrics, namely, accuracy, precision, recall and F1 score are chosen to assess the classification results numerically. The experimental results on two real-life datasets show that the proposed hybrid algorithm outperforms other algorithms in network traffic grant classification and has certain effectiveness.},
  archive      = {J_APIN},
  author       = {Mo, Lina and Qi, Xiaogang and Liu, Lifang},
  doi          = {10.1007/s10489-024-05375-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4834-4847},
  shortjournal = {Appl. Intell.},
  title        = {Network traffic grant classification based on 1DCNN-TCN-GRU hybrid model},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A hybrid information-based two-phase expansion algorithm
for community detection with imbalanced scales. <em>APIN</em>,
<em>54</em>(6), 4814–4833. (<a
href="https://doi.org/10.1007/s10489-024-05424-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scale of communities in real-world networks is often imbalanced, which has a significant impact on community detection performance. Existing approaches exhibit a trade-off between accuracy and computational cost, with global methods offering higher accuracy but requiring intensive computations, and local methods accelerating the detection at the expense of accuracy. Despite these challenges, few works concentrate on how to effectively handle community detection with imbalanced community scales. To address this gap, first, a hybrid method that combines global and local information in the network is proposed to identify core nodes. This involves incorporating hierarchical structural information used to measure the global influence of the node, together with the effective local boundaries ensuring even distribution of core nodes in the network, to alleviate the impact of community scale imbalance. Second, we propose a two-phase expansion strategy to handle the imbalance scale of communities and prevent over-expansion of a single structure. In the first phase of the strategy, the belonging function is proposed to better measure the strength of connections between the current node and the other nodes for local community expansion. In the second phase of the strategy, we present a weighted label propagation method to efficiently expand the unlabeled boundary nodes and the nodes with overlapping attributes. Extensive experiments were conducted over twenty networks in comparison with eight state-of-the-art baseline methods, demonstrating that CONTEX is very competitive to these methods in achieving higher accuracy of community detection, while maintaining a relevantly lower computational time.},
  archive      = {J_APIN},
  author       = {Liu, Shiliang and Zhang, Xinyao and Ma, Yinglong},
  doi          = {10.1007/s10489-024-05424-y},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4814-4833},
  shortjournal = {Appl. Intell.},
  title        = {A hybrid information-based two-phase expansion algorithm for community detection with imbalanced scales},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual contextual relationship augmented transformer for
image captioning. <em>APIN</em>, <em>54</em>(6), 4794–4813. (<a
href="https://doi.org/10.1007/s10489-024-05416-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image captioning task is among the most important tasks in computer vision. Most existing methods mine more useful contextual information from image features. Similarly, to mine more contextual information, this paper proposes a visual contextual relationship augmented transformer (VRAT) method for improving the correctness of image description statements. In VRAT, visual contextual features are enhanced by using a pre-trained visual contextual relationship augmented module (VRAM). In VRAM, we classify images into three categories: globe, object, and grid, and use encoders of CLIP and ResNext to encode images and text to supplement the original image descriptions with visual and textual features. Finally, a similarity retrieval model is constructed to match global features, object features, and grid features for contextual relationships. During model training, our model supplements the original image captioning model with global, object, and grid visual features and textual features. In addition, to improve the quality of the attention-focused image features, we propose an attention augmented module (AAM) that adds a compensated attention module to the original multi-head attention, which allows a large number of image features in the model to focus more on important information and filter out some unimportant attention information. To alleviate the imbalance of positive and negative samples during training, we propose a multi-label focal loss in the model and combine it with the original cross-entropy loss function to improve the performance of the model. Experiments on the MSCOCO image description benchmark dataset show that the proposed method can perform well and outperform many existing state-of-the-art methods. The improvement in the CIDEr score and BLEU-1 score over the baseline model was 7.7 and 1.5, respectively.},
  archive      = {J_APIN},
  author       = {Su, Qiang and Hu, Junbo and Li, Zhixin},
  doi          = {10.1007/s10489-024-05416-y},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4794-4813},
  shortjournal = {Appl. Intell.},
  title        = {Visual contextual relationship augmented transformer for image captioning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Resolution-sensitive self-supervised monocular absolute
depth estimation. <em>APIN</em>, <em>54</em>(6), 4781–4793. (<a
href="https://doi.org/10.1007/s10489-024-05414-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation is an essential component of computer vision applications for environment perception, 3D reconstruction and scene understanding. Among the available methods, self-supervised monocular depth estimation is noteworthy for its cost-effectiveness, ease of installation and data accessibility. However, there are two challenges with current methods. Firstly, the scale factor of self-supervised monocular depth estimation is uncertain, which poses significant difficulties for practical applications. Secondly, the depth prediction accuracy for high-resolution images is still unsatisfactory, resulting in low utilization of computational resources. We propose a novel solution to address these challenges with three specific contributions. Firstly, an interleaved depth network skip-connection structure and a new depth network decoder are proposed to improve the depth prediction accuracy for high-resolution images. Secondly, a data vertical splicing module is suggested as a data enhancement method to obtain more non-vertical features and improve model generalization. Lastly, a scale recovery module is proposed to recover the accurate absolute depth without additional sensors, which solves the issue of uncertainty in the scale factor. The experimental results demonstrate that the proposed framework significantly improves the prediction accuracy of high-resolution images. In particular, the novel network structure and data vertical splicing module contribute significantly to this improvement. Moreover, in a scenario where the camera height is fixed and the ground is flat, the effect of scale recovery module is comparable to that achieved by using ground truth. Overall, the RSANet framework offers a promising solution to solve the existing challenges in self-supervised monocular depth estimation.},
  archive      = {J_APIN},
  author       = {Zhou, Yuquan and Zhang, Chentao and Deng, Lianjun and Fu, Jianji and Li, Hongyi and Xu, Zhouyi and Zhang, Jianhuan},
  doi          = {10.1007/s10489-024-05414-0},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4781-4793},
  shortjournal = {Appl. Intell.},
  title        = {Resolution-sensitive self-supervised monocular absolute depth estimation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel lightweight CNN for chest x-ray-based lung disease
identification on heterogeneous embedded system. <em>APIN</em>,
<em>54</em>(6), 4756–4780. (<a
href="https://doi.org/10.1007/s10489-024-05420-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global spread of epidemic lung diseases, including COVID-19, underscores the need for efficient diagnostic methods. Addressing this, we developed and tested a computer-aided, lightweight Convolutional Neural Network (CNN) for rapid and accurate identification of lung diseases from 29,131 aggregated Chest X-ray (CXR) images representing seven disease categories. Employing the five-fold cross-validation method to ensure the robustness of our results, our CNN model, optimized for heterogeneous embedded devices, demonstrated superior diagnostic performance. It achieved a 98.56% accuracy, outperforming established networks like ResNet50, NASNetMobile, Xception, MobileNetV2, DenseNet121, and ViT-B/16 across precision, recall, F1-score, and AUC metrics. Notably, our model requires significantly less computational power and only 55 minutes of average training time per fold, making it highly suitable for resource-constrained environments. This study contributes to developing efficient, lightweight networks in medical image analysis, underscoring their potential to enhance point-of-care diagnostic processes.},
  archive      = {J_APIN},
  author       = {Sanida, Theodora and Dasygenis, Minas},
  doi          = {10.1007/s10489-024-05420-2},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4756-4780},
  shortjournal = {Appl. Intell.},
  title        = {A novel lightweight CNN for chest X-ray-based lung disease identification on heterogeneous embedded system},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Physics-informed deep learning to quantify anomalies for
real-time fault mitigation in 3D printing. <em>APIN</em>,
<em>54</em>(6), 4736–4755. (<a
href="https://doi.org/10.1007/s10489-024-05402-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 3D printing processes, there are many thermal stress related defects that can have a significant negative impact on the shape and size of the structure. Such anomalies in the heat transfer of the printing process need to be detected at an early stage. Understanding heat transfer is crucial, and simulation models can offer insights while reducing the need for costly experiments. Traditional numerical solvers for heat transfer can be complex to adapt to diverse printed part geometries, and their reliance on predefined mathematical models limits their flexibility. Our physics-informed deep learning (PIDL) approach eliminates the need for discretization, simplifying the analysis of complex geometries and enabling automation. The drawback of parametric PIDL is their scalability for high-dimensional problems. Computational time, energy and cost of training prevent real-time analysis. It often takes only a few seconds to print a single layer. We can show an energy efficient transfer and training strategy to reduce the computational effort of PIDL significantly. The approach is able to quantify relevant effects of thermal stresses and mitigate errors during selective laser melting (SLM). To this end, heat transfer is modelled, simulated and analysed using high-dimensional data obtained from printing experiments with different geometries of metal components. The proposed method is applied to the solving forward problem of heat transfer prediction. The governing results are based on the heat equation, which is integrated into a deep neural network (DNN).},
  archive      = {J_APIN},
  author       = {Uhrich, Benjamin and Pfeifer, Nils and Schäfer, Martin and Theile, Oliver and Rahm, Erhard},
  doi          = {10.1007/s10489-024-05402-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4736-4755},
  shortjournal = {Appl. Intell.},
  title        = {Physics-informed deep learning to quantify anomalies for real-time fault mitigation in 3D printing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Task attention-based multimodal fusion and curriculum
residual learning for context generalization in robotic assembly.
<em>APIN</em>, <em>54</em>(6), 4713–4735. (<a
href="https://doi.org/10.1007/s10489-024-05417-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of flexible manufacturing, Deep Reinforcement Learning (DRL) has emerged as a pivotal technology for robotic assembly tasks. Despite advancements in sample efficiency and interaction safety through residual reinforcement learning with initial policies, challenges persist in achieving context generalization amidst stochastic systems characterized by large random errors and variable backgrounds. Addressing these challenges, this study introduces a novel framework that integrates task attention-based multimodal fusion with an adaptive error curriculum within a residual reinforcement learning paradigm. Our approach commences with the formulation of a task attention-based multimodal policy that synergizes task-centric visual, relative pose, and tactile data into a compact, end-to-end model. This model is explicitly designed to enhance context generalization by improving observability, thereby ensuring robustness against stochastic errors and variable backgrounds. The second facet of our framework, curriculum residual learning, introduces an adaptive error curriculum that intelligently modulates the guidance and constraints of a model-based feedback controller. This progression from perfect to significantly imperfect initial policies incrementally enhances policy robustness and learning process stability. Empirical validation demonstrates the capability of our method to efficiently acquire a high-precision policy for assembly tasks with clearances as tight as 0.1 mm and error margins up to 20 mm within a 3.5-hour training window-a feat challenging for existing RL-based methods. The results indicate a substantial reduction in average completion time by 75 $$\%$$ and a 34 $$\%$$ increase in success rate over the classical two-step approach. An ablation study was conducted to assess the contribution of each component within our framework. Real-world task experiments further corroborate the robustness and generalization of our method, achieving over a 90 $$\%$$ success rate in variable contexts.},
  archive      = {J_APIN},
  author       = {Wang, Chuang and Lin, Ze and Liu, Biao and Su, Chupeng and Chen, Gang and Xie, Longhan},
  doi          = {10.1007/s10489-024-05417-x},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4713-4735},
  shortjournal = {Appl. Intell.},
  title        = {Task attention-based multimodal fusion and curriculum residual learning for context generalization in robotic assembly},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). R-CCF: Region-aware continual contrastive fusion for weakly
supervised object detection. <em>APIN</em>, <em>54</em>(6), 4689–4712.
(<a href="https://doi.org/10.1007/s10489-024-05403-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly-supervised learning has emerged as a compelling method for object detection by reducing the fully annotated labels requirement in the training procedure. Recently, some works have treated the detection task as a classification task, resulting in highlighting only discriminative object parts. Moreover, fully-supervised object detectors use specific modules (e.g. feature pyramid networks (FPN) and region proposal network (RPN)) to accurately localize target objects, while weakly-supervised object detectors, such as a well-designed module for object localization, rarely exist. To address the above challenges and gaps, we propose a region-aware continual contrastive fusion (R-CCF) module, which can be plugged into any off-the-shelf weak detector to improve detection performance by refining object location. Specifically, a novel region association (RA) algorithm is proposed to automatically query similarities of the most discriminative regions with their surrounding regions and then to form new rough object locations. Furthermore, we introduce an effective object integration (OI) constraint, including a class sub-constraint and a distance sub-constraint, to refine the rough object locations from the RA algorithm further and achieve accurate object regions. By integrating our R-CCF module into weakly supervised detector architectures and training end-to-end, we can continually refine object locations by contrastively fusing the discriminative regions with surrounding patches. Extensive experiments demonstrate the effectiveness of the proposed method in weakly supervised object detection and show that integrating R-CCF into the state-of-the-art MIST [1] achieves 58.3% in mAP on the PASCAL VOC2007 benchmark, surpassing MIST by 0.2% absolutely. Moreover, R-CCF based on OICR [2] and WSDDN [3] achieve 42.5% and 32.5% in mAP on the PASCAL VOC2007, which is 1.3% and 2.1% higher than the baseline detectors, respectively. We also test the robustness of R-CCF on the PASCAL VOC 2012 dataset, and R-CCF outperforms the baseline methods clearly.},
  archive      = {J_APIN},
  author       = {Zhang, Yongqiang and Tian, Rui and Zhang, Yin and Zhang, Zian and Bai, Yancheng and Ding, Mingli and Zuo, Wangmeng},
  doi          = {10.1007/s10489-024-05403-3},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4689-4712},
  shortjournal = {Appl. Intell.},
  title        = {R-CCF: Region-aware continual contrastive fusion for weakly supervised object detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional probability table limit-based quantization for
bayesian networks: Model quality, data fidelity and structure score.
<em>APIN</em>, <em>54</em>(6), 4668–4688. (<a
href="https://doi.org/10.1007/s10489-023-05153-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Networks (BN) are robust probabilistic graphical models mainly used with discrete random variables requiring discretization and quantization of continuous data. Quantization is known to affect model accuracy, speed and interpretability, and there are various quantization methods and performance comparisons proposed in literature. Therefore, this paper introduces a novel approach called CPT limit-based quantization (CLBQ) aimed to address the trade-off among model quality, data fidelity and structure score. CLBQ sets CPT size limitation based on how large the dataset is so as to optimize the balance between the structure score of BNs and mean squared error. For such a purpose, a range of quantization values for each variable was evaluated and a Pareto set was designed considering structure score and mean squared error (MSE). A quantization value was selected from the Pareto set in order to balance MSE and structure score, and the method’s effectiveness was tested using different datasets, such as discrete variables with added noise, continuous variables and real continuous data. In all tests, CLBQ was compared to another quantization method known as Dynamic Discretization. Moreover, this study assesses the suitability of CLBQ for the search and score of BN structure learning, in addition to examining the landscape of BN structures while varying dataset sizes and confirming its consistency. It was sought to find the expected structure location through a landscape analysis and optimal BNs on it so as to confirm whether the expected results were actually achieved in the search and score of BN structure learning. Results demonstrate that CLBQ is quite capable of striking a balance between model quality, data fidelity and structure score, in addition to evidencing its potential application in the search and score of BN structure learning, thus further research should explore different structure scores and quantization methods through CLBQ. Furthermore, its code and used datasets have all been made available.},
  archive      = {J_APIN},
  author       = {Rodrigues Mendes Ribeiro, Rafael and Natal, Jordão and Polpo de Campos, Cassio and Dias Maciel, Carlos},
  doi          = {10.1007/s10489-023-05153-8},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4668-4688},
  shortjournal = {Appl. Intell.},
  title        = {Conditional probability table limit-based quantization for bayesian networks: Model quality, data fidelity and structure score},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-state delayed echo state network with empirical
wavelet transform for time series prediction. <em>APIN</em>,
<em>54</em>(6), 4646–4667. (<a
href="https://doi.org/10.1007/s10489-024-05386-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, considering the effect of multiple delayed states on the reservoir itself, based on the advantage of the empirical wavelet transform, an improved ESN with multiple delayed states is proposed, called multi-state delayed echo state network with empirical wavelet transform (EWT-MSD-ESN). Firstly, the empirical wavelet transform is used to decompose the input signal, and then the main features of all decomposed components of the input signal can be extracted. Secondly, considering the multi-state delayed capability of the reservoir, the reservoir state equation of the EWT-MSD-ESN can be adjusted adaptively by using the autocorrelation coefficient of the input signal, such that the intrinsic characteristics of different learning tasks can be fully reflected. Finally, four numerical simulation examples and two actual examples are used to validate the predictive performance of EWT-MSD-ESN.},
  archive      = {J_APIN},
  author       = {Yao, Xianshuang and Wang, Huiyu and Shao, Yanning and Huang, Zhanjun and Cao, Shengxian and Ma, Qingchuan},
  doi          = {10.1007/s10489-024-05386-1},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4646-4667},
  shortjournal = {Appl. Intell.},
  title        = {Multi-state delayed echo state network with empirical wavelet transform for time series prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage approach solo_GAN for overlapping cervical cell
segmentation based on single-cell identification and boundary
generation. <em>APIN</em>, <em>54</em>(6), 4621–4645. (<a
href="https://doi.org/10.1007/s10489-024-05378-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate cell segmentation is a pivotal step throughout the cervical cancer treatment continuum, encompassing early screening, guiding treatment decisions, and assessing long-term prognosis. Currently, in clinical practice, pathologists rely on microscopic examination of cell characteristics followed by manual annotation, leveraging their expert knowledge. Nonetheless, this approach is labor-intensive, time-consuming, and subject to subjectivity. While existing segmentation methods successfully delineate cell clusters, they struggle with single-cell segmentation in overlapping scenarios, often relying on pixel classification methods. This approach tends to produce discontinuous boundaries and incomplete contours. In this paper, we introduce a two-phase framework, Solo_GAN, capable of generating complete boundaries for single cells in overlapping cell clusters and complex backgrounds. In the first phase of our framework, we propose a target detection model based on YOLOv3 for identifying single-cell regions of interest (ROI) in Pap cervical images. In the second stage, the ROIs are fed into a novel network called the dual-domain mapping segmentation network, which is used to generate complete single-cell boundary maps. The process involves conversion between cervical cell images in different states, achieving the generation of single-cell boundaries while retaining the original features of the image. Our method has been extensively evaluated on a Hybrid cervical cell dataset (public and private sets) for its effectiveness. The results demonstrate that our approach consistently outperforms the state-of-the-art methods and proves highly effective. We provide visualizations of the output at each processing stage and compare them with mainstream methodologies. The cell segmentation method proposed in this paper holds considerable significance for clinical research on cells in different stages of cervical cancer.},
  archive      = {J_APIN},
  author       = {He, Zihao and Jia, Dongyao and Zhang, Chuanwang and Li, Ziqi and Wu, Nengkai},
  doi          = {10.1007/s10489-024-05378-1},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4621-4645},
  shortjournal = {Appl. Intell.},
  title        = {A two-stage approach solo_GAN for overlapping cervical cell segmentation based on single-cell identification and boundary generation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complex visual question answering based on uniform form and
content. <em>APIN</em>, <em>54</em>(6), 4602–4620. (<a
href="https://doi.org/10.1007/s10489-024-05383-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex visual question answering holds the potential to enhance artificial intelligence proficiency in understanding natural language, stimulate advances in computer vision technologies, and expand the range of practical applications. However, achieving desirable answers is often hindered by factors such as inconsistent form and content of pre-training and fine-tuning tasks, and the involvement of external knowledge. In this paper, we propose a complex visual question answering model based on uniform form and content, which aims to achieve better feature consistency and enhance model performance. To guide the question answering task and compensate for inconsistencies in the form of pre-training and downstream tasks, an encoding and decoding model is employed to generate auto-prompt tuning templates with masks. Moreover, the intermediate process between pre-training and the downstream task, which is similar to the downstream task, helps to further bridge the content gap between the two modalities. Based on this foundation, we propose a novel APT-CVQA model that incorporates a hybrid architecture and a joint loss function for cross-entropy and SIMCLR. On the complex scenario KR-VQA dataset, the accuracy of our model surpasses the optimal performance by 2.45 $$\%$$ . On the universal dataset GQA, our model performs 6.87 $$\%$$ better than the optimal performance of the compared models. The whole process is divided into three phases. Phase-1 generates auto-prompt tuning templates, Phase-2 facilitates the creation of intermediate pre-trained checkpoints, and Phase-3 is used for fine-tuning.},
  archive      = {J_APIN},
  author       = {Chen, Deguang and Chen, Jianrui and Fang, Chaowei and Zhang, Zhichao},
  doi          = {10.1007/s10489-024-05383-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4602-4620},
  shortjournal = {Appl. Intell.},
  title        = {Complex visual question answering based on uniform form and content},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Evolutionary dynamic grouping based cooperative
co-evolution algorithm for large-scale optimization. <em>APIN</em>,
<em>54</em>(6), 4585–4601. (<a
href="https://doi.org/10.1007/s10489-024-05390-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively address large-scale optimization problems, this paper proposes an evolutionary dynamic grouping (EDG) based cooperative co-evolution (CC) algorithm. In the proposed algorithm, a novel decomposition method is designed to generate the sub-components of decision variables dynamically. Additionally, an evolutionary search method based on the fireworks search strategy is proposed to enhance the searchability of the algorithm. The performance of the proposed algorithm is assessed using two benchmark suites, IEEE CEC’2010 and IEEE CEC’2013, as well as a real-world optimization problem, the 0/1 Knapsack Problem (KP). Experimental results demonstrate that the proposed algorithm achieves competitive results when compared with other state-of-the-art algorithms.},
  archive      = {J_APIN},
  author       = {Yang, Wanting and Liu, Jianchang and Tan, Shubin and Zhang, Wei and Liu, Yuanchao},
  doi          = {10.1007/s10489-024-05390-5},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4585-4601},
  shortjournal = {Appl. Intell.},
  title        = {Evolutionary dynamic grouping based cooperative co-evolution algorithm for large-scale optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Video-based beat-by-beat blood pressure monitoring via
transfer deep-learning. <em>APIN</em>, <em>54</em>(6), 4564–4584. (<a
href="https://doi.org/10.1007/s10489-024-05354-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, learning physiological vital signs such as blood pressure (BP), hemoglobin levels, and oxygen saturation, from Photoplethysmography (PPG) signal, is receiving more attention. Despite successive progress that has been made so far, continuously revealing new aspects characterizes that field as a rich research topic. It includes a diverse number of critical points represented in signal denoising, data cleaning, employed features, feature format, feature selection, feature domain, model structure, problem formulation (regression or classification), and model combinations. It is worth noting that extensive research efforts are devoted to utilizing different variants of machine learning and deep learning models while transfer learning is not fully explored yet. So, in this paper, we are introducing a per-beat rPPG-to-BP mapping scheme based on transfer learning. An interesting representation of a 1-D PPG signal as a 2-D image is proposed for enabling powerful off-the-shelf image-based models through transfer learning. It resolves limitations about training data size due to strict data cleaning. Also, it enhances model generalization by exploiting underlying excellent feature extraction. Moreover, non-uniform data distribution (data skewness) is partially resolved by introducing logarithmic transformation. Furthermore, double cleaning is applied for training contact PPG data and testing rPPG beats as well. The quality of the segmented beats is tested by checking some of the related quality metrics. Hence, the prediction reliability is enhanced by excluding deformed beats. Varying rPPG quality is relaxed by selecting beats during intervals of the highest signal strength. Based on the experimental results, the proposed system outperforms the state-of-the-art systems in the sense of mean absolute error (MAE) and standard deviation (STD). STD for the test data is decreased to 5.4782 and 3.8539 for SBP and DBP, respectively. Also, MAE decreased to 2.3453 and 1.6854 for SBP and DBP, respectively. Moreover, the results for BP estimation from real video reveal that the STD reaches 8.027882 and 6.013052 for SBP and DBP, respectively. Also, MAE for the estimated BP from real videos reaches 7.052803 and 5.616028 for SBP and DBP, respectively. Proposed camera-based blood pressure monitoring system},
  archive      = {J_APIN},
  author       = {Omer, Osama A. and Salah, Mostafa and Hassan, Loay and Abdelreheem, Ahmed and Hassan, Ammar M.},
  doi          = {10.1007/s10489-024-05354-9},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4564-4584},
  shortjournal = {Appl. Intell.},
  title        = {Video-based beat-by-beat blood pressure monitoring via transfer deep-learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SelfPAB: Large-scale pre-training on accelerometer data for
human activity recognition. <em>APIN</em>, <em>54</em>(6), 4545–4563.
(<a href="https://doi.org/10.1007/s10489-024-05322-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Annotating accelerometer-based physical activity data remains a challenging task, limiting the creation of robust supervised machine learning models due to the scarcity of large, labeled, free-living human activity recognition (HAR) datasets. Researchers are exploring self-supervised learning (SSL) as an alternative to relying solely on labeled data approaches. However, there has been limited exploration of the impact of large-scale, unlabeled datasets for SSL pre-training on downstream HAR performance, particularly utilizing more than one accelerometer. To address this gap, a transformer encoder network is pre-trained on various amounts of unlabeled, dual-accelerometer data from the HUNT4 dataset: 10, 100, 1k, 10k, and 100k hours. The objective is to reconstruct masked segments of signal spectrograms. This pre-trained model, termed SelfPAB, serves as a feature extractor for downstream supervised HAR training across five datasets (HARTH, HAR70+, PAMAP2, Opportunity, and RealWorld). SelfPAB outperforms purely supervised baselines and other SSL methods, demonstrating notable enhancements, especially for activities with limited training data. Results show that more pre-training data improves downstream HAR performance, with the 100k-hour model exhibiting the highest performance. It surpasses purely supervised baselines by absolute F1-score improvements of 7.1% (HARTH), 14% (HAR70+), and an average of 11.26% across the PAMAP2, Opportunity, and RealWorld datasets. Compared to related SSL methods, SelfPAB displays absolute F1-score enhancements of 10.4% (HARTH), 18.8% (HAR70+), and 16% (average across PAMAP2, Opportunity, RealWorld).},
  archive      = {J_APIN},
  author       = {Logacjov, Aleksej and Herland, Sverre and Ustad, Astrid and Bach, Kerstin},
  doi          = {10.1007/s10489-024-05322-3},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4545-4563},
  shortjournal = {Appl. Intell.},
  title        = {SelfPAB: Large-scale pre-training on accelerometer data for human activity recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised diagnosis of wind-turbine gearbox
misalignment and imbalance faults. <em>APIN</em>, <em>54</em>(6),
4525–4544. (<a
href="https://doi.org/10.1007/s10489-024-05373-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both wear-induced bearing failure and misalignment of the powertrain between the rotor and the electrical generator are common failure modes in wind-turbine motors. In this study, Semi-Supervised Learning (SSL) is applied to a fault detection and diagnosis solution. Firstly, a dataset is generated containing both normal operating patterns and seven different failure classes of the two aforementioned failure modes that vary in intensity. Several datasets are then generated, maintaining different numbers of labeled instances and unlabeling the others, in order to evaluate the number of labeled instances needed for the desired accuracy level. Subsequently, different types of SSL algorithms and combinations of algorithms are trained and then evaluated with the test data. The results showed that an SSL approach could improve the accuracy of trained classifiers when a small number of labeled instances were used together with many unlabeled instances to train a Co-Training algorithm or combinations of such algorithms. When a few labeled instances (fewer than 10% or 327 instances, in this case) were used together with unlabeled instances, the SSL algorithms outperformed the result obtained with the Supervised Learning (SL) techniques used as a benchmark. When the number of labeled instances was sufficient, the SL algorithm (using only labeled instances) performed better than the SSL algorithms (accuracy levels of 87.04% vs. 86.45%, when labeling 10% of instances). A competitive accuracy of 97.73% was achieved with the SL algorithm processing a subset of 40% of the labeled instances. Steps and processes for approaching semi-supervised FDD of wind-turbine gearbox misalignment and imbalance faults},
  archive      = {J_APIN},
  author       = {Maestro-Prieto, Jose Alberto and Ramírez-Sanz, José Miguel and Bustillo, Andrés and Rodriguez-Díez, Juan José},
  doi          = {10.1007/s10489-024-05373-6},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4525-4544},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised diagnosis of wind-turbine gearbox misalignment and imbalance faults},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Audio-visual speech synthesis using vision
transformer–enhanced autoencoders with ensemble of loss functions.
<em>APIN</em>, <em>54</em>(6), 4507–4524. (<a
href="https://doi.org/10.1007/s10489-024-05380-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio-visual speech synthesis (AVSS) has garnered attention in recent years for its utility in the realm of audio-visual learning. AVSS transforms one speaker’s speech into another’s audio-visual stream while retaining linguistic content. This approach extends existing AVSS methods by first modifying vocal features from the source to the target speaker, akin to voice conversion (VC), and then synthesizing the audio-visual stream for the target speaker, termed audio-visual synthesis (AVS). In this work, a novel AVSS approach is proposed using vision transformer (ViT)-based Autoencoders (AEs), enriched with a combination of cycle consistency and reconstruction loss functions, with the aim of enhancing synthesis quality. Leveraging ViT’s attention mechanism, this method effectively captures spectral and temporal features from input speech. The combination of cycle consistency and reconstruction loss improves synthesis quality and aids in preserving essential information. The proposed framework is trained and tested on benchmark datasets, and compared extensively with state-of-the-art (SOTA) methods. The experimental results demonstrate the superiority of the proposed approach over existing SOTA models, in terms of quality and intelligibility for AVSS, indicating the potential for real-world applications.},
  archive      = {J_APIN},
  author       = {Ghosh, Subhayu and Sarkar, Snehashis and Ghosh, Sovan and Zalkow, Frank and Jana, Nanda Dulal},
  doi          = {10.1007/s10489-024-05380-7},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4507-4524},
  shortjournal = {Appl. Intell.},
  title        = {Audio-visual speech synthesis using vision transformer–enhanced autoencoders with ensemble of loss functions},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DS-MSFF-net: Dual-path self-attention multi-scale feature
fusion network for CT image segmentation. <em>APIN</em>, <em>54</em>(6),
4490–4506. (<a
href="https://doi.org/10.1007/s10489-024-05372-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed tomography (CT) is an important technique that is widely used in disease screening and diagnosis. In order to assist doctors in diagnosis and treatment plans, an efficient and accurate automatic image segmentation technology is urgently needed. CT images of different lesions always have problems such as different resolutions, different numbers of lesions, and inconspicuous contrast between lesions and background areas, which brings considerable challenges to the automated segmentation process. To this end, we propose a dual-path self-attention multi-scale feature fusion network (DS-MSFF-Net) that fuses self-attention mechanism and dilated convolution. It is worth noting that this network includes two parallel branch paths, which enables it to extract long-range semantic feature information effectively while extracting detailed feature information of CT images. Additionally, a novel feature extraction module is designed to focus limited learning resources on low-resolution high-order semantic feature maps, which can improve the segmentation accuracy without significant additional computational overhead. We extensively evaluate our method on the LIDC-IDRI lung nodule segmentation dataset and the LiTS2017 liver segmentation dataset, which outperforms other recent state-of-the-art methods on various CT image segmentation tasks.},
  archive      = {J_APIN},
  author       = {Zhang, Xiaoqian and Pu, Lei and Wan, Liming and Wang, Xiao and Zhou, Ying},
  doi          = {10.1007/s10489-024-05372-7},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4490-4506},
  shortjournal = {Appl. Intell.},
  title        = {DS-MSFF-net: Dual-path self-attention multi-scale feature fusion network for CT image segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-start team orienteering problem for UAS mission
re-planning with data-efficient deep reinforcement learning.
<em>APIN</em>, <em>54</em>(6), 4467–4489. (<a
href="https://doi.org/10.1007/s10489-024-05367-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the Multi-Start Team Orienteering Problem (MSTOP), a mission re-planning problem where vehicles are initially located away from the depot and have different amounts of fuel. We consider/assume the goal of multiple vehicles is to travel to maximize the sum of collected profits under resource (e.g., time, fuel) consumption constraints. Such re-planning problems occur in a wide range of intelligent UAS applications where changes in the mission environment force the operation of multiple vehicles to change from the original plan. To solve this problem with deep reinforcement learning (RL), we develop a policy network with self-attention on each partial tour and encoder-decoder attention between the partial tour and the remaining nodes. We propose a modified REINFORCE algorithm where the greedy rollout baseline is replaced by a local mini-batch baseline based on multiple, possibly non-duplicate sample rollouts. By drawing multiple samples per training instance, we can learn faster and obtain a stable policy gradient estimator with significantly fewer instances. The proposed training algorithm outperforms the conventional greedy rollout baseline, even when combined with the maximum entropy objective. The efficiency of our method is further demonstrated in two classical problems – the Traveling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP). The experimental results show that our method enables models to develop more effective heuristics and performs competitively with the state-of-the-art deep reinforcement learning methods.},
  archive      = {J_APIN},
  author       = {Lee, Dong Ho and Ahn, Jaemyung},
  doi          = {10.1007/s10489-024-05367-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {6},
  pages        = {4467-4489},
  shortjournal = {Appl. Intell.},
  title        = {Multi-start team orienteering problem for UAS mission re-planning with data-efficient deep reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Metric learning for monotonic classification: Turning the
space up to the limits of monotonicity. <em>APIN</em>, <em>54</em>(5),
4443–4466. (<a
href="https://doi.org/10.1007/s10489-024-05371-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents, for the first time, a distance metric learning algorithm for monotonic classification. Monotonic datasets arise in many real-world applications, where there exist order relations in the input and output variables, and the outputs corresponding to ordered pairs of inputs are also expected to be ordered. Monotonic classification can be addressed through several distance-based classifiers that are able to respect the monotonicity constraints of the data. The performance of distance-based classifiers can be improved with the use of distance metric learning algorithms, which are able to find the distances that best represent the similarities among each pair of data samples. However, learning a distance for monotonic data has an additional drawback: the learned distance may negatively impact the monotonic constraints of the data. In our work, we propose a new model for learning distances that does not corrupt these constraints. This methodology will also be useful in identifying and discarding non-monotonic pairs of samples that may be present in the data due to noise. The experimental analysis conducted, supported by a Bayesian statistical testing, demonstrates that the distances obtained by the proposed method can enhance the performance of several distance-based classifiers in monotonic problems.},
  archive      = {J_APIN},
  author       = {Suárez, Juan Luis and González-Almagro, Germán and García, Salvador and Herrera, Francisco},
  doi          = {10.1007/s10489-024-05371-8},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4443-4466},
  shortjournal = {Appl. Intell.},
  title        = {Metric learning for monotonic classification: Turning the space up to the limits of monotonicity},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SRENet: Structure recovery ensemble network for single image
deraining. <em>APIN</em>, <em>54</em>(5), 4425–4442. (<a
href="https://doi.org/10.1007/s10489-024-05382-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-image deraining remains a formidable challenge. Its objective is not only to eliminate rain streaks from the target image but also to restore its spatial details and high-level contextual structure. Recently, numerous CNN-based methods have been introduced for this purpose. While these methods can adeptly remove rain streaks, they often face difficulties in restoring high-quality, rain-free images while preserving clear and precise structures—especially when those structures resemble rain streaks. To extract a diverse array of feature information for image structure restoration, we introduce a network called the Structure Recovery Ensemble Network (SRENet). This network comprises three learners, each designed with three parallel subnetworks. This arrangement allows for the acquisition of a broader range of structural features by transitioning from deep vertical networks to horizontal parallelization across multiple subnetworks. To extract structural features without interference from rain streak information, we employ an independent loss strategy in which each learner is trained to address different specific challenges in the image deraining process, such as rain removal and structure restoration. Additionally, we design a guided fusion module to seamlessly integrate features from the various learners and subnetworks. Comprehensive experiments on benchmark datasets confirm that our proposed method sets new state-of-the-art standards. On the synthetic datasets, SRENet achieved average improvements of 0.85% in SSIM and 0.81% in PSNR compared to mainstream benchmarks. On real-world rainy images, SRENet demonstrates improvements of 6.71% in NIQE and 11.4% in BRISQUE.},
  archive      = {J_APIN},
  author       = {Zhang, Dan and Xu, Yingbing and Ma, Liyan and Li, Xiaowei and Zhang, Xiangyu and Peng, Yan and Chen, Yaoran},
  doi          = {10.1007/s10489-024-05382-5},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4425-4442},
  shortjournal = {Appl. Intell.},
  title        = {SRENet: Structure recovery ensemble network for single image deraining},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heterogeneous graph neural network with graph-data
augmentation and adaptive denoising. <em>APIN</em>, <em>54</em>(5),
4411–4424. (<a
href="https://doi.org/10.1007/s10489-024-05363-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs are especially important in our daily life, which describe objects and their connections through nodes and edges. For this complex network structure, many heterogeneous graph neural networks have been designed, but the traditional heterogeneous graph neural network has several obvious shortcomings: (1) Models using meta-paths require selection of meta-paths, failing to learn all meta-paths in the dataset, and cannot capture structural information beyond meta-paths. (2) Models that do not apply meta-paths will be limited by the relationships of the original graph. Due to the absence or omission of some very important but costly relationships in the dataset, the ability of the model to learn node features is limited. (3) The existence of noise will affect the optimization of the parameters of the heterogeneous graph neural network models. In response to these problems, we propose our model: Heterogeneous Graph Neural Network with Graph-data Augmentation and Adaptive Denoising (GAAD). We hope that our model is not affected by differences in graph structure and noise nodes in the graph structure. In summary, we hope that our model can adapt to most graph structures. So we propose a method based on graph neural network to mine the hidden relationship between heterogeneous nodes, calculate the possibility of the existence of edges between heterogeneous nodes, strengthen the graph structure by adding highly possible edges, enrich the information transmission between nodes. Then we apply an adaptive noise reduction algorithm to prevent the possible noise diffusion caused by data enhancement in the graph structure. Extensive experiments on three real-world network datasets demonstrate the superiority of GAAD over the state-of-the-art methods. The code is available on https://github.com/xiaojunlou0831/GAAD .},
  archive      = {J_APIN},
  author       = {Lou, Xiaojun and Liu, Guanjun and Li, Jian},
  doi          = {10.1007/s10489-024-05363-8},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4411-4424},
  shortjournal = {Appl. Intell.},
  title        = {Heterogeneous graph neural network with graph-data augmentation and adaptive denoising},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Multi-level relation learning for cross-domain few-shot
hyperspectral image classification. <em>APIN</em>, <em>54</em>(5),
4392–4410. (<a
href="https://doi.org/10.1007/s10489-024-05384-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain few-shot hyperspectral image classification focuses on learning prior knowledge from a large number of labeled samples from source domains and then transferring the knowledge to the tasks which contain few labeled samples in target domains. Following the metric-based manner, many current methods first extract the features of the query and support samples, and then directly predict the classes of query samples according to their distance to the support samples or prototypes. The relations between samples have not been fully explored and utilized. Different from current works, this paper proposes to learn sample relations on different levels and take them into the model learning process, to improve the cross-domain few-shot hyperspectral image classification. Building on current method of &quot;Deep Cross-Domain Few-Shot Learning for Hyperspectral Image Classification&quot; which adopts a domain discriminator to deal with domain-level distribution difference, the proposed method applies contrastive learning to learn the class-level sample relations to obtain more discriminable sample features. In addition, it adopts a transformer based cross-attention learning module to learn the set-level sample relations and acquire the attention from query samples to support samples. Our experimental results have demonstrated the contribution of the multi-level relation learning mechanism for few-shot hyperspectral image classification when compared with the state of the art methods. All the codes are available at github https://github.com/HENULWY/STBDIP .},
  archive      = {J_APIN},
  author       = {Liu, Chun and Yang, Longwei and Li, Zheng and Yang, Wei and Han, Zhigang and Guo, Jianzhong and Yu, Junyong},
  doi          = {10.1007/s10489-024-05384-3},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4392-4410},
  shortjournal = {Appl. Intell.},
  title        = {Multi-level relation learning for cross-domain few-shot hyperspectral image classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mediating effects of NLP-based parameters on the readability
of crowdsourced wikipedia articles. <em>APIN</em>, <em>54</em>(5),
4370–4391. (<a
href="https://doi.org/10.1007/s10489-024-05399-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this era of information and communication technology, a large population relies on the Internet to gather information. One of the most popular information sources on the Internet is Wikipedia. Wikipedia is a free encyclopedia that provides a wide range of information to its users. However, there have been concerns about the readability of information on Wikipedia time and again. The readability of the text is defined as the ease of understanding the underlying text. Past studies have analyzed the readability of Wikipedia articles with the help of conventional readability metrics, such as the Flesch-Kincaid readability score and the Automatic Readability Index (ARI). Such metrics only consider the surface-level parameters, such as the number of words, sentences, and paragraphs in the text, to quantify the readability. However, the readability of the text must also take into account the quality of the text. In this study, we consider many new NLP-based parameters capturing the quality of the text, such as lexical diversity, semantic diversity, lexical complexity, and semantic complexity and analyze their impact on the readability of Wikipedia articles using artificial neural networks. Besides NLP parameters, the crowdsourced parameters also affect the readability, and therefore, we also analyze the impact of crowdsourced parameters and observe that the crowdsourced parameters not only influence the readability scores but also affect the NLP parameters of the text. Additionally, we investigate the mediating effect of NLP parameters that connect the crowdsourced parameters to the readability of the text. The results show that the impact of crowdsourced parameters on readability is partially due to the profound effect of NLP-based parameters.},
  archive      = {J_APIN},
  author       = {Setia, Simran and Chhabra, Anamika and Arjun Verma, Amit and Saxena, Akrati},
  doi          = {10.1007/s10489-024-05399-w},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4370-4391},
  shortjournal = {Appl. Intell.},
  title        = {Mediating effects of NLP-based parameters on the readability of crowdsourced wikipedia articles},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LA-RCNN: Luong attention-recurrent- convolutional neural
network for EV charging load prediction. <em>APIN</em>, <em>54</em>(5),
4352–4369. (<a
href="https://doi.org/10.1007/s10489-024-05394-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the domain of accurate Electric Vehicle (EV) charge prediction, a crucial aspect of the energy consumption system. Predicting EV energy consumption is challenging due to the dynamic dependence and heterogeneity. Despite various approaches proposed in previous studies for intelligent charging, many models rely on limited inputs and ignore the non-linear interactivity between different time series. Moreover, to our knowledge, previous research has not considered the number of connected EVs during the charging procedure. This paper develops an attention-based recurrent convolutional neural network model (LA-RCNN) designed to forecast EV charging load using multivariate time series inputs, including meteorological data and the number of connected users. The proposed model incorporates multiplicative Luong Attention to identify temporal dependencies and correlations. Our objective is to predict the national charging load by considering the charging state and the number of plug-in EVs connected to various charging stations. Using real-world EV charging data from three Chinese cities, we demonstrate that the LA-RCNN model significantly enhances forecast accuracy compared to benchmark methods, reducing MAPE by 21.33% and RMSE by 18.73% as compared to LSTM models. These results highlight the importance of nonlinear attention-based architectures and diverse contextual data sources for effective EV load prediction.},
  archive      = {J_APIN},
  author       = {Mekkaoui, Djamel Eddine and Midoun, Mohamed Amine and Shen, Yanming},
  doi          = {10.1007/s10489-024-05394-1},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4352-4369},
  shortjournal = {Appl. Intell.},
  title        = {LA-RCNN: Luong attention-recurrent- convolutional neural network for EV charging load prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Hybrid density-based adaptive weighted collaborative
representation for imbalanced learning. <em>APIN</em>, <em>54</em>(5),
4334–4351. (<a
href="https://doi.org/10.1007/s10489-024-05393-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative representation-based classification (CRC) has been extensively applied to various recognition fields due to its effectiveness and efficiency. Nevertheless, it is generally suboptimal for imbalanced learning. Previous studies have revealed that a class-imbalance distribution can lead CRC, and even most conventional classification methods, to ignore the minority class and prioritize the majority class. To address this deficiency, this paper proposes a hybrid density-based adaptive weighted collaborative representation model that incorporates a regularization technique and an adaptive weight generation mechanism into the CRC framework. A new regularization term, based on class-specific representation, is introduced to decrease the correlation between classes and enhance CRC’s discriminative ability. The sample distribution and density information within and between classes are employed to assign greater weights to minority samples, thereby strengthening the representation capabilities of minority samples and reducing the bias towards the majority class. Furthermore, it is theoretically demonstrated that this model has a closed-form solution. Its complexity is comparable to that of CRC, ensuring its efficiency. Extensive experiments on diverse data sets from the KEEL repository show the superiority of the proposed method compared to other state-of-the-art imbalanced classification methods.},
  archive      = {J_APIN},
  author       = {Li, Yanting and Wang, Shuai and Jin, Junwei and Tao, Hongwei and Han, Chuang and Chen, C. L. Philip},
  doi          = {10.1007/s10489-024-05393-2},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4334-4351},
  shortjournal = {Appl. Intell.},
  title        = {Hybrid density-based adaptive weighted collaborative representation for imbalanced learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative adversarial network for newborn 3D skeleton part
segmentation. <em>APIN</em>, <em>54</em>(5), 4319–4333. (<a
href="https://doi.org/10.1007/s10489-024-05406-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Childbirth simulations have been studied in order to predict and prevent difficult delivery issues. The reconstruction of the maternal pelvic model, which consists of a comprehensive fetal model with articulated joints, is important for therapeutic purposes. However, it is difficult and time-consuming to segment the various bones using classical image processing approaches. The aim of this study is to develop and evaluate a generative adversarial network to automatically segment the bony structures of the complete neonatal skeleton. A database of 124 newborn CT images was collected and segmented. Each 3D reconstructed skeleton was divided into 23 distinct bony segments. We proposed the generative adversarial network based on PointNet to perform the automated segmentation directly on the 3D point clouds. Our method was compared to the pointwise convolutional neural network to demonstrate its accuracy and efficiency. The GAN model produced highly accurate results with an IoU of 93.68% ± 7.37%, a Dice of 96.56% ± 4.41% and an accuracy score of 96.72% ± 3.56%, compared to 72.30% ± 5.10% for IoU, 83.82% ± 3.44% for Dice and 84.81% ± 3.25% for accuracy respectively by the pointwise convolutional neural network. In addition, our model behaved better on skeletons in anatomical postures than ones in fetal positions. This study opens new avenues for fast and accurate 3D part segmentation of the newborn 3D skeleton. In the future, further study should focus on segmenting fused bones like vertebrae and integrating the whole articulated skeleton into the maternal pelvic model to simulate complex vaginal delivery and perform associated preventive actions.},
  archive      = {J_APIN},
  author       = {Nguyen-Le, Hien-Duyen and Ferrandini, Morgane and Nguyen, Duc-Phong and Tran, Vi-Do and Vo, Hoai-Danh and Nguyen, Tan-Nhu and Dao, Tien-Tuan},
  doi          = {10.1007/s10489-024-05406-0},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4319-4333},
  shortjournal = {Appl. Intell.},
  title        = {Generative adversarial network for newborn 3D skeleton part segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weakly supervised grounded image captioning with semantic
matching. <em>APIN</em>, <em>54</em>(5), 4300–4318. (<a
href="https://doi.org/10.1007/s10489-024-05389-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual attention has been extensively adopted in many tasks, such as image captioning. It not only improves the performance of image captioning but is also used to enhance the quality of caption rationality. Rationality can be understood as the ability to maintain attention on the correct regions while generating words or phrases. This is critical for alleviating the problems of object hallucinations. Recently, many researchers have devoted to improving grounding accuracy by linking generated object words or phrases to appropriate regions of the image. However, collecting word-region alignment is expensive and limited, and the generated object words may not appear in the annotation sentences. To address this challenge, we propose a weakly supervised grounded image captioning method. Specifically, we design a region-word matching block to estimate the match scores for the candidate nouns with all regions. Compared to manual annotations, the match score may contain some mistakes. To make the captioning model compatible with these mistakes, we design a reinforcement loss that takes into account both attention weights and match scores. This allows the captioning model to generate a more accurate and grounded sentence. Experimental results on two commonly used benchmark datasets (MSCOCO, Flickr30k) demonstrate the superiority of the proposed blocks. Extensive ablation studies also validate the effectiveness and robustness of the proposed modules. Last but not least, our blocks are available in a variety of captioning models and do not require additional label or extra time consumption in inference stage.},
  archive      = {J_APIN},
  author       = {Du, Sen and Zhu, Hong and Lin, Guangfeng and Liu, Yuanyuan and Wang, Dong and Shi, Jing and Wu, Zhong},
  doi          = {10.1007/s10489-024-05389-y},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4300-4318},
  shortjournal = {Appl. Intell.},
  title        = {Weakly supervised grounded image captioning with semantic matching},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Evaluation on the effect of water environment treatment –a
new exploration considering time based on the RCS. <em>APIN</em>,
<em>54</em>(5), 4277–4299. (<a
href="https://doi.org/10.1007/s10489-023-05218-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The River Chief System (RCS), an innovative top-down and bottom-up water resource management system in China, is implemented to manage increasingly complex water environment issues. However, there has been a time lag in policy implementation. To accurately and scientifically assess the effect of RCS, a dynamic multiple-attribute decision-making method considering the time factor (DMADM) has been proposed. We have constructed the model consisting of 17 indicators from four aspects and determined the index weights and time weights by using the gray relation analysis method, the maximum entropy principle, and the subjective empowerment method. Finally, we applied the model to evaluate the water environment governance effect in the Taihu Basin from 2008 to 2020. The results have been ranked by possibility degree matrix, showing that: (1) The water environment in Taihu Basin maintains a steady improvement trend until 2014, except in Jiangsu Province;(2) The ranking result of the final comprehensive evaluation value is Shanghai ([0.334, 0.376]) ≻ Zhejiang ([0.316, 0.353]) ≻ Jiangsu ([0.305, 0.336]). Shanghai is far ahead with systematic pollution control measures, while Jiangsu lags due to the large fluctuation of pollutants (COD, NH3-N) in the wastewater. The study finds that the water environment management in Taihu Basin did improve over the past years, but failed to achieve the RCS governance goals at each stage. Enhancing coordination and cooperation and improving supervision mechanism for precise governance can better consolidate the results of RCS governance.},
  archive      = {J_APIN},
  author       = {Chen, Yanping and Chen, Shaoqi and Yu, Jiaojiao and Wen, Xiaowei and Xu, Yejun},
  doi          = {10.1007/s10489-023-05218-8},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4277-4299},
  shortjournal = {Appl. Intell.},
  title        = {Evaluation on the effect of water environment treatment –A new exploration considering time based on the RCS},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-modal contrastive learning for multimodal sentiment
recognition. <em>APIN</em>, <em>54</em>(5), 4260–4276. (<a
href="https://doi.org/10.1007/s10489-024-05355-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment recognition has obtained increasing attention in recent years due to its potential to improve sentiment recognition accuracy by integrating information from multiple modalities. However, the heterogeneity issue caused by the differences in modalities poses a significant challenge for multimodal sentiment recognition. In this paper, we propose a novel framework, Cross-Modal Contrastive Learning (CMCL), which integrates multiple contrastive learning methods and multimodal data augmentation to address the heterogeneity issue. Specifically, we establish a cross-modal contrastive learning framework by leveraging diversity contrastive learning, consistency contrastive learning and sample-level contrastive learning. Through diversity contrastive learning, we constrain modality features to different feature spaces, capturing the complementary nature of modality-specific features. Additionally, through consistency contrastive learning, we map the representations of different modalities into a shared feature space, capturing the consistency of modality-specific features. We also introduce two data augmentation techniques, namely random noise and modal combination, to improve the model’s robustness. The experimental results show that our approach achieves state-of-the-art performance on three benchmark datasets and outperforms the existing baseline models. Our work demonstrates the effectiveness of cross-modal contrastive learning and data augmentation in multimodal sentiment recognition, and provides valuable insights for future research in this area.},
  archive      = {J_APIN},
  author       = {Yang, Shanliang and Cui, Lichao and Wang, Lei and Wang, Tao},
  doi          = {10.1007/s10489-024-05355-8},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4260-4276},
  shortjournal = {Appl. Intell.},
  title        = {Cross-modal contrastive learning for multimodal sentiment recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient optimization for object detection in learning with
noisy labels. <em>APIN</em>, <em>54</em>(5), 4248–4259. (<a
href="https://doi.org/10.1007/s10489-024-05357-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have made significant progress benefiting large-scale correctly human-labeled datasets. However, large-scale human-labeled datasets are often ambiguous because the limited experience can lead to mislabeled classes. Most research related to learning with noisy labels concentrates on image classification, while we focus on object detection that also suffers from noisy labels. In this paper, we propose a method that applies gradient optimization for object detection (GOOD), aiming to combat poor generalization caused by noisy labels in objection detection. Usually, a detection task is divided into a foreground-background subtask and a foreground-object subtask. Hence, gradient descent with cross-entropy exploits corrected gradient guidance for foreground-background subtask, while dynamic gradient underweighted ascent with cross-entropy and variant gradient clipping with improved symmetric cross-entropy are mutually employed to prevent incorrect gradient guidance for foreground-object subtask. We conducted extensive experiments on PASCAL VOC 2012 and COCO 2017, demonstrating the effectiveness of GOOD. Furthermore, we promote GOOD to instance segmentation, and competitive results on Cityscapes show that it is also appropriate for instance segmentation. Specifically, we achieved a 9.4% improvement on PASCAL VOC 2012, 5.2% on COCO 2017, and 4.3% on Cityscapes.},
  archive      = {J_APIN},
  author       = {Xia, Qiangqiang and Hu, Chunyan and Lee, Feifei and Chen, Qiu},
  doi          = {10.1007/s10489-024-05357-6},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4248-4259},
  shortjournal = {Appl. Intell.},
  title        = {Gradient optimization for object detection in learning with noisy labels},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Quasi-atomic relations based rough set model and convex
geometry. <em>APIN</em>, <em>54</em>(5), 4230–4247. (<a
href="https://doi.org/10.1007/s10489-024-05405-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous studies have extensively examined the correlation between convex structures and covering rough set models. However, limited attention has been devoted to investigating the relationship between convex structures and rough set models based on relations. In this paper, we aim to integrate convex geometry with rough sets based on relations. Firstly, a novel class of binary relation known as quasi-atomic relation is introduced. We show that each ordinal convex geometry can be reformulated by rough sets based on quasi-atomic relations. Subsequently, we illustrate that any convex geometry can be embedded in an ordinal convex geometry using the rough set approach. Secondly, we develop a new model called the multi-valued rough set model which serves as a valuable tool for investigating convex geometry. A novel representation of any convex geometry is provided by multi-valued rough sets based on the family of quasi-atomic relations. Furthermore, we demonstrate that any convex geometry can be decomposed into a union of ordinal convex geometries. Lastly, We develop a method to determine whether an element belongs to a convex closure of a given set. In addition, we incorporate terminologies from rough set theory into the study of convex geometry by defining concepts such as rough convex sets and degree of convexity which are utilized to analyze the structure of convex geometry. In summary, this paper offers an efficient method to integrate rough sets with convex geometry, which extends the theory and application of rough sets.},
  archive      = {J_APIN},
  author       = {Wang, Zhaohao},
  doi          = {10.1007/s10489-024-05405-1},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4230-4247},
  shortjournal = {Appl. Intell.},
  title        = {Quasi-atomic relations based rough set model and convex geometry},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage adversarial transformer based approach for
multivariate industrial time series anomaly detection. <em>APIN</em>,
<em>54</em>(5), 4210–4229. (<a
href="https://doi.org/10.1007/s10489-024-05395-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensors in complex industrial systems generate multivariate time series data, frequently leading to diverse abnormal patterns that pose challenges for detection. The existing multivariate abnormal detection methods may encounter difficulties when applied to datasets with low dimensions or sparse relationships between variables. To address these issues, this study proposes a two-stage adversarial Transformer-based anomaly detection method. On the one hand, an autoregressive temporal convolutional network component is embedded before the multi-head attention module to capture features encompassing long-term and local information. Besides, this component utilizes a trainable neural network instead of the vanilla Transformer’s absolute position encoding, resulting in enhanced position information. On the other hand, the proposed two-stage adversarial learning strategy allows the model to effectively learn intricate multivariate data patterns via constraining latent space, thereby enhancing anomaly detection performance. Our method achieves F1 scores of 0.9679, 0.7947, and 0.6452 on a real-world dataset and two public industrial sensor datasets, demonstrating superior overall anomaly detection performance compared to recent advanced works.},
  archive      = {J_APIN},
  author       = {Chen, Junfu and Pi, Dechang and Wang, Xixuan},
  doi          = {10.1007/s10489-024-05395-0},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4210-4229},
  shortjournal = {Appl. Intell.},
  title        = {A two-stage adversarial transformer based approach for multivariate industrial time series anomaly detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Momentum portfolio selection based on learning-to-rank
algorithms with heterogeneous knowledge graphs. <em>APIN</em>,
<em>54</em>(5), 4189–4209. (<a
href="https://doi.org/10.1007/s10489-024-05377-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence techniques for financial time series analysis have been used to enhance momentum trading methods. However, most previous studies, which have treated stocks as independent entities, have overlooked the significance of correlations among individual stocks, thus compromising portfolio performance. To address this gap, a momentum trading framework is proposed that combines heterogeneous data, such as corporate governance factors and financial domain knowledge, to model the relationships between stocks. Our approach involves adopting a knowledge graph embedding approach to map relations among heterogeneous relationships in the data, which is then utilized to train a multitask supervised learning approach based on a learning-to-rank algorithm. This method culminates in a robust portfolio selection method on the basis of the framework. Experimental results using data from the Taiwan Stock Exchange demonstrate that our proposed method outperforms traditional linear models and other machine learning methods in predictive ability. The investment portfolio constructed serves as an invaluable aid to investment decision-making.},
  archive      = {J_APIN},
  author       = {Wu, Mei-Chen and Huang, Szu-Hao and Chen, An-Pin},
  doi          = {10.1007/s10489-024-05377-2},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4189-4209},
  shortjournal = {Appl. Intell.},
  title        = {Momentum portfolio selection based on learning-to-rank algorithms with heterogeneous knowledge graphs},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysing the impact of ChatGPT in research. <em>APIN</em>,
<em>54</em>(5), 4172–4188. (<a
href="https://doi.org/10.1007/s10489-024-05298-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are a type of machine learning that handles a wide range of Natural Language Processing (NLP) scenarios. Recently, in December 2022, a company called OpenAI released ChatGPT, a tool that, within a few months, became the most representative example of LLMs, automatically generating unique and coherent text on many topics, summarising and rewriting it, or even translating it to other languages. ChatGPT originated some controversy in academia since students can generate unique text for writing assessments being sometimes extremely difficult to distinguish whether it comes from ChatGPT or a person. In research, some journals specifically banned ChatGPT in scientific papers. However, when used correctly, it becomes a powerful tool to rewrite, for instance, scientific papers and, thus, deliver researchers’ messages in a better way. In this paper, we conduct an empirical study of the impact of ChatGPT in research. We downloaded the abstract of over 45,000 papers from over 300 journals from Dec 2022 and Feb 2023 belonging to different research editorials. We use four of the most known ChatGPT detection tools and conclude that ChatGPT played a role in around 10% of the papers published in every editorial, showing that authors from different fields have rapidly adopted such a tool in their research.},
  archive      = {J_APIN},
  author       = {Picazo-Sanchez, Pablo and Ortiz-Martin, Lara},
  doi          = {10.1007/s10489-024-05298-0},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4172-4188},
  shortjournal = {Appl. Intell.},
  title        = {Analysing the impact of ChatGPT in research},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An integrated decision framework for evaluating and
recommending health care services. <em>APIN</em>, <em>54</em>(5),
4153–4171. (<a
href="https://doi.org/10.1007/s10489-024-05396-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality management techniques such as the quality function deployment model can help hospitals assess and improve the quality of their services by integrating the voice of customers. The different quality parameters of this model are usually determined and assessed by experts; nonetheless, obtaining such experts is not always easy or inexpensive. Moreover, in this method, patient opinions are not usually considered directly, although they are the real users of the services and those who can best assess those services. Nevertheless, these opinions are easily accessible today, owing to the development of medical social networks where patients directly convey their opinions about the different services and features of a hospital. Therefore, it is feasible to replace expert knowledge with the information provided by these opinions. Based on this idea, this study proposes a novel fuzzy recommendation model based on the quality function deployment method to rank hospitals depending on patient opinions and preferences regarding hospital services. This model integrates a topic modeling strategy for determining hospital requirements, customer needs, and the relationship between them as well as a sentiment analysis algorithm for assessing customer satisfaction regarding hospital services. To demonstrate the usefulness of the proposed method, several experiments were conducted using patient reviews from real hospitals, and the method was compared against other recommendation models. The results prove that this approach represents a step toward more personalized and effective health care system selection considering patient preferences and opinions.},
  archive      = {J_APIN},
  author       = {Alshouha, Bashar and Serrano-Guerrero, Jesus and Chiclana, Francisco and Romero, Francisco P. and Olivas, Jose A.},
  doi          = {10.1007/s10489-024-05396-z},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4153-4171},
  shortjournal = {Appl. Intell.},
  title        = {An integrated decision framework for evaluating and recommending health care services},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SymforNet: Application of cross-modal information
correspondences based on self-supervision in symbolic music generation.
<em>APIN</em>, <em>54</em>(5), 4140–4152. (<a
href="https://doi.org/10.1007/s10489-024-05335-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we explore to address challenges related to incorrect scores, inconsistent rhythm and labeling in the generation of symbolic music scores, with a focus on the utilization of self-supervised models. We present the SymforNet model for symbolic music generation, which is based on self-supervision and deep learning. The model incorporates an attention mechanism and demonstrates exceptional proficiency in recognizing contextual elements of various categories. Experimental results indicate that: (1) The SymforNet model achieve an impressive 88% accuracy in generating music score; (2) In both the training and test sets, the SymforNet model exhibits significantly superior loss values, surpassing the all baseline models; (3) An examination of the multi-track Used Pitch Class data reveals that the SymforNet model, particularly in the context of sequences comprising three to four tracks, displays a strong correlation; (4) By comparing about the quality of music scores, SymforNet has a 87% rate of generating correct scores.},
  archive      = {J_APIN},
  author       = {Abudukelimu, Halidanmu and Chen, Jishang and Liang, Yunze and Abulizi, Abudukelimu and Yasen, Alimujiang},
  doi          = {10.1007/s10489-024-05335-y},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4140-4152},
  shortjournal = {Appl. Intell.},
  title        = {SymforNet: Application of cross-modal information correspondences based on self-supervision in symbolic music generation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). An adaptive evolutionary modular neural network with
intermodule connections. <em>APIN</em>, <em>54</em>(5), 4121–4139. (<a
href="https://doi.org/10.1007/s10489-024-05308-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To approach the brain-like neural network and further improve the performance of the modular neural network (MNN), an adaptive evolutionary modular neural network with intermodule connections (EA-ICMNN) is proposed in this study. The EA-ICMNN is composed of a group of multilayer neural networks. Unlike traditional MNNs, in addition to the intramodule connections of subnetworks, intermodule connections are built for EA-ICMNN. All the parameters of the EA-ICMNN are learned by the improved Levenberg–Marquardt algorithm, and the optimal structure is adaptively determined by the improved mutation operator in the multiobjective optimization algorithm NSGAII. To verify the effectiveness of the proposed model, the EA-ICMNN is tested on several benchmark datasets and a practical prediction problem for biochemical oxygen demand in wastewater treatment process. The experimental results show that the proposed model has better generalization ability than other MNNs and that its structure is simplified by its sparse intermodule connections.},
  archive      = {J_APIN},
  author       = {Li, Meng and Li, Wenjing and Chen, Zhiqian and Qiao, Junfei},
  doi          = {10.1007/s10489-024-05308-1},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4121-4139},
  shortjournal = {Appl. Intell.},
  title        = {An adaptive evolutionary modular neural network with intermodule connections},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Link prediction using deep autoencoder-like non-negative
matrix factorization with l21-norm. <em>APIN</em>, <em>54</em>(5),
4095–4120. (<a
href="https://doi.org/10.1007/s10489-024-05365-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction aims to predict missing links or eliminate spurious links and anticipate new links by analyzing observed network topological structure information. Non-negative matrix factorization(NMF) is widely used in solving the issue of link prediction due to its good interpretability and scalability. However, most existing NMF-based approaches involve shallow decoder models, which are incapable of capturing complex hierarchical information hidden in networks, and seldom consider random noise. To address these issues, a novel deep autoencoder-like nonnegative matrix factorization method with $$\varvec{L_{2,1}}$$ norm for link prediction models(DANMFL) is proposed. Unlike conventional NMF-based approaches, our model contains a decoder component and an encoder component, which capture complex hierarchical information effectively, leading to more accurate prediction results. In addition, we use the $$\varvec{L_{2,1}}$$ norm to remove random noise in each layer and the convergence of our model is strictly proven. We conduct extensive experiments on twelve real-world networks and the experimental results show that DANMFL is superior to existing state-of-the-art baseline approaches in terms of prediction accuracy. Codes are available at https://github.com/litongf/DANMFL .},
  archive      = {J_APIN},
  author       = {Li, Tongfeng and Zhang, Ruisheng and Yao, Yabing and Liu, Yunwu and Ma, Jun},
  doi          = {10.1007/s10489-024-05365-6},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4095-4120},
  shortjournal = {Appl. Intell.},
  title        = {Link prediction using deep autoencoder-like non-negative matrix factorization with l21-norm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-generation based method for few-shot learning with
few-shot instance-level privileged information. <em>APIN</em>,
<em>54</em>(5), 4077–4094. (<a
href="https://doi.org/10.1007/s10489-024-05388-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Learning (FSL) aims to recognize the novel classes from few novel samples. Recently, lots of methods have been proposed to improve FSL performance by introducing privileged information. However, on the one hand, they utilize the class name or class-level description generated by some tools such as WordNet as the privileged information. On the other hand, they are all one-generation based and just use the simple convex integration of visual modality and privileged information modality. Besides, the classic FSL dataset miniImageNet has no labels for few-shot instance-level privileged information. In this paper, we propose that the few-shot instance-level privileged information generated by few-shot visual images samples are more concrete and more diverse, which is more in line with the real world situation than the class-level privileged information that is the abstract concept summarized from a large number of visual image samples. For this, we propose a novel Two-generation based FSL method (2G-FSL) which transfers the prior knowledge from the prior model to the posterior model. This can make 2G-FSL learns the meta-knowledge about preserving correct prior knowledge and self-correcting erroneous prior knowledge after introducing the few-shot instance-level privileged information, growing into a more robust posterior model. In 2G-FSL, we introduce a novel Latent Feature Augmentation (LFA) module in posterior model to learn the episode-related augmentation and integration of the latent features of visual and privileged information modalities instead of the simple convex integration, which can generate diverse modality integration strategies for enhancing the diversity of latent features to make the features more robust to alleviate the insufficient data problem of FSL. We make the dataset of few-shot instance-level privileged information of miniImageNet publicly available for the subsequent research of FSL with few-shot instance-level privileged information. Experimental results demonstrate the effectiveness and superiority of 2G-FSL with LFA in FSL with few-shot instance-level privileged information.},
  archive      = {J_APIN},
  author       = {Xu, Jian and He, Jinghui and Liu, Bo and Cao, Fan and Xiao, Yanshan},
  doi          = {10.1007/s10489-024-05388-z},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4077-4094},
  shortjournal = {Appl. Intell.},
  title        = {A two-generation based method for few-shot learning with few-shot instance-level privileged information},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale pooling learning for camouflaged instance
segmentation. <em>APIN</em>, <em>54</em>(5), 4062–4076. (<a
href="https://doi.org/10.1007/s10489-024-05369-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged instance segmentation (CIS) focuses on handling instances that attempt to blend into the background. However, existing CIS methods emphasize global interactions but overlook hidden clues at various scales, resulting in inaccurate recognition of camouflaged instances. To address this, we propose a multi-scale pooling network (MSPNet) to mine the hidden cues offered by the camouflaged instances at various scales. The network achieves an enhanced fusion of multi-scale information mainly through multilayer pooling. Specifically, the pyramid pooling transformer (P2T) is utilized as a robust backbone for extracting multi-scale features. Then, we introduce an end-to-end pooling learning transformer (PLT) to obtain instance-aware parameters and high-quality mask features. To further augment the fusion of various mask features, we design a novel multi-scale complementary feature pooling (MCFP) module. Additionally, we also suggest an instance normalization module with fused spatial attention (FSA-IN) to combine instance-aware parameters and mask features, resulting in the final camouflaged instances. Experimental results show the effectiveness of MSPNet, surpassing existing CIS models on the COD10K-Test and NC4K datasets, with respective average precision (AP) scores of 49.6% and 53.4%. This demonstrates the effectiveness of the proposed approach in detecting camouflaged instances. Our code will be published at https://github.com/another-u/MSPNet-main .},
  archive      = {J_APIN},
  author       = {Li, Chen and Jiao, Ge and Yue, Guowen and He, Rong and Huang, Jiayu},
  doi          = {10.1007/s10489-024-05369-2},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4062-4076},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale pooling learning for camouflaged instance segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Cognitive radio resource scheduling using an adaptive
multiobjective evolutionary algorithm. <em>APIN</em>, <em>54</em>(5),
4043–4061. (<a
href="https://doi.org/10.1007/s10489-024-05398-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of IoT devices and the increasing popularity of location-oriented services in cyber-physical-social systems, the cognitive engines of these systems have taken on a multitude of parameters across various dimensions, making it impractical and time-consuming to search for the exact optimal solution. To address this challenge, the use of nature-inspired or evolutionary algorithms to find satisfactory solutions in a timely manner has gained significant attention, with reference point-based algorithms being one of the prominent approaches. However, when dealing with nonuniform, degenerate, and discrete Pareto fronts in the target space, using a considerable number of reference points may become ineffective, leading to a loss of diversity in exploration and exploitation during the problem-solving process. Consequently, the distribution of the solutions is adversely affected. To overcome this challenge, this paper presents a strategy to estimate the eigenvalues of the Pareto front in a timely manner. When encountering nonuniform, degenerate, and discrete Pareto fronts, a combination of radial space partitioning and angle selection mechanisms is employed to address these issues. Subsequently, an adaptive selection-based many-objective evolutionary algorithm (ASMaOEA) is proposed. Extensive comparisons with several competing methods on 31 representative benchmark problems demonstrate that ASMaOEA can provide a flexible configuration for decision engines in three typical scenarios involving cyber-physical-social systems. Furthermore, the analysis confirms that ASMaOEA can reduce the bit error rate and improve the system’s throughput, thereby offering substantial benefits to the overall performance of the system.},
  archive      = {J_APIN},
  author       = {Wang, Hongbo and Wang, Yizhe and Zeng, Fanbing and Wang, Jin},
  doi          = {10.1007/s10489-024-05398-x},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4043-4061},
  shortjournal = {Appl. Intell.},
  title        = {Cognitive radio resource scheduling using an adaptive multiobjective evolutionary algorithm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient algorithms to mine concise representations of
frequent high utility occupancy patterns. <em>APIN</em>, <em>54</em>(5),
4012–4042. (<a
href="https://doi.org/10.1007/s10489-024-05296-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying all frequent high utility occupancy itemsets (FHUOIs) in a quantitative transaction dataset is a new trend in data mining. By combining both factors of frequency and utility occupancy, these patterns are more suitable for several applications in the real world. These patterns not only reflect the interests of most users but also contribute a high proportion of the utility in supporting transactions. Nonetheless, the set of all discovered FHUOIs may be very large, especially for large and dense datasets or for low values of predefined minimum thresholds. For this reason, it is often quite challenging for users to analyze and use the obtained patterns. To address this issue, this paper proposes two novel algorithms named MaxCloFHUOIM and CloFHUOIM to extract compact representations of FHUOIs. The former is designed to simultaneously mine two concise representations of FHUOIs that consist of all closed FHUOIs and all maximal FHUOIs, whereas the latter only discovers the closed FHUOIs, which provide a lossless summary of all FHUOIs. The proposed algorithms rely on a novel weak upper bound on utility occupancy, to reduce the search space by quickly pruning itemsets with low utility occupancy. Especially, the algorithms integrate two new efficient strategies to prune non-closed FHUOI candidate branches early in the prefix search tree. Results from an in-depth experimental evaluation conducted on several benchmark real-life and synthetic quantitative datasets demonstrate that MaxCloFHUOIM and CloFHUOIM have excellent performance in terms of runtime, memory usage, and scalability. In particular, the proposed algorithms are up to two orders of magnitude faster than a baseline algorithm.},
  archive      = {J_APIN},
  author       = {Duong, Hai and Pham, Huy and Truong, Tin and Fournier-Viger, Philippe},
  doi          = {10.1007/s10489-024-05296-2},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {4012-4042},
  shortjournal = {Appl. Intell.},
  title        = {Efficient algorithms to mine concise representations of frequent high utility occupancy patterns},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TV-ALP: A log dataset of television assembly line production
under multi-person collaboration for process mining research.
<em>APIN</em>, <em>54</em>(5), 3990–4011. (<a
href="https://doi.org/10.1007/s10489-024-05347-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining technology has been widely used to optimize the processes of various organizations, especially in enterprises. It facilitates cooperation between departments and prompts efficient process design and resource scheduling in the production workshop. However, as a data-driven approach, the lack of production logs hinders the development of enterprise process mining research. Therefore, we introduce a new benchmark dataset named TV-ALP to provide effective data support for the combination of process mining and workshop production. The dataset comes from the field survey experience and product operation instructions, which highly restores the operation of the production workshop and details the processing of television (TV) sets in the assembly line. We compare TV-ALP with other public datasets for detailed statistical analysis and provide benchmark performance for the remaining time prediction task. The experimental results show that TV-ALP can meet the requirements of process mining and analysis research in terms of both scale and quality. In addition, while maintaining the data commonality of public datasets, it also emphasizes the importance of role information and supports a series of role-based log studies. The complete dataset is accessible for download at https://github.com/Zzou-Sdust/TV-ALP-dataset.},
  archive      = {J_APIN},
  author       = {Zou, Minghao and Zeng, Qingtian and Duan, Hua and Ni, Weijian and Chen, Shuang},
  doi          = {10.1007/s10489-024-05347-8},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3990-4011},
  shortjournal = {Appl. Intell.},
  title        = {TV-ALP: A log dataset of television assembly line production under multi-person collaboration for process mining research},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local feature matching from detector-based to detector-free:
A survey. <em>APIN</em>, <em>54</em>(5), 3954–3989. (<a
href="https://doi.org/10.1007/s10489-024-05330-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local feature matching has been a critical task in computer vision applications. In the early days of computer vision, local feature matching relied heavily on detector-based methods, where keypoint detectors were used to extract and describe the salient features of an image. However, with the advent of deep learning, detector-free methods that do not rely on keypoint detection have become increasingly popular. These methods directly learn feature descriptors from the image data, leading to improved performance and faster computation times. In this review, we explore the evolution of local feature matching from detector-based to detector-free methods, discussing the advantages and disadvantages of each approach and highlighting the recent advancements in the field. We also discuss the challenges and opportunities for future research in this area.},
  archive      = {J_APIN},
  author       = {Liao, Yun and Di, Yide and Zhu, Kaijun and Zhou, Hao and Lu, Mingyu and Zhang, Yijia and Duan, Qing and Liu, Junhui},
  doi          = {10.1007/s10489-024-05330-3},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3954-3989},
  shortjournal = {Appl. Intell.},
  title        = {Local feature matching from detector-based to detector-free: A survey},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental feature selection for large-scale hierarchical
classification with the arrival of new samples. <em>APIN</em>,
<em>54</em>(5), 3933–3953. (<a
href="https://doi.org/10.1007/s10489-024-05352-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, the amount of class labels is growing rapidly, which poses a great challenge to classification tasks. The hierarchical classification was thus introduced to address this issue by considering the structural information between different class labels. In this paper, we propose an incremental feature selection algorithm for handling the arrival of new samples by using the theory of fuzzy rough sets. As a preliminary step, we propose a non-incremental hierarchical feature selection algorithm, which is an improved version of the existing method. Then utilizing the sibling strategy, the incremental calculation of the dependency degree at the arrival of samples is discussed. Based on the analysis of dependency degree change, we design feature addition and deletion strategies, as well as the incremental feature selection algorithm. In the experimental section, two versions of algorithms are designed. The experimental results show that our improvement of the existing method is highly effective and can significantly accelerate the process of feature selection. In addition, version 2 of the incremental algorithm exhibits much higher efficiency than the improved non-incremental algorithm on several datasets, as well as the existing method. Compared to six hierarchical feature selection algorithms, our algorithm achieves better results on the classification accuracy and three hierarchical evaluation metrics. The effectiveness and efficiency of version 1 are also verified by the comparison of version 2 and other results.},
  archive      = {J_APIN},
  author       = {Tian, Yang and She, Yanhong},
  doi          = {10.1007/s10489-024-05352-x},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3933-3953},
  shortjournal = {Appl. Intell.},
  title        = {Incremental feature selection for large-scale hierarchical classification with the arrival of new samples},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning evolving relations for multivariate time series
forecasting. <em>APIN</em>, <em>54</em>(5), 3918–3932. (<a
href="https://doi.org/10.1007/s10489-023-05220-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting is essential in various fields, including healthcare and traffic management, but it is a challenging task due to the strong dynamics in both intra-channel relations (temporal patterns within individual variables) and inter-channel relations (the relationships between variables), which can evolve over time with abrupt changes. This paper proposes ERAN (Evolving Relational Attention Network), a framework for multivariate time series forecasting, that is capable to capture such dynamics of these relations. On the one hand, ERAN represents inter-channel relations with a graph which evolves over time, modeled using a recurrent neural network. On the other hand, ERAN represents the intra-channel relations using a temporal attentional convolution, which captures the local temporal dependencies adaptively with the input data. The elvoving graph structure and the temporal attentional convolution are intergrated in a unified model to capture both types of relations. The model is experimented on a large number of real-life datasets including traffic flows, energy consumption, and COVID-19 transmission data. The experimental results show a significant improvement over the state-of-the-art methods in multivariate time series forecasting particularly for non-stationary data.},
  archive      = {J_APIN},
  author       = {Nguyen-Thai, Binh and Le, Vuong and Tieu, Ngoc-Dung T. and Tran, Truyen and Venkatesh, Svetha and Ramzan, Naeem},
  doi          = {10.1007/s10489-023-05220-0},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3918-3932},
  shortjournal = {Appl. Intell.},
  title        = {Learning evolving relations for multivariate time series forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decoding human taste perception by reconstructing and mining
temporal-spatial features of taste-related EEGs. <em>APIN</em>,
<em>54</em>(5), 3902–3917. (<a
href="https://doi.org/10.1007/s10489-024-05374-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For humans, taste is essential for perceiving the nutrient content or harmful components of food. The current method of taste sensory evaluation relies on artificial sensory evaluation and an electronic tongue. The former has strong subjectivity and poor repeatability, and the latter is not sufficiently flexible. To decode people&#39;s objective taste perception, a strategy for acquiring and recognizing four classes (sour, sweet, bitter, and salty) in taste-related electroencephalograms (EEGs) was proposed. First, according to the proposed experimental paradigm, the taste-related EEGs of subjects under different taste stimulations were collected. Second, to avoid insufficient training of the model due to the small number of EEG samples, a temporal and spatial reconstruction data augmentation (TSRDA) method was proposed, effectively augmenting taste-related EEGs by reconstructing the important features in temporal and spatial dimensions. Third, a multiview channel attention (MVCA) module was introduced into a designed convolutional neural network to extract the important features of the augmented EEG. The proposed method had an accuracy of 99.56%, F1 score of 99.48%, and kappa value of 99.38%, showing the method&#39;s ability to successfully decoded sour, sweet, bitter, and salty EEG signals. In conclusion, combining TSRDA with EEG technology provides an objective and effective method for the sensory evaluation of food taste.},
  archive      = {J_APIN},
  author       = {Xia, Xiuxin and Yang, Yuchao and Shi, Yan and Zheng, Wenbo and Men, Hong},
  doi          = {10.1007/s10489-024-05374-5},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3902-3917},
  shortjournal = {Appl. Intell.},
  title        = {Decoding human taste perception by reconstructing and mining temporal-spatial features of taste-related EEGs},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PCS-granularity weighted ensemble clustering via
co-association matrix. <em>APIN</em>, <em>54</em>(5), 3884–3901. (<a
href="https://doi.org/10.1007/s10489-024-05368-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble clustering has attracted much attention for its robustness and effectiveness compared to single clustering. As one of the representative methods, most co-association matrix-based ensemble clustering typically only take into account a single type of information contained in base partitions. This study proposes a new weighted ensemble clustering algorithm of fusing multi-level data information to sufficiently mine the information from the base partition family. Three different levels of data information, including partition granularity level, cluster granularity level and sample granularity level, are concomitantly considered in the co-association matrix. More specifically, we utilize knowledge granularity to measure the quality of base partitions, and rough membership to quantify the credibility of base clusters; Additionally, the relative similarity of a pair of samples is estimated with respect to different base partitions, taking into account the close relationship between samples and the structure of base clusters. Subsequently, the partition-cluster-sample-granularity weighted co-association (PCSCA) matrix is proposed to address the limitations of the co-association matrix, quantifying the quality of information at multiple levels. Finally, this study introduces the partition-cluster-sample-granularity weighted ensemble clustering (PCSEC), which incorporates the PCSCA matrix. The experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Wu, Zhishan and Cai, Mingjie and Xu, Feng and Li, Qingguo},
  doi          = {10.1007/s10489-024-05368-3},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3884-3901},
  shortjournal = {Appl. Intell.},
  title        = {PCS-granularity weighted ensemble clustering via co-association matrix},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). A structure for predicting wind speed using fuzzy
granulation and optimization techniques. <em>APIN</em>, <em>54</em>(5),
3859–3883. (<a
href="https://doi.org/10.1007/s10489-023-04906-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing scarcity of global energy, the rapid development of science and technology, and the growing demand for environmental protection, wind energy is receiving increasing attention as the cleanest source of energy. Due to its pollution-free nature and widespread availability, it has become a preferred source of electricity generation in many countries. However, wind speed prediction plays a vital role in wind power generation. Traditional prediction models, due to randomness and uncertainty, often produce unstable and inaccurate results, leading to power and economic losses. Therefore, this study proposes a hybrid prediction system based on an information processing strategy and a multi-objective optimization algorithm. By preprocessing the data and optimizing the combination of five individual models, the singularity of a single model is overcome, a Pareto-optimal solution is obtained, and accurate and stable prediction results are provided. To verify the effectiveness of the proposed combined model in predicting wind speed, various experiments on a wind speed series were conducted based on a wind power station located in Penglai, China. The results show that the combined model proposed in this study has better prediction performance than conventional models.},
  archive      = {J_APIN},
  author       = {Wang, ShiWen and Wang, Jianzhou and Zeng, Bo and Zhao, Weigang},
  doi          = {10.1007/s10489-023-04906-9},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3859-3883},
  shortjournal = {Appl. Intell.},
  title        = {A structure for predicting wind speed using fuzzy granulation and optimization techniques},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Pose pattern mining using transformer for motion
classification. <em>APIN</em>, <em>54</em>(5), 3841–3858. (<a
href="https://doi.org/10.1007/s10489-024-05325-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capitalizing on the rapid development of diverse deep learning technologies in the field of image analysis, studies are now being conducted to detect objects within images, estimate the poses of target objects, and classify motions. However, the magnitude of image data and computational complexity present challenges in performing real-time image analysis. In addition, the classification of human motions, specifically, requires an effective methodology based on analysis of the changing features of poses from frame to frame. To address this, pose pattern mining using a transformer for motion classification is proposed, which expands the output of the neural network of an object detection model into a time-series pose classification model combining EfficientNet and transformer mechanisms. With regard to the structure of the configured model, the object detection model maintains the mechanisms and displays the effect of expanding the output node of the internal neural network into a time-series-based pose-motion analysis model. Sequence pattern mining is then applied to ensure the efficiency of the data analysis. This hybrid methodology achieved a response time of 0.059 s per frame and an accuracy of 86.67%. Therefore, it may be surmised that this proposed method can be applied to fields such as security and surveillance systems that require fast processing times and high levels of accuracy.},
  archive      = {J_APIN},
  author       = {Lee, Seo-El and Yoo, Hyun and Chung, Kyungyong},
  doi          = {10.1007/s10489-024-05325-0},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3841-3858},
  shortjournal = {Appl. Intell.},
  title        = {Pose pattern mining using transformer for motion classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust depth completion based on semantic aggregation.
<em>APIN</em>, <em>54</em>(5), 3825–3840. (<a
href="https://doi.org/10.1007/s10489-024-05366-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Guided by information from RGB images, depth completion methods rebuild the dense depth from sparse depth input. However, the varying densities of valid pixels in sparse depth maps pose a significant challenge to the robustness of the completion model. To improve the robustness of depth completion, we propose a two-stage model called Semantic Aggregated Depth Completion (SADC) in this paper, comprising a coarse-grained completion stage and a fine-grained completion stage. In the coarse-grained completion stage, the Semantic Extraction Network (SEN) extracts RGB features and sends them to the Dynamic Semantic Aggregation (DSA) to predict the local semantic relationship (LSR) matrix. DSA aggregates the valid information based on the LSR matrix iteratively, resulting in coarse-grained completion results. In the fine-grained completion stage, SADC uses the Semantic Guidance Network (SGN) and Semantic Guidance Fusion (SGF) modules to refine the dense depth features from coarse-grained completion results by RGB features in multi-level and predict fine-grained completion results. We validate our method on NYU-v2 and KITTI with different valid pixel densities. The results demonstrate that SADC performs best results on benchmark tests and exhibits robustness to different densities without retraining.},
  archive      = {J_APIN},
  author       = {Fu, Zhichao and Li, Xin and Huai, Tianyu and Li, Weijie and Dong, Daoguo and He, Liang},
  doi          = {10.1007/s10489-024-05366-5},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3825-3840},
  shortjournal = {Appl. Intell.},
  title        = {Robust depth completion based on semantic aggregation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MFU-net: A deep multimodal fusion network for breast cancer
segmentation with dual-layer spectral detector CT. <em>APIN</em>,
<em>54</em>(5), 3808–3824. (<a
href="https://doi.org/10.1007/s10489-023-05090-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of medical imaging technologies, breast cancer segmentation remains challenging, especially when considering multimodal imaging. Compared to a single-modality image, multimodal data provide additional information, contributing to better representation learning capabilities. This paper applies these advantages by presenting a deep learning network architecture for segmenting breast cancer with multimodal computed tomography (CT) images based on fusing U-Net architectures that can learn richer representations from multimodal data. The multipath fusion architecture introduces an additional fusion module across different paths, enabling the model to extract features from different modalities at each level of the encoding path. This approach enhances segmentation performance and produces more robust results compared to using a single modality. The study reports experiments conducted on multimodal CT images from 36 patients for training, validation, and testing purposes. The results demonstrate that the proposed model ouperforms the U-Net architecture when considering different combinations of input image modalities. Specifically, when combining two distinct CT modalities, the ZE and IoNW input combination yields the highest Dice score of 0.8546.},
  archive      = {J_APIN},
  author       = {Yang, Aisen and Xu, Lulu and Qin, Na and Huang, Deqing and Liu, Ziyi and Shu, Jian},
  doi          = {10.1007/s10489-023-05090-6},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3808-3824},
  shortjournal = {Appl. Intell.},
  title        = {MFU-net: A deep multimodal fusion network for breast cancer segmentation with dual-layer spectral detector CT},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tri-level attribute reduction based on neighborhood rough
sets. <em>APIN</em>, <em>54</em>(5), 3786–3807. (<a
href="https://doi.org/10.1007/s10489-024-05361-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tri-level attribute reduction is an interesting topic that aims to reduce the data dimensionality from different levels and granularity perspectives. However, existing research exhibits limitations, mainly in handling symbolic data, lack of effective reduction algorithms, and scarcity of data experiments and performance evaluations, which would be an obstacle to the further development of tri-level attribute reduction in theory and application. Hence, we systematically investigate tri-level attribute reduction based on neighborhood rough sets (NRSs) for numerical data. We first give the class-specific and object-specific attribute reduction conditions based on NRS, respectively. Furthermore, we explore and analyze relationships of tri-level reducts. From the perspective of forward and backward reduction, we propose algorithms of class-specific attribute reduction based on dependency degree, and object-specific reduction algorithms based on inconsistency degree. Finally, we introduce a novel metric to validate the efficiency of specific class and specific object attribute reductions. The results of data experiments show the feasibility and effectiveness of tri-level attribute reduction based on NRS in data analysis.},
  archive      = {J_APIN},
  author       = {Luo, Lianhui and Yang, Jilin and Zhang, Xianyong and Luo, Junfang},
  doi          = {10.1007/s10489-024-05361-w},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3786-3807},
  shortjournal = {Appl. Intell.},
  title        = {Tri-level attribute reduction based on neighborhood rough sets},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-based substructure pattern mining with edge-weight.
<em>APIN</em>, <em>54</em>(5), 3756–3785. (<a
href="https://doi.org/10.1007/s10489-024-05356-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To represent complex inter-relationships among entities, weighted graphs are more useful than their unweighted counterparts. In a transactional graph setting, researchers have made several attempts to mine weighted frequent subgraphs from a collection of edge-weighted graphs, which will serve as the representative feature of the underlying graph database and can be further used for analysis. As weighted support of any pattern does not hold downward closure property, a property that is often used in frequent pattern mining to control search space, has made weighted frequent substructure mining a tremendously difficult task. This article proposes an efficient weighted frequent subgraph mining framework called WFSM-MaxPWS for graphs with static edge weights. We introduce a new pruning technique called MaxPWS pruning along with canonical labeling of subgraphs, which helps reduce the search space significantly without compromising completeness. Extending the WFSM-MaxPWS framework, we propose another framework called DewgSpan that is capable of mining graphs with dynamic edge weight. DewgSpan utilizes a summarized edge-weight distribution table to overcome the new challenges of dynamic edge-weight settings. Evaluation results show that WFSM-MaxPWS and DewgSpan are significantly faster than the existing MaxW pruning technique of weighted pattern mining.},
  archive      = {J_APIN},
  author       = {Islam, Md. Ashraful and Ahmed, Chowdhury Farhan and Alam, Md. Tanvir and Leung, Carson Kai-Sang},
  doi          = {10.1007/s10489-024-05356-7},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3756-3785},
  shortjournal = {Appl. Intell.},
  title        = {Graph-based substructure pattern mining with edge-weight},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). One-stop multiscale reconciliation attention network with
scribble supervision for salient object detection in optical remote
sensing images. <em>APIN</em>, <em>54</em>(5), 3737–3755. (<a
href="https://doi.org/10.1007/s10489-024-05359-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection in optical remote sensing images (RSI-SOD) faces significant challenges due to the unique characteristics of RSI imaging. Existing methods heavily rely on labor-intensive pixel-level annotations and overlook the potential of low-cost sparse annotations. Moreover, weakly supervised RSI-SOD methods introduce multiple sparse annotations and training processes, leading to a multistaged SOD task and considerable performance gaps compared to fully supervised approaches. To address these issues, we propose a one-stop end-to-end RSI-SOD method that solely relies on scribble annotations. Our framework, named the one-stop multiscale reconciliation attention network (OMRA-Net), features encoding, reconciliation, polishing, and convergence layers for effective feature extraction, reconciliation, polishing, and object structure restoration. Evaluation on publicly available datasets demonstrates that OMRA-Net outperforms existing weakly supervised and unsupervised SOD methods, achieving comparable or superior performance to fully supervised models. Ablation studies further validate the effectiveness of our proposed model design.},
  archive      = {J_APIN},
  author       = {Yan, Ruixiang and Yan, Longquan and Cao, Yufei and Geng, Guohua and Zhou, Pengbo},
  doi          = {10.1007/s10489-024-05359-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3737-3755},
  shortjournal = {Appl. Intell.},
  title        = {One-stop multiscale reconciliation attention network with scribble supervision for salient object detection in optical remote sensing images},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross modality person re-identification via mask-guided
dynamic dual-task collaborative learning. <em>APIN</em>, <em>54</em>(5),
3723–3736. (<a
href="https://doi.org/10.1007/s10489-024-05344-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared cross modality person re-identification (CM-ReID) has received extensive attention on the community due to its profound applicability for 24-h scene surveillance. The huge modality discrepancy makes it very susceptible to background clutter, especially for infrared images. In this paper, we propose a mask-guided dynamic dual-task collaborative learning (MG-DDCL) method to extract background irrelevant pedestrian representation. A dynamic dual-task collaborative learning strategy is proposed to extract pedestrian representation and generate foreground masks by a unified convolutional neural network. This strategy improved the map by 0.95% and improved the Rank-1 by 1.9%. To make the guidance mask to facilitate the cross modality person re-identification task, we modify the hard-mask produced by semantic segmentation into the friendly soft-mask and generate foreground response map by the regression learning manner. Compared with the classification manner, our method has significant advantages. Extensive experiments conducted on two datasets SYSU-MM01 and RegDB demonstrate the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Shao, Wenbin and Liu, Yujie and Zhang, Wenxin and Li, Zongmin},
  doi          = {10.1007/s10489-024-05344-x},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3723-3736},
  shortjournal = {Appl. Intell.},
  title        = {Cross modality person re-identification via mask-guided dynamic dual-task collaborative learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advanced linguistic intuitionistic fuzzy maclaurin symmetric
means for MAGDM. <em>APIN</em>, <em>54</em>(5), 3680–3722. (<a
href="https://doi.org/10.1007/s10489-023-05225-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two multi-attribute group decision-making (MAGDM) algorithms that rely on ingenious linguistic intuitionistic fuzzy (LIF) weighted Maclaurin symmetric means. At the outset, the advanced LIF Maclaurin symmetric mean (ALIFMSM), advanced LIF weighted Maclaurin symmetric mean (ALIFWMSM), advanced LIF dual Maclaurin symmetric mean (ALIFDMSM) and advanced LIF weighted dual Maclaurin symmetric mean (ALIFWDMSM) are introduced in response to the effect of the extreme values on the available LIF correlation means. Then, we present a typical MAGDM algorithm based on the ALIFWMSM (resp. ALIFWDMSM) (Algorithm I), and a practical example shows that it overcomes the defects of a series of existing algorithms. Moreover, considering that the research on LIF numbers (LIFNs) as the attribute weights and the decision- maker (DM) weights has not been reported thus far, we devise an additional MAGDM algorithm relying on the ALIFWMSM (Algorithm II). Algorithm II is for such problems where each DM, according to their respective perceptions, not only provides the LIF evaluation values for the alternatives, but also assigns the LIF importance for the attributes; meanwhile, DMs’ LIF importance is generated through negotiation and compromise among group members. Algorithm II consists of two main phases as follows: The 1st phase derives the combined attribute weights corresponding to each DM and the combined DM weights; the 2nd phase fuses evaluation information of the alternatives by the ALIFWMSM. Finally, Algorithm II is used to address a real-world case. Additionally, a comparative analysis with other similar works is performed to illustrate its novelty.},
  archive      = {J_APIN},
  author       = {Li, Jinjun and Chen, Minghao},
  doi          = {10.1007/s10489-023-05225-9},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3680-3722},
  shortjournal = {Appl. Intell.},
  title        = {Advanced linguistic intuitionistic fuzzy maclaurin symmetric means for MAGDM},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concept logic trees: Enabling user interaction for
transparent image classification and human-in-the-loop learning.
<em>APIN</em>, <em>54</em>(5), 3667–3679. (<a
href="https://doi.org/10.1007/s10489-024-05321-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretable deep learning models are increasingly important in domains where transparent decision-making is required. In this field, the interaction of the user with the model can contribute to the interpretability of the model. In this research work, we present an innovative approach that combines soft decision trees, neural symbolic learning, and concept learning to create an image classification model that enhances interpretability and user interaction, control, and intervention. The key novelty of our method relies on the fusion of an interpretable architecture with neural symbolic learning, allowing the incorporation of expert knowledge and user interaction. Furthermore, our solution facilitates the inspection of the model through queries in the form of first-order logic predicates. Our main contribution is a human-in-the-loop model as a result of the fusion of neural symbolic learning and an interpretable architecture. We validate the effectiveness of our approach through comprehensive experimental results, demonstrating competitive performance on challenging datasets when compared to state-of-the-art solutions.},
  archive      = {J_APIN},
  author       = {Rodríguez, David M. and Cuéllar, Manuel P. and Morales, Diego P.},
  doi          = {10.1007/s10489-024-05321-4},
  journal      = {Applied Intelligence},
  month        = {3},
  number       = {5},
  pages        = {3667-3679},
  shortjournal = {Appl. Intell.},
  title        = {Concept logic trees: Enabling user interaction for transparent image classification and human-in-the-loop learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RETRACTED ARTICLE: An innovative natural-derived
meta-heuristic optimization method. <em>APIN</em>, <em>54</em>(4), 3665.
(<a href="https://doi.org/10.1007/s10489-016-0805-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Zare, Nasrin and Shameli, Hosein and Parvin, Hamid},
  doi          = {10.1007/s10489-016-0805-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3665},
  shortjournal = {Appl. Intell.},
  title        = {RETRACTED ARTICLE: An innovative natural-derived meta-heuristic optimization method},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Short-term traffic flow prediction based on SAE and its
parallel training. <em>APIN</em>, <em>54</em>(4), 3650–3664. (<a
href="https://doi.org/10.1007/s10489-023-05157-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The alleviation of traffic congestion relies on efficient traffic control and traffic guidance, which are based on real-time short-term traffic flow prediction. In this paper, the stacked autoencoder (SAE) deep learning model with powerful feature learning capability is selected to predict the traffic flow on road sections. The process of training SAE includes the pre-training phase and the fine-tuning phase, which mainly apply the BP algorithm. However, the process of training SAE is time-consuming and cannot meet the real-time performance of modern application systems. This paper proposes a parallel training strategy for the SAE prediction model based on data parallel mode. The gradient solution process in our algorithm satisfies the conditions of parallel computing, so the training process can be designed in a parallel manner. The original dataset is distributed to some computing nodes, which are work nodes. The work node is responsible for gradient calculation using the local data. The task of the sole master node is to synthesize the gradient calculation results and then broadcast the updated gradient to each work node. The simulation results show that the SAE-based prediction model achieves better results than the traditional model, and the parallel algorithm reduces the running time of training processes.},
  archive      = {J_APIN},
  author       = {Tan, Xiaoxue and Zhou, Yonghua and Zhao, Lu and Mei, Yiduo},
  doi          = {10.1007/s10489-023-05157-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3650-3664},
  shortjournal = {Appl. Intell.},
  title        = {Short-term traffic flow prediction based on SAE and its parallel training},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep dependence in hydroclimatological variables.
<em>APIN</em>, <em>54</em>(4), 3629–3649. (<a
href="https://doi.org/10.1007/s10489-024-05345-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among artificial intelligence (AI) models, the recurrent neural network (RNN)-based temporal AI, long short-term memory (LSTM) model has been successfully applied to hydroclimatological time series due to its long-lead-time predictions. However, few logical reasons and explanations for its performance by investigating and discovering its deep structure have been made. Therefore, research on the outlook for LSTM models was conducted in the current study by investigating its hidden states and was focused on the dependence structures and statistical behaviors. Here, the three most critical datasets of hydroclimatological variables were applied as the representative climate index data for the Pacific Decadal Oscillation (PDO) and two critical rivers, the Colorado River and Nile River. The results indicate that each hidden unit is responsible for different frequency variations in the input data and is sensitive to special occasions of input data. This separation of the roles of the hidden units leads to variations in the dependence structure along with the numbers of hidden units and the unique characteristics of statistical behaviors. Specifically, the dependence decreases along with the increase in the number of hidden units until the complex structure of the original input data is appropriately separated into the independent hidden units. Overall, the current study reveals that there is a relationship between attaining maturity of the deep learning LSTM model and the dependence structure of the hidden units, especially for hydroclimatological variables, and concludes that the dependence structure of the hidden units can provide valuable information to further extract the explanations of the deep learning model and to select an appropriate model structure, including the number of hidden units. This finding can help to simulate and predict climate and hydrologic conditions whose long-term behaviors are critical for water resource management.},
  archive      = {J_APIN},
  author       = {Lee, Taesam and Kim, Jongsuk},
  doi          = {10.1007/s10489-024-05345-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3629-3649},
  shortjournal = {Appl. Intell.},
  title        = {Deep dependence in hydroclimatological variables},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ResMFuse-net: Residual-based multilevel fused network with
spatial–temporal features for hand hygiene monitoring. <em>APIN</em>,
<em>54</em>(4), 3606–3628. (<a
href="https://doi.org/10.1007/s10489-024-05305-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automation of hand hygiene monitoring is critical in healthcare for ensuring clean hands and preventing infectious disease spread. While advancements have been made, existing methods have limitations in accurately detecting and classifying handwashing actions. This paper addresses these limitations and introduces the Residual-Based Multilevel Fused Network (ResMFuse-Net) as a novel approach to automate the quality assurance of hand hygiene procedures. Our model integrates advanced techniques, including feature fusion, model compression, a feature fusion block (FFB), and a modified separable residual block (SE-ResB). The proposed model fused two networks into one trainable feature extraction pipeline, and applies model compression to retain the core blocks that are crucial for propagating strong and robust features while conserving a significant fraction of the computing resources. Additionally, we introduce a FFB that includes ConvLSTM and alpha dropout to learn spatial dependencies, establish correlations between frames in a video, and mitigate overfitting. This paper introduces a SE-ResB, which is a customized residual component composed of separable convolutions and LeakyReLU activation. The SE-ResB is incorporated to handle the fused features and generate a more diverse set of features, leading to considerable performance enhancements. This study also includes an ablation analysis that highlights the importance of each component. The proposed ResMFuse-Net is evaluated on two datasets: a newly created handwashing dataset (451 videos) and a publicly available dataset (656 videos). Achieving a recognition accuracy of 97.61% on the handwashing dataset and 98.69% on the other dataset, the ResMFuse-Net outperforms previous methods with fewer parameters and FLOPs, demonstrating its efficiency and cost-effectiveness.},
  archive      = {J_APIN},
  author       = {Asif, Sohaib and Xu, Xinyi and Zhao, Ming and Chen, Xuehan and Tang, Fengxiao and Zhu, Yusen},
  doi          = {10.1007/s10489-024-05305-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3606-3628},
  shortjournal = {Appl. Intell.},
  title        = {ResMFuse-net: Residual-based multilevel fused network with spatial–temporal features for hand hygiene monitoring},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale decision systems with test cost and applications
to three-way multi-attribute decision-making. <em>APIN</em>,
<em>54</em>(4), 3591–3605. (<a
href="https://doi.org/10.1007/s10489-024-05307-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real life, humans often need to deal with data hierarchically structured at different levels. The more detailed data that is collected, the greater the cost will be. When humans make decisions, they often want to achieve the goal while paying a lower cost. Therefore, it is necessary to construct a multi-scale three-way multi-attribute decision-making model with cost consideration. First, this paper proposes a multi-scale decision system with test cost, considering the conditional attribute costs at different scales. Second, the optimal scale is selected based on information entropy and total test cost. Then, we construct a new neighborhood, probability function, and relative loss function. On this basis, we establish a three-way decision model for multi-scale decision systems to solve multi-attribute decision-making problems. Finally, the experiments show that the proposed method can effectively reduce the cost while achieving the decision-making goal, demonstrating the effectiveness and superiority of the method.},
  archive      = {J_APIN},
  author       = {Wu, Jiaming and Liu, Danyue and Huang, Zhehuang and Li, Jinjin},
  doi          = {10.1007/s10489-024-05307-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3591-3605},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale decision systems with test cost and applications to three-way multi-attribute decision-making},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Crowdfunding project evaluation based on fermatean fuzzy
SAHARA three-way decision method. <em>APIN</em>, <em>54</em>(4),
3566–3590. (<a
href="https://doi.org/10.1007/s10489-024-05334-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdfunding is a web-based financing scheme which aims to generate initial capital for startups. Nowadays, there are numerous programs which face the shortage in capital has already launching by crowdfunding. Meanwhile, there are always lots of potential investors who are puzzled by their choices and are thus cannot join them. In this paper, an assessment framework of crowdfunding projects founded on the three-way decision (TWD) is offered to solve the issue. The fuzziness and uncertainty in the evaluation information are the major factors affecting the accuracy of the output and the Fermatean fuzzy sets (FFS) of the proposed model conquers the problem. A Preference Selection Index - Standard Deviation Bayesian method is arranged to determine objective attribute weights with the precise and reliable data. Traditional fuzzy aggregation operators do not perform well in extreme and contradictory information processing situations, and FFS - evidence reasoning methodology (ERM) is proposed to gather messages, while the conditional probability is exported from the similarity metric. Improved FFS objective relative utility function supports TWD classifications and rankings, and the TWD-SAHARA utility function offers non-linear benefits tailored to human psychology. The proposed FF-PSI-SD-ERM-TWD has been utilized on eight crowdsourcing projects, and its effectiveness has been proven by sensitivity analysis and the results comparison.},
  archive      = {J_APIN},
  author       = {Wu, Meiqin and Song, Jiawen and Fan, Jianping},
  doi          = {10.1007/s10489-024-05334-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3566-3590},
  shortjournal = {Appl. Intell.},
  title        = {Crowdfunding project evaluation based on fermatean fuzzy SAHARA three-way decision method},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). River runoff causal discovery with deep reinforcement
learning. <em>APIN</em>, <em>54</em>(4), 3547–3565. (<a
href="https://doi.org/10.1007/s10489-024-05348-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery from river runoff data aids flood prevention and mitigation strategies, garnering attention in climate and earth science. However, most climate causal discovery methods rely on conditional independence approaches, overlooking the non-stationary characteristics of river runoff data and leading to poor performance. In this paper, we propose a river runoff causal discovery method based on deep reinforcement learning, called RCD-DRL, to effectively learn causal relationships from non-stationary river runoff time series data. The proposed method utilizes an actor-critic framework, which consists of three main modules: an actor module, a critic module, and a reward module. In detail, RCD-DRL first employs the actor module within the encoder-decoder architecture to learn latent features from raw river runoff data, enabling the model to quickly adapt to non-stationary data distributions and generating a causality matrix at different stations. Subsequently, the critic network with two fully connected layers is designed to estimate the value of the current encoded features. Finally, the reward module, based on the Bayesian information criterion (BIC), is used to calculate the reward corresponding to the currently generated causal matrix. Experimental results obtained on both synthetic and real datasets demonstrate the superior performance of the proposed method over the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Ji, Junzhong and Wang, Ting and Liu, Jinduo and Wang, Muhua and Tang, Wei},
  doi          = {10.1007/s10489-024-05348-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3547-3565},
  shortjournal = {Appl. Intell.},
  title        = {River runoff causal discovery with deep reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UAV-enabled fair offloading for MEC networks: A DRL approach
based on actor-critic parallel architecture. <em>APIN</em>,
<em>54</em>(4), 3529–3546. (<a
href="https://doi.org/10.1007/s10489-024-05339-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data processing is a key challenge for computationally limited Ground Users (GUs) in various applications. Unmanned Aerial Vehicles (UAVs) equipped with Multi-access Edge Computing (MEC) servers can assist GUs by offloading their computing tasks. However, existing work ignores fairness when multiple GUs compete for limited computing resources, which may result in UAV underserving certain GUs. In this paper, we investigate a flight trajectory optimization based on reinforcement learning for UAV selection of target GUs for task computation, which provides low latency and fair offloading computing services for GUs by jointly training UAV flight trajectories and task offloading decisions. We formulate UAV flight and offloading as a mixed integer non-convex optimization problem with high-dimensional state and action spaces. The problem is then transformed into a Markov Decision Processes (MDPs) problem and the Maximizing Service Efficiency Proximal Policy Optimization (MSE-PPO) algorithm is proposed to find the optimal solution. The algorithm adopts an actor-critic-based parallel architecture to handle the parameterized action space. Specifically, the UAV position sequence is updated while ensuring an optimal offloading policy between the UAV and the GUs. Simulation results verify that the average system rewards including computational energy efficiency and fairness index are improved by 35.06 $$\%$$ and 12.10 $$\%$$ respectively compared to DDPG and PPO algorithms.},
  archive      = {J_APIN},
  author       = {Li, Wei and Li, Si and Shi, Huaguang and Yan, Wenhao and Zhou, Yi},
  doi          = {10.1007/s10489-024-05339-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3529-3546},
  shortjournal = {Appl. Intell.},
  title        = {UAV-enabled fair offloading for MEC networks: A DRL approach based on actor-critic parallel architecture},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint data augmentation and knowledge distillation for
few-shot continual relation extraction. <em>APIN</em>, <em>54</em>(4),
3516–3528. (<a
href="https://doi.org/10.1007/s10489-024-05327-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot continual relation extraction (CRE) aims to perpetually learn new relations through a limited set of training samples. Its primary challenges include few-shot problems and catastrophic forgetting of old relations. Through empirical research on the existing CRE works, we observe that the cause of catastrophic forgetting is not only an increase in the number of new classes but confusion between similar relations. To address the above issues, we propose a joint data augmentation and knowledge distillation method for few-shot continual relation extraction (JDAKD). Specifically, JDAKD is designed to learn more accurate and robust relationship representations via a similar class-adversarial enhancement mechanism. Furthermore, a novel distillation structure is implemented in which the base model and the model from the previous stage serve as complementary teacher models to guide the learning process. Additionally, a generative adversarial network is employed to augment the data, effectively mitigating the few-shot problem. Extensive experiments conducted on the FewRel and TACRED datasets demonstrate that our proposed JDAKD model outperforms several competitive baseline methods. Notably, in the last task, JDAKD achieves remarkable accuracy improvements, surpassing the second-best model, SCKD, by 4.43% and 3.1%, respectively.},
  archive      = {J_APIN},
  author       = {Wei, Zhongcheng and Zhang, Yunping and Lian, Bin and Fan, Yongjian and Zhao, Jijun},
  doi          = {10.1007/s10489-024-05327-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3516-3528},
  shortjournal = {Appl. Intell.},
  title        = {Joint data augmentation and knowledge distillation for few-shot continual relation extraction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FRAnomaly: Flow-based rapid anomaly detection from images.
<em>APIN</em>, <em>54</em>(4), 3502–3515. (<a
href="https://doi.org/10.1007/s10489-024-05332-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies, such as defects in newly manufactured products or damage in long-used material structures, is a tedious task for humans. Given the current advances in the areas of artificial intelligence (AI) and computer vision, automation of visual quality control is possible and can be a reliable solution. Current methods that achieve state-of-the-art anomaly detection results often use features of different scales extracted from pre-trained convolutional neural networks (CNN). We propose employing multiple feature sets of the same scale alongside a normalizing flow model designed specifically for such sets. Such input features allow the creation of significantly smaller flow models with faster inference. We managed to achieve a decrease of up to 77.5% in the number of flow model parameters and 63.6% in inference time while still accomplishing results better than all other flow models and all but one non-flow method. Experimental evaluation on publicly available MVTec AD and MTD datasets showed a state-of-the-art level of performance of our models, thus proving that it is not necessary to use different scales to detect anomalies of different sizes. This research paves the way for real-time, efficient AI-based automation of visual inspection. Anomaly detection pipeline of FRAnomaly},
  archive      = {J_APIN},
  author       = {Milković, Fran and Posilović, Luka and Medak, Duje and Subašić, Marko and Lončarić, Sven and Budimir, Marko},
  doi          = {10.1007/s10489-024-05332-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3502-3515},
  shortjournal = {Appl. Intell.},
  title        = {FRAnomaly: Flow-based rapid anomaly detection from images},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample-level weighting for multi-task learning with
auxiliary tasks. <em>APIN</em>, <em>54</em>(4), 3482–3501. (<a
href="https://doi.org/10.1007/s10489-024-05300-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) can improve the generalization performance of neural networks by sharing representations with related tasks. Nonetheless, MTL is challenging in practice because it can also degrade performance through harmful interference between tasks. Recent work has pursued task-specific loss weighting as a solution for this interference. However, existing algorithms treat tasks as atomic, lacking the ability to explicitly separate harmful and helpful signals beyond the task level. To this end, we propose SLGrad, a sample-level highly-dynamic weighting algorithm for multi-task learning with auxiliary tasks. By exploiting a hold-out meta objective, SLGrad reshapes the task distributions through sample-level weights to eliminate harmful auxiliary signals and augment useful task signals. Substantial generalization performance gains are observed on both semi-synthetic and synthetic datasets, as well as on three common real-world supervised multi-task problems. By studying the resulting sample and task weight distributions, we show that SLGrad is able to bridge the existing gap between sample weighting in single-task learning and dynamic task weighting in multi-task learning.},
  archive      = {J_APIN},
  author       = {Grégoire, Emilie and Chaudhary, Muhammad Hafeez and Verboven, Sam},
  doi          = {10.1007/s10489-024-05300-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3482-3501},
  shortjournal = {Appl. Intell.},
  title        = {Sample-level weighting for multi-task learning with auxiliary tasks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated accurate insomnia detection system using wavelet
scattering method using ECG signals. <em>APIN</em>, <em>54</em>(4),
3464–3481. (<a
href="https://doi.org/10.1007/s10489-024-05284-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polysomnograms (PSGs), commonly conducted in sleep laboratories, serve as the gold standard for sleep analysis. Among the vital PSG components, the electroencephalogram (EEG) stands out, yet its recording and analysis pose technical challenges, particularly within home settings. PSG procedures involve intricate sleep labs and the attachment of multiple electrodes to subjects’ bodies, making them less patient-friendly. The discomfort of wearing electrodes on the skull cap in an altered sleep environment can adversely impact sleep quality and data accuracy. In contrast, electrocardiogram (ECG) signals present a more accessible option for home-based sleep monitoring due to their simpler recording and analysis. Leveraging ECG signals for automated insomnia detection holds promise in enhancing practicality. Consequently, this study aims to develop an automated approach solely utilizing ECG signals, conveniently captured through wearable devices, for precise insomnia identification. For the automated identification of insomniac subjects, the proposed study uses the Deep Wavelet Scattering Network (DWSN) network. The extracted DWSN-based features of the ECG signals have been applied to different machine-learning algorithms to identify insomnia. The proposed method was validated on three different datasets, namely the Wisconsin Sleep Cohort (WSC) dataset (n = 308; where n = number of subjects), the Sleep Disorder Research Centre (SDRC) dataset (n = 22), and the Cyclic Alternating Pattern (CAP) dataset (n = 25). Our proposed method obtained the highest classification accuracy of 99.9% using the Weighted K-Nearest Neighbour (WKNN) classifier, and a Kappa value of 0.993 with the WSC dataset. Similarly, the highest classification accuracy of 99.60% for the SDRC dataset was obtained using the Trilayered Neural Network (TNN) classifier with a Kappa value of 0.991. The highest classification accuracy of 99% was obtained for the CAP dataset using the Ensemble of Bagged Tree (EBT) classifier with a 0.979 Kappa value. The proposed study suggests an automated, computerized method for creating a machine learning model with explainable artificial intelligence (XAI) capabilities, employing DWSN-based characteristics to distinguish healthy subjects and insomnia subjects. To gain an understanding of the model, the study uses feature ranking based on SHAP (Shapley Additive exPlanations). The proposed study is also the first of its kind to provide the highest accuracy for the classification of insomnia using a huge database. Hence, our model is more generalized as it used diverse and large-scale databases. The suggested study outperformed all previous methods in terms of efficiency, dependability, and accuracy. Thus, the proposed method can potentially aid in the clinical identification of insomnia.},
  archive      = {J_APIN},
  author       = {Sharma, Nishant and Sharma, Manish and Telangore, Hardik and Acharya, U Rajendra},
  doi          = {10.1007/s10489-024-05284-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3464-3481},
  shortjournal = {Appl. Intell.},
  title        = {Automated accurate insomnia detection system using wavelet scattering method using ECG signals},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A self-supervised learning model based on variational
autoencoder for limited-sample mammogram classification. <em>APIN</em>,
<em>54</em>(4), 3448–3463. (<a
href="https://doi.org/10.1007/s10489-024-05358-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have found extensive application in medical imaging analysis, particularly in mammography classification. However, these models encounter challenges associated with limited annotated mammography public datasets. In recent years, self-supervised learning (SSL) has emerged as a noteworthy solution to addressing data scarcity by leveraging pretext and downstream tasks. Nevertheless, we recognize a notable scarcity of self-supervised learning models designed for the classification task in mammography. In this context, we propose a novel self-supervised learning model for limited-sample mammogram classification. Our proposed SSL model comprises two primary networks. The first is a pretext task network designed to learn discriminative features through mammogram reconstruction using a variational autoencoder (VAE). Subsequently, the downstream network, dedicated to the classification of mammograms, uses the encoded space extracted by the VAE as input through a simple convolutional neural network. The performance of the proposed model is assessed on public INbreast and MIAS datasets. Comparative analyzes are conducted for the proposed model against previous studies for the same classification task and dataset. The proposed SSL model demonstrates high performance with an AUC of 0.94 for density, 0.99 for malignant-nonmalignant classifications on INbreast, 0.97 for benign-malignant, 0.99 for density, and 0.99 for normal-benign-malignant classifications on MIAS. Additionally, the proposed model reduces computational costs with only 228 trainable parameters, 204.95K FLOPs, and a depth of 3 in mammogram classification. Overall, the proposed SSL model exhibits a robust network architecture characterized by repeatability, consistency, generalization ability, and transferability among datasets, providing less computational complexity than previous studies.},
  archive      = {J_APIN},
  author       = {Karagoz, Meryem Altin and Nalbantoglu, O. Ufuk},
  doi          = {10.1007/s10489-024-05358-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3448-3463},
  shortjournal = {Appl. Intell.},
  title        = {A self-supervised learning model based on variational autoencoder for limited-sample mammogram classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TPE-MM: Thumbnail preserving encryption scheme based on
markov model for JPEG images. <em>APIN</em>, <em>54</em>(4), 3429–3447.
(<a href="https://doi.org/10.1007/s10489-024-05318-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in mobile communication have enabled images to be shared more conveniently, and the consequent risk of privacy breaches has been increasingly emphasized. Previously, traditional image encryption algorithms were mostly adopted by individuals to encrypt plain images into noise-like meaningless cipher images. This type of algorithm provides security for image privacy protection but is unable to achieve usability in cloud platforms. Furthermore, existing image encryption algorithms only target the protection of lossless compression or non-compressed formats images (e.g., BMP, PNG, etc.), but neglect the encryption needs of JPEG format images. Since the latter has the benefits of less file storage and excellent visual quality, it has been widely applied in a variety of scenarios. Thus, a thumbnail preserving encryption (TPE) scheme based on Markov model (TPE-MM) for JPEG images is proposed to equilibrate security and availability. Specifically, an approximate sum-preserving encryption method (ASP-EM) in restricted range based on its features is proposed to preserve the plain thumbnail features to accomplish cipher image usability. Subsequently, an adaptive encryption method based on Markov model (AEM-MM) was proposed to improve the encryption effect of cipher images and retain the compression performance of JPEG images. Simulation experiments show that the cipher image has good visual quality, low expansion rate, and is resistant to outline attacks.},
  archive      = {J_APIN},
  author       = {Chai, Xiuli and Long, Guoqiang and Gan, Zhihua and Zhang, Yushu},
  doi          = {10.1007/s10489-024-05318-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3429-3447},
  shortjournal = {Appl. Intell.},
  title        = {TPE-MM: Thumbnail preserving encryption scheme based on markov model for JPEG images},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CAPPAD: A privacy-preservation solution for autonomous
vehicles using SDN, differential privacy and data aggregation.
<em>APIN</em>, <em>54</em>(4), 3417–3428. (<a
href="https://doi.org/10.1007/s10489-023-04991-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Vehicles (AVs) and driverless cars which are equipped with communication capabilities, advanced sensing, and Intelligent Control Systems (ICS), aim to modernize the transportation system. It increases user satisfaction by enhancing personal safety, reducing infrastructure costs, decreasing environmental interruption, and saving time for passengers. On the other hand, in emergency cases when AVs require maintenance, their generated sensitive information (e.g., AV location, low brake fluid amount of an AV) should be shared with Road Side Units (RSUs) and other vehicles to address their problems and provide quality services. Despite its appealing benefits, sensitive data sharing carries security and privacy issues that trigger serious risks like unintentional physical accidents. If the privacy of the AV is breached and its sensitive data is unintentionally disclosed during data transmission, adversaries can misuse them and cause artificial accidents. Current studies in this area lack efficiency and cost-effectiveness. To fill this gap and reduce the number of potential accidents, this article proposes a new Context-Aware Privacy-Preserving method for Autonomous Driving (CAPPAD). In particular, the Software-Defined Networking (SDN) paradigm is employed to bring flexibility to AVs’ privacy management while its SDN controller runs a novel algorithm for privacy preservation. Depending on whether the data generated is sensitive or not and whether there is an emergency, the AV applies Differential Privacy (DP) or Data Aggregation (DA) as its privacy-preserving method. Finally, extensive simulations are performed through MININET-WIFI to show the performance of CAPPAD in terms of privacy-preserving degree, computational cost overhead, computational complexity overhead, and latency. We also compare it with other relevant well-known studies to show its superior effectiveness.},
  archive      = {J_APIN},
  author       = {Gheisari, Mehdi and Khan, Wazir Zada and Najafabadi, Hamid Esmaeili and McArdle, Gavin and Rabiei-Dastjerdi, Hamidreza and Liu, Yang and Fernández-Campusano, Christian and Abdalla, Hemn Barzan},
  doi          = {10.1007/s10489-023-04991-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3417-3428},
  shortjournal = {Appl. Intell.},
  title        = {CAPPAD: A privacy-preservation solution for autonomous vehicles using SDN, differential privacy and data aggregation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal sentiment analysis based on cross-instance graph
neural networks. <em>APIN</em>, <em>54</em>(4), 3403–3416. (<a
href="https://doi.org/10.1007/s10489-024-05309-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the diversity of social media information, enhancing the accuracy of sentiment analysis for social media necessitates a comprehensive understanding of text and image information. Observing multimodal posts across social media platforms reveals similarities within images or texts containing posts, such as the association of rainbows with positive posts and darkness with negative posts. However, most previous studies have only modeled individual image-text pairs and ignored the global co-occurrence characteristics of the dataset. To address this problem, we propose a cross-instance graph neural network that leverages the global characteristics of the dataset to detect sentiments in text-image pairs. First, the method extracts five attributes from each image, constructs a co-occurrence matrix using the co-occurrence relationships between the attributes, and generates an attribute-graph convolutional network (Attribute_GCN). For the text modality, words are used as nodes, and when two words occur together more than twice, an edge is created between them. Then, point-wise mutual information and message-passing mechanisms are utilized to update the representations of the edges and nodes, resulting in the construction of Text_GNN. The hidden representations of the multimodal are obtained by encoding. Finally, a multimodal in-deep fusion with the multihead attention mechanism is implemented to better predict the sentiment of image-text pairs. We conducted extensive experiments using three public multimodal datasets, and the experimental results validated the availability of the proposed method.},
  archive      = {J_APIN},
  author       = {Wang, Hongbin and Ren, Chun and Yu, Zhengtao},
  doi          = {10.1007/s10489-024-05309-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3403-3416},
  shortjournal = {Appl. Intell.},
  title        = {Multimodal sentiment analysis based on cross-instance graph neural networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforced covariance weighted mean of vectors optimizer:
Insight, diversity, deep analysis and feature selection. <em>APIN</em>,
<em>54</em>(4), 3351–3402. (<a
href="https://doi.org/10.1007/s10489-023-05261-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The WeIghted meaN oF vectOrs (INFO) algorithm is widely used as an efficient optimization tool due to its simple structure and superior performance. However, achieving a balance in solving complex high-dimensional problems is difficult and quickly falls into premature convergence or local optimality. To better balance the conflict between exploration and exploitation capabilities, a Q-learning Covariance weIghted meaN oF vectOrs Algorithm (QCINFOCMA) based on reinforcement learning is designed in this study to solve the global optimization problem. QCINFOCMA incorporates a covariance matrix adaptation evolution strategy and Cauchy mutation as a new exploration scheme. The Q-learning strategy in reinforcement learning is also integrated into the original INFO to achieve adaptive switching between the original local search and the new exploration scheme. This allows search agents to use rewards and penalties to select exploration methods without following established models or strategies. In this study, a comprehensive analysis is conducted, pitting QCINFOCMA against 10 heuristics and 9 state-of-the-art algorithms, utilizing the IEEE CEC 2017 test functions. The experimental results show that QCINFOCMA outperforms other advanced algorithms in terms of convergence speed and convergence accuracy. Subsequently, QCINFOCMA was subjected to a discretization process, effectively transforming it into a binary tool through the application of a specific transformation function. This binary tool was then employed to address the real-world challenge of feature selection across a cohort of 36 datasets obtained from the UCI machine learning library. Empirical findings demonstrate that QCINFOCMA attains superior classification accuracy and requires fewer features in comparison to alternative optimization algorithms. The proposed QCINFOCMA can be a novel optimization tool for implementing global optimization and wrapper-based feature selection tasks.},
  archive      = {J_APIN},
  author       = {Xu, Boyang and Heidari, Ali Asghar and Chen, Huiling},
  doi          = {10.1007/s10489-023-05261-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3351-3402},
  shortjournal = {Appl. Intell.},
  title        = {Reinforced covariance weighted mean of vectors optimizer: Insight, diversity, deep analysis and feature selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). V-GMR: A variational autoencoder-based heterogeneous graph
multi-behavior recommendation model. <em>APIN</em>, <em>54</em>(4),
3337–3350. (<a
href="https://doi.org/10.1007/s10489-024-05360-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional single-behavior models, multibehavior recommendation models incorporate the auxiliary behavior information of users. This integration step addresses the cold-start and data sparsity issues and provides more comprehensive and detailed interaction information for the model. Despite the efforts made by multibehavior recommendation models to analyze user behavior semantics and capture user preferences, challenges remain in terms of effectively modeling the relationships between different types of user feedback. This issue is exacerbated by the heavy reliance on hyperparameters, which leads to overparameterization. In this paper, we propose a variational autoencoder (VAE) and graph-based heterogeneous multibehavior recommendation model (V-GMR), which aims to capture user behavior preferences and mitigate the aforementioned issues. First, we employ VAEs to encode user behaviors and learn feature representations that effectively capture multibehavior information. Second, we develop a preference fusion enhancer based on a VAE to integrate auxiliary user behaviors with the target behavior, effectively addressing the problem concerning sparse interaction data. Third, we design a special behavior decoding layer to handle the latent variables acquired from the preference fusion enhancer. In this layer, we reconstruct the loss function and resolve the issue of optimizing the neural network parameters through backpropagation in the presence of deterministic input values. The effectiveness of V-GMR is validated through experiments conducted on three real-world datasets, and the contributions of the V-GMR model components are verified through ablation experiments.},
  archive      = {J_APIN},
  author       = {Yang, Haoqin and Rang, Ran and Xing, Linlin and Zhang, Longbo and Cai, Hongzhen and Guo, Maozu and Sun, Jiaqi},
  doi          = {10.1007/s10489-024-05360-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3337-3350},
  shortjournal = {Appl. Intell.},
  title        = {V-GMR: A variational autoencoder-based heterogeneous graph multi-behavior recommendation model},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Steering vector embedding complex-valued generative
adversarial nets for radar signal generation and large-scale phase
enhancement learning for super-resolution DOA estimation. <em>APIN</em>,
<em>54</em>(4), 3325–3336. (<a
href="https://doi.org/10.1007/s10489-024-05353-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying deep learning techniques to solve radar signal processing problems such as phase-enhanced direction of arrival (DOA) estimation involves the acquisition of large-scale data, which are usually small and difficult to obtain. Hence, we develop a steering vector embedding complex-valued generative adversarial network (CVGAN) for radar data generation; this is an excellent technique for increasing the size of the dataset we can collect. First, a novel CVGAN model is proposed to mine real radar data features and generate fake data with similar distribution characteristics through game theory. To improve the interpretability of the data generated by CVGAN, a steering vector embedding technique is proposed, in which fake radar data with the desired DOA are generated by embedding the corresponding steering vector. The proposed CVGAN model can effectively reduce the dependence of the model on the amount of data we need to collect. The simulation and experimental results show that the proposed CVGAN model can fully explore the data features contained in a small number of samples and augment the datasets, and the phase enhancement learning model combined with the CVGAN has higher estimation accuracy and generalizability for DOA estimation.},
  archive      = {J_APIN},
  author       = {Xiang, Houhong},
  doi          = {10.1007/s10489-024-05353-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3325-3336},
  shortjournal = {Appl. Intell.},
  title        = {Steering vector embedding complex-valued generative adversarial nets for radar signal generation and large-scale phase enhancement learning for super-resolution DOA estimation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Local structure learning for incomplete multi-view
clustering. <em>APIN</em>, <em>54</em>(4), 3308–3324. (<a
href="https://doi.org/10.1007/s10489-023-05237-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering, which aims to divide different groups into incomplete views produced by various sensors, has attracted research attention. In this article, we propose a local structure learning for incomplete multi-view clustering (LS-IMC) algorithm. The algorithm jointly learns a consensus of incomplete views and a clustering result. Specifically, by fusing consistent representation and local structure learning into one optimization term, we can adequately capture the intrinsic geometric structure from missing and available data. In addition, the weight of incomplete views is learned adaptively to balance the importance of different views. Furthermore, we integrate representation learning and clustering processes into a unified framework so that the clustering result can be obtained directly and without the need for post-processing. Experiments performed on eight incomplete multi-view datasets demonstrate the effectiveness of the proposed LS-IMC compared to other current approaches.},
  archive      = {J_APIN},
  author       = {Wang, Yongchun and Yang, Youlong and Ning, Tong},
  doi          = {10.1007/s10489-023-05237-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3308-3324},
  shortjournal = {Appl. Intell.},
  title        = {Local structure learning for incomplete multi-view clustering},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A general variation-driven network for medical image
synthesis. <em>APIN</em>, <em>54</em>(4), 3295–3307. (<a
href="https://doi.org/10.1007/s10489-023-05017-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of medical image synthesis has exponentially grown due to constrained medical resources, making it a critical component in numerous clinical applications. This process facilitates the generation of high-quality, multi-modal medical images, ultimately enhancing medical image diagnostics. Currently, prevailing medical image synthesis methodologies primarily rely on voxel-based or GAN-based strategies to address substantial challenges arising from disparities in various imaging principles and significant noise. However, these methodologies rarely consider the intensity distribution difference among multi-modal or multi-parameters medical images, which generates unstable and unexplainable results. In response to these limitations, we propose a novel approach-a general variation-driven neural network for medical image synthesis that considers explicit data distribution. Within this method, we introduce the concept of a variation-based distance metric, providing a quantitative framework for capturing distribution disparities between medical images originating from both the source and target domains. Subsequently, guided by this variation-based distance metric, we introduce a robust end-to-end neural network architecture carefully designed to synthesize target medical images. Our proposed method has undergone extensive experimentation across various medical image synthesis tasks, including cross-modality transformations between CT and MRI, high-dose CT synthesis from low-dose CT, and the conversion of multi-parameters in MRI, including T1, T2, T1ce, and Flair sequences. In comparative assessments against existing methods, our approach consistently outperforms them across three publicly available datasets: Gold Atlas, LDCT, and BraTS2018. Additionally, we have successfully applied our model to generate high-quality Micro-CT images in dental clinics from CBCT data, significantly enhancing diagnostic capabilities in this clinical setting.},
  archive      = {J_APIN},
  author       = {Chen, Yufei and Yang, Xiaoyu and Yue, Xiaodong and Lin, Xiang and Zhang, Qi and Fujita, Hamido},
  doi          = {10.1007/s10489-023-05017-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3295-3307},
  shortjournal = {Appl. Intell.},
  title        = {A general variation-driven network for medical image synthesis},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large-scale UAV swarm confrontation based on hierarchical
attention actor-critic algorithm. <em>APIN</em>, <em>54</em>(4),
3279–3294. (<a
href="https://doi.org/10.1007/s10489-024-05293-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale unmanned aerial vehicle (UAV) swarm confrontation scenarios, the design of decision-making and coordination strategies becomes extremely difficult. Multi-Agent Reinforcement Learning (MARL), as a novel decision-making approach to address this issue, faces challenges such as poor scalability and the curse of dimensionality. To overcome these challenges, the paper proposes a Hierarchical Attention Actor-Critic (HAAC) algorithm. The HAAC algorithm includes a centralized critic network based on a Hierarchical Two-stage Attention Network (H2ANet), along with a hierarchical actor policy network that combines rules and reinforcement learning approaches. H2ANet is specifically designed to model the relationships between UAVs and extract crucial information from neighboring UAVs, enabling the generation of advanced cooperative and competitive strategies. The HAAC algorithm effectively reduces the dimensionality of both action and state spaces. Experimental results conducted demonstrate that the HAAC algorithm outperforms existing methods and is able to extend its learned policies to large-scale scenarios.},
  archive      = {J_APIN},
  author       = {Nian, Xiaohong and Li, Mengmeng and Wang, Haibo and Gong, Yalei and Xiong, Hongyun},
  doi          = {10.1007/s10489-024-05293-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3279-3294},
  shortjournal = {Appl. Intell.},
  title        = {Large-scale UAV swarm confrontation based on hierarchical attention actor-critic algorithm},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to rank influential nodes in complex networks via
convolutional neural networks. <em>APIN</em>, <em>54</em>(4), 3260–3278.
(<a href="https://doi.org/10.1007/s10489-024-05336-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes is crucial for enhancing information diffusion in complex networks. Several approaches have been proposed to find these influential nodes based on the network structure that significantly impacts the node influence. Recently, several deep learning algorithms have also been introduced to identify influential nodes based on network exploration and node feature selection. However, this has led to challenges in enhancing efficiency and minimizing computation time. To address these challenges, we propose a novel framework called LCNN that uses convolutional neural networks and node-local representations to identify influential nodes in complex networks. We argue that we can measure node influence capacity using multi-scale metrics and a node’s adjacent matrix of one-hop neighbors to improve extracted information while reducing running time. According to the susceptible-infectious-recovered (SIR) model, the experiment results demonstrate that our proposed LCNN outperforms the state-of-the-art methods on both real-world and synthetic networks. Additionally, it exhibits a moderate time consumption, which makes it suitable for large-scale networks.},
  archive      = {J_APIN},
  author       = {Ahmad, Waseem and Wang, Bang and Chen, Si},
  doi          = {10.1007/s10489-024-05336-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3260-3278},
  shortjournal = {Appl. Intell.},
  title        = {Learning to rank influential nodes in complex networks via convolutional neural networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing action quality with semantic-sequence performance
regression and densely distributed sample weighting. <em>APIN</em>,
<em>54</em>(4), 3245–3259. (<a
href="https://doi.org/10.1007/s10489-024-05349-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action Quality Assessment (AQA) is a critical branch of video understanding, offering impartial evaluations for competitive sports. Existing paradigms tend to assess action quality using equal-length clips that lack sufficient semantics, leading to suboptimal predictions. To address this issue, we propose to conduct AQA with Semantic-Sequence Performance Regression (SSPR). SSPR first divides an action into a series of unequal-length segments according to the semantic continuity of the video, such as jumping, dropping, and entering the water in diving. Specifically, the latest Temporal Convolutional Network (TCN) is adopted for semantic-sequence segmentation. To better achieve SSPR, we design a feature fusion module that integrates the semantics of each segment using cascaded 1D convolutions. Furthermore, the imbalanced distribution phenomenon is usually ignored in AQA and we attempt to propose a new loss called positive-weighting MSE (PW-MSE) to deal with it. PW-MSE encourages the network to focus more on densely distributed samples during training, which further improves the network’s ranking performance. Experimental results on the benchmark datasets (i.e., UNLV-Dive and AQA-7) demonstrate that our proposed method outperforms the current state-of-the-arts.},
  archive      = {J_APIN},
  author       = {Huang, Feng and Li, Jianjun},
  doi          = {10.1007/s10489-024-05349-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3245-3259},
  shortjournal = {Appl. Intell.},
  title        = {Assessing action quality with semantic-sequence performance regression and densely distributed sample weighting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view key information representation and multi-modal
fusion for single-subject routine action recognition. <em>APIN</em>,
<em>54</em>(4), 3222–3244. (<a
href="https://doi.org/10.1007/s10489-024-05319-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, human action recognition has witnessed remarkable progress, and its achievements have been applied to daily life. However, most methods extract features from only a single view within each modality, which may not comprehensively capture the diversity and complexity of actions. Moreover, the ineffective removal of redundant information can result in an inconspicuous description of key information. These issues cloud affect the final action recognition accuracy. To address these issues, this paper proposes a novel method for single-subject routine action recognition, which combines multi-view key information representation and multi-modal fusion. Firstly, the energy of non-primary motion areas is reduced by motion mean normalization in the depth video sequence, thereby enhancing key information of action. Then, depth motion history map (DMHM) and depth spatio-temporal energy map (DSTEM) are extracted from planes and axes, respectively. The proposed DMHM effectively preserves the spatio-temporal information of actions, DSTEM preserves the motion contour and energy information. In terms of skeleton sequences, statistical features and motion contribution degree of each joint are extracted from the view of motion distribution and weights, respectively. Finally, depth and skeleton features are fused to achieve multi-modal fusion-based action recognition. The proposed method highlights the information of the main motion areas, and achieves recognition accuracies of 96.70 $$\%$$ on MSR-Action3D, 93.26 $$\%$$ on UTD-MHAD, and above 97.73 $$\%$$ on all tests of CZU-MHAD. The experimental results demonstrate that the proposed method effectively preserves action information and has better recognition accuracy than most existing methods.},
  archive      = {J_APIN},
  author       = {Chao, Xin and Ji, Genlin and Qi, Xiaosha},
  doi          = {10.1007/s10489-024-05319-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3222-3244},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view key information representation and multi-modal fusion for single-subject routine action recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An equidistance index intuitionistic fuzzy c-means
clustering algorithm based on local density and membership degree
boundary. <em>APIN</em>, <em>54</em>(4), 3205–3221. (<a
href="https://doi.org/10.1007/s10489-024-05297-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy c-means (FCM) algorithm is an unsupervised clustering algorithm that effectively expresses complex real world information by integrating fuzzy parameters. Due to its simplicity and operability, it is widely used in multiple fields such as image segmentation, text categorization, pattern recognition and others. The intuitionistic fuzzy c-means (IFCM) clustering has been proven to exhibit better performance than FCM due to further capturing uncertain information in the dataset. However, the IFCM algorithm has limitations such as the random initialization of cluster centers and the unrestricted influence of all samples on all cluster centers. Therefore, a novel algorithm named equidistance index IFCM (EI-IFCM) is proposed for improving shortcomings of the IFCM. Firstly, the EI-IFCM can commence its learning process from more superior initial clustering centers. The EI-IFCM algorithm organizes the initial cluster centers based on the contribution of local density information from the data samples. Secondly, the membership degree boundary is assigned for the data samples satisfying the equidistance index to avoid the unrestricted influence of all samples on all cluster centers in the clustering process. Finally, the performance of the proposed EI-IFCM is numerically validated using UCI datasets which contain data from healthcare, plant, animal, and geography. The experimental results indicate that the proposed algorithm is competitive and suitable for fields such as plant clustering, medical classification, image differentiation and others. The experimental results also indicate that the proposed algorithm is surpassing in terms of iteration and precision in the mentioned fields by comparison with other efficient clustering algorithms.},
  archive      = {J_APIN},
  author       = {Ma, Qianxia and Zhu, Xiaomin and Zhao, Xiangkun and Zhao, Butian and Fu, Guanhua and Zhang, Runtong},
  doi          = {10.1007/s10489-024-05297-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3205-3221},
  shortjournal = {Appl. Intell.},
  title        = {An equidistance index intuitionistic fuzzy c-means clustering algorithm based on local density and membership degree boundary},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model-agnostic generation-enhanced technology for few-shot
intrusion detection. <em>APIN</em>, <em>54</em>(4), 3181–3204. (<a
href="https://doi.org/10.1007/s10489-024-05290-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious traffic on the Internet has become an increasingly serious problem, and several artificial intelligence (AI)-based malicious traffic detection methods have been proposed. Generally, AI-based methods need numerous benign and specific types of malicious traffic training instances to achieve better detection results. However, for attacks with only a few instances, known as the few-shot attacks, these methods often perform poorly, and how to train a model for detecting few-shot attacks is a huge challenge. For this problem, we propose a novel intrusion detection system based on generative adversarial networks and model-agnostic meta-learning. The system adopts a hybrid detection mechanism where an anomaly-based classifier determines whether incoming traffic is malicious and a signature-based classifier identifies the class of malicious traffic. In the system, the samples of few-shot attacks are augmented by maximizing the use of meta-knowledge and then applied to assist the detection of few-shot attacks to obtain better detection results. The experiments show that for CSE-CIC-IDS2018 and Bot-IoT datasets, this system can detect malicious traffic with 94.3%/1.8% TPR/FPR and 99.8%/0.1% TPR/FPR, respectively, and also can identify the class of the few-shot attacks with 95.2% and 91.9% accuracy, respectively. Compared with other related methods, the system improves the accuracy of identifying few-shot attacks on these two datasets by at least 2.2% and 1.5%, respectively. Additionally, a parameter visualization process is designed, which shows the fast-adaptive property and better generalization capability of the system.},
  archive      = {J_APIN},
  author       = {He, Junpeng and Yao, Lingfeng and Li, Xiong and Khan, Muhammad Khurram and Niu, Weina and Zhang, Xiaosong and Li, Fagen},
  doi          = {10.1007/s10489-024-05290-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3181-3204},
  shortjournal = {Appl. Intell.},
  title        = {Model-agnostic generation-enhanced technology for few-shot intrusion detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). DFAMNet: Dual fusion attention multi-modal network for
semantic segmentation on LiDAR point clouds. <em>APIN</em>,
<em>54</em>(4), 3169–3180. (<a
href="https://doi.org/10.1007/s10489-024-05302-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of outdoor point clouds is an important task in the field of computer vision, aiming to classify outdoor point cloud data into different semantic categories. The methods based on pure point cloud have some shortcomings, such as incomplete information and difficulty in processing incomplete data. In the paper, it proposes pseudo point cloud method to align image with point cloud. The image features are extracted through a 2D network, and then the point cloud is mapped onto the image to obtain the corresponding pixel features, forming the pseudo point cloud. Then the dual fusion attention mechanism is designed to fuse the features of point cloud and pseudo point cloud. It improves the efficiency of the fusion network. The experimental results show that this method outperforms existing methods on the large-scale SemanticKITTI benchmark and achieves third place performance on the NuScenes benchmark. Code is available at https://github.com/Pdsn5/DFAMNet .},
  archive      = {J_APIN},
  author       = {Li, Mingjie and Wang, Gaihua and Zhu, Minghao and Li, Chunzheng and Liu, Hong and Pan, Xuran and Long, Qian},
  doi          = {10.1007/s10489-024-05302-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3169-3180},
  shortjournal = {Appl. Intell.},
  title        = {DFAMNet: Dual fusion attention multi-modal network for semantic segmentation on LiDAR point clouds},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CDPNet: Conformer-based dual path joint modeling network for
bird sound recognition. <em>APIN</em>, <em>54</em>(4), 3152–3168. (<a
href="https://doi.org/10.1007/s10489-024-05362-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bird species monitoring is important for the preservation of biological diversity because it provides fundamental information for biodiversity assessment and protection. Automatic acoustic recognition is considered to be an essential technology for realizing automatic monitoring of bird species. Current deep learning-based bird sound recognition methods do not fully conduct long-term correlation modeling along both the time and frequency axes of the spectrogram. Additionally, these methods have not completely studied the impact of different scales of features on the final recognition. To solve the abovementioned problems, we propose a Conformer-based dual path joint modeling network (CDPNet) for bird sound recognition. To the best of our knowledge, this is the first attempt to adopt Conformer in the bird sound recognition task. Specifically, the proposed CDPNet mainly consists of a dual-path time-frequency joint modeling module (DPTFM) and a multi-scale feature fusion module (MSFFM). The former aims to simultaneously capture time-frequency local features, long-term time dependence, and long-term frequency dependence to better model bird sound characteristics effectively. The latter is designed to improve recognition accuracy by fusing different scales of features. The proposed algorithm is implemented on an edge computing platform, NVIDIA Jetson Nano, to build a real-time bird sound recognition monitoring system. The ablation experimental results verify the benefit of using the DPTFM and the MSFFM. Through training and testing on the Semibirdaudio dataset containing 27,155 sound clips and the public Birdsdata dataset, the proposed CDPNet outperforms the other state-of-the-art models in terms of F1-score, precision, recall, and accuracy.},
  archive      = {J_APIN},
  author       = {Guo, Huimin and Jian, Haifang and Wang, Yiyu and Wang, Hongchang and Zheng, Shuaikang and Cheng, Qinghua and Li, Yuehao},
  doi          = {10.1007/s10489-024-05362-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3152-3168},
  shortjournal = {Appl. Intell.},
  title        = {CDPNet: Conformer-based dual path joint modeling network for bird sound recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Two-view point cloud registration network: Feature and
geometry. <em>APIN</em>, <em>54</em>(4), 3135–3151. (<a
href="https://doi.org/10.1007/s10489-023-05263-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rigid point cloud registration is a crucial upstream task in computer vision, whose goal is to align two misaligned point clouds using a rigid transformation. Existing methods, which directly utilize extracted point features for computing point relationships, are likely to result in a wrong-matching relationship since two or more similar feature points in the source point cloud easily correspond to the same point in the target point cloud. To this end, this paper proposes a two-view point cloud registration network that better alleviates the problem of similar feature points from both the feature and geometry levels. Specifically, at the feature level, a residual correction unit is proposed to learn feature-aware coefficients from raw 3D point clouds to adaptively increase or decrease the difference between features. An attention mechanism is established in two-point clouds to capture the implicit feature relationship between the two-point clouds, gathering the information of another point cloud to enrich the feature information of its own point cloud. Second, at the geometry level, a dual-view graph topology fusion module is described. All points in the graph structure are no longer independent but connected by their geometry structure. Therefore, each point can aggregate neighbor information in the same point cloud and in different point clouds through the constructed single graph and interactive graph, so that each point can enhance the difference between points through its geometry structure. In order to fuse the information of a single graph and an interactive graph, a cross-attention module is proposed to supplement contextual information to obtain point features that are more suitable for matching. Experimental results demonstrate that our method achieves excellent results on complete and partial noisy point clouds.},
  archive      = {J_APIN},
  author       = {Wang, Lingpeng and Yang, Bing and Ye, Hailiang and Cao, Feilong},
  doi          = {10.1007/s10489-023-05263-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3135-3151},
  shortjournal = {Appl. Intell.},
  title        = {Two-view point cloud registration network: Feature and geometry},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variational mode decomposition and bagging extreme learning
machine with multi-objective optimization for wind power forecasting.
<em>APIN</em>, <em>54</em>(4), 3119–3134. (<a
href="https://doi.org/10.1007/s10489-024-05331-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wind power forecast is an useful support tool for planning and operating wind farm production, facilitating decisions regarding maintenance and load share. This paper presents an evaluation of a cooperative method, which uses a time series pre-processing strategy, artificial neural networks, and multi-objective optimization to forecast wind power generation. The proposed approach also evaluates the accuracy of the hybridization of variational mode decomposition (VMD) with bootstrap aggregation and extreme learning machine model for forecasting very short and short-term wind power generation. Multi-objective strategy aggregates the VMD-based components and obtains the final forecasting. The results imply that the presented algorithm has better forecasting performance compared to bootstrap stacking, other machine learning approaches, and statistical models, with a reduction of root mean squared error of approximately 12.76%, 25.25%, 31.91%, and 34.76%, respectively, for out-of-sample predictions. The forecasting results indicate that the presented approach can improve generalizability and accuracy in cases of very short and short-term wind energy generation.},
  archive      = {J_APIN},
  author       = {Ribeiro, Matheus Henrique Dal Molin and da Silva, Ramon Gomes and Moreno, Sinvaldo Rodrigues and Canton, Cristiane and Larcher, José Henrique Kleinübing and Stefenon, Stefano Frizzo and Mariani, Viviana Cocco and Coelho, Leandro dos Santos},
  doi          = {10.1007/s10489-024-05331-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3119-3134},
  shortjournal = {Appl. Intell.},
  title        = {Variational mode decomposition and bagging extreme learning machine with multi-objective optimization for wind power forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New uncertainty measurement for a decision table with
application to feature selection. <em>APIN</em>, <em>54</em>(4),
3092–3118. (<a
href="https://doi.org/10.1007/s10489-024-05310-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A decision table consists of samples, categorical features, and a decision feature. Uncertainty measurement (UM) can supply new points of view for analyzing data. Thus, it is vital to study the uncertainty of the decision table. Some UMs, such as classification precision, rough membership degree, dependence degree, and attribute importance, cannot accurately measure the uncertainty of a decision table. For example, the dependence degree only considers the information provided by the lower approximation of the decision and ignores the upper approximation, which may lead to some information loss. This paper proposes new UMs in a decision table and gives an application for feature selection. First, new UMs such as conditional information entropy, conditional information quantity, and conditional discriminant index in a decision table are proposed. Then, statistical analysis is used to identify the strengths and weaknesses of the proposed UMs. Next, the UM with the best performance is applied to create a heuristic select feature algorithm in a decision table. Finally, the created algorithm is compared to five other feature selection algorithms, and numerical experiments demonstrate its superior performance.},
  archive      = {J_APIN},
  author       = {Zhang, Gangqiang and Song, Yan and Yu, Guangji and Li, Zhaowen},
  doi          = {10.1007/s10489-024-05310-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3092-3118},
  shortjournal = {Appl. Intell.},
  title        = {New uncertainty measurement for a decision table with application to feature selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A light-weight quantum self-attention model for classical
data classification. <em>APIN</em>, <em>54</em>(4), 3077–3091. (<a
href="https://doi.org/10.1007/s10489-024-05337-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an interdisciplinary field combining quantum computation and machine learning, Quantum Machine Learning (QML) has shown the potential to outperform classical machine learning on some algorithms. Given that the transformer, with self-attention as its core mechanism, has become a popular backbone model in the field of machine learning, the exploration of a quantum version of the self-attention mechanism has become an intriguing topic. In this paper, we propose a Quantum Self-Attention Model (QSAM) based on Variational Quantum Algorithms (VQA), aiming to combine the advantages of quantum neural network and self-attention together. To implement the self-attention mechanism on quantum neural network, we employ parameterized quantum circuits to learn the features of input data in quantum-enhanced spaces, then introduce the innovative Amplitude-Phase Decomposition Measurement (APDM) to obtain the essential components of self-attention model: $$\varvec{query}$$ , $$\varvec{key}$$ and $$\varvec{value}$$ . By introducing APDM, we can implement the quantum self-attention model with a lower parameter quantity than that of previous methods, making our QSAM have a better deployability on near-term quantum devices. We apply QSAM on both NLP and CV datasets for binary and multiple classification. The results show that our QSAM outperforms its classical counterpart and is as good as the state-of-the-art quantum self-attention model on NLP datasets. On CV datasets, our QSAM achieves better performance than other quantum image classifiers. These results demonstrate the powerful learning ability of our QSAM.},
  archive      = {J_APIN},
  author       = {Zhang, Hui and Zhao, Qinglin and Chen, Chuangtao},
  doi          = {10.1007/s10489-024-05337-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3077-3091},
  shortjournal = {Appl. Intell.},
  title        = {A light-weight quantum self-attention model for classical data classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-triggered adjustable prescribed performance control for
stochastic multiagent systems with communication faults. <em>APIN</em>,
<em>54</em>(4), 3058–3076. (<a
href="https://doi.org/10.1007/s10489-024-05306-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex working environment and accurate transient performance bring the challenges for the tracking control of multiagent systems (MASs). To guarantee the control performance of stochastic MASs under the limited communication resources and random communication noises, an adaptive adjustable prescribed performance control strategy via compensatory self-triggered mechanism is designed. First of all, a data-driven fault detection mechanism is proposed to detect the occurrence of the communication faults caused by the random communication noises. The boundary of detecting outlier is directly determined by the less collected operation data without updating continuously. Then, the shifting function which has less intermediate functions is designed, which can be used to achieve the adjustable prescribed performance control method that the tracking errors are restricted in the adjustable bounds. Next, a compensatory self-triggered mechanism is proposed to address the problem of the excessive trigger intervals caused by the large control signal. Finally, all signals of the closed-loop system are verified semiglobally uniformly ultimately bounded in probability by the Lyapunov stability method. The effectiveness of the control method is verified by simulation results.},
  archive      = {J_APIN},
  author       = {Wang, Wenzhe and Cao, Liang and Pan, Yingnan and Ren, Hongru and Xue, Hong},
  doi          = {10.1007/s10489-024-05306-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3058-3076},
  shortjournal = {Appl. Intell.},
  title        = {Self-triggered adjustable prescribed performance control for stochastic multiagent systems with communication faults},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multimodal fusion-based deep learning framework combined
with local-global contextual TCNs for continuous emotion recognition
from videos. <em>APIN</em>, <em>54</em>(4), 3040–3057. (<a
href="https://doi.org/10.1007/s10489-024-05329-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous emotion recognition plays a crucial role in developing friendly and natural human-computer interaction applications. However, there exist two significant challenges unresolved in this field: how to effectively fuse complementary information from multiple modalities and capture long-range contextual dependencies during emotional evolution. In this paper, a novel multimodal continuous emotion recognition framework was proposed to address the above challenges. For the multimodal fusion challenge, the Multimodal Attention Fusion (MAF) method is proposed to fully utilize complementarity and redundancy between multiple modalities. To tackle temporal context dependencies, the Local Contextual Temporal Convolutional Network (LC-TCN) and the Global Contextual Temporal Convolutional Network (GC-TCN) were presented. These networks have the ability to progressively integrate multi-scale temporal contextual information from input streams of different modalities. Comprehensive experiments are conducted on the RECOLA and SEWA datasets to assess the effectiveness of our proposed framework. The experimental results demonstrate superior recognition performance compared to state-of-the-art approaches, achieving 0.834 and 0.671 on RECOLA, 0.573 and 0.533 on SEWA in terms of arousal and valence, respectively. These findings indicate a novel direction for continuous emotion recognition by exploring temporal multi-scale information.},
  archive      = {J_APIN},
  author       = {Shi, Congbao and Zhang, Yuanyuan and Liu, Baolin},
  doi          = {10.1007/s10489-024-05329-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3040-3057},
  shortjournal = {Appl. Intell.},
  title        = {A multimodal fusion-based deep learning framework combined with local-global contextual TCNs for continuous emotion recognition from videos},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A classification method of marine mammal calls based on
two-channel fusion network. <em>APIN</em>, <em>54</em>(4), 3017–3039.
(<a href="https://doi.org/10.1007/s10489-023-05138-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marine mammals are an important part of marine ecosystems, and human intervention seriously threatens their living environments. Few studies exist on the marine mammal call recognition task, and the accuracy of current research needs to improve. In this paper, a novel MG-ResFormer two-channel fusion network architecture is proposed, which can extract local features and global timing information from sound signals almost perfectly. Second, in the input stage of the model, we propose an improved acoustic feature energy fingerprint, which is different from the traditional single feature approach. This feature also contains frequency, energy, time sequence and other speech information and has a strong identity. Additionally, to achieve more reliable accuracy in the multiclass call recognition task, we propose a multigranular joint layer to capture the family and genus relationships between classes. In the experimental section, the proposed method is compared with the existing feature extraction methods and recognition methods. In addition, this paper also compares with the latest research, and the proposed method is the most advanced algorithm thus far. Ultimately, our proposed method achieves an accuracy of 99.39% in the marine mammal call recognition task.},
  archive      = {J_APIN},
  author       = {Li, Danyang and Liao, Jie and Jiang, Hongbo and Jiang, Kailin and Chen, Mingwei and Zhou, Bei and Pu, Haibo and Li, Jun},
  doi          = {10.1007/s10489-023-05138-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {3017-3039},
  shortjournal = {Appl. Intell.},
  title        = {A classification method of marine mammal calls based on two-channel fusion network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incomplete multi-view clustering via self-attention networks
and feature reconstruction. <em>APIN</em>, <em>54</em>(4), 2998–3016.
(<a href="https://doi.org/10.1007/s10489-024-05299-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, numerous deep learning-based methods have been proposed for incomplete multi-view clustering. However, these approaches overlook two crucial issues. First, they focus solely on the global information contained in the latent representations derived from deep networks, neglecting the importance of local focal points. Second, while leveraging consistent or complementary inter-view information for cross-view learning, they disregard the intrinsic relationships among different samples within the same view. To address these concerns, this manuscript presents an original approach: incomplete multi-view clustering based on self-attention networks and feature reconstruction (SNFR). Specifically, SNFR initially employs self-attention networks to emphasize the pivotal information within views, aiming to reduce the inter-view reconstruction loss. Subsequently, an improved entropy weighting method is applied to reconstruct the feature relationships among the diverse samples within the same view, thereby facilitating consistent cross-view information learning. Our proposed method is evaluated on six widely used multi-view datasets through extensive experiments, highlighting its remarkable superiority over the alternative approaches in terms of clustering performance},
  archive      = {J_APIN},
  author       = {Zhang, Yong and Jiang, Li and Liu, Da and Liu, Wenzhe},
  doi          = {10.1007/s10489-024-05299-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {2998-3016},
  shortjournal = {Appl. Intell.},
  title        = {Incomplete multi-view clustering via self-attention networks and feature reconstruction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervison with data-augmentation improves few-shot
learning. <em>APIN</em>, <em>54</em>(4), 2976–2997. (<a
href="https://doi.org/10.1007/s10489-024-05340-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervision learning (SSL) has shown exceptionally promising results in natural language processing and, more recently, in image classification and recognition. Recent research works have demonstrated SSL’s benefits on large unlabeled datasets. However, relatively little investigation has been done into how well it works with smaller datasets. Typically, this challenge entails training a model on a very small quantity of data and then evaluating the model on out-of-distribution data. Few-shot image classification aims to classify classes that haven’t been seen before using a limited number of training examples. Recent few-shot learning research focuses on developing good representation models that can quickly adapt to test tasks. In this paper, we investigate the role of self-supervision in the context of few-shot learning. We devised a model that improves the network’s representation learning by employing a self-supervised auxiliary task that is based on composite rotation. We propose a composite rotation-based auxiliary task that rotates the image on two levels: inner and outer, and assigns one of 16 rotation classes to the modified image. Then, we further trained our model, which enables us to capture the robust learnable features that assist in focusing on better visual details of an object present in the given image. We find that the network is able to learn to extract more generalized and discriminative features, which in turn helps to enhance the effectiveness of its few-shot classification. This approach significantly outperforms the state-of-the-art on several public benchmarks. In addition, we demonstrated empirically that models trained using the proposed approach perform better than the baseline model even when the query examples in the episode are not aligned with the support examples. Extensive ablation experiments are performed to validate the various components of our approach. We also investigate our strategy’s impact on the network’s ability to discriminate visual features. Graphical Abstract},
  archive      = {J_APIN},
  author       = {Kumar, Prashant and Toshniwal, Durga},
  doi          = {10.1007/s10489-024-05340-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {2976-2997},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervison with data-augmentation improves few-shot learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UnifiedSC: A unified framework via collaborative
optimization for multi-task person re-identification. <em>APIN</em>,
<em>54</em>(4), 2962–2975. (<a
href="https://doi.org/10.1007/s10489-024-05333-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID) encompasses two independent study branches, i.e., single-modality and cross-modality identifications. Since single-modality and cross-modality pedestrian data have completely different properties, it is hard to accomplish both tasks at once. However, studying either of the two tasks alone limits the application of person ReID. Therefore, we first explore the relationship between single-modality and cross-modality person ReID and attempt to solve the multi-task optimization problem. To this end, we propose a unified framework, termed UnifiedSC, to mine identity-invariant discriminative features for multi-task person ReID. To effectively optimize the deep model, we construct a collaborative optimization strategy to simultaneously train visible and infrared images from two aspects. On the one hand, two independent classifiers are designed to separately perform single-modality and cross-modality pedestrian identification. On the other hand, we handle the identity-aware feature discrepancy problem at both the feature and classifier levels. At the feature level, we introduce a verification model to distinguish positive/negative sample pairs and employ the weighted regularization triplet to constrain the relative feature distribution. Meanwhile, at the classifier level, we create a shared-weight classifier to map pedestrian features from different domains into a similar feature space. With the promotion of collaborative optimization, the proposed UnifiedSC framework could perceive different pedestrian information and mine identity-invariant features. Our method achieves a mean rank-1 of = 84.7% on the Market1501 and SYSU-MM01 databases, while it also achieves a mean rank-1 of = 78.9% on the DukeMTMC-reID and SYSU-MM01 databases. Abundant experiments adequately demonstrate that UnifiedSC achieves state-of-the-art performance in both tasks and is valuable for person ReID.},
  archive      = {J_APIN},
  author       = {Si, Tongzhen and He, Fazhi and Li, Penglei},
  doi          = {10.1007/s10489-024-05333-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {2962-2975},
  shortjournal = {Appl. Intell.},
  title        = {UnifiedSC: A unified framework via collaborative optimization for multi-task person re-identification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Amplification methods to promote the attacks against machine
learning-based intrusion detection systems. <em>APIN</em>,
<em>54</em>(4), 2941–2961. (<a
href="https://doi.org/10.1007/s10489-024-05311-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security of machine learning attracts increasing attention in both academia and industry due to its vulnerability to adversarial examples. However, the research on adversarial examples in intrusion detection is currently in its infancy. In this paper, two novel adversarial attack amplification methods based on a unified framework are proposed to promote the attack performance of the classic white-box attack methods. The proposed methods shield the underlying implementation details of the target attack methods and can effectively boost different target attack methods through a unified interface. The proposed methods extract the original adversarial perturbations from the adversarial examples produced by the target attack methods and amplify the original adversarial perturbations to generate the amplified adversarial examples. The preliminary experimental results show that the proposed methods can effectively improve the attack performance of the classic white-box attack methods. Besides, the amplified adversarial examples crafted by the proposed methods show excellent transferability across different machine learning classifiers, which ensures that the application of the proposed methods is not limited to the white-box setting. Consequently, the proposed methods can be utilized to better assess the robustness of the machine learning-based intrusion detection systems against adversarial examples in various contexts.},
  archive      = {J_APIN},
  author       = {Zhang, Sicong and Xu, Yang and Zhang, Xinyu and Xie, Xiaoyao},
  doi          = {10.1007/s10489-024-05311-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {2941-2961},
  shortjournal = {Appl. Intell.},
  title        = {Amplification methods to promote the attacks against machine learning-based intrusion detection systems},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-exemplar affinity propagation clustering based on
local density peak. <em>APIN</em>, <em>54</em>(3), 2915–2939. (<a
href="https://doi.org/10.1007/s10489-023-05243-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the representatives of subclusters in multi-exemplar affinity propagation clustering (MEAP), exemplars are important in generating and merging subclusters. However, MEAP ignores the difference in data point distribution between local neighbourhoods, leading to a situation in which these selected exemplars are sometimes not the most appropriate points to represent subclusters, and the clustering performance is greatly affected. Meanwhile, local density peaks (LDPs) are found to be good representatives in local neighbourhoods. Thus, we propose the multi-exemplar affinity propagation clustering algorithm based on local density peaks (LDP-MEAP), where each exemplar should be selected from LDPs. Since MEAP must regard all points as potential exemplars (PE), we first design the MEAP with settable PE based on the assumption that the similarity values from points to PE are finite and to non-PE are negatively infinite, and we call it MEAP-PE. We then search the LDPs by point similarities to coordinate with MEAP-PE using k nearest neighbours and local density with natural neighbours. Finally, we specify that all LDPs are PE in MEAP-PE and update messages iteratively to obtain clusters. We combine MEAP-PE with LDPs, providing a new approach for AP-based clustering methods with lower computational complexity and better clustering performance. Compared with other LDP-based methods, LDP-MEAP also has better clustering performance. Comparative experiments with many prior approaches on 16 datasets demonstrate the superiority of our proposed method.},
  archive      = {J_APIN},
  author       = {Zhou, Shibing and Chen, Zhewei and Duan, Rao and Song, Wei},
  doi          = {10.1007/s10489-023-05243-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2915-2939},
  shortjournal = {Appl. Intell.},
  title        = {Multi-exemplar affinity propagation clustering based on local density peak},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing knowledge graph embedding with structure and
semantic features. <em>APIN</em>, <em>54</em>(3), 2900–2914. (<a
href="https://doi.org/10.1007/s10489-024-05315-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding converts knowledge graphs based on symbolic representations into low-dimensional vectors. Effective knowledge graph embedding methods are key to ensuring downstream tasks. Some studies have shown significant performance differences among various knowledge graph embedding models on different datasets. They attribute this issue to the insufficient representation ability of the models. However, what representation ability knowledge graph embedding models possess is still unknown. Therefore, this paper first selects three representative models for analysis: translation and rotation models in distance models, and the Bert model in neural network models. Based on the analysis results, it can be concluded that the translation model focuses on clustering features, the rotation model focuses on hierarchy features, and the Bert model focuses on word co-occurrence features. This paper categorize clustering and hierarchy as structure features, and word co-occurrence as semantic features. Furthermore, a model that solely focuses on a single feature will lead to a lack of accuracy and generality, making it challenging for the model to be applicable to modern large-scale knowledge graphs. Therefore, this paper proposes an ensemble model with structure and semantic features for knowledge graph embedding. Specifically, the ensemble model includes a structure part and a semantic part. The structure part consists of three models: translation, rotation and cross. Translation and rotation models serve as basic feature extraction, while the cross model enhances the interaction between them. The semantic part is built based on Bert and integrated with the structure part after fine-tuning. In addition, this paper also introduces a frequency model to mitigate the training imbalance caused by differences in entity frequencies. Finally, we verify the effectiveness of the model through link prediction. Experiments show that the ensemble model has achieved improvement on FB15k-237 and YAGO3-10, and also has good performance on WN18RR, proving the effectiveness of the model.},
  archive      = {J_APIN},
  author       = {Wang, Yalin and Peng, Yubin and Guo, Jingyu},
  doi          = {10.1007/s10489-024-05315-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2900-2914},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing knowledge graph embedding with structure and semantic features},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Comprehensive vulnerability aspect extraction.
<em>APIN</em>, <em>54</em>(3), 2881–2899. (<a
href="https://doi.org/10.1007/s10489-023-05262-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting valuable information from unstructured vulnerability reports constitutes a fundamental task in numerous cybersecurity applications. Existing approaches necessitate the creation of new extraction models and data labeling efforts, also inadvertently leading to duplicated information extraction. Therefore, we devote to extracting almost all valuable aspects at in a single sweep to benefit most downstream tasks. However, comprehensive extraction is challenging, which not only increases the boundaries of the aspects to be located but also reduces the number of learnable words in a vulnerability report. In this paper, we propose the Vulnerability Portrait Automatic Generator (Vul-PAG), designed to facilitate comprehensive vulnerability aspect extraction by capturing and amalgamating word’s multi-view information. It encompasses a split-reorganization mechanism based on the wordpiece mechanism to capture the internal writing feature of words alongside a MidConst task to grasp the syntactic feature of words. Further, we fuse them with the semantic feature output from the context-dependent language model to bolster the word’s representation ability. Furthermore, we present the first-ever dataset crafted for the comprehensive extraction of vulnerability aspects, containing 2200 descriptions and encompassing eight distinct aspects. Extensive experimental results show that Vul-PAG outperforms state-of-the-art methods by 3.47, 2.68, and 3.07 in terms of precision, recall, and F1-score, respectively.},
  archive      = {J_APIN},
  author       = {Li, Qindong and Tang, Wenyi and Chen, Xingshu and Feng, Song and Wang, Lizhi},
  doi          = {10.1007/s10489-023-05262-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2881-2899},
  shortjournal = {Appl. Intell.},
  title        = {Comprehensive vulnerability aspect extraction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust discriminative feature learning with calibrated data
reconstruction and sparse low-rank model. <em>APIN</em>, <em>54</em>(3),
2867–2880. (<a href="https://doi.org/10.1007/s10489-017-1060-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since large amounts of labeled high-dimensional data needed to be processed, supervised feature learning has become an important and challenging problem in machine learning. Conventional supervised methods often adopt ℓ 2-norm loss function, which is sensitive to the outliers. However, real world data always contain lots of outliers that make traditional supervised methods fail to achieve the optimal performance. In addition, these methods can not reconstruct the original complex structured data well, since the dimensions of their learned projection matrices are often limited to the number of classes and are sub-optimal. To address these challenges, we propose a novel robust discriminative feature learning (RDFL) method via calibrated data reconstruction and sparse low-rank model. Specifically, RDFL preserves the discriminant information and simultaneously reconstructs the complex low-rank structure by minimizing joint ℓ 2,1-norm reconstruction error and within-class distance. To solve the proposed non-smooth problem, we derive an efficient optimization algorithm to soften the contributions of outliers. Meanwhile, we adopt the general power iteration method (GPIM) to accelerate our algorithm to make it scalable to large scale problem and theoretically analyze the convergence and computational complexity of the proposed algorithm. Extensive experimental results present that our proposed RDFL outperforms other compared methods in most cases and significantly improve the robust performance to noise and outliers.},
  archive      = {J_APIN},
  author       = {Luo, Tingjin and Yang, Yang and Yi, Dongyun and Ye, Jieping},
  doi          = {10.1007/s10489-017-1060-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2867-2880},
  shortjournal = {Appl. Intell.},
  title        = {Robust discriminative feature learning with calibrated data reconstruction and sparse low-rank model},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint learning of structural and textual information on
propagation network by graph attention networks for rumor detection.
<em>APIN</em>, <em>54</em>(3), 2851–2866. (<a
href="https://doi.org/10.1007/s10489-024-05312-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the advantages in information dissemination, social media is growing rapidly among the public but has also become a medium for the spread of rumors. Given the serious damage rumors bring to society, detecting rumors from the mass information on social media is becoming an arduous challenge. Therefore, some deep learning techniques, such as Recurrent Neural Networks and Graph Neural Networks, have been applied to detect rumors with propagation paths and content. Nonetheless, these deep learning-based methods ignore the propagation structure of rumors or cannot effectively extract the propagation structure information of each node. Inspired by this, we propose a novel rumor detection framework named $$\varvec{Rumor2Topic}$$ . We first adopt $$\varvec{GraphAnchorLDA}$$ (Graph Anchor Latent Dirichlet Allocation) to extract the structural topic representation of rumor events, and then utilize Graph Attention Networks (GATs) to further extract the complex semantic and propagation structure information of rumor events. Meanwhile, the encouraging empirical results of $$\varvec{Rumor2Topic}$$ on several benchmarks confirm that the proposed method is superior to the most advanced methods. Our proposed Rumor2Topic achieved 2.62%, 2.07%, and 2.57% improvements compared to the optimal method on three publicly available benchmarks, Twitter15, Twitter16, and Weibo, respectively.},
  archive      = {J_APIN},
  author       = {Zhao, Qihang and Zhang, Yuzhe and Feng, Xiaodong},
  doi          = {10.1007/s10489-024-05312-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2851-2866},
  shortjournal = {Appl. Intell.},
  title        = {Joint learning of structural and textual information on propagation network by graph attention networks for rumor detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Human-object interaction detection based on cascade
multi-scale transformer. <em>APIN</em>, <em>54</em>(3), 2831–2850. (<a
href="https://doi.org/10.1007/s10489-024-05324-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-object interaction (HOI) detection is an advanced computer vision task for detecting the relationship between human and surrounding objects. Some methods have emerged to accomplish this task with impressive results, but possess certain limitations. We analyze in detail the advantages and disadvantages between different paradigms, and creatively propose a cascade multi-scale transformer (CMST). CMST comprises three key components: a shared encoder, a human-object pair decoder, and an interaction decoder. These three components are responsible for extracting contextual features, localizing the human-object pairs and classifying the specific interactions in pairs, respectively. CMST decouples the tasks of object detection and interaction classification while still maintains an end-to-end detection pipeline. Furthermore, we aim to address the issues of high computational complexity and slow convergence associated with the transformer architecture. To achieve this, we propose two novel attention mechanisms: multi-scale human-object pair attention and multi-scale interaction attention. By incorporating these attentions, we introduce multi-scale features, making our model well-suited for complex scenes involving instances of varying scales. The effectiveness of our approach is proven on widely-used benchmarks where we achieve better improvements. The experimental results demonstrate that CMST has great potential for real-time applications and complex scene detection.},
  archive      = {J_APIN},
  author       = {Xia, Limin and Ding, Xiaoyue},
  doi          = {10.1007/s10489-024-05324-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2831-2850},
  shortjournal = {Appl. Intell.},
  title        = {Human-object interaction detection based on cascade multi-scale transformer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Effects of single and multiple imputation strategies on
addressing over-fitting issues caused by imbalanced data from various
scenarios. <em>APIN</em>, <em>54</em>(3), 2812–2830. (<a
href="https://doi.org/10.1007/s10489-024-05295-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of missing values consistently emerges as a critical issue in most machine learning tasks, as they can alter the distribution of the training data and consequently lead to overfitting. The theoretical framework for missing value imputation has reached a considerable level of maturity, with numerous imputation models having been proposed. However, there has been limited research conducted on the underlying causes of missing values and scenarios where imbalanced data is significantly correlated with target variables due to business logic. In this study, we conducted simulation studies to evaluate the imputation performance of six imputation models on six datasets under three missing mechanisms, including random dropout, imbalance dropout based on features, and imbalance dropout based on labels, to identify an appropriate approach to deal with imbalanced missing data with certain patterns. By recognizing the missing pattern and imputing the data with a suitable imputation method, the overfitting issue caused by missingness has been significantly mitigated in a real-world application.},
  archive      = {J_APIN},
  author       = {Yang, Jiaxi and Wang, Yihan and Yang, Ye and Ding, Kai and Na, Chongning and Yang, Yao},
  doi          = {10.1007/s10489-024-05295-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2812-2830},
  shortjournal = {Appl. Intell.},
  title        = {Effects of single and multiple imputation strategies on addressing over-fitting issues caused by imbalanced data from various scenarios},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards a unified framework for imperceptible textual
attacks. <em>APIN</em>, <em>54</em>(3), 2798–2811. (<a
href="https://doi.org/10.1007/s10489-024-05292-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the great success of Deep Neural Networks (DNNs) in the field of natural language processing (NLP), they are increasingly facing tremendous threats from textual attacks in two kinds: adversarial attacks and backdoor attacks. Both of them are able to manipulate DNNs into producing the designated target label. By searching the optimal replacement in the massive space of possible candidates, current textual attacks deal with each input sample one at a time. However, attacking in this manner is time consuming, and the generated samples suffer from low semantic consistency and language fluency. To address this issue, we design a unified framework for targeted adversarial attacks and backdoor attacks, which employs a masked language model to produce imperceptible poisoned samples directly. We conduct extensive experiments on three benchmark datasets for three different NLP model architectures. Experimental results reveal that the proposed framework can achieve the state-of-the-art attacking performance for backdoor attacks with a substantial improvement, and a more pronounced improvements for targeted adversarial attacks, while concurrently maintaining the high linguistic quality of generated samples.},
  archive      = {J_APIN},
  author       = {Shi, Jiahui and Li, Linjing and Zeng, Daniel},
  doi          = {10.1007/s10489-024-05292-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2798-2811},
  shortjournal = {Appl. Intell.},
  title        = {Towards a unified framework for imperceptible textual attacks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fair-satisfied-based group decision making with prospect
theory under DHLTS: The application in enterprise human resource
allocation. <em>APIN</em>, <em>54</em>(3), 2783–2797. (<a
href="https://doi.org/10.1007/s10489-023-05222-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group decision making (GDM) can make full use of information in the group and consider perspectives of multiple stakeholders, which matches the characteristic of enterprise human resource (HR) allocation. This paper tries to optimize the enterprise HR allocation by establishing a fair-satisfied-based GDM model with two objectives of fairness and satisfaction respectively. Firstly, double hierarchy linguistic term set is used to collect the evaluation information of decision makers (DMs). Then, two quantification methods for DMs’ satisfaction perception and fairness perception are respectively provided respectively based on the Prospect theory. Moreover, combining with the Pareto optimal idea, the fair-satisfied-based GDM model is designed and applied to deal with an enterprise HR allocation problem. Finally, some comprehensive analyses are made to validate the proposed method.},
  archive      = {J_APIN},
  author       = {Liu, Xing and Gou, Xunjie and Xu, Zeshui},
  doi          = {10.1007/s10489-023-05222-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2783-2797},
  shortjournal = {Appl. Intell.},
  title        = {Fair-satisfied-based group decision making with prospect theory under DHLTS: The application in enterprise human resource allocation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-constrained network dismantling using quadratic
evolutionary algorithm for interdependent networks. <em>APIN</em>,
<em>54</em>(3), 2767–2782. (<a
href="https://doi.org/10.1007/s10489-024-05289-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dismantling and protection of networks is a significant problem that has wide-ranging applications and attracts many researchers. Most current studies only focus on single-layer or one-to-one interdependent networks. However, this paper considers the more realistic case where the links between layers in interdependent networks are one-to-many, and the networks’ robustness is studied accordingly. To solve the problem of dissolving interdependent networks under the premise of heterogeneous costs, we propose a cost-constrained elite quadratic evolutionary algorithm (CCEEA) based on cost constraints. Based on the network’s prior information, the initial optimal feasible solutions derived from four classical algorithms are regarded as the initial elite individuals of CCEEA. The set of attack nodes is then continuously updated interactively according to a new evolutionary mechanism with flexible updates so that the combination of nodes in the final set of attack nodes can maximally facilitate the disintegration of the network. We conducted experiments on a series of representative networks and showed that on synthetic networks, the CCEEA algorithm outperforms the other four state-of-the-art attack strategies by more than 13% in terms of disintegration, which is up to 25% higher. In particular, it can be up to more than 90% higher in real networks.},
  archive      = {J_APIN},
  author       = {Li, Yong-hui and Liu, San-yang and Bai, Yi-guang},
  doi          = {10.1007/s10489-024-05289-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2767-2782},
  shortjournal = {Appl. Intell.},
  title        = {Cost-constrained network dismantling using quadratic evolutionary algorithm for interdependent networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse and regression learning of large-scale fuzzy
cognitive maps based on adaptive loss function. <em>APIN</em>,
<em>54</em>(3), 2750–2766. (<a
href="https://doi.org/10.1007/s10489-023-05112-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive maps (FCMs) learning is a hot topic in recent years. However, as the number of concepts increases in FCMs, it is difficult to learn the sparse and robust FCMs from a small amount of data, especially from noise data. In this paper, a new large-scale FCMs learning method based on the sparse regression of adaptive loss function is presented, marked as AQP-FCM. Adaptive loss function and $$L_1$$ -norm are introduced in the model to deal with noise data. We solve the model by ADMM method and quadratic programming method to learn the FCMs better. Moreover, the convergence of model is proved. We did a series of experiments under the synthetic data of time series and noise synthesis data. AQP-FCM is also applied to reconstruct gene regulatory network (GRNs). The results of the experiments show that the proposed AQP-FCM method has good performance.},
  archive      = {J_APIN},
  author       = {Zhou, Qimin and Ma, Yingcang and Xing, Zhiwei and Yang, Xiaofei},
  doi          = {10.1007/s10489-023-05112-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2750-2766},
  shortjournal = {Appl. Intell.},
  title        = {Sparse and regression learning of large-scale fuzzy cognitive maps based on adaptive loss function},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attentive graph structure learning embedded in deep
spatial-temporal graph neural network for traffic forecasting.
<em>APIN</em>, <em>54</em>(3), 2716–2749. (<a
href="https://doi.org/10.1007/s10489-024-05291-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A smooth traffic flow is very crucial for an intelligent traffic system. Consequently, traffic forecasting is critical in achieving unwrinkled traffic flow. However, due to its spatial and temporal interdependence, traffic forecasting might be more difficult. Graph neural networks (GNN) are widely used to obtain traffic forecasting due to their capability to operate in non-Euclidean data. The topological connection of the traffic network plays a crucial role in graph structure learning. Therefore, the importance of the adjacency matrix in graph construction might be significant for effective traffic forecasting. As a result, for efficient graph construction, a Deep Spatial-Temporal Graph Neural Network (DSTGNN) is proposed for the construction of the weighted adjacency matrix and traffic speed prediction accurately by recording topological and temporal information. Three different weighted adjacency matrices are suggested depending on three different proposed algorithms for different variations of traffic’s spatial condition. The new adjacency matrix is used in a novel DSTGNN for predicting the traffic state. The novel model comprised multiple layers with skip connections to adequately extract the variation of temporal and spatial information. DSTGNN outperforms the standard and other graph neural network models on four traffic speed datasets, SZ-taxi, Los-loop, PeMSD7, and METR-LA.},
  archive      = {J_APIN},
  author       = {Bikram, Pritam and Das, Shubhajyoti and Biswas, Arindam},
  doi          = {10.1007/s10489-024-05291-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2716-2749},
  shortjournal = {Appl. Intell.},
  title        = {Attentive graph structure learning embedded in deep spatial-temporal graph neural network for traffic forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emotion-cause pair extraction via knowledge-driven
multi-classification and graph-based position embedding. <em>APIN</em>,
<em>54</em>(3), 2703–2715. (<a
href="https://doi.org/10.1007/s10489-024-05326-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion-Cause Pair Extraction (ECPE) is an important yet challenging task, focused on concurrently extracting emotional clauses and their corresponding causal clauses. Despite notable improvements in extraction performance over the past few years, three critical issues have been overlooked: (1) The binary classification of emotional and causal clauses may neglect the emotional semantics. In reality, there exist four types of clauses: emotion, cause, emotion-cause, and none-emotion-cause. (2) The integration of prior knowledge concerning sentiment information and causal information has been lacking. (3) The positional information of emotion-cause pairs may be adversely affected by imprecise emotional hypotheses and unbalanced document lengths. To tackle these challenges, we propose a new knowledge-driven multi-classification sub-task aimed at classifying clauses into the four mentioned types. Additionally, we introduce graph-based position embedding to capture relevant positional information. Experimental results underscore the effectiveness of our approach in addressing these issues.},
  archive      = {J_APIN},
  author       = {Zong, Linlin and Zhang, Jinglin and Zhou, Jiahui and Zhang, Xianchao and Xu, Bo},
  doi          = {10.1007/s10489-024-05326-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2703-2715},
  shortjournal = {Appl. Intell.},
  title        = {Emotion-cause pair extraction via knowledge-driven multi-classification and graph-based position embedding},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024d). Managing non-cooperative behaviors in consensus reaching
processes: A comprehensive self-management weight generation mechanism.
<em>APIN</em>, <em>54</em>(3), 2673–2702. (<a
href="https://doi.org/10.1007/s10489-024-05281-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision-making, a consensus-reaching process (CRP) is critical to minimize conflicts among decision-makers. Non-cooperative behaviors during the CRP may slow the consensus achievement or even lead to consensus failure. Previous research has not thoroughly identified various non-cooperative behaviors nor has it developed distinct management strategies for different CRP stages. This study aims to provide a systematic approach for identifying and addressing non-cooperative behaviors at different CRP stages, employing tailored management for each behavior type. We introduce and apply a concept named ‘comprehensive score’ to facilitate varied responses to non-cooperative behaviors throughout the CRP. A null-norm operator-based self-management weight generation mechanism is proposed to monitor experts’ historical performance, while a systematic analysis of experts’ characteristics enables detailed classification of non-cooperative behaviors. Through the research, we find that there are seven types of non-cooperative researches which needs to be respectively addressed according to its effects. The proposed management scheme improves the efficiency of CRP. Besides, the current research enriches the mechanisms for identifying and handling non-cooperative behaviors. It offers methodological references for non-cooperative behaviors management in more complex decision-making scenarios.},
  archive      = {J_APIN},
  author       = {Liu, Yaya and Zhang, Xiaowen and Rodríguez, Rosa M. and Martínez, Luis},
  doi          = {10.1007/s10489-024-05281-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2673-2702},
  shortjournal = {Appl. Intell.},
  title        = {Managing non-cooperative behaviors in consensus reaching processes: A comprehensive self-management weight generation mechanism},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probability density prediction of peak load based on mixed
frequency noise-assisted multivariate empirical mode decomposition.
<em>APIN</em>, <em>54</em>(3), 2648–2672. (<a
href="https://doi.org/10.1007/s10489-024-05286-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate peak load forecasting is crucial to ensuring the reliable operation of the power system. However, existing prediction models often neglect full explanations for peak loads by factors that are often complex and fluctuating. Moreover, different factors are usually sampled at diverse frequencies, and existing processing methods have substantial limitations in mining irregular mixed-frequency multi-series information, leading to reduced accuracy. Consequently, this paper proposes an innovative ensemble peak-load prediction model that combines noise-assisted multivariate empirical mode decomposition algorithm for mixed-frequency sampling data with the quantile regression neural network to effectively tackle the aforementioned challenges. Firstly, noise-assisted multivariate empirical mode decomposition algorithm for mixed-frequency sampling data is employed to transform several mixed-frequency fluctuating time series into multiple sets of stationary sub-sequences. Secondly, the quantile prediction of peak load is performed for each group of subsequences using the quantile regression neural network. Finally, conditional quantiles under each quantile are accumulated as the samples for kernel density estimation to complete probability density forecasting. The case study validates the superiority and stability of the proposed model. Extensive experimental results on two real-world datasets from the VT and the Houston in America show that our proposed model is significantly superior to other benchmark methods regarding peak load especially on extremes.},
  archive      = {J_APIN},
  author       = {He, Yaoyao and Liu, Yuting and Zhang, Wanying},
  doi          = {10.1007/s10489-024-05286-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2648-2672},
  shortjournal = {Appl. Intell.},
  title        = {Probability density prediction of peak load based on mixed frequency noise-assisted multivariate empirical mode decomposition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustering-based attack detection for adversarial
reinforcement learning. <em>APIN</em>, <em>54</em>(3), 2631–2647. (<a
href="https://doi.org/10.1007/s10489-024-05275-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting malicious attacks presents a major challenge in the field of reinforcement learning (RL), as such attacks can force the victim to perform abnormal actions, with potentially severe consequences. To mitigate these risks, current research focuses on the enhancement of RL algorithms with efficient detection mechanisms, especially for real-world applications. Adversarial attacks have the potential to alter the environmental dynamics of a Markov Decision Process (MDP) perceived by an RL agent. Leveraging these changes in dynamics, we propose a novel approach to detect attacks. Our contribution can be summarized in two main aspects. Firstly, we propose a novel formalization of the attack detection problem that entails analyzing modifications made by attacks to the transition and reward dynamics within the environment. This problem can be framed as a context change detection problem, where the goal is to identify the transition from a “free-of-attack” situation to an “under-attack” scenario. To solve this problem, we propose a groundbreaking “model-free” clustering-based countermeasure. This approach consists of two essential steps: first, partitioning the transition space into clusters, and then using this partitioning to identify changes in environmental dynamics caused by adversarial attacks. To assess the efficiency of our detection method, we performed experiments on four established RL domains (grid-world, mountain car, carpole, and acrobot) and subjected them to four advanced attack types. Uniform, Strategically-timed, Q-value, and Multi-objective. Our study proves that our technique has a high potential for perturbation detection, even in scenarios where attackers employ more sophisticated strategies.},
  archive      = {J_APIN},
  author       = {Majadas, Rubén and García, Javier and Fernández, Fernando},
  doi          = {10.1007/s10489-024-05275-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2631-2647},
  shortjournal = {Appl. Intell.},
  title        = {Clustering-based attack detection for adversarial reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-path hypernetworks of style and text for one-shot
domain adaptation. <em>APIN</em>, <em>54</em>(3), 2614–2630. (<a
href="https://doi.org/10.1007/s10489-023-05229-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a one-shot domain adaptation model is an exciting and challenging topic in computer vision and graphics. A feasible solution is to fine-tune a pre-trained generator to the target domain by leveraging the powerful semantic capabilities of CLIP (Contrastive Language-Image Pretraining). Unfortunately, when the target image shows a significant difference from the source domain, existing methods would result in overfitting, and generated images do not correctly reflect the texture of the target image. To address this issue, we propose a Dynamic Domain Transfer Strategy (DDTS) to align the texture information between the source and target domain by dynamically adjusting the direction of domain transfer. Furthermore, the delicately designed dual-path hypernetworks of style and text (Dual-HyperST) for one-shot domain adaptation characterize the target domain’s textual style and visual style with a text-guide path and a style-guide path. Specifically, the style-guided path predicts a set of style weight offsets by the target image, followed by the text-guided path predicts a set of text weight offsets by a text prompt. To better integrate the information between these two paths, we introduce a hypernetwork that learns to modulate the pre-trained generator instead of fine-tuning. Qualitative and quantitative experiments demonstrate the superiority of Dual-HyperST, which surpasses the state-of-the-art methods in the diversity and high quality of the generated images.},
  archive      = {J_APIN},
  author       = {Li, Siqi and Pu, Yuanyuan and Zhao, Zhengpeng and Yang, Qiuxia and Gu, Jinjing and Li, Yupan and Xu, Dan},
  doi          = {10.1007/s10489-023-05229-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2614-2630},
  shortjournal = {Appl. Intell.},
  title        = {Dual-path hypernetworks of style and text for one-shot domain adaptation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). AMGCN: Adaptive multigraph convolutional networks for
traffic speed forecasting. <em>APIN</em>, <em>54</em>(3), 2594–2613. (<a
href="https://doi.org/10.1007/s10489-024-05301-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic speed forecasting is a crucial aspect of traffic management that requires an accurate multi spatiotemporal time series forecasting technique. Previous studies typically employ graph neural network (GNN)-based methods for this task, but they are limited by their focus on spatial dependence based on real geographic distance in road networks. These structures are often inadequate for accurately describing spatial dependencies in the real world. Recently, multigraph neural networks (MGNNs) have shown considerable promise for improving forecasting performance by modelling graph structures from different spatial relationships. However, these kinds of methods do not account for complex relationships between aspects and latent dependence that cannot be known beforehand. To address these shortcomings, we propose a novel traffic speed forecasting method called adaptive multigraph convolutional networks (AMGCN), where we first introduce five predefined graphs based on spatial distance, accessibility, pattern similarity, distribution similarity and KL divergence. We fuse these graphs into a complex prior graph using a method based on spatial attention and graph relation attention. In this process, the spatial dependence in the road network is modelled comprehensively from multiple perspectives. In addition, we introduce the adaptive graph to calculate the similarity between learnable node embeddings to assist the forecasting. In this process, spatial dependencies that still cannot be captured by predefined graphs can be obtained by the way of data-driven. We utilize a mix-hop graph convolution with a residual connection to capture spatial dependencies in prior graphs and adaptive graphs. Time dependencies are also captured through causal convolution based on equidistance downsampling to prevent overfitting and redundancy in capturing spatiotemporal interactions. Extensive experiments on four real-world datasets demonstrate that our proposed method achieves superior performance compared to other baselines and effectively captures the spatiotemporal dependencies of the road network. Source codes are available at https://github.com/hfimmortal/AMGCN .},
  archive      = {J_APIN},
  author       = {Li, Chenghao and Zhao, Yahui and Zhang, Zhenguo},
  doi          = {10.1007/s10489-024-05301-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2594-2613},
  shortjournal = {Appl. Intell.},
  title        = {AMGCN: Adaptive multigraph convolutional networks for traffic speed forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bit-close: A fast incremental concept calculation method.
<em>APIN</em>, <em>54</em>(3), 2582–2593. (<a
href="https://doi.org/10.1007/s10489-024-05272-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of Formal Concept Analysis (FCA) finds diverse applications in fields like knowledge extraction, cognitive concept learning and data mining. The construction of a concept lattice significantly influences the effectiveness of formal concept analysis; hence, the development of high-performance algorithms for concept construction is crucial. In this paper, we introduce a novel algorithm called “Bit-Close” for formal concept construction. Bit-Close leverages bit representation and operations, fundamental to computer science, to enhance the In-Close algorithm. Furthermore, we explore the parallel method of Bit-Close. Our experimental results, obtained from multiple public and random datasets, demonstrate that Bit-Close outperforms In-Close by approximately 20% and is significantly better than other competing algorithms.},
  archive      = {J_APIN},
  author       = {Ke, Yunfeng and Li, Jinhai and Li, Shen},
  doi          = {10.1007/s10489-024-05272-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2582-2593},
  shortjournal = {Appl. Intell.},
  title        = {Bit-close: A fast incremental concept calculation method},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A diverse/converged individual competition algorithm for
computationally expensive many-objective optimization. <em>APIN</em>,
<em>54</em>(3), 2564–2581. (<a
href="https://doi.org/10.1007/s10489-024-05270-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) are popular for solving expensive optimization problems. However, most existing SAEAs are designed for solving single-objective or multiobjective optimization problems with two or three objectives. Few works had been reported to deal with expensive many-objective optimization problems with more than three objectives because of two difficulties. One is the curse of dimensionality caused by many-objective problems, and the other is the fewer computational resources available in a limited time for expensive optimization problems. Since an effective selection method can better solve the many-objective optimization problems, high-efficiency search and accurate model can save computational resources for expensive optimization problems, this paper proposes a diverse/converged individual competition algorithm, which owns a novel diverse/converged individual competition selection mechanism, a hybrid search mechanism, and a segmentation approach. The diverse/converged individual competition selection mechanism maintains a good balance between the convergence and diversity of the selected solutions for solving many-objective optimization problems. The hybrid search mechanism performs a memetic search and genetic search at different stages of the evolution process to further generate superior solutions. The segmentation approach uses two different populations with small numbers to build two surrogate models which will predict different areas, and it can improve the accuracy of the prediction. The proposed algorithm is compared with several state-of-art algorithms on widely used benchmark functions. The experimental results show that the proposed algorithm performs significantly better than the compared algorithms.},
  archive      = {J_APIN},
  author       = {Lin, Jie and Zhang, Sheng Xin and Zheng, Shao Yong},
  doi          = {10.1007/s10489-024-05270-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2564-2581},
  shortjournal = {Appl. Intell.},
  title        = {A diverse/converged individual competition algorithm for computationally expensive many-objective optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WMBAL: Weighted minimum bounds for active learning.
<em>APIN</em>, <em>54</em>(3), 2551–2563. (<a
href="https://doi.org/10.1007/s10489-024-05328-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, aimed at reliably acquiring difficult samples for object detection models from massive raw data, we propose a novel difficult sample mining strategy based on active learning with Weighted Minimum Bounds (WMB). To accurately gauge the difficulty of samples for object detection models, we introduce the concept of weighted minimum bounds. Uniquely, the metric for measuring sample difficulty includes the classification discrepancy within detection frames and a weight factor derived from the Average Precision (AP) of the object detection model on the val set. Additionally, we introduce the Don’t Care Area (DCA) to capture the uncertainty in localization tasks for object detection models. The DCA is utilized only during the data mining and training phases, ensuring that no additional time is incurred during inference. Furthermore, we propose a periodic and phased framework based on active learning for mining difficult samples, which can progressively identify challenging samples from unlabeled data and perform iterative optimization. To evaluate the effectiveness of our methods, we have collected the VANJEE-Image dataset and the VANJEE-PointCloud dataset from real-world scenarios. We empirically demonstrate the superiority of our approach, which outperforms traditional active learning methods on both image detection and point cloud detection datasets. The code and datasets are available at https://github.com/sharkls/WMBAL-Weighted-Minimum-Bounds-for-Active-Learning.},
  archive      = {J_APIN},
  author       = {Lu, Shuai and Zheng, Jiaxi and Li, Zhi and Dai, Xuerui},
  doi          = {10.1007/s10489-024-05328-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2551-2563},
  shortjournal = {Appl. Intell.},
  title        = {WMBAL: Weighted minimum bounds for active learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Missing data imputation and classification of small sample
missing time series data based on gradient penalized adversarial
multi-task learning. <em>APIN</em>, <em>54</em>(3), 2528–2550. (<a
href="https://doi.org/10.1007/s10489-024-05314-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, time series data obtained is usually small and missing, which poses a great challenge to data analysis in different domains, such as increasing the bias of model predictions, reducing the accuracy of model classification, and affecting the analysis data. This paper aims to address the problem of missing data imputation and classification of small sample time series data. By exploring and implementing efficient data interpolation strategies to improve classification accuracy, the robustness and accuracy of classification models in the face of incomplete data. To achieve this, we propose a new model that can effectively classify time series data with missing values. Our model utilizes a bi-directional long short-term memory network combined with an extreme learning machine for the imputation task, which can recover the missing time series values. For the classification task, we employ a self-attentional Inception Time network, which is regularized by a classification loss to effectively mitigate network overfitting. To improve the performance of the model on small sample time series datasets, we use a gradient penalty adversarial training approach. Our model integrates the advantages of multiple network modules, the gradient penalty adversarial multi-task model achieves optimal imputation and robust classification of missing small sample time series data. To evaluate the overall performance of our model, we selected forty datasets from the UCR time series datasets, and selected the German emotional speech datasets and the EEG epilepsy datasets, with the plant electrical signal datasets obtained from real measurements. A series of experiments were conducted to evaluate the effectiveness of our method compared to other methods, the datasets were set up with multiple missing rates, with root mean square error and coefficient of determination to assess the accuracy of imputation, and with accuracy to assess the performance of the classification task. The results show that our proposed method outperforms existing methods in terms of imputation accuracy and classification performance. To better understand the deep learning model, we used the Grad-CAM +  + method to enhance the reliability and credibility of the model by visualizing the important features of the temporal data when the plant electrical signal datasets was tested. In summary, this paper presents a model framework for the imputation and classification of missing small sample time series data, and the experimental results show that our model provides an effective solution for dealing with the analysis of missing small sample time series data.},
  archive      = {J_APIN},
  author       = {Liu, Jing-Jing and Yao, Jie-Peng and Liu, Jin-Hang and Wang, Zhong-Yi and Huang, Lan},
  doi          = {10.1007/s10489-024-05314-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2528-2550},
  shortjournal = {Appl. Intell.},
  title        = {Missing data imputation and classification of small sample missing time series data based on gradient penalized adversarial multi-task learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive sensorimotor control model emulating neural
activities for planar human arm reaching movements. <em>APIN</em>,
<em>54</em>(3), 2508–2527. (<a
href="https://doi.org/10.1007/s10489-023-04796-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional Electrical Stimulation (FES) has demonstrated potential in clinical applications, but determining the optimal electrical current to stimulate muscles remains challenging due to the intricate coordination of various muscle groups during human movement. In this study, we introduce a novel approach to model and control human arm planar reaching movements. In terms of the model, a comprehensive human upper limb model is developed, taking into account the double-link structure, six muscles, and the connection points between muscles and the skeletal system. Regarding the control, a comprehensive sensorimotor control model emulating neural activities for human arm planar reaching movements is proposed. The control model effectively incorporates the imprecise nature of human visual sensory feedback for arm endpoint positioning and emulates the neural activities to determine appropriate stimulation levels for each of the six constituent muscles, inducing muscle contractions and guiding the skeletal systems to the target positions. The effectiveness of the proposed controller is demonstrated via numerical simulation experiments. Through comparisons with different controllers, it is shown that the proposed controller exhibits superior performance in tracking predefined motion trajectories and robustness in dealing with various skeletal muscle arm parameters.},
  archive      = {J_APIN},
  author       = {Zhao, Yongkun and Zhang, Mingquan and Wu, Haijun and Jing, Shibo and Zhou, Tianyu and Todoh, Masahiro},
  doi          = {10.1007/s10489-023-04796-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2508-2527},
  shortjournal = {Appl. Intell.},
  title        = {A comprehensive sensorimotor control model emulating neural activities for planar human arm reaching movements},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MPNet: Temporal knowledge graph completion based on a
multi-policy network. <em>APIN</em>, <em>54</em>(3), 2491–2507. (<a
href="https://doi.org/10.1007/s10489-024-05320-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graphs completion (TKGC) is a critical task that aims to forecast facts that will occur in future timestamps. It has attracted increasing research interest in recent years. Among the many approaches, reinforcement learning-based methods have gained attention due to their efficient performance and interpretability. However, these methods still face two challenges in the prediction task. First, a single policy network lacks the capability to capture the dynamic and static features of entities and relationships separately. Consequently, it fails to evaluate candidate actions comprehensively from multiple perspectives. Secondly, the composition of the action space is incomplete, often guiding the agent towards distant historical events and missing the answers in recent history. To address these challenges, this paper proposes a Temporal Knowledge Graph Completion Based on a Multi-Policy Network(MPNet). It constructs three policies from the aspects of static entity-relation, dynamic relationships, and dynamic entities, respectively, to evaluate candidate actions comprehensively. In addition, this paper creates a more diverse action space that guides the agent in investigating answers within historical subgraphs more effectively. The effectiveness of MPNet is validated through an extrapolation setting, and extensive experiments conducted on three benchmark datasets demonstrate the superior performance of MPNet compared to existing state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Wang, Jingbin and Wu, RenFei and Wu, YuWei and Zhang, FuYuan and Zhang, SiRui and Guo, Kun},
  doi          = {10.1007/s10489-024-05320-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2491-2507},
  shortjournal = {Appl. Intell.},
  title        = {MPNet: Temporal knowledge graph completion based on a multi-policy network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wasserstein GAN-based architecture to generate collaborative
filtering synthetic datasets. <em>APIN</em>, <em>54</em>(3), 2472–2490.
(<a href="https://doi.org/10.1007/s10489-024-05313-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, generative applications are reshaping different fields, such as art, computer vision, speech processing, and natural language. The computer science personalization area is increasingly relevant since large companies such as Spotify, Netflix, TripAdvisor, Amazon, and Google use recommender systems. Then, it is rational to expect that generative learning will increasingly be used to improve current recommender systems. In this paper, a method is proposed to generate synthetic recommender system datasets that can be used to test the recommendation performance and accuracy of a company on different simulated scenarios, such as large increases in their dataset sizes, number of users, or number of items. Specifically, an improvement in the state-of-the-art method is proposed by applying the Wasserstein concept to the generative adversarial network for recommender systems (GANRS) seminal method to generate synthetic datasets. The results show that our proposed method reduces the mode collapse, increases the sizes of the synthetic datasets, improves their ratings distributions, and maintains the potential to choose the desired number of users, number of items, and starting size of the dataset. Both the baseline GANRS and the proposed Wasserstein-based WGANRS deep learning architectures generate fake profiles from dense, short, and continuous embeddings in the latent space instead of the sparse, large, and discrete raw samples that previous GAN models used as a source. To enable reproducibility, the Python and Keras codes are provided in open repositories along with the synthetic datasets generated to test the proposed architecture ( https://github.com/jesusbobadilla/ganrs.git ).},
  archive      = {J_APIN},
  author       = {Bobadilla, Jesús and Gutiérrez, Abraham},
  doi          = {10.1007/s10489-024-05313-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2472-2490},
  shortjournal = {Appl. Intell.},
  title        = {Wasserstein GAN-based architecture to generate collaborative filtering synthetic datasets},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic-guided spatio-temporal attention for few-shot
action recognition. <em>APIN</em>, <em>54</em>(3), 2458–2471. (<a
href="https://doi.org/10.1007/s10489-024-05294-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot action recognition is a challenging problem aimed at learning a model capable of adapting to recognize new categories using only a few labeled videos. Recently, some works use attention mechanisms to focus on relevant regions to obtain discriminative representations. Despite the significant progress, these methods still cannot attain outstanding performance due to insufficient examples and a scarcity of additional supplementary information. In this paper, we propose a novel Semantic-guided Spatio-temporal Attention (SGSTA) approach for few-shot action recognition. The main idea of SGSTA is to exploit the semantic information contained in the text embedding of labels to guide attention to more accurately capture the rich spatio-temporal context in videos when visual content is insufficient. Specifically, SGSTA comprises two essential components: a visual-text alignment module and a semantic-guided spatio-temporal attention module. The former is used to align visual features and text embeddings to eliminate semantic gaps between them. The latter is further divided into spatial attention and temporal attention. Firstly, a semantic-guided spatial attention is applied on the frame feature map to focus on semantically relevant spatial regions. Then, a semantic-guided temporal attention is used to encode the semantically enhanced temporal context with a temporal Transformer. Finally, use the spatio-temporally contextual representation obtained to learn relationship matching between support and query sequences. In this way, SGSTA can fully utilize rich semantic priors in label embeddings to improve class-specific discriminability and achieve accurate few-shot recognition. Comprehensive experiments on four challenging benchmarks demonstrate that the proposed SGSTA is effective and achieves competitive performance over existing state-of-the-art methods under various settings.},
  archive      = {J_APIN},
  author       = {Wang, Jianyu and Liu, Baolin},
  doi          = {10.1007/s10489-024-05294-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2458-2471},
  shortjournal = {Appl. Intell.},
  title        = {Semantic-guided spatio-temporal attention for few-shot action recognition},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hesitant fuzzy three-way concept lattice and its attribute
reduction. <em>APIN</em>, <em>54</em>(3), 2445–2457. (<a
href="https://doi.org/10.1007/s10489-024-05317-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis is a widely studied mathematical tool for performing data analysis and processing. Three-way decision is a model of decision making based on human cognition, which decomposes the problem to be solved into three elements and then reprocesses them. Hesitant fuzzy sets use some possible values instead of one, which can reflect the hesitation and uncertainty of the decision makers. This paper combines the three elements together for the first time and proposes a hesitant fuzzy three-way concept lattice model, which not only extends the concept lattice model but also provides a new way to deal with imprecise data. Firstly, the hesitant fuzzy three-way concept lattice model is proposed and the related properties are investigated. Further, two methods of constructing the hesitant fuzzy three-way concept lattice are studied, and the related construction algorithms are given. Thirdly, the attribute reduction based on the hesitant fuzzy three-way concept lattice is proposed, and a heuristic reduction algorithm is given. Finally, the effectiveness of the proposed algorithms for constructing the hesitant fuzzy three-way concept lattice is verified through some experiments, and the efficiency of the algorithm is compared.},
  archive      = {J_APIN},
  author       = {Zhang, Jun and Hu, Qian and Mi, Jusheng and Fu, Chao},
  doi          = {10.1007/s10489-024-05317-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2445-2457},
  shortjournal = {Appl. Intell.},
  title        = {Hesitant fuzzy three-way concept lattice and its attribute reduction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GaitCTCG: Cross-view gait recognition via cascaded residual
temporal shift and comprehensive multi-granularity learning.
<em>APIN</em>, <em>54</em>(3), 2428–2444. (<a
href="https://doi.org/10.1007/s10489-023-05241-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait is one of the most popular biometrics for identity authentication today due to its noninvasive perception. Diverse spatial representations and temporal modeling are crucial information for gait recognition, especially under covariation conditions. However, most existing algorithms only focus on the specific temporal-scale modeling (i.e., short-term or long-term) and single-level or single-granularity (i.e., global or local) spatial representation; these algorithms lack flexibility and diversity for the extraction of features. To address this issue, we propose a cascaded residual temporal shift and comprehensive multi-granularity learning (GaitCTCG) network for gait recognition. Specifically, a cascaded residual temporal shift (CRTS) module was proposed to capture multiple receptive fields in the temporal dimension without any additional parameters or computational cost, thereby flexibly integrating features of different temporal scales. A comprehensive multi-granularity learning (CMGL) module was designed with a multi-layer multi-granularity scheme to extract and fuse comprehensive spatial representations at different scales, exploiting various visual details of the input. Furthermore, a micro gait energy generator (MGEG) was also developed to distill sequence representation, which refined the local temporal segments while preserving richer spatial information. Extensive experiments on two of the most popular public datasets demonstrated the state-of-the-art performance of our proposed method, which achieved rank-1 accuracies of 98.0%, 95.3%, and 84.4% in the normal walking (NM), bag carrying (BG), and coat-wearing (CL) scenarios on CASIA-B, and 91.2% on OUMVLP. The source code will be published at https://github.com/HUAFOR/GaitCTCG .},
  archive      = {J_APIN},
  author       = {Huang, Binyuan and Zhou, Chengju and He, Lewei and Xu, Chi and Pan, Jiahui},
  doi          = {10.1007/s10489-023-05241-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2428-2444},
  shortjournal = {Appl. Intell.},
  title        = {GaitCTCG: Cross-view gait recognition via cascaded residual temporal shift and comprehensive multi-granularity learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). IGA-SOMK + +: A new clustering method for constructing web
user profiles of older adults in china. <em>APIN</em>, <em>54</em>(3),
2397–2427. (<a
href="https://doi.org/10.1007/s10489-024-05267-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining user data and constructing web user profiles of older adults from the perspective of elderly services is conducive to understanding their behavioral habits, needs, and usage preferences on the web, which provides more targeted elderly care services. In this paper, IGA-SOMK +  + , which is a novel clustering method for constructing web user profiles of older adults, is proposed based on the China Family Panel Studies (CFPS) survey data, which include 6596 older adults aged greater than 60 years. The selected data aspects include basic information, work situation, health situation, living habits, and web use services. To describe the web user profiles of older adults, a hybrid method based on improved genetic algorithm (IGA) feature selection, self-organizing feature maps (SOM), and K-means +  + is proposed. Data on older adults’ web use behaviors are first processed, and IGA is used for feature selection based on the adaptive crossover and mutation probabilities. SOM is then used to determine the initial center vectors of K-means +  + for further clustering, which is referred to as SOMK +  + (SOM-K-means + +). The results of IGA-SOMK +  + are compared with those of the state-of-the-art methods, including the K-means, mini batch K-means, Agnes, K-modes, FCM, K-means +  + , SOMK +  + , and IHPSO-KM. In addition, the significance and robustness of IGA-SOMK +  + are analyzed. The experimental results show that the IGA feature selection reduces the influence of the redundant feature factors and improves the performance of the clustering algorithm. SOMK +  + overcomes the sensitivity of K-means to initial cluster centers. Moreover, IGA-SOMK +  + has the best clustering effect among the compared algorithms in terms of silhouette coefficient (SC), calinski-harabaz (CH) index, and davies-bouldin (DB) metrics. For example, it increases the SC from 0.280 to 0.629. Finally, by analyzing the results, the user group of older adults is segmented to perform the deep mining of CFPS data, which verifies the feasibility of the user profile model. This paper summarizes the basic situation of the current web access of older adults in China in terms of web use services, as well as the importance of the web in their lives and in the information channels. It also provides suggestions for the current problems of older adults in accessing the web.},
  archive      = {J_APIN},
  author       = {Li, Yue and Liu, Chengqi and Hu, Xinyue and Qi, Jianfang and Chen, Gong},
  doi          = {10.1007/s10489-024-05267-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2397-2427},
  shortjournal = {Appl. Intell.},
  title        = {IGA-SOMK + +: A new clustering method for constructing web user profiles of older adults in china},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clarification question generation diversity and specificity
enhancement based on question keyword prediction. <em>APIN</em>,
<em>54</em>(3), 2379–2396. (<a
href="https://doi.org/10.1007/s10489-024-05316-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clarification question generation is used mainly to solve the potential missing product information problem in e-commerce. However, the problem of not being able to better understand contextual semantic information has arisen when studying the diversity and specificity of clarification questions. This further leads to imprecise prediction of question keywords. With the aim of solving the current constraints, we propose the Transformer Encoder of Keyword Predictor Keyword-Conditioned Network (TEKPCNet). First, the transformer encoder has been proven to perform well in predicting external question keywords by encoding context. Then, the Text Convolutional Neural Network (TextCNN) and multilayer perceptron are combined to enhance the input of the encoder-decoder model. The diversity and specificity of the clarification question generation process should be further enhanced. Finally, the decoding process is completed by combining the attention mechanism. The generated clarification questions were evaluated in terms of two datasets using both automatic assessment and human evaluation. The experimental results show that the proposed model outperforms the other models.},
  archive      = {J_APIN},
  author       = {Zhou, Mingtao and Zhou, Juxiang and Gan, Jianhou and Gao, Wei and Xu, Jian},
  doi          = {10.1007/s10489-024-05316-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2379-2396},
  shortjournal = {Appl. Intell.},
  title        = {Clarification question generation diversity and specificity enhancement based on question keyword prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ABNGrad: Adaptive step size gradient descent for optimizing
neural networks. <em>APIN</em>, <em>54</em>(3), 2361–2378. (<a
href="https://doi.org/10.1007/s10489-024-05303-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic adaptive gradient decent algorithms, such as AdaGrad and Adam, are extensively used to train deep neural networks. However, randomly sampling gradient information introduces instability to the learning rates, leading to adaptive methods with poor generalization. To address this issue, the ABNGrad algorithm, which leverages the absolute value operation and the normalization technique, is proposed. More specifically, the absolute value function is first incorporated into the iteration of the second-order moment estimate to ensure that it monotonically increases. Then, the normalization technique is employed to prevent a rapid decrease in the learning rate. In particular, the techniques used in this paper can also be integrated into other existing adaptive algorithms, such as Adam, AdamW, AdaBound, and RAdam, yielding good performance. Additionally, it is shown that ABNGrad can attain the optimal regret bound for solving online convex optimization problems. Finally, many experimental results illustrate the effectiveness of ABNGrad. For a comprehensive exploration of the advantages of the proposed approach and the specifics of its detailed implementation, the readers are referred to the following https://github.com/Wenhan-Jiang/ABNGrad.git},
  archive      = {J_APIN},
  author       = {Jiang, Wenhan and Liang, Yuqing and Jiang, Zhixia and Xu, Dongpo and Zhou, Linhua},
  doi          = {10.1007/s10489-024-05303-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2361-2378},
  shortjournal = {Appl. Intell.},
  title        = {ABNGrad: Adaptive step size gradient descent for optimizing neural networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive hypergraph regularized logistic regression model
for bioinformatic selection and classification. <em>APIN</em>,
<em>54</em>(3), 2349–2360. (<a
href="https://doi.org/10.1007/s10489-024-05304-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of cancer using established biological knowledge has become increasingly prevalent, primarily due to the improved accuracy and enhanced biological interpretability this method offers for classification outcomes. Despite these advances, current cancer classification methods encounter challenges in maintaining the intricate structure of gene networks and leveraging the statistical information embedded within gene data. In this paper, we introduce an adaptive hypergraph regularized logistic regression model that capitalizes on established biological knowledge and statistical information within gene data. Specifically, our model integrates a hypergraph into the objective function, an innovation that preserves the complex gene network structure more effectively. Additionally, we implement adaptive penalties in the penalty term, which facilitates the targeted selection of disease-related genes based on gene weights. To further refine our model, we incorporate constraints on gene pairs with high statistical correlations within the penalty term, thereby minimizing the inclusion of redundant genes. We adopt the block coordinate descent algorithm to address the nonconvexity of our model. Through comparative experimentation with established methodologies on real datasets, our proposed model demonstrates marked improvement in classification accuracy and adept selection of genes pertinent to specific diseases.},
  archive      = {J_APIN},
  author       = {Jin, Yong and Hou, Huaibin and Qin, Mian and Yang, Wei and Zhang, Zhen},
  doi          = {10.1007/s10489-024-05304-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {2349-2360},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive hypergraph regularized logistic regression model for bioinformatic selection and classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DBTN: An adaptive neural network for multiple-disease
detection via imbalanced medical images distribution. <em>APIN</em>,
<em>54</em>(2), 2188–2210. (<a
href="https://doi.org/10.1007/s10489-023-05165-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring medical images while maintaining patient information confidentiality is a difficult task, which leads to a lack of sufficient data for deep learning-based disease detection. To address the challenges of few-shot learning in such scenarios, researchers generally resort to the transfer learning ability of the pre-train model. However, in practice, the pre-trained model only updates its fully connected layers or a few other layers with limited data examples while holding its many layers unchanged. Nonetheless, such transfer learning paradigms are not expected to alter the layer structure of the model. Consequently, the benefits of pre-trained models are limited, especially when the target dataset deviates from the source dataset in terms of data pattern. Moreover, the time cost of transfer retraining should also be considered. To alleviate these impacts, we propose a novel paradigm for multiple disease detection via medical images that combined a meta-heuristic algorithm and transfer learning. We also present a novel optimization algorithm and design two novel adaptive frameworks (BTL, DTL), and four adaptive neural networks (BVTN, BSTN, DVTN, and DSTN). In our paradigm, pre-trained models could adaptively adjust the feature extraction ability by reshaping a few network layers to accommodate the data distribution differences between source and target datasets. Thus, the negative impact of such differences can be effectively alleviated. We conduct experiments on three datasets (brain magnetic resonance, chest X-ray, and skin image datasets) with different data distributions. Experimental results show that our paradigm can effectively mitigate the impact of differences in data distribution, and that our method outperforms four state-of-the-art methods on all three datasets.},
  archive      = {J_APIN},
  author       = {Li, Xiang and Lan, Long and Sun, Chang-Yong and Yang, Shaowu and Wang, Shuihua and Yang, Wenjing and Liu, Hengzhu and Zhang, Yudong},
  doi          = {10.1007/s10489-023-05165-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2188-2210},
  shortjournal = {Appl. Intell.},
  title        = {DBTN: An adaptive neural network for multiple-disease detection via imbalanced medical images distribution},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Are my answers medically accurate? Exploiting medical
knowledge graphs for medical question answering. <em>APIN</em>,
<em>54</em>(2), 2172–2187. (<a
href="https://doi.org/10.1007/s10489-024-05282-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Poor health is one of the fundamental causes behind the suffering and deprivation of human beings. One of the United Nations (UN) Sustainable Development Goals is to enhance the quality of healthcare for everyone, which includes economic coverage, availability of high-quality fundamental health-care services, and access to proper, efficient, high-quality, and affordable important vaccinations and medications. Question-Answering (QA) in the medical domain has recently piqued the interest among the researchers and other stakeholders. Medical QA systems have the potential to enhance access to healthcare services, improve patient interactions with doctors, and reduce medical costs through e-medicine. In this paper, we describe a knowledge enabled QA model, which demonstrates how large-scale medical information in the form of knowledge graphs can aid in extracting more relevant answers. The proposed model employs two scoring methods, viz. Medical Entity Scoring (MES) and Context Relevance Scoring (CRS). MES ranks the medical entities from graphs according to their relevance, while CRS is used to reason over the supporting paragraph using the query vector. The system’s knowledge is obtained through the use of two distinct resources, viz. PharmKG is used for pharmaceutical terminology management, whereas Unified Medical Language System UMLS is used for general medical terminology management. Empirical results on the MASH-QA and COVID-QA datasets demonstrate that our proposed approach outperforms existing State-of-the-art in both machine evaluation and human judgment.},
  archive      = {J_APIN},
  author       = {Zafar, Aizan and Varshney, Deeksha and Kumar Sahoo, Sovan and Das, Amitava and Ekbal, Asif},
  doi          = {10.1007/s10489-024-05282-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2172-2187},
  shortjournal = {Appl. Intell.},
  title        = {Are my answers medically accurate? exploiting medical knowledge graphs for medical question answering},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic and geometric information propagation for oriented
object detection in aerial images. <em>APIN</em>, <em>54</em>(2),
2154–2171. (<a
href="https://doi.org/10.1007/s10489-023-05227-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike the natural scenes, aerial objects are often in arbitrary orientations and surrounded by cluttered backgrounds, causing the heterogeneous object features contaminated with backgrounds and interleaved clustered objects. Though segmentation denoising has been proposed to enhance arbitrary-oriented object detection in previous studies, the typical semantic segmentation brings ambiguous background information and ignores the significant geometric information propagation. In this paper, we explore the non-monotonic impacts of segmentation on object detection. Based on this, we propose a novel aerial object detector named PCG-Net to enhance the semantic and geometric information, as well as, alleviate the noise interference through segmentation guidance. PCG-Net includes a pseudo-siamese multi-scale relation module (PSM), a complementary segmentation map (CSM) and a global context module with adaptive distinction(GCMA). PSM captures the critical geometric and semantic features through parallel horizontal and oriented box-wise segmentation branches with interaction. As the guidance of each branch in PSM, CSM synergizes binary segmentation map and foreground semantic segmentation map so as to refine the semantic information and restrain the ambiguous background simultaneously. Based on the segmentation features from PSM, GCMA rebuilds and complements the global contextual information with pixel-level discrimination. Through exploiting the rich semantic, geometric and contextual information, the proposed framework enhances the feature representation powerfully in aerial images and suppresses noise interference effectively. Experiment results on three challenging aerial datasets including DOTA, HRSC2016 and DIOR-R, demonstrate the effectiveness of our approach.},
  archive      = {J_APIN},
  author       = {Niu, Tong and He, Xiaohai and Chen, Honggang and Qing, Linbo and Teng, Qizhi},
  doi          = {10.1007/s10489-023-05227-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2154-2171},
  shortjournal = {Appl. Intell.},
  title        = {Semantic and geometric information propagation for oriented object detection in aerial images},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved decision tree algorithm based on boundary mixed
attribute dependency. <em>APIN</em>, <em>54</em>(2), 2136–2153. (<a
href="https://doi.org/10.1007/s10489-023-05238-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective extension of rough set theory, the variable precision neighborhood rough set model has been applied to the attribute dependency-based improvement of decision tree algorithm of the solution concerning continuous data. However, the boundary region, as an effective description of the uncertainty of knowledge, has not been taken into account in the existing algorithms. In this paper, we define a novel decision rule based on boundary region and attribute dependency, and construct a decision tree algorithm via this decision rule. First, we define a measure called boundary coefficient based on the boundary region, which can be used for comparative quantitative analysis. Second, we define the boundary mixed attribute dependency by combining the boundary coefficient and the attribute dependency, which can consider both the boundary case of the target set and the attribute dependency. Finally, a novel decision tree algorithm is proposed by using the boundary mixed attribute dependency as the decision rule. The experimental results show that with a slight increase in leaf nodes, the total running time decreases and the maximum accuracy increases to 0.9518, which indicates the effectiveness of the proposed algorithm.},
  archive      = {J_APIN},
  author       = {Lin, Bowen and Liu, Caihui and Miao, Duoqian},
  doi          = {10.1007/s10489-023-05238-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2136-2153},
  shortjournal = {Appl. Intell.},
  title        = {An improved decision tree algorithm based on boundary mixed attribute dependency},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of reinforcement learning algorithms for nuclear
power plant fuel optimization. <em>APIN</em>, <em>54</em>(2), 2100–2135.
(<a href="https://doi.org/10.1007/s10489-023-05013-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nuclear fuel loading pattern optimization problem belongs to the class of large-scale combinatorial optimization. It is also characterized by multiple objectives and constraints, which makes it impossible to solve explicitly. Stochastic optimization methodologies including Genetic Algorithms and Simulated Annealing are used by different nuclear utilities and vendors but hand-designed solutions continue to be the prevalent method in the industry. To improve the state-of-the-art, Deep Reinforcement Learning (RL), in particular, Proximal Policy Optimization is leveraged. This work presents a first-of-a-kind approach to utilize deep RL to solve the loading pattern problem and could be leveraged for any engineering design optimization. This paper is also to our knowledge the first to propose a study of the behavior of several hyper-parameters that influence the RL algorithm. The algorithm is highly dependent on multiple factors such as the shape of the objective function derived for the core design that behaves as a fudge factor that affects the stability of the learning. But also an exploration/exploitation trade-off that manifests through different parameters such as the number of loading patterns seen by the agents per episode, the number of samples collected before a policy update , and an entropy factor that increases the randomness of the policy during training. We found that RL must be applied similarly to a Gaussian Process in which the acquisition function is replaced by a parametrized policy. Then, once an initial set of hyper-parameters is found, reducing and until no more learning is observed will result in the highest sample efficiency robustly and stably. This resulted in an economic benefit of 535,000 - 642,000 $/year/plant. Future work must extend this research to multi-objective settings and comparing them to state-of-the-art implementation of stochastic optimization methods.},
  archive      = {J_APIN},
  author       = {Seurin, Paul and Shirvan, Koroush},
  doi          = {10.1007/s10489-023-05013-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2100-2135},
  shortjournal = {Appl. Intell.},
  title        = {Assessment of reinforcement learning algorithms for nuclear power plant fuel optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic2Graph: Graph-based multi-modal feature fusion for
action segmentation in videos. <em>APIN</em>, <em>54</em>(2), 2084–2099.
(<a href="https://doi.org/10.1007/s10489-023-05259-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action segmentation have been widely applied in many fields. Most previous studies employed video-based vision models for this purpose. However, they often rely on a large receptive field, LSTM or Transformer methods to capture long-term dependencies within videos, leading to significant computational resource requirements. To address this challenge, graph-based model was proposed. However, previous graph-based models are less accurate. Hence, this study introduces a graph-structured approach named Semantic2Graph, to model long-term dependencies in videos, thereby reducing computational costs and raise the accuracy. We construct a graph structure of video at the frame-level. Temporal edges are utilized to model the temporal relations and action order within videos. Additionally, we have designed positive and negative semantic edges, accompanied by corresponding edge weights, to capture both long-term and short-term semantic relationships in video actions. Node attributes encompass a rich set of multi-modal features extracted from video content, graph structures, and label text, encompassing visual, structural, and semantic cues. To synthesize this multi-modal information effectively, we employ a graph neural network (GNN) model to fuse multi-modal features for node action label classification. Experimental results demonstrate that Semantic2Graph outperforms state-of-the-art methods in terms of performance, particularly on benchmark datasets such as GTEA and 50Salads. Multiple ablation experiments further validate the effectiveness of semantic features in enhancing model performance. Notably, the inclusion of semantic edges in Semantic2Graph allows for the cost-effective capture of long-term dependencies, affirming its utility in addressing the challenges posed by computational resource constraints in video-based vision models.},
  archive      = {J_APIN},
  author       = {Zhang, Junbin and Tsai, Pei-Hsuan and Tsai, Meng-Hsun},
  doi          = {10.1007/s10489-023-05259-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2084-2099},
  shortjournal = {Appl. Intell.},
  title        = {Semantic2Graph: Graph-based multi-modal feature fusion for action segmentation in videos},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A memetic approach to multi-disciplinary design and
numerical optimization problems using intensify slime mould optimizer.
<em>APIN</em>, <em>54</em>(2), 2031–2083. (<a
href="https://doi.org/10.1007/s10489-023-05073-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new memetic metaheuristic optimizer, hybridizing the classical Slime Mould Optimization Algorithm (SMA) with Harris hawk’s Optimizer (HHO), is developed. The proposed hSMA-HHO is based on SMA- a swarm-inspired population metaheuristics algorithm with a notable approach in global optimization and HHO- a nature-inspired algorithm based on the supportive behavior and hunting style of Harris hawks. Although both algorithms perform well individually, they still require improvement for better efficacious results. The exploitation and exploration behavior are improved. Also, the problem of trapping in local optima is removed as observed by investigating the proposed algorithm on an extensive set of standard benchmarks comprising multiple functions with various dimensions. The results achieved are analyzed and compared with other recent metaheuristic algorithms. Furthermore, convergence graphs and statistical analysis prove the supremacy of the proposed hSMA-HHO algorithm over other up-to-date metaheuristics algorithms. The proposed algorithm is also checked to solve the optimal design of 11 well-recognized constrained engineering problems. Analysis and comparison of results reveal that the proposed hSMA-HHO algorithm is an encouraging and viable optimization approach for elucidating different engineering design problems.},
  archive      = {J_APIN},
  author       = {Sehgal, Shivani and Ganesh, Aman and Kamboj, Vikram Kumar and Malik, O. P.},
  doi          = {10.1007/s10489-023-05073-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2031-2083},
  shortjournal = {Appl. Intell.},
  title        = {A memetic approach to multi-disciplinary design and numerical optimization problems using intensify slime mould optimizer},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). A novel immune detector training method for network anomaly
detection. <em>APIN</em>, <em>54</em>(2), 2009–2030. (<a
href="https://doi.org/10.1007/s10489-024-05288-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial immune system and network anomaly detection system are developed with common goals and principles considered. Moreover, artificial immune-based network anomaly detection can adaptively learn and dynamically detect threats. However, existing immune recognition algorithms suffer from the curse of dimensionality, hole problems, and detector inefficiency tolerance. In this paper, we proposed a novel immune detector training mechanism for network anomaly detection. First, a hybrid filter embedded feature selection algorithm is designed to comprehensively evaluate features and select the optimal subset. Then, candidate detectors are generated based on self antigens, and the nonself region is represented using complementary space to circumvent the hole problem. Finally, considering the training efficiency during the evolution of the candidate detectors, an antigen clustering feature tree is constructed to rapidly index the tolerance objects. Furthermore, the algorithm considers the effect of the collaboration of multiple mature detectors on candidate detectors, and a Monte Carlo-based coverage estimation algorithm is designed to achieve more accurate and fine-grained maturation tolerance of candidate detectors. The theoretical analysis shows that the time complexity of our algorithm is significantly reduced. The experimental results show that our algorithm not only improves the detection accuracy but also reduces the time cost of detector training.},
  archive      = {J_APIN},
  author       = {Liu, Xiaowen and Yang, Geying and Wang, Lina and Fu, Jie and Wang, Qinghao},
  doi          = {10.1007/s10489-024-05288-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {2009-2030},
  shortjournal = {Appl. Intell.},
  title        = {A novel immune detector training method for network anomaly detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scene text image super-resolution via textual reasoning and
multiscale cross-convolution. <em>APIN</em>, <em>54</em>(2), 1997–2008.
(<a href="https://doi.org/10.1007/s10489-023-05251-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text image super-resolution aims to upgrade the visual quality of low-resolution images and contributes to the accuracy of the subsequent scene text recognition task. However, advanced super-resolution methods with more attention to text-oriented information still have challenges in extremely blurred images. To address this problem, we propose a novel network based on textual reasoning and multiscale cross-convolution (TRMCC), in which a text structure preservation module is designed to explore the correlation of horizontal features among layers to enhance the structural similarity between the reconstructions and the corresponding high-resolution (HR) images and the multiscale cross-convolution block explores structural information hierarchically in layers with various perceptual fields in a progressive manner. In addition, based on human behavior in the presence of blurred images with linguistic rules, the text semantic reasoning module incorporated a self-attention mechanism and language-based textual reasoning to improve the accuracy of textual prior information. Comprehensive experiments conducted on the real-scene text image dataset TextZoom demonstrated the superiority of our model compared with existing state-of-the-art models, especially on structural similarity and information integrity.},
  archive      = {J_APIN},
  author       = {Yu, Lan and Li, Xiaojie and Yu, Qi and Li, Guangju and Jin, Dehu and Qi, Meng},
  doi          = {10.1007/s10489-023-05251-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1997-2008},
  shortjournal = {Appl. Intell.},
  title        = {Scene text image super-resolution via textual reasoning and multiscale cross-convolution},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). C <span class="math display"><sup>2</sup></span> net:
Content-dependent and -independent cross-attention network for anomaly
detection in videos. <em>APIN</em>, <em>54</em>(2), 1980–1996. (<a
href="https://doi.org/10.1007/s10489-023-05252-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in videos is a challenging issue that identifies unexpected occurrences if normal training examples are provided. Most approaches focus on designing elaborate models to mine normal patterns using content-dependent information. Nevertheless, content-dependent information, which includes various details, would have both positive and negative effects. The abundant details around abnormal events are conducive to anomaly detection by producing obvious errors, while complex details around normal events may lead to the erroneous detection of anomalies in challenging normal samples. To alleviate the problem of challenging normal samples, we propose a content-independent image without complex details for all normal samples during the training phase. It represents the pseudo label of regular patterns as a normal supporter. Accordingly, a content-dependent and -independent cross-attention network, termed C $$^2$$ Net, is introduced by jointly considering the advantage of content-dependent information and content-independent pseudo-label simultaneously. C $$^2$$ Net employs a fusion-first-then-separation strategy, where it injects the content-independent pseudo-label supporter into content-dependent frames using an auto-encoder network. It then reconstructs the content-independent pseudo-label supporter and the content-dependent frame respectively using siamese sub-networks. Additionally, a novel cross-attention module is designed between the siamese sub-networks to separate the information of the content-independent pseudo-label supporter and the content-dependent frame. The experimental results on three publicly outdoor datasets and a publicly indoor dataset about cognitive disorder rehabilitation assessment verify the effectiveness of C $$^2$$ Net.},
  archive      = {J_APIN},
  author       = {Liang, Jiafei and Xiao, Yang and Zhou, Joey Tianyi and Yang, Feng and Li, Ting and Fang, Zhiwen},
  doi          = {10.1007/s10489-023-05252-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1980-1996},
  shortjournal = {Appl. Intell.},
  title        = {C $$^{2}$$ net: Content-dependent and -independent cross-attention network for anomaly detection in videos},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Efficient heuristics for learning scalable bayesian network
classifier from labeled and unlabeled data. <em>APIN</em>,
<em>54</em>(2), 1957–1979. (<a
href="https://doi.org/10.1007/s10489-023-05242-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naive Bayes (NB) is one of the top ten machine learning algorithms whereas its attribute independence assumption rarely holds in practice. A feasible and efficient approach to improving NB is relaxing the assumption by adding augmented edges to the restricted topology of NB. In this paper we prove theoretically that the generalized topology may be a suboptimal solution to model multivariate probability distributions if its fitness to data cannot be measured. Thus we propose to apply log-likelihood function as the scoring function, then introduce an efficient heuristic search strategy to explore high-dependence relationships, and for each iteration the learned topology will be improved to fit data better. The proposed algorithm, called log-likelihood Bayesian classifier (LLBC), can respectively learn two submodels from labeled training set and individual unlabeled testing instance, and then make them work jointly for classification in the framework of ensemble learning. Our extensive experimental evaluations on 36 benchmark datasets from the University of California at Irvine (UCI) machine learning repository reveal that, LLBC demonstrates excellent classification performance and provides a competitive approach to learn from labeled and unlabeled data.},
  archive      = {J_APIN},
  author       = {Wang, Limin and Wang, Junjie and Guo, Lu and Li, Qilong},
  doi          = {10.1007/s10489-023-05242-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1957-1979},
  shortjournal = {Appl. Intell.},
  title        = {Efficient heuristics for learning scalable bayesian network classifier from labeled and unlabeled data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lesion-aware knowledge distillation for diabetic retinopathy
lesion segmentation. <em>APIN</em>, <em>54</em>(2), 1937–1956. (<a
href="https://doi.org/10.1007/s10489-024-05274-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal fundus images have been widely utilized for screening Diabetic Retinopathy (DR). The lesion information contained in these images is indispensable for the diagnosis of DR. The acquisition of lesion information depends on the sophisticated lesion segmentation methods. Nevertheless, the existing lesion segmentation methods highly rely on huge computational complexity and massive storage, making it difficult to apply in real-world clinical scenarios. Knowledge distillation (KD) has become an essential tool to reduce the computational complexity of the network. However, the lesion regions being insignificant in fundus images, directly applying the current KD methods cannot adequately transfer sufficient lesion knowledge, which restricts the learning of knowledge distillation. In essence, the challenge is how to enhance the focus of the KD process on lesion regions and to transfer more comprehensive pathological knowledge to the student network. Considering the importance of lesion regions in fundus images and the global semantic relations among lesion regions across various fundus images, we propose a Lesion-aware Knowledge Distillation (LKD) framework focusing on the transfer of lesion knowledge. The key contribution of the proposed framework is the creation of lesion embedding queue from the global training samples, which facilitates the transfer of global pathology knowledge from the teacher network to the student network, thus promoting the acquisition of lesion-related knowledge. Furthermore, we propose a self-paced hard sample learning strategy for knowledge transfer of lesion embedding queue, which additionally improves the efficiency of knowledge transfer. We evaluate LKD on IDRiD and DDR benchmark datasets, the overall performance of the proposed mehtod improves 2.1% AUPR as well as 2.2% DICE and 1.5% AUPR as well as 2.2% DICE compared to the previous best results. A particular improvement of 2.3% and 3.2% in DICE are achieved on the IDRiD dataset for tiny lesions, i.e., MA and HE, respectively. Our code is available at https://github.com/YaqiWangCV/LKD .},
  archive      = {J_APIN},
  author       = {Wang, Yaqi and Hou, Qingshan and Cao, Peng and Yang, Jinzhu and R. Zaiane, Osmar},
  doi          = {10.1007/s10489-024-05274-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1937-1956},
  shortjournal = {Appl. Intell.},
  title        = {Lesion-aware knowledge distillation for diabetic retinopathy lesion segmentation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding the input features that reduce the entropy of a
neural network’s prediction. <em>APIN</em>, <em>54</em>(2), 1922–1936.
(<a href="https://doi.org/10.1007/s10489-024-05277-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning-based image classification, the entropy of a neural network’s output is often taken as a measure of its uncertainty. We introduce an explainability method that identifies those features in the input that impact most this uncertainty. Learning the corresponding features by straightforward backpropagation typically leads to results that are hard to interpret. We propose an extension of the recently proposed oriented, modified integrated gradients (OMIG) technique as an alternative to produce perturbations of the input that have a visual quality comparable to explainability methods from the literature but marks features that have a substantially higher impact on the entropy. The potential benefits of the modified OMIG method are demonstrated by comparison with current state-of-the-art explainability methods on several popular databases. In addition to a qualitative analysis of explainability results, we propose a metric for their quantitative comparison, which evaluates the impact of identified features on the entropy of a prediction.},
  archive      = {J_APIN},
  author       = {Amanova, Narbota and Martin, Jörg and Elster, Clemens},
  doi          = {10.1007/s10489-024-05277-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1922-1936},
  shortjournal = {Appl. Intell.},
  title        = {Finding the input features that reduce the entropy of a neural network’s prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-varying group formation tracking for nonlinear
multi-agent systems under switching topologies. <em>APIN</em>,
<em>54</em>(2), 1909–1921. (<a
href="https://doi.org/10.1007/s10489-024-05285-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a group formation tracking controller for nonlinear multi-agent systems under switching topologies is proposed in which the group formation may have multiple time-varying subformations. Each subgroup has several active leaders with unknown but bounded control inputs and multiple followers whose dynamics are considered to consist of two parts, namely, the known linear term and the unknown nonlinear term. A distributed control protocol is then designed for the followers to realize time-varying group formation tracking, which is based on an extended state observer that estimates the state and nonlinear term of each follower. To guarantee the stability of the multi-agent system with the designed control protocol under switching topologies, a threshold for the dwell time, namely, the minimum time interval for each topology before switching, is derived. Finally, a numerical example with a group of unmanned aerial vehicles (UAVs), including three subgroups, is presented to verify the effectiveness of the proposed control protocol.},
  archive      = {J_APIN},
  author       = {Cai, Xin and Zhu, Hai and Zhu, Xiaozhou and Yao, Wen},
  doi          = {10.1007/s10489-024-05285-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1909-1921},
  shortjournal = {Appl. Intell.},
  title        = {Time-varying group formation tracking for nonlinear multi-agent systems under switching topologies},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KGTN-ens: Few-shot image classification with knowledge graph
ensembles. <em>APIN</em>, <em>54</em>(2), 1893–1908. (<a
href="https://doi.org/10.1007/s10489-023-05129-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose KGTN-ens, a framework extending the recent Knowledge Graph Transfer Network (KGTN) in order to incorporate multiple knowledge graph embeddings at a small cost. There are many real-world scenarios in which the amount of data is severely limited (e.g. health industry, rare anomalies). Prior knowledge can be used to tackle this task. In KGTN, one can use a single knowledge source at once. The purpose of this study is to investigate the possibility of combining multiple knowledge sources. We evaluate it with different embeddings in a few-shot image classification task. Our model is partially trained on $$k \in \{ 1, 2, 5, 10\}$$ samples. We also construct a new knowledge source – Wikidata embeddings – and evaluate it with KGTN and KGTN-ens. With ResNet50, our approach outperforms KGTN in terms of the top-5 accuracy on the ImageNet-FS dataset for the majority of tested settings. For $$k \in \{ 1, 2, 5, 10\}$$ respectively, we obtained +0.63/+0.58/+0.43/+0.26 pp. (novel classes) and +0.26/+0.25/+0.32/–0.04 pp. (all classes).},
  archive      = {J_APIN},
  author       = {Filipiak, Dominik and Fensel, Anna and Filipowska, Agata},
  doi          = {10.1007/s10489-023-05129-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1893-1908},
  shortjournal = {Appl. Intell.},
  title        = {KGTN-ens: Few-shot image classification with knowledge graph ensembles},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal variational contrastive learning for few-shot
classification. <em>APIN</em>, <em>54</em>(2), 1879–1892. (<a
href="https://doi.org/10.1007/s10489-024-05269-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of metric-based few-shot learning methods heavily relies on the discriminative ability of the prototypes and feature embeddings of queries. However, using instance-level unimodal prototypes often falls short in capturing the essence of various categories. To this end, we propose a multimodal variational contrastive learning framework that aims to enhance prototype representativeness and refine the discrimination of query features by acquiring distribution-level representations. Our approach starts by training a variational auto-encoder through supervised contrastive learning in both the visual and semantic spaces. The trained model is employed to augment the support set by sampling features from the learned semantic distributions and generate pseudo-semantics for queries to achieve information balance across samples in both the support and query sets. Furthermore, we establish a multimodal instance-to-distribution model that learns to transform instance-level multimodal features into distribution-level representations via variational inference, facilitating robust metric. Experiments show that our MVC consistently brings between 0.5 $$\%$$ and 7 $$\%$$ improvement in accuracy over state-of-the-art methods on standard few-shot learning datasets like miniImageNet, CIFAR-FS, tieredImageNet, and CUB, demonstrating the superiority of our method in terms of classification performance and robustness. The source code is available at: https://github.com/pmhDL/MVC.git .},
  archive      = {J_APIN},
  author       = {Pan, Meihong and Shen, Hongbin},
  doi          = {10.1007/s10489-024-05269-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1879-1892},
  shortjournal = {Appl. Intell.},
  title        = {Multimodal variational contrastive learning for few-shot classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rethinking the role of attention mechanism: A causality
perspective. <em>APIN</em>, <em>54</em>(2), 1862–1878. (<a
href="https://doi.org/10.1007/s10489-024-05279-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the core technology of Transformers, the attention mechanism is almost indispensable. However, many experimental findings show that the models developed based on the attention mechanism are not as perfect as imagined, and there are pitfalls in their ability to capture effective information, especially in some multi-modal tasks. In this paper, we continue to delve into this issue and try to uncover the mysterious nature of the attention mechanism through powerful explainable causal inference techniques. At the theoretical level, we rigorously characterize the capacity bottleneck of the attention mechanism in multi-modal tasks and demonstrate the shortcomings of the attention model in its ability to weed out invalid features. Further, we obtain results consistent with the theoretical analysis in the experimental session. In particular, the model optimized under the guidance of our theoretical analysis achieves superiority over state-of-the-art methods in visual question-answering tasks. Excitingly, we find that the attention mechanism’s defects can be repaired, and the repair method has strong generalization properties. This distinct advantage will provide a clear interpretable optimization technique for the attention-based framework.},
  archive      = {J_APIN},
  author       = {Wang, Chao and Zhou, Yang},
  doi          = {10.1007/s10489-024-05279-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1862-1878},
  shortjournal = {Appl. Intell.},
  title        = {Rethinking the role of attention mechanism: A causality perspective},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust meter reading detection via differentiable
binarization. <em>APIN</em>, <em>54</em>(2), 1847–1861. (<a
href="https://doi.org/10.1007/s10489-024-05278-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, scene text detection based on pixel-level segmentation becomes quite popular in industry, which is suitable for real-time digital meter reading detection. However, detection results of existing methods are usually not satisfactory due to the poor quality of images captured in a complex environment. In this paper, a novel method named Retina Differentiable Binarization (RetinaDB) is proposed for digital meter reading detection, which is robust to low quality images including blur, out-of-focus, shadow and so on. Bottom-up path augmentation and fusion factor are adopted into our feature pyramid network module to enhance the robustness of segmentation network, and an adaptive binarization function is designed for a better approximation to the standard binarization function. The experimental results, obtained on ICDAR 2015 and a digital meter reading dataset, show that the proposed RetinaDB significantly outperforms existing methods in both accuracy and efficiency. In particular, on the digital meter reading dataset, our detector achieves an F1-measure of 97.61%, inferencing at 47.13 FPS when using ResNet-18 as a backbone. When using ResNet-50, our method achieves the best detection results of 98.79%, 99.58% and 98.01% in terms of F1-measure, precision and recall.},
  archive      = {J_APIN},
  author       = {Rao, Yunbo and Guo, Hangrui and Liu, Dalang and Zeng, Shaoning},
  doi          = {10.1007/s10489-024-05278-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1847-1861},
  shortjournal = {Appl. Intell.},
  title        = {Robust meter reading detection via differentiable binarization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiresolution feature guidance based transformer for
anomaly detection. <em>APIN</em>, <em>54</em>(2), 1831–1846. (<a
href="https://doi.org/10.1007/s10489-024-05283-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is represented as an unsupervised learning to identify deviated images from normal images. In general, there are two main challenges of anomaly detection tasks, i.e., the class imbalance and the unexpectedness of anomalies. In this paper, we propose a multiresolution feature guidance method based on Transformer named GTrans for unsupervised anomaly detection and localization. In GTrans, an Anomaly Guided Network (AGN) pre-trained on ImageNet is developed to provide surrogate labels for features and tokens. Under the tacit knowledge guidance of the AGN, the anomaly detection network named Trans utilizes Transformer to effectively establish a relationship between features with multiresolution, enhancing the ability of the Trans in fitting the normal data manifold. Due to the strong generalization ability of AGN, GTrans locates anomalies by comparing the differences in spatial distance and direction of multi-scale features extracted from the AGN and the Trans. Our experiments demonstrate that the proposed GTrans achieves state-of-the-art performance in both detection and localization on the MVTec AD dataset. GTrans achieves image-level and pixel-level anomaly detection AUROC scores of 99.0% and 97.9% on the MVTec AD dataset, respectively.},
  archive      = {J_APIN},
  author       = {Yan, Shuting and Chen, Pingping and Chen, Honghui and Mao, Huan and Chen, Feng and Lin, Zhijian},
  doi          = {10.1007/s10489-024-05283-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1831-1846},
  shortjournal = {Appl. Intell.},
  title        = {Multiresolution feature guidance based transformer for anomaly detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-source domain generalization peron re-identification
with knowledge accumulation and distribution enhancement. <em>APIN</em>,
<em>54</em>(2), 1818–1830. (<a
href="https://doi.org/10.1007/s10489-024-05266-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization person re-identification (re-ID) is a more realistic task that aims to learn a model with multiple labeled source domains and generalize its inference to an unseen domain. However, under joint training of multi-source domains, some difficulties such as domain imbalance, domain shifts and small training batches not only influence the representation learning of the model but also lead to poor generalization performance. In this work, we enhance the generalization performance by proposing two strategies including knowledge accumulation and distribution enhancement for multi-source domain generalization person re-ID. Specifically, we encourage the learning of semantically significant features globally by establishing a simple but effective knowledge accumulation feature classifier (KAFC). In which, continuous learning guided by the label information explicitly provides stable prototype matching for each source domain, directly solving the problem that unstable parameter updates due to the small-batch data and source domain shifts. Secondly, to enhance the generalization ability and learn more robust representations, a multi-mix batch normalization (MMBN) module is introduced to generate the mixture features with cross-domain distribution information, where an approach based on the exponential moving average is adopted for capturing the domain distribution knowledge. Extensive experiments on multiple widely-used benchmarks demonstrate that our method can effectively improve the generalization capability on unseen domains.},
  archive      = {J_APIN},
  author       = {Peng, Wanru and Chen, Houjin and Li, Yanfeng and Sun, Jia},
  doi          = {10.1007/s10489-024-05266-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1818-1830},
  shortjournal = {Appl. Intell.},
  title        = {Multi-source domain generalization peron re-identification with knowledge accumulation and distribution enhancement},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective algorithm for genealogical graph partitioning.
<em>APIN</em>, <em>54</em>(2), 1798–1817. (<a
href="https://doi.org/10.1007/s10489-023-05265-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel Approximately Balanced Tree Partitioning Algorithm (TPA) to overcome the significant challenges in genealogical data management, encompassing the storage, maintenance, and interpretation of complex familial networks. Our TPA is adept at modularizing and simplifying intricate relationships in genealogical graphs into logically succinct tree structures, reducing user cognitive load and enhancing the utility of genealogical data in real applications like hereditary disease research, forensic investigation, and consanguinity counseling. In addition, TPA prioritizes structural closeness in partitioning to avoid misleading insights from unrelated data points and maintain a balance of node distribution to prevent workload and communication overheads in distributed graph data processing systems. The effectiveness of our algorithm is demonstrated through extensive experiments on four real-world genealogical datasets, substantiating its superiority over five state-of-the-art rival models in dealing with the complex and rapidly expanding landscape of genealogical data.},
  archive      = {J_APIN},
  author       = {Sheng, Shaojing and Zhang, Zan and Zhou, Peng and Wu, Xindong},
  doi          = {10.1007/s10489-023-05265-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1798-1817},
  shortjournal = {Appl. Intell.},
  title        = {An effective algorithm for genealogical graph partitioning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep learning integrated framework for predicting stock
index price and fluctuation via singular spectrum analysis and particle
swarm optimization. <em>APIN</em>, <em>54</em>(2), 1770–1797. (<a
href="https://doi.org/10.1007/s10489-024-05271-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity and volatility of stock market trading, there are still some issues in the existing prediction methods, including the processing of data noise, inexplicable selection of model parameters, and the lag in predicting price fluctuations. Aiming to better predict daily stock prices and fluctuations caused by high noise non-stationary data in actual trading, we propose a hybrid deep learning framework based on Singular Spectrum Analysis (SSA), multiple feature selection, and Long Short Term Memory (LSTM) network optimized by Particle Swarm Optimization (PSO). Based on Pearson correlation coefficients, we select features highly correlated with the closing price as inputs, and further achieve the noise reduction and optimization of those input sources by applying SSA to decompose the stock price time series into independent component signals. Using the stock price data from China and USA, we compared the prediction performance of our method with several well-known methods, and found that it achieved higher price prediction accuracy during periods of high stock volatility. For example, the R-squared and prediction accuracy of Shanghai Composite Index achieved 0.9998 and 99.01%, while the prediction metrics of S &amp;P 500 reached 0.9883 and 94.26%, respectively. Besides, considering transaction costs, our method also achieved the highest profit in trading tests, even compared to long-term holding strategy.},
  archive      = {J_APIN},
  author       = {Wang, Chia-Hung and Yuan, Jinchen and Zeng, Yingping and Lin, Shengming},
  doi          = {10.1007/s10489-024-05271-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1770-1797},
  shortjournal = {Appl. Intell.},
  title        = {A deep learning integrated framework for predicting stock index price and fluctuation via singular spectrum analysis and particle swarm optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning based agents for improving layouts of
automotive crash structures. <em>APIN</em>, <em>54</em>(2), 1751–1769.
(<a href="https://doi.org/10.1007/s10489-024-05276-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topology optimization of crash structures in automotive and aeronautical applications is challenging. Purely mathematical methods struggle due to the complexity of determining the sensitivities of the relevant objective functions and restrictions according to the design variables. For this reason, the Graph- and Heuristic-based Topology optimization (GHT) was developed, which controls the optimization process with rules derived from expert knowledge. In order to extend the collected expert rules, the use of reinforcement learning (RL) agents for deriving a new optimization rule is proposed in this paper. This heuristic is designed in such a way that it can be applied to many different models and load cases. An environment is introduced in which agents interact with a randomized graph to improve cells of the graph by inserting edges. The graph is derived from a structural frame model. Cells represent localized parts of the graph and delineate the areas where agents can insert edges. A newly developed shape preservation metric is presented to evaluate the performance of topology changes made by agents. This metric evaluates how much a cell has deformed by comparing its shape in the deformed and undeformed state. The training process of the agents is described and their performance is evaluated in the training environment. It is shown how the agents and the environment can be integrated as a new heuristic into the GHT. An optimization of the frame model and a vehicle rocker model with the enhanced GHT is carried out to assess its performance in practical optimizations.},
  archive      = {J_APIN},
  author       = {Trilling, Jens and Schumacher, Axel and Zhou, Ming},
  doi          = {10.1007/s10489-024-05276-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1751-1769},
  shortjournal = {Appl. Intell.},
  title        = {Reinforcement learning based agents for improving layouts of automotive crash structures},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning and interpreting asymmetry-labeled DAGs: A case
study on COVID-19 fear. <em>APIN</em>, <em>54</em>(2), 1734–1750. (<a
href="https://doi.org/10.1007/s10489-024-05268-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks are widely used to learn and reason about the dependence structure of discrete variables. However, they can only formally encode symmetric conditional independence, which is often too strict to hold in practice. Asymmetry-labeled DAGs have been recently proposed to extend the class of Bayesian networks by relaxing the symmetric assumption of independence and denoting the dependence between the variables of interest. Here, we introduce novel structural learning algorithms for this class of models, which, whilst efficient, allow for a straightforward interpretation of the underlying dependence structure. A comprehensive computational study highlights the efficiency of the algorithms. A real-world data application using data from the Fear of COVID-19 Scale collected in Italy showcases their use in practice.},
  archive      = {J_APIN},
  author       = {Leonelli, Manuele and Varando, Gherardo},
  doi          = {10.1007/s10489-024-05268-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1734-1750},
  shortjournal = {Appl. Intell.},
  title        = {Learning and interpreting asymmetry-labeled DAGs: A case study on COVID-19 fear},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). MBSSA-bi-AESN: Classification prediction of bi-directional
adaptive echo state network based on modified binary salp swarm
algorithm and feature selection. <em>APIN</em>, <em>54</em>(2),
1706–1733. (<a
href="https://doi.org/10.1007/s10489-024-05280-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, the demand for multivariate time series prediction has surged, drawing increased attention to feature selection and neural networks in machine learning. However, certain feature selection methods neglect the alignment between actual data sample differences and clustering results, while neural networks lack automatic parameter adjustment in response to changing target features. This paper presents the MBSSA-Bi-AESN model, a Bi-directional Adaptive Echo State Network that utilizes the modified salp swarm algorithm (MBSSA) and feature selection to address the limitations of manually set parameters. Initial feature subset selection involves assigning weights based on the consistency of clustering results with differences. Subsequently, the four critical parameters in the Bi-AESN model are optimized using MBSSA. The optimized Bi-AESN model and selected feature subset are then integrated for simultaneous model learning and optimal feature subset selection. Experimental analysis on eight datasets demonstrates the superior prediction accuracy of the MBSSA-Bi-AESN model compared to benchmark models, underscoring its feasibility, validity, and universality.},
  archive      = {J_APIN},
  author       = {Wu, Xunjin and Zhan, Jianming and Li, Tianrui and Ding, Weiping and Pedrycz, Witold},
  doi          = {10.1007/s10489-024-05280-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1706-1733},
  shortjournal = {Appl. Intell.},
  title        = {MBSSA-bi-AESN: Classification prediction of bi-directional adaptive echo state network based on modified binary salp swarm algorithm and feature selection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Masked co-attention model for audio-visual event
localization. <em>APIN</em>, <em>54</em>(2), 1691–1705. (<a
href="https://doi.org/10.1007/s10489-023-05191-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of Audio-Visual Event Localization (AVEL) is to leverage audio and video cues in a combined manner to localize video segments that contain audio-visual events and classify their respective categories. The primary focus is on enhancing the semantic consistency between the video and audio segments while mitigating the influence of unrelated segments. However, data from different modalities are encoded in separated spaces, leading to modality gap. To address this issue, we propose a model based on masked co-attention (MCA) mechanism to better explore the multi-modal correlations. In this approach, both intra and cross modal attention are employed to determine the correlation between visual and audio segments. Furthermore, we introduce a mask strategy of two levels. At the feature level, a random masking method is proposed to alleviate overfitting concerns during training. At the attention level, the mask is applied to the co-attention map to filter out redundant information, thereby obtaining fine-grained multi-modal embeddings. Our proposed framework MCA achieves state-of-the-art results on the publicly available AVE dataset.},
  archive      = {J_APIN},
  author       = {Liu, Hengwei and Gu, Xiaodong},
  doi          = {10.1007/s10489-023-05191-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1691-1705},
  shortjournal = {Appl. Intell.},
  title        = {Masked co-attention model for audio-visual event localization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial perturbation denoising utilizing common
characteristics in deep feature space. <em>APIN</em>, <em>54</em>(2),
1672–1690. (<a
href="https://doi.org/10.1007/s10489-023-05253-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that deep neural networks (DNNs) are vulnerable to adversarial examples (AEs). Denoising based on the input pre-processing is one of the defenses against adversarial attacks. However, it is hard to remove multiple adversarial perturbations, especially in the presence of evolving attacks. To address this challenge, we attempt to extract the commonality of adversarial perturbations. Due to the imperceptibility of adversarial perturbations in the input space, we conduct the extraction in the deep feature space where the perturbations become more apparent. Through the obtained common characteristics, we craft common adversarial examples (CAEs) to train the denoiser. Furthermore, to prevent image distortion while removing as much of the adversarial perturbation as possible, we propose a hybrid loss function that guides the training process at both the pixel level and the deep feature space. Our experiments show that our defense method can eliminate multiple adversarial perturbations, significantly enhancing adversarial robustness compared to previous state-of-the-art methods. Moreover, it can be plug-and-play for various classification models, which demonstrates the generalizability of our defense method.},
  archive      = {J_APIN},
  author       = {Huang, Jianchang and Dai, Yinyao and Lu, Fang and Wang, Bin and Gu, Zhaoquan and Zhou, Boyang and Qian, Yaguan},
  doi          = {10.1007/s10489-023-05253-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1672-1690},
  shortjournal = {Appl. Intell.},
  title        = {Adversarial perturbation denoising utilizing common characteristics in deep feature space},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). WAE-TLDN: Self-supervised fusion for multimodal medical
images via a weighted autoencoder and a tensor low-rank decomposition
network. <em>APIN</em>, <em>54</em>(2), 1656–1671. (<a
href="https://doi.org/10.1007/s10489-023-05097-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal medical image fusion (MMIF) integrates the advantages of multiple source images to assist clinical diagnosis. Existing image fusion methods need help to distinguish the importance between features and often define features to be retained subjectively, which leads to global structure loss and limits the performance of fusion. To overcome these restrictions, we propose a novel self-supervised tensor low-rank decomposition fusion network that can effectively extract global information from high-rank to low-rank conversion processes. Specifically, the compensation of textural features is performed by employing a self-supervised auxiliary task, and the whole network is dynamically fine-tuned according to a hybrid loss. In our model, an enhanced weights (EW) estimation method based on the global luminance contrast is developed, and a structure tensor loss with constraints is introduced to improve the robustness of the fusion results. Moreover, extensive experiments on six types of multimodal medical images show that visual and qualitative results are superior to competitors, validating the effectiveness of our methods.},
  archive      = {J_APIN},
  author       = {Pan, Linna and Nie, Rencan and Zhang, Gucheng and Cao, Jinde and Han, Yao},
  doi          = {10.1007/s10489-023-05097-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1656-1671},
  shortjournal = {Appl. Intell.},
  title        = {WAE-TLDN: Self-supervised fusion for multimodal medical images via a weighted autoencoder and a tensor low-rank decomposition network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improvement of move naturalness for playing good-quality
games with middle-level players. <em>APIN</em>, <em>54</em>(2),
1637–1655. (<a
href="https://doi.org/10.1007/s10489-023-05210-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the game field, computer programs have surpassed top human players in many games. A well-known example is AlphaZero. These strong programs provide human players with opportunities to improve their skills. However, human players may not enjoy such strong opponents. To make middle-level players learn from playing good-quality games with strong programs, we have proposed to combine programs with distinct roles in our previous research. One role is a superhuman program that proposes and accurately evaluates candidate moves. The other role is a naturalness (or human likeness) evaluator. Candidate moves are evaluated by combining the two roles using a function, and the moves with the highest scores are played. This study builds upon our earlier work to further improve the naturalness of moves. First, we propose a search mechanism inspired by the sequential halving algorithm to decide candidate moves and the moves to play. Second, we propose a new score function to address several issues of the previous approach. We conduct experiments to compare the proposed approaches with several existing approaches. The results show that the move naturalness of he proposed approaches is greatly improved and that performance in other aspects is at least as good as existing approaches.},
  archive      = {J_APIN},
  author       = {Hsueh, Chu-Hsuan and Ikeda, Kokolo},
  doi          = {10.1007/s10489-023-05210-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1637-1655},
  shortjournal = {Appl. Intell.},
  title        = {Improvement of move naturalness for playing good-quality games with middle-level players},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the potential of federated learning in mental
health research: A systematic literature review. <em>APIN</em>,
<em>54</em>(2), 1619–1636. (<a
href="https://doi.org/10.1007/s10489-023-05095-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of technology has created new opportunities to improve the accuracy and efficiency of medical diagnoses, treatments, and overall patient care in several medical domains, including mental health. One promising novel approach is federated learning, a machine learning approach that allows multiple devices to train a shared model without exchanging raw data. Instead of centralizing the data in one location, each device or machine holds a portion of the data and collaborates with other devices to update the shared model. In this way, federated learning enables training on more extensive and diverse datasets than would be possible with centralized training while preserving the privacy and security of individual data. In the mental health domain, federated learning has the potential to improve mental disorders’ detection, diagnosis, and treatment. By pooling data from multiple sources while maintaining patient privacy by keeping data secure and ensuring that they are not used for unauthorized purposes. This literature survey reviews recent studies that have exploited federated learning in the psychiatric domain, covering multiple data resources and different machine-learning techniques. Furthermore, we formulate the gap in the current methodologies and propose new research directions.},
  archive      = {J_APIN},
  author       = {Khalil, Samar Samir and Tawfik, Noha S. and Spruit, Marco},
  doi          = {10.1007/s10489-023-05095-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1619-1636},
  shortjournal = {Appl. Intell.},
  title        = {Exploring the potential of federated learning in mental health research: A systematic literature review},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HLC: Hierarchically-aware label correlation for hierarchical
text classification. <em>APIN</em>, <em>54</em>(2), 1602–1618. (<a
href="https://doi.org/10.1007/s10489-023-05257-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Text Classification (HTC) leverages the hierarchical structure of labels to enhance text categorization. Existing methods use a combination of text and structure encoders to generate a composite representation. However, these methods may face challenges when encoding the hierarchy and capturing the label correlations that convey information about the relationships and dependencies among the labels. To address these challenges, we introduce the Hierarchy-Aware Label Correlation (HLC) model in this paper. HLC adopts a customized Graphomer as its structure encoder to learn the hierarchy. Graphormer utilizes self-attention to capture global dependencies and explicit structure encoding mechanisms to model relationships among labels. Additionally, HLC is optimized on Cross-Entropy with Anchor Label (CEAL) loss function, specifically designed to learn the hierarchical label correlations. CEAL introduces an anchor label with a fixed score of zero, distinguishing target labels from non-target ones. This distinctive approach encourages HLC to predict higher scores for true target labels and lower scores for non-target labels compared to the anchor label. We conducted experiments on three benchmark datasets and compared them with existing methods. The results suggest that HLC can be an effective method for HTC.},
  archive      = {J_APIN},
  author       = {Kumar, Ashish and Toshinwal, Durga},
  doi          = {10.1007/s10489-023-05257-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1602-1618},
  shortjournal = {Appl. Intell.},
  title        = {HLC: Hierarchically-aware label correlation for hierarchical text classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Box-spoof attack against single object tracking.
<em>APIN</em>, <em>54</em>(2), 1585–1601. (<a
href="https://doi.org/10.1007/s10489-023-05264-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has revealed that single object tracking (SOT) is susceptible to adversarial examples, with even small perturbations added to video frames leading to tracking failure. However, most of the existing methods are online attack methods. These methods generate video-specific or target-specific perturbation to deceive the trackers through a frame-by-frame online paradigm. This method is inherently inefficient in the production of adversarial examples, rendering it less than ideal for real-time application scenarios. To address this, we propose a novel offline attack method that can achieve high-frequency attack strength by using only one frame of video, called box-spoof attack (BS-Attack). In contrast to prior methods perturb feature maps or confidence maps in a frame-by-frame manner. Our BS-Attack directs its focus towards the proposal selection stage, a relatively late stage within the tracking pipeline. Notably, our method generates perturbations by utilizing the information from the initial frame, which can achieve rapid disturbance generation and high-frequency attack strength. In addition to confidence loss, we incorporate joint intersection-over-union and shrink loss to keep the predicted bounding box away from the ground truth and shrink it. BS-Attack requires only one video to generate a perturbation that can deceive the entire dataset. The UAV123, OTB100, VOT2018, and VOT2019 datasets are used to demonstrate the effectiveness of this method in attacking popular trackers such as SiamRPN, SiamRPN++, and SiamMask. The results show that BS-Attack outperforms state-of-the-art online and offline attack methods.},
  archive      = {J_APIN},
  author       = {Jiang, Yan and Yin, Guisheng and Jing, Weipeng and Mohaisen, Linda and Emam, Mahmoud and Yuan, Ye},
  doi          = {10.1007/s10489-023-05264-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1585-1601},
  shortjournal = {Appl. Intell.},
  title        = {Box-spoof attack against single object tracking},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient EEG signal fading processing framework based on
the cognitive limbic system and deep learning. <em>APIN</em>,
<em>54</em>(2), 1566–1584. (<a
href="https://doi.org/10.1007/s10489-023-05258-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-invasive electroencephalography (EEG) is a technique for monitoring brain activity that is valuable in the diagnosis and study of the brain. However, due to factors such as brain-computer interface (BCI) devices deficiency, dynamic network limitations, and subject issues, EEG signals may fade throughout the entire process from signal generation to acquisition. The fading of EEG signals can cause changes in the data distribution, blur the information and have a negative impact on subsequent research and application. In order to reduce the adverse effects of data fading, this paper proposes a hierarchical bidirectional long-short term memory (LSTM)-Attention network based on cognitive brain limbic system (HBLANet). HBLANet classifies randomly fading signals multiple times by way of a dimensionality-reducing classification algorithm in order to narrow down the feature interval processed by a single neural network. Then the different types of EEG signals acquired from the classification are processed in a more focused manner using a bidirectional LSTM-Attention network. In this paper, the overall performance of the network is greatly improved by decomposing complex signal processing tasks into smaller tasks. The model is evaluated on the EEG-denoisenet dataset and compared with competitive networks such as feature pyramid network (FPN), UNet, MultiResUNet, 1D-ResCNN etc., and the results show that the proposed network achieves better fading processing outcomes. In the overall experiment, the processed EEG signals achieve the relative root mean squared error (RRMSE) value of 0.009, the signal-to-noise ratio (SNR) of 32.78, and the correlation coefficient (CC) of 0.98. Furthermore, the denoising task in the overall experiment achieves even more exciting results, with a SNR of 40.48 and a CC of 0.991 for the processed EEG signal in the case of processing high SNR signals (the range of the SNR is from -2 to 2). Therefore, we believe that the framework has an important reference value for future research on signal quality restoration.},
  archive      = {J_APIN},
  author       = {Wang, Wenlong and Li, Baojiang and Wang, Haiyan and Wang, Xichao},
  doi          = {10.1007/s10489-023-05258-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1566-1584},
  shortjournal = {Appl. Intell.},
  title        = {An efficient EEG signal fading processing framework based on the cognitive limbic system and deep learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regression applied to symbolic interval-spatial data.
<em>APIN</em>, <em>54</em>(2), 1545–1565. (<a
href="https://doi.org/10.1007/s10489-023-05051-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic data analysis is a research area related to machine learning and statistics, which provides tools to describe geo-objects, and enables several types of variables to be dealt with, including interval type variables. Moreover, despite the recent progress in understanding symbolic data, there are no studies in the literature that address this type of data in the context of spatial data analysis. Thus, in this paper, we propose two different approaches of the spatial regression model for symbolic interval-valued data. The first fits a linear regression model on the minimum and maximum values of the interval values and the second fits a linear regression model on the center and range values of the interval. In order to evaluate the performance of these approaches, we have performed Monte Carlo simulations in which we calculated the mean value of the performance metric of the models analyzed. Furthermore, we also analyzed two applications involving real data. In the first, we examined the performance of the models in the Brazilian State of Pernambuco. In the second application, we analyzed the performance of the models for the Brazilian Northeastern region. Both applications were related to socioeconomic variables. We observed that in areas with less spatial variability, the interval spatial regression model performs better when compared with a usual method. When considering areas with a higher spatial variability, both ways presented similar results.},
  archive      = {J_APIN},
  author       = {Freitas, Wanessa W. L. and de Souza, Renata M. C. R. and Amaral, Getúlio J. A. and de Moraes, Ronei M.},
  doi          = {10.1007/s10489-023-05051-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1545-1565},
  shortjournal = {Appl. Intell.},
  title        = {Regression applied to symbolic interval-spatial data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reparameterized dilated architecture: A wider field of view
for pedestrian detection. <em>APIN</em>, <em>54</em>(2), 1525–1544. (<a
href="https://doi.org/10.1007/s10489-023-05255-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancements in the field of computer vision, the performance of state-of-the-art (SOTA) methods in pedestrian detection has reached new heights. Despite this progress, challenges persist in constructing global information dependencies and context awareness due to limited receptive fields in most detectors. These constraints particularly affect edge and small pedestrian target detection. Our proposed solution, reparameterized dilated convolution (RDConv), strategically employs sawtooth dilation rates to broaden the receptive field without increasing computational costs. RDConv maintains the same cost as small convolutional kernels but offers a larger receptive field, enabling comprehensive modeling of the relationship between pedestrians and their environment, enhancing context awareness. To address the need for pedestrian information dependencies crucial for edge and small-target detection, we introduce the group multihead self-attention (G-MSA) mechanism. Overcoming high computational costs and limited interaction issues in traditional self-attention schemes, we adopt deep separation and supplementary boundary feature computation. RDConv and G-MSA are integrated into a multibranch framework to assess information flow interactions. To address the diverse requirements of activation functions for convolution and self-attention mechanisms, we propose the dynamic boundary (DB) activation function. It can adaptively adjust the nonlinearity and gradient of information from each layer in the network, accommodating the integrated structure of the two merging methods. Applied to YOLOv5s and tested on City Persons, Caltech Pedestrian, and PASCAL VOC datasets, our approach achieves significant metrics of 33.61 AP0.5, 61.41 AP0.5, and 92.08 mAP (YOLOv5m). Results across three datasets strongly affirm the effectiveness of our method.},
  archive      = {J_APIN},
  author       = {Gong, Lixiong and Huang, Xiao and Chen, Jialin and Xiao, Miaoling and Chao, Yinkang},
  doi          = {10.1007/s10489-023-05255-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1525-1544},
  shortjournal = {Appl. Intell.},
  title        = {Reparameterized dilated architecture: A wider field of view for pedestrian detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NL2SQL with partial missing metadata based on multi-view
metadata graph compensation and reasoning. <em>APIN</em>,
<em>54</em>(2), 1511–1524. (<a
href="https://doi.org/10.1007/s10489-023-05221-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of metadata-dependent NL2SQL models will be seriously decreased, while facing the incomplete or distorted metadata information. In response to this problem, we proposed a metadata compensation approach, which represents the question together with SQL query, data cell value relevance and incomplete schema data as a global metadata graph, and applies knowledge graph reasoning to complete the metadata graph. This global metadata graph is a multi-graph. An improved transR model was proposed to represent this multi-graph by integrating the contributions from multiple relationships between two nodes. Depending on the compensated metadata graph, new end-to-end and preprocess improving frameworks were respectively constructed for adapting to different metadata-dependent NL2SQL systems. The new models have been evaluated on Spider dataset with artificially simulated partial metadata relation deficiency or metadata distortion. Except ablation comparing, the new models also have been compared with some approaches of existing and have demonstrated improved performance.},
  archive      = {J_APIN},
  author       = {Lin, Jie and Liang, Yulong and Li, Jiyan and Bai, Yi and Wang, Yong},
  doi          = {10.1007/s10489-023-05221-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1511-1524},
  shortjournal = {Appl. Intell.},
  title        = {NL2SQL with partial missing metadata based on multi-view metadata graph compensation and reasoning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing missing facts inference in knowledge graph using
triplet subgraph attention embeddings. <em>APIN</em>, <em>54</em>(2),
1497–1510. (<a
href="https://doi.org/10.1007/s10489-023-05254-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the heterogeneous structure of the knowledge graph (KG), relationships between entities remain missing. However, optimal use of KG requires inference of missing fact triplet (entity-relation-entity). The fact inference predicts a missing relationship using an embedding approach in a supervised learning setup, representing entities and relationships in a low-dimensional vector space. Recent work uses attention-aware embeddings, but when applied directly to entire KG, attention mechanisms can be computationally expensive, especially for large graphs. The attention-based KG embedding model uses negative sampling, which can cause a gradient vanishing problem during learning. This paper proposes a novel triplet subgraph attention embedding (TSAE) model that combines a simplified graph attention mechanism with a neural network to learn embedding without negative sampling requirements. The attention layer processes the triplet-level subgraph entities to learn the central entity features by aggregating the neighbor’s features. A neural network processes attention-aware triplet entity features through hidden layers to compute the likelihood of relationship types between triplet entities. TSAE generates more fine-grained entity embeddings using simplified attention mechanism, reduces computational complexity, and offers interpretable embeddings. Experimental results on the benchmark data sets exhibit TSAE superiority over the baselines. The case study shows the efficacy of the model for the KG completion task.},
  archive      = {J_APIN},
  author       = {Khobragade, Anish and Ghumbre, Shashikant and Pachghare, Vinod},
  doi          = {10.1007/s10489-023-05254-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1497-1510},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing missing facts inference in knowledge graph using triplet subgraph attention embeddings},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot out-of-scope intent classification: Analyzing the
robustness of prompt-based learning. <em>APIN</em>, <em>54</em>(2),
1474–1496. (<a
href="https://doi.org/10.1007/s10489-023-05215-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-scope (OOS) intent classification is an emerging field in conversational AI research. The goal is to detect out-of-scope user intents that do not belong to a predefined intent ontology. However, establishing a reliable OOS detection system is challenging due to limited data availability. This situation necessitates solutions rooted in few-shot learning techniques. For such few-shot text classification tasks, prompt-based learning has been shown more effective than conventionally finetuned large language models with a classification layer on top. Thus, we advocate for exploring prompt-based approaches for OOS intent detection. Additionally, we propose a new evaluation metric, the Area Under the In-scope and Out-of-Scope Characteristic curve (AU-IOC). This metric addresses the shortcomings of current evaluation standards for OOS intent detection. AU-IOC provides a comprehensive assessment of a model’s dual performance capacities: in-scope classification accuracy and OOS recall. Under this new evaluation method, we compare our prompt-based OOS detector against 3 strong baseline models by exploiting the metadata of intent annotations, i.e., intent description. Our study found that our prompt-based model achieved the highest AU-IOC score across different data regimes. Further experiments showed that our detector is insensitive to a variety of intent descriptions. An intriguing finding shows that for extremely low data settings (1- or 5-shot), employing a naturally phrased prompt template boosts the detector’s performance compared to rather artificially structured template patterns.},
  archive      = {J_APIN},
  author       = {Jiang, Yiwei and De Raedt, Maarten and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
  doi          = {10.1007/s10489-023-05215-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1474-1496},
  shortjournal = {Appl. Intell.},
  title        = {Few-shot out-of-scope intent classification: Analyzing the robustness of prompt-based learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection using three-stage heuristic measures based
on mutual fuzzy granularities. <em>APIN</em>, <em>54</em>(2), 1445–1473.
(<a href="https://doi.org/10.1007/s10489-023-05142-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mutual information is fundamental for feature selection, and relevant conditional and joint mutual fuzzy granularities (MFGs) characterize feature correlation and redundancy in fuzzy decision systems, respectively. Recently, conditional MFGs have been utilized to generate three-stage heuristic measures, and thus, two feature selection algorithms (called GFMRI-FS and NGFMRI-FS) have emerged. However, these methods emphasize correlation connections but neglect redundancy deletion, thus the approach can be improved. In this paper, a joint MFG with redundant feature information is supplemented to reasonably modify existing heuristic measures, and new three-stage heuristic measures are constructed to obtain two improved selection algorithms (called C-GFMRI-FS and C-NGFMRI-FS). First, the measurement mechanisms of the MFGs are analyzed, and three-stage correctional heuristic measures are established to acquire the dependency semantics, bound combinations, size relationships, theoretical extensions, applied optimization, parametric monotonicity, and systematic algorithms. Then, the three-stage current and correctional heuristic measures obtain granulation monotonicity/certainty and nonmonotonicity/uncertainty, respectively, as well as uncertainty fluctuations on feature-dynamic subset chains. Furthermore, feature selection is investigated by correctional heuristic measures, and two selection algorithms (i.e., C-GFMRI-FS and C-NGFMRI-FS) are designed. Finally, table examples and data experiments validate the uncertainty heuristic measures and feature selection algorithms; accordingly, C-GFMRI-FS and C-NGFMRI-FS outperform GFMRI-FS and NGFMRI-FS and achieve better classification results. This study fuses conditional and joint MFGs to make systematic improvements in heuristic measurements and feature selection, thus facilitating data learning.},
  archive      = {J_APIN},
  author       = {Wang, Qian and Zhang, Xianyong},
  doi          = {10.1007/s10489-023-05142-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1445-1473},
  shortjournal = {Appl. Intell.},
  title        = {Feature selection using three-stage heuristic measures based on mutual fuzzy granularities},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of fuzzy hyperbox classifiers based on a two-stage
genetic algorithm and simultaneous strategy. <em>APIN</em>,
<em>54</em>(2), 1426–1444. (<a
href="https://doi.org/10.1007/s10489-023-04986-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy min-max (FMM) neural network can be regarded as a typical fuzzy hyperbox classifier that is designed in a sequential way, which leads to an input order drawback and overlap elimination limitation. In this paper, we propose a two-stage-based genetic algorithm (TGA) to construct blue a fuzzy hyperbox classifier (FHC) in a simultaneous way. The simultaneous method is realized by estimating all parameters of hyperboxes at one time rather than by separately determining the parameters of hyperboxes in a sequential way. In this paper, we propose a two-stage-based genetic algorithm to construct the fuzzy hyperbox classifier. The overall TGA consists of two stages, namely, the construction stage and optimization stage. The construction stage is aimed at designing the FHC structure, while the goal of the optimization stage is to further optimize the FHC structure. Using a two-stage genetic algorithm to directly construct a fuzzy hyperbox classifier can overcome the problem of input order and hyperbox overlap. The experimental results show that the proposed FHC yields higher classification accuracy in comparison with the stage-of-the-art FMMs reported in the literature.},
  archive      = {J_APIN},
  author       = {Huang, Wei and Duan, Mengyu and Wan, Shaohua},
  doi          = {10.1007/s10489-023-04986-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1426-1444},
  shortjournal = {Appl. Intell.},
  title        = {Design of fuzzy hyperbox classifiers based on a two-stage genetic algorithm and simultaneous strategy},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning facial expression-aware global-to-local
representation for robust action unit detection. <em>APIN</em>,
<em>54</em>(2), 1405–1425. (<a
href="https://doi.org/10.1007/s10489-023-05154-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of detecting facial action units (AU) often utilizes discrete expression categories, such as Angry, Disgust, and Happy, as auxiliary information to enhance performance. However, these categories are unable to capture the subtle transformations of AUs. Additionally, existing works suffer from overfitting due to the limited availability of AU datasets. This paper proposes a novel fine-grained global expression representation encoder to capture continuous and subtle global facial expressions and improve AU detection. The facial expression representation effectively reduces overfitting by isolating facial expressions from other factors such as identity, background, head pose, and illumination. To further address overfitting, a local AU features module transforms the global expression representation into local facial features for each AU. Finally, the local AU features are fed into an AU classifier to determine the occurrence of each AU. Our proposed method outperforms previous works and achieves state-of-the-art performances on both in-the-lab and in-the-wild datasets. This is in contrast to most existing works that only focus on in-the-lab datasets. Our method specifically addresses the issue of overfitting from limited data, which contributes to its superior performance.},
  archive      = {J_APIN},
  author       = {An, Rudong and Jin, Aobo and Chen, Wei and Zhang, Wei and Zeng, Hao and Deng, Zhigang and Ding, Yu},
  doi          = {10.1007/s10489-023-05154-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1405-1425},
  shortjournal = {Appl. Intell.},
  title        = {Learning facial expression-aware global-to-local representation for robust action unit detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time-series forecasting of consolidation settlement using
LSTM network. <em>APIN</em>, <em>54</em>(2), 1386–1404. (<a
href="https://doi.org/10.1007/s10489-023-05219-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consolidation settlement refers to the deformation of soil due to external forces resulting in a reduction in the soil volume, posing a significant challenge for construction on soft ground due to the high compressibility of the soil. Methods, such as preloading and prefabricated vertical drains, have been applied to enhance the strength of the ground and accelerate the consolidation process. However, measurement-based methods, which are commonly used in practice, tend to produce inaccurate results when the measurement records are limited, and the prediction results may have a large variance depending on an engineering judgment. This study aimed to overcome these limitations by developing a long short term memory (LSTM) based model for predicting consolidation settlement with improved accuracy. The model was evaluated through 120 cases with different amounts of training data (10%–70%) and was compared with practical methods such as the hyperbolic and Asaoka methods. The LSTM model outperformed the practical methods, with an average RMSE and MAPE of less than 0.1m and 2%, respectively. The model was also capable of predicting the final settlement with an average MAPE of less than 3% regardless of the amount of training. Statistical analysis have also indicated that the LSTM model had the highest probability of accurately predicting the settlement. The results of this study indicate that deep learning algorithms can be successfully used to predict consolidation settlement and provide highly accurate predictions for construction projects on soft ground. This study has the potential to assist the design and construction of civil engineering projects.},
  archive      = {J_APIN},
  author       = {Hong, Seongho and Ko, Seok-Jun and Woo, Sang Inn and Kwak, Tae-Young and Kim, Sung-Ryul},
  doi          = {10.1007/s10489-023-05219-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1386-1404},
  shortjournal = {Appl. Intell.},
  title        = {Time-series forecasting of consolidation settlement using LSTM network},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intuitionistic fuzzy multi-view support vector machines with
universum data. <em>APIN</em>, <em>54</em>(2), 1365–1385. (<a
href="https://doi.org/10.1007/s10489-023-05260-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an energizing direction in machine learning, multi-view learning (MVL) is aimed at exploiting the information among different views for improving the generalization performance. Thus far, various support vector machines for multi-view learning (MvSVMs) have been developed. Despite showing effectiveness, existing methods have failed tonalysis of parameter sensitiv consider the fact that real-world data often contain noise and outliers. Besides, it has been demonstrated that the use of the Universum data can improve the performance of classifiers. Therefore, we propose two novel intuitionistic fuzzy multi-view support vector machines with Universum data. The proposed methods can not only reduce the effect of noise and outliers on classifiers but also improve the model performance. Specifically, intuitionistic fuzzy membership scores are integrated to mitigate the negative impact of the noise and outliers. Then, Universum data is incorporated to exploit the priori information about the data distribution for assisting in the generation of decision hyperplanes. Two proposed convex optimization problems are solved by introducing the dual forms of the models separately to obtain the classifiers. We conduct classification experiments on relevant multi-view datasets, and the proposed convex models are shown to outperform several state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Lou, Chunling and Xie, Xijiong},
  doi          = {10.1007/s10489-023-05260-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1365-1385},
  shortjournal = {Appl. Intell.},
  title        = {Intuitionistic fuzzy multi-view support vector machines with universum data},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Standardized validation of vehicle routing algorithms.
<em>APIN</em>, <em>54</em>(2), 1335–1364. (<a
href="https://doi.org/10.1007/s10489-023-05212-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing routing schedules is a pivotal aspect of smart delivery systems. Therefore, the field has been blooming for decades, and numerous algorithms for this task have been proposed for various formulations of rich vehicle routing problems. There is, however, an important gap in the state of the art that concerns the lack of an established and widely-adopted approach toward thorough verification and validation of such algorithms in practical scenarios. We tackle this issue and propose a comprehensive validation approach that can shed more light on functional and non-functional abilities of the solvers. Additionally, we propose novel similarity metrics to measure the distance between the routing schedules that can be used in verifying the convergence abilities of randomized techniques. To reflect practical aspects of intelligent transportation systems, we introduce an algorithm for elaborating solvable benchmark instances for any vehicle routing formulation, alongside the set of quality metrics that help quantify the real-life characteristics of the delivery systems, such as their profitability. The experiments prove the flexibility of our approach through utilizing it to the NP-hard pickup and delivery problem with time windows, and present the qualitative, quantitative, and statistical analysis scenarios which help understand the capabilities of the investigated techniques. We believe that our efforts will be a step toward the more critical and consistent evaluation of emerging vehicle routing (and other) solvers, and will allow the community to easier confront them, thus ultimately focus on the most promising research avenues that are determined in the quantifiable and traceable manner.},
  archive      = {J_APIN},
  author       = {Jastrzab, Tomasz and Myller, Michal and Tulczyjew, Lukasz and Blocho, Miroslaw and Kawulok, Michal and Czornik, Adam and Nalepa, Jakub},
  doi          = {10.1007/s10489-023-05212-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1335-1364},
  shortjournal = {Appl. Intell.},
  title        = {Standardized validation of vehicle routing algorithms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). MHRE: Multivariate link prediction method for medical
hyper-relational facts. <em>APIN</em>, <em>54</em>(2), 1311–1334. (<a
href="https://doi.org/10.1007/s10489-023-05248-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As hyper-relational facts continue to proliferate within knowledge graphs, link prediction on binary relations has become inadequate, while link prediction on hyper-relations has emerged as a research hotspot. Existing methods typically employ n-ary tuples, primary triple with auxiliary descriptions, or hypergraphs to represent hyper-relational facts and conduct link prediction. However, medical hyper-relational facts are more intricate and frequently lack multiple components, which presents challenges for current methods in conveying their structure, semantics, and predicting multiple missing elements simultaneously. To address these issues, in this paper, we introduce MHRE, the pioneering link prediction method specifically designed for medical hyper-relational facts. Initially, we represent medical hyper-relational facts as a heterogeneous multi-relational directed graph with hyper-relations at its core to depict both its structure and implicit semantics. Next, we develop a role-aware graph attention mechanism network to acquire distributed vector representations of entities and relations within the graph. Importantly, it fine-tunes the semantic weights of different components within hyper-relational facts by incorporating neighboring nodes and role information through learning. Lastly, we devise a prediction module based on self-attention mechanisms, enabling the simultaneous prediction of multiple missing elements within a medical hyper-relational fact. We conduct experiments using publicly available datasets, such as JF17K, WikiPeople, and their adapted versions, alongside a proprietary medical dataset. We compare MHRE with state-of-the-art baselines and further conduct ablation studies and parameter analysis. The experimental results confirm the efficacy and superiority of MHRE. In a range of benchmark tests involving hyper-relational facts, MHRE consistently outperforms current state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Wang, Weiguang and Zhang, Xuanyi and Zhang, Juan and Cai, Wei and Zhao, Haiyan and Zhang, Xia},
  doi          = {10.1007/s10489-023-05248-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1311-1334},
  shortjournal = {Appl. Intell.},
  title        = {MHRE: Multivariate link prediction method for medical hyper-relational facts},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An augmented AI-based hybrid fraud detection framework for
invoicing platforms. <em>APIN</em>, <em>54</em>(2), 1297–1310. (<a
href="https://doi.org/10.1007/s10489-023-05223-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this era of e-commerce, many companies are moving towards subscription-based invoicing platforms to maintain their electronic invoices. Unfortunately, fraudsters are using these platforms for different types of malicious activities. Identifying fraudsters is often challenging for many companies due to the limitation of time and other resources. A fully automated fraud detection model can be useful, but it creates a risk of false-positive identification. This paper proposed a hybrid fraud detection framework when only a small set of labelled (fraud/non-fraud) data is available, and human input is required in the final decision-making step. This framework used a combination of unsupervised and supervised machine learning, red-flag prioritization, and an augmented AI approach containing a human-in-the-loop process. It also proposed a weighted center based on the feature importance scores for the fraud risk cluster and used it in the red-flag prioritization process. Finally, the approach is illustrated using a case study to identify fraudulent users in an invoicing platform. Our hybrid framework showed promising results in identifying fraudulent users and improving human performance when human input is required to make the final decision.},
  archive      = {J_APIN},
  author       = {Wahid, Dewan F. and Hassini, Elkafi},
  doi          = {10.1007/s10489-023-05223-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1297-1310},
  shortjournal = {Appl. Intell.},
  title        = {An augmented AI-based hybrid fraud detection framework for invoicing platforms},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RSMformer: An efficient multiscale transformer-based
framework for long sequence time-series forecasting. <em>APIN</em>,
<em>54</em>(2), 1275–1296. (<a
href="https://doi.org/10.1007/s10489-023-05250-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long sequence time-series forecasting (LSTF) is a significant and challenging task. Many real-world applications require long-term forecasting of time series. In recent years, Transformer-based models have emerged as a promising solution for addressing LSTF tasks. Nevertheless, the model’s performance is constrained by several issues, including the single time scale, the quadratic calculation complexity of the self-attention mechanism, and the high memory occupation. Based on the limitations mentioned above, we propose a novel approach in this paper, namely the multiscale residual sparse attention model RSMformer, built upon the Transformer architecture. Firstly, a residual sparse attention (RSA) mechanism is devised to select dominant queries for computation, utilizing the attention sparsity criterion. This approach effectively reduces the computational complexity to $$\varvec{\mathcal {O}}$$ (LlogL). Secondly, we employ a multiscale forecasting strategy to iteratively refine the accuracy of prediction results at multiple scales by utilizing up-and-down sampling techniques and cross-scale centralization schemes, which effectively capture the temporal dependencies at different time scales. Extensive experiments on six publicly available datasets show that RSMformer performs significantly better than the compared state-of-the-art benchmarks and excels in the LSTF tasks.},
  archive      = {J_APIN},
  author       = {Tong, Guoxiang and Ge, Zhaoyuan and Peng, Dunlu},
  doi          = {10.1007/s10489-023-05250-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1275-1296},
  shortjournal = {Appl. Intell.},
  title        = {RSMformer: An efficient multiscale transformer-based framework for long sequence time-series forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust transfer learning for high-dimensional quantile
regression model with linear constraints. <em>APIN</em>, <em>54</em>(2),
1263–1274. (<a
href="https://doi.org/10.1007/s10489-023-05232-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning has emerged as a crucial technique for leveraging source domain information to enhance the performance of target tasks. However, existing transfer learning methods often overlook the heterogeneity and heavy-tailed nature of high-dimensional data, which can potentially undermine the final performance. This study aims to address the problem of high-dimensional quantile regression within the context of transfer learning and investigates the impact of incorporating linear constraints. In the case of known transferable sources, a two-step transfer learning algorithm is proposed in this study. To mitigate the negative effects of including non-informative sources, a transferable source detection algorithm based on cross-validation is introduced. The effectiveness of the proposed methods and the significant performance improvement achieved by incorporating linear constraints are demonstrated through numerical simulations and empirical analysis using used car transaction data.},
  archive      = {J_APIN},
  author       = {Cao, Longjie and Song, Yunquan},
  doi          = {10.1007/s10489-023-05232-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1263-1274},
  shortjournal = {Appl. Intell.},
  title        = {Robust transfer learning for high-dimensional quantile regression model with linear constraints},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shallow quantum neural networks (SQNNs) with application to
crack identification. <em>APIN</em>, <em>54</em>(2), 1247–1262. (<a
href="https://doi.org/10.1007/s10489-023-05192-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum neural networks have been explored in a number of tasks including image recognition. Most of the approaches involve using quantum gates in the neurons. Hybrid neural networks combining classical and quantum layers are recently being studied. The goal of the hybridization is to exploit the generalization benefits of quantum networks while reducing the requisite number of qubits. In this context, a Shallow Quantum Neural Network (SQNN) is proposed in this paper. Such architectures have not been studied previously on image processing tasks. The SQNN is expected to be successful in image classification tasks with limited training set size. Two types of SQNNs have been developed, these are ResNet-SQNNs and VGG16-SQNNs. The SQNN models are applied to the problem of detection of surface cracks on images. Introduction of hybrid classical-quantum layers in a typical pretrained neural network model detects cracks with a greater validation accuracy as compared to classical Res-NNs and VGG16-NNs. Moreover, an entangled feature mapping has been incorporated with the parameterized quantum circuit in SQNNs. This outperforms classical approaches providing improved accuracy and training times. To demonstrate the computational advantage of the quantum neural networks over the classical neural networks, a comparative analysis has been conducted based on efficiencies and improvement in the accuracy achieved for the surface crack detection task.},
  archive      = {J_APIN},
  author       = {Das, Meghashrita and Naskar, Arundhuti and Mitra, Pabitra and Basu, Biswajit},
  doi          = {10.1007/s10489-023-05192-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1247-1262},
  shortjournal = {Appl. Intell.},
  title        = {Shallow quantum neural networks (SQNNs) with application to crack identification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Determining the best feature combination through text and
probabilistic feature analysis for GPT-2-based mobile app review
detection. <em>APIN</em>, <em>54</em>(2), 1219–1246. (<a
href="https://doi.org/10.1007/s10489-023-05201-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile apps, used by many people worldwide, have become an essential part of life. Before using a mobile app, users judge the reliability of apps according to their reviews. Therefore, app reviews are essential components of management for companies. Unfortunately, some fake reviewers write negative reviews for competing apps. Moreover, artificial intelligence (AI)-based macro bot programs that generate app reviews have emerged and can create large numbers of reviews with malicious purposes in a short time. One notable AI technology that can generate such reviews is Generative Pre-trained Transformer-2 (GPT-2). The reviews generated by GPT-2 use human-like grammar; therefore, it is difficult to detect them with only text mining techniques, which use tools like part-of-speech (POS) tagging and sentiment scores. Thus, probability-based sampling techniques in GPT-2 must be used. In this study, we identified features to detect reviews generated by GPT-2 and determined the optimal feature combination for improving detection performance. To achieve this, based on the analysis results, we built a training dataset to find the best feature combination for detecting the generated reviews. Various machine learning models were then trained and evaluated using this dataset. As a result, the model that used both text mining and probability-based sampling techniques detected generated reviews more effectively than the model that used only text mining techniques. This model achieved a top classification accuracy of 90% and a macro F1 of 0.90. We expect the results of this study to help app developers maintain a more stable mobile app ecosystem.},
  archive      = {J_APIN},
  author       = {Lee, Seung-Cheol and Lee, Dong-Gun and Seo, Yeong-Seok},
  doi          = {10.1007/s10489-023-05201-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1219-1246},
  shortjournal = {Appl. Intell.},
  title        = {Determining the best feature combination through text and probabilistic feature analysis for GPT-2-based mobile app review detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformer-based few-shot object detection in traffic
scenarios. <em>APIN</em>, <em>54</em>(1), 947–958. (<a
href="https://doi.org/10.1007/s10489-023-05245-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In few-shot object detection (FSOD), many approaches retrain the detector in the inference stage, which is unrealistic in real applications. Moreover, high-quality region proposals are difficult to generate for novel classes using a limited support set. Inspired by the recent development of visual prompt learning (VPL) and detection with transformers (DETR), an approach is proposed in which 1) a class-agnostic training is designed to extend the detector to novel classes and 2) visual prompts are combined with pseudoclass embeddings to improve the query generation. The proposed approach is evaluated on multiple traffic datasets. The results show that it outperforms other mainstream approaches by a margin of 1.1% in mean average precision (mAP). An effective FSOD approach based on VPL and DETR is proposed, that has no retraining in the inference stage, and it accurately localizes novel objects by using an improved query generation mechanism.},
  archive      = {J_APIN},
  author       = {Sun, Erjun and Zhou, Di and Tian, Yan and Xu, Zhaocheng and Wang, Xun},
  doi          = {10.1007/s10489-023-05245-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {947-958},
  shortjournal = {Appl. Intell.},
  title        = {Transformer-based few-shot object detection in traffic scenarios},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CSViz: Class separability visualization for high-dimensional
datasets. <em>APIN</em>, <em>54</em>(1), 924–946. (<a
href="https://doi.org/10.1007/s10489-023-05149-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data visualization is an essential task during the lifecycle of any Data Science (DS) project, particularly during the Exploratory Data Analysis (EDA) for a correct data preparation and understanding. In classification problems, data visualization is useful for revealing the existence of class separability patterns within the dataset. This information is very valuable and can be later used during the process of building a Machine Learning (ML) model. High-Dimensional Data (HDD) arise as one of the biggest challenges in DS. HDD require special treatment since traditional visualization techniques, such as the scatterplot matrix (SPLOM), have limitations when dealing with them due to space restrictions. Other visualization methods involve dimensionality reduction techniques, which can lead to losing important information and reducing the interpretability of the data. In this paper, the Class Separability Visualization (CSViz) method is introduced as a new Visual Analytics (VA) approach to address the challenge of visualizing labeled HDD through subspaces. The proposed method enables an overview of the class separability offering a series of 2-Dimensional subspaces visualizations containing exclusive subsets of points of the original variables that encompass the most valuable and significant separable patterns. The proposed method is tested over 50 datasets with different characteristics providing promising results. In all cases, more than 90% of the data observations are shown with three plots or less. Hence, the presented CSViz significantly eases the EDA by reducing the number of plots to be inspected in a SPLOM and thus, the amount of time invested in it. CSViz graphical abstract},
  archive      = {J_APIN},
  author       = {Cuesta, Marina and Lancho, Carmen and Fernández-Isabel, Alberto and Cano, Emilio L. and Martín De Diego, Isaac},
  doi          = {10.1007/s10489-023-05149-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {924-946},
  shortjournal = {Appl. Intell.},
  title        = {CSViz: Class separability visualization for high-dimensional datasets},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overview of indoor scene recognition and representation
methods based on multimodal knowledge graphs. <em>APIN</em>,
<em>54</em>(1), 899–923. (<a
href="https://doi.org/10.1007/s10489-023-05235-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a comprehensive overview of multi-modal knowledge graph technology and a three-layer framework for scene recognition. Integrating diverse 3D expertise into a deep neural network enhances scene cognition and knowledge representation. Real-time 3D scene graph construction via feature matching is explored, demonstrating the feasibility of effective scene knowledge representation. Leveraging advanced multimodal knowledge graph and scene recognition, the paper presents a promising avenue for AI-driven scene cognition and construction. It contributes to understanding multi-modal knowledge graph technology’s potential in addressing scene recognition challenges and implications for future advancements. This interdisciplinary work establishes a foundation for intelligent scene analysis and interpretation.},
  archive      = {J_APIN},
  author       = {Li, Jianxin and Si, Guannan and Tian, Pengxin and An, Zhaoliang and Zhou, Fengyu},
  doi          = {10.1007/s10489-023-05235-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {899-923},
  shortjournal = {Appl. Intell.},
  title        = {Overview of indoor scene recognition and representation methods based on multimodal knowledge graphs},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). On mask-based image set desensitization with recognition
support. <em>APIN</em>, <em>54</em>(1), 886–898. (<a
href="https://doi.org/10.1007/s10489-023-05239-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Deep Neural Networks (DNN) have emerged as a practical method for image recognition. The raw data, which contain sensitive information, are generally exploited within the training process. However, when the training process is outsourced to a third-party organization, the raw data should be desensitized before being transferred to protect sensitive information. Although masks are widely applied to hide important sensitive information, preventing inpainting masked images is critical, which may restore the sensitive information. The corresponding models should be adjusted for the masked images to reduce the degradation of the performance for recognition or classification tasks due to the desensitization of images. In this paper, we propose a mask-based image desensitization approach while supporting recognition. This approach consists of a mask generation algorithm and a model adjustment method. We propose exploiting an interpretation algorithm to maintain critical information for the recognition task in the mask generation algorithm. In addition, we propose a feature selection masknet as the model adjustment method to improve the performance based on the masked images. Extensive experimentation results based on multiple image datasets reveal significant advantages (up to 9.34% in terms of accuracy) of our approach for image desensitization while supporting recognition.},
  archive      = {J_APIN},
  author       = {Li, Qilong and Liu, Ji and Sun, Yifan and Zhang, Chongsheng and Dou, Dejing},
  doi          = {10.1007/s10489-023-05239-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {886-898},
  shortjournal = {Appl. Intell.},
  title        = {On mask-based image set desensitization with recognition support},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prostate cancer grade using self-supervised learning and
novel feature aggregator based on weakly-labeled gbit-pixel pathology
images. <em>APIN</em>, <em>54</em>(1), 871–885. (<a
href="https://doi.org/10.1007/s10489-023-05224-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prostate cancer (PCa) is the second most common cancer in men worldwide. The Gleason score, determined by pathologists through microscopic examination of pathological tissue, is the most powerful prognostic indicator for patients diagnosed with prostate cancer. However, there is inter- and intra-observer variability among pathologists, and the scoring process imposes a significant workload on them. This study presents a deep learning model that utilizes gigapixel pathology images and slide-level labels for prostate cancer detection and Gleason grading. WSIs are first cropped into small patches, and a deep learning model trained using self-supervised learning is used to extract features from the patches. An attention-LSTM is then used to aggregate features and perform the final classification. Our pipeline for Gleason grading, which utilizes a 6-level classification system, achieves a quadratic weighted kappa of 0.930 on the internal test dataset (n = 531). Furthermore, it demonstrates good generalization on the external test dataset (n = 155) with a quadratic weighted kappa of 0.8668. The proposed model integrating a self-supervised feature extraction model and an attention LSTM aggregator, is one of the most advanced scoring methods for grading prostate cancer using only slide-level labels. It represents a significant advancement in automating the extraction of prostate cancer grading information in digital diagnostic pathology and will help to address the critical shortage of pathologists.},
  archive      = {J_APIN},
  author       = {Liang, Ma and Hao, Chen and Ming, Gong},
  doi          = {10.1007/s10489-023-05224-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {871-885},
  shortjournal = {Appl. Intell.},
  title        = {Prostate cancer grade using self-supervised learning and novel feature aggregator based on weakly-labeled gbit-pixel pathology images},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-scale condition aggregation and iterative refinement
for copy-move forgery detection. <em>APIN</em>, <em>54</em>(1), 851–870.
(<a href="https://doi.org/10.1007/s10489-023-05174-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copy-move forgery detection poses a significant challenge because the brightness and contrast of forged and real regions are highly consistent, and the forensic clues are weakened by various affine transformations and post-processing operations. Existing deep learning models ignore the hierarchical dependencies of the features and pay less attention to information purification. To solve these problems, we propose a novel two-stage model to detect copy-move forgery, dubbed by CCAIR-Net. First, in the coarse localization stage, we propose a cross-scale condition aggregation module to integrate multi-level features from global to local. This aggregation structure can eliminate semantic disparities and capture multi-scale hierarchical dependencies of features. In particular, the condition aggregation block enables feature purification and filtering of interfering information. Second, in the refinement stage, the designed weighted fusion mechanism can guide the model to remove falsely detected regions and supplement the miss-detected regions by adaptively weighted fusion of coarse-grained and fine-grained features. Furthermore, the stage-wise training strategy takes advantage of different losses to train the network to detect tampered regions at various scales. Extensive experiments demonstrate that the proposed CCAIR-Net performs better than state-of-the-art methods. It can detect and segment forged and real areas more accurately, even for affine transformations and post-processing attack images.},
  archive      = {J_APIN},
  author       = {Xu, Yanzhi and Zheng, Jiangbin and Fang, Aiqing and Irfan, Muhammad},
  doi          = {10.1007/s10489-023-05174-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {851-870},
  shortjournal = {Appl. Intell.},
  title        = {Cross-scale condition aggregation and iterative refinement for copy-move forgery detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling different effects of user and product attributes on
review sentiment classification. <em>APIN</em>, <em>54</em>(1), 835–850.
(<a href="https://doi.org/10.1007/s10489-023-05236-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental task, review sentiment classification aims to predict a user’s overall sentiment in a review about a product. Recent studies have proven critical effects of user and product attributes on this task. However, they usually adopt the same way to incorporate these two attributes, which does not fully consider their different effects and thus is not capable of leveraging them effectively. To address this issue, we propose a simple and effective review sentiment classification model based on hierarchical attention network, where different effects of user and product attributes are respectively captured via fusion modules and attention mechanisms. We further propose a training framework based on mutual distillation to fully capture the individual effects of user and product attributes. Specifically, two auxiliary models with only the user or product attribute are introduced to benefit our model. During the joint training process, our model and the auxiliary models boost each other via mutual knowledge distillation in an iterative manner. On the benchmark IMDB and Yelp datasets, our model significantly outperforms competitive baselines with a 1.6% improvement in average accuracy. When BERT embeddings are used as inputs, our model still performs much better than recent BERT-enhanced baselines.},
  archive      = {J_APIN},
  author       = {Wu, Changxing and Cao, Liuwen and Chen, Jiayu and Wang, Yuanyun and Su, Jinsong},
  doi          = {10.1007/s10489-023-05236-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {835-850},
  shortjournal = {Appl. Intell.},
  title        = {Modeling different effects of user and product attributes on review sentiment classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). User re-identification via human mobility trajectories with
siamese transformer networks. <em>APIN</em>, <em>54</em>(1), 815–834.
(<a href="https://doi.org/10.1007/s10489-023-05234-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People are keen to share their geospatial locations to access social activities or services via mobile internet, which provides a new perspective for us to understand human mobility. However, the collection of individual mobility data arouses great concern about privacy among the public. Specifically, anonymized mobility records can be used to imply the routine behavior of individuals such that people can be re-identified even if they share footprints with different accounts or platforms. In this context, this study explored the probability of re-identifying anonymized users with advanced deep learning techniques, only leveraging their trajectories collected during a long time period. Such a user re-identification task realizes the identification of anonymous users by mining the characteristics of anonymous trajectories. Prevailing methods adopt deep sequential learning models, such as recurrent neural networks (RNNs), to capture the inherent similarity between any two trajectories, replacing classic statistical models. Despite that, RNN-like models usually fail in learning effective knowledge from longer sequences, such as one’s visited locations in one week. To this end, we propose a novel model based on the Siamese Transformer network. The entire model comprises a discriminant module and retrieval module. The discriminant module uses the Transformer model to detect the characteristics of the trajectory and employs an improved attention mechanism to achieve similarity measurement between trajectories. The retrieval module helps the model deal with the matching between the anonymous trajectory and user by constructing a mapping relationship between users and locations. Extensive experiments on four real-world location-based social network datasets demonstrated that our method outperforms existing methods.},
  archive      = {J_APIN},
  author       = {Wang, Bin and Zhang, Mingming and Ding, Peng and Yang, Tao and Jin, Yaohui and Xu, Yanyan},
  doi          = {10.1007/s10489-023-05234-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {815-834},
  shortjournal = {Appl. Intell.},
  title        = {User re-identification via human mobility trajectories with siamese transformer networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label learning of missing labels using label-specific
features: An embedded packaging method. <em>APIN</em>, <em>54</em>(1),
791–814. (<a href="https://doi.org/10.1007/s10489-023-05203-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning label-specific features is an effective strategy for multi-label classification. Existing multi-label classification methods for learning label-specific features face two challenges. One is the incompleteness of the training label data, and the other is that existing techniques generate label-specific features and build multi-label classifiers independently, ignoring the decoupled nature of the two phases. In this paper, we propose an embedding packing method that combines the generation of label-specific features and subsequent model induction to deal with the multi-label classification problem of missing labels. The proposed method first recovers the missing labels using higher-order label correlation while completing the generation of label-specific features in the embedded feature space and finally completes the construction of a multi-label classifier by combining empirical loss minimization and learned label correlation. Moreover, this paper utilizes the kernel expansion technique to ensure that the model can handle linearly inseparable data. We use alternating optimization techniques to solve the potential optimization problem effectively. Comparative analysis experiments are conducted on ten benchmark multi-label datasets to verify that the proposed method is as competitive as other state-of-the-art methods in dealing with missing-label data.},
  archive      = {J_APIN},
  author       = {Zhao, Dawei and Tan, Yi and Sun, Dong and Gao, Qingwei and Lu, Yixiang and Zhu, De},
  doi          = {10.1007/s10489-023-05203-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {791-814},
  shortjournal = {Appl. Intell.},
  title        = {Multi-label learning of missing labels using label-specific features: An embedded packaging method},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New approaches for mining high utility itemsets with
multiple utility thresholds. <em>APIN</em>, <em>54</em>(1), 767–790. (<a
href="https://doi.org/10.1007/s10489-023-05145-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, two research directions have been noticed in data mining: frequent itemset mining (FIM) and high utility itemset mining (HUIM). The FIM process will output itemsets whose number of occurrences together exceeds or equals the required threshold, but this process ignores the beneficial attribute of each item. HUIM algorithms are proposed to overcome the disadvantage of FIM, but these algorithms only use a single threshold, which is unsuitable in the real world when applications often require different utility thresholds. HUIM algorithms with multi-threshold utilities are proposed, but these have high mining time and memory consumption. This paper thus presents an efficient method for Mining High Utility Itemsets with Multiple Utility Thresholds (MHUI-MUT). The article applies upper bounds and the strategy of pruning, thus reducing database scanning, and proposes a cut-off threshold to minimize the mining time.We also present a method to parallelize the algorithm to make the most of the performance of multi-core computers. The experimental results show the superior speed of the MHUI-MUT algorithm compared to the previous one, and the parallel version also outperforms the proposed sequential algorithm.},
  archive      = {J_APIN},
  author       = {Huynh, Bao and Tung, N. T. and Nguyen, Trinh D. D. and Trinh, Cuong and Snasel, Vaclav and Nguyen, Loan},
  doi          = {10.1007/s10489-023-05145-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {767-790},
  shortjournal = {Appl. Intell.},
  title        = {New approaches for mining high utility itemsets with multiple utility thresholds},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered robust safety control for
multiplayer fully cooperative games with mismatched uncertainties and
asymmetric input constraints. <em>APIN</em>, <em>54</em>(1), 749–766.
(<a href="https://doi.org/10.1007/s10489-023-05233-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a dynamic event-triggered robust safety control method for multiplayer fully cooperative games with mismatched uncertainties and asymmetric input constraints under continuous-time nonlinear systems. Firstly, to address the safety constraints on the system states, a suitable barrier function is proposed to transform the original constrained system into an unconstrained system. Subsequently, through the construction of an auxiliary system, the robust control (RC) problem is transformed into optimal control problem with auxiliary control laws. Secondly, the control laws are subjected to asymmetric constraints by designing a non-quadratic function. Unlike traditional static event-triggered control, a new dynamic event-triggered mechanism is introduced for updating the control laws. In addition, a new critic neural network (NN) weight update method is constructed to approximate the solution of the event-triggered Hamiltonian Jacobi Bellman (HJB) equation by using the concurrent learning technique. Furthermore, Lyapunov’s theorem proves that the closed-loop system is uniformly ultimately bounded (UUB). Finally, a simulation example of a single-linked robotic arm is provided to verify the validity of the proposed method in this paper.},
  archive      = {J_APIN},
  author       = {Qin, Chunbin and Zhu, Tianzeng and Jiang, Kaijun and Zhang, Jishi},
  doi          = {10.1007/s10489-023-05233-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {749-766},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic event-triggered robust safety control for multiplayer fully cooperative games with mismatched uncertainties and asymmetric input constraints},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An iterative 3D human body reconstruction method driven by
personalized dimensional prior knowledge. <em>APIN</em>, <em>54</em>(1),
738–748. (<a href="https://doi.org/10.1007/s10489-023-05214-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, remarkable strides have been made in 3D human reconstruction. However, the focus has primarily been on pose reconstruction, which fails to capture the true shape of the human body, particularly for individuals who are overweight or underweight. Therefore, based on a combination of regression and optimization, as well as ensuring accurate posture, we incorporate reasonable prior knowledge for the shape part of the reconstructions during iteration to obtain a Skinned Multi-Person Linear Model (SMPL) with a reasonable shape. During the training process, in regard to the pose, we fit 2D joint points, which can be obtained through images, and the training is still feasible even if the ground truth is missing; for the shape, we obtain the dimension information by measurement, but the initial height and waist need to be provided. To assess our method, we collect the dimension data from 200 individuals and achieved a remarkable average precision of 97 $$\%$$ based on a thorough comparison of the results. Our main research objective is to construct a more realistic model of the human body by adding reasonable body dimension information as prior knowledge during the iterative loop, and to measure 38 body dimensions of the human body. Our experiments demonstrate that our method, in regard to the shape, outperforms other state-of-the-art techniques while simultaneously maintaining postural accuracy.},
  archive      = {J_APIN},
  author       = {Dong, Yukun and Yuan, Qi and Peng, Rongrong and Wang, Shengtao and Sun, Junqi},
  doi          = {10.1007/s10489-023-05214-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {738-748},
  shortjournal = {Appl. Intell.},
  title        = {An iterative 3D human body reconstruction method driven by personalized dimensional prior knowledge},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A period-extracted multi-featured dynamic graph convolution
network for traffic demand prediction. <em>APIN</em>, <em>54</em>(1),
722–737. (<a href="https://doi.org/10.1007/s10489-023-05226-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban online car-hailing demand prediction poses a significant challenge in developing intelligent transportation systems due to its intricate and dynamic spatio-temporal correlation. Prior research has demonstrated promising outcomes in demand forecasting by employing graph neural networks. However, these studies either solely rely on static prior information or allow the model to independently capture spatial associations. In terms of temporal considerations, effectively modeling both long-term and short-term dependencies remains a crucial factor that significantly impacts overall performance. To tackle these challenges, we propose a novel Period-Extracted Multi-featured Dynamic Graph Convolution Network (PE-MDGCN) for traffic demand prediction. Specifically, our proposed model introduces the Period Dynamic Arrival Learning module and the Static Feature Dynamic Adaptation module, to effectively capture shorter-term relations based on time intervals and arrival connections, as well as the dynamic changes based on static multi-featured graphs. Furthermore, our proposed spatio-temporal multi-graph learning framework leverages a temporal contextual gated mechanism and multi-visual field convolution to efficiently capture global, long-term, and short-term information. By conducting comprehensive experiments on two real-world traffic demand datasets, our model consistently surpasses all baseline models in terms of various evaluation metrics.},
  archive      = {J_APIN},
  author       = {Zhu, Yuntian and Ni, Qingjian},
  doi          = {10.1007/s10489-023-05226-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {722-737},
  shortjournal = {Appl. Intell.},
  title        = {A period-extracted multi-featured dynamic graph convolution network for traffic demand prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discovering frequent parallel episodes in complex event
sequences by counting distinct occurrences. <em>APIN</em>,
<em>54</em>(1), 701–721. (<a
href="https://doi.org/10.1007/s10489-023-05187-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event sequences are common types of data. Several episode mining algorithms have been developed to find episodes (subsequences of events) that appear frequently in an event sequence, with the aim of discovering useful knowledge for decision-making and predictions. However, most of these algorithms can only process simple event sequences (where, at most, one event occurs at each timestamp). In contrast, in many real-life applications, multiple events may occur at the same timestamp, resulting in complex event sequences. Moreover, numerous episode mining algorithms overestimate the frequency of episodes by counting the same events multiple times. As a solution, some algorithms have been designed to count only non-overlapping occurrences. Yet, it can be argued that this definition is too strict and discards many important events. To address these limitations, this paper presents an algorithm named EMDO (Episode Mining under Distinct Occurrences (EMDO) to find frequent episodes in a complex sequence by counting distinct occurrences. The proposed concept of distinct occurrences ensures that each event is not counted more than once but allows distinct occurrences to overlap. A second algorithm, called EMDO-P, is also presented in this paper to derive strong episode rules in event sequences from episodes found by EMDO. To the best of our knowledge, this is the first study on mining frequent episodes using a frequency definition based on distinct occurrences. The experimental results confirm that the proposed algorithms are efficient.},
  archive      = {J_APIN},
  author       = {Ouarem, Oualid and Nouioua, Farid and Fournier-Viger, Philippe},
  doi          = {10.1007/s10489-023-05187-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {701-721},
  shortjournal = {Appl. Intell.},
  title        = {Discovering frequent parallel episodes in complex event sequences by counting distinct occurrences},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SQPMF: Successive point of interest recommendation system
based on probability matrix factorization. <em>APIN</em>,
<em>54</em>(1), 680–700. (<a
href="https://doi.org/10.1007/s10489-023-05196-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Location-Based Social Networks, successive Point Of Interest (POI) recommendation systems have become a hot spot in the field of recommendation systems. Successive POI recommendation systems suggest to users new and interesting places to visit. However, in real-life POI recommendation, there are often a small number of users facing a huge number of POIs. Traditional successive POI recommendation methods are not capable to deal with the large sparse datasets, as they only consider the simple relationship between users and POIs. They do not use the context information of users and POIs, which can enable better recommendation results. To utilize the context information, this paper proposes a novel successive POI recommendation method, SQPMF, which integrates user personal preferences, user social relationships and POI transition relationships into the system for accurate recommendation of the next POI. Our experimental evaluation using three real-life datasets, Gowalla, Foursquare and Brightkite, shows that our method SQPMF consistently outperforms all state-of-the-art methods in recommendation of successive POIs. Compared with other methods, SQPMF improves Precision, Recall and F1-score by an average of at least 6.1 $$\%$$ , 5.8 $$\%$$ and 5.7 $$\%$$ respectively on three publicly available datasets.},
  archive      = {J_APIN},
  author       = {Wang, Jie and Huang, Zhiyi and Liu, Zhaobin},
  doi          = {10.1007/s10489-023-05196-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {680-700},
  shortjournal = {Appl. Intell.},
  title        = {SQPMF: Successive point of interest recommendation system based on probability matrix factorization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 3P-ECLAT: Mining partial periodic patterns in columnar
temporal databases. <em>APIN</em>, <em>54</em>(1), 657–679. (<a
href="https://doi.org/10.1007/s10489-023-05172-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial periodic pattern (3P) mining is a vital data mining technique that aims to discover all interesting patterns that have exhibited partial periodic behavior in temporal databases. Previous studies have primarily focused on identifying 3Ps only in row temporal databases. One can not ignore the existence of 3Ps in columnar temporal databases as many real-world applications, such as Facebook and Adobe, employ them to store their big data. This paper proposes an efficient single database scan algorithm, Partial Periodic Pattern-Equivalence Class Transformation (3P-ECLAT), to identify all 3Ps in a columnar temporal database. The proposed algorithm compresses the given database into a novel list-based data structure and mines it recursively to find all 3Ps. The 3P-ECLAT leverages the “downward closure property” and “depth-first search technique” to reduce the search space and the computational cost. Extensive experiments have been conducted on synthetic and real-world databases to demonstrate the efficiency of the 3P-ECLAT algorithm. The memory and runtime results show that 3P-ECLAT outperforms its competitor considerably. Furthermore, 3P-ECLAT is highly scalable and is superior to the previous approach in handling large databases. Finally, to demonstrate the practical utility of our algorithm, we provide two real-world case studies, one on analyzing traffic congestion during disasters and another on identifying the highly polluted areas in Japan.},
  archive      = {J_APIN},
  author       = {Pamalla, Veena and Rage, Uday Kiran and Penugonda, Ravikumar and Palla, Likhitha and Watanobe, Yutaka and Ito, Sadanori and Zettsu, Koji and Toyoda, Masashi and Bathala, Venus vikranth raj},
  doi          = {10.1007/s10489-023-05172-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {657-679},
  shortjournal = {Appl. Intell.},
  title        = {3P-ECLAT: Mining partial periodic patterns in columnar temporal databases},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view and multi-augmentation for self-supervised visual
representation learning. <em>APIN</em>, <em>54</em>(1), 629–656. (<a
href="https://doi.org/10.1007/s10489-023-05163-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, the appearance of identical objects depends on factors as varied as resolution, angle, illumination conditions, and viewing perspectives. This suggests that the data augmentation pipeline could benefit downstream tasks by exploring the overall data appearance in a self-supervised framework. Previous work on self-supervised learning that yields outstanding performance relies heavily on data augmentation such as cropping and color distortion. However, most methods use a static data augmentation pipeline, limiting the amount of feature exploration. To generate representations that encompass scale-invariant, explicit information about various semantic features and are invariant to nuisance factors such as relative object location, brightness, and color distortion, we propose the Multi-View, Multi-Augmentation (MVMA) framework. MVMA consists of multiple augmentation pipelines, with each pipeline comprising an assortment of augmentation policies. By refining the baseline self-supervised framework to investigate a broader range of image appearances through modified loss objective functions, MVMA enhances the exploration of image features through diverse data augmentation techniques. Transferring the resultant representation learning using convolutional networks (ConvNets) to downstream tasks yields significant improvements compared to the state-of-the-art DINO across a wide range of vision tasks and classification tasks: +4.1% and +8.8% top-1 on the ImageNet dataset with linear evaluation and k-NN classifier, respectively. Moreover, MVMA achieves a significant improvement of +5% $$AP_{50}$$ and +7% $$AP_{50}^m$$ on COCO object detection and segmentation.},
  archive      = {J_APIN},
  author       = {Tran, Van Nhiem and Huang, Chi-En and Liu, Shen-Hsuan and Aslam, Muhammad Saqlain and Yang, Kai-Lin and Li, Yung-Hui and Wang, Jia-Ching},
  doi          = {10.1007/s10489-023-05163-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {629-656},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view and multi-augmentation for self-supervised visual representation learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bi-AFN++CA: Bi-directional adaptive fusion network combining
context augmentation for small object detection. <em>APIN</em>,
<em>54</em>(1), 614–628. (<a
href="https://doi.org/10.1007/s10489-023-05216-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep CNN-based generic object detectors have achieved impressive results, their performance significantly drops when detecting small objects, mainly due to their low-resolution and lack of distinguishable features, especially in cluttered backgrounds. Feature Pyramid Network (FPN) is a promising solution that aggregates features across various scales in a top-down manner. Nevertheless, existing FPN-based methods are limited by their stacked fusion phases, which completely transfer all information, hindering the expression of multi-scale representation and potentially obliterate the representation of small objects. Additionally, small objects in cluttered environments can be occluded or densely crowded, making it challenging to detect them solely based on multi-scale representation. To address these challenges, we propose the Bi-directional Adaptive Fusion Network combined with Context Augmentation (Bi-AFN++CA), aiming to enhance the performance of small object detection by integrating both multi-scale representation and contextual one. The Bi-AFN++CA consists of two main components, the Bi-directional Adaptive Fusion Network (Bi-AFN) and the Context Extraction Module (CEM). The Bi-AFN enriches multi-scale representation through the simultaneous use of Semantics Restraint Module (SRM) and Details Enhancement Module (DEM), facilitating feature information exchange in both top-down and bottom-up pathways. On the other hand, the CEM focuses on extracting contextual representation from both spatial and channel dimensions, providing an additional source of feature information. Extensive experiments were conducted on the VisDrone2021-DET, MS COCO, and DIOR datasets, and the results demonstrate that our method significantly outperforms existing state-of-the-art methods in detecting small objects.},
  archive      = {J_APIN},
  author       = {Zhang, Hongying and Chen, Enyao},
  doi          = {10.1007/s10489-023-05216-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {614-628},
  shortjournal = {Appl. Intell.},
  title        = {Bi-AFN++CA: Bi-directional adaptive fusion network combining context augmentation for small object detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep non-negative matrix factorization with edge generator
for link prediction in complex networks. <em>APIN</em>, <em>54</em>(1),
592–613. (<a href="https://doi.org/10.1007/s10489-023-05211-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction aims to infer missing links or predict future links based on observed topology or attribute information in the network. Many link prediction methods based on non-negative matrix factorization (NMF) have been proposed to solve prediction problem. However, due to the sparsity of real networks, the observed topology information is probably very limited, which affects the performance of existing link prediction methods. In this paper, we utilize Deep Non-negative Matrix Factorization (DNMF) models with Edge Generator to address the network sparsity problem and propose link prediction methods EG-DNMF and EG-FDNMF. Under the framework of DNMF, several representative potential edges are incorporated so as to reconstruct the original network for link prediction. Specifically, in order to explore the potential structural features of the network in a more fine-grained manner, we first divide the original network into three sub-networks. Then, the DNMF models are employed to mine complex and nonlinear interaction relationships in sub-networks, thereby guiding the network reconstruction process. Finally, the NMF algorithm is applied on the reconstructed original network for link prediction. Experiment results on 12 different networks show that our methods have comparable performance with respect to 13 representative link prediction methods which include 6 NMF/DNMF-based approaches and 7 heuristic-based approaches. In addition, experiments also show that the sub-networks after partitioning are beneficial for capturing the underlying features of the network. Codes are available at https://github.com/yabingyao/EGDNMF4LinkPrediction},
  archive      = {J_APIN},
  author       = {Yao, Yabing and He, Yangyang and Huang, Zhentian and Xu, Zhipeng and Yang, Fan and Tang, Jianxin and Gao, Kai},
  doi          = {10.1007/s10489-023-05211-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {592-613},
  shortjournal = {Appl. Intell.},
  title        = {Deep non-negative matrix factorization with edge generator for link prediction in complex networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse feature selection via local feature and high-order
label correlation. <em>APIN</em>, <em>54</em>(1), 565–591. (<a
href="https://doi.org/10.1007/s10489-023-05136-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, some existing feature selection approaches neglect the correlation among labels, and almost manifold-based multilabel learning models do not considered the relationship between features and labels, which result in reducing classification effect. To overcome the shortcomings, our work develops a fresh sparse feature selection approach via local feature and high-order label correlation. First, the sparse processing is performed by applying the l2,1 norm on the weight coefficient matrix, and a loss function between the sample and label matrices can be established to explore the potential relationship between features and labels. The designed loss function can be directly sparse by the weight coefficient matrix, which calculates this weight of each feature, and then some features with higher scores are selected. Second, the combination of manifold learning and Laplacian score is used to deal with local features to make full use of local feature correlation. The manifold regularization for the embedded feature selection can guide exploring potential real labels and selecting different features for individual labels. Finally, to safeguard the rank of the high-order label matrix from being damaged, a self-representation strategy is employed. Then the high-order label weight matrix and the label error term are defined to enhance the accuracy of label self-representation and correct the deviation between the self-representation scheme and the real label, and the Frobenius and the l2 norm regularization can avoid those trivial solutions and overfitting issues. A representation function of high-order label correlation is proposed based on the self-representation strategy, which can accurately represent the potential information between high-order labels. Thus, those local features are scored by the Laplacian score for different features to select an optimal feature subset with higher scores. Experiments on 16 multilabel datasets illustrate that our constructed algorithm will be efficient in obtaining important feature set and implementing powerful classification efficacy on multilabel classification.},
  archive      = {J_APIN},
  author       = {Sun, Lin and Ma, Yuxuan and Ding, Weiping and Xu, Jiucheng},
  doi          = {10.1007/s10489-023-05136-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {565-591},
  shortjournal = {Appl. Intell.},
  title        = {Sparse feature selection via local feature and high-order label correlation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic online decisioning hyper-heuristic for high
dimensional optimization. <em>APIN</em>, <em>54</em>(1), 544–564. (<a
href="https://doi.org/10.1007/s10489-023-05185-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing heuristic optimizers are found to be restricted to problems of moderate dimensionality, and their performance suffers when solving high-dimensional or large-scale optimization tasks. In this paper, we transform the high-dimensional optimization into online decision making problems and propose a stochastic online decisioning hyper-heuristic framework, by considering multi-armed bandits with temporal reward estimation as our essential backbone. The multi-armed bandit problem simulates an agent which tries to balance exploration and exploitation simultaneously. Specifically, we introduce 1) a sliding time window to assign temporal credit for differing heuristics, and 2) boltzmann exploration for balancing the exploration-exploitation tradeoff. The proposed method is well suited for real-world applications, with flexible compatibility for versatile cost definitions, easy interfaces for heuristics as well as fewer hyper-parameters for consistent generalization performance. Experimental studies on the benchmarks results verify the efficacy and significance of the proposed framework, i.e., when considering three differing heuristics, our method reported consistently competitive performance on benchmark problems with a dimensionality up to 10,000.},
  archive      = {J_APIN},
  author       = {Xia, Wang and Hongwei, Ge and Mingde, Zhao and Yaqing, Hou and Mingyang, Sun},
  doi          = {10.1007/s10489-023-05185-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {544-564},
  shortjournal = {Appl. Intell.},
  title        = {Stochastic online decisioning hyper-heuristic for high dimensional optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Replacing self-attentions with convolutional layers in
multivariate long sequence time-series forecasting. <em>APIN</em>,
<em>54</em>(1), 522–543. (<a
href="https://doi.org/10.1007/s10489-023-05205-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers have attracted increasing interest in time-series forecasting. However, there are two issues for Multi-Head Self-Attention (MHSA) layers in Multivariate Long Sequence Time-series Forecasting (MLSTF): the massive computation resource consumption and the lack of inductive bias for learning the seasonal and trend pattern of time-series sequences. To address these issues, a systematic method is proposed to replace part of the MHSA layers in Transformers with convolutional layers. Specifically, the self-attention patterns are categorized into four types, i.e., diagonal, vertical, block and heterogeneous patterns. The relationships are explored between convolutional layers and MHSA layers exhibiting different self-attention patterns. Based on which, the evaluation metrics are proposed to decide whether to replace MHSA layers with convolutional layers or not. The experimental results on two representative Transformer-based forecasting models show that our method can achieve competitive results with the original Transformer-based forecasting models and greatly reduce their number of parameters and flops. The performance of models on small data sets has also been greatly improved due to the introduction of convolutional operations. Further, this method is adapted to Transformer-based models for other time series tasks and achieves similar results.},
  archive      = {J_APIN},
  author       = {Wang, Yong and Peng, Jianjian and Wang, Xiaohu and Zhang, Zhicheng and Duan, Junting},
  doi          = {10.1007/s10489-023-05205-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {522-543},
  shortjournal = {Appl. Intell.},
  title        = {Replacing self-attentions with convolutional layers in multivariate long sequence time-series forecasting},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 1-d multi-channel CNN with transfer functions for inverse
electromagnetic behaviors modeling and design optimization of
high-dimensional filters. <em>APIN</em>, <em>54</em>(1), 503–521. (<a
href="https://doi.org/10.1007/s10489-023-05200-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an essential passive component in modern wireless communication systems, the design of high-frequency filters has become increasingly crucial. To achieve the target behavior specifications, traditional design methods are constrained by designers’ expertise or reliant on repetitive frequency sweeps using commercial software. Such processes suffer from low efficiency, limited applicability, and high computational costs. Artificial neural network-based modeling has become an important tool for designing devices. To realize accurate and fast electromagnetic modeling and design of passive components, this work proposes an inverse model integrating transfer functions and one-dimensional multi-channel convolutional neural networks (TF-1DMC-CNN). This model introduces transfer functions to ensure precise representation of electromagnetic responses while addressing the challenge of input dimensionality in wideband modeling. Input dimensions are reduced from 161 to 20 and 221 to 20 for two examples. The 1DMC-CNN processes distinct TF coefficients in each channel and extracts features in parallel. The geometrical parameters can be directly predicted in a single feedforward pass through the trained inverse model without needing iterative optimization. Compared to other inverse neural networks, the proposed model achieves the smallest testing errors. It obtains better model accuracy with fewer training samples, reducing data generation time. Compared to the traditional EM optimization method, this approach reduces CPU time for optimizations, enabling predictions of geometric structures that meet different design indexes. For multi-objective optimization, the proposed model predicts the structure within 0.16 seconds.},
  archive      = {J_APIN},
  author       = {Ren, Yimin and Deng, Xiaojiao and You, Zhengyang and Zheng, Xiaoping},
  doi          = {10.1007/s10489-023-05200-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {503-521},
  shortjournal = {Appl. Intell.},
  title        = {1-D multi-channel CNN with transfer functions for inverse electromagnetic behaviors modeling and design optimization of high-dimensional filters},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ULME-GAN: A generative adversarial network for
micro-expression sequence generation. <em>APIN</em>, <em>54</em>(1),
490–502. (<a href="https://doi.org/10.1007/s10489-023-05213-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the lack of micro-expression datasets is a significant obstacle to micro-expression research and hinders the development of micro-expression supervised data generation. To address this issue, we propose the unsupervised learning micro-expression sequences generative adversarial network (ULME-GAN) approach, which generates micro-expression sequences that can be controlled. By analyzing all action units (AUs) that appear in main micro-expression datasets, a novel method called action unit matrix and re-encoding (AUMR) is proposed to generate micro-expression sequences that appear more natural and seamless by smoothing the AU matrix extracted from the source video. Our experiments demonstrate that the ULME-GAN approach can generate micro-expression videos/images that maintain the input source video/image pattern better than other methods, such as the first order motion model and StyleGAN. Furthermore, the micro-expression recognition task demonstrates that the augmented dataset can lead to a significant improvement in the performance of micro-expression recognition models. Finally, ULME-GAN can generate videos/images with specific micro-expression patterns defined by an input AU matrix, making it suitable for various applications even when there is insufficient source video.},
  archive      = {J_APIN},
  author       = {Zhou, Ju and Sun, Sirui and Xia, Haolin and Liu, Xinyu and Wang, Hanpu and Chen, Tong},
  doi          = {10.1007/s10489-023-05213-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {490-502},
  shortjournal = {Appl. Intell.},
  title        = {ULME-GAN: A generative adversarial network for micro-expression sequence generation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporally extended goal recognition in fully observable
non-deterministic domain models. <em>APIN</em>, <em>54</em>(1), 470–489.
(<a href="https://doi.org/10.1007/s10489-023-05087-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Goal Recognition is the task of discerning the intended goal that an agent aims to achieve, given a set of goal hypotheses, a domain model, and a sequence of observations (i.e., a sample of the plan executed in the environment). Existing approaches assume that goal hypotheses comprise a single conjunctive formula over a single final state and that the environment dynamics are deterministic, preventing the recognition of temporally extended goals in more complex settings. In this paper, we expand goal recognition to temporally extended goals in Fully Observable Non-Deterministic (fond) planning domain models, focusing on goals on finite traces expressed in Linear Temporal Logic (ltl $$_f$$ ) and Pure-Past Linear Temporal Logic (ppltl). We develop the first approach capable of recognizing goals in such settings and evaluate it using different ltl $$_f$$ and ppltl goals over six fond planning domain models. Empirical results show that our approach is accurate in recognizing temporally extended goals in different recognition settings.},
  archive      = {J_APIN},
  author       = {Pereira, Ramon Fraga and Fuggitti, Francesco and Meneguzzi, Felipe and De Giacomo, Giuseppe},
  doi          = {10.1007/s10489-023-05087-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {470-489},
  shortjournal = {Appl. Intell.},
  title        = {Temporally extended goal recognition in fully observable non-deterministic domain models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way decision: A unification of two-universe models of
rough sets. <em>APIN</em>, <em>54</em>(1), 460–469. (<a
href="https://doi.org/10.1007/s10489-023-05209-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The note concerns two-universe rough sets. First, we discuss the name of two-universe model. Second, we outline two lines of the development of two-universe rough sets and affirm that three-way decision unifies models of two-universe rough sets.},
  archive      = {J_APIN},
  author       = {Li, Xiaonan and Yan, Yucong},
  doi          = {10.1007/s10489-023-05209-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {460-469},
  shortjournal = {Appl. Intell.},
  title        = {Three-way decision: A unification of two-universe models of rough sets},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing microblog sentiment analysis through multi-level
feature interaction fusion with social relationship guidance.
<em>APIN</em>, <em>54</em>(1), 443–459. (<a
href="https://doi.org/10.1007/s10489-023-05206-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In sentiment analysis of microblogs that involve social relationships, a common approach is to expand the features of target microblogs using microblog relationship networks. However, the current research methodology only relies on individual interaction behaviors on social platforms to construct these networks, disregarding the guiding influence of microblog relationship networks on microblogs. Consequently, this leads to the feature expansion of microblogs while introducing interference among them. To address this problem, this study aims to construct a more precise microblog relationship network by incorporating multiple interactive behaviors from social platforms. This network will serve as a guide for sentiment interactions among microblog texts, thereby mitigating feature interference. Firstly, we utilize various interaction behaviors on social platforms to build a microblog relationship network. We employ a LINE network embedding to represent the microblog relationship network as microblog relationship features. Secondly, we extract word-level and sentence-level features from the microblog text using a BERT pre-training model. The word-level features are combined using convolutional neural networks. Subsequently, the word-level and sentence-level features of microblogs are separately guided for interaction fusion through relational features. An attention network is then constructed to fuse the post-interaction features in a single step. Prior to secondary fusion, the primary fusion features, post-interaction word-level features, and post-interaction sentence-level features are weighted, and the sentiment categories of microblogs are outputted. Finally, we compare the proposed method with the text-only microblog sentiment analysis approach and the sentiment analysis method that incorporates social relationships on two real datasets. The comparison results demonstrate the superiority of our proposed method.},
  archive      = {J_APIN},
  author       = {Gan, Chenquan and Cao, Xiaopeng and Zhu, Qingyi and Jain, Deepak Kumar and García, Salvador},
  doi          = {10.1007/s10489-023-05206-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {443-459},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing microblog sentiment analysis through multi-level feature interaction fusion with social relationship guidance},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Channel-augmented joint transformation for transferable
adversarial attacks. <em>APIN</em>, <em>54</em>(1), 428–442. (<a
href="https://doi.org/10.1007/s10489-023-05171-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are vulnerable to adversarial examples that fool the models with tiny perturbations. Although adversarial attacks have achieved incredible attack success rates in the white-box setting, most existing adversaries often exhibit weak transferability in the black-box setting, especially for models with defense mechanisms. In this work, we reveal the cross-model channel redundancy and channel invariance of DNNs and thus propose two channel-augmented methods to improve the transferability of adversarial examples, namely, the channel transformation (CT) method and the channel-invariant Patch (CIP) method. Specifically, channel transformation shuffles and rewrites channels to enhance cross-model feature redundancy in convolution, and channel-invariant patches distinctly weaken different channels to achieve loss-preserving transformation. We compute the aggregated gradients of the transformed dataset to create adversaries with higher transferability. In addition, the two proposed methods can be naturally combined with each other and with almost all other gradient-based methods to further improve performance. Empirical results on the ImageNet dataset demonstrate that our attack methods exhibit higher transferability and achieve higher attack success rates than state-of-the-art gradient-based attacks. Specifically, our attack improves the average attack success rate from 86.9% to 91.0% on normally trained models and from 44.6% to 68.3% on adversarially trained models.},
  archive      = {J_APIN},
  author       = {Zheng, Desheng and Ke, Wuping and Li, Xiaoyu and Zhang, Shibin and Yin, Guangqiang and Qian, Weizhong and Zhou, Yong and Min, Fan and Yang, Shan},
  doi          = {10.1007/s10489-023-05171-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {428-442},
  shortjournal = {Appl. Intell.},
  title        = {Channel-augmented joint transformation for transferable adversarial attacks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting CNN’s visual explanations to drive anomaly
detection. <em>APIN</em>, <em>54</em>(1), 414–427. (<a
href="https://doi.org/10.1007/s10489-023-05177-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, deep learning is a key technology for many applications in the industrial area such as anomaly detection. The role of Machine Learning (ML) in this field relies on the ability of training a network to learn to inspect images to determine the presence or not of anomalies. Frequently, in Industry 4.0 w.r.t. the anomaly detection task, the images to be analyzed are not optimal, since they contain edges or areas, that are not of interest which could lead the network astray. Thus, this study aims at identifying a systematic way to train a neural network to make it able to focus only on the area of interest. The study is based on the definition of a loss to be applied in the training phase of the network that, using masks, gives higher weight to the anomalies identified within the area of interest. The idea is to add an Overlap Coefficient to the standard cross-entropy. In this way, the more the identified anomaly is outside the Area of Interest (AOI) the greater is the loss. We call the resulting loss Cross-Entropy Overlap Distance (CEOD). The advantage of adding the masks in the training phase is that the network is forced to learn and recognize defects only in the area circumscribed by the mask. The added benefit is that, during inference, these masks will no longer be needed. Therefore, there is no difference, in terms of execution times, between a standard Convolutional Neural Network (CNN) and a network trained with this loss. In some applications, the masks themselves are determined at run-time through a trained segmentation network, as we have done for instance in the &quot;Machine learning for visual inspection and quality control&quot; project, funded by the MISE Competence Center Bi-REX.},
  archive      = {J_APIN},
  author       = {Fraccaroli, Michele and Bizzarri, Alice and Casellati, Paolo and Lamma, Evelina},
  doi          = {10.1007/s10489-023-05177-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {414-427},
  shortjournal = {Appl. Intell.},
  title        = {Exploiting CNN’s visual explanations to drive anomaly detection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). An optical flow estimation method based on multiscale
anisotropic convolution. <em>APIN</em>, <em>54</em>(1), 398–413. (<a
href="https://doi.org/10.1007/s10489-023-05131-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the tracking accuracy degradation problem in scenarios with large displacements or nonrigid motion during target tracking, this paper proposes an optical flow estimation method based on multiscale anisotropic convolution. The network structure is improved in a step-by-step manner by extracting the data flow from the network according to the observed features. For the low-level neural network, a layered multiscale structure is used to build a cascade network by using hybrid dilated convolution to obtain feature information at different scales while ensuring the tracking accuracy. For the upper-layer neural network, hybrid inflated deformable convolution is used by learning the contextual long-range correlations and multidirectional adaptive offsets of features. Experiments are conducted on the Flying Chairs, KITTI, and MPI datasets. The results show that compared with various popular algorithm methods, the model in this paper reduces endpoint errors while retaining edge information in regions with large displacements or nonrigid motion. Code is available at https://github.com/yifanna/MACFlow-pytorch .},
  archive      = {J_APIN},
  author       = {Wang, Yifan and Li, Yang and Wang, Jiaqi and Lv, Haofeng},
  doi          = {10.1007/s10489-023-05131-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {398-413},
  shortjournal = {Appl. Intell.},
  title        = {An optical flow estimation method based on multiscale anisotropic convolution},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Few-shot defect detection using feature enhancement and
image generation for manufacturing quality inspection. <em>APIN</em>,
<em>54</em>(1), 375–397. (<a
href="https://doi.org/10.1007/s10489-023-05199-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual defect detection, which is pivotal in industrial quality control, often requires extensive datasets for training deep-learning models. However, in industrial environments, the presence of multiple production batches, small lot sizes, and rapidly evolving task requirements make it challenging to acquire sufficient and diverse defect data. To address these challenges, this study introduces an innovative approach to data augmentation and defect detection under few-data conditions. Our strategy employs a two-stage feature-enhancement method complemented by an expert knowledge-based image-generation method. The former ensures robustness in color and richness in feature representation by focusing on local defect irregularities. The latter leverages both the core mechanistic understanding of experts and nonquantitative empirical insights, combined with a variable background domain, to generate rich images with diverse defect features. We evaluated the feasibility and effectiveness of the proposed method using a proprietary dataset curated by an automotive component manufacturing enterprise. The experimental results revealed that, across the five defect categories, training on 2 images achieved an F1-Score of 41.06%, which improved to 67.11% when the training dataset was expanded to 15 images. A comparative analysis with prevailing feature enhancement and image generation methods revealed our solution’s superiority, bridging methodological drawbacks, and markedly eclipsing others in terms of enhancement potency. Furthermore, when benchmarked against additional public industrial datasets, the model exhibited exceptional adaptability and superior performance, thus highlighting its potential as a robust tool for quality control in manufacturing scenarios.},
  archive      = {J_APIN},
  author       = {Gong, Yu and Liu, Mingzhou and Wang, Xiaoqiao and Liu, Conghu and Hu, Jing},
  doi          = {10.1007/s10489-023-05199-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {375-397},
  shortjournal = {Appl. Intell.},
  title        = {Few-shot defect detection using feature enhancement and image generation for manufacturing quality inspection},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HGTHP: A novel hyperbolic geometric transformer hawkes
process for event prediction. <em>APIN</em>, <em>54</em>(1), 357–374.
(<a href="https://doi.org/10.1007/s10489-023-05169-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event sequences with spatiotemporal characteristics have been rapidly produced in various domains, such as earthquakes in seismology, electronic medical records in health care, and transactions in the financial market. These data are discrete events that are continuous and often continue for weeks, months, or years, and past events may trigger subsequent events. In this context, modeling spatiotemporal event sequences and forecasting the occurrence time and marker of the next event has become a hot topic. However, existing models either fail to capture the long-term temporal dependencies or ignore the essential spatial information between sequences. Moreover, existing models learn the influence of past events and predicted future events in Euclidean space, which has been shown to cause a significant distortion in hierarchical structure data. To correctly predict future events from historical events and design interventions and controls to guide the event dynamics to the desired results and inspired by the high capacity of modeling data in hyperbolic space, we proposed a novel hyperbolic graph transformer Hawkes process (HGTHP) model to capture the long-term temporal dependencies and spatial information from historical events with a hierarchical structure. The core concept of the HGTHP is to integrate the learned spatial information into the event embedding as auxiliary information and capture long-short term temporal dependencies from event sequences in non-Euclidean space by a hyperbolic self-attention mechanism. Numerous experiments on synthetic and real-world datasets proved that the proposed model obtains spatiotemporal information from hyperbolic space, and its predictions outperform those of state-of-the-art baselines in both time and marker, proving the proposed model’s effectiveness.},
  archive      = {J_APIN},
  author       = {Xie, Yiman and Wu, Jianbin},
  doi          = {10.1007/s10489-023-05169-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {357-374},
  shortjournal = {Appl. Intell.},
  title        = {HGTHP: A novel hyperbolic geometric transformer hawkes process for event prediction},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Differential evolution with the mutation strategy
transformation based on a quartile for numerical optimization.
<em>APIN</em>, <em>54</em>(1), 334–356. (<a
href="https://doi.org/10.1007/s10489-023-05038-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is an evolutionary algorithm that is straightforward but effective and has been satisfactorily implemented in a variety of fields. However, the DE relies heavily on the mutation strategy, and utilizing different mutation strategies can boost DE’s performance at different phases during the evolution. This paper proposes a DE variant with the strategy transformation (qSTDE) based on a quartile. The proposed qSTDE uses feedback information from individuals and the entire population distribution to determine the position ofmutation strategy transformation, balancing theDE’s exploration and exploitation capabilities. Individuals are first ranked in accordance with their fitness values, and then the ranked population is separated into four sub-populations using quartile points. Next, the Euclidean distances between the best individual and four individuals that are randomly selected from the four sub-populations are calculated, as well as their Euclidean distances to the searching space ratios. Further, the evolution process is completely separated into two phases, and the transformation position is determined through the comparison of ratios for a given threshold. Finally, different mutation strategies are used in different stages depending on the distinction between the two stages and the transformation position. The proposed qSTDE is evaluated on CEC2005 and CEC2014 benchmark test functions. The experimental results show that the qSTDE is efficient and competitive contrasted to the state-of-the-art DE variants.},
  archive      = {J_APIN},
  author       = {Jin, Peiyuan and Cen, Jianming and Feng, Quanxi and Ai, Wu and Chen, Huazhou and Qiao, Hanli},
  doi          = {10.1007/s10489-023-05038-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {334-356},
  shortjournal = {Appl. Intell.},
  title        = {Differential evolution with the mutation strategy transformation based on a quartile for numerical optimization},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the cooperative scheduling problem of muck transport
under time-segment restriction in an entire region. <em>APIN</em>,
<em>54</em>(1), 317–333. (<a
href="https://doi.org/10.1007/s10489-023-05189-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the acceleration of urbanization, there is an urgent need to build more transportation facilities to alleviate travel pressure. However, during the construction of a subway station, a large amount of muck is generated and must be transported to a treatment center. In response to transportation policies, this paper establishes a regional and time-limited transportation model for muck trucks based on their departure time points. The model aims to dispatch the least number of vehicles and complete all transportation tasks as quickly as possible, taking into account constraints such as restricted travel time. This paper uses the NSGA-II algorithm with multi-segment encoding to solve this problem, and numerical experiments are conducted to analyze the performance of the proposed method. The results indicate that the improved algorithm has better convergence and distribution than the standard NSGA-II. The study also validates the effectiveness of the proposed method through a real-world example of muck transportation at subway stations in a specific city. The collaborative scheduling schemes developed through the methods proposed in this paper have effectively avoided the travel restriction period, providing managers with multiple decision-making options.},
  archive      = {J_APIN},
  author       = {Wang, Duanyi and Liu, Zhaoxia and Chen, Lin and Wei, Mengxiao and Li, Zongrong and Li, Yuming},
  doi          = {10.1007/s10489-023-05189-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {317-333},
  shortjournal = {Appl. Intell.},
  title        = {Solving the cooperative scheduling problem of muck transport under time-segment restriction in an entire region},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FedSEMA: Similarity-aware for representation consistency in
federated contrastive learning. <em>APIN</em>, <em>54</em>(1), 301–316.
(<a href="https://doi.org/10.1007/s10489-023-05193-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has emerged as a promising method for addressing the non-independent and identically distributed (non-IID) problem in federated learning. Existing methods make the limited assumption that all clients are consistently available in each communication round. However, in the more constrained scenario of cross-device settings, resource-constrained clients intermittently participate in the training process, resulting in the updates of the local models being delayed and thus reducing the representation consistency in the federated contrastive loss. In this paper, we analyse the superiority of the federated contrastive loss over traditional methods in terms of addressing the non-IID problem: the federated contrastive loss not only corrects the local objective towards the global objective but also debiases the local updates. To address the representation inconsistency issue, we propose a novel method called Federated Similarity-aware Exponential Moving Average update (FedSEMA), which incorporates a similarity-aware function into the EMA update process. First, FedSEMA adaptively facilitates the underlying pairwise collaborations between clients to generate personalized knowledge based on the similarity-aware EMA update procedure. Second, FedSEMA effectively exploits personalized knowledge to update the delayed local models, maintaining representation consistency to maximally benefit representation learning. Our extensive experiments conducted on various datasets under different non-IID settings demonstrate that FedSEMA is an effective and robust method for tackling the representation inconsistency issue.},
  archive      = {J_APIN},
  author       = {Zhou, Yanbing and Wu, Yingbo and Zhou, Jiyang and Zheng, Xin},
  doi          = {10.1007/s10489-023-05193-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {301-316},
  shortjournal = {Appl. Intell.},
  title        = {FedSEMA: Similarity-aware for representation consistency in federated contrastive learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HFNF: Learning a hybrid fourier neural filter with a
heterogeneous loss for sequential recommendation. <em>APIN</em>,
<em>54</em>(1), 283–300. (<a
href="https://doi.org/10.1007/s10489-023-05204-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation predicts users’ future interactions by capturing dynamic sequential patterns hidden in their historical behavioral sequences. Recently, many deep neural networks have been applied to learn representations of these sequences. However, noisy interactions in user behavior data impose a negative effect on these learned representations. To address this issue, we propose a model called Hybrid Fourier Neural Filter (HFNF) for the sequential recommendation, which is a combination of two kinds of Fourier neural filters and three kinds of objective functions. In HFNF, a global filter network and an adaptive Fourier neural operator are integrated to model dynamic user behaviors by fully exploiting their respective powerful denoising and expressiveness capabilities. Furthermore, a heterogeneous loss is designed to better train HFNF by enhancing preference learning while preserving the uniformity and the alignment of the learned representations. Experiments conducted on eight benchmark datasets demonstrate the superiority of the proposed HFNF model over competing deep neural network based sequential recommendation models.},
  archive      = {J_APIN},
  author       = {Xiao, Yadong and Huang, Jiajin and Yang, Jian},
  doi          = {10.1007/s10489-023-05204-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {283-300},
  shortjournal = {Appl. Intell.},
  title        = {HFNF: Learning a hybrid fourier neural filter with a heterogeneous loss for sequential recommendation},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint rumour and stance identification based on semantic and
structural information in social networks. <em>APIN</em>,
<em>54</em>(1), 264–282. (<a
href="https://doi.org/10.1007/s10489-023-05170-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumours that have spread in social networks have harmed society seriously, so rumour verification is a substantial task in social media analysis and natural language processing. In social networks, replies with different stances may provide direct clues to the veracity of the rumours. Thus, rumour verification would benefit from joint training with stance detection. However, there are still some shortcomings in current research, such as the unsatisfactory use of structure and semantic information in the conversation, features for different tasks independent of each other except for sharing input, and the insufficient discrimination of tweets with different stances. Aiming at these shortcomings, we first used the graph transformer to simultaneously obtain structural and semantic information such as dialogue reply, similar posts, same user, and same stance. Secondly, we adopted the partition filter network to explicitly model the rumour&amp; stance-specific features and the shared interactive feature. Finally, we strengthened the discriminability of tweets with different stances through contrastive learning. Experiments on SemEval2017 and PHEME corpus show that the proposed model significantly improves the rumour and stance detection tasks.},
  archive      = {J_APIN},
  author       = {Luo, Nanhang and Xie, Dongdong and Mo, Yiwen and Li, Fei and Teng, Chong and Ji, Donghong},
  doi          = {10.1007/s10489-023-05170-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {264-282},
  shortjournal = {Appl. Intell.},
  title        = {Joint rumour and stance identification based on semantic and structural information in social networks},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Explainable prediction of deposited film thickness in IC
fabrication with CatBoost and SHapley additive exPlanations (SHAP)
models. <em>APIN</em>, <em>54</em>(1), 246–263. (<a
href="https://doi.org/10.1007/s10489-023-05121-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a study on developing a chemical vapor deposition film thickness prediction model for semiconductor IC manufacturing. Traditional methods for measuring layer thickness are time-consuming and labor-intensive, prompting the exploration of machine-learning techniques for virtual measurement. These techniques estimate layer thickness directly from production process data, enabling real-time monitoring of product quality and maintaining process efficiency. This study used the Harris Hawks optimization algorithm (HHO) to perform feature selection on deposition process data and constructed a predictive model using the selected feature parameters. Four machine learning models, namely Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM), and Categorical Boosting (CatBoost), are evaluated using metrics such as mean squared error (MSE), mean absolute percentage error (MAPE), and R-squared ( $$\varvec{R}^{\varvec{2}}$$ ) on a test set. Results demonstrate that the CatBoost model outperforms the others with an MSE of 353.55, MAPE of 0.246% and $$\varvec{R}^{\varvec{2}}$$ of 0.796, highlighting its superior prediction accuracy in estimating film thickness. However, the integrated tree model used in this study is complex, and its prediction results cannot be directly interpreted, making the model less credible. To address this issue, the SHAP method was introduced for interpretable analysis of the model. Overall, this study shows that the use of machine learning models, such as the CatBoost model, combined with SHAP analysis, significantly improves the credibility of prediction results on deposited film thickness in IC fabrication. Moreover, the timely adjustment of production equipment parameters can be achieved to reduce process deviations and improve IC yield.},
  archive      = {J_APIN},
  author       = {Shi, Yumeng and Cai, Yu and Lou, Shunyuan and Chen, Yining},
  doi          = {10.1007/s10489-023-05121-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {246-263},
  shortjournal = {Appl. Intell.},
  title        = {Explainable prediction of deposited film thickness in IC fabrication with CatBoost and SHapley additive exPlanations (SHAP) models},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating grid features and geometric coordinates for
enhanced image captioning. <em>APIN</em>, <em>54</em>(1), 231–245. (<a
href="https://doi.org/10.1007/s10489-023-05198-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of image captioning is to provide precise descriptions of depicted objects and their relationships. To perform this task, previous studies have mainly relied on region features or a combination of these features and geometric coordinates. However, a significant limitation of these methods is their failure to incorporate grid features and their geometric coordinates, resulting in captions that inadequately identify object-related information within the global context. To overcome this limitation, we employ Swin Transformer and Deformable DETR to extract new grid and region features, along with their respective coordinates. Subsequently, we integrate the geometric coordinates of grids and regions into their corresponding features and incorporate grid features into the region features. The previously obtained features in the encoder are then used to generate text in the decoder. Through quantitative and qualitative analysis of the experimental results, our novel features and caption model have demonstrated superiority over previous methods. Specifically, our approach achieves superior inference accuracy on the COCO and Nocaps image captioning benchmarks. Compared to the baseline method, our model exhibits a 4.3% improvement, reaching a score of 136.9 on the CIDEr evaluation metric.},
  archive      = {J_APIN},
  author       = {Zhao, Fengzhi and Yu, Zhezhou and Zhao, He and Wang, Tao and Bai, Tian},
  doi          = {10.1007/s10489-023-05198-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {231-245},
  shortjournal = {Appl. Intell.},
  title        = {Integrating grid features and geometric coordinates for enhanced image captioning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic filter pruning algorithm for image classification.
<em>APIN</em>, <em>54</em>(1), 216–230. (<a
href="https://doi.org/10.1007/s10489-023-05207-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network pruning is an essential technique for compressing and accelerating convolutional neural networks (CNNs). Existing pruning algorithms primarily evaluate filter importance or similarity, and then remove unimportant filters or keep only one similar filter at each convolutional layer based on a global pruning ratio. These methods, ignoring the sensitivity of pruning among different convolutional layers, rely on a lot of manual experience and multiple experiments to obtain the optimal convolutional neural network structure. To this end, we propose an automatic filter pruning algorithm via feature map average similarity and reverse search genetic algorithm(RSGA), dubbed as AFPruner, which automatically searches for the optimal combination of pruning ratio for all convolutional layers, evaluates filter similarity by feature map average similarity and then prunes similarity filter. Our method is evaluated against several state-of-the-art CNNs on three different classification datasets, and the experimental results show that our algorithm outperforms most current network pruning algorithms.},
  archive      = {J_APIN},
  author       = {Xue, Yifan and Yao, Wangshu and Peng, Siyuan and Yao, Shiyou},
  doi          = {10.1007/s10489-023-05207-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {216-230},
  shortjournal = {Appl. Intell.},
  title        = {Automatic filter pruning algorithm for image classification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weight-adaptive channel pruning for CNNs based on
closeness-centrality modeling. <em>APIN</em>, <em>54</em>(1), 201–215.
(<a href="https://doi.org/10.1007/s10489-023-05164-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network pruning provides significant performance in reducing the resource requirements for deploying deep convolutional models. Recent pruning techniques concentrate on eliminating less important or redundant channels from the network. However, these well-designed methods conflict in some situations. For example, some filters are important in importance-based methods but may be regarded as redundant in similarity-based methods. So, the correctness of some existing methods is questionable. In this paper, a novel pruning approach, entitled weight-adaptive channel pruning (WACP), is presented to address the problem. Our approach takes full advantage of the feature similarity information instead of simply categorizing the similarity feature as redundant. Specifically, we first reveal that there is a stable similarity relationship between different output features, independent of the batch size of input images. Then, based on the similarity information, we propose a weight-adaptive compensation strategy to minimize the performance loss caused by pruning. Moreover, we design a novel channel pruning algorithm that determines which features should be retained from a set of similar features by introducing the closeness centrality of graph theory. Extensive and targeted experiments have demonstrated the validity of our proposed WACP for compressing networks. The comparison results demonstrate that the WACP achieves state-of-the-art performance on several benchmark networks and datasets, even for a very high compression rate. For example, WACP improves accuracy by 0.46% while reducing FLOPs by 52.2% and parameters by 43.5% with ResNet-56 on CIFAR-10. For ResNet-50 on ImageNet, WACP prunes more than 55% of FLOPs with only a 0.70%/0.42% decline in top-1/top-5 accuracy. The codes are at https://github.com/lsianke/WACP .},
  archive      = {J_APIN},
  author       = {Dong, Zhao and Duan, Yuanzhi and Zhou, Yue and Duan, Shukai and Hu, Xiaofang},
  doi          = {10.1007/s10489-023-05164-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {201-215},
  shortjournal = {Appl. Intell.},
  title        = {Weight-adaptive channel pruning for CNNs based on closeness-centrality modeling},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hierarchical learning based artificial bee colony
algorithm for numerical global optimization and its applications.
<em>APIN</em>, <em>54</em>(1), 169–200. (<a
href="https://doi.org/10.1007/s10489-023-05202-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Artificial Bee Colony algorithm (ABC) is a swarm intelligence algorithm inspired by honey bee harvesting behavior. It boasts the benefits of minimal parameters and strong exploration capabilities. However, the ABC algorithm is still susceptible to local optima entrapment and lacks consideration of selection probability in the onlooker bee phase, leading to reduced convergence accuracy in later search stages. To address these issues, this paper introduces an enhanced ABC algorithm called Hierarchical Learning-based Artificial Bee Colony (HLABC). Initially, a hierarchical learning approach is devised, dividing the entire population into distinct layers based on solution quality. In this hierarchical approach, bees at lower layers can access much better advantageous information from higher layers. Secondly, the exploitation ability of onlooker bees is enhanced through novel strategies designed based on hierarchical learning. Thirdly, the exploration ability of scout bees is strengthened by implementing an opposition-based learning method. To evaluate the performance of the proposed algorithm, 69 benchmark functions from four benchmark suites (CEC2005, CEC2010, CEC2013 and CEC2022) are used to test the performance of HLABC, along with five variants of the ABC algorithm, The experimental statistical results show that the HLABC algorithm outperforms the ABC algorithm on all test problems with an average winning rate of 89%. Furthermore, to validate the performance of the HLABC algorithm in real-world optimization problems, this paper applies the HLABC algorithm to two practical applications: the deployment of wireless sensor networks (WSNs), the power scheduling problem in a smart home (PSPSH) and the multi-thresholding image segmentation (MIS). The experimental and statistical results demonstrate that HLABC is an efficient and stable optimizer. It shows better or comparable performance compared to other ABC variants when considering the quality of solutions for a suite of benchmark problems and real-world optimization problems. These findings affirm the effectiveness and versatility of the HLABC algorithm in addressing both theoretical and practical optimization challenges.},
  archive      = {J_APIN},
  author       = {Zhang, Qingke and Bu, Xianglong and Gao, Hao and Li, Tianqi and Zhang, Huaxiang},
  doi          = {10.1007/s10489-023-05202-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {169-200},
  shortjournal = {Appl. Intell.},
  title        = {A hierarchical learning based artificial bee colony algorithm for numerical global optimization and its applications},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection based on multi-perspective entropy of
mixing uncertainty measure in variable-granularity rough set.
<em>APIN</em>, <em>54</em>(1), 147–168. (<a
href="https://doi.org/10.1007/s10489-023-05194-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood rough set is an important model in feature selection. However, it only determines the granularity of the neighborhood from a feature perspective, while ignoring the influence of sample distribution on the granularity of the neighborhood. Moreover, the use of single and monotonic uncertainty measures limits its ability to obtain high-quality features in complex and large-scale data, as well as perform feature selection for high-dimensional data. To address these issues, we propose several improvements. Firstly, we construct a sample space state function to evaluate the influence of sample distribution on the granularity of the samples. Based on the state of the sample space, we then propose four perspectives of variable-granularity neighborhoods and define the upper and lower approximations for these neighborhoods. Additionally, we define the dependence of variable-granularity neighborhoods and the positive regions from an algebraic perspective. These definitions together form a comprehensive variable-granularity rough set model that can automatically adjust the granularity size according to the sample distribution and select high-quality features. Secondly, in order to comprehensively assess the uncertainty of data, we introduce the information and algebraic perspectives. We propose a multi-perspective mixed entropy measure in the variable-granularity rough set framework. Thirdly, to avoid the problem of selecting redundant features caused by using a monotonic evaluation function in classical neighborhood rough set feature selection algorithms, we propose a non-monotonic feature selection algorithm based on the individual perspective of samples and the mixed entropy measures of the variable-granularity rough set. Finally, to overcome the high time complexity of feature selection on high-dimensional data, we introduce Fish-Score as a preliminary dimensionality reduction technique. Experimental results on eleven datasets and using fifteen algorithms demonstrate that our method not only improves classification accuracy but also effectively reduces the number of features.},
  archive      = {J_APIN},
  author       = {Xu, Jiucheng and Zhou, Changshun and Xu, Shihui and Zhang, Lei and Han, Ziqin},
  doi          = {10.1007/s10489-023-05194-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {147-168},
  shortjournal = {Appl. Intell.},
  title        = {Feature selection based on multi-perspective entropy of mixing uncertainty measure in variable-granularity rough set},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). Task recommendation based on user preferences and user-task
matching in mobile crowdsensing. <em>APIN</em>, <em>54</em>(1), 131–146.
(<a href="https://doi.org/10.1007/s10489-023-05208-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile crowdsensing, the sensing platform recruits users to complete large-scale sensing tasks cooperatively. In order to guarantee the quality of sensing tasks, the platform needs to recommend suitable tasks to users. Existing task recommendation methods typically focus on unilateral factors, such as user preferences or task quality, leading to low platform utility and task acceptance rate respectively. To solve the above issue, this paper proposes a task recommendation method which takes both user preferences and user-task matching into consideration. Firstly, we apply the Deep Interest Network (DIN) in the context of mobile crowdsensing to recommend tasks according to user preferences. Secondly, the concept of user-task matching is introduced, in which both the task difficulty and the user reliability are taken into account. Finally, we propose task recommendation algorithms and conduct extensive experiments on a real dataset. The experimental results show that the proposed method can not only improve the utility of the platform significantly, but also improve the recommendation accuracy slightly under longer recommendation list.},
  archive      = {J_APIN},
  author       = {Li, Xiaolin and Zhang, Lichen and Zhou, Meng and Bian, Kexin},
  doi          = {10.1007/s10489-023-05208-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {131-146},
  shortjournal = {Appl. Intell.},
  title        = {Task recommendation based on user preferences and user-task matching in mobile crowdsensing},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On evaluation trials in speaker verification. <em>APIN</em>,
<em>54</em>(1), 113–130. (<a
href="https://doi.org/10.1007/s10489-023-05071-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation trials are crucial to measure performance of speaker verification systems. However, the design of trials that can faithfully reflect system performance and accurately distinguish between different systems remains an open issue. In this paper, we focus on a particular problem: the impact of trials that are easy to solve for the majority of systems. We show that these ‘easy trials’ not only report over-optimistic absolute performance, but also lead to biased relative performance in system comparisons when they are asymmetrically distributed. This motivated the idea of mining ‘hard trials’, i.e., trials that are regarded to be difficult by current representative techniques. Three approaches to retrieving hard trials will be reported, and the properties of the retrieved hard trials are studied, from the perspectives of both machines and humans. Finally, a novel visualization tool which we name a Config-Performance (C-P) map is proposed. In this map, the value at each location represents the performance with a particular proportion of easy and hard trials, thus offering a global view of the system in various test conditions. The identified hard trials and the code of the C-P map tool have been released at http://lilt.cslt.org/trials/demo/ .},
  archive      = {J_APIN},
  author       = {Li, Lantian and Wang, Di and Abel, Andrew and Wang, Dong},
  doi          = {10.1007/s10489-023-05071-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {113-130},
  shortjournal = {Appl. Intell.},
  title        = {On evaluation trials in speaker verification},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RELight: A random ensemble reinforcement learning based
method for traffic light control. <em>APIN</em>, <em>54</em>(1), 95–112.
(<a href="https://doi.org/10.1007/s10489-023-05197-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic lights are crucial for urban traffic management, as they significantly impact congestion reduction and travel safety. Traditional methods relying on hand-crafted rules and operator experience are limited in their ability to adapt to changing traffic environments. To address this challenge, we have been exploring intelligent traffic light control using deep reinforcement learning techniques. However, current approaches often suffer from inadequate training data and unstable training processes, leading to suboptimal performance and real-world consequences. In this study, we propose RELight, a novel random ensemble reinforcement learning-based traffic light control framework. RELight effectively utilizes collected empirical data, ensuring a stable and efficient training process. To evaluate the performance of our proposed framework, we conducted a comprehensive set of experiments on a variety of datasets, including four synthetic datasets and a real traffic dataset collected from surveillance cameras at an intersection in Hangzhou, China. The results show that RELight outperforms existing approaches, demonstrating its superiority and potential for practical traffic light control applications.},
  archive      = {J_APIN},
  author       = {Huang, Jianbin and Tan, Qinglin and Qi, Ruijie and Li, He},
  doi          = {10.1007/s10489-023-05197-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {95-112},
  shortjournal = {Appl. Intell.},
  title        = {RELight: A random ensemble reinforcement learning based method for traffic light control},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel xi’an drum music generation method based on bi-LSTM
deep reinforcement learning. <em>APIN</em>, <em>54</em>(1), 80–94. (<a
href="https://doi.org/10.1007/s10489-023-05195-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese Folk Drum music is an excellent traditional cultural resource, it has brilliant historical and cultural heritage and excellent traditional cultural connotation. However, the survey found that the social and cultural values, tourism economic values, and national self-confidence embodied in folk drum music, such as Xi&#39;an drum music, are far from being released, and even its own inheritance and development are facing difficulties. The research focuses on the automatic generation of Xi&#39;an drum music, with the aim of further inheriting, developing, and utilizing this exceptional traditional cultural resource. While Artificial Intelligence (AI) music generation has gained popularity in recent years, most platforms primarily focus on modern music rather than Chinese folk music. To address these issues and the unique challenges faced by Xi&#39;an drum music, this paper proposes a Bi-LSTM network-based deep reinforcement learning model. The model incorporates the distinctive characteristics of ancient Chinese music, such as pitch, chord, and mode, and utilizes the Actor-Critic algorithm in reinforcement learning. During the simulation generation stage, an improved method of generating strategies through reward and punishment scores is introduced. Additionally, the model takes into account abstract concept constraints, such as chord progression and music theory rules, which are translated into computer language. By constructing a chord reward mechanism and a music principle reward mechanism, the model achieves harmony constraints and enables the systematic generation of drum music. Experimental results demonstrate that the proposed model, based on Bi-LSTM deep reinforcement learning, can generate Xi&#39;an drum music with high quality and artistic aesthetics. This research contributes to the preservation, development, and utilization of Xi&#39;an drum music, leveraging advancements in AI music generation technology.},
  archive      = {J_APIN},
  author       = {Li, Peng and Liang, Tian-mian and Cao, Yu-mei and Wang, Xiao-ming and Wu, Xiao-jun and Lei, Lin-yi},
  doi          = {10.1007/s10489-023-05195-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {80-94},
  shortjournal = {Appl. Intell.},
  title        = {A novel xi’an drum music generation method based on bi-LSTM deep reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Empowering precision medicine: AI-driven schizophrenia
diagnosis via EEG signals: A comprehensive review from 2002–2023.
<em>APIN</em>, <em>54</em>(1), 35–79. (<a
href="https://doi.org/10.1007/s10489-023-05155-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schizophrenia (SZ) is a prevalent mental disorder characterized by cognitive, emotional, and behavioral changes. Symptoms of SZ include hallucinations, illusions, delusions, lack of motivation, and difficulties in concentration. While the exact causes of SZ remain unproven, factors such as brain injuries, stress, and psychotropic drugs have been implicated in its development. SZ can be classified into different types, including paranoid, disorganized, catatonic, undifferentiated, and residual. Diagnosing SZ involves employing various tools, including clinical interviews, physical examinations, psychological evaluations, the Diagnostic and Statistical Manual of Mental Disorders (DSM), and neuroimaging techniques. Electroencephalography (EEG) recording is a significant functional neuroimaging modality that provides valuable insights into brain function during SZ. However, EEG signal analysis poses challenges for neurologists and scientists due to the presence of artifacts, long-term recordings, and the utilization of multiple channels. To address these challenges, researchers have introduced artificial intelligence (AI) techniques, encompassing conventional machine learning (ML) and deep learning (DL) methods, to aid in SZ diagnosis. This study reviews papers focused on SZ diagnosis utilizing EEG signals and AI methods. The introduction section provides a comprehensive explanation of SZ diagnosis methods and intervention techniques. Subsequently, review papers in this field are discussed, followed by an introduction to the AI methods employed for SZ diagnosis and a summary of relevant papers presented in tabular form. Additionally, this study reports on the most significant challenges encountered in SZ diagnosis, as identified through a review of papers in this field. Future directions to overcome these challenges are also addressed. The discussion section examines the specific details of each paper, culminating in the presentation of conclusions and findings.},
  archive      = {J_APIN},
  author       = {Jafari, Mahboobeh and Sadeghi, Delaram and Shoeibi, Afshin and Alinejad-Rokny, Hamid and Beheshti, Amin and García, David López and Chen, Zhaolin and Acharya, U. Rajendra and Gorriz, Juan M.},
  doi          = {10.1007/s10489-023-05155-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {35-79},
  shortjournal = {Appl. Intell.},
  title        = {Empowering precision medicine: AI-driven schizophrenia diagnosis via EEG signals: a comprehensive review from 2002–2023},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time prediction of gas flow dynamics in diesel engines
using a deep neural operator framework. <em>APIN</em>, <em>54</em>(1),
14–34. (<a href="https://doi.org/10.1007/s10489-023-05178-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this work is to address the need for fast and accurate models for analyzing transient gas flow dynamics in diesel engines. We employ a neural operator-based surrogate model, called DeepONet, to learn and predict the transient gas flow dynamics in real-time. The neural operator maps the relationship between engine control stimulus, namely engine speed, fuel injection per cycle, EGR, and VGT valve openings with seven output states that include intake and exhaust manifold pressures, residual gas fraction inside the cylinder, as well as the dynamics of the EGR and VGT actuators. To establish a benchmark, we compare results from the DeepONet model to a mean-value gas flow engine model simulated with Simulink. We observe a maximum relative $$\mathcal L_2$$ error of $$6.5\%$$ , a reasonable accuracy for transient dynamics. The DeepONet model also exhibits good robustness to noisy input functions. Additionally, to evaluate the epistemic uncertainty in our model predictions, we adopt a mean ensemble approach, yielding a worst-case error of $$12\%$$ at a standard deviation of $$2\sigma $$ from the mean value. In summary, our proposed framework offers real-time prediction capabilities and facilitates data-driven learning of complex input-output operator mappings. This makes the DeepONet surrogate particularly useful for preliminary analyses of system dynamics, control system optimization, and health monitoring of sub-systems.},
  archive      = {J_APIN},
  author       = {Kumar, Varun and Goswami, Somdatta and Smith, Daniel and Karniadakis, George Em},
  doi          = {10.1007/s10489-023-05178-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {14-34},
  shortjournal = {Appl. Intell.},
  title        = {Real-time prediction of gas flow dynamics in diesel engines using a deep neural operator framework},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Safe optimal robust control of nonlinear systems with
asymmetric input constraints using reinforcement learning.
<em>APIN</em>, <em>54</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10489-023-05184-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {External disturbances and asymmetric input constraints may cause a major problem to the optimal control of the system. Aiming at such problem, this article presents a safe and optimal robust control method based on adaptive dynamic programming (ADP) to ensure the system operated in a safe region and with the optimal performance. Initially, a novel nonquadratic form cost function is imported for the system to address the asymmetric input constraints. Then, to ensure the safety of the system, a control barrier function (CBF) is appended to the cost function to penalize the unsafe behavior. And a damping factor is also introduced to the CBF to balance safety and optimality. Finally, one single critic network is utilized to simplify the complex computational steps, which is different from the traditional actor-critic networks to address the Hamilton-Jacobi-Bellman Equation (HJBE) for obtaining the optimal neural controller. Additionally, based on Lyapunov method, all signals in the closed-loop system are proven to be uniformly ultimately bounded (UUB). At last, the experimental results confirm the effectiveness of the designed approach.},
  archive      = {J_APIN},
  author       = {Zhang, Dehua and Wang, Yuchen and Jiang, Kaijun and Liang, Linlin},
  doi          = {10.1007/s10489-023-05184-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Safe optimal robust control of nonlinear systems with asymmetric input constraints using reinforcement learning},
  volume       = {54},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
