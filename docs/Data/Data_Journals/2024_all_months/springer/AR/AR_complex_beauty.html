<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ar---30">AR - 30</h2>
<ul>
<li><details>
<summary>
(2024). Optical flow-based control for micro air vehicles: An
efficient data-driven incremental nonlinear dynamic inversion approach.
<em>AR</em>, <em>48</em>(8), 1–17. (<a
href="https://doi.org/10.1007/s10514-024-10174-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an innovative approach for optical flow-based control of micro air vehicles (MAVs), addressing challenges inherent in the nonlinearity of optical flow observables. The proposed incremental nonlinear dynamic inversion (INDI) control scheme employs an efficient data-driven approach to directly estimate the inverse of the time-varying INDI control effectiveness in real-time. This method eliminates the constant effectiveness assumption typically made by traditional INDI methods and reduces the computational burden associated with inverting this variable at each time step. It effectively handles rapidly changing system dynamics, often encountered in optical flow-based control, particularly height-dependent control variables. Stability analysis of the proposed control scheme is conducted, and its robustness and efficiency are demonstrated through both numerical simulations and real-world flight tests. These tests include multiple landings of an MAV on a static, flat surface with several different tracking setpoints, as well as hovering and landings on moving and undulating surfaces. Despite the challenges posed by noisy optical flow estimates and lateral or vertical movements of the landing surfaces, the MAV successfully tracks or lands on the surface with an exponential decay of both height and vertical velocity almost simultaneously, aligning with the desired performance.},
  archive      = {J_AR},
  author       = {Ho, Hann Woei and Zhou, Ye and Feng, Yiting and de Croon, Guido C. H. E.},
  doi          = {10.1007/s10514-024-10174-4},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {Optical flow-based control for micro air vehicles: An efficient data-driven incremental nonlinear dynamic inversion approach},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered integrated task and motion planning
for process-aware source seeking. <em>AR</em>, <em>48</em>(8), 1–20. (<a
href="https://doi.org/10.1007/s10514-024-10177-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process-aware source seeking (PASS) problem in flow fields aims to find an informative trajectory to reach an unknown source location while taking the energy consumption in the flow fields into consideration. Taking advantage of the dynamic flow field partition technique, this paper formulates this problem as a task and motion planning (TAMP) problem and proposes a bi-level hierarchical planning framework to decouple the planning of inter-region transition and inner-region trajectory by introducing inter-region junctions. An integrated strategy is developed to enable efficient upper-level planning by investigating the optimal solution of the lower-level planner. In order to leverage the information acquisition and computational burden, a dynamic event-triggered mechanism is introduced to enable asynchronized estimation, region partitioning and re-plans. The proposed algorithm provides guaranteed convergence of the trajectory, and achieves automatic trade-offs of both exploration-exploitation and accuracy-efficiency. Simulations in a highly complicated and realistic ocean surface flow field validate the merits of the proposed algorithm, which demonstrates a significant reduction in computational burden without compromising planning optimality.},
  archive      = {J_AR},
  author       = {Li, Yingke and Hou, Mengxue and Zhou, Enlu and Zhang, Fumin},
  doi          = {10.1007/s10514-024-10177-1},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-20},
  shortjournal = {Auton. Robot.},
  title        = {Dynamic event-triggered integrated task and motion planning for process-aware source seeking},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Continuous planning for inertial-aided systems. <em>AR</em>,
<em>48</em>(8), 1–15. (<a
href="https://doi.org/10.1007/s10514-024-10180-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inertial-aided systems require continuous motion excitation among other reasons to characterize the measurement biases that will enable accurate integration required for localization frameworks. This paper proposes the use of informative path planning to find the best trajectory for minimizing the uncertainty of IMU biases and an adaptive traces method to guide the planner towards trajectories that aid convergence. The key contribution is a novel regression method based on Gaussian Process (GP) to enforce continuity and differentiability between waypoints from a variant of the $$\hbox {RRT}^*$$ planning algorithm. We employ linear operators applied to the GP kernel function to infer not only continuous position trajectories, but also velocities and accelerations. The use of linear functionals enable velocity and acceleration constraints given by the IMU measurements to be imposed on the position GP model. The results from both simulation and real-world experiments show that planning for IMU bias convergence helps minimize localization errors in state estimation frameworks.},
  archive      = {J_AR},
  author       = {Usayiwevu, Mitchell and Sukkar, Fouad and Yoo, Chanyeol and Fitch, Robert and Vidal-Calleja, Teresa},
  doi          = {10.1007/s10514-024-10180-6},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-15},
  shortjournal = {Auton. Robot.},
  title        = {Continuous planning for inertial-aided systems},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A concurrent learning approach to monocular vision range
regulation of leader/follower systems. <em>AR</em>, <em>48</em>(8),
1–15. (<a href="https://doi.org/10.1007/s10514-024-10178-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores range and bearing angle regulation of a leader–follower using monocular vision. The main challenge is that monocular vision does not directly provide a range measurement. The contribution is a novel concurrent learning (CL) approach, called CL Subtended Angle and Bearing Estimator for Relative pose (CL-SABER), which achieves range regulation without communication, persistency of excitation or known geometry and is demonstrated on a physical, robot platform. A history stack estimates target size which augments the Kalman filter (KF) with a range pseudomeasurement. The target is followed to scale without drift, persistency of excitation requirements, prior knowledge, or additional measurements. Finite excitation is required to achieve parameter convergence and perform steady-state regulation using CL-SABER. Evaluation using simulation and mobile robot experiments in special Euclidean planar space (SE(2)) show that the new method provides stable and consistent range regulation, as demonstrated by the inter-rater reliability, including in noisy and high leader acceleration environments.},
  archive      = {J_AR},
  author       = {Fairfax, Luisa and Vela, Patricio},
  doi          = {10.1007/s10514-024-10178-0},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-15},
  shortjournal = {Auton. Robot.},
  title        = {A concurrent learning approach to monocular vision range regulation of leader/follower systems},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: Planning under uncertainty for safe robot
exploration using gaussian process prediction. <em>AR</em>,
<em>48</em>(8), 1. (<a
href="https://doi.org/10.1007/s10514-024-10181-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  author       = {Stephens, Alex and Budd, Matthew and Staniaszek, Michal and Casseau, Benoit and Duckworth, Paul and Fallon, Maurice and Hawes, Nick and Lacerda, Bruno},
  doi          = {10.1007/s10514-024-10181-5},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1},
  shortjournal = {Auton. Robot.},
  title        = {Correction: Planning under uncertainty for safe robot exploration using gaussian process prediction},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal policies for autonomous navigation in strong
currents using fast marching trees. <em>AR</em>, <em>48</em>(8), 1–19.
(<a href="https://doi.org/10.1007/s10514-024-10179-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several applications require that unmanned vehicles, such as UAVs and AUVs, navigate environmental flows. While the flow can improve the vehicle’s efficiency when directed towards the goal, it may also cause feasibility problems when it is against the desired motion and is too strong to be counteracted by the vehicle. This paper proposes the flow-aware fast marching tree algorithm (FlowFMT*) to solve the optimal motion planning problem in generic three-dimensional flows. Our method creates either an optimal path from start to goal or, with a few modifications, a vector field-based policy that guides the vehicle from anywhere in its workspace to the goal. The basic idea of the proposed method is to replace the original neighborhood set used by FMT* with two sets that consider the reachability from/to each sampled position in the space. The new neighborhood sets are computed considering the flow and the maximum speed of the vehicle. Numerical results that compare our methods with the state-of-the-art optimal control solver illustrate the simplicity and correctness of the method.},
  archive      = {J_AR},
  author       = {Martinez Rocamora Jr., Bernardo and Pereira, Guilherme A. S.},
  doi          = {10.1007/s10514-024-10179-z},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-19},
  shortjournal = {Auton. Robot.},
  title        = {Optimal policies for autonomous navigation in strong currents using fast marching trees},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BFAR: Improving radar odometry estimation using a bounded
false alarm rate detector. <em>AR</em>, <em>48</em>(8), 1–16. (<a
href="https://doi.org/10.1007/s10514-024-10176-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces a novel detector, bounded false-alarm rate (BFAR), for distinguishing true detections from noise in radar data, leading to improved accuracy in radar odometry estimation. Scanning frequency-modulated continuous wave (FMCW) radars can serve as valuable tools for localization and mapping under low visibility conditions. However, they tend to yield a higher level of noise in comparison to the more commonly employed lidars, thereby introducing additional challenges to the detection process. We propose a new radar target detector called BFAR which uses an affine transformation of the estimated noise level compared to the classical constant false-alarm rate (CFAR) detector. This transformation employs learned parameters that minimize the error in odometry estimation. Conceptually, BFAR can be viewed as an optimized blend of CFAR and fixed-level thresholding designed to minimize odometry estimation error. The strength of this approach lies in its simplicity. Only a single parameter needs to be learned from a training dataset when the affine transformation scale parameter is maintained. Compared to ad-hoc detectors, BFAR has the advantage of a specified upper-bound for the false-alarm probability, and better noise handling than CFAR. Repeatability tests show that BFAR yields highly repeatable detections with minimal redundancy. We have conducted simulations to compare the detection and false-alarm probabilities of BFAR with those of three baselines in non-homogeneous noise and varying target sizes. The results show that BFAR outperforms the other detectors. Moreover, We apply BFAR to the use case of radar odometry, and adapt a recent odometry pipeline, replacing its original conservative filtering with BFAR. In this way, we reduce the translation/rotation odometry errors/100 m from 1.3%/0.4 $$^\circ $$ to 1.12%/0.38 $$^\circ $$ , and from 1.62%/0.57 $$^\circ $$ to 1.21%/0.32 $$^\circ $$ , improving translation error by 14.2% and 25% on Oxford and Mulran public data sets, respectively.},
  archive      = {J_AR},
  author       = {Alhashimi, Anas and Adolfsson, Daniel and Andreasson, Henrik and Lilienthal, Achim and Magnusson, Martin},
  doi          = {10.1007/s10514-024-10176-2},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-16},
  shortjournal = {Auton. Robot.},
  title        = {BFAR: Improving radar odometry estimation using a bounded false alarm rate detector},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SAR: Generalization of physiological agility and dexterity
via synergistic action representation. <em>AR</em>, <em>48</em>(8),
1–21. (<a href="https://doi.org/10.1007/s10514-024-10182-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning effective continuous control policies in high-dimensional systems, including musculoskeletal agents, remains a significant challenge. Over the course of biological evolution, organisms have developed robust mechanisms for overcoming this complexity to learn highly sophisticated strategies for motor control. What accounts for this robust behavioral flexibility? Modular control via muscle synergies, i.e. coordinated muscle co-contractions, is considered to be one putative mechanism that enables organisms to learn muscle control in a simplified and generalizable action space. Drawing inspiration from this evolved motor control strategy, we use physiologically accurate human hand and leg models as a testbed for determining the extent to which a Synergistic Action Representation (SAR) acquired from simpler tasks facilitates learning and generalization on more complex tasks. We find in both cases that SAR-exploiting policies significantly outperform end-to-end reinforcement learning. Policies trained with SAR were able to achieve robust locomotion on a diverse set of terrains (e.g., stairs, hills) with state-of-the-art sample efficiency (4 M total steps), while baseline approaches failed to learn any meaningful behaviors under the same training regime. Additionally, policies trained with SAR on in-hand 100-object manipulation task significantly outperformed (&gt;70% success) baseline approaches (&lt;20% success). Both SAR-exploiting policies were also found to generalize zero-shot to out-of-domain environmental conditions, while policies that did not adopt SAR failed to generalize. Finally, using a simulated robotic hand and humanoid agent, we establish the generality of SAR on broader high-dimensional control problems, solving tasks with greatly improved sample efficiency. To the best of our knowledge, this investigation is the first of its kind to present an end-to-end pipeline for discovering synergies and using this representation to learn high-dimensional continuous control across a wide diversity of tasks. Project website: https://sites.google.com/view/sar-rl},
  archive      = {J_AR},
  author       = {Berg, Cameron and Caggiano, Vittorio and Kumar, Vikash},
  doi          = {10.1007/s10514-024-10182-4},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-21},
  shortjournal = {Auton. Robot.},
  title        = {SAR: Generalization of physiological agility and dexterity via synergistic action representation},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multirotor nonlinear model predictive control based on
visual servoing of evolving features. <em>AR</em>, <em>48</em>(8), 1–22.
(<a href="https://doi.org/10.1007/s10514-024-10183-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a Visual Servoing Nonlinear Model Predictive Control (NMPC) scheme for autonomously tracking a moving target using multirotor Unmanned Aerial Vehicles (UAVs). The scheme is developed for surveillance and tracking of contour-based areas with evolving features. NMPC is used to manage input and state constraints, while additional barrier functions are incorporated in order to ensure system safety and optimal performance. The proposed control scheme is designed based on the extraction and implementation of the full dynamic model of the features describing the target and the state variables. Real-time simulations and experiments using a quadrotor UAV equipped with a camera demonstrate the effectiveness of the proposed strategy.},
  archive      = {J_AR},
  author       = {Aspragkathos, Sotirios N. and Rousseas, Panagiotis and Karras, George C. and Kyriakopoulos, Kostas J.},
  doi          = {10.1007/s10514-024-10183-3},
  journal      = {Autonomous Robots},
  month        = {12},
  number       = {8},
  pages        = {1-22},
  shortjournal = {Auton. Robot.},
  title        = {Multirotor nonlinear model predictive control based on visual servoing of evolving features},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). R <span class="math display">×</span> r: Rapid eXploration
for reinforcement learning via sampling-based reset distributions and
imitation pre-training. <em>AR</em>, <em>48</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10514-024-10170-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method for enabling Reinforcement Learning of motor control policies for complex skills such as dexterous manipulation. We posit that a key difficulty for training such policies is the difficulty of exploring the problem state space, as the accessible and useful regions of this space form a complex structure along manifolds of the original high-dimensional state space. This work presents a method to enable and support exploration with Sampling-based Planning. We use a generally applicable non-holonomic Rapidly-exploring Random Trees algorithm and present multiple methods to use the resulting structure to bootstrap model-free Reinforcement Learning. Our method is effective at learning various challenging dexterous motor control skills of higher difficulty than previously shown. In particular, we achieve dexterous in-hand manipulation of complex objects while simultaneously securing the object without the use of passive support surfaces. These policies also transfer effectively to real robots. A number of example videos can also be found on the project website: sbrl.cs.columbia.edu},
  archive      = {J_AR},
  author       = {Khandate, Gagan and Saidi, Tristan L. and Shang, Siqi and Chang, Eric T. and Liu, Yang and Dennis, Seth and Adams, Johnson and Ciocarlie, Matei},
  doi          = {10.1007/s10514-024-10170-8},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Auton. Robot.},
  title        = {R $$\times $$ r: Rapid eXploration for reinforcement learning via sampling-based reset distributions and imitation pre-training},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ASAPs: Asynchronous hybrid self-reconfiguration algorithm
for porous modular robotic structures. <em>AR</em>, <em>48</em>(7),
1–16. (<a href="https://doi.org/10.1007/s10514-024-10171-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programmable matter refers to material that can be programmed to alter its physical properties, including its shape. Such matter can be built as a lattice of attached robotic modules, each seen as an autonomous agent with communication and motion capabilities. Self-reconfiguration consists in changing the initial arrangement of modules to form a desired goal shape, and is known to be a complex problem due to its algorithmic complexity and motion constraints. In this paper, we propose to use a max-flow algorithm as a centralized global planner to determine the concurrent paths to be traversed by modules through a porous structure composed of 3D Catoms meta-modules with the aim of increasing the parallelism of motions, and hence decreasing the self-reconfiguration time. We implement a traffic light system as a distributed asynchronous local planning algorithm to control the motions to avoid collisions. We evaluated our algorithm using VisibleSim simulator on different self-reconfiguration scenarios and compared the performance with an existing fully distributed synchronous self-reconfiguration algorithm for similar structures. The results show that the new method provides a significant gain in self-reconfiguration time and energy efficiency.},
  archive      = {J_AR},
  author       = {Bassil, Jad and Piranda, Benoît and Makhoul, Abdallah and Bourgeois, Julien},
  doi          = {10.1007/s10514-024-10171-7},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Auton. Robot.},
  title        = {ASAPs: Asynchronous hybrid self-reconfiguration algorithm for porous modular robotic structures},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Planning under uncertainty for safe robot exploration using
gaussian process prediction. <em>AR</em>, <em>48</em>(7), 1–29. (<a
href="https://doi.org/10.1007/s10514-024-10172-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploration of new environments is a crucial challenge for mobile robots. This task becomes even more complex with the added requirement of ensuring safety. Here, safety refers to the robot staying in regions where the values of certain environmental conditions (such as terrain steepness or radiation levels) are within a predefined threshold. We consider two types of safe exploration problems. First, the robot has a map of its workspace, but the values of the environmental features relevant to safety are unknown beforehand and must be explored. Second, both the map and the environmental features are unknown, and the robot must build a map whilst remaining safe. Our proposed framework uses a Gaussian process to predict the value of the environmental features in unvisited regions. We then build a Markov decision process that integrates the Gaussian process predictions with the transition probabilities of the environmental model. The Markov decision process is then incorporated into an exploration algorithm that decides which new region of the environment to explore based on information value, predicted safety, and distance from the current position of the robot. We empirically evaluate the effectiveness of our framework through simulations and its application on a physical robot in an underground environment.},
  archive      = {J_AR},
  author       = {Stephens, Alex and Budd, Matthew and Staniaszek, Michal and Casseau, Benoit and Duckworth, Paul and Fallon, Maurice and Hawes, Nick and Lacerda, Bruno},
  doi          = {10.1007/s10514-024-10172-6},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1-29},
  shortjournal = {Auton. Robot.},
  title        = {Planning under uncertainty for safe robot exploration using gaussian process prediction},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging the reality gap in drone swarm development through
mixed reality. <em>AR</em>, <em>48</em>(7), 1–11. (<a
href="https://doi.org/10.1007/s10514-024-10169-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm algorithms promise to solve certain problems in large multi-robot systems. The evaluation of large swarms is however challenging as simulations alone often lack some properties of real systems whereas real-world experiments are costly and complex. We present a mixed reality (MR) system that connects simulated and physical robots though a 5G network, facilitating MR experiments to evaluate communication-based swarm algorithms. The effectiveness of the system is demonstrated through extensive experiments with unmanned aerial vehicles. Measurements show that the communication requirements of swarm coordination are well met by 5G but the computing power of the simulation server can be a bottleneck. However, even when the simulation slows down, communication and coordination take place in real time. In conclusion, 5G-enabled MR experiments are a feasible tool for bridging the reality gap in the development and evaluation of robot swarms.},
  archive      = {J_AR},
  author       = {Sende, Micha and Raffelsberger, Christian and Bettstetter, Christian},
  doi          = {10.1007/s10514-024-10169-1},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1-11},
  shortjournal = {Auton. Robot.},
  title        = {Bridging the reality gap in drone swarm development through mixed reality},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual asymmetric limit surfaces and their applications to
planar manipulation. <em>AR</em>, <em>48</em>(7), 1–15. (<a
href="https://doi.org/10.1007/s10514-024-10173-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present models and planning algorithms to slide an object on a planar surface via frictional patch contact made with its top surface, whether the surface is horizontal or inclined. The core of our approach is the asymmetric dual limit surfaces model that determines slip boundary conditions for both the top and support patch contacts made with the object. This model enables us to compute a range of twists that can keep the object in sticking contact with the robot end-effector while slipping on the supporting plane. Based on these constraints, we derive a planning algorithm to slide objects with only top contact to arbitrary goal poses without slippage between end effector and the object. We fit the proposed model and demonstrate its predictive accuracy on a variety of object geometries and motions. We also evaluate the planning algorithm over a variety of objects and goals, demonstrating an orientation error improvement of 90% when compared to methods naive to linear path planners. For more results and information, please visit https://www.mmintlab.com/dual-limit-surfaces/ .},
  archive      = {J_AR},
  author       = {Yi, Xili and Dang, An and Fazeli, Nima},
  doi          = {10.1007/s10514-024-10173-5},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Auton. Robot.},
  title        = {Dual asymmetric limit surfaces and their applications to planar manipulation},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TIP: A trust inference and propagation model in multi-human
multi-robot teams. <em>AR</em>, <em>48</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10514-024-10175-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust is a crucial factor for effective human–robot teaming. Existing literature on trust modeling predominantly focuses on dyadic human-autonomy teams where one human agent interacts with one robot. There is little, if not no, research on trust modeling in teams consisting of multiple human and robotic agents. To fill this important research gap, we present the Trust Inference and Propagation (TIP) model to model and estimate human trust in multi-human multi-robot teams. In a multi-human multi-robot team, we postulate that there exist two types of experiences that a human agent has with a robot: direct and indirect experiences. The TIP model presents a novel mathematical framework that explicitly accounts for both types of experiences. To evaluate the model, we conducted a human-subject experiment with 15 pairs of participants ( $$N=30$$ ). Each pair performed a search and detection task with two drones. Results show that our TIP model successfully captured the underlying trust dynamics and significantly outperformed a baseline model. To the best of our knowledge, the TIP model is the first mathematical framework for computational trust modeling in multi-human multi-robot teams.},
  archive      = {J_AR},
  author       = {Guo, Yaohui and Yang, X. Jessie and Shi, Cong},
  doi          = {10.1007/s10514-024-10175-3},
  journal      = {Autonomous Robots},
  month        = {10},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Auton. Robot.},
  title        = {TIP: A trust inference and propagation model in multi-human multi-robot teams},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formal design, verification and implementation of robotic
controller software via RoboChart and RoboTool. <em>AR</em>,
<em>48</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10514-024-10163-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current practice in simulation and implementation of robot controllers is usually undertaken with guidance from high-level design diagrams and pseudocode. Thus, no rigorous connection between the design and the development of a robot controller is established. This paper presents a framework for designing robotic controllers with support for automatic generation of executable code and automatic property checking. A state-machine based notation, RoboChart, and a tool (RoboTool) that implements the automatic generation of code and mathematical models from the designed controllers are presented. We demonstrate the application of RoboChart and its related tool through a case study of a robot performing an exploration task. The automatically generated code is platform independent and is used in both simulation and two different physical robotic platforms. Properties are formally checked against the mathematical models generated by RoboTool, and further validated in the actual simulations and physical experiments. The tool not only provides engineers with a way of designing robotic controllers formally but also paves the way for correct implementation of robotic systems.},
  archive      = {J_AR},
  author       = {Li, Wei and Ribeiro, Pedro and Miyazawa, Alvaro and Redpath, Richard and Cavalcanti, Ana and Alden, Kieran and Woodcock, Jim and Timmis, Jon},
  doi          = {10.1007/s10514-024-10163-7},
  journal      = {Autonomous Robots},
  month        = {8},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Auton. Robot.},
  title        = {Formal design, verification and implementation of robotic controller software via RoboChart and RoboTool},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Active velocity estimation using light curtains via
self-supervised multi-armed bandits. <em>AR</em>, <em>48</em>(6), 1–23.
(<a href="https://doi.org/10.1007/s10514-024-10168-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To navigate in an environment safely and autonomously, robots must accurately estimate where obstacles are and how they move. Instead of using expensive traditional 3D sensors, we explore the use of a much cheaper, faster, and higher resolution alternative: programmable light curtains. Light curtains are a controllable depth sensor that sense only along a surface that the user selects. We adapt a probabilistic method based on particle filters and occupancy grids to explicitly estimate the position and velocity of 3D points in the scene using partial measurements made by light curtains. The central challenge is to decide where to place the light curtain to accurately perform this task. We propose multiple curtain placement strategies guided by maximizing information gain and verifying predicted object locations. Then, we combine these strategies using an online learning framework. We propose a novel self-supervised reward function that evaluates the accuracy of current velocity estimates using future light curtain placements. We use a multi-armed bandit framework to intelligently switch between placement policies in real time, outperforming fixed policies. We develop a full-stack navigation system that uses position and velocity estimates from light curtains for downstream tasks such as localization, mapping, path-planning, and obstacle avoidance. This work paves the way for controllable light curtains to accurately, efficiently, and purposefully perceive and navigate complex and dynamic environments.},
  archive      = {J_AR},
  author       = {Ancha, Siddharth and Pathak, Gaurav and Zhang, Ji and Narasimhan, Srinivasa and Held, David},
  doi          = {10.1007/s10514-024-10168-2},
  journal      = {Autonomous Robots},
  month        = {8},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Auton. Robot.},
  title        = {Active velocity estimation using light curtains via self-supervised multi-armed bandits},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning based autonomous multi-rotor landing
on moving platforms. <em>AR</em>, <em>48</em>(4), 1–21. (<a
href="https://doi.org/10.1007/s10514-024-10162-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-rotor UAVs suffer from a restricted range and flight duration due to limited battery capacity. Autonomous landing on a 2D moving platform offers the possibility to replenish batteries and offload data, thus increasing the utility of the vehicle. Classical approaches rely on accurate, complex and difficult-to-derive models of the vehicle and the environment. Reinforcement learning (RL) provides an attractive alternative due to its ability to learn a suitable control policy exclusively from data during a training procedure. However, current methods require several hours to train, have limited success rates and depend on hyperparameters that need to be tuned by trial-and-error. We address all these issues in this work. First, we decompose the landing procedure into a sequence of simpler, but similar learning tasks. This is enabled by applying two instances of the same RL based controller trained for 1D motion for controlling the multi-rotor’s movement in both the longitudinal and the lateral directions. Second, we introduce a powerful state space discretization technique that is based on i) kinematic modeling of the moving platform to derive information about the state space topology and ii) structuring the training as a sequential curriculum using transfer learning. Third, we leverage the kinematics model of the moving platform to also derive interpretable hyperparameters for the training process that ensure sufficient maneuverability of the multi-rotor vehicle. The training is performed using the tabular RL method Double Q-Learning. Through extensive simulations we show that the presented method significantly increases the rate of successful landings, while requiring less training time compared to other deep RL approaches. Furthermore, for two comparison scenarios it achieves comparable performance than a cascaded PI controller. Finally, we deploy and demonstrate our algorithm on real hardware. For all evaluation scenarios we provide statistics on the agent’s performance. Source code is openly available at https://github.com/robot-perception-group/rl_multi_rotor_landing .},
  archive      = {J_AR},
  author       = {Goldschmid, Pascal and Ahmad, Aamir},
  doi          = {10.1007/s10514-024-10162-8},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Auton. Robot.},
  title        = {Reinforcement learning based autonomous multi-rotor landing on moving platforms},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guiding real-world reinforcement learning for in-contact
manipulation tasks with shared control templates. <em>AR</em>,
<em>48</em>(4), 1–17. (<a
href="https://doi.org/10.1007/s10514-024-10164-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The requirement for a high number of training episodes has been a major limiting factor for the application of Reinforcement Learning (RL) in robotics. Learning skills directly on real robots requires time, causes wear and tear and can lead to damage to the robot and environment due to unsafe exploratory actions. The success of learning skills in simulation and transferring them to real robots has also been limited by the gap between reality and simulation. This is particularly problematic for tasks involving contact with the environment as contact dynamics are hard to model and simulate. In this paper we propose a framework which leverages a shared control framework for modeling known constraints defined by object interactions and task geometry to reduce the state and action spaces and hence the overall dimensionality of the reinforcement learning problem. The unknown task knowledge and actions are learned by a reinforcement learning agent by conducting exploration in the constrained environment. Using a pouring task and grid-clamp placement task (similar to peg-in-hole) as use cases and a 7-DoF arm, we show that our approach can be used to learn directly on the real robot. The pouring task is learned in only 65 episodes (16 min) and the grid-clamp placement task is learned in 75 episodes (17 min) with strong safety guarantees and simple reward functions, greatly alleviating the need for simulation.},
  archive      = {J_AR},
  author       = {Padalkar, Abhishek and Quere, Gabriel and Raffin, Antonin and Silvério, João and Stulp, Freek},
  doi          = {10.1007/s10514-024-10164-6},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {4},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {Guiding real-world reinforcement learning for in-contact manipulation tasks with shared control templates},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Laplacian regularized motion tomography for underwater
vehicle flow mapping with sporadic localization measurements.
<em>AR</em>, <em>48</em>(4), 1–16. (<a
href="https://doi.org/10.1007/s10514-024-10165-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization measurements for an autonomous underwater vehicle (AUV) are often difficult to obtain. In many cases, localization measurements are only available sporadically after the AUV comes to the sea surface. Since the motion of AUVs is often affected by unknown underwater flow fields, the sporadic localization measurements carry information of the underwater flow field. Motion tomography (MT) algorithms have been developed to compute a underwater flow map based on the sporadic localization measurements. This paper extends MT by introducing Laplacian regularization in to the problem formulation and the MT algorithm. Laplacian regularization enforces smoothness in the spatial distribution of the underwater flow field. The resulted Laplacian regularized motion tomography (RMT) algorithm converges to achieve a finite error bounded. The performance of the RMT and other variants of MT are compared through the method of data resolution analysis. The improved performance of RMT is confirmed by experimental data collected from underwater glider ocean sensing experiments.},
  archive      = {J_AR},
  author       = {Meriam, Ouerghi and Mengxue, Hou and Fumin, Zhang},
  doi          = {10.1007/s10514-024-10165-5},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {4},
  pages        = {1-16},
  shortjournal = {Auton. Robot.},
  title        = {Laplacian regularized motion tomography for underwater vehicle flow mapping with sporadic localization measurements},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneously learning intentions and preferences during
physical human-robot cooperation. <em>AR</em>, <em>48</em>(4), 1–21. (<a
href="https://doi.org/10.1007/s10514-024-10167-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of collaborative robots allows humans and robots to cooperate in a direct and physical way. While this leads to amazing new opportunities to create novel robotics applications, it is challenging to make the collaboration intuitive for the human. From a system’s perspective, understanding the human intentions seems to be one promising way to get there. However, human behavior exhibits large variations between individuals, such as for instance preferences or physical abilities. This paper presents a novel concept for simultaneously learning a model of the human intentions and preferences incrementally during collaboration with a robot. Starting out with a nominal model, the system acquires collaborative skills step-by-step within only very few trials. The concept is based on a combination of model-based reinforcement learning and inverse reinforcement learning, adapted to fit collaborations in which human and robot think and act independently. We test the method and compare it to two baselines: one that imitates the human and one that uses plain maximum entropy inverse reinforcement learning, both in simulation and in a user study with a Franka Emika Panda robot arm.},
  archive      = {J_AR},
  author       = {van der Spaa, Linda and Kober, Jens and Gienger, Michael},
  doi          = {10.1007/s10514-024-10167-3},
  journal      = {Autonomous Robots},
  month        = {7},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Auton. Robot.},
  title        = {Simultaneously learning intentions and preferences during physical human-robot cooperation},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Adaptive hybrid local–global sampling for fast informed
sampling-based optimal path planning. <em>AR</em>, <em>48</em>(2), 1–12.
(<a href="https://doi.org/10.1007/s10514-024-10157-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper improves the performance of RRT $$^*$$ -like sampling-based path planners by combining admissible informed sampling and local sampling (i.e., sampling the neighborhood of the current solution). An adaptive strategy regulates the trade-off between exploration (admissible informed sampling) and exploitation (local sampling) based on online rewards from previous samples. The paper demonstrates that the algorithm is asymptotically optimal and has a better convergence rate than state-of-the-art path planners (e.g., Informed-RRT $$^*$$ ) in several simulated and real-world scenarios. An open-source, ROS-compatible implementation of the algorithm is publicly available.},
  archive      = {J_AR},
  author       = {Faroni, Marco and Pedrocchi, Nicola and Beschi, Manuel},
  doi          = {10.1007/s10514-024-10157-5},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Auton. Robot.},
  title        = {Adaptive hybrid local–global sampling for fast informed sampling-based optimal path planning},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Terrain traversability prediction through self-supervised
learning and unsupervised domain adaptation on synthetic data.
<em>AR</em>, <em>48</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s10514-024-10158-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Terrain traversability estimation is a fundamental task for supporting robot navigation on uneven surfaces. Recent learning-based approaches for predicting traversability from RGB images have shown promising results, but require manual annotation of a large number of images for training. To address this limitation, we present a method for traversability estimation on unlabeled videos that combines dataset synthesis, self-supervision and unsupervised domain adaptation. We pose the traversability estimation as a vector regression task over vertical bands of the observed frame. The model is pre-trained through self-supervision to reduce the distribution shift between synthetic and real data and encourage shared feature learning. Then, supervised training on synthetic videos is carried out, while employing an unsupervised domain adaptation loss to improve its generalization capabilities on real scenes. Experimental results show that our approach is on par with standard supervised training, and effectively supports robot navigation without the need of manual annotations. Training code and synthetic dataset will be publicly released at: https://github.com/perceivelab/traversability-synth .},
  archive      = {J_AR},
  author       = {Vecchio, Giuseppe and Palazzo, Simone and Guastella, Dario C. and Giordano, Daniela and Muscato, Giovanni and Spampinato, Concetto},
  doi          = {10.1007/s10514-024-10158-4},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Auton. Robot.},
  title        = {Terrain traversability prediction through self-supervised learning and unsupervised domain adaptation on synthetic data},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The human in the loop perspectives and challenges for
RoboCup 2050. <em>AR</em>, <em>48</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s10514-024-10159-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics researchers have been focusing on developing autonomous and human-like intelligent robots that are able to plan, navigate, manipulate objects, and interact with humans in both static and dynamic environments. These capabilities, however, are usually developed for direct interactions with people in controlled environments, and evaluated primarily in terms of human safety. Consequently, human-robot interaction (HRI) in scenarios with no intervention of technical personnel is under-explored. However, in the future, robots will be deployed in unstructured and unsupervised environments where they will be expected to work unsupervised on tasks which require direct interaction with humans and may not necessarily be collaborative. Developing such robots requires comparing the effectiveness and efficiency of similar design approaches and techniques. Yet, issues regarding the reproducibility of results, comparing different approaches between research groups, and creating challenging milestones to measure performance and development over time make this difficult. Here we discuss the international robotics competition called RoboCup as a benchmark for the progress and open challenges in AI and robotics development. The long term goal of RoboCup is developing a robot soccer team that can win against the world’s best human soccer team by 2050. We selected RoboCup because it requires robots to be able to play with and against humans in unstructured environments, such as uneven fields and natural lighting conditions, and it challenges the known accepted dynamics in HRI. Considering the current state of robotics technology, RoboCup’s goal opens up several open research questions to be addressed by roboticists. In this paper, we (a) summarise the current challenges in robotics by using RoboCup development as an evaluation metric, (b) discuss the state-of-the-art approaches to these challenges and how they currently apply to RoboCup, and (c) present a path for future development in the given areas to meet RoboCup’s goal of having robots play soccer against and with humans by 2050.},
  archive      = {J_AR},
  author       = {Rossi, Alessandra and Paetzel-Prüsmann, Maike and Keijsers, Merel and Anderson, Michael and Anderson, Susan Leigh and Barry, Daniel and Gutsche, Jan and Hart, Justin and Iocchi, Luca and Kokkelmans, Ainse and Kuijpers, Wouter and Liu, Yun and Polani, Daniel and Roscon, Caleb and Scheunemann, Marcus and Stone, Peter and Vahl, Florian and van de Molengraft, René and von Stryk, Oskar},
  doi          = {10.1007/s10514-024-10159-3},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Auton. Robot.},
  title        = {The human in the loop perspectives and challenges for RoboCup 2050},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforcement learning with imitative behaviors for humanoid
robots navigation: Synchronous planning and control. <em>AR</em>,
<em>48</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10514-024-10160-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots have strong adaptability to complex environments and possess human-like flexibility, enabling them to perform precise farming and harvesting tasks in varying depths of terrains. They serve as essential tools for agricultural intelligence. In this article, a novel method was proposed to improve the robustness of autonomous navigation for humanoid robots, which intercommunicates the data fusion of the footprint planning and control levels. In particular, a deep reinforcement learning model - Proximal Policy Optimization (PPO) that has been fine-tuned is introduced into this layer, before which heuristic trajectory was generated based on imitation learning. In the RL period, the KL divergence between the agent’s policy and imitative expert policy as a value penalty is added to the advantage function. As a proof of concept, our navigation policy is trained in a robotic simulator and then successfully applied to the physical robot GTX for indoor multi-mode navigation. The experimental results conclude that incorporating imitation learning imparts anthropomorphic attributes to robots and facilitates the generation of seamless footstep patterns. There is a significant improvement in ZMP trajectory in y-direction from the center by 21.56% is noticed. Additionally, this method improves dynamic locomotion stability, the body attitude angle falling between less than ± 5.5 $$^\circ $$ compared to ± 48.4 $$^\circ $$ with traditional algorithm. In general, navigation error is below 5 cm, which we verified in the experiments. It is thought that the outcome of the proposed framework presented in this article can provide a reference for researchers studying autonomous navigation applications of humanoid robots on uneven ground.},
  archive      = {J_AR},
  author       = {Wang, Xiaoying and Zhang, Tong},
  doi          = {10.1007/s10514-024-10160-w},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {Reinforcement learning with imitative behaviors for humanoid robots navigation: Synchronous planning and control},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editorial - robotics: Science and systems 2022. <em>AR</em>,
<em>48</em>(2), 1–2. (<a
href="https://doi.org/10.1007/s10514-024-10161-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  doi          = {10.1007/s10514-024-10161-9},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {2},
  pages        = {1-2},
  shortjournal = {Auton. Robot.},
  title        = {Editorial - robotics: Science and systems 2022},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: Adaptive hybrid local-global sampling for fast
informed sampling-based optimal path planning. <em>AR</em>,
<em>48</em>(2), 1. (<a
href="https://doi.org/10.1007/s10514-024-10166-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AR},
  author       = {Faroni, Marco and Pedrocchi, Nicola and Beschi, Manuel},
  doi          = {10.1007/s10514-024-10166-4},
  journal      = {Autonomous Robots},
  month        = {5},
  number       = {2},
  pages        = {1},
  shortjournal = {Auton. Robot.},
  title        = {Correction: Adaptive hybrid local-global sampling for fast informed sampling-based optimal path planning},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting the hospital by integrating mobile robotic
assistance systems: A comprehensive classification of the risks to be
addressed. <em>AR</em>, <em>48</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10514-023-10154-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile service robots are a promising technology for supporting workflows throughout the hospital. Combined with an understanding of the environment and the current situation, such systems have the potential to become invaluable tools for overcoming personal shortages and streamlining healthcare workflows. However, few robotic systems have actually been translated to practical application so far, which is due to many challenges centered around the strict and unique requirements imposed by the different hospital environments, which have not yet been collected and analyzed in a structured manner. To address this need, we now present a comprehensive classification of different dimensions of risk to be considered when designing mobile service robots for the hospital. Our classification consists of six risk categories – environmental complexity, hygienic requirements, interaction with persons and objects, workflow flexibility and autonomy – for each of which a scale with distinct risk levels is provided. This concept, for the first time allows for a precise classification of mobile service robots for the hospital, which can prove useful for certification and admission procedures as well as for defining architectural and safety requirements throughout the design process of such robots.},
  archive      = {J_AR},
  author       = {Bernhard, Lukas and Schwingenschlögl, Patrik and Hofmann, Jörg and Wilhelm, Dirk and Knoll, Alois},
  doi          = {10.1007/s10514-023-10154-0},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {Boosting the hospital by integrating mobile robotic assistance systems: A comprehensive classification of the risks to be addressed},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collocation methods for second and higher order systems.
<em>AR</em>, <em>48</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s10514-023-10155-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is often unnoticed that the predominant way to use collocation methods is fundamentally flawed when applied to optimal control in robotics. Such methods assume that the system dynamics is given by a first order ODE, whereas robots are often governed by a second or higher order ODE involving configuration variables and their time derivatives. To apply a collocation method, therefore, the usual practice is to resort to the well known procedure of casting an Mth order ODE into M first order ones. This manipulation, which in the continuous domain is perfectly valid, leads to inconsistencies when the problem is discretized. Since the configuration variables and their time derivatives are approximated with polynomials of the same degree, their differential dependencies cannot be fulfilled, and the actual dynamics is not satisfied, not even at the collocation points. This paper draws attention to this problem, and develops improved versions of the trapezoidal and Hermite–Simpson collocation methods that do not present these inconsistencies. In many cases, the new methods reduce the dynamics transcription error in one order of magnitude, or even more, without noticeably increasing the cost of computing the solutions.},
  archive      = {J_AR},
  author       = {Moreno-Martín, Siro and Ros, Lluís and Celaya, Enric},
  doi          = {10.1007/s10514-023-10155-z},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Auton. Robot.},
  title        = {Collocation methods for second and higher order systems},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximal coverage problems with routing constraints using
cross-entropy monte carlo tree search. <em>AR</em>, <em>48</em>(1),
1–22. (<a href="https://doi.org/10.1007/s10514-024-10156-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial search, and environmental monitoring are key technologies in robotics. These problems can be reformulated as maximal coverage problems with routing constraints, which are NP-hard problems. The generalized cost-benefit algorithm (GCB) can solve these problems with theoretical guarantees. To achieve better performance, evolutionary algorithms (EA) boost its performance via more samples. However, it is hard to know the terminal conditions of EA to outperform GCB. To solve these problems with theoretical guarantees and terminal conditions, in this research, the cross-entropy based Monte Carlo Tree Search algorithm (CE-MCTS) is proposed. It consists of three parts: the EA for sampling the branches, the upper confidence bound policy for selections, and the estimation of distribution algorithm for simulations. The experiments demonstrate that the CE-MCTS outperforms benchmark approaches (e.g., GCB, EAMC) in spatial search problems.},
  archive      = {J_AR},
  author       = {Lin, Pao-Te and Tseng, Kuo-Shih},
  doi          = {10.1007/s10514-024-10156-6},
  journal      = {Autonomous Robots},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Auton. Robot.},
  title        = {Maximal coverage problems with routing constraints using cross-entropy monte carlo tree search},
  volume       = {48},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
