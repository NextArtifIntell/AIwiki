<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJMLC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijmlc---353">IJMLC - 353</h2>
<ul>
<li><details>
<summary>
(2024). Solving the fuzzy p-hub center problem using imperialist
competitive algorithm. <em>IJMLC</em>, <em>15</em>(12), 6163–6183. (<a
href="https://doi.org/10.1007/s13042-024-02311-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The p-hub center location tries to minimize the maximum travel times by locating p hubs and allocating other nodes to these hub nodes. There is a wide application in various fields of study for the p-hub center problems, such as telecommunication and transportation systems. In the proposed fuzzy p-hub center problem (FPHCP) by Yang et al. (Yang et al. in Appl Soft Comput 13:2624–2632, 2013), a risk aversion PHCP is considered where travel times are trapezoidal fuzzy variables and value-at-risk criterion is the objective function. In the mentioned research, the original value-at-risk PHCP has turned into two equivalent mixed-integer linear programming models, and a genetic algorithm incorporating local search (GALS) has been applied to solve the equivalent mixed-integer linear programming models. Considering the properties of FPHCPs, the Imperialist competitive algorithm (ICA) incorporating edge recombination operator (ERO) and Elzinga-Hearn algorithm (EHA) is a more suitable method to solve FPHCPs proposed in the current study. The ICA, which uses assimilation and revolution operators, is an effective tool for solving hard combinational optimization problems. The ERO is applied for assimilation in the proposed ICA, an operator that creates a parent like a set of existing parents by looking at the edges. In addition, the EHA is applied for revolution in the proposed ICA, which maintains a covering circle for a subset of the points. We evaluated the performance of the exact method (EM), GALS, and ICA incorporating ERO and EHA by solving and comparing their accuracy and speed on 81 small-scale and large-scale FPHCP samples. Our experiments demonstrate that the proposed method achieves optimal solutions in solving all small-scale sample tests of FPHCPs. Also, it was faster than EM and GALS for solving these sample tests. Finding optimum solutions for large-scale FPHCP sample tests by EM was impossible due to the limitation of computational CPU time. In solving large-scale sample tests, ICA achieved significantly higher accuracy in a shorter time than GALS. So, results show that ICA outperformed EM and GALS in terms of accuracy and speed for solving all FPHCP sample tests.},
  archive      = {J_IJMLC},
  author       = {Abbasi, Mehdi and Sadough, Fatemeh and Mahmoudi, Amin},
  doi          = {10.1007/s13042-024-02311-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6163-6183},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Solving the fuzzy p-hub center problem using imperialist competitive algorithm},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint feature fusion hashing for cross-modal retrieval.
<em>IJMLC</em>, <em>15</em>(12), 6149–6162. (<a
href="https://doi.org/10.1007/s13042-024-02309-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing retrieval maps data from different modalities into a common low-dimensional hash code space, enabling fast and efficient retrieval. Recently, there has been a growing interest in the cross-modal hashing retrieval approach. Nonetheless, a significant number of current methodologies overlook the influence of semantically rich features on retrieval performance. In addition, class attribute embedding is often forgotten in cross-modal feature fusion, which is crucial for learning more discriminative hash codes. To meet these challenges, we put forward a novel method, namely joint feature fusion hashing (JFFH) for cross-modal retrieval. Specifically, we use the fast language image pre-training model as the feature coding module of cross-modal data. To more effectively mitigate semantic disparities between modalities, we introduce a multimodal contrastive learning loss to strengthen the interaction between modalities and improve the semantic representation of modalities. In addition, we extract class attribute features as class embedding and integrate them with cross-modal features to enhance the semantic relationship within the fused features. To better capture both inter-modal and intra-modal dependencies as well as semantic relevance, we integrate the self-attention mechanism into the multi-modal fusion transformer encoder to facilitate efficient feature fusion. Besides, we apply label-wise high-level semantic similarity and feature-wise low-level semantic similarity to enhance the discrimination of hash codes. Our JFFH method shows better retrieval performance in large-scale cross-modal retrieval.},
  archive      = {J_IJMLC},
  author       = {Cao, Yuxia},
  doi          = {10.1007/s13042-024-02309-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6149-6162},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Joint feature fusion hashing for cross-modal retrieval},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bi-objective feature selection in high-dimensional datasets
using improved binary chimp optimization algorithm. <em>IJMLC</em>,
<em>15</em>(12), 6107–6148. (<a
href="https://doi.org/10.1007/s13042-024-02308-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The machine learning process in high-dimensional datasets is far more complicated than in low-dimensional datasets. In high-dimensional datasets, Feature Selection (FS) is necessary to decrease the complexity of learning. However, FS in high-dimensional datasets is a complex process that requires the combination of several search techniques. The Chimp Optimization Algorithm, known as ChOA, is a new meta-heuristic method inspired by the chimps’ individual intellect and sexual incentive in cooperative hunting. It is basically employed in solving complex continuous optimization problems, while its binary version is frequently utilized in solving difficult binary optimization problems. Both versions of ChOA are subject to premature convergence and are incapable of effectively solving high-dimensional optimization problems. This paper proposes the Binary Improved ChOA Algorithm (BICHOA) for solving the bi-objective, high-dimensional FS problems (i.e., high-dimensional FS problems that aim to maximize the classifier’s accuracy and minimize the number of selected features from a dataset). BICHOA improves the performance of ChOA using four new exploration and exploitation techniques. First, it employs the opposition-based learning approach to initially create a population of diverse binary feasible solutions. Second, it incorporates the Lévy mutation function in the main probabilistic update function of ChOA to boost its searching and exploring capabilities. Third, it uses an iterative exploration technique based on an exploratory local search method called the $$\beta$$ -hill climbing algorithm. Finally, it employs a new binary time-varying transfer function to calculate binary feasible solutions from the continuous feasible solutions generated by the update equations of the ChOA and $$\beta$$ -hill climbing algorithms. BICHOA’s performance was assessed and compared against six machine learning classifiers, five integer programming methods, and nine efficient popular optimization algorithms using 25 real-world high-dimensional datasets from various domains. According to the overall experimental findings, BICHOA scored the highest accuracy, best objective value, and fewest selected features for each of the 25 real-world high-dimensional datasets. Besides, the reliability of the experimental findings was established using Friedman and Wilcoxon statistical tests.},
  archive      = {J_IJMLC},
  author       = {Al-qudah, Nour Elhuda A. and Abed-alguni, Bilal H. and Barhoush, Malek},
  doi          = {10.1007/s13042-024-02308-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6107-6148},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Bi-objective feature selection in high-dimensional datasets using improved binary chimp optimization algorithm},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Multi-source domain adaptation for dependency parsing via
domain-aware feature generation. <em>IJMLC</em>, <em>15</em>(12),
6093–6106. (<a
href="https://doi.org/10.1007/s13042-024-02306-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With deep representation learning advances, supervised dependency parsing has achieved a notable enhancement. However, when the training data is drawn from various predefined out-domains, the parsing performance drops sharply due to the domain distribution shift. The key to addressing this problem is to model the associations and differences between multiple source and target domains. In this work, we propose an innovative domain-aware adversarial and parameter generation network for multi-source cross-domain dependency parsing where a domain-aware parameter generation network is used for identifying domain-specific features and an adversarial network is used for learning domain-invariant ones. Experiments on the benchmark datasets reveal that our model outperforms strong BERT-enhanced baselines by 2 points in the average labeled attachment score (LAS). Detailed analysis of various domain representation strategies shows that our proposed distributed domain embedding can accurately capture domain relevance, which motivates the domain-aware parameter generation network to emphasize useful domain-specific representations and disregard unnecessary or even harmful ones. Additionally, extensive comparison experiments show deeper insights on the contributions of the two components.},
  archive      = {J_IJMLC},
  author       = {Li, Ying and Zhang, Zhenguo and Xian, Yantuan and Yu, Zhengtao and Gao, Shengxiang and Mao, Cunli and Huang, Yuxin},
  doi          = {10.1007/s13042-024-02306-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6093-6106},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-source domain adaptation for dependency parsing via domain-aware feature generation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extraction of entity relationships serving the field of
agriculture food safety regulation. <em>IJMLC</em>, <em>15</em>(12),
6077–6092. (<a
href="https://doi.org/10.1007/s13042-024-02304-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture food (agri-food) safety is closely related to all aspects of people&#39;s lives. In recent years, with the emergence of deep learning technology based on big data, the extraction of information relations in the field of agri-food safety supervision has become a research hotspot. However, most of the current work only expands the relationship recognition based on the traditional named entity recognition task, which makes it difficult to establish a true &#39;connection&#39; between entities and relationships. The pipelined and federated extraction architectures that have emerged in this area are problematic in practice. In addition, the contextual information of the text corpus in the agri-food safety regulatory domain has not been fully utilized. To address the above issues, this paper proposes a semi-joint entity relationship extraction model (EB-SJRE) based on contextual entity boundary features. Firstly, a Token pair subject-object correspondence matrix label is designed to intuitively model the subject-object boundary, which is more friendly to complex entities in the field of agri-food safety regulation. Secondly, the dynamic fine-tuning of Bert makes the text embedding more relevant to the textual context of the agri-food safety regulation domain. Finally, we introduce an attention mechanism in the Token pair tagging framework to capture deep semantic subject-object boundary association information, which cleverly solves the problem of bias exposure due to the pipeline structure and the dimensional explosion due to the joint extraction structure. The experimental results show that our model achieves the best F1-score of 88.71% on agri-food safety regulation domain data and F1-scores of 92.36%, 92.80%, 88.91%, and 92.21% on NYT, NYT-star, WebNLG, and WebNLG-star, respectively. This indicates that EB-SJRE has excellent generalization ability in both the agri-food safety regulatory and public sectors.},
  archive      = {J_IJMLC},
  author       = {Zhao, Zhihua and Liu, Yiming and Lv, Dongdong and Li, Ruixuan and Yu, Xudong and Mao, Dianhui},
  doi          = {10.1007/s13042-024-02304-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6077-6092},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Extraction of entity relationships serving the field of agriculture food safety regulation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiscale-integrated deep learning approaches for
short-term load forecasting. <em>IJMLC</em>, <em>15</em>(12), 6061–6076.
(<a href="https://doi.org/10.1007/s13042-024-02302-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term load forecasting (STLF) is crucial for the power system. Traditional methods generally used signal decomposition techniques for feature extraction. However, these methods are limited in extrapolation performance, and the parameter of decomposition modes needs to be preset. To end this, this paper develops a novel STLF algorithm based on multi-scale perspective decomposition. The proposed algorithm adopts the multi-scale deep neural network (MscaleDNN) to decompose load series into low- and high-frequency components. Considering outliers of load series, this paper introduces the adaptive rescaled lncosh (ARlncosh) loss to fit the distribution of load data and improve the robustness. Furthermore, the attention mechanism (ATTN) extracts the correlations between different moments. In two power load data sets from Portugal and Australia, the proposed model generates competitive forecasting results.},
  archive      = {J_IJMLC},
  author       = {Yang, Yang and Gao, Yuchao and Wang, Zijin and Li, Xi’an and Zhou, Hu and Wu, Jinran},
  doi          = {10.1007/s13042-024-02302-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6061-6076},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multiscale-integrated deep learning approaches for short-term load forecasting},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-indicator based multi-objective evolutionary algorithm
with application to neural architecture search. <em>IJMLC</em>,
<em>15</em>(12), 6049–6060. (<a
href="https://doi.org/10.1007/s13042-024-02300-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {$${\mathbf{I}}_{{\mathbf{SDE}}^{+}}$$ is proven to be one of the leading scalable indicator for evolutionary multi and many-objective optimization. However, it fails to segregate members of a given population beyond the first front as a large number of solutions in the population have identical $${\mathbf{I}}_{{\mathbf{SDE}}^{+}}$$ values. This mainly affects the performance of the algorithm when handling optimization problems with lower objectives. Consequently, we hypothesize that the overall performance of the algorithm can be further improved by introducing a categorization mechanism similar to the categorization of Pareto Fronts (PFs) in dominance-based methods. Therefore, in this work, we propose a Multi-Indicator-Based Multi-Objective Evolutionary Algorithm (MI-MOEA) which categorizes all the solutions into different fronts. Specifically, the indicators are based on the popular $${\mathbf{I}}_{{\mathbf{SDE}}^{+}}$$ indicator and make use of the minimum and median distance values among the different distances when the solutions with better Sum of Objectives (SOB) are projected. The use of these two $${\mathbf{I}}_{{\mathbf{SDE}}^{+}}$$ -based indicator values features an efficient balance of exploration and exploitation. To evaluate the performance of the proposed MI-MOEA, Neural Architecture Search (NAS) which involves the design of appropriate architectures suitable for specific applications is employed. From an optimization perspective, NAS involves multiple conflicting objectives that needs to be simultaneously optimized. In this paper, we consider a recently proposed multi-objective NAS benchmark and favorably evaluate the performance of MI-MOEA compared to other state-of-the-art MOEAs.},
  archive      = {J_IJMLC},
  author       = {Ajani, Oladayo S. and Darlan, Daison and Ivan, Dzeuban Fenyom and Mallipeddi, Rammohan},
  doi          = {10.1007/s13042-024-02300-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6049-6060},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-indicator based multi-objective evolutionary algorithm with application to neural architecture search},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment classification of movie reviews: A powerful method
based on ensemble of classifiers and features. <em>IJMLC</em>,
<em>15</em>(12), 6027–6048. (<a
href="https://doi.org/10.1007/s13042-024-02299-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the sentiment of movie reviews is crucial in the film industry, as it can inform movie recommendations and aid in the creation of successful films. However, existing sentiment classification methods still suffer from limitations in two key aspects: representation and classification. To this end, we propose a powerful method that improves sentiment classification in two ways. First, a new feature selection ensemble (FSE) approach is designed to enhance the representation by identifying the most informative subset of movie review features. Second, an improved meta-learning-based dynamic ensemble selection (META-DES) approach is proposed to enhance the sentiment identification process of the movie reviews. The experiments on several real-world datasets demonstrate the effectiveness of both FSE and dynamic ensemble selection in recognizing the sentiment of movie reviews. Moreover, the comparison results between the improved META-DES and existing state-of-the-art of sentiment classification also indicate the competitiveness of our approach for sentiment classification of movie reviews.},
  archive      = {J_IJMLC},
  author       = {Pei, Jian and Zhang, Zhong-Liang and Liu, Wan-An},
  doi          = {10.1007/s13042-024-02299-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6027-6048},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sentiment classification of movie reviews: A powerful method based on ensemble of classifiers and features},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Anchor-based domain adaptive hashing for unsupervised image
retrieval. <em>IJMLC</em>, <em>15</em>(12), 6011–6026. (<a
href="https://doi.org/10.1007/s13042-024-02298-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional image retrieval methods suffer from a significant performance degradation when the model is trained on the target dataset and run on another dataset. To address this issue, Domain Adaptive Retrieval (DAR) has emerged as a promising solution, specifically designed to overcome domain shifts in retrieval tasks. However, existing unsupervised DAR methods still face two primary limitations: (1) they under-explore the intrinsic structure among domains, resulting in limited generalization capabilities; and (2) the models are often too complex to be applied to large-scale datasets. To tackle these limitations, we propose a novel unsupervised DAR method named Anchor-based Domain Adaptive Hashing (ADAH). ADAH aims to exploit the commonalities among domains with the assumption that a consensus latent space exists for the source and target domains. To achieve this, an anchor-based similarity reconstruction scheme is proposed, which learns a set of domain-shared anchors and domain-specific anchor graphs, and then reconstructs the similarity matrix with these anchor graphs, thereby effectively exploiting inter- and intra-domain similarity structures. Subsequently, by treating the anchor graphs as feature embeddings, we solve the Distance-Distance Difference Minimization (DDDM) problem between them and their corresponding hash codes. This preserves the similarity structure of the similarity matrix in the hash code. Finally, a two-stage strategy is employed to derive the hash function, ensuring its effectiveness and scalability. Experimental results on four datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Chen, Yonghao and Fang, Xiaozhao and Liu, Yuanyuan and Hu, Xi and Han, Na and Kang, Peipei},
  doi          = {10.1007/s13042-024-02298-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {6011-6026},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Anchor-based domain adaptive hashing for unsupervised image retrieval},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved many-objective meta-heuristic adaptive
decomposition algorithm based on mutation individual position detection.
<em>IJMLC</em>, <em>15</em>(12), 5981–6010. (<a
href="https://doi.org/10.1007/s13042-024-02297-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial applications and optimization problems in reality often involve multiple objectives. Due to the high dimensionality of objective space in many-objective optimization problems (MaOPs), the ability of traditional evolution operators to search the optimal region and generate promising offspring sharply decreases. Besides, as the number of objectives increases, it becomes difficult to balance the convergence and diversity of the population. Considering all these facts, this paper proposes a mutation individual position detection strategy. It estimates both individual fitness and diversity contributions, and assigns appropriate positions to individuals in the mutation operator through individual ranking. Then, by introducing an external population to adjust the weight vectors, its maintenance process takes into account the matching information between the population and the weight vectors. By comparing five representative algorithms, numerical experiments have shown that the algorithm can obtain a well distributed final solution set on optimization problems of various objective scales. Moreover, it also demonstrates advantages in generating excellent offspring individuals and balancing the overall performance of the population. In summary, the algorithm has competitiveness in solving MaOPs.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jinlu and Wei, Lixin and Guo, Zeyin and Hu, Ziyu and Che, Haijun},
  doi          = {10.1007/s13042-024-02297-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5981-6010},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved many-objective meta-heuristic adaptive decomposition algorithm based on mutation individual position detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label distribution learning via second-order
self-representation. <em>IJMLC</em>, <em>15</em>(12), 5963–5979. (<a
href="https://doi.org/10.1007/s13042-024-02295-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning is an effective learning approach for addressing label polysemy in the field of machine learning. In contrast to multi-label learning, label distribution learning can accurately represent the relative importance of labels and has richer semantic information about labels. Presently label distribution learning algorithms frequently integrate label correlation into their models to narrow down the assumption space of the model. However, existing label distribution learning works on label correlation use one-to-one or many-to-one correlation which has limitations in representing more complex correlation relationships. To address this issue, we attempt to extend the existing correlation relationships to many-to-many relationships. Specifically, we first construct a many-to-many correlation mining framework based on self-representation. Then by using the learned many-to-many correlation, a label distribution learning algorithm is designed. Our algorithm achieved the best performance in $$78.21\%$$ of cases across all datasets and all performance metrics with the algorithm having the best average ranking. It also demonstrated statistical superiority compared to the comparison algorithms in pairwise two-tailed t-tests. This paper introduces a novel approach to representing and applying label correlations in label distribution learning. The exploitation of this new many-to-many correlation can enhance the representational capabilities of label distribution learning models.},
  archive      = {J_IJMLC},
  author       = {Yu, Peiqiu and Chen, Lei and Li, Weiwei and Jia, Xiuyi},
  doi          = {10.1007/s13042-024-02295-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5963-5979},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Label distribution learning via second-order self-representation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ETCGN: Entity type-constrained graph networks for
document-level relation extraction. <em>IJMLC</em>, <em>15</em>(12),
5949–5962. (<a
href="https://doi.org/10.1007/s13042-024-02293-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction aims at discerning semantic connections between entities within a given document. Compared with sentence-level relation extraction settings, the complexity of document-level relation extraction lies in necessitating models to exhibit the capability to infer semantic relations across multiple sentences. In this paper, we propose a novel model, named Entity Type-Constrained Graph Network (ETCGN). The proposed model utilizes a graph structure to capture intricate interactions among diverse mentions within the document. Moreover, it aggregates references to the same entity while integrating path-based reasoning mechanisms to deduce relations between entities. Furthermore, we present a novel constraint method that capitalizes on entity types to confine the scope of potential relations. Experimental results on two public dataset (DocRED and HacRED) show that our model outperforms a number of baselines and achieves state-of-the-art performance. Further analysis verifies the effectiveness of type-based constraints and path-based reasoning mechanisms. Our code is available at: https://github.com/yhx30/ETCGN .},
  archive      = {J_IJMLC},
  author       = {Yang, Hangxiao and Chen, Changpu and Zhang, Shaokai and Chen, Baiyang and Liu, Chang and Li, Qilin},
  doi          = {10.1007/s13042-024-02293-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5949-5962},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ETCGN: Entity type-constrained graph networks for document-level relation extraction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid intelligent optimization algorithm to select
discriminative genes from large-scale medical data. <em>IJMLC</em>,
<em>15</em>(12), 5921–5948. (<a
href="https://doi.org/10.1007/s13042-024-02292-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying disease-related genes is an ongoing study issue in biomedical analysis. Many research has recently presented various strategies for predicting disease-related genes. However, only a handful of them were capable of identifying or selecting relevant genes with a low computational burden. In order to tackle this issue, we introduce a new filter–wrapper-based gene selection (GS) method based on metaheuristic algorithms (MHAs) in conjunction with the k-nearest neighbors ( $${k{\hbox {-NN}}}$$ ) classifier. Specifically, we hybridize two MHAs, bat algorithm (BA) and JAYA algorithm (JA), embedded with perturbation as a new perturbation-based exploration strategy (PES), to obtain JAYA–bat algorithm (JBA). The fact that JBA outperforms 10 state-of-the-art GS methods on 12 high-dimensional microarray datasets (ranging from 2000 to 22,283 features or genes) is impressive. It is also noteworthy that relevant genes are first selected via a filter-based method called mutual information (MI), and then further optimized by JBA to select the near-optimal genes in a timely fashion. Comparing the performance analysis of 11 well-known original MHAs, including BA and JA, the proposed JBA achieves significantly better results with improvement rates of 12.36%, 12.45%, 97.88%, 9.84%, 12.45%, and 12.17% in terms of fitness, accuracy, gene selection ratio, precision, recall, and F1-score, respectively. The results of Wilcoxon’s signed-rank test at a significance level of $$\alpha =0.05$$ further validate the superiority of JBA over its peers on most of the datasets. The use of PES and the combination of BA and JA’s strengths appear to enhance JBA’s exploration and exploitation capabilities. This gives it a significant advantage in gene selection ratio, while also ensuring the highest classification accuracy and the lowest computational time among all competing algorithms. Thus, this research could potentially make a significant contribution to the field of biomedical analysis.},
  archive      = {J_IJMLC},
  author       = {Wang, Tao and Jia, LiYun and Xu, JiaLing and Gad, Ahmed G. and Ren, Hai and Salem, Ahmed},
  doi          = {10.1007/s13042-024-02292-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5921-5948},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid intelligent optimization algorithm to select discriminative genes from large-scale medical data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-stage emergency supplies procurement model based on
prospect multi-attribute three-way decision. <em>IJMLC</em>,
<em>15</em>(12), 5895–5919. (<a
href="https://doi.org/10.1007/s13042-024-02291-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency supply chain management has recently drawn growing attention of managers and researchers with frequent appearance of pandemics, disasters and safety accidents. Previous studies proposed methods for supplier selection and order allocation, while they cannot satisfy the demand for emergency supplies as emergency events bring many uncertainties and risks in supply chain disruption. To guarantee the efficiency in emergency supplies procurement, this work aims at putting forward a two-stage approach for emergency supplier selection and order allocation by use of three-way decision and fuzzy multi-objective optimization. Firstly, by considering the perceived utilities and perceived losses of purchasing process simultaneously, a prospect profit-based three-way decision model is established. Next, the prospect multi-attribute three-way decision model for emergency supplier selection is proposed, constructing the calculation approaches of thresholds, conditional probabilities as well as decision rules. Thirdly, inspired by perceived utilities and perceived losses of supplies purchasing, the utility-based objective function and loss-based objective function are introduced to multi-objective optimization model for order allocation. Finally, a real case of government emergency supplies procurement is discussed to show the applicability and effectiveness of the proposed approach. The final results of the proposed methodology show that it can effectively manage data with uncertainty, determine the qualified suppliers as well as alternative suppliers simultaneously to prevent emergency supply chain disruption, and provide satisfactory solutions for order allocation by introducing different combinations of objective functions according to decision makers’ preference.},
  archive      = {J_IJMLC},
  author       = {Jia, Fan and Wang, Yujie and Liu, Yuanyuan},
  doi          = {10.1007/s13042-024-02291-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5895-5919},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A two-stage emergency supplies procurement model based on prospect multi-attribute three-way decision},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A generalized tri-factorization method for accurate matrix
completion. <em>IJMLC</em>, <em>15</em>(12), 5881–5893. (<a
href="https://doi.org/10.1007/s13042-024-02289-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the speeds of the traditional nuclear norm minimization methods, a fast tri-factorization method (FTF) was recently proposed for matrix completion, and it received widespread attention in the fields of machine learning, image processing and signal processing. However, its low convergence accuracy became increasingly obvious, limiting its further application. To enhance the accuracy of FTF, a generalized tri-factorization method (GTF) is proposed in this paper. In GTF, the nuclear norm minimization model of FTF is improved to a novel $${{\varvec{L}}}_{1,{\varvec{p}}}$$ (0 &lt; p &lt; 2) norm minimization model that can be optimized very efficiently by using QR decomposition. Since the $${{\varvec{L}}}_{1,{\varvec{p}}}$$ norm is a tighter relaxation of the rank function than the nuclear norm, the GTF method is much more accurate than the traditional methods. The experimental results demonstrate that GTF is more accurate and faster than the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Liu, Qing and Wu, Hao and Zong, Yu and Liu, Zheng-Yu},
  doi          = {10.1007/s13042-024-02289-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5881-5893},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A generalized tri-factorization method for accurate matrix completion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual stream attention network for facial expression
recognition in the wild. <em>IJMLC</em>, <em>15</em>(12), 5863–5880. (<a
href="https://doi.org/10.1007/s13042-024-02287-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition (FER) is crucial for human-computer interaction and has achieved satisfactory results on lab-collected datasets. However, occlusion and head pose variation in the real world make FER extremely challenging due to facial information deficiency. This paper proposes a novel Dual Stream Attention Network (DSAN) for occlusion and head pose robust FER. Specifically, DSAN consists of a Global Feature Element-based Attention Network (GFE-AN) and a Multi-Feature Fusion-based Attention Network (MFF-AN). A sparse attention block and a feature recalibration loss designed in GFE-AN selectively emphasize feature elements meaningful for facial expression and suppress those unrelated to facial expression. And a lightweight local feature attention block is customized in MFF-AN to extract rich semantic information from different representation sub-spaces. In addition, DSAN takes into account computation overhead minimization when designing model architecture. Extensive experiments on public benchmarks demonstrate that the proposed DSAN outperforms the state-of-the-art methods with 89.70% on RAF-DB, 89.93% on FERPlus, 65.77% on AffectNet-7, 62.13% on AffectNet-8. Moreover, the parameter size of DSAN is only 11.33M, which is lightweight compared to most of the recent in-the-wild FER algorithms.},
  archive      = {J_IJMLC},
  author       = {Tang, Hui and Li, Yichang and Jin, Zhong},
  doi          = {10.1007/s13042-024-02287-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5863-5880},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A dual stream attention network for facial expression recognition in the wild},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep reinforcement learning control method guided by
RBF-ARX pseudo LQR. <em>IJMLC</em>, <em>15</em>(12), 5839–5861. (<a
href="https://doi.org/10.1007/s13042-024-02283-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the efficiency of deep reinforcement learning for complex systems is a challenging task. In this work, a model-based deep reinforcement learning method named as RBF-ARX (autoregressive model with exogenous inputs and Gaussian radial basis function network-style coefficients) model guided deep reinforcement learning algorithm (RBF-ARX GDRL) is proposed to facilitate the training of optimal controller for control task of continues system, in which RBF-ARX model-based pseudo linear quadratic regulator (PLQR) is introduced in the training process of deep reinforcement learning (DRL). The PLQR is designed based on RBF-ARX model and serves for policy training by providing a gradient component which guides the reinforcement learning in a semi-supervised manner. The actions generated from policy network and the PLQR are evaluated by state-action value networks, and based on those values an adaptive method is proposed to search for the direction and the step-size of policy updates in the training process. According to the relationship between episode return and policy parameters, an anchor-and-trial scheme is proposed to monotonously improve the policy. The training process and the simulation results on stabilizing the single stage inverted pendulum system show that, the proposed method facilitates the training process of the optimal controller applied to the system, and the trained controller achieves higher steady-state and transient performance in the step response experiments, and less energy consumption.},
  archive      = {J_IJMLC},
  author       = {Peng, Tianbo and Peng, Hui and Liu, Fang},
  doi          = {10.1007/s13042-024-02283-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5839-5861},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A deep reinforcement learning control method guided by RBF-ARX pseudo LQR},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mobile robot path planning based on multi-experience pool
deep deterministic policy gradient in unknown environment.
<em>IJMLC</em>, <em>15</em>(12), 5823–5837. (<a
href="https://doi.org/10.1007/s13042-024-02281-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The path planning for unmanned mobile robots has always been a crucial issue, especially in unknown environments. Reinforcement learning widely used in path planning due to its ability to learn from unknown environments. But, in unknown environments, deep reinforcement learning algorithms have problems such as long training time and instability. In this article, improvements have been made to the deep deterministic policy gradient algorithm (DDPG) to address the aforementioned issues. Firstly, the experience pool is divided into different experience pools based on the difference between adjacent states; Secondly, experience is collected from various experience pools in different proportions for training, enabling the robot to achieve good obstacle avoidance ability; Finally, by designing a guided reward function, the convergence speed of the algorithm has been improved, and the robot can find the target point faster. The algorithm has been tested in practice and simulation, and the results show that it can enable robots to complete path planning tasks in complex unknown environments.},
  archive      = {J_IJMLC},
  author       = {Wei, Linxin and Xu, Quanxing and Hu, Ziyu},
  doi          = {10.1007/s13042-024-02281-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5823-5837},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Mobile robot path planning based on multi-experience pool deep deterministic policy gradient in unknown environment},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). One-step graph-based multi-view clustering via specific and
unified nonnegative embeddings. <em>IJMLC</em>, <em>15</em>(12),
5807–5822. (<a
href="https://doi.org/10.1007/s13042-024-02280-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering techniques, especially spectral clustering methods, are quite popular today in the fields of machine learning and data science owing to the ever-growing diversity in data types and information sources. As the landscape of data continues to evolve, the need for advanced clustering approaches becomes increasingly crucial. In this context, the research in this study addresses the challenges posed by traditional multi-view spectral clustering techniques, offering a novel approach that simultaneously learns nonnegative embedding matrices and spectral embeddings. Moreover, the cluster label matrix, also known as the nonnegative embedding matrix, is split into two different types of matrices: (1) the shared nonnegative embedding matrix, which reflects the common cluster structure, (2) the individual nonnegative embedding matrices, which represent the unique cluster structure of each view. The proposed strategy allows us to effectively deal with noise and outliers in multiple views. The simultaneous optimization of the proposed model is solved efficiently with an alternating minimization scheme. The proposed method exhibits significant improvements, with an average accuracy enhancement of 4% over existing models, as demonstrated through extensive experiments on various real datasets. This highlights the efficacy of the approach in achieving superior clustering results.},
  archive      = {J_IJMLC},
  author       = {El Hajjar, Sally and Abdallah, Fahed and Omrani, Hichem and Chaaban, Alain Khaled and Arif, Muhammad and Alturki, Ryan and AlGhamdi, Mohammed J.},
  doi          = {10.1007/s13042-024-02280-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5807-5822},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {One-step graph-based multi-view clustering via specific and unified nonnegative embeddings},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Doublem-net: Multi-scale spatial pyramid pooling-fast and
multi-path adaptive feature pyramid network for UAV detection.
<em>IJMLC</em>, <em>15</em>(12), 5781–5805. (<a
href="https://doi.org/10.1007/s13042-024-02278-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) are extensively applied in military, rescue operations, and traffic detection fields, resulting from their flexibility, low cost, and autonomous flight capabilities. However, due to the drone’s flight height and shooting angle, the objects in aerial images are smaller, denser, and more complex than those in general images, triggering an unsatisfactory target detection effect. In this paper, we propose a model for UAV detection called DoubleM-Net, which contains multi-scale spatial pyramid pooling-fast (MS-SPPF) and Multi-Path Adaptive Feature Pyramid Network (MPA-FPN). DoubleM-Net utilizes the MS-SPPF module to extract feature maps of multiple receptive field sizes. Then, the MPA-FPN module first fuses features from every two adjacent scales, followed by a level-by-level interactive fusion of features. First, using the backbone network as the feature extractor, multiple feature maps of different scale ranges are extracted from the input image. Second, the MS-SPPF uses different pooled kernels to repeat multiple pooled operations at various scales to achieve rich multi-perceptive field features. Finally, the MPA-FPN module first incorporates semantic information between each adjacent two-scale layer. The top-level features are then passed back to the bottom level-by-level, and the underlying features are enhanced, enabling interaction and integration of features at different scales. The experimental results show that the mAP50-95 ratio of DoubleM-Net on the VisDrone dataset is 27.5%, and that of Doublem-Net on the DroneVehicle dataset in RGB and Infrared mode is 55.0% and 60.4%, respectively. Our model demonstrates excellent performance in air-to-ground image detection tasks, with exceptional results in detecting small objects.},
  archive      = {J_IJMLC},
  author       = {Li, Zhongxu and He, Qihan and Zhao, Hong and Yang, Wenyuan},
  doi          = {10.1007/s13042-024-02278-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5781-5805},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Doublem-net: Multi-scale spatial pyramid pooling-fast and multi-path adaptive feature pyramid network for UAV detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint features-guided linear transformer and CNN for
efficient image super-resolution. <em>IJMLC</em>, <em>15</em>(12),
5765–5780. (<a
href="https://doi.org/10.1007/s13042-024-02277-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating convolutional neural networks (CNNs) and transformers has notably improved lightweight single image super-resolution (SISR) tasks. However, existing methods lack the capability to exploit multi-level contextual information, and transformer computations inherently add quadratic complexity. To address these issues, we propose a Joint features-Guided Linear Transformer and CNN Network (JGLTN) for efficient SISR, which is constructed by cascading modules composed of CNN layers and linear transformer layers. Specifically, in the CNN layer, our approach employs an inter-scale feature integration module (IFIM) to extract critical latent information across scales. Then, in the linear transformer layer, we design a joint feature-guided linear attention (JGLA). It jointly considers adjacent and extended regional features, dynamically assigning weights to convolutional kernels for contextual feature selection. This process garners multi-level contextual information, which is used to guide linear attention for effective information interaction. Moreover, we redesign the method of computing feature similarity within the self-attention, reducing its computational complexity to linear. Extensive experiments shows that our proposal outperforms state-of-the-art models while balancing performance and computational costs.},
  archive      = {J_IJMLC},
  author       = {Wang, Bufan and Zhang, Yongjun and Long, Wei and Cui, Zhongwei},
  doi          = {10.1007/s13042-024-02277-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5765-5780},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Joint features-guided linear transformer and CNN for efficient image super-resolution},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy-preserving matrix factorization for recommendation
systems using gaussian mechanism and functional mechanism.
<em>IJMLC</em>, <em>15</em>(12), 5745–5763. (<a
href="https://doi.org/10.1007/s13042-024-02276-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building a recommendation system involves analyzing user data, which can potentially leak sensitive information about users. As shown in numerous recent works, anonymizing user data is not sufficient for preserving user privacy. Differential Privacy is a mathematically rigorous privacy guarantee that has been adopted by numerous corporations and government entities for preserving user privacy in such scenarios. Developing differentially private machine learning algorithms typically involve adding randomness into the algorithm pipeline, which evidently degrades the performance of the algorithm—giving raise to privacy-utility trade-off. Existing differentially private matrix factorization algorithms offer poor privacy-utility trade-off for use in practical systems. Motivated by this, we propose two differentially private matrix factorization algorithms for application in recommendation systems, which provide better privacy-utility trade-off compared to the existing approaches. Our first algorithm adopts the framework of noisy gradient descent using the Gaussian Mechanism, whereas our second algorithm extends the Functional Mechanism framework to incorporate it into matrix factorization. In both cases, we perform theoretical analysis of the privacy of the algorithms. Additionally, we employ Rényi differential privacy to analyze the algorithms for a tight characterization of the overall privacy loss. We perform extensive experiments on real data by varying relevant privacy, algorithm, and dataset parameters. We compare the performance of our proposed algorithms with existing non-private and differentially private algorithms, and demonstrate that our algorithms can provide utility close to that of the non-private algorithm while guaranteeing strict privacy, outperforming the existing approaches.},
  archive      = {J_IJMLC},
  author       = {Mugdho, Sohan Salahuddin and Imtiaz, Hafiz},
  doi          = {10.1007/s13042-024-02276-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5745-5763},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Privacy-preserving matrix factorization for recommendation systems using gaussian mechanism and functional mechanism},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation labeling in product knowledge graphs with large
language models for e-commerce. <em>IJMLC</em>, <em>15</em>(12),
5725–5743. (<a
href="https://doi.org/10.1007/s13042-024-02274-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Product Knowledge Graphs (PKGs) play a crucial role in enhancing e-commerce system performance by providing structured information about entities and their relationships, such as complementary or substitutable relations between products or product types, which can be utilized in recommender systems. However, relation labeling in PKGs remains a challenging task due to the dynamic nature of e-commerce domains and the associated cost of human labor. Recently, breakthroughs in Large Language Models (LLMs) have shown surprising results in numerous natural language processing tasks, especially in the in-context learning (ICL). In this paper, we conduct an empirical study of LLMs for relation labeling in e-commerce PKGs, investigating their powerful learning capabilities in natural language and effectiveness in predicting relations between product types with few-shot in-context learning. We evaluate the performance of various LLMs, including PaLM-2, GPT-3.5, and Llama-2, on benchmark datasets for e-commerce relation labeling tasks. We use different prompt engineering techniques to examine their impact on model performance. Our results show that LLMs can achieve competitive performance compared to human labelers using just 1–5 labeled examples per relation. We also illustrate the bias issues in LLMs towards minority ethnic groups. Additionally, we show that LLMs significantly outperform existing KG completion models or classification methods in relation labeling for e-commerce KGs and exhibit performance strong enough to replace human labeling. Beyond empirical investigations, we also carry out a theoretical analysis to explain the superior capability of LLMs in few-shot ICL by comparing it with kernel regression.},
  archive      = {J_IJMLC},
  author       = {Chen, Jiao and Ma, Luyi and Li, Xiaohan and Xu, Jianpeng and Cho, Jason H. D. and Nag, Kaushiki and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
  doi          = {10.1007/s13042-024-02274-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5725-5743},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relation labeling in product knowledge graphs with large language models for e-commerce},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-strategy hybrid cuckoo search algorithm with
specular reflection based on a population linear decreasing strategy.
<em>IJMLC</em>, <em>15</em>(12), 5683–5723. (<a
href="https://doi.org/10.1007/s13042-024-02273-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cuckoo search algorithm (CS), an algorithm inspired by the nest-parasitic breeding behavior of cuckoos, has proved its own effectiveness as a problem-solving approach in many fields since it was proposed. Nevertheless, the cuckoo search algorithm still suffers from an imbalance between exploration and exploitation as well as a tendency to fall into local optimization. In this paper, we propose a new hybrid cuckoo search algorithm (LHCS) based on linear decreasing of populations, and in order to optimize the local search of the algorithm and make the algorithm converge quickly, we mix the solution updating strategy of the Grey Yours sincerely, wolf optimizer (GWO) and use the linear decreasing rule to adjust the calling ratio of the strategy in order to balance the global exploration and the local exploitation; Second, the addition of a specular reflection learning strategy enhances the algorithm&#39;s ability to jump out of local optima; Finally, the convergence ability of the algorithm on different intervals and the adaptive ability of population diversity are improved using a population linear decreasing strategy. The experimental results on 29 benchmark functions from the CEC2017 test set show that the LHCS algorithm has significant superiority and stability over other algorithms when the quality of all solutions is considered together. In order to further verify the performance of the proposed algorithm in this paper, we applied the algorithm to engineering problems, functional tests, and Wilcoxon test results show that the comprehensive performance of the LHCS algorithm outperforms the other 14 state-of-the-art algorithms. In several engineering optimization problems, the practicality and effectiveness of the LHCS algorithm are verified, and the design cost can be greatly reduced by applying it to real engineering problems.},
  archive      = {J_IJMLC},
  author       = {Ouyang, Chengtian and Liu, Xin and Zhu, Donglin and Zheng, Yangyang and Zhou, Changjun and Zou, Chengye},
  doi          = {10.1007/s13042-024-02273-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5683-5723},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-strategy hybrid cuckoo search algorithm with specular reflection based on a population linear decreasing strategy},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep feature dendrite with weak mapping for small-sample
hyperspectral image classification. <em>IJMLC</em>, <em>15</em>(12),
5667–5681. (<a
href="https://doi.org/10.1007/s13042-024-02272-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) classification faces the challenges of large and complex data and costly training labels. Existing methods for small-sample HSI classification may not achieve good generalization because they pursue powerful feature extraction and nonlinear mapping abilities. We argue that small samples need deep feature extraction but weak nonlinear mapping to achieve generalization. Based on this, we propose a Deep Feature Dendrite (DFD) method, which consists of two parts: a deep feature extraction part that uses a convolution-tokenization-attention module to effectively extract spatial-spectral features, and a controllable mapping part that uses a residual dendrite network to perform weak mapping and enhance generalization ability. We conducted experiments on four standard datasets, and the results show that our method has higher classification accuracy than other existing methods. Significance: This paper pioneers and verifies weak mapping and generalization for HSI classification (new ideas). DFD code is available at https://github.com/liugang1234567/DFD},
  archive      = {J_IJMLC},
  author       = {Liu, Gang and Xu, Jiaying and Zhao, Shanshan and Zhang, Rui and Li, Xiaoyuan and Guo, Shanshan and Pang, Yajing},
  doi          = {10.1007/s13042-024-02272-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5667-5681},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep feature dendrite with weak mapping for small-sample hyperspectral image classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning-guided intrusion detection and neural key
exchange for safeguarding patient data on the internet of medical
things. <em>IJMLC</em>, <em>15</em>(12), 5635–5665. (<a
href="https://doi.org/10.1007/s13042-024-02269-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the security of the Internet of Medical Things (IoMT) in healthcare, this paper offers a Federated Learning (FL)-guided Intrusion Detection System (IDS) and an Artificial Neural Network (ANN)-based key exchange mechanism inside a blockchain framework. The IDS are essential for spotting network anomalies and taking preventative action to guarantee the secure and dependable functioning of IoMT systems. The suggested method integrates FL-IDS with a blockchain-based ANN-based key exchange mechanism, providing several important benefits: (1) FL-based IDS creates a shared ledger that aggregates nearby weights and transmits historical weights that have been averaged, lowering computing effort, eliminating poisoning attacks, and improving data visibility and integrity throughout the shared database. (2) The system uses edge-based detection techniques to protect the cloud in the case of a security breach, enabling quicker threat recognition with less computational and processing resource usage. FL’s effectiveness with fewer data samples plays a part in this benefit. (3) The bidirectional alignment of ANNs ensures a strong security framework and facilitates the production of keys inside the IoMT network on the blockchain. (4) Mutual learning approaches synchronize ANNs, making it easier for IoMT devices to distribute synchronized keys. (5) XGBoost and ANN models were put to the test using BoT-IoT datasets to gauge how successful the suggested method is. The findings show that ANN demonstrates greater performance and dependability when dealing with heterogeneous data available in IoMT, such as ICU (Intensive Care Unit) data in the medical profession, compared to alternative approaches studied in this study. Overall, this method demonstrates increased security measures and performance, making it an appealing option for protecting IoMT systems, especially in demanding medical settings like ICUs.},
  archive      = {J_IJMLC},
  author       = {Zhong, Chongzhou and Sarkar, Arindam and Manna, Sarbajit and Khan, Mohammad Zubair and Noorwali, Abdulfattah and Das, Ashish and Chakraborty, Koyel},
  doi          = {10.1007/s13042-024-02269-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5635-5665},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Federated learning-guided intrusion detection and neural key exchange for safeguarding patient data on the internet of medical things},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A copy-move forgery detection technique using DBSCAN-based
keypoint similarity matching. <em>IJMLC</em>, <em>15</em>(12),
5607–5634. (<a
href="https://doi.org/10.1007/s13042-024-02268-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era marked by the contrast between information and disinformation, the ability to differentiate between authentic and manipulated images holds immense importance for both security professionals and the scientific community. Copy-move forgery is widely practiced thus, sprang up as a prevalent form of image manipulation among different types of forgeries. In this counterfeiting process, a region of an image is copied and pasted into different parts of the same image to hide or replicate the same objects. As copy-move forgery is hard to detect and localize, a swift and efficacious detection scheme based on keypoint detection is introduced. Especially the localization of forged areas becomes more difficult when the forged image is subjected to different post-processing attacks and geometrical attacks. In this paper, a robust, translation-invariant, and efficient copy-move forgery detection technique has been introduced. To achieve this goal, we developed an AKAZE-driven keypoint-based forgery detection technique. AKAZE is applied to the LL sub-band of the SWT-transformed image to extract translation invariant features, rather than extracting them directly from the original image. We then use the DBSCAN clustering algorithm and a uniform quantizer on each cluster to form group pairs based on their feature descriptor values. To mitigate false positives, keypoint pairs are separated by a distance greater than a predefined shift vector distance. This process forms a collection of keypoints within each cluster by leveraging their similarities in feature descriptors. Our clustering-based similarity-matching algorithm effectively locates the forged region. To assess the proposed scheme we deploy it on different datasets with post-processing attacks ranging from blurring, color reduction, contrast adjustment, brightness change, and noise addition. Even our method successfully withstands geometrical manipulations like rotation, skewing, and different affine transform attacks. Visual outcomes, numerical results, and comparative analysis show that the proposed model accurately detects the forged area with fewer false positives and is more computationally efficient than other methods.},
  archive      = {J_IJMLC},
  author       = {Mukherjee, Soumya and Pal, Arup Kumar and Maji, Soham},
  doi          = {10.1007/s13042-024-02268-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5607-5634},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A copy-move forgery detection technique using DBSCAN-based keypoint similarity matching},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The concept information of graph granule with application to
knowledge graph embedding. <em>IJMLC</em>, <em>15</em>(12), 5595–5606.
(<a href="https://doi.org/10.1007/s13042-024-02267-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) has become one of the most effective methods for the numerical representation of entities and their relations in knowledge graphs. Traditional methods primarily utilise triple facts, structured as (head entity, relation, tail entity), as the basic knowledge units in the learning process and use additional external information to improve the performance of models. Since triples are sometimes less than adequate and external information is not always available, obtaining structured internal knowledge from knowledge graphs (KGs) naturally becomes a feasible method for KGE learning. Motivated by this, this paper employs formal concept analysis (FCA) to mine deterministic concept knowledge in KGs and proposes a novel KGE model by taking the concept information into account. More specifically, triples sharing the same head entity are organised into knowledge structures named graph granules, and then were transformed into concept lattices, based on which a novel lattice-based KGE model (TransGr) is proposed for knowledge graph completion. TransGr assumes that entities and relations exist in different granules and uses a matrix (obtained by fusing concepts from concept lattice) for quantitatively depicting the graph granule. Afterwards, it forces entities and relations to meet graph granule constraints when learning vector representations of KGs. Experiments on link prediction and triple classification demonstrated that the proposed TransGr is effective on the datasets with relatively complete graph granules.},
  archive      = {J_IJMLC},
  author       = {Niu, Jiaojiao and Chen, Degang and Ma, Yinglong and Li, Jinhai},
  doi          = {10.1007/s13042-024-02267-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5595-5606},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {The concept information of graph granule with application to knowledge graph embedding},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEMNet: An end-to-end efficient model for PCB surface tiny
defect detection. <em>IJMLC</em>, <em>15</em>(12), 5579–5594. (<a
href="https://doi.org/10.1007/s13042-024-02264-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The miniaturization of electronic products has led to the denser and more crowded wiring on printed circuit boards (PCBs), which has made PCB defects smaller and more difficult to detect. Moreover, the complex morphology of PCB defects highlights the importance of capturing their contextual information for improved detection accuracy and efficiency. While CNN can effectively capture local information, its layered convolution-based feature extraction method has limitations in capturing contextual information. The transformer structure can capture long-range dependencies effectively, but at the cost of increased computational effort. To address this issue, an end-to-end efficient model (EEMNet) for PCB surface tiny defect detection is proposed, leveraging the modularity idea. This model includes a novel and efficient attention mechanism that can capture global dependencies without adding too much computational effort, along with several plug-and-play modules for enhancing tiny defect features. The model also incorporates a scale-sensitive localization loss function and makes extensive use of Ghost convolution to substantially reduce the number of model parameters. The resulting EEMNet achieves a detection accuracy of 99.1 $$\%$$ and a detection speed of 77 FPS on a published PCB dataset, outperforming existing PCB detection algorithms. Overall, the proposed model provides an efficient and effective solution for PCB tiny defect detection.},
  archive      = {J_IJMLC},
  author       = {Wu, Yuxiang and Zheng, Liming and Chen, Enze},
  doi          = {10.1007/s13042-024-02264-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5579-5594},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {EEMNet: An end-to-end efficient model for PCB surface tiny defect detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel abstractive summarization model based on topic-aware
and contrastive learning. <em>IJMLC</em>, <em>15</em>(12), 5563–5577.
(<a href="https://doi.org/10.1007/s13042-024-02263-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of abstractive summarization models are designed based on the Sequence-to-Sequence(Seq2Seq) architecture. These models are able to capture syntactic and contextual information between words. However, Seq2Seq-based summarization models tend to overlook global semantic information. Moreover, there exist inconsistency between the objective function and evaluation metrics of this model. To address these limitations, a novel model named ASTCL is proposed in this paper. It integrates the neural topic model into the Seq2Seq framework innovatively, aiming to capture the text’s global semantic information and guide the summary generation. Additionally, it incorporates contrastive learning techniques to mitigate the discrepancy between the objective loss and the evaluation metrics through scoring multiple candidate summaries. On CNN/DM XSum and NYT datasets, the experimental results demonstrate that the ASTCL model outperforms the other generic models in summarization task.},
  archive      = {J_IJMLC},
  author       = {Tang, Huanling and Li, Ruiquan and Duan, Wenhao and Dou, Quansheng and Lu, Mingyu},
  doi          = {10.1007/s13042-024-02263-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5563-5577},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel abstractive summarization model based on topic-aware and contrastive learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequential attention layer-wise fusion network for
multi-view classification. <em>IJMLC</em>, <em>15</em>(12), 5549–5561.
(<a href="https://doi.org/10.1007/s13042-024-02260-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional network has shown excellent performance in multi-view classification. Currently, to output a fused node embedding representation in multi-view scenarios, existing researches tend to ensure the consistency of embedded node information among multiple views. However, they pay much attention to the immediate neighbors information rather than multi-order node information which can capture complex relationships and structures to enhance feature propagation. Furthermore, the embedded node information in each convolutional layer has not been fully utilized because the consistency is frequently achieved by the final convolutional layer. To tackle these limitations, we develop a new end-to-end multi-view learning architecture: sequential attention Layer-wise Fusion Network for multi-view classification (SLFNet). Motivated by the fact that for each view, multi-order node information is hidden in the multiple layer-wise node embedding representations, a set of sequential attentions can then be calculated over those multiple layers, which provides a novel fusion strategy from the perspectives of multi-order. The contributions of our architecture are: (1) capturing multi-order node information instead of using the immediate neighbors, thereby obtaining more accurate node embedding representations; (2) designing a sequential attention module that allows adaptive learning of node embedding representation for each layer, thereby attentively fusing these layer-wise node embedding representations. Our experiments, focusing on semi-supervised node classification tasks, highlight the superiorities of SLFNet compared to state-of-the-art approaches. Reports on deeper layer convolutional results further confirm its effectiveness in addressing over-smoothing problem.},
  archive      = {J_IJMLC},
  author       = {Teng, Qing and Yang, Xibei and Sun, Qiguo and Wang, Pingxin and Wang, Xun and Xu, Taihua},
  doi          = {10.1007/s13042-024-02260-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5549-5561},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sequential attention layer-wise fusion network for multi-view classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). WTGCN: Wavelet transform graph convolution network for
pedestrian trajectory prediction. <em>IJMLC</em>, <em>15</em>(12),
5531–5548. (<a
href="https://doi.org/10.1007/s13042-024-02258-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of pedestrian trajectory prediction remains challenging due to variable scenarios, complex social interactions, and uncertainty in pedestrian motion. Previous trajectory prediction research only models from the time domain, which makes it difficult to accurately capture the global and detailed features of complex pedestrian social interactions and the uncertainty of pedestrian movement. These methods also ignore the relationship between scene features and the potential motion patterns of pedestrians. Therefore, we propose a wavelet transform graph convolution network to obtain accurate pedestrian potential motion patterns through time-frequency analysis. We first construct spatial and temporal graphs, then obtain the attention score matrices through the self-attention mechanism in the time domain and combine them with the scene features. Then, we utilize the two-dimensional discrete wavelet transform to generate low-frequency and high-frequency components for representing global and detailed features of spatial-temporal interactions. These components are then further processed using asymmetric convolution, and the wavelet transform adjacency matrix is obtained through the inverse wavelet transform. We then employ graph convolution to combine the graph and the adjacency matrix to obtain spatial and temporal interaction features. Finally, we design the wavelet transform temporal convolution network to directly predict the two-dimensional Gaussian distribution parameters of the future trajectory. Extensive experiments on the ETH, UCY, and SDD datasets demonstrate that our method outperforms the state-of-the-art methods in prediction performance.},
  archive      = {J_IJMLC},
  author       = {Chen, Wangxing and Sang, Haifeng and Wang, Jinyu and Zhao, Zishan},
  doi          = {10.1007/s13042-024-02258-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5531-5548},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {WTGCN: Wavelet transform graph convolution network for pedestrian trajectory prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GFD-SSL: Generative federated knowledge distillation-based
semi-supervised learning. <em>IJMLC</em>, <em>15</em>(12), 5509–5529.
(<a href="https://doi.org/10.1007/s13042-024-02256-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated semi-supervised learning (Fed-SSL) algorithms have been developed to address the challenges of decentralized data access, data confidentiality, and costly data labeling in distributed environments. Most existing Fed-SSL algorithms are based on the federated averaging approach, which utilizes an equivalent model on all machines and replaces local models during the learning process. However, these algorithms suffer from significant communication overhead when transferring parameters of local models. In contrast, knowledge distillation-based Fed-SSL algorithms reduce communication costs by only transferring the output of local models on shared data between machines. However, these algorithms assume that all local data on the machines are labeled, and that there exists a large set of shared unlabeled data for training. These assumptions are not always feasible in real-world applications. In this paper, a knowledge distillation-based Fed-SSL algorithm has been presented, which does not make any assumptions about how the data is distributed among machines. Additionally, it artificially generates shared data required for the learning process. The learning process of the presented approach employs a semi-supervised GAN on local machines and has two stages. In the first stage, each machine trains its local model independently. In the second stage, each machine generates some artificial data in each step and propagates it to other machines. Each machine trains its discriminator with these data and the average output of all machines on these data. The effectiveness of this algorithm has been examined in terms of accuracy and the amount of communication among machines by using different data sets with different distributions. The evaluations reveal that, on average, the presented algorithm is 15% more accurate than state-of-the-art methods, especially in the case of non-IID data. In addition, in most cases, it yields better results than existing studies in terms of the amount of data communication among machines.},
  archive      = {J_IJMLC},
  author       = {Karami, Ali and Ramezani, Reza and Baraani Dastjerdi, Ahmad},
  doi          = {10.1007/s13042-024-02256-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5509-5529},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GFD-SSL: Generative federated knowledge distillation-based semi-supervised learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Context-aware generative prompt tuning for relation
extraction. <em>IJMLC</em>, <em>15</em>(12), 5495–5508. (<a
href="https://doi.org/10.1007/s13042-024-02255-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is designed to extract semantic relation between predefined entities from text. Recently, prompt tuning has achieved promising results in the field of relation extraction, and its core idea is to insert a template into the input and model the relation extraction as an masked language modeling (MLM) problem. However, existing prompt tuning approaches ignore the rich semantic information between entities and relations resulting in suboptimal performance. In addition, since MLM tasks can only identify one relation at a time, the widespread problem of entity overlap in relation extraction cannot be solved. To this end, we propose a novel Context-Aware Generative Prompt Tuning (CAGPT) method which ensures the comprehensiveness of triplet extraction by modeling relation extraction as a generative task, and outputs triplets related to the same entity at one time to overcome the entity overlap problem. Moreover, we connect entities and relations with natural language and inject entity and relationship information into the designed template which can make full use of the rich semantic information between entities and relations. Extensive experimental results on four benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Liu, Xiaoyong and Wen, Handong and Xu, Chunlin and Du, Zhiguo and Li, Huihui and Hu, Miao},
  doi          = {10.1007/s13042-024-02255-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5495-5508},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Context-aware generative prompt tuning for relation extraction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Axiomatic approaches to three types of l-valued rough sets.
<em>IJMLC</em>, <em>15</em>(12), 5469–5493. (<a
href="https://doi.org/10.1007/s13042-024-02252-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, considering L being a GL-quantale, we further develop the theory of L-valued rough sets with an L-set as the basic universe of defining L-valued rough approximation operators. Choosing an L-set as the universe can break the rules of adopting Zadeh’s fuzzy sets as the universe. We first introduce three types of L-valued relations on L-sets, namely, inverse serial, mediate, Euclidean, and then characterize them by L-valued rough sets. Adopting the idea of single axiomatic characterizations of L-valued rough sets, we present the axiomatical characterizations of L-valued upper and lower rough approximation operators on an L-set concerning these new L-valued relations by fuzzy unions and fuzzy intersections. Moreover, in the framework of category, we introduce the concepts of L-valued Alexander co-topological spaces and L-valued closure spaces on L-sets by fuzzy unions and fuzzy intersections, then prove they are category isomorphic. By fuzzy unions, we obtain a simplified axiomatic system of the L-valued closure spaces, which highlights the advantages of fuzzy unions. Finally, we obtain the category of L-valued Alexander co-topological spaces and their continuous mappings is isomorphic to the category of L-valued preordered approximation spaces and their order-preserving mappings.},
  archive      = {J_IJMLC},
  author       = {Chen, Yanan and Wei, Xiaowei},
  doi          = {10.1007/s13042-024-02252-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {12},
  number       = {12},
  pages        = {5469-5493},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Axiomatic approaches to three types of L-valued rough sets},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced spatial–temporal dynamics in pose forecasting
through multi-graph convolution networks. <em>IJMLC</em>,
<em>15</em>(11), 5453–5467. (<a
href="https://doi.org/10.1007/s13042-024-02254-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been a growing interest in predicting human motion, which involves forecasting future body poses based on observed pose sequences. This task is complex due to modeling spatial and temporal relationships. Autoregressive models, including recurrent neural networks (RNNs) and their variants, as well as transformer networks, are commonly used for addressing this challenge. However, autoregressive models have several serious drawbacks, such as vanishing or exploding gradients. Other researchers have attempted to solve the communication problem in the spatial dimension by integrating graph convolutional networks (GCNs) and long short-term memory (LSTM) or convolutional neural network (CNN) models. These approaches process temporal and spatial information separately and fuse them to extract features, whereas this sequential processing hampers the model’s ability to capture spatiotemporal information and perform feature extraction simultaneously. To address this in human pose forecasting, we propose a novel approach called the multi-graph convolution network (MGCN). By introducing an augmented graph for pose sequences, our model captures spatial and temporal information in one step only using GCN. Multiple frames provide multiple parts, which are joined together in a unified graph instance. Furthermore, our model investigates the impact of natural structure and sequence-aware attention. In the experimental evaluation of the large-scale benchmark datasets (Human3.6M, AMSS, and 3DPW), MGCN outperforms the state-of-the-art methods in human pose prediction.},
  archive      = {J_IJMLC},
  author       = {Ren, Hongwei and Zhang, Xiangran and Shi, Yuhong and Liang, Kewei},
  doi          = {10.1007/s13042-024-02254-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5453-5467},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced spatial–temporal dynamics in pose forecasting through multi-graph convolution networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inherit or discard: Learning better domain-specific child
networks from the general domain for multi-domain NMT. <em>IJMLC</em>,
<em>15</em>(11), 5439–5452. (<a
href="https://doi.org/10.1007/s13042-024-02253-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-domain NMT aims to develop a parameter-sharing model for translating general and specific domains, such as biology, legal, etc., which often struggle with the parameter interference problem. Existing approaches typically tackle this issue by learning a domain-specific sub-network for each domain equally, but they ignore the significant data imbalance problem across domains. For instance, the training data for the general domain often outweighs the biological domain tenfold. In this paper, we observe a natural similarity between the general and specific domains, including shared vocabulary or similar sentence structure. We propose a novel parameter inheritance strategy to adaptively learn domain-specific child networks from the general domain. Our approach employs gradient similarity as the criterion for determining which parameters should be inherited or discarded between the general and specific domains. Extensive experiments on several multi-domain NMT corpora demonstrate that our method significantly outperforms several strong baselines. In addition, our method exhibits remarkable generalization performance in adapting to few-shot multi-domain NMT scenarios. Further investigations reveal that our method achieves good interpretability because the parameters learned by the child network from the general domain depend on the interconnectedness between the specific domain and the general domain.},
  archive      = {J_IJMLC},
  author       = {Xu, Jinlei and Wen, Yonghua and Xiang, Yan and Jiang, Shuting and Huang, Yuxin and Yu, Zhengtao},
  doi          = {10.1007/s13042-024-02253-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5439-5452},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Inherit or discard: Learning better domain-specific child networks from the general domain for multi-domain NMT},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Deep question generation model based on dual attention
guidance. <em>IJMLC</em>, <em>15</em>(11), 5427–5437. (<a
href="https://doi.org/10.1007/s13042-024-02249-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question generation refers to the automatic generation of questions by computer systems based on given paragraphs and answers, which is one of the research hotspots in natural language processing. Although previous work has made great progress, there are still some limitations: (1) The rich structural information hidden in word sequences is ignored. (2) Current studies focus on sequence-to-sequence-based neural networks to maximize the use of question-and-answer information in the context. However, the context often contains a large number of redundant and irrelevant sentences, and these models fail to filter redundant information or focus on key sentences. To address these limitations, we use a Graph Convolutional Network (GCN) and a Bidirectional Long Short Term Memory (Bi-LSTM) Network to capture the structure and sequence information of the context simultaneously. Then, we use a contrastive learning strategy for content selection to fuse the document-level and graph-level representations. We also use a dual attention mechanism for the passage and answer. Next, we use the gating mechanism to dynamically assign weights and merge them into context information to support the question decoding by modeling their interaction. We also conduct qualitative and quantitative evaluations on the HotpotQA deep question-centric dataset, and the experimental results show that the proposed model is effective.},
  archive      = {J_IJMLC},
  author       = {Li, Jinhong and Zhang, Xuejie and Wang, Jin and Zhou, Xiaobing},
  doi          = {10.1007/s13042-024-02249-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5427-5437},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep question generation model based on dual attention guidance},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised filter feature selection based on natural
laplacian score and maximal information coefficient. <em>IJMLC</em>,
<em>15</em>(11), 5415–5425. (<a
href="https://doi.org/10.1007/s13042-024-02246-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial preprocessing step in data mining, feature selection aims to obtain an excellent feature set, so as to improve the accuracy of classifiers and reduce the training time. This task is non-trivial, especially when there are missing labels in datasets. Although some semi-supervised filter feature selection methods have been proposed, they generally fall short in effectively leveraging both labeled and unlabeled information, and lack adaptability to specific datasets. This paper proposes a novel semi-supervised filter feature selection method called NM Score to overcome these shortcomings. Specifically, to calculate the NM Score of a feature, its power of locality preserving and label discrimination in the whole data space is measured via the natural Laplacian score (NLS), which is an improved parameter-free Laplacian score based on natural neighbors. Meanwhile, its correlation with the limited available label information is measured via the general and equitable maximal information coefficient (MIC). Then, NLS and MIC are combined adaptively based on conflict ratios between neighborhood and labels to determine the NM Score of a feature and hence assess its importance. Experiments are conducted based on UCI datasets and high-dimensional gene datasets, and results reveal that NM Score is more effective than several state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Wu, Quanwang and Cai, Kun and Sun, Jianxun and Wang, Shanwei and Zeng, Jie},
  doi          = {10.1007/s13042-024-02246-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5415-5425},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semi-supervised filter feature selection based on natural laplacian score and maximal information coefficient},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Channel spatio-temporal convolutional network for pedestrian
trajectory prediction. <em>IJMLC</em>, <em>15</em>(11), 5395–5413. (<a
href="https://doi.org/10.1007/s13042-024-02245-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction is a crucial technology for agents to assist human beings, which remains highly challenging due to the complex interactions between pedestrians and the environment. However, previous works based on pedestrian relative position modeling have the problem of ignoring environmental information and global pedestrian perception, which inevitably leads to a significant deviation from reality. To address these challenges, we introduce a Channel Spatio-temporal Convolutional Network (CSTCN) for predicting pedestrian trajectories. The CSTCN explicitly models pedestrian interactions with perceptual information to capture the temporal and spatial characteristics of pedestrians. Meanwhile, we use Group-SE to model the sensitivity of pedestrians to multi-channel data, which facilitates predictions based on historically observed trajectories. We evaluated our proposed method on the ETH and UCY datasets. The experimental results demonstrate that our method outperforms other state-of-the-art methods by 11.4% in Average Displacement Error (ADE) and 6.7% in Final Displacement Error (FDE).},
  archive      = {J_IJMLC},
  author       = {Lu, Zhonghao and Luo, Yonglong and Xu, Lina and Hu, Ying and Zheng, Xiaoyao and Sun, Liping},
  doi          = {10.1007/s13042-024-02245-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5395-5413},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Channel spatio-temporal convolutional network for pedestrian trajectory prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low-dimensional intrinsic dimension reveals a phase
transition in gradient-based learning of deep neural networks.
<em>IJMLC</em>, <em>15</em>(11), 5381–5394. (<a
href="https://doi.org/10.1007/s13042-024-02244-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks complete a feature extraction task by propagating the inputs through multiple modules. However, how the representations evolve with the gradient-based optimization remains unknown. Here we leverage the intrinsic dimension of the representations to study the learning dynamics and find that the training process undergoes a phase transition from expansion to compression under disparate training regimes. Surprisingly, this phenomenon is ubiquitous across a wide variety of model architectures, optimizers, and data sets. We demonstrate that the variation in the intrinsic dimension is consistent with the complexity of the learned hypothesis, which can be quantitatively assessed by the critical sample ratio that is rooted in adversarial robustness. Meanwhile, we mathematically show that this phenomenon can be analyzed in terms of the mutable correlation between neurons. Although the evoked activities obey a power-law decaying rule in biological circuits, we identify that the power-law exponent of the representations in deep neural networks predicted adversarial robustness well only at the end of the training but not during the training process. These results together suggest that deep neural networks are prone to producing robust representations by adaptively eliminating or retaining redundancies. The code is publicly available at https://github.com/cltan023/learning2022 .},
  archive      = {J_IJMLC},
  author       = {Tan, Chengli and Zhang, Jiangshe and Liu, Junmin and Zhao, Zixiang},
  doi          = {10.1007/s13042-024-02244-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5381-5394},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Low-dimensional intrinsic dimension reveals a phase transition in gradient-based learning of deep neural networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subspace learning via hessian regularized latent
representation learning with <span
class="math display"><em>l</em><sub>2, 0</sub></span> -norm constraint:
Unsupervised feature selection. <em>IJMLC</em>, <em>15</em>(11),
5361–5380. (<a
href="https://doi.org/10.1007/s13042-024-02243-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection techniques have shown promising results in dealing with unlabelled high-dimensional data. Laplacian graph-based techniques with $${l}_{\text{2,1}}$$ -norm row-sparsity constraint have been popular for unsupervised feature selection tasks. However, the Laplacian graph fails to effectively preserve the topological structure of the data. To add insult to injury, $${l}_{\text{2,1}}$$ -norm is the only slack version of $${l}_{2,o}$$ -norm which cannot select exact top $$k$$ features, and has sparsity limitation. Aiming to tackle these defects, we propose a Hessian regularized latent representation learning with $${l}_{\text{2,0}}$$ -norm Constraint. Hessian regularization can preserve topological structure of data effectively, and $${l}_{\text{2,0}}$$ -norm constraint is able to select top group of features. Additionally, the feature selection process is conducted within the learned latent representation, which not only exhibits robustness to noise but also takes into account the connectivity information among data instances. Non-negative matrix factorization of the affinity matrix is employed to model the latent representation, enabling the incorporation of sample connections in the representation. An optimization strategy is proposed based on power iteration method to solve this sparse unsupervised feature selection. Convergence of optimization algorithm is proved and experimental studies on real-world datasets are conducted. The obtained results demonstrate the effectiveness of proposed method.},
  archive      = {J_IJMLC},
  author       = {Moslemi, Amir and Shaygani, Afshin},
  doi          = {10.1007/s13042-024-02243-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5361-5380},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Subspace learning via hessian regularized latent representation learning with $${l}_{2,0}$$ -norm constraint: Unsupervised feature selection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bridging the gap: Advancing the transparency and
trustworthiness of network intrusion detection with explainable AI.
<em>IJMLC</em>, <em>15</em>(11), 5337–5360. (<a
href="https://doi.org/10.1007/s13042-024-02242-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive rise of internet usage and the development of web applications across various platforms, ensuring network and system security has become a critical concern. While machine learning (ML) and deep learning (DL) have revolutionized intrusion detection systems (IDSs), their effectiveness is hampered by a crucial limitation: opacity. These &quot;black box&quot; models lack human interpretability, transparency, explainability, and logical reasoning in their prediction outputs, greatly hindering mainstream adoption, confidence, and trust in these systems. This study proposes a novel XAI-based framework that integrates explanations at every stage of the machine-learning pipeline and combines local and global, intrinsic and post-hoc, and model-agnostic and model-specific explanations. We also introduce ExplainDTC, SecureForest-RFE, RationaleNet, and CNNShield architectures in network security solutions. These architectures leverage the UNSW-NB15 dataset to detect network intrusions with high accuracy and provide quantifiable, human-interpretable explanations for their decisions to build trust through explainability. To explain how a decision is made by the models, we integrate multiple XAI methods such as LIME, SHAP, ElI5, and ProtoDash on top of our architectures. The generated explanations provide quantifiable insights into the influential factors and their respective impact on network intrusion predictions. Additionally, we provide comprehensive textual explanations alongside visualizations in XAI, empowering diverse audiences with transparent, reproducible insights into model decision-making. Thus, our approach introduces more transparency, richness in explainability, trust, and effectiveness between the decisions made by our improved IDS models and the users, facilitating the path for a more secure digital future.},
  archive      = {J_IJMLC},
  author       = {Islam, Md. Tohidul and Syfullah, Md. Khalid and Rashed, Md.Golam and Das, Dipankar},
  doi          = {10.1007/s13042-024-02242-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5337-5360},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Bridging the gap: Advancing the transparency and trustworthiness of network intrusion detection with explainable AI},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical few-shot learning based on top-down correction
mechanism with stop strategy. <em>IJMLC</em>, <em>15</em>(11),
5321–5336. (<a
href="https://doi.org/10.1007/s13042-024-02240-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has become an important branch of machine learning, which aims to give correct prediction information to unknown samples. Many few-shot models mostly adopt a hierarchical structure and make good use of the sample information at different levels of granularity to finish class prediction. However, existing few-shot learning only focuses on the amount of information correctly predicted and ignores the different risk levels of an incorrect prediction. For example, in the field of medical image pathology analysis, difficult pathological images can only be roughly distinguished as whether they are diseased and cannot be specifically analyzed for the degree of disease. In this paper, we propose a hierarchical few-shot learning based on top-down correction mechanism with stop strategy (HTDS) for few-shot classification. Firstly, we get the coarse-grained of each class by taking the mean value for each class, and we use the coarse-grained and the original fine-grained samples to build a decision tree with a multi-granularity hierarchical structure. The decision tree represents the class relationship among samples. Secondly, a threshold is established to measure the impact of coarse-grained on test sample classification. It stops the correct classification at the coarse-grained level and transfers the incorrect classification down to the fine-grained level. Finally, the fine-grained layer assists the coarse-grained layer in classification via a top-down correction mechanism. It minimizes the coarse-grained risk of misclassification. By using stop strategy and revision mechanisms, we can differentiate pathological images and use auxiliary information to assist in different levels of classification in the field of medical image analysis. The experimental results show that our model is better than some popular multi-granularity hierarchical based few-shot learning models.},
  archive      = {J_IJMLC},
  author       = {Jia, Xiao and Mao, Yingchi and Chen, Hao and Ping, Ping and Qi, Rongzhi},
  doi          = {10.1007/s13042-024-02240-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5321-5336},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical few-shot learning based on top-down correction mechanism with stop strategy},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ASR-fed: Agnostic straggler-resilient semi-asynchronous
federated learning technique for secured drone network. <em>IJMLC</em>,
<em>15</em>(11), 5303–5319. (<a
href="https://doi.org/10.1007/s13042-024-02238-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as a transformative artificial intelligence paradigm, facilitating knowledge sharing among distributed edge devices while upholding data privacy. However, dynamic networks and resource-constrained devices such as drones, face challenges like power outages and network contingencies, leading to the straggler effect that impedes the global model performance. To address this, we present ASR-Fed, a novel agnostic straggler-resilient semi-asynchronous FL aggregating algorithm. ASR-Fed incorporates a selection function to dynamically utilize updates from high-performing and active clients, while circumventing contributions from straggling clients during future aggregations. We evaluate the effectiveness of ASR-Fed using two prominent cyber-security datasets, WSN-DS, and Edge-IIoTset, and perform simulations with different deep learning models across formulated unreliable network scenarios. The simulation results demonstrate ASR-Fed’s effectiveness in achieving optimal accuracy while significantly reducing communication costs when compared with other FL aggregating protocols.},
  archive      = {J_IJMLC},
  author       = {Ihekoronye, Vivian Ukamaka and Nwakanma, Cosmas Ifeanyi and Kim, Dong-Seong and Lee, Jae Min},
  doi          = {10.1007/s13042-024-02238-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5303-5319},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ASR-fed: Agnostic straggler-resilient semi-asynchronous federated learning technique for secured drone network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised anomaly detection approach for cyberattack
identification. <em>IJMLC</em>, <em>15</em>(11), 5291–5302. (<a
href="https://doi.org/10.1007/s13042-024-02237-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing amount of devices connected to the huge net known as the internet, it is not surprising the corresponding growth of cyber attacks. The era of the Internet of Things (IoT) has proved to be an environment in which malicious activities have been able to proliferate with great comfort. Due to this kind of threat, having powerful machine learning-based classifiers is almost a critical need nowadays. Besides, to properly face new and previously unseen attacks unsupervised learners need to be involved. An unsupervised network threat detector is provided in this work. The proposed approach is based on three steps. The main one is a novel anomaly score, which relies on modeling the tails of the empirical distributions and on an interpretation of the well-known Bayes theorem. A step for an unsupervised feature selection and another one for data reduction are also considered, both aimed at gaining robustness of the procedure. All three steps are in a completely unsupervised way, facilitating an ad hoc scenario deploying. The whole method showed good performance reaching $$98.44\%$$ and $$98.14\%$$ in the F1-score over different datasets. The obtained results are competitive with other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Segurola-Gil, Lander and Moreno-Moreno, Mikel and Irigoien, Itziar and Florez-Tapia, Ane Miren},
  doi          = {10.1007/s13042-024-02237-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5291-5302},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised anomaly detection approach for cyberattack identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploiting graph neural network with one-shot learning for
fault diagnosis of rotating machinery. <em>IJMLC</em>, <em>15</em>(11),
5279–5290. (<a
href="https://doi.org/10.1007/s13042-024-02236-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insufficient training data often leads to overfitting, posing a significant challenge in diagnosing faults in mechanical devices, particularly rotating machinery. To address this issue, this paper introduces a novel approach employing a graph neural network (GNN) with one-shot learning for fault diagnosis in rotating machinery. Firstly, the Short-Time Fourier Transform (STFT) is utilized for data preprocessing to convert the one-dimensional data into two-dimensional pictures. Subsequently, Feature extraction a convolutional neural network (CNN) is utilized to perform feature extraction. By introducing the adjacency matrix to explore the spatial information within data, a graph neural network (GNN) method is proposed to achieve the fault classification of rotating machinery with small sample. The method utilizes GNN to process structural information between, transferring the distance metric from Euclidean space to non-Euclidean space. Classification accuracy is thereby improved based on information processing in non-Euclidean space.Experiments were implemented on two datasets to verify the proposed method, including an open dataset of the rolling bearing and an experimental rig of the rotate vector (RV) reducer in an industrial robot. Siamese Net, Matching Net, and sparse auto-encoder with random forest (SAE + RF) wereemployed as the comparisons to further prove the effectiveness of the proposed method. Results indicate that the proposed method outperforms all the comparative methods in both rotating machineries.},
  archive      = {J_IJMLC},
  author       = {Yang, Shuai and Chen, Xu and Wang, Yu and Bai, Yun and Pu, Ziqiang},
  doi          = {10.1007/s13042-024-02236-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5279-5290},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Exploiting graph neural network with one-shot learning for fault diagnosis of rotating machinery},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparative analysis of open-source federated learning
frameworks - a literature-based survey and review. <em>IJMLC</em>,
<em>15</em>(11), 5257–5278. (<a
href="https://doi.org/10.1007/s13042-024-02234-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While Federated Learning (FL) provides a privacy-preserving approach to analyze sensitive data without centralizing training data, the field lacks an detailed comparison of emerging open-source FL frameworks. Furthermore, there is currently no standardized, weighted evaluation scheme for a fair comparison of FL frameworks that would support the selection of a suitable FL framework. This study addresses these research gaps by conducting a comparative analysis of 15 individual open-source FL frameworks filtered by two selection criteria, using the literature review methodology proposed by Webster and Watson. These framework candidates are compared using a novel scoring schema with 15 qualitative and quantitative evaluation criteria, focusing on features, interoperability, and user friendliness. The evaluation results show that the FL framework Flower outperforms its peers with an overall score of 84.75%, while Fedlearner lags behind with a total score of 24.75%. The proposed comparison suite offers valuable initial guidance for practitioners and researchers in selecting an FL framework for the design and development of FL-driven systems. In addition, the FL framework comparison suite is designed to be adaptable and extendable accommodating the inclusion of new FL frameworks and evolving requirements.},
  archive      = {J_IJMLC},
  author       = {Riedel, Pascal and Schick, Lukas and von Schwerin, Reinhold and Reichert, Manfred and Schaudt, Daniel and Hafner, Alexander},
  doi          = {10.1007/s13042-024-02234-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5257-5278},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Comparative analysis of open-source federated learning frameworks - A literature-based survey and review},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Different gaze direction (DGNet) collaborative learning for
iris segmentation. <em>IJMLC</em>, <em>15</em>(11), 5239–5255. (<a
href="https://doi.org/10.1007/s13042-024-02232-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of the iris plays a pivotal role in iris recognition systems, yet it remains challenging, particularly in scenarios with noisy images from non-cooperative subjects. While deep learning, exemplified by the U-Net architecture, has shown promise in iris segmentation, it often struggles with capturing structures of varying shapes within the iris. To address this problem, we present a novel collaborative learning framework termed Different Gaze Direction Network (DGNet) for iris segmentation. The proposed methodology leverages both center gaze correspondence modeling (CGCM) and partial correspondence modeling (PCM) to establish inter-image relationships among images captured from different gaze directions. By conceptualizing images as distinct temporal slices, we employ 3D convolution to integrate primary features intuitively, facilitating a holistic understanding of group-level semantics. Moreover, in order to enhance inter-image correspondence, we propose Dyads Correlation Fusion (DCF) technique. Additionally, the paper introduces gaze direction aggregation (GDA) module amalgamates CGCM and PCM inter-image relationships to explore comprehensive collaboration cues. Through the Primary-and-Partial Weighting Fusion module, we dynamically combine primary and partial features to learn semantic representations and predict segmentation maps. DGNet’s efficacy is evaluated across four benchmark datasets, demonstrating superior performance compared to state-of-the-art methodologies. Specifically, DGNet achieves F1-scores of 99.37%, 99.22%, 97.35%, and 97.67% on CASIA, UBIRIS.v2, MICHE-I, and SVBPI datasets, respectively. Additionally, DGNet achieves Precision values of 99.41%, 99.31%, 97.68%, and 97.44%, Recall values of 99.34%, 99.12%, 97.04%, and 97.91%, and Mean Intersection over Union (MIOU) values of 98.64%, 98.71%, 95.64%, and 96.12% on the respective datasets.},
  archive      = {J_IJMLC},
  author       = {Bonyani, Mahdi and Ghanbari, Maryam and Rad, Ahmad},
  doi          = {10.1007/s13042-024-02232-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5239-5255},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Different gaze direction (DGNet) collaborative learning for iris segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient identification technique for 2-additive fuzzy
measures with consideration of objective relationships among features.
<em>IJMLC</em>, <em>15</em>(11), 5217–5237. (<a
href="https://doi.org/10.1007/s13042-024-02231-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to develop an efficient identification technique for 2-additive fuzzy measures with a deep understanding of objective relationships among features. More efforts are made to achieve this goal. Firstly, an efficient form of monotonicity constraints is presented for the 2-additive fuzzy measure, thus reducing the sheer number of monotonicity constraints from $$n{2}^{n-1}$$ down to $$n\left(n-1\right)/2$$ for $$n$$ features or decision criteria. By this means, we can obtain the two kinds of index values more efficiently, i.e., the importance index values of decision criteria and the interaction index values between them, especially the latter. Secondly, a decision parameter is introduced to reinforce the decision-making trial and evaluation laboratory method. In this way, the objective coefficients are specifically designed, with a deep understanding of the objective cause-and-effect relationships among criteria, to adjust the initial index values as above with the aim of reducing the decision group’s subjective bias. A desired monotone 2-additive fuzzy measure can then be identified by using these two kinds of index values adjusted. Finally, the developed technique is applied to the green material selection with a practical example, and the numerical efficiency shows that in the identification of 2-additive fuzzy measures with 6 features, the number of monotonicity constraints massively reduces from the original 192 down to the current 15. We also show the relatively good performance of the developed technique by comparing it with other methods.},
  archive      = {J_IJMLC},
  author       = {Guan, Xueting and Guo, Kaihong and Tian, He},
  doi          = {10.1007/s13042-024-02231-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5217-5237},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Efficient identification technique for 2-additive fuzzy measures with consideration of objective relationships among features},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive joint optimization framework for pruning and
quantization. <em>IJMLC</em>, <em>15</em>(11), 5199–5215. (<a
href="https://doi.org/10.1007/s13042-024-02229-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning and quantization are among the most widely used techniques for deep learning model compression. Their combined application holds the potential for even greater performance gains. Most existing works combine pruning and quantization sequentially. However, this separation makes it difficult to fully leverage their complementarity and exploit the potential benefits of joint optimization. To address the limitations of existing methods, we propose A-JOPQ (adaptive joint optimization of pruning and quantization), an adaptive joint optimization framework for pruning and quantization. Starting with a deep neural network, A-JOPQ first constructs a pruning network through adaptive mutual learning with a quantization network. This process compensates for the loss of structural information during pruning. Subsequently, the pruning network is incrementally quantized using adaptive multi-teacher knowledge distillation of itself and the original uncompressed model. This approach effectively mitigates the adverse effects of quantization. Finally, A-JOPQ generates a pruning-quantization network that achieves significant model compression while maintaining high accuracy. Extensive experiments conducted on several public datasets demonstrate the superiority of our proposed method. Compared to existing methods, A-JOPQ achieves higher accuracy with a smaller model size. Additionally, we extend A-JOPQ to federated learning (FL) settings. Simulation experiments show that A-JOPQ can enhance FL by enabling resource-limited clients to participate effectively.},
  archive      = {J_IJMLC},
  author       = {Li, Xiaohai and Yang, Xiaodong and Zhang, Yingwei and Yang, Jianrong and Chen, Yiqiang},
  doi          = {10.1007/s13042-024-02229-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5199-5215},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An adaptive joint optimization framework for pruning and quantization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on load excitation identification method of
multi-connected air conditioning compressor based on RBF network with
multi-strategy fusion SSA. <em>IJMLC</em>, <em>15</em>(11), 5185–5198.
(<a href="https://doi.org/10.1007/s13042-024-02227-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The load excitation of the multi-connected air conditioning compressor is the major source of vibration in the entire air conditioning pipeline system, which imposes a direct impact on the vibration noise and reliability of the overall system. Accurate identification of the compressor&#39;s load excitation is a primary condition to ensure its normal operation and is an essential part of the comprehensive testing and evaluation of the system&#39;s dynamic performance. In this paper, aiming at the problem of the inability to directly identify the time-varying load excitation of the multi-circuit air conditioning compressor, a predictive model is built on the basis of the Radial Basis Function (RBF) Neural Network. Meanwhile, to ameliorate the overall network model’s identification performance, a Multi-Strategy Fused Sparrow Search Algorithm (ISSA) is adopted for optimization regarding the center, the basic functions’ variance, and the weights from the hidden layer to the input one in RBF. This algorithm not only improves the joiners, discoverers, and scouts positioning in the Sparrow Search Algorithm (SSA) but also adds the Firefly Algorithm (FA) to disturb the positions of all sparrows, thereby preventing the algorithm from being trapped in local optima and enhancing the global search ability. The results of practical testing and simulation experiments show that the Firefly Algorithm improved Multi-Strategy Fused Sparrow Search Algorithm-Radial Basis Function (FAISSA-RBF) algorithm reduces the convergence to below 10–2, and the R2 is improved by approximately 12.7% compared to the SSA-RBF. This ensures the normal and stable operation of the air conditioning compressor system under time-varying conditions and the effective identification of load excitation.},
  archive      = {J_IJMLC},
  author       = {Wang, Lu and Fang, Qiansheng and Gao, Lifu and Sun, Yuxiang and Cao, Huibin},
  doi          = {10.1007/s13042-024-02227-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5185-5198},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Research on load excitation identification method of multi-connected air conditioning compressor based on RBF network with multi-strategy fusion SSA},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor low-rank representation combined with consistency and
diversity exploration. <em>IJMLC</em>, <em>15</em>(11), 5173–5184. (<a
href="https://doi.org/10.1007/s13042-024-02224-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many tensor data processing methods have been proposed. Tensor low-rank representation (TLRR) is a recently proposed tensor-based clustering method that has shown good clustering performance in some applications. However, TLRR does not make full use of the consistency and diversity information hidden in different similarity matrices. Therefore, we propose the TLRR combined with consistency and diversity exploration (TLRR-CD) method. First, the tensor Frobenius norm and tensor product (t-product), which is defined as the multiplication of two tensors, are used to obtain the low-rank representation tensor, which can be seen as being composed of many similarity matrices. Second, the low-rank representation tensor is further decomposed into a consistent tensor, which contains the common structural information contained in the different similarity matrices, and a diversity tensor, which contains the locally specific structural information of different similarity matrices. Finally, the Hilbert–Schmidt Independence Criterion (HSIC), which is used to measure the relevance of local specific structural information, and spectral clustering are unified into the final objective function to improve clustering performance. In addition, the optimization process of TLRR-CD is also given. The experimental results show the good performance of TLRR-CD.},
  archive      = {J_IJMLC},
  author       = {Kan, Yaozu and Lu, Gui-Fu and Ji, Guangyan and Du, Yangfan},
  doi          = {10.1007/s13042-024-02224-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5173-5184},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Tensor low-rank representation combined with consistency and diversity exploration},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autoencoder evolutionary algorithm for large-scale
multi-objective optimization problem. <em>IJMLC</em>, <em>15</em>(11),
5159–5172. (<a
href="https://doi.org/10.1007/s13042-024-02221-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization problems characterized by a substantial number of decision variables, which are also called large-scale multi-objective optimization problems (LSMOPs), are becoming increasingly prevalent. Traditional evolutionary algorithms may deteriorate drastically when tackling a large number of decision variables. For LSMOPs, the dimensionality of the decision variables needs to be reduced and the algorithm needs to be designed according to the characteristics of divide-and-conquer. The autoencoder evolutionary algorithm (AEEA) is proposed based on autoencoder dimensionality reduction, the grouping of decision variables, and the application of divide-and-conquer strategies. The proposed algorithm is compared with other classical algorithms. The experiment result shows that AEEA achieves excellent convergence and diversity, and still performs well in decision variables of higher dimensions. Finally, it is verified that the autoencoder improves the running time of the proposed algorithm.},
  archive      = {J_IJMLC},
  author       = {Hu, Ziyu and Xiao, Zhixing and Sun, Hao and Yang, He},
  doi          = {10.1007/s13042-024-02221-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5159-5172},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Autoencoder evolutionary algorithm for large-scale multi-objective optimization problem},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Robust local k-proximal plane clustering based on l2,1-norm
minimization. <em>IJMLC</em>, <em>15</em>(11), 5143–5158. (<a
href="https://doi.org/10.1007/s13042-024-02220-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {K-proximal plane clustering (kPPC) cluster data points to the center points and local k-proximal plane clustering (LkPPC) uses the combination of hyperplane and points as the cluster center to localize the hyperplane. However, the $$l_{2}$$ -norm is employed to group the data into corresponding clusters, which is sensitive to outliers because of the square operation. Many previous works chose to use $$l_{1}$$ -norm instead of $$l_{2}$$ -norm to improve robustness. However, this approach has limited improvement in the robustness of outlier, and the solution of $$l_{1}$$ -norm mostly uses a greedy algorithm search strategy, which is easy to fall into local optimization and consumes a long time. In this paper, we propose a clustering method using $$l_{2,1}$$ -norm, named RLkPPC. To solve the objective function, we combine an efficient iterative optimization algorithm with the Lagrange multiplier method, and on this basis, propose a non-greedy weighted iterative optimization algorithm for solving the $$l_{2,1}$$ -norm minimum problem. Compared to existing methods, the advantage of our method is: (1) similar to LkPPC, it has a clear geometric explanation; (2) it has good robustness and a stronger ability to resist the influence of outliers; (3) it uses a non-greedy weighted iterative optimization algorithm, prevent falling into local optima. The experimental results on some artificial and benchmark datasets indicate that our algorithm has the robustness and clustering accuracy advantages.},
  archive      = {J_IJMLC},
  author       = {Wang, Jiawei and Liu, Yingan and Fu, Liyong},
  doi          = {10.1007/s13042-024-02220-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5143-5158},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust local K-proximal plane clustering based on l2,1-norm minimization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain adaptive knowledge tracing. <em>IJMLC</em>,
<em>15</em>(11), 5129–5142. (<a
href="https://doi.org/10.1007/s13042-024-02219-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) is one of the fundamental tasks in intelligent education, which mainly predicts students’ performance on new questions based on their historical learning interaction behavior. Although many deep learning methods have been successfully applied to KT tasks, there are still some problems in real scenarios. The data acquisition of student interactions is often the key problem in many KT tasks, since most KT models require a large amount of student interaction data for model training. However, such data is difficult to obtain because it may contain personal information about students. Our goal is to leverage existing student exercises from another subject/dataset (namely source domain) to train a KT model and adapt it to the current subject/dataset (namely target domain) using only a small amount of target domain data. Therefore, we propose a novel Domain Adaptive Knowledge Tracing model (DAKT). To achieve the adaptation of knowledge tracing, we design a domain-shared answer embedding module to capture the behavioral features of students’ past answers and a domain-adaptive knowledge state module to adapt the model to the target domain. We conduct extensive experiments on four benchmark datasets to demonstrate the effectiveness of our model.},
  archive      = {J_IJMLC},
  author       = {Tang, Yumeng and Yang, Wanqi and Xie, Yuquan and Yang, Ming},
  doi          = {10.1007/s13042-024-02219-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5129-5142},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Domain adaptive knowledge tracing},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved two-stage task allocation of distributed UAV swarms
based on an improved auction mechanism. <em>IJMLC</em>, <em>15</em>(11),
5119–5128. (<a
href="https://doi.org/10.1007/s13042-024-02218-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to better handle the dynamic task allocation of UAV swarms, this paper first models the task allocation problem of UAV swarms. Then, improvements were made to the previous auction-based methods in terms of two aspects—the auction function and auction mechanism, and a two-stage task allocation method for UAV swarms based on an improved auction mechanism was proposed. When improving the auction function, an auction function with a parameter considering both UAVs and tasks was designed. By using machine learning to obtain the parameter, relatively stable experimental performance can be achieved. To further optimize the performance, a re-auction mechanism was proposed. Finally, by comparing with commonly used methods based on auction mechanisms, including the method of a linear combination of the MiniSum and MiniMax team objectives for task allocation and the other method, the feasibility of improving the auction function and auction mechanism was verified, and better experimental results were obtained.},
  archive      = {J_IJMLC},
  author       = {Tan, Chaoren and Liu, Xin},
  doi          = {10.1007/s13042-024-02218-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5119-5128},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improved two-stage task allocation of distributed UAV swarms based on an improved auction mechanism},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SAPDA: Significant areas preserved data augmentation.
<em>IJMLC</em>, <em>15</em>(11), 5107–5118. (<a
href="https://doi.org/10.1007/s13042-024-02214-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data Augmentation is an essential technology for improving the performance of deep learning models. However, the semantic information change in current data augmentation methods may impair the model performance, especially in randomly erasing-based data augmentation. We focus on exploiting a Significant Areas Preserved Data Augmentation (SAPDA) method to mitigate this issue, where the most informative areas are preserved. Moreover, the significant areas (SA) are derived from perceptions of current models during the model training process. Therefore, the areas preserved by SAPDA are different for each stage of training. Inspired by hard sample mining, first, we define the SA of images by employing a Class Activation Map (CAM). The SA consists of Discriminative Area (DA), Misclassified Area (MA), and Uncertain Area (UA). Further, the SA is preserved during data augmentation, which could keep the semantic information unchanged and make the model focus on difficult and uncertain areas. Extensive experiments are conducted on CIFAR-10, CIFAR-100, and ImageNet, which show that our proposed SAPDA could further improve the model performance in combination with existing SOTA data augmentation methods. Also, the SAPDA could enhance the model’s ability in semi-supervised learning and noisy label learning.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xueyuan and Quan, Li and Yang, Yongliang},
  doi          = {10.1007/s13042-024-02214-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5107-5118},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SAPDA: Significant areas preserved data augmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Industrial product surface defect detection via the fast
denoising diffusion implicit model. <em>IJMLC</em>, <em>15</em>(11),
5091–5106. (<a
href="https://doi.org/10.1007/s13042-024-02213-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of intelligent manufacturing, surface defect detection plays a pivotal role in the automated quality control of industrial products, constituting a fundamental aspect of smart factory evolution. Considering the diverse sizes and feature scales of surface defects on industrial products and the difficulty in procuring high-quality training samples, the achievement of real-time and high-quality surface defect detection through artificial intelligence technologies remains a formidable challenge. To address this, we introduce a defect detection approach grounded in the Fast Denoising Probabilistic Implicit Models. Firstly, we propose a noise predictor influenced by the spectral radius feature tensor of images. This enhancement augments the ability of generative model to capture nuanced details in non-defective areas, thus overcoming limitations in model versatility and detail portrayal. Furthermore, we present a loss function constraint based on the Perron-root. This is designed to incorporate the constraint within the representational space, ensuring the denoising model consistently produces high-quality samples. Lastly, comprehensive experiments on both the Magnetic Tile and Market-PCB datasets, benchmarked against nine most representative models, underscore the exemplary detection efficacy of our proposed approach.},
  archive      = {J_IJMLC},
  author       = {Wang, Yue and Yang, Yong and Liu, Mingsheng and Tang, Xianghong and Wang, Haibin and Hao, Zhifeng and Shi, Ze and Wang, Gang and Jiang, Botao and Liu, Chunyang},
  doi          = {10.1007/s13042-024-02213-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5091-5106},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Industrial product surface defect detection via the fast denoising diffusion implicit model},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced multi-view anomaly detection on attribute networks
by truncated singular value decomposition. <em>IJMLC</em>,
<em>15</em>(11), 5071–5089. (<a
href="https://doi.org/10.1007/s13042-024-02211-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of attribute network anomaly detection, current research methodologies, such as reconstruction and contrastive learning, frequently face challenges including the minimal differentiation in embedding representations of normal and anomalous nodes, an excessive dependence on local information, and a susceptibility to noise from adjacent nodes. To overcome these limitations, this paper presents a novel approach: the Enhanced Multi-view Anomaly Detection on Attribute Networks by Truncated Singular Value Decomposition (EMTSVD) method. EMTSVD leverages TSVD to generate improved views of both attributes and structures. Through the use of a low-rank approximation matrix, EMTSVD effectively filters out noise and isolates critical structural and attribute information. This isolated information is subsequently incorporated into the node embedding representations, significantly enhancing the differentiation between normal and anomalous nodes. Moreover, EMTSVD employs an attention mechanism to integrate multiple views, effectively minimizing spatial feature redundancy and further diminishing the effects of noise disturbances. Empirical evidence highlights EMTSVD&#39;s adeptness at accurately identifying essential node information within networks. By bolstering the distinction in embedding representations between normal and anomalous nodes, EMTSVD markedly advances the precision of anomaly detection in attribute networks.},
  archive      = {J_IJMLC},
  author       = {Lee, Baozhen and Su, Yuwei and Kong, Qianwen and Zhang, Tingting},
  doi          = {10.1007/s13042-024-02211-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5071-5089},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced multi-view anomaly detection on attribute networks by truncated singular value decomposition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CausalFD: Causal invariance-based fraud detection against
camouflaged preference. <em>IJMLC</em>, <em>15</em>(11), 5053–5070. (<a
href="https://doi.org/10.1007/s13042-024-02209-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraudsters engage in diverse patterns and deceptive interactions, allowing them to move effortlessly within online networks. However, current fraud detection methods heavily rely on correlated experiences and often face challenges in adapting to changing fraud patterns. To solve this problem, our paper introduces a fraud detection method called CausalFD. It includes a mechanism that learns the invariant preference behind evolving camouflaged preference as fraud patterns change. Specifically, we first introduce the concept of camouflaged preference in fraud detection to reveal the importance of identifying fraudster behavior variation and invariance for aiding downstream task inference. Next, we design a module called neighborhood heterophily perception (NHP) to measure the level of heterophily between a node and its neighbors. This helps in understanding the node’s surroundings to identify fraud patterns and establish environmental conditions for causal inference. Lastly, we design the preference invariance mining (PIM) module to uncover potential causal relationships among users. This module analyzes user associations using the causal inference mechanism to identify consistent user preferences. The combination of both methods enables the identification of the fraudster’s motives even amidst changing fraud patterns. We conducted extensive experiments on two widely used fraud datasets, and the results demonstrate that our model exhibits excellent capabilities in fraud detection.},
  archive      = {J_IJMLC},
  author       = {Song, Yudan and Wei, Yuecen and Yuan, Haonan and Sun, Qingyun and Fu, Xingcheng and Wang, Li-e and Li, Xianxian},
  doi          = {10.1007/s13042-024-02209-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5053-5070},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CausalFD: Causal invariance-based fraud detection against camouflaged preference},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The construction of multi-granularity generalized one-sided
concept lattices. <em>IJMLC</em>, <em>15</em>(11), 5033–5052. (<a
href="https://doi.org/10.1007/s13042-024-02208-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis (FCA) is an important analytical tool for cognitive science. The generalized one-sided concept lattice extends the classical concept lattice, which considers the order between the attributes values. The structure of generalized one-sided concept lattice is more complicated than the classical concept lattice. The complexity of constructing generalized one-sided concept lattice is added when the original formal context extends to a multi-granularity formal context. To address this problem, this paper proposes Zoom algorithms based on the granularity trees and the existing generalized one-sided concept lattices. Firstly, the Zoom-in algorithm is designed to construct the generalized one-sided concept lattice when changing the granularity of the attribute value from coarse-granularity to fine-granularity. Then, Zoom-out algorithm is explored to produce the generalized one-sided concept lattice when changing the granularity of the attribute value from fine-granularity to coarse-granularity. Finally, experimental results explain the effectiveness of our algorithms.},
  archive      = {J_IJMLC},
  author       = {Shao, Zhimin and Hu, Zhiyong and Lv, Mengmeng and Shao, Mingwen and Guo, Rui and Zhang, Shidong},
  doi          = {10.1007/s13042-024-02208-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5033-5052},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {The construction of multi-granularity generalized one-sided concept lattices},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved dense residual network with the coordinate and
pixel attention mechanisms for helmet detection. <em>IJMLC</em>,
<em>15</em>(11), 5015–5031. (<a
href="https://doi.org/10.1007/s13042-024-02205-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Helmet detection in road surveillance images has become increasingly important with the increasing number of accidents involving two-wheeled electric vehicles and motorcycles. However, small detection targets and complex road environments make traditional helmet detection methods difficult. In this study, we propose an intelligent helmet detection model based on convolutional neural networks. To accurately capture the location of the helmet, we introduce the coordinate attention to obtain position information in the model. We thereafter introduce the pixel attention to enhance interpixel correlation and pixel-level feature filtering for the input images. These two attention mechanisms are combined to design the CPA module, and multi-CPA groups are constructed in a densely connected manner to obtain improved CPAG dense blocks. The proposed dual-attention mechanism effectively enhanced the weight of useful information and suppressed useless information. A dense block can improve the feature extraction ability and avoid information loss in the network. The CPAG dense block is inserted into the convolutional network model to obtain CPAG-Net as the detection network. To complete the system, we added a localization network to obtain the upper part of the rider. The localization network is accomplished using an improved YOLOv5s model in which we introduce an efficient channel attention mechanism to improve the localization ability for small targets. We compared the performance of the proposed method with those of several other methods. The results indicate that the proposed method is more robust than the other methods and has a higher accuracy for helmet detection in road surveillance images.},
  archive      = {J_IJMLC},
  author       = {Mi, Jiang and Luo, Jingrui and Zhao, Haixia and Huang, Xingguo},
  doi          = {10.1007/s13042-024-02205-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {5015-5031},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improved dense residual network with the coordinate and pixel attention mechanisms for helmet detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic event-triggered non-fragile dissipative filtering
for interval type-2 fuzzy markov jump systems. <em>IJMLC</em>,
<em>15</em>(11), 4999–5013. (<a
href="https://doi.org/10.1007/s13042-024-02204-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the design of non-fragile dissipative filters for discrete-time interval type-2 fuzzy Markov jump systems (IT-2FMJSs). The novel mode-dependent dynamic event-triggered strategy (DETS) is used to lower the frequency of filter updates while improving information transmission efficiency. In addition, the hidden Markov model is employed to construct an asynchronous, non-fragile dissipative filter of uncertain interval type. The mode-independent and dependent filters can be effectively coupled by modifying the conditional probability matrices (CPMs) and the interval value range of uncertain terms. Furthermore, the vertex separation approach is used to address the computational difficulty of interval uncertainty in the filter. Finally, sufficient requirements are obtained based on the Lyapunov stability theory to guarantee that the filtering error system is stochastically stable with extended dissipative performance. The correctness and effectiveness of the proposed conclusions are illustrated by two simulation examples.},
  archive      = {J_IJMLC},
  author       = {Han, Lihuan and Wang, Yincai and Ma, Yuechao},
  doi          = {10.1007/s13042-024-02204-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {4999-5013},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic event-triggered non-fragile dissipative filtering for interval type-2 fuzzy markov jump systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging text mining and analytic hierarchy process for
the automatic evaluation of online courses. <em>IJMLC</em>,
<em>15</em>(11), 4973–4998. (<a
href="https://doi.org/10.1007/s13042-024-02203-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduced a multi-criteria decision-making methodology leveraging text mining and analytic hierarchy process (AHP) for online course quality evaluation based on students’ feedback texts. First, a hierarchical structure of online course evaluation criteria was formulated by integrating topics (sub-criteria) identified through topic modeling and interpreted based on transactional distance and technology acceptance theories. Second, the weights of the criteria in the hierarchical structure were determined based on topic proportions. Third, the AHP was employed to determine the overall relative advantage of online courses and their relative advantage within each criterion based on the hierarchical framework and criterion weights. The proposed approach was implemented on the datasets of 6940 reviews for knowledge-seeking courses in Art, Design, and Humanities (D1) and 44,697 reviews for skill-seeking courses in Computer Science, Engineering, and Programming (D2) from Class Central to determine ranking positions of nine courses from both D1 and D2 as alternatives. Results revealed common concerns among knowledge and skill-seeking course learners, encompassing “assessment”, “content”, “effort”, “usefulness”, “enjoyment”, “faculty”, “interaction”, and “structure”. The article provides valuable insights into the online course evaluation and selection processes for learners in D1 and D2 groups. Notably, both groups prioritize “effort” and “faculty”, while D2 learners value “assessment” and “enjoyment”, and D1 learners value “usefulness” more. This study demonstrates the efficacy of leveraging online learner reviews and topic modeling for automating MOOC evaluation and informing learners’ decision-making processes.},
  archive      = {J_IJMLC},
  author       = {Chen, Xieling and Xie, Haoran and Tao, Xiaohui and Wang, Fu Lee and Cao, Jie},
  doi          = {10.1007/s13042-024-02203-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {4973-4998},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Leveraging text mining and analytic hierarchy process for the automatic evaluation of online courses},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Target link protection against link-prediction-based attacks
via artificial bee colony algorithm based on random walk.
<em>IJMLC</em>, <em>15</em>(11), 4959–4971. (<a
href="https://doi.org/10.1007/s13042-024-02198-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is a network analysis model used to discover missing links or future relationships that may appear, which has been widely used in many real network systems to predict the potential relationship between two individuals. However, link prediction can also be used by attackers to identify sensitive links that users are unwilling to expose, which makes only removing sensitive links from the original network ineffective and leads to the disclosure of privacy. In this paper, we propose a target link protection mechanism via artificial bee colony algorithm based on random walk (RABC), which can defend the link prediction attacks based on resource allocation (RA) metric effectively. To enhance the local search ability of RABC, the random walk algorithm is combined with the original artificial bee colony algorithm. Then, we compare our method with other existing methods, which shows that RABC has higher efficiency while ensuring the effectiveness. Finally, extensive experiments on real social networks are conducted to demonstrate the good performance of RABC on protecting sensitive links from being detected successfully by link prediction model. Furthermore, the perturbed networks generated by RABC is transferable to defend against other link prediction attacks.},
  archive      = {J_IJMLC},
  author       = {Jiang, Zhongyuan and Liu, Haibo and Li, Jing and Li, Xinghua and Ma, Jianfeng and Yu, Philip S.},
  doi          = {10.1007/s13042-024-02198-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {4959-4971},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Target link protection against link-prediction-based attacks via artificial bee colony algorithm based on random walk},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KAT: Knowledge-aware attentive recommendation model
integrating two-terminal neighbor features. <em>IJMLC</em>,
<em>15</em>(11), 4941–4958. (<a
href="https://doi.org/10.1007/s13042-024-02194-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its ability to effectively address the cold start and sparsity problems in collaborative filtering, knowledge graph is commonly used as auxiliary information in recommendation systems. However, the existing recommendation algorithms based on knowledge graphs mainly focus on utilizing the connection structure to obtain user interests or item features, without emphasizing the simultaneous feature extraction on both the user and item sides. Therefore, the learned embeddings can not effectively represent the potential semantics of users and items. In this paper, we proposed KAT, a knowledge-aware attentive recommendation model integrating two-terminal neighbor features, which to extract fine-grained user and item features by alternating preference propagation and neighborhood information aggregation. The two modules automatically update and share entity embedding. Specifically, we introduce knowledge-aware attention mechanism to enhance the distinction of adjacent entities. Furthermore, we design a neighbor sampling mechanism to calculate the maximum node influence by extracting the largest connected subnet, which avoids the instability of the model performance caused by random sampling. We validate the effectiveness of KAT on four different datasets: movie, music, book, and grape (the latter is a dataset that we constructed through market research). Numerous experiments have demonstrated that KAT significantly outperforms several recent baselines, and AUC and ACC have increased by 2.81% and 1.28% respectively on our self-built dataset.},
  archive      = {J_IJMLC},
  author       = {Liu, Tianqi and Zhang, Xinxin and Wang, Wenzheng and Mu, Weisong},
  doi          = {10.1007/s13042-024-02194-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {4941-4958},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {KAT: Knowledge-aware attentive recommendation model integrating two-terminal neighbor features},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relabeling and policy distillation of hierarchical
reinforcement learning. <em>IJMLC</em>, <em>15</em>(11), 4923–4939. (<a
href="https://doi.org/10.1007/s13042-024-02192-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical reinforcement learning (HRL) is a promising method to extend traditional reinforcement learning to solve more complex tasks. HRL can solve the problems of long-term reward sparsity and credit assignment. However, the existing HRL methods are trained in specific environments and target tasks each time, resulting in low sample utilization. In addition, the low-level sub-policies of the agent will interfere with each other during the migration process, resulting in poor policy stability. Aiming at the issue above, this paper proposes an HRL method, Relabeling and Policy Distillation of Hierarchical Reinforcement Learning (R-PD-HRL), that integrates meta-learning, shared reward relabeling and policy distillation to accelerate the learning speed and improve the policy stability of the agent. In the training process, a reward relabeling module is introduced to act on the experience buffer. Different reward functions are used to relabel the interaction trajectory for the training of other tasks under the same task distribution. At the low-level, policy distillation technology is used to compress the sub-policies of the low-level, and the interference between the policies is reduced while ensuring the correctness of the original low-level sub-policies. Finally, according to different tasks, the high-level policy calls the low-level optimal policy to complete the decision. In both continuous and discrete state-action environments, experimental results show that compared with other methods, the improved sample utilization of this method greatly accelerates the learning speed, and the success rate is as high as 0.6.},
  archive      = {J_IJMLC},
  author       = {Zou, Qijie and Zhao, Xiling and Gao, Bing and Chen, Shuang and Liu, Zhiguo and Zhang, Zhejie},
  doi          = {10.1007/s13042-024-02192-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {4923-4939},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relabeling and policy distillation of hierarchical reinforcement learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HFCCW: A novel hybrid filter-clustering-coevolutionary
wrapper feature selection approach for network anomaly detection.
<em>IJMLC</em>, <em>15</em>(11), 4887–4922. (<a
href="https://doi.org/10.1007/s13042-024-02187-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network anomaly detection (NAD) is a crucial Artificial Intelligence (AI)-based security solution for protecting computer networks. However, analyzing high-dimensional data is a significant impediment for NAD systems. The process of Feature Selection (FS) addresses this challenge by reducing or eliminating irrelevant or redundant features. Conventional FS algorithms face the drawbacks of diminished accuracy, elevated computational costs, and the inclusion of irrelevant and redundant features. This paper presents a novel three-fold Hybrid Filter-Clustering-Coevolutionary Wrapper (HFCCW) based FS approach to overcome these issues. The proposed method integrates filter and clustering techniques in the initial phases to prevent irrelevant and redundant features from being included. The first phase involves removing irrelevant features by employing the Fisher score filter method, followed by the application of clustering based on the Minimum Spanning Tree (MST) in the second phase. The second phase aims to eliminate redundant features and effectively narrow down the search space of the coevolutionary algorithm in the third phase. The method employed in the third phase adeptly integrates the strengths of particle swarm optimization (PSO) and binary grey wolf optimization (BGWO) techniques, effectively harmonizing the exploration and exploitation trade-off in the optimization process. The incorporation of the Levy Flight (LF) concept in the final iterations of BGWOPSO enhances the search steps of GWO during the third phase. It addresses the issue of GWO being confined to local optima. This improvement is achieved by applying BLFGWOPSO in the final phase of the proposed HFCCW approach. Empirical findings on the CICIDS2017 dataset substantiate the efficacy of the proposed method in enhancing classification accuracy, selecting optimal feature subsets with fewer features, reducing computing costs and improving convergence rates. Furthermore, the proposed method achieves a favorable trade-off between accuracy and computing time when contrasted with state-of-the-art methods such as filter, metaheuristic-based wrapper, and hybrid FS approaches.},
  archive      = {J_IJMLC},
  author       = {Sharma, Niharika and Arora, Bhavna},
  doi          = {10.1007/s13042-024-02187-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {4887-4922},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {HFCCW: A novel hybrid filter-clustering-coevolutionary wrapper feature selection approach for network anomaly detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aspect based hotel recommendation system using dilated
multichannel CNN and BiGRU with hyperbolic linear unit. <em>IJMLC</em>,
<em>15</em>(11), 4867–4886. (<a
href="https://doi.org/10.1007/s13042-024-02184-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the recommendation system has become one of the important tools of e-commerce, which provides suggestions to the user for some resources such as hotels, songs, books, movies, etc. The existing hotel recommendation method has faced many problems such as data sparsity, cold-start problems, scalability, etc. Traditional Convolutional Neural Networks (CNNs) often struggle to capture long-term semantic characteristics, and their variants, such as Dilated CNNs, may encounter issues with gradient exploding. Moreover, Gated Recurrent Units (GRUs) and Bidirectional GRUs, while effective in capturing context information, may suffer from low learning efficiency and convergence challenges. Hence, this paper proposes the hotel recommendation system to use the hybrid of dilated multichannel convolutional neural network (MCNN) and bi-directional gated recurrent unit (BiGRU) with an attention mechanism. The main aim of this research is to develop a more efficient, scalable, regularized, and generalized recommendation system which can recommend the name of the hotels to the travellers based on their preferences by analysing the previous so far traveller’s comments together with the rating value to improve the forecast accuracy. The aspect based attention mechanisms are employed to evaluate the word, sentence, and semantic level similarity weight based vectors for mining useful information. The proposed approach has shown improved performance than existing approaches in terms of 99.46% Accuracy, 98.94% Precision, 98.84% Recall, and 98.75% F1-score.},
  archive      = {J_IJMLC},
  author       = {Jai Arul Jose, G. and Mastan, Mahammad and Al-Nuaimy, Louay A. Hussein},
  doi          = {10.1007/s13042-024-02184-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {11},
  number       = {11},
  pages        = {4867-4886},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Aspect based hotel recommendation system using dilated multichannel CNN and BiGRU with hyperbolic linear unit},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel ORESTE approach for MAGDM incorporating
probabilistic interval-valued linguistic information: Case studies in
higher education quality and the energy industry. <em>IJMLC</em>,
<em>15</em>(10), 4845–4866. (<a
href="https://doi.org/10.1007/s13042-024-02202-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute group decision making (MAGDM) is a pivotal tool in diverse evaluations. However, existing approaches often overlook attribute ambiguity and interrelationships, leading to unreliable outcomes. This article introduces a novel MAGDM support scheme that extends the widely accepted ORESTE (organísation, rangement et Synthese dèdonnees relarionnelles, in French) method to the context of Probabilistic Hesitant Interval-Value Sets (PHIVSs). PHIVSs integrate Hesitant Fuzzy Linguistic Terms (HFLTs) and Probabilistic Linguistic Term Sets (PLTSs) and transform conventional linguistic terms into interval-based expressions. This augmentation significantly extends their applicability in MAGDM scenarios, particularly those marked by elevated uncertainty. The conventional ORESTE model, a standard MAGDM tool, encounters limitations in intricate scenarios, resulting in data loss and necessitating more adaptive solutions. Our integrated PHIVS approach overcomes these challenges by incorporating fuzzy representation into ORESTE, enabling robust MAGDM solutions. Preferences are classified into three intensities based on likelihoods, establishing a structured Preference Intensity Relation (PIR). PIR effectively discerns among alternatives, elucidating preferences, indifference, or incomparability. This distinction proves invaluable in complex and uncertain decision-making across diverse domains. A key innovation of our approach lies in the unexplored application of PHIVS and ORESTE in MAGDM. Utilizing probability measures for PHIVSs, we establishes precise binary connections among alternatives for enhancing assessment and prioritization. The representation of evaluations with PHIVS and integration of likelihood measures offer an efficient solution for intricate MAGDM problems, particularly those laden with uncertainty. To illustrate the utility of our approach, we provide two comprehensive examples. These examples showcase the practicality and effectiveness of our approach in real-world assessments, highlighting its significance in advancing decision-making methodologies.},
  archive      = {J_IJMLC},
  author       = {Guo, Jing and Zhu, Xianjun and Li, Hui},
  doi          = {10.1007/s13042-024-02202-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4845-4866},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel ORESTE approach for MAGDM incorporating probabilistic interval-valued linguistic information: Case studies in higher education quality and the energy industry},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust adaptive control of uncertain dynamic systems using
self-evolving neural learning technique. <em>IJMLC</em>,
<em>15</em>(10), 4829–4843. (<a
href="https://doi.org/10.1007/s13042-024-02200-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an advanced self-evolving regressive neural (ASE-GRNN) algorithm developed to control of the highly nonlinear uncertain plants regarding to unknown dynamics and undetermined perturbations. The suggested ASE-GRNN architecture is adaptively online updated to satisfy the control purposes and to respond the time-varied external perturbations. This scheme can begin from scratch and adaptively updates not only its architecture but also its coefficients online to successfully satisfy the tracking task. Also, ASE-GRNN is able to not only add, trim, but also replace neurons online in terms of specific control problem, regardless internal/external perturbation, and implementation configurations. Then the coefficients’ online updated ability applied to the neural weighting values enhances ASE-GRNN performance. Two numerical benchmark tests, include a CSTR benchmark test and a BLDC-motor driving precision control system, are applied to verify the superiority and the feasibility of ASE-GRNN algorithm.},
  archive      = {J_IJMLC},
  author       = {Anh, Ho Pham Huy and Dat, Nguyen Tien},
  doi          = {10.1007/s13042-024-02200-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4829-4843},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust adaptive control of uncertain dynamic systems using self-evolving neural learning technique},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised incremental domain generalization learning
based on causal invariance. <em>IJMLC</em>, <em>15</em>(10), 4815–4828.
(<a href="https://doi.org/10.1007/s13042-024-02199-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, semi-supervised learning (SSL) methods based on pseudo-labeling algorithms have been widely applied and achieved significant success. However, most existing deep semi-supervised learning methods suffer from the problem of distribution shift between the source and target domains, as well as the issue of “cognitive bias” in pseudo labeling algorithms, where the model&#39;s errors are difficult to rectify as they accumulate through the pseudo-labeling process. This paper introduces the concept of causal invariance and proposes an incremental repeated labeling strategy with a high confidence threshold to enhance the utilization of unlabeled samples. It effectively solves the issue of distribution discrepancy between the source and target domains in the field of semi-supervised learning, as well as the problem of pseudo label &quot;cognitive bias&quot;, thus improving the accuracy of the model. Extensive experiments on CIFAR-10, CIFAR-100, SVHN, STL-10, PACS and VLCS demonstrate that semi-supervised incremental models based on causal invariance have a significant improvement in domain generalization ability compared with state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Ning and Wang, Huiling and Yang, Shaocong and Chu, Huan and Dong, Shi and Viriyasitavat, Wattana},
  doi          = {10.1007/s13042-024-02199-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4815-4828},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semi-supervised incremental domain generalization learning based on causal invariance},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive nonlinear whale optimization multi-layer
perceptron cyber intrusion detection framework. <em>IJMLC</em>,
<em>15</em>(10), 4801–4814. (<a
href="https://doi.org/10.1007/s13042-024-02193-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing prevalence of cyber threats has created a critical need for robust defense against such incidents. Many Cyber Intrusion Detection Systems (CIDSs), utilizing machine learning have been developed for this purpose. Although, these recent CIDSs have provided the capability to analyze vast amounts of data and identify malicious activities, there are still challenges to be tackled to enhance their effectiveness. The exponential growth of the search space is one of these challenges which makes finding an optimal solution computationally infeasible for large datasets. Furthermore, the weight space while searching for optimal weight is highly nonlinear. Motivated by the observed characteristics, complexities, and challenges in the field, this paper presents an innovative (CIDS) named ANWO-MLP (Adaptive Nonlinear Whale Optimization Multi-layer Perceptron). A novel feature selection method called ANWO-FS (Adaptive Nonlinear Whale Optimization-Feature Selection) is employed in the proposed CIDS to identify the most predictive features enabling robust MLP training even in the highly nonlinear weight spaces. The insider threat detection process is improved by investigating vital aspects of CIDS, including data processing, initiation, and output handling. We adopt ANWOA (previously proposed by us) to mitigate local stagnation, enable rapid convergence, optimize control parameters, and handle multiple objectives by initializing the weight vector in the ANWO-MLP training with minimal mean square error. Experiments conducted on three highly imbalanced datasets demonstrate an average efficacy rate of 98.33%. The details of the results below show the robustness, stability, and efficiency of the proposed ANWO-MLP compared to existing approaches.},
  archive      = {J_IJMLC},
  author       = {El-Ghaish, Hany and Miqrish, Haitham and Elmogy, Ahmed and Elawady, Wael},
  doi          = {10.1007/s13042-024-02193-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4801-4814},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An adaptive nonlinear whale optimization multi-layer perceptron cyber intrusion detection framework},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pronunciation guided copy and correction model for ASR error
correction. <em>IJMLC</em>, <em>15</em>(10), 4787–4799. (<a
href="https://doi.org/10.1007/s13042-024-02191-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error correction has proven to be an effective means for refining mistakes produced by Automatic Speech Recognition (ASR) models, thereby contributing to a notable reduction in the Word Error Rate (WER) at the ASR post-edit stage. Existing ASR error correction methods built upon sequence-to-sequence architecture may be suffered from the over-correction issue, resulting in the introduction of new mistakes or alterations to correct portions. In this paper, we propose a Pronunciation Guided Copy and Correction (PGCC) model for ASR error correction. Leveraging the fact that ASR hypotheses share a big overlap with the correct text and are frequently characterized by homophone errors, our approach incorporates a copy module into the BART pre-trained model’s encoder-decoder structure, this module optimally decides whether to retain a token from the source input (via copying) or generate a modified one through the decoder. Furthermore, a hierarchical phonetic feature encoder is designed to provide guidance to the copy module and BART decoder, implicitly identifying the positions of homophone errors and generating precise corrections. Experiments on two public datasets demonstrate the effectiveness of our proposed method, showcasing remarkable reductions of 18.18% and 44.84% in character error rate and outperforming solid baseline models.},
  archive      = {J_IJMLC},
  author       = {Dong, Ling and Wang, Wenjun and Yu, Zhengtao and Huang, Yuxin and Guo, Junjun and Zhou, Guojiang},
  doi          = {10.1007/s13042-024-02191-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4787-4799},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pronunciation guided copy and correction model for ASR error correction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Open-ti: Open traffic intelligence with augmented language
model. <em>IJMLC</em>, <em>15</em>(10), 4761–4786. (<a
href="https://doi.org/10.1007/s13042-024-02190-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation has greatly benefited the cities’ development in the modern civilization process. Intelligent transportation, leveraging advanced computer algorithms, could further increase people’s daily commuting efficiency. However, intelligent transportation, as a cross-discipline, often requires practitioners to comprehend complicated algorithms and obscure neural networks, bringing a challenge for the advanced techniques to be trusted and deployed in practical industries. Recognizing the expressiveness of the pre-trained large language models, especially the potential of being augmented with abilities to understand and execute intricate commands, we introduce Open-TI. Serving as a bridge to mitigate the industry-academic gap, Open-TI is an innovative model targeting the goal of Turing Indistinguishable Traffic Intelligence, it is augmented with the capability to harness external traffic analysis packages based on existing conversations. Marking its distinction, Open-TI is the first method capable of conducting exhaustive traffic analysis from scratch—spanning from map data acquisition to the eventual execution in complex simulations. Besides, Open-TI is able to conduct task-specific embodiment like training and adapting the traffic signal control policies (TSC), explore demand optimizations, etc. Furthermore, we explored the viability of LLMs directly serving as control agents, by understanding the expected intentions from Open-TI, we designed an agent-to-agent communication mode to support Open-TI conveying messages to ChatZero (control agent), and then the control agent would choose from the action space to proceed the execution. We eventually provide the formal implementation structure, and the open-ended design invites further community-driven enhancements. A demo video is provided at: https://youtu.be/pZ4-5PXz9Xs .},
  archive      = {J_IJMLC},
  author       = {Da, Longchao and Liou, Kuanru and Chen, Tiejin and Zhou, Xuesong and Luo, Xiangyong and Yang, Yezhou and Wei, Hua},
  doi          = {10.1007/s13042-024-02190-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4761-4786},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Open-ti: Open traffic intelligence with augmented language model},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local descriptor-based spatial cross attention network for
few-shot learning. <em>IJMLC</em>, <em>15</em>(10), 4747–4759. (<a
href="https://doi.org/10.1007/s13042-024-02189-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning aims to classify novel images based on a small number of labeled examples. While recent work has shown promise using local descriptors, existing methods generally classify local descriptors independently, which potentially can loss the spatial and other essential information for new tasks. Moreover, such works ignore the semantics expressed by local descriptors may be irrelevant to image semantics. In this paper, we propose two methods to address these challenges. Firstly, we design a novel Spatial Cross Attention Module to generate a spatial cross attention map between a query and a class representation to enhance the local descriptors that are most relevant to each task. Then, we employ dense classification loss, which supervises the learning of all local descriptors, to constrain the semantic consistency of local descriptors. Furthermore, we show that the feature extractor trained by our method can be extended to some new baseline methods to achieve better performance. Extensive experiments conducted on three widely used few-shot learning benchmark datasets indicate that our proposed method achieves the competitive results.},
  archive      = {J_IJMLC},
  author       = {Huang, Jiamin and Zhao, Lina and Yang, Hongwei},
  doi          = {10.1007/s13042-024-02189-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4747-4759},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Local descriptor-based spatial cross attention network for few-shot learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain generalization person re-identification via style
adaptation learning. <em>IJMLC</em>, <em>15</em>(10), 4733–4746. (<a
href="https://doi.org/10.1007/s13042-024-02188-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain generalization person re-identification (DG Re-ID) aims to deploy a Re-ID model trained on multiple source domains to unseen domains without adaptation, which is a practical and challenging problem. Due to the significant drop in performance of DG Re-ID methods on unseen target domains, Mixture of Experts (MoE) is used to set up an expert branch for each domain to learn its unique features and thus improve the identification performance on unseen target domains. However, most of the MoE-based DG Re-ID methods only aggregate multiple branch features to simulate the unseen target domain and ignore the role of style in classification recognition among different domains. To address these problems, we propose Style-Adaptive Learning DG Re-ID (SALDG) method, which includes Global Branch, Expert Branches, Class-level Style-adaptive Learning (CSL) module, and Domain-level Style-adaptive Learning (DSL) module. The Global Branch and the Expert Branches extract the global feature and different domain style features respectively. The CSL module can learn the style information of each domain, and the DSL module adaptively mixes the style information of each domain learned by the CSL module to form more complex style information and enhance style diversity in the global feature space. Through extensive experiments, compared with the state-of-the-art methods, the mAP and R-1 accuracy of SALDG on Market1501, DukeMTMC, CUHK03, MSMT17 datasets are improved by approximately 4.1% and 5% respectively.},
  archive      = {J_IJMLC},
  author       = {Guo, Yingchun and Dou, Xinsheng and Zhu, Ye and Wang, Xinyao},
  doi          = {10.1007/s13042-024-02188-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4733-4746},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Domain generalization person re-identification via style adaptation learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concept drift detection methods based on different weighting
strategies. <em>IJMLC</em>, <em>15</em>(10), 4709–4732. (<a
href="https://doi.org/10.1007/s13042-024-02186-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distribution of data often evolves over time, necessitating classifiers to adjust in order to maintain optimal classification accuracy. This phenomenon, termed “concept drift”, poses a significant challenge. Detectors specifically designed for identifying concept drift are typically integrated to bolster classifier performance. In this study, we introduce two innovative methodologies designed to address the prevalent issues of high miss detection, excessive false alarms, and prolonged detection latencies encountered in many contemporary concept drift detection algorithms. The first approach, termed the Hybrid Weighting-based Concept Drift Detection Method (HW_DDM), incorporates both linear and exponential weighting for long and short windows, respectively, within a composite window model. Subsequently, concept drift is detected by calculating the weighted mean value within the window, leveraging the Hoeffding and McDirmid inequality thresholds. The second strategy, named the Dynamic Weighting-based Hoeffding Drift Detection Method (DW_HDDM), employs a mechanism that dynamically adjusts the Hoeffding threshold and dynamically weights classification prediction outcomes, thereby catering to the drift and augmenting detection efficacy. Comparative evaluations using both synthetic and real-world datasets against leading-edge algorithms are presented. The empirical results underscore that HW_DDM exhibits the lowest false detection rate with negligible miss detections on synthetic datasets. In contrast, DW_HDDM shines with minimal detection delay, reduced miss detection rates, and a diminished false detection rate, demonstrating superior classification accuracy on real-world datasets when pitted against benchmark algorithms.},
  archive      = {J_IJMLC},
  author       = {Han, Meng and Mu, Dongliang and Li, Ang and Liu, Shujuan and Gao, Zhihui},
  doi          = {10.1007/s13042-024-02186-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4709-4732},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Concept drift detection methods based on different weighting strategies},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gas concentration prediction based on ED-SLSTM model under
the framework of trend prediction-time point prediction. <em>IJMLC</em>,
<em>15</em>(10), 4695–4707. (<a
href="https://doi.org/10.1007/s13042-024-02183-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problems of low prediction accuracy and inability to achieve long-term prediction in traditional coal mine gas concentration prediction, this paper proposes a new gas concentration prediction framework based on the problem of independent gate units of traditional Long Short Time Memory (LSTM) neural network—“Trend Prediction-Time Point Prediction” (TP-TPP) structure, and it is the first time to add a selection gate mechanism to the LSTM model to construct the Select LSTM (SLSTM) model, which is in line with the actual production pattern of coal mines. Firstly, the data of gas multi-parameter time series are processed, and then the input data features under the framework of trend prediction are reconstructed. Then the modified Snake Optimizer (SO) algorithm is used to simplify the parameter adjustment process of neural network. Here the Encoder–Decoder–SLSTM (ED-SLSTM) model is compared with LightGBM, LSTM, Bi-LSTM, LSTM-Attention and CEEMDAN-LSTM models under the framework of TP-TPP, respectively. The performance of each evaluation index in ED-SLSTM is closer to the real value than them of other models. The results show that ED-SLSTM has higher prediction accuracy and better prediction effect.},
  archive      = {J_IJMLC},
  author       = {Wang, Xiangqian and Xu, Ningke and Meng, Xiangrui},
  doi          = {10.1007/s13042-024-02183-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4695-4707},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Gas concentration prediction based on ED-SLSTM model under the framework of trend prediction-time point prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label feature selection via spectral clustering-based
label enhancement and manifold distribution consistency. <em>IJMLC</em>,
<em>15</em>(10), 4669–4693. (<a
href="https://doi.org/10.1007/s13042-024-02181-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection can effectively improve the performance and efficiency of subsequent learning tasks by selecting important features within multi-label data. However, for handling multiple labels, many approaches group them to gather insights for label fusion, but ignore the different importance of these label groups and treat them equally, which seems unfair to individual label groups and fails to consider their distinct significances. Moreover, for handling the relationship between features and labels, many multi-label feature selection methods efficiently achieve linear fitting of features and labels through manifold learning, but ignore fitting spatial distribution between feature space and label space. Motivated by these, this paper integrates label distribution learning and spectral clustering to evaluate the unique significance of each label group and construct an improved label space, which is then aligned with the feature space through manifold distribution consistency for multi-label feature selection. First, we propose a hypothetical model indicating the existence of a relationship among labels, wherein this relationship involves clustering subordinate labels around a central core label. On this basis, we employ spectral clustering to generate distinct label clusters by integrating density peaks, thereafter combining this with label distribution learning to assess the significance of each cluster. Then, we design a manifold distribution consistency evaluation, i.e., quantifying the structural disparity between feature space and the enhanced label space achieved through spectral clustering-based label enhancement strategy, so as to obtain a low-dimensional feature space and the optimal feature subset. Finally, experimental results showcase the superiority of our proposed multi-label feature selection algorithm when compared with five other algorithms, across several datasets from diverse domains.},
  archive      = {J_IJMLC},
  author       = {Shu, Wenhao and Cao, Dongtao and Qian, Wenbin},
  doi          = {10.1007/s13042-024-02181-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4669-4693},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-label feature selection via spectral clustering-based label enhancement and manifold distribution consistency},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation correlations-aware graph convolutional network with
text-enhanced for knowledge graph embedding. <em>IJMLC</em>,
<em>15</em>(10), 4659–4668. (<a
href="https://doi.org/10.1007/s13042-024-02179-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tail distribution is a difficult challenge for knowledge graph embedding. We expect to solve the problem by complementing the information through the neighbor aggregation mechanism of GCN. However, the GCN method and its derivations are unable to learn the representation of edges. To address this problem, we propose RCGCN-TE, Relation Correlations-aware Graph Convolutional Network with Text-Enhanced for knowledge graph embedding, which is the first effort to enable GCN to learn the representation of relations directly. First, the pre-trained language model is used to extract semantic information. Then, the relation correlation graph is constructed by defining the relation relevance function based on the co-occurrence pattern and semantic similarity of relations. Finally, two GCNS are designed to learn entities and relations respectively. Experimental results on tasks such as triple classification and link prediction are better than the baseline. For example, Hits@10, Hits@3, and Hits@1 improved by 8.23 $$\%$$ , 37.49 $$\%$$ , and 46.94 $$\%$$ , respectively, on the entity prediction task.},
  archive      = {J_IJMLC},
  author       = {Yu, Hong and Tang, Jinxuan and Peng, Zhihan and Wang, Ye},
  doi          = {10.1007/s13042-024-02179-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4659-4668},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relation correlations-aware graph convolutional network with text-enhanced for knowledge graph embedding},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Link prediction based on depth structure in social networks.
<em>IJMLC</em>, <em>15</em>(10), 4639–4657. (<a
href="https://doi.org/10.1007/s13042-024-02178-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is an important task in social network analysis. Considering that the properties of nodes in social networks are generally inaccurate, it is more reliable and effective to use the network structure features to predict the links in the network. However, a central challenge of such methods is how to fully mine and utilize the network structure information. Here, we introduce a deep structure link prediction model (DSLP), whose idea is to integrate multiple types of community structures and multiple topology features into one probability model. We detect three types of community structures, disjoint, crisp overlap and fuzzy overlap, and then design an edge probability parameter to reflect their importance. Additionally, we propose an effective method to aggregate multiple topology features based on nodes and paths. We perform extensive experiments on artificial networks and real-world social networks to compare the proposed method with nine baseline algorithms, and the results show that our method offers higher precision than that of these well-known approaches. Finally, we discuss the method of integrating trusted node properties and feature selection.},
  archive      = {J_IJMLC},
  author       = {Yang, Jie and Wu, Yu},
  doi          = {10.1007/s13042-024-02178-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4639-4657},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Link prediction based on depth structure in social networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified deep learning model for multitask representation and
transfer learning: Image classification, object detection, and image
captioning. <em>IJMLC</em>, <em>15</em>(10), 4617–4637. (<a
href="https://doi.org/10.1007/s13042-024-02177-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of deep learning has demonstrated impressive performance in computer vision tasks such as object detection, image classification, and image captioning. Though most models excel at performing single vision or language tasks, designing a single architecture that balances task specialization, performance, and adaptability across diverse tasks is challenging. To effectively address vision and language integration challenges, a combination of text embeddings and visual representation is necessary to understand dependencies of each subarea for multiple tasks. This paper proposes a single architecture that can handle various tasks in computer vision with fine-tuning capabilities for other specific vision and language tasks. The proposed model employs a modified DenseNet201 as a feature extractor (network backbone), an encoder-decoder architecture, and a task-specific head for inference. To tackle overfitting and improve precision, enhanced data augmentation and normalization techniques are employed. The model’s robustness is evaluated on over five datasets for different tasks: image classification, object detection, image captioning, and adversarial attack and defense. The experimental results demonstrate competitive performance compared to other works on CIFAR-10, CIFAR-100, Flickr8, Flickr30, Caltech10, and other task-specific datasets such as OCT, BreakHis, and so on. The proposed model is flexible and easy to adapt to new tasks, as it can also be extended to other vision and language tasks through fine-tuning with task-specific input indices.},
  archive      = {J_IJMLC},
  author       = {Bayisa, Leta Yobsan and Wang, Weidong and Wang, Qingxian and Ukwuoma, Chiagoziem C. and Gutema, Hirpesa Kebede and Endris, Ahmed and Abu, Turi},
  doi          = {10.1007/s13042-024-02177-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4617-4637},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unified deep learning model for multitask representation and transfer learning: Image classification, object detection, and image captioning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel aerospace target decision model considering will of
commander based on probability transformation. <em>IJMLC</em>,
<em>15</em>(10), 4603–4615. (<a
href="https://doi.org/10.1007/s13042-024-02176-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer evidence theory has been widely applied in the field of aerospace target decision. However, the existing aerospace target decision models are difficult to meet the changing war situation. For this reason, a novel aerospace target decision model based on probability transformation is proposed, which realizes the effective combination of humans and machines. Firstly, the true proposition preference degree is defined, which measures the proximity of the single-target and the true proposition ground on the average information of the single-target. Secondly, to assess the single-target more comprehensively, the support degree of the single-target ground on the normalized plausibility function and belief function is defined, which represents the support degree of the basic probability assignment function for the single-target. Finally, combined with the commanders’ judgment of the war situation, the aerospace target decision is achieved, which provides aid to the commanders in determining the attribute of the aircraft. According to some numerical examples, the proposed method can produce a reasonable and easy to make decision probability distribution, which can judge the target with higher accuracy in aerospace target decision.},
  archive      = {J_IJMLC},
  author       = {Hu, Zhentao and Su, Yujie and Qiu, Qian},
  doi          = {10.1007/s13042-024-02176-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4603-4615},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel aerospace target decision model considering will of commander based on probability transformation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Yolo-sd: Simulated feature fusion for few-shot industrial
defect detection based on YOLOv8 and stable diffusion. <em>IJMLC</em>,
<em>15</em>(10), 4589–4601. (<a
href="https://doi.org/10.1007/s13042-024-02175-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect detection from images, an important application in the development of the industrial internet, has been gaining increasing attention due to its close relationship with product quality in industrial production. However, two major challenges in defect detection persist: (1) Limited availability of datasets. Deep learning-based models typically require large-scale training sets to achieve satisfactory detection results. (2) Insufficient image quality and low detection accuracy. When many object detection methods are applied to industrial defect detection, they often exhibit poor performance in handling unclear boundaries, complex backgrounds, noise, and textures. In this study, we propose an advanced defect detection method based on YOLO and Stable Diffusion (YOLO-SD). For the few-shot dataset, a controllable generation module is designed, that integrates CLIP, LoRA, and ControlNet based on Stable Diffusion. Among them, CLIP text inversion can generate the most suitable prompt words from the defect dataset, providing prompt input for Stable Diffusion. LoRA can intervene and adjust the image style of Stable Diffusion by training on the defect dataset in a fine-tuning way. ControlNet obtains boundary and depth maps through HED and Midas. For the insufficient image quality and low detection accuracy, an improved YOLO model with an attention-based Fusion Simulated Feature module (FSF) is built that extracts defect features of the original images and generated images, which provides richer semantic information to improve the detection accuracy. At the same time, in order to make the model lightweight, we introduce a test optimization strategy to improve the model training process. Extensive experiments on the NEU-DET steel defect dataset show that the images generated by our method can expand the dataset to train the model and achieve a certain improvement in defect detection.},
  archive      = {J_IJMLC},
  author       = {Wen, Yihao and Wang, Li},
  doi          = {10.1007/s13042-024-02175-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4589-4601},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Yolo-sd: Simulated feature fusion for few-shot industrial defect detection based on YOLOv8 and stable diffusion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep generative clustering methods based on disentangled
representations and augmented data. <em>IJMLC</em>, <em>15</em>(10),
4575–4588. (<a
href="https://doi.org/10.1007/s13042-024-02173-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel clustering approach that utilizes variational autoencoders (VAEs) with disentangled representations, enhancing the efficiency and effectiveness of clustering. Traditional VAE-based clustering models often conflate generative and clustering information, leading to suboptimal clustering performance. To overcome this, our model distinctly separates latent representations into two modules: one for clustering and another for generation. This separation significantly improves clustering performance. Additionally, we employ augmented data to maximize mutual information between cluster assignment variables and the optimized latent variables. This strategy not only enhances clustering effectiveness but also allows the construction of latent variables that synergistically combine clustering information from original data with generative information from augmented data. Through extensive experiments, our model demonstrates superior clustering performance without the need for pre-training, outperforming existing deep generative clustering models. Moreover, it achieves state-of-the-art clustering accuracy on certain datasets, surpassing models that require pre-training.},
  archive      = {J_IJMLC},
  author       = {Xu, Kunxiong and Fan, Wentao and Liu, Xin},
  doi          = {10.1007/s13042-024-02173-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4575-4588},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep generative clustering methods based on disentangled representations and augmented data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale patch fuzzy decision for face recognition with
category information. <em>IJMLC</em>, <em>15</em>(10), 4561–4574. (<a
href="https://doi.org/10.1007/s13042-024-02169-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small size sample face recognition is one of the most challenging problems in image classification. Multi-scale patch collaborative representation is an effective method to deal with this problem. The existing methods only consider the sample information at different scales, ignoring category information in the process of multi-scale information fusion. However, different categories of images contain different information, which has a great impact on face recognition results. To solve this problem, this paper proposes a multi-scale patch fuzzy decision method for face recognition with category information, which considers the influence of different category information on image classification results. Firstly, the fuzzy decision matrix is introduced to describe the degree of samples belonging to different categories at a single scale. Then, a weight vector is introduced for each category to describe the importance of patch scales in the category. Specifically, each element of a weight vector represents the weight value of each scale in the corresponding category, so that each category could get a weight vector at all scales. Finally, the optimization objective function for face recognition is constructed by considering the classification information both from the same category and from different categories. Experimental results on six face databases showed that the proposed method is robust and superior to most advanced small-size sample face recognition methods.},
  archive      = {J_IJMLC},
  author       = {Pei, Shibing and Chen, Minghao and Wang, Changzhong},
  doi          = {10.1007/s13042-024-02169-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4561-4574},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-scale patch fuzzy decision for face recognition with category information},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised domain specificity for knowledge transfer.
<em>IJMLC</em>, <em>15</em>(10), 4549–4559. (<a
href="https://doi.org/10.1007/s13042-024-02165-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation (DA) aligns domain invariant features between different domains as much as possible, but domain-specific features are largely ignored. In this paper, our aim is to utilize specific information on the target domain to improve domain adaptation. To address this issue, a natural idea is to use another classifier to model-specific information independently, because it is difficult to combine the different features of the two domains in a single model. Specifically, we propose a two-branch network (TBN), which utilizes ground truth labels to train the source domain classifier and utilizes pseudo-labels to train the target domain classifier. Different classifiers were able to learn different domain-specific features. Considering the noise impact of pseudo-labels, we propose one-time clustering module to further boost the accuracy of pseudo-labels. In particular, TBN can be easily integrated into various DA methods to further improve their performance. The superiority of the proposed method is validated on several standard datasets.},
  archive      = {J_IJMLC},
  author       = {Wen, Chenglin and Zhao, Fangwen and Liu, Weifeng},
  doi          = {10.1007/s13042-024-02165-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4549-4559},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised domain specificity for knowledge transfer},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised fuzzy-rough extreme learning machine for
classification of cancer from microRNA. <em>IJMLC</em>, <em>15</em>(10),
4537–4548. (<a
href="https://doi.org/10.1007/s13042-024-02164-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The miRNA is a tiny, single-stranded RNA of nearly 22 nucleotides long that is transcribed from DNA and controls the genes in protein synthesis process. As expression levels of miRNAs vary significantly between cancerous and non-cancerous cells. Therefore, miRNAs can play a vital role in the development of cancer. Cancer classification from miRNA gene expression data is an area of interest to the bioinformatics and computational biology researches in recent past. However, traditional machine learning classifiers often do not produce the desired results due to lack of training patterns present in miRNA data. Additionally they are not often able to deal with overlapping, vague, uncertain, ambiguous and indiscernible cancer subtypes classes of the miRNA data. Motivated from the above said issues, we propose a novel semi-supervised fuzzy-rough based extreme learning machine (SSFRELM) method. Two stages are involved in the proposed method, where in the first stage, the soft class labels of the unlabeled samples are assigned using fuzzy-rough set theory, those are subsequently applied on the semi-supervised extreme learning machine in the second stage. The proposed SSFRELM method can improve classification accuracy since it utilizes unlabeled patterns together with limited labeled patterns in the learning process to develop the semi-supervised extreme learning machine and can handle the overlapping, vague, uncertainty, ambiguity, and indiscernibility usually present in miRNA gene expression data as it uses fuzzy-rough set theory. The proposed method is assessed using eight publicly available miRNA gene expression datasets from five different cancer types with respect to various classification evaluation measures in comparison to four other state-of-the-art methods. Experimental results justify that the proposed method outperformed the other counter-parts methods for cancer pattern classification. Paired t-test results also confirm the statistical significance of the better results achieved by the proposed SSFRELM over other methods for most of the cases.},
  archive      = {J_IJMLC},
  author       = {Kumar, Ansuman and Marak, Dikme Chisil B. and Halder, Anindya},
  doi          = {10.1007/s13042-024-02164-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4537-4548},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semi-supervised fuzzy-rough extreme learning machine for classification of cancer from microRNA},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive weighted self-representation method for
incomplete multi-view clustering. <em>IJMLC</em>, <em>15</em>(10),
4521–4536. (<a
href="https://doi.org/10.1007/s13042-024-02163-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multi-view data in reality, part of its elements may be missing because of human or machine error. Incomplete multi-view clustering (IMC) clusters the incomplete multi-view data according to the characters of various views of the instances. Recently, IMC has attracted much attention and many related methods have been proposed. However, the existing approaches still need to be developed and innovated in the following aspects: (1) current methods only consider the differences of different views, while the different influences of instances, as well as distinguishes between missing values and completed values are ignored. (2) The updating scheme for weighting matrix in adaptive weighted algorithms usually relies on an optimization sub-problem, whose optimal solution may not be easy to achieve. (3) The adaptive weighted subspace algorithms that can recover the incomplete data are anchor types. The randomness of the anchor matrix may cause unreliability. To tackle these limitations, we propose an adaptive weighted self-representation (AWSR) subspace method for IMC. The AWSR method tunes the weighting matrix adaptively in accordance with the views of different instances and the recovery process of the missing values. The low rank and smoothness constraints on the representation matrix make the subspace reveal the underlying features of the dataset accurately. We also analyze the convergence property of the block coordinate method for our optimization model theoretically. Numerical performance on five real-world data shows that the AWSR method is effective and delivers superior results when compared to other eight widely-used approaches considering the clustering accuracy (ACC), normalized mutual information (NMI) and Purity.},
  archive      = {J_IJMLC},
  author       = {Feng, Lishan and Zhou, Guoxu and Chang, Jingya},
  doi          = {10.1007/s13042-024-02163-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4521-4536},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An adaptive weighted self-representation method for incomplete multi-view clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual-encoder network based on multi-layer feature fusion
for infrared and visible image fusion. <em>IJMLC</em>, <em>15</em>(10),
4511–4520. (<a
href="https://doi.org/10.1007/s13042-024-02162-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion (IVIF) is to achieve the fused images with multimodal complementary information of source images. To effectively fuse the complementary information, a dual-encoder network based on multi-layer feature fusion for IVIF is proposed, which can effectively fuse the features of source images at different levels. Specifically, a deep semantic information fusion module (DSIFM) is constructed to merge the deep-level features of the network at different scales. Meanwhile, considering the difference between infrared and visible features, a shallow-middle information fusion module (SMIFM) is built to integrate the shallow and middle features obtained by two encoders with the deep features delivered by the network. Furthermore, a joint loss function including sensitivity loss and structural similarity loss is defined to preserve the salient targets and texture features of source images in the fusion result. Qualitative and quantitative experimental results confirm the superiority of the proposed method over state-of-the-art approaches. Specifically, our method improves the MI and SSIM metrics by 60.78% and 17.45%, respectively, compared to the deep learning-based approach with the best average values on the TNO dataset. Our code is available on the website: https://github.com/yotick/IJMLC .},
  archive      = {J_IJMLC},
  author       = {Huang, Shuying and Wu, Xueqiang and Yang, Yong and Wan, Weiguo and Wang, Xiaozheng},
  doi          = {10.1007/s13042-024-02162-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4511-4520},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A dual-encoder network based on multi-layer feature fusion for infrared and visible image fusion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building semi-supervised decision trees with semi-cart
algorithm. <em>IJMLC</em>, <em>15</em>(10), 4493–4510. (<a
href="https://doi.org/10.1007/s13042-024-02161-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees are a fundamental statistical learning tool for addressing classification and regression problems through a recursive partitioning approach that effectively accommodates numerical and categorical data [1, 2]. The Classification and regression tree (CART) algorithm underlies modern Boosting methodologies such as Gradient boosting machine (GBM), Extreme gradient boosting (XGBoost), and Light gradient boosting machine (LightGBM). However, the standard CART algorithm may require improvement due to its inability to learn from unlabeled data. This study proposes several modifications to incorporate test data into the training phase. Specifically, we introduce a method based on Graph-based semi-supervised learning called “Distance-based Weighting,” which calculates and removes irrelevant records from the training set to accelerate the training process and improve performance. We present Semi-supervised classification and regression tree (Semi-Cart), a new implementation of CART that constructs a decision tree using weighted training data. We evaluated its performance on thirteen datasets from various domains. Our results demonstrate that Semi-Cart outperforms standard CART methods and contributes to statistical learning.},
  archive      = {J_IJMLC},
  author       = {Abedinia, Aydin and Seydi, Vahid},
  doi          = {10.1007/s13042-024-02161-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4493-4510},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Building semi-supervised decision trees with semi-cart algorithm},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Redis-based full-text search extensions for relational
databases. <em>IJMLC</em>, <em>15</em>(10), 4475–4491. (<a
href="https://doi.org/10.1007/s13042-024-02160-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to overcome the inefficiency and resource consumption of full-text search in relational databases, a light full-text search model with auxiliary cache is developed. Specially, we utilize the MySQL as the data storage layer and the Redis as the index cache layer. We first design a full-index cache mechanism by the Redis-based inverted indexes construction methods to augment the efficient memory processing capability of relational databases. In addition, an increment-index synchronization mechanism is implemented to fit the dynamic update of relation database. For hot data, an index update optimization mechanism is provided to guarantee the fast response and accuracy of full-text search. The proposed Redis-based auxiliary cache method has also been put into practical industrial applications and achieved promising results. Finally, we evaluate our method from index space occupation, time consumption and the accuracy of retrieval results. The experimental results show that the proposed model outperforms MySQL Full-Text method 2–3 times and surpasses ElasticSearch 12 times in space resource consumption.},
  archive      = {J_IJMLC},
  author       = {Liao, Xuehua and Peng, Lilan and Yang, Ting and Li, Tianrui and Zhu, Zhousen},
  doi          = {10.1007/s13042-024-02160-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4475-4491},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Redis-based full-text search extensions for relational databases},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DP-u-net++: Inter-layer feature fusion for colorectal gland
image segmentation. <em>IJMLC</em>, <em>15</em>(10), 4459–4473. (<a
href="https://doi.org/10.1007/s13042-024-02159-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal adenocarcinoma is a common malignant digestive tract tumor from the colonic gland epithelium. The sliced microscopic images of the colorectal gland have great diversity in shapes, large differences in scale, and it is difficult for traditional networks to segment the glandular regions efficiently. In this paper, we propose a novel inter-layer feature fusion network named DP-U-Net++, which introduces improved deep feature fusion and enhanced dense skip-connection, and using pretrained ResNet-34 to extracts features. To combine with the advantages of Self Attention, position embedding is incorporated for correlation computation, and channel relevance in each layer is enhanced by an extra ECA block. Inspired by Attention U-Net, we propose a new structure called Dilated Spatial Attention Gate which expands the receptive field in feature fusion. Finally, the output features of the decoder derived from different branches are fused with low-level spatial features to achieve better performance. we conducted experiments on the GlaS and CRAG datasets and a verification experiment on the PH2 dataset. Compared with the baseline, our method improves metrics by 1.61% and 1.27% in dice coefficient and by 2.37% and 3.22% in mIOU on GlaS and CRAG, respectively. Experiments on gland segmentation datasets demonstrate that the proposed method in this paper outperforms baselines. Our source code can be found at https://github.com/icm162/ModelFrame .},
  archive      = {J_IJMLC},
  author       = {Peng, Ziyang and Peng, Kexin and Liu, Chengdao and Zhang, Xingzhi},
  doi          = {10.1007/s13042-024-02159-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4459-4473},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DP-U-net++: Inter-layer feature fusion for colorectal gland image segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust semi-supervised deep learning approach for emotion
recognition using EEG signals. <em>IJMLC</em>, <em>15</em>(10),
4445–4458. (<a
href="https://doi.org/10.1007/s13042-024-02158-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many deep learning models are recently proposed for Electroencephalography (EEG) classification tasks. However, they are full-supervised and require large amounts of labeled data. Labeling EEG signals is a time-consuming and expensive process needing many trials and careful analysis by the experts. Recently, many modern semi-supervised methods are proposed that require less supervised information to achieve competitive performance with that of supervised ones, but they are mainly developed in the computer vision domain and adapting these methods for EEG applications is an open issue. This paper presents a robust semi-supervised deep Learning method. To this end, we design appropriate augmentations for EEG signals leading to promising results in a low-supervised setting. Especially, compared to naïve Gaussian noise used in previous work, the proposed strong augmentation boosts the performance of our method by a large margin. We also enhance our method by utilizing distribution alignment and relative confidence threshold techniques. We carry out several experiments on the Database for Emotion Analysis using Physiological dataset in both valence/arousal emotion recognition tasks. The results confirm that the proposed method leverage the unlabeled information effectively and significantly outperforms the peer methods.},
  archive      = {J_IJMLC},
  author       = {Al-Asadi, Ahmed Waleed and Salehpour, Pedram and Aghdasi, Hadi S.},
  doi          = {10.1007/s13042-024-02158-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4445-4458},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A robust semi-supervised deep learning approach for emotion recognition using EEG signals},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Translation model based on discrete fourier transform and
skipping sub-layer methods. <em>IJMLC</em>, <em>15</em>(10), 4435–4444.
(<a href="https://doi.org/10.1007/s13042-024-02156-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine translation quality has seen tremendous improvement since the development of neural machine translation. However, translation models are memory intensive, with expensive hardware facilities and slow training speed. To reduce memory requirements and speed up translation, we propose the Transformer Discrete Fourier method with Skipping Sub-Layer (TF-SSL), which incorporates the discrete Fourier transform and a Skipping Sub-Layer algorithm, after relative positional embedding for Chinese and English source sentences. The input sequence is based on a Transformer model in the relative positional embedding layer, and the text is transformed into word vectors with information encoding via the embedding matrix, so that the word vectors can effectively capture interdependences between the texts. We distribute the transform coefficient matrix after the 2D Fourier transform near the center of the Encoder layer with a short matrix of transform coefficients, which accelerates translation on a GPU. The accuracy and speed are improved by skipping the sub-layer method, and the sub-layer is randomly omitted to introduce disturbance to the training, thus imposing greater constraint effects on the sub-layers. We conduct the ablation study and comparative analyses. Results show that our approach achieves improvement in both BLEU scores and GFLOPS values compared to the baseline Transformer model and other deep learning models.},
  archive      = {J_IJMLC},
  author       = {Li, Yuchen and Chen, Shuxu and Liu, Zhuoya and Che, Chao and Zhong, Zhaoqian},
  doi          = {10.1007/s13042-024-02156-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4435-4444},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Translation model based on discrete fourier transform and skipping sub-layer methods},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised deep hashing with multiple similarity
preservation for cross-modal image-text retrieval. <em>IJMLC</em>,
<em>15</em>(10), 4423–4434. (<a
href="https://doi.org/10.1007/s13042-024-02154-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep hashing cross-modal image-text retrieval has the advantage of low storage cost and high retrieval efficiency by mapping different modal data into a Hamming space. However, the existing unsupervised deep hashing methods generally relied on the intrinsic similarity information of each modal for structural matching, failing to fully consider the heterogeneous characteristics and semantic gaps of different modalities, which results in the loss of latent semantic correlation and co-occurrence information between the different modalities. To address this problem, this paper proposes an unsupervised deep hashing with multiple similarity preservation (UMSP) method for cross-modal image-text retrieval. First, to enhance the representation ability of the deep features of each modality, a modality-specific image-text feature extraction module is designed. Specifically, the image network with parallel structure and text network are constructed with the vision-language pre-training image encoder and multi-layer perceptron to capture the deep semantic information of each modality and learn a common hash code representation space. Then, to bridge the heterogeneous gap and improve the discriminability of hash codes, a multiple similarity preservation module is builded based on three perspectives: joint modal space, cross-modal hash space and image modal space, which aids the network to preserve the semantic similarity of modalities. Experimental results on three benchmark datasets (Wikipedia, MIRFlickr-25K and NUS-WIDE) show that UMSP outperforms other unsupervised methods for cross-modal image-text retrieval.},
  archive      = {J_IJMLC},
  author       = {Xiong, Siyu and Pan, Lili and Ma, Xueqiang and Hu, Qinghua and Beckman, Eric},
  doi          = {10.1007/s13042-024-02154-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4423-4434},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised deep hashing with multiple similarity preservation for cross-modal image-text retrieval},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Seq2Seq-AFL: Fuzzing via sequence-to-sequence model.
<em>IJMLC</em>, <em>15</em>(10), 4403–4421. (<a
href="https://doi.org/10.1007/s13042-024-02153-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzing is a technique in which anomalous data is fed into software to find potential bugs. It is mainly used to discover vulnerabilities including but not limited to buffer overflows, memory leaks, and crashes when handling abnormal inputs. However, to ensure all inputs are valid in Fuzzing is infeasible in practice due to the high instrumentation overhead. Popular Fuzzers (e.g., AFL) often generate a large number of invalid mutations when performing Fuzzing, which prevents Fuzzers from discovering potential paths that lead to new crashes. More importantly, it prevents Fuzzers from making wise decisions on fuzzing operators. In this article, we propose a mutation sensitive Fuzzing solution Seq2Seq-AFL, in which mutation operator and mutation position are simultaneously taken into account, and different Seq2Seq models are designed to perform optimization scheme. The optimization scheme is capable of efficiently training a function for obtaining mutation operator and mutation position pairs, and utilizes the function to conduct Fuzzing. To verify the effectiveness of our scheme, we construct the dataset with two-dimensional vector data that corresponding to objdump, readelf, and nm programs. The experiment results demonstrate that our proposed scheme significantly improves the performance of the state-of-the-art AFL Fuzzing tool, with the coverage improvements of 13.7%, 17.6% and 6.9% of objdump, readelf and nm, respectively. Especially, Seq2Seq-AFL exposes a total of 21 Crashes for objdump.},
  archive      = {J_IJMLC},
  author       = {Yang, Liqun and Wei, Chaoren and Yang, Jian and Ma, Jinxin and Guo, Hongcheng and Cheng, Long and Li, Zhoujun},
  doi          = {10.1007/s13042-024-02153-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4403-4421},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Seq2Seq-AFL: Fuzzing via sequence-to-sequence model},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-level attention long short-term memory neural
network based on rival rise algorithm for traffic volume prediction.
<em>IJMLC</em>, <em>15</em>(10), 4389–4402. (<a
href="https://doi.org/10.1007/s13042-024-02152-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of traffic volume forecasting, several critical factors, such as weather conditions, have often been neglected. Consequently, we present a novel multi-level attention mechanism (MA) that integrates considerations of both weather and spatial-temporal aspects. Furthermore, we employ the multi-level attention mechanism within the Long Short-Term Memory (MALSTM) model to effectively capture pertinent features from high-dimensional data. However, it is important to note that the performance of deep learning methods is significantly influenced by hyperparameters. Within this paper, we introduce the Rival Rise Algorithm (RRA), a novel nature-inspired intelligence algorithm that mimics competitive behaviors found in nature. The strategies employed by RRA encompass two stages: the ’self-improve stage’ and the ’imitate-improve stage’. To evaluate the efficiency of the algorithm, we employ 13 commonly used optimization mathematical problems, covering both unimodal and multimodal scenarios. The results conclusively illustrate that the proposed RRA surpasses SFOA, DSFGWO, GWO, SSA, and CSSA in terms of accuracy, stability, and robustness. Furthermore, as a case study, we utilize the RRA-MALSTM model to predict traffic flows at an intersection located in Shenzhen, China, and metro passenger flows at a staion located in Minneapolis, Ameroca. When compared to traditional prediction models in SHenzhen dataset, MALSTM yields a performance of 2.3401 compared to STLSTM’s 2.3719, demonstrating a growth of 1.3%, and the RRA with improvement rates of 2.1% and 2.2%, respectively. Additionally, MALSTM outperforms LSTM with MAE at 230.89 and RMSE at 339.56 by 18.1% and 23.3%, showcasing the benefits of multi-attention, while RRA outperforms GWO, the least effective among the eight algorithms, showing improvements in MAE by 1.5% and RMSE by 2.9%.},
  archive      = {J_IJMLC},
  author       = {Liao, Kaili and Zhou, Wuneng},
  doi          = {10.1007/s13042-024-02152-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4389-4402},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-level attention long short-term memory neural network based on rival rise algorithm for traffic volume prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HDRC: A subjective quality assessment database for
compressed high dynamic range image. <em>IJMLC</em>, <em>15</em>(10),
4373–4388. (<a
href="https://doi.org/10.1007/s13042-024-02151-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the quality of high dynamic range (HDR) images has emerged as a challenging and contemporary topic with the proliferation of HDR content. In this work, a new HDR compression (HDRC) database is proposed, aiming to provide a benchmark for the development of full-reference HDR image quality assessment (IQA) algorithms when facing the latest HDR compression distortions. In particular, the proposed HDRC database is the first HDR-IQA database to incorporate Versatile Video Coding (VVC) compression distortions, closely associated with practical application scenarios. Furthermore, the proposed HDRC database is currently the largest HDR-IQA database, including 80 reference images and 400 distorted images. Extensive experiments are conducted by studying the performance compared to existing HDR-IQA databases when evaluating three HDR-specific IQA models and nine IQA models prevalent for low dynamic range (LDR) content, revealing the challenges the proposed HDRC database brings. The results indicate that the existing IQA models demonstrate noticeable decreases in accuracy when assessing new compression distortions, underscoring the need for the development of novel HDR-IQA models. Consequently, the suggested HDRC database can serve as a potential database for HDR-IQA research, fostering a comprehensive exploration of the associated fields.},
  archive      = {J_IJMLC},
  author       = {Liu, Yue and Ni, Zhangkai and Chen, Peilin and Wang, Shiqi and Kwong, Sam},
  doi          = {10.1007/s13042-024-02151-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4373-4388},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {HDRC: A subjective quality assessment database for compressed high dynamic range image},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning structure perception MLPs on graphs: A layer-wise
graph knowledge distillation framework. <em>IJMLC</em>, <em>15</em>(10),
4357–4372. (<a
href="https://doi.org/10.1007/s13042-024-02150-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are expressive in dealing with graph data. Because of the large storage requirements and the high computational complexity, it is difficult to deploy these cumbersome models in resource-constrained environments. As a representative model compression strategy, knowledge distillation (KD) is introduced into graph analysis research to address this problem. However, there are some crucial challenges in existing graph knowledge distillation algorithms, such as knowledge transfer effectiveness and student model designation. To address these problems, a new graph distillation model is proposed in this paper. Specifically, a layer-wise mapping strategy is designed to distill knowledge for training the student model, in which staged knowledge learned by intermediate layers of teacher GNNs is captured to form supervision signals. And, an adaptive weight mechanism is developed to evaluate the importance of the distilled knowledge. On this basis, a structure perception MLPs is constructed as the student model, which can capture prior information of the input graph from the perspectives of node feature and topology structure. In this way, the proposed model shares the prediction advantage of GNNs and the latency advantage of MLPs. Node classification experiments on five benchmark datasets demonstrate the validity and superiority of our model over baseline algorithms.},
  archive      = {J_IJMLC},
  author       = {Du, Hangyuan and Yu, Rong and Bai, Liang and Bai, Lu and Wang, Wenjian},
  doi          = {10.1007/s13042-024-02150-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4357-4372},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning structure perception MLPs on graphs: A layer-wise graph knowledge distillation framework},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards platform profit-aware fairness in personalized
recommendation. <em>IJMLC</em>, <em>15</em>(10), 4341–4356. (<a
href="https://doi.org/10.1007/s13042-024-02149-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable progress of machine learning has had a significant impact on decision-making, thus fairness is an important topic. Existing fair recommendation methods generally design a constraint framework between consumer satisfaction or item exposure in the optimization model. However, these methods only focus on the fairness of consumers and items, but fail to ensure the fairness of platforms. Ignoring platform fairness may lead to an imbalance between consumer satisfaction and platform profit. In this paper, we propose a novel recommendation method based on fairness called CPG-FairRec, which consists of three modules: Data division module, Global fairness-aware module and Local fairness-aware module. Data division module divides the consumers and items into two groups based on spendings and prices, respectively. Global fairness-aware module learns the difference_score of the item group and consumer group based on the consumer’s historical behavior, and continuously balance the satisfaction of consumer group and the exposure of item group. Local fairness-aware module aims to optimize the exposure of individual item through the greedy algorithm based on the item price to achieve higher platform profit. We conduct experiments on two real-world datasets and results demonstrate the superiority of the CPG-FairRec in recommendation quality and profitability.},
  archive      = {J_IJMLC},
  author       = {Liu, Shenghao and Sun, Jiayang and Deng, Xianjun and Wang, Heng and Liu, Wei and Zhu, Chenlu and Yang, Laurence T. and Wu, Celimuge},
  doi          = {10.1007/s13042-024-02149-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4341-4356},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Towards platform profit-aware fairness in personalized recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Low resource neural machine translation model optimization
based on semantic confidence weighted alignment. <em>IJMLC</em>,
<em>15</em>(10), 4325–4340. (<a
href="https://doi.org/10.1007/s13042-024-02148-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of neural machine translation models based on the Transformer architecture is contingent upon the quality of the data. When the training data contains a high proportion of noise, the performance of the model deteriorates. This paper addresses the issue of diminished model capability in the presence of noisy datasets by proposing an optimization method based on semantic confidence-weighted alignment. This method integrates alignment metrics and model parameter confidence adjustments to recalibrate loss weights, thereby enhancing the model’s ability to identify and process noisy data. Experimental results demonstrate that this approach significantly improves the performance of translation models, particularly in low-resource language pairs such as Malay-Chinese, especially when dealing with noisy datasets. Compared to traditional methods, there is a notable increase in BLEU scores.},
  archive      = {J_IJMLC},
  author       = {Zhuang, Xuhui and Gao, ShengXiang and Yu, ZhengTao and Guo, Junjun and Wang, XiaoCong},
  doi          = {10.1007/s13042-024-02148-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4325-4340},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Low resource neural machine translation model optimization based on semantic confidence weighted alignment},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the estimation of distribution algorithm with a
differential mutation for multilevel thresholding image segmentation.
<em>IJMLC</em>, <em>15</em>(10), 4255–4323. (<a
href="https://doi.org/10.1007/s13042-024-02146-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation consists of separating an image into regions that are entirely different from each other, and multilevel thresholding is a method used to perform this task. This article proposes an Estimation of Distribution Algorithms (EDA) combined with a Differential Evolution (DE) operator as a metaheuristic to solve the multilevel thresholding problem. The proposal is called the Differential Mutation Estimation of Distribution Algorithm (DMEDA), where the inclusion of the Differential Mutation increases the standard EDA’s exploration capacity. The performance of the DMEDA for image segmentation is tested using Otsu’s between-class variance and Kapur’s entropy as objective functions applied separately over the Berkeley Segmentation Data Set 300 (BSDS300). Besides, a comparative study includes eight well-known algorithms in the literature. In this sense, statistical and non-parametric tests are performed to verify the efficiency of the DMEDA in solving the image segmentation problem from an optimization perspective. In terms of segmentation, different metrics are employed to verify the capabilities of the DMEDA to segment digital images properly. Regarding the two objective functions, the proposed DMEDA obtains better results in 97% of the experiments for Otsu’s between-class variance and 85% for Kapur’s entropy.},
  archive      = {J_IJMLC},
  author       = {Ramos-Frutos, Jorge Armando and Miguel-Andrés, Israel and Oliva, Diego and Casas-Ordaz, Angel},
  doi          = {10.1007/s13042-024-02146-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {10},
  number       = {10},
  pages        = {4255-4323},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving the estimation of distribution algorithm with a differential mutation for multilevel thresholding image segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection in high-dimensional data: An enhanced RIME
optimization with information entropy pruning and DBSCAN clustering.
<em>IJMLC</em>, <em>15</em>(9), 4211–4254. (<a
href="https://doi.org/10.1007/s13042-024-02143-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When confronted with high-dimensional data, evolutionary feature selection methods encounter the formidable challenge known as the “curse of dimensionality”. To overcome this challenge, our study delves into developing an optimized algorithm, enhanced RIME (ERIME), which ingeniously integrates feature information entropy pruning and the DBSCAN spatial clustering particle evolution method to tackle the intricacies of feature selection. Initially, a dimensionality reduction strategy is introduced based on feature information entropy pruning, effectively limiting the computational burden associated with high-dimensional data. This strategy enhances the algorithm’s search speed and substantially boosts its overall efficiency. Hence, a particle deletion strategy is proposed to safeguard the quality of particles within the population, selectively eliminating particles through multidimensional clustering while monitoring individual fitness differences. Additionally, we incorporate a particle generation strategy rooted in the Markov chain Monte Carlo method, strategically sampling and generating new particles from the distribution of superior particles. The efficacy of the ERIME is rigorously evaluated on 26 benchmark datasets, including 14 high-dimensional datasets and 12 low-dimensional datasets. A comprehensive comparison is conducted with seven cutting-edge intelligent algorithms: IMFO, PSO_GWO, MCGSA, BBPS, QBBA, SSA, and WOA. The experimental results demonstrate the algorithm’s ability to obtain exceptional feature subsets, notably showcasing its competitive edge in resolving high-dimensional feature selection challenges. Regarding average fitness value, ERIME attains a remarkable 79.54% improvement in convergence accuracy compared to RIME. Regarding the average classification error rate, ERIME achieves an impressive 98.54% reduction compared to RIME. Furthermore, in effectively selecting features, ERIME outperforms RIME by reducing the count by 85%. In conclusion, the enhanced RIME algorithm proposed in this study effectively solves the complex problems of high-dimensional feature selection.},
  archive      = {J_IJMLC},
  author       = {Wu, Huangying and Chen, Yi and Zhu, Wei and Cai, Zhennao and Heidari, Ali Asghar and Chen, Huiling},
  doi          = {10.1007/s13042-024-02143-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4211-4254},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection in high-dimensional data: An enhanced RIME optimization with information entropy pruning and DBSCAN clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EEG-based detection of cognitive load using VMD and LightGBM
classifier. <em>IJMLC</em>, <em>15</em>(9), 4193–4210. (<a
href="https://doi.org/10.1007/s13042-024-02142-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive load, which alters neuronal activity, is essential to understanding how the brain reacts to stress. This work aims to classify electroencephalogram (EEG) signals to detect cognitive load by extracting features from intrinsic mode functions (IMFs). The variational mode decomposition (VMD) was used for the eight-level decomposition of each EEG channel data (4 s). Next, entropy-based features were extracted from each IMF. The extracted features were fed to supervised machine learning (ML) classifiers: light gradient boosting machine (LightGBM), extreme gradient boosting (XGBoost), and categorical boosting (CatBoost) for classification. Experiments are conducted on two public EEG datasets, multi-arithmetic tasks (MAT) and simultaneous task EEG workload (STEW). The performance is measured via accuracy, specificity, sensitivity, positive predictive value, log-loss score, F1 score, and area under receiver operating curves (AUROC). The proposed LightGBM classifier technique demonstrates superior classification accuracy rates of 97.22% and 95.51% for the MAT and STEW datasets. The experiment results demonstrated that the proposed technique detects cognitive load more precisely than existing methods. The LightGBM classifier model enhanced accuracy and sensitivity in predicting outcomes through the utilization of ML and data mining methods.},
  archive      = {J_IJMLC},
  author       = {Jain, Prince and Yedukondalu, Jammisetty and Chhabra, Himanshu and Chauhan, Urvashi and Sharma, Lakhan Dev},
  doi          = {10.1007/s13042-024-02142-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4193-4210},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {EEG-based detection of cognitive load using VMD and LightGBM classifier},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building on prior lightweight CNN model combined with
LSTM-AM framework to guide fault detection in fixed-wing UAVs.
<em>IJMLC</em>, <em>15</em>(9), 4175–4191. (<a
href="https://doi.org/10.1007/s13042-024-02141-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fixed-wing UAVs (FW-UAVs) are empowered to handle diverse civilian and military missions, but sensor failure scenarios are constantly rising. Rapid advancement in deep learning methods currently proposes state-of-the-art solutions for fault detection of UAVs. However, most recent deep learning-based detection models suffer from model size, high computational complexity, and high-power consumption, which are challenging for small-sized FW-UAVs with limited battery backup and computational power. Therefore, to overcome these problems, this article introduces a lightweight CNN model built on prior work combined with the LSTM-AM framework to obtain accurate fault detection of FW-UAVs with low power consumption and fast computations. First, lightweight CNN architecture aims to minimize computational complexity while maintaining high accuracy in fault detection. The LSTM model merged with Attention Mechanism (AM), allows the architecture to obtain temporal dependencies and concentrate on essential features for enhanced fault detection accuracy. The combined version of lightweight CNN, LSTM, and AM commits to more reliable and efficient fault detection in FW-UAV applications, improving UAV drones’ overall performance and safety.},
  archive      = {J_IJMLC},
  author       = {Kumar, Aakash and Wang, Shifeng and Shaikh, Ali Muhammad and Bilal, Hazrat and Lu, Bo and Song, Shigeng},
  doi          = {10.1007/s13042-024-02141-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4175-4191},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Building on prior lightweight CNN model combined with LSTM-AM framework to guide fault detection in fixed-wing UAVs},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interval-valued test cost sensitive attribute reduction
related to risk attitude. <em>IJMLC</em>, <em>15</em>(9), 4155–4174. (<a
href="https://doi.org/10.1007/s13042-024-02140-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is a typical topic in the field of rough sets. As an extension of this topic, test cost sensitive attribute reduction has garnered considerable attention in recent years, and scholars have made many achievements. However, existing research commonly operates under the assumption that test costs are exact values, disregarding the challenges associated with quantifying test costs accurately in certain real-world contexts. In light of the situation, this paper employs the form of interval values to represent the possible range of test costs and then studies the problem of attribute reduction based on interval-valued test costs. Firstly, a theoretical model for interval-valued test cost sensitive attribute reduction is constructed by utilizing a ranking method of intervals. In this model, some important concepts and properties are discussed. Especially, considering that the risk attitudes of different decision-makers may affect the decision results, an optimization problem related to risk attitude is formulated. Secondly, a backtracking algorithm and a heuristic algorithm are developed for tackling the optimization problem, along with the application of a competition strategy to enhance the heuristic algorithm’s performance. Finally, the performance of the two algorithms is evaluated on multiple UCI datasets, and comparisons are drawn with several state-of-the-art attribute reduction methods. Experimental analyses well illustrate the effectiveness and superiority of the suggested algorithms. It is hoped that this work provides new insights into cost sensitive attribute reduction from the perspective of cost uncertainty and provides a reference for decision-making problems.},
  archive      = {J_IJMLC},
  author       = {Lu, Yaqian and Liao, Shujiao and Yang, Wenyuan and Guan, Ya’nan and Wu, Di},
  doi          = {10.1007/s13042-024-02140-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4155-4174},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Interval-valued test cost sensitive attribute reduction related to risk attitude},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PSO-ECM: Particle swarm optimization-based evidential
c-means algorithm. <em>IJMLC</em>, <em>15</em>(9), 4133–4153. (<a
href="https://doi.org/10.1007/s13042-024-02139-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extension of Fuzzy C-Means (FCM), Evidence C-Means (ECM) is proposed in the framework of Dempster–Shafer theory (DST) and has been applied to many fields. However, the objective function of ECM involves only the distortion between the object and the prototype, which relies heavily on the initial prototype. Therefore, ECM may encounter the problem of local optimization. To solve this problem, this paper introduces ECM with Particle Swarm Optimization (PSO) initialization to determine the initial clustering centroids, and proposes Particle Swarm Optimization-based Evidential C-Means (PSO-ECM), which reduces the influence of bad initial prototypes and improves the local optimality problem of ECM. PSO-ECM is compared with three other clustering algorithms in four experiments and with ECM on a noise-containing dataset. According to the experimental results, PSO-ECM performs well in terms of different clustering validity metrics compared with existing clustering algorithms, has high stability of clustering, and can effectively and stably cluster noise-containing datasets and accurately identify outlier points.},
  archive      = {J_IJMLC},
  author       = {Cai, Yuxuan and Zhou, Qianli and Deng, Yong},
  doi          = {10.1007/s13042-024-02139-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4133-4153},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PSO-ECM: Particle swarm optimization-based evidential C-means algorithm},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TARN: A lightweight two-branch adaptive residual network for
image super-resolution. <em>IJMLC</em>, <em>15</em>(9), 4119–4132. (<a
href="https://doi.org/10.1007/s13042-024-02138-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, single-image super-resolution (SISR) methods based on convolutional neural networks have achieved remarkable results. However, most methods improve the reconstruction performance of the network by increasing the depth and complexity of the network, which leads to an increase in the computation and storage of the network. To address this problem, this paper proposes a new lightweight two-branch adaptive residual network (TARN) for SISR reconstruction. To effectively utilize the residual features, a two-branch adaptive residual block (TARB) based on the lattice linear combination structure is designed. In TARB, an attention residual block (ARB) is built by combining residual learning and attention mechanisms, which can realize the interactive learning of two branches and retain the most useful feature information for SISR reconstruction. To realize the learning of hierarchical features of different depths, multiple TARBs are cascaded to form the backbone structure of TARN. Furthermore, the features extracted by TARBs are aggregated into a feature bank, and then a distillation fusion block (DFB) is designed to perform features compression and distillation by recalibrating the channel feature responses and adaptively assigning weights. Experimental results on multiple datasets show that the proposed TARN achieves better subjective performance and quantitative results than most state-of-the-art lightweight networks. Specifically, the proposed TARN achieves the higher PSNR values (32.20, 28.19, and 26.15) and SSIM values (0.9289, 0.8529, and 0.7874) than all the comparison methods on the Urban100 dataset in terms of 2 × , 3 × , and 4 × super-resolution, respectively.},
  archive      = {J_IJMLC},
  author       = {Huang, Shuying and Wang, Jichao and Yang, Yong and Wan, Weiguo},
  doi          = {10.1007/s13042-024-02138-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4119-4132},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TARN: A lightweight two-branch adaptive residual network for image super-resolution},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A real-valued label noise cleaning method based on ensemble
iterative filtering with noise score. <em>IJMLC</em>, <em>15</em>(9),
4093–4118. (<a
href="https://doi.org/10.1007/s13042-024-02137-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data always contain noise for a variety of reasons. In a regression task, noisy labels interfere with the construction of an accurate model, leading to a decline in the prediction accuracy. Methods that have emerged to deal with continuous label noise are rather limited in contrast with those on class noise cleaning techniques. To address this gap, we propose a novel noise filter to clean noisy instances with real-valued label noise. This method combines several filtering strategies. First, an iterative filtering process is carried out, allowing us to avoid using potential noisy examples in each new filtering iteration. Second, we develop a noise score to assess the noise level of each detected noisy instance. The higher the noise score is, the more likely that the instance is noisy. Finally, an ensemble filtering scheme is implemented. The fusion of detection from different models makes the determination of noisy examples even more reliable. The validity of the proposed method is verified through extensive experiments. We discuss the selection of the best hyperparameters, and compare the developed method with several state-of-the-art noise filters using public regression datasets. The outcomes show that our method not only achieves a good balance between the elimination of noisy samples and the retention of clean samples but also outperforms all the other compared methods, especially at higher noise levels. Simultaneously, the results of a case study of temperature prediction in an electric arc furnace suggest that training a domain-related regressor on a dataset preprocessed with the proposed noise filter contributes to a great improvement in the prediction accuracy.},
  archive      = {J_IJMLC},
  author       = {Li, Chuang and Mao, Zhizhong and Jia, Mingxing},
  doi          = {10.1007/s13042-024-02137-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4093-4118},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A real-valued label noise cleaning method based on ensemble iterative filtering with noise score},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RSGNN: Residual structure graph neural network.
<em>IJMLC</em>, <em>15</em>(9), 4079–4092. (<a
href="https://doi.org/10.1007/s13042-024-02136-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to conventional artificial neural networks, Graph Neural Networks (GNNs) better handle graph-structured data. Graph topology plays an important role in learning graph representations and impacts the performance of GNNs. However, existing GNNs encounter challenges in adequately capturing and representing the entire graph topology. In order to better capture the information about topological graph structures during message-passing, we propose a novel GNN architecture called Residual Structure Graph Neural Network (RSGNN). Specifically, RSGNN constructs residual links on local subgraphs to express the potential relationships between nodes, thus compensating for the lack of structural information solely conveyed by real edge connections. Meanwhile, the influence of edge structures of neighbor nodes is considered. We conduct comprehensive experiments on various graph benchmark datasets to evaluate the efficacy of the proposed RSGNN model. The experimental results demonstrate that our model outperforms existing state-of-the-art methods and alleviates the over-smoothing issue.},
  archive      = {J_IJMLC},
  author       = {Chen, Shuang and Zhang, Changlun and Gu, Fan and Wang, Haochen},
  doi          = {10.1007/s13042-024-02136-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4079-4092},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RSGNN: Residual structure graph neural network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised domain adaptation by incremental learning for
concept drifting data streams. <em>IJMLC</em>, <em>15</em>(9),
4055–4078. (<a
href="https://doi.org/10.1007/s13042-024-02135-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental learning is a learning paradigm in which a model is updated continuously as new data becomes available, and its main challenge is to adapt to non-stationary environments without the time-consuming re-training process. Many efforts have been made on incremental supervised learning. However, providing sufficient labeled data remains a major problem. Recently, domain adaptation methods have gained attention. These methods aim to leverage the knowledge from an auxiliary source domain to boost the performance of the model in the target domain by reducing the domain discrepancy between them. Regarding these issues, in the present paper, a proposed model aims to incrementally learn a new domain characterized by drifts due to a non-stationary environment. It utilizes an unsupervised, fuzzy-based domain adaptation to classify data streams faced with concept drift while accounting for a label-agnostic incremental setting in the target domain. Incremental learning updates occur whenever the entropy-based metric indicates uncertainty, ensuring informative samples are integrated. Also, outdated samples are forgotten during the training stage using the dynamic sample weighting strategy. Through experimentation on forty-five tasks, the superiority of the proposed model in handling dynamic adaptation on non-stationary domains is demonstrated, showcasing improvements in accuracy and computational efficiency.},
  archive      = {J_IJMLC},
  author       = {Moradi, Mona and Rahmanimanesh, Mohammad and Shahzadi, Ali},
  doi          = {10.1007/s13042-024-02135-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4055-4078},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised domain adaptation by incremental learning for concept drifting data streams},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Meta-DPSTL: Meta learning-based differentially private
self-taught learning. <em>IJMLC</em>, <em>15</em>(9), 4021–4053. (<a
href="https://doi.org/10.1007/s13042-024-02134-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-taught learning models are successfully applied to improve the target model’s performance in different low-resource environments. In this setting, features are learned using unlabeled instances in the source domain; thereafter, the learned feature representations are transferred to the target domain for the supervised classification task. Two important challenges in this setup include learning efficient feature representations in the source domain and securing instance privacy against attacks carried out during knowledge transfer from the source to the target domain. We propose $$Meta-DPSTL$$ , a novel Meta Differentially Private Self-Taught Learning model to overcome these challenges. The proposed approach implements self-taught learning in the meta-learning-based framework; training of meta-learner and base-learner proceeds episodically and is equivalent to estimating source and target domain parameters, respectively. Further, to protect the sensitive source data from a potential attacker, differential privacy is added to the meta-parameters learned in an episode before they are passed to the target domain to train the base-learner. To measure the immunity of the proposed model to an inversion attack, we propose a novel Relative Reconstruction Distance (RRD) metric. Lastly, an inversion attack is carried out on the meta-parameters; empirical results obtained on the handwritten digits recognition dataset, $$COVID-19$$ $$X-Ray$$ Radiography dataset, and $$COVID-19$$ Lung CT Scans dataset confirm the utility of meta-learning-based self-taught features in obtaining richer feature representations and hence, providing base-learners that are more generalizable. Relative reconstruction distance values computed on these datasets show that the differentially-private meta-parameters are robust to inversion attacks. Consequently, the proposed approach may be used in applications where the privacy requirements of sensitive source domain datasets are paramount.},
  archive      = {J_IJMLC},
  author       = {Singh, Upendra Pratap and Sinha, Indrajeet Kumar and Singh, Krishna Pratap and Verma, Shekhar},
  doi          = {10.1007/s13042-024-02134-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {4021-4053},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Meta-DPSTL: Meta learning-based differentially private self-taught learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel semantic feature enhancement network for extracting
lake water from remote sensing images. <em>IJMLC</em>, <em>15</em>(9),
3999–4019. (<a
href="https://doi.org/10.1007/s13042-024-02133-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic lake water extraction method based on semantic segmentation is a research hotspot in the field of remote sensing image processing. In remote sensing images, the presence of complex noise information at the lake boundary hinders the normal expression of boundary information, which leads to methods cannot extract a coherent lake boundary. Moreover, partial small-scale lakes’ texture features are weak and easily masked by the background information. To address the above issues, an end-to-end semantic segmentation network is designed. The network uses a symmetric encoder-decoder architecture to extract lake water in remote sensing images. On the one hand, a directional noise reduction filtering algorithm is proposed to reduce the impact of noise information on the network segmentation process. The algorithm utilizes a preset directional guide map to guide the nonlinear propagation of boundary noise and suppress low-contrast halo artifacts in the image, thereby better preserving the boundary sharpness of the lake. On the other hand, for the problem of missing small-scale lakes, an attention gate compression module is embedded in the skip connection. This module can adaptively integrate the correlation features between different ground objects, and selectively assign more attention to small-scale lakes, thereby improving the network’s ability to recognize such lakes. In the experimental results, our method can produce more accurate lake water extraction results than the current mainstream methods. Besides it has an excellent performance in accurately identifying lake boundaries and small-scale lakes.},
  archive      = {J_IJMLC},
  author       = {Hao, Rong-Rong and Sun, Hong-Mei and Wang, Rui-Xuan and Pan, Ang and Jia, Rui-Sheng},
  doi          = {10.1007/s13042-024-02133-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3999-4019},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel semantic feature enhancement network for extracting lake water from remote sensing images},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pretraining without wordpieces: Learning over a vocabulary
of millions of words. <em>IJMLC</em>, <em>15</em>(9), 3989–3998. (<a
href="https://doi.org/10.1007/s13042-024-02132-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard BERT adopts subword-based tokenization, which may break a word into two or more wordpieces (e.g., converting “lossless” to “loss” and “less”). This will bring inconvenience in following situations: (1) what is the best way to obtain the contextual vector of a word that is divided into multiple wordpieces? (2) how to predict a word via cloze test without knowing the number of wordpieces in advance? In this work, we explore to develop a BERT-style pretrained model over a vocabulary of words instead of wordpieces. We call such word-level BERT model as WordBERT. We train models with different vocabulary sizes, initialization configurations and languages. Results show that, compared to standard wordpiece-based BERT, WordBERT makes significant improvements on cloze test and machine reading comprehension. On many other natural language understanding tasks, including POS tagging, chunking and NER, WordBERT consistently performs better than BERT. Model analysis indicates that the major advantage of WordBERT over BERT lies in the understanding for low-frequency words and rare words. Furthermore, since the pipeline is language-independent, we train WordBERT for Chinese language and obtain significant gains on five natural language understanding datasets. Lastly, the analyse on inference speed illustrates WordBERT has comparable time cost to BERT in natural language understanding tasks.},
  archive      = {J_IJMLC},
  author       = {Feng, Zhangyin and Tang, Duyu and Feng, Xiaocheng and Zhou, Cong and Liao, Junwei and Wu, Shuangzhi and Qin, Bing and Cao, Yunbo and Shi, Shuming},
  doi          = {10.1007/s13042-024-02132-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3989-3998},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pretraining without wordpieces: Learning over a vocabulary of millions of words},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing spotted hyena optimization with fuzzy logic for
complex engineering optimization. <em>IJMLC</em>, <em>15</em>(9),
3969–3988. (<a
href="https://doi.org/10.1007/s13042-024-02130-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, solving complex real-world challenges has become a significant and vital task, many of these challenges involve combinatorial issues where optimal solutions are desired. Traditional optimization strategies have proven to be efficient for small-scale problems. However, when it comes to larger problems, such as those in the finance or business domains, a meta-heuristic search algorithm, like the Spotted Hyena optimization (SHO), is implemented. However, the SHO algorithm faces a challenge in selecting the optimal cluster head, resulting in low efficiency. To address this issue, a new bio-inspired optimization strategy called a novel Fuzzy Based Spotted Hyena Optimizer (FSHO) is proposed. This novel algorithm aims to solve the problem of optimum clustering and provides a solution to real-world engineering challenges. In addition, the Spotted Hyena algorithm is combined with Fuzzy C-Means to enhance its exploration capability, making it well-suited for optimization tasks. The implementation of this strategy is carried out using MATLAB, and its performance is evaluated using 29 benchmark functions, as well as by addressing various complex and computationally expensive engineering issues. Comparing the cost analysis of existing techniques such as FFA, AVOA, MGO, and GTO, the proposed FSHO achieves significantly better results with a cost reduction of 1.2%, as opposed to 5%, 3%, 2.7%, and 1.5% achieved by the other techniques, respectively. This method not only enhances performance but also provides cost-effective analysis with a low convergence rate.},
  archive      = {J_IJMLC},
  author       = {Padmapriya, N. and Kumaratharan, N.},
  doi          = {10.1007/s13042-024-02130-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3969-3988},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing spotted hyena optimization with fuzzy logic for complex engineering optimization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Structural entropy minimization combining graph
representation for money laundering identification. <em>IJMLC</em>,
<em>15</em>(9), 3951–3968. (<a
href="https://doi.org/10.1007/s13042-024-02129-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Money laundering identification (MLI) is a challenging task for financial AI research and application due to its massive transaction volume, label sparseness, and label bias. Most of the existing MLI methods focus on individual-level abnormal behavior while neglecting the community factor that money laundering is a collaborative group crime. Furthermore, the massive volume of transactions and the issue of label shifting also impede the application of supervised or semi-supervised models. To this end, this paper proposes an efficient community-oriented algorithm, namely SEGE, to identify money laundering based on structural entropy minimization (SEM) with graph embedding in an unsupervised approach. Experiments on both a private real-world money laundering network and a public synthetic dataset show that our SEGE algorithm derives prominent performance and outperforms the parameterized learning-based graph representation methods. Moreover, we find that there are pervasive sub-communities in the real-world money laundering network. Based on our local algorithm, we propose a real combat strategy against the money laundering group, in which when we have several scattered suspicious accounts in the transaction network, we are able to retrieve the whole money laundering group by the union of sub-communities with both high precision and high recall rates.},
  archive      = {J_IJMLC},
  author       = {Wang, Shaojiang and Wang, Pengcheng and Wu, Bin and Zhu, Yifan and Luo, Wei and Pan, Yicheng},
  doi          = {10.1007/s13042-024-02129-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3951-3968},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Structural entropy minimization combining graph representation for money laundering identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BiL-FaND: Leveraging ensemble technique for efficient
bilingual fake news detection. <em>IJMLC</em>, <em>15</em>(9),
3927–3949. (<a
href="https://doi.org/10.1007/s13042-024-02128-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, we tackled the critical challenge of detecting fake news in a bilingual context, focusing on English and Urdu. This issue is particularly important in the digital age, where misinformation can impact society and politics. To address this, we developed “BiL-FaND,” an ensemble-based system integrating multiple models designed to analyze distinct aspects of news content. The system employed Multilingual BERT for textual analysis, LSTM models for categorical and numerical data processing, and a caption-generating model using ResNet-101 and GRU for multimedia content analysis. This diverse methodological approach was key in handling the complexity and nuances of multilingual fake news. Our findings were significant, demonstrating the effectiveness of our approach. The textual analysis layer achieved 87% accuracy, indicating strong linguistic analysis performance. The LSTM models for categorical and numerical data showed excellent accuracies of 97% and 94%, respectively, highlighting their capability in pattern recognition and data interpretation. The multimedia layer further augmented our system’s accuracy, as evidenced by BLEU scores of 0.82 for English and 0.75 for Urdu captions, with an accuracy of 92%, calculated based on cosine similarity. These results concluded that our multi-layered, ensemble approach was highly effective in the bilingual fake news detection domain and achieved an overall accuracy of 92.07%.},
  archive      = {J_IJMLC},
  author       = {Munir, Saad and Asif Naeem, M.},
  doi          = {10.1007/s13042-024-02128-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3927-3949},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BiL-FaND: Leveraging ensemble technique for efficient bilingual fake news detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-label image classification method combining
multi-stage image semantic information and label relevance.
<em>IJMLC</em>, <em>15</em>(9), 3911–3925. (<a
href="https://doi.org/10.1007/s13042-024-02127-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image classification (MLIC) is a fundamental and highly challenging task in the field of computer vision. Most methods usually only focus on the inter-label association or the way to extract image semantics, ignoring the relevance of labels at multiple semantic levels. To this end, we propose a new approach for multi-label image classification. Our method consists of a class activation mapping (CAM) module for multi-level semantic extraction of images and a graph convolutional network (GCN) module for label relevance construction. The CAM module follows the sequence of human visual perception of objects and segments the global image into multiple local images with target objects. Afterward, the segmented images are fused into the global stream to obtain global to local semantic information. The GCN module combines the label word embedding matrix and the co-occurrence matrix to map a matrix with label dependencies. Finally, the image features and the classifier are combined to obtain the final classification result. Extensive experiments on two benchmark datasets, i.e., VOC2007 and MS-COCO, show that our approach achieves better results on several generic evaluation indicators compared with state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Wu, Liwen and Zhao, Lei and Tang, Peigeng and Pu, Bin and Jin, Xin and Zhang, Yudong and Yao, Shaowen},
  doi          = {10.1007/s13042-024-02127-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3911-3925},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-label image classification method combining multi-stage image semantic information and label relevance},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge graph completion model based on hyperbolic
hierarchical attention network. <em>IJMLC</em>, <em>15</em>(9),
3893–3909. (<a
href="https://doi.org/10.1007/s13042-024-02126-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) infers missing knowledge triples based on the facts in the knowledge base. In recent years, many representation learning models for knowledge reasoning have achieved promising link prediction results, especially those based on graph attention networks and their derivatives. Such models usually utilize the local neighborhood information for each node to learn representation vectors of target entities. However, most existing work focuses on modeling symmetry/asymmetry/composition/inversion relations, with less emphasis on hierarchical relations. Thus, a new hierarchical hyperbolic attention network for knowledge graph completion (HHAN-KGC) based on hyperbolic geometry is proposed in this paper. In HHAN-KGC, the entities at different hierarchies are distinguished by computing the distances between embedded feature vectors in the hyperbolic space and the origin, simultaneously, integrating neighboring information in the tangent space through the semantic attention mechanism, effectively addressing the limitations of existing hyperbolic models in reasoning about complex relations. The methodology analysis and experimental results demonstrate that HHAN-KGC can effectively model semantic hierarchies in the hyperbolic space, further enhancing the semantic representations of entities and relations. The results on multiple knowledge graph datasets indicate that HHAN-KGC outperforms the state-of-the-art methods in knowledge graph link prediction.},
  archive      = {J_IJMLC},
  author       = {Luo, Jiaohuang and Song, Changlong},
  doi          = {10.1007/s13042-024-02126-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3893-3909},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge graph completion model based on hyperbolic hierarchical attention network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving world models for robot arm grasping with backward
dynamics prediction. <em>IJMLC</em>, <em>15</em>(9), 3879–3891. (<a
href="https://doi.org/10.1007/s13042-024-02125-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of Industry 4.0, intelligent manufacturing has emerged as a prominent trend for future development. The integration of intelligent manufacturing scenarios with reinforcement learning offers significant advantages and potential. However, in real world scenarios, reinforcement learning faces challenges in terms of sampling efficiency and potential mechanical damage. Model-based reinforcement learning demonstrates advantages that make it more applicable to real scenarios. In this study, we propose the improved Dreamer algorithm and develop a system for learning picking and placing operations using multimodal information. The enhanced algorithm efficiently mitigates the challenge of low sample efficiency and demonstrates remarkable efficacy in addressing high-dimensional state space problems. Furthermore, the policy acquired through reinforcement learning can be utilised for the manipulation of object with diverse geometries. To verify the effectiveness of the algorithm, we construct a production line simulation environment for robotic arm manipulation based on the Coppeliasim platform. Additionally, the advantages of the improved algorithm are further validated through the continuous complex control tasks in DeepMind.},
  archive      = {J_IJMLC},
  author       = {Yuan, Yetian and Wang, Shuze and Mei, Yunpeng and Zhang, Weipu and Sun, Jian and Wang, Gang},
  doi          = {10.1007/s13042-024-02125-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3879-3891},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving world models for robot arm grasping with backward dynamics prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Framelet-based dual hypergraph neural networks for student
performance prediction. <em>IJMLC</em>, <em>15</em>(9), 3863–3877. (<a
href="https://doi.org/10.1007/s13042-024-02124-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of educational data mining, accurately predicting student performance is vital for developing effective educational strategies. However, existing methods often fall short in capturing the complex relationships between students, focusing mainly on individual attributes. This paper introduces a pioneering framelet-based dual hypergraph neural network (FD-HGNN) model to advance this task. Our innovative approach decomposes student feature matrices into low-pass and high-pass components using a framelet-based transform. These components form the basis for creating hypergraphs, capturing intricate student relationships. The model integrates a dual hypergraph neural network with distinct channels for low-pass and high-pass components, augmented by a variance interaction layer employing an attention mechanism. This structure ensures a more comprehensive representation of student data, enhancing prediction accuracy. Extensive validation against traditional machine learning methods and graph neural networks across four real-world educational datasets demonstrates the superiority of our approach. The findings highlight the significant potential of our model in revolutionizing student performance prediction in educational settings.},
  archive      = {J_IJMLC},
  author       = {Yang, Yazhi and Shi, Jiandong and Li, Ming and Fujita, Hamido},
  doi          = {10.1007/s13042-024-02124-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3863-3877},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Framelet-based dual hypergraph neural networks for student performance prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Teaching content recommendations in music appreciation
courses via graph embedding learning. <em>IJMLC</em>, <em>15</em>(9),
3847–3862. (<a
href="https://doi.org/10.1007/s13042-024-02123-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional music appreciation course teaching model relies on questionnaires or manual decision-making to determine teaching content, which is time-consuming and easily reduces student satisfaction and teaching quality. How to use artificial intelligence technology to improve the selection process of teaching content is a valuable and important issue. This paper treats the above problem as a teaching content recommendation task and proposes a two-stage graph embedding learning (TSGEL) framework. Specifically, our TSGEL includes three customized modules: (1) a graph convolution module with side information to capture students’ preferences through effective information propagation on student-song graphs; (2) a refined prediction module aims to highlight students’ general preferences, thereby alleviating possible inconsistencies between training and testing distributions; and (3) a teaching content recommendation module selects some songs that can achieve group tradeoffs as teaching content based on the obtained student preferences. The first two modules constitute the individual stage for learning student preferences, and the latter is the group stage for integrating the preferences of all the students to recommend teaching content. Finally, we conduct extensive experiments on a public dataset and a real course dataset to verify the effectiveness and compatibility of our TSGEL.},
  archive      = {J_IJMLC},
  author       = {Liu, Dugang and Lin, Xiaolin and Li, Lingjie and Ming, Zishan},
  doi          = {10.1007/s13042-024-02123-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3847-3862},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Teaching content recommendations in music appreciation courses via graph embedding learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Btda: Basis transformation based distribution alignment for
imbalanced semi-supervised learning. <em>IJMLC</em>, <em>15</em>(9),
3829–3845. (<a
href="https://doi.org/10.1007/s13042-024-02122-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) employs unlabeled data with limited labeled samples to enhance deep networks, but imbalance degrades performance due to biased pseudo-labels skewing decision boundaries. To address this challenge, we propose two optimization conditions inspired by our theoretical analysis. These conditions focus on aligning class distributions and representations. Additionally, we introduce a plug-and-play method called Basis Transformation based distribution alignment (BTDA) that efficiently aligns class distributions while considering inter-class relationships. BTDA mitigates the negative impact of biased pseudo-labels through basis transformation, which involves a learnable transition matrix. Extensive experiments demonstrate the effectiveness of integrating existing SSL methods with BTDA in image classification tasks with class imbalance. For example, BTDA achieves accuracy improvements ranging from 2.47 to 6.66% on CIFAR10-LT and SVHN-LT datasets, and a remarkable 10.95% improvement on the tail class, even under high imbalanced rates. Despite its simplicity, BTDA achieves state-of-the-art performance in SSL with class imbalance on representative datasets.},
  archive      = {J_IJMLC},
  author       = {Ye, Jinhuang and Gao, Xiaozhi and Li, Zuoyong and Wu, Jiawei and Xu, Xiaofeng and Zheng, Xianghan},
  doi          = {10.1007/s13042-024-02122-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3829-3845},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Btda: Basis transformation based distribution alignment for imbalanced semi-supervised learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable decision fusion algorithm for enabling
decentralized computation in distributed, big data clustering problems.
<em>IJMLC</em>, <em>15</em>(9), 3803–3827. (<a
href="https://doi.org/10.1007/s13042-024-02121-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the world of big data, extracting meaningful insights from large and continually growing distributed datasets is a major challenge. Classical clustering algorithms are effective at identifying clusters with convex structures. However, they fall short in identifying arbitrary-shaped clusters (more irregular and complex patterns), which are often encountered in real-world applications. The process of identifying non-convex cluster representations from very large and growing datasets is a challenge. It is further compounded by the distributed nature of the data, necessitating complex computations across multiple devices. Support Vector Clustering (SVC) is a much-celebrated algorithm capable of finding arbitrarily shaped clusters. However, the major limitation of this algorithm is that it will not scale to large volumes of data as the time and space complexity is high. The second limitation of the SVC algorithm is the requirement for large computation time in finding cluster structures. The adoption of a coreset based methodology is required for finding the true representation of the underlying large datasets. The implementation of hierarchical clustering on these distributed coresets, unlocks the potential to uncover a structured hierarchy of abstractions across the disseminated data. Moreover, a distance-based clustering approach guarantees the identification of clusters with diverse and arbitrary shapes, providing a robust framework for detecting complex structures. This research utilizes the Core Vector Machine (CVM) approach using an approximate Minimum Enclosing Ball (MEB) algorithm to efficiently address the complexities inherent in traditional SVC. Additionally, an enhanced medoid algorithm is employed for cluster head identification across the data sources. Hierarchical clustering is performed in the Reproducing Kernel Hilbert Space (RKHS) using cosine similarity distance matrices. This is used to identify compact non-convex clusters within distributed datasets. Performance assessment involves benchmarking our approach against state-of-the-art improved SVC algorithms using large datasets. The outcomes validate the superior performance of our approach compared to existing methods.},
  archive      = {J_IJMLC},
  author       = {Jennath, H. S. and Asharaf, S.},
  doi          = {10.1007/s13042-024-02121-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3803-3827},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Scalable decision fusion algorithm for enabling decentralized computation in distributed, big data clustering problems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gait coordination feature modeling and multi-scale gait
representation for gait recognition. <em>IJMLC</em>, <em>15</em>(9),
3791–3802. (<a
href="https://doi.org/10.1007/s13042-024-02120-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is an advanced biometric modality that identifies individuals based on their walking postures. Currently, the majority of gait recognition methods employ silhouette images as the primary representation of gait. However, the inclusion of silhouette information, which incorporates details about clothing and carried items, may interfere with the extraction of gait features. To this end, we present GaitSkeleton, a novel approach that utilizes skeleton sequences as the gait representation. GaitSkeleton models the motor coordination feature of gait and combines three-scale spatial features to obtain discriminative features for gait recognition. To capture the coordination relationship between joints, we design a Coordination Feature Learner (CFL). CFL is embedded into the ST-GCN block to enhance the model’s representational capacity. Additionally, we introduce a novel feature cascade module called MSCM, which further enhances the discriminative information by sampling spatial features at three scales. The entire network significantly enhances the discriminative nature of gait features. Experimental results on the CASIA-B dataset demonstrate that our method achieves state-of-the-art performance in model-based gait recognition.},
  archive      = {J_IJMLC},
  author       = {Zhu, Dandan and Ji, Laihu and Zhu, Liping and Li, Chengyang},
  doi          = {10.1007/s13042-024-02120-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3791-3802},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Gait coordination feature modeling and multi-scale gait representation for gait recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emerging trends in federated learning: From model fusion to
federated x learning. <em>IJMLC</em>, <em>15</em>(9), 3769–3790. (<a
href="https://doi.org/10.1007/s13042-024-02119-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a new learning paradigm that decouples data collection and model training via multi-party computation and model aggregation. As a flexible learning setting, federated learning has the potential to integrate with other learning frameworks. We conduct a focused survey of federated learning in conjunction with other learning algorithms. Specifically, we explore various learning algorithms to improve the vanilla federated averaging algorithm and review model fusion methods such as adaptive aggregation, regularization, clustered methods, and Bayesian methods. Following the emerging trends, we also discuss federated learning in the intersection with other learning paradigms, termed federated X learning, where X includes multitask learning, meta-learning, transfer learning, unsupervised learning, and reinforcement learning. In addition to reviewing state-of-the-art studies, this paper also identifies key challenges and applications in this field, while also highlighting promising future directions.},
  archive      = {J_IJMLC},
  author       = {Ji, Shaoxiong and Tan, Yue and Saravirta, Teemu and Yang, Zhiqin and Liu, Yixin and Vasankari, Lauri and Pan, Shirui and Long, Guodong and Walid, Anwar},
  doi          = {10.1007/s13042-024-02119-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3769-3790},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Emerging trends in federated learning: From model fusion to federated x learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rcoco: Contrastive collective link prediction across
multiplex network in riemannian space. <em>IJMLC</em>, <em>15</em>(9),
3745–3767. (<a
href="https://doi.org/10.1007/s13042-024-02118-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction typically studies the probability of future interconnection among nodes with the observation in a single social network. More often than not, real scenario is presented as a multiplex network with common (anchor) users active in multiple social networks. In the literature, most existing works study either the intra-link prediction in a single network or inter-link prediction among networks (a.k.a. network alignment), and consider two learning tasks are independent from each other, which is still away from the fact. On the representation space, the vast majority of existing methods are built upon the traditional Euclidean space, unaware of the inherent geometry of social networks. The third issue is on the scarce anchor users. Annotating anchor users is laborious and expensive, and thus it is impractical to work with quantities of anchor users. Herein, in light of the issues above, we propose to study a challenging yet practical problem of Geometry-aware Collective Link Prediction across Multiplex Network. To address this problem, we present a novel contrastive model, RCoCo, which collaborates intra- and inter-network behaviors in Riemannian spaces. In RCoCo, we design a curvature-aware graph attention network ( $$\kappa$$ -GAT), conducting attention mechanism in Riemannian manifold whose curvature is estimated by the Ricci curvatures over the network. Thereafter, we formulate intra- and inter-contrastive loss in the manifolds, in which we augment graphs by exploring the high-order structure of community and information transfer on anchor users. Finally, we conduct extensive experiments with 14 strong baselines on 8 real-world datasets, and show the effectiveness of RCoCo.},
  archive      = {J_IJMLC},
  author       = {Sun, Li and Li, Mengjie and Yang, Yong and Li, Xiao and Liu, Lin and Zhang, Pengfei and Du, Haohua},
  doi          = {10.1007/s13042-024-02118-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3745-3767},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Rcoco: Contrastive collective link prediction across multiplex network in riemannian space},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust graph neural networks with dirichlet regularization
and residual connection. <em>IJMLC</em>, <em>15</em>(9), 3733–3743. (<a
href="https://doi.org/10.1007/s13042-024-02117-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Network (GNN) has attracted considerable research interest in various graph data modeling tasks. Most GNNs require efficient and sufficient label information during training phase. However, in open environments, the performance of existing GNNs sharply decrease according to the data (structure, attribute and label) missing and noising. Several recent attempts have been made to improve the performance and robustness of GNNs, most of which are contrastive learning-based and auto encoder-based strategies. In this paper, a semi-supervised learning framework is proposed for graph modeling tasks, i.e., robust graph neural network with Dirichlet regularization and Residual connection (DRGNN). Specifically, the structure and feature of the original graph are both masked to generate the masked graph, which is sent to the graph representation learning block (encoder) to learn the latent node representation. Additionally, an initial residual connect is introduced into the graph representation learning block to directly transmit the original node feature to the last layer to retain the inherent information of the node itself. Finally, the whole network is jointly optimized by the structure reconstructed loss, feature reconstructed loss and the classification loss. Note that a Dirichlet regularization constraint is introduced into the learning objective to dominate the latent node representation into a local smoothing scenario, which is more conforms with the manifold assumption of the graph representation learning. Extensive experiments demonstrate the state-of-the-art accuracy and the robustness of the proposed DRGNN on benchmark datasets.},
  archive      = {J_IJMLC},
  author       = {Yao, Kaixuan and Du, Zijin and Li, Ming and Cao, Feilong and Liang, Jiye},
  doi          = {10.1007/s13042-024-02117-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3733-3743},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust graph neural networks with dirichlet regularization and residual connection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge transfer enabled reinforcement learning for
efficient and safe autonomous ship collision avoidance. <em>IJMLC</em>,
<em>15</em>(9), 3715–3731. (<a
href="https://doi.org/10.1007/s13042-024-02116-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on collision avoidance decision-making (CADM) for autonomous ships is a very challenging task in the shipping field. Considered one of the machine learning algorithms that has received considerable attention, reinforcement learning technology enables actions to be continually optimized by agents interacting with the environment, aiming to maximize rewards and returns. Significant potential is attributed to the research on autonomous ship collision avoidance. To investigate an efficient and practical ship collision avoidance algorithm, the knowledge transfer (KT) method is employed in this research to introduce an improved reinforcement learning approach. With a thorough understanding of ship collision avoidance behavior and the Convention on the International Regulations for Preventing Collisions at Sea (COLREGs), a reward function is designed to guide and constrain ship collision avoidance behavior. Subsequently, ship collision avoidance tasks are categorized, and knowledge from source tasks is extracted and transferred to closely related target tasks. Experiments have been conducted across various collision avoidance tasks, encompassing diverse types and degrees of similarity. In multi-ships cases, the success rate of the learned knowledge applications of head-on, overtaking, and crossing encounter cases are 90%, 95%, and 82.5% respectively. The outcomes demonstrate that the proposed method enhances algorithmic efficiency while satisfying the requirements for safety and rule compliance in ship collision avoidance behavior. Furthermore, the methodology could also benefit other autonomous systems in dynamic environments.},
  archive      = {J_IJMLC},
  author       = {Wang, Chengbo and Wang, Ning and Gao, Hongbo and Wang, Leihao and Zhao, Yizhuo and Fang, Mingxing},
  doi          = {10.1007/s13042-024-02116-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3715-3731},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge transfer enabled reinforcement learning for efficient and safe autonomous ship collision avoidance},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pattern learning for scheduling microservice workflow to
cloud containers. <em>IJMLC</em>, <em>15</em>(9), 3701–3714. (<a
href="https://doi.org/10.1007/s13042-024-02115-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patterns are crucial for efficiently scheduling microservice workflow applications to containers in cloud computing scenarios. However, it is challenging to learn patterns of microservice workflows because of their complex precedence constrained structures provided by users with more lightweighted, diversified, and personalized services. In this paper, we propose a graph neural network is designed to identify patterns within a set of microservice workflows by mining the common substructures of workflows. Based on the learned patterns, a pattern-based scheduling algorithm framework is developed for microservice workflows with soft deadline constraints to minimize the average tardiness. A sorting strategy is introduced based on urgency and pattern coverage rate. For simplification of the task sorting process, the pattern-based task sorting algorithm (PB-TS) is devised. Furthermore, a resource selection phase is incorporated to the pattern-based resource selection algorithm (PB-RS) to minimize the candidate resource space. Experimental results demonstrate the proposed method is much efficient as compared to three classical algorithms.},
  archive      = {J_IJMLC},
  author       = {Li, Wenzheng and Li, Xiaoping and Chen, Long},
  doi          = {10.1007/s13042-024-02115-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3701-3714},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pattern learning for scheduling microservice workflow to cloud containers},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards exploiting linear regression for
multi-class/multi-label classification: An empirical analysis.
<em>IJMLC</em>, <em>15</em>(9), 3671–3700. (<a
href="https://doi.org/10.1007/s13042-024-02114-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression and classification are the two main learning tasks in supervised learning, and both of them can be solved by learning a hyperplane from training samples. However, the hyperplane in regression task aims at approximating the labels of samples as much as possible, while the hyperplane in classification task aims at separating the samples belonging to different classes as much as possible. From this perspective, regression and classification are two completely different learning tasks. However, linear regression is often used to solve multi-class/multi-label classification problems, which can be decomposed into a set of binary classification problems. In this paper, we focus on analyzing the issues of regression models in classification tasks. Firstly, when $$\{-1, +1\}$$ is used to denote negative and positive class, we derive that it is essentially equivalent to optimizing square loss as the surrogate loss function of zero-one loss to solve binary classification problem via learning linear regression model. Then, we also derive what will happen to the model when $$\{-1, +1\}$$ is replaced with $$\{0, 1\}$$ for three different versions of linear regression. Finally, extensive experiments are conducted over multi-label/multi-class classification tasks and corresponding discussions are further conducted according to the experimental results.},
  archive      = {J_IJMLC},
  author       = {Jia, Bin-Bin and Liu, Jun-Ying and Zhang, Min-Ling},
  doi          = {10.1007/s13042-024-02114-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3671-3700},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Towards exploiting linear regression for multi-class/multi-label classification: An empirical analysis},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A group incremental feature selection based on knowledge
granularity under the context of clustering. <em>IJMLC</em>,
<em>15</em>(9), 3647–3670. (<a
href="https://doi.org/10.1007/s13042-024-02113-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a widely used data preprocessing method, feature selection with rough sets aims to delete redundant conditional features. However, most of the traditional feature selection methods target to the static data set environment, and the importance of features is used as the base for feature selection. These methods only consider the importance of features themselves and do not consider the impact of features on classification. In order to overcome such shortcomings, we first use the information of knowledge granules to calculate the similarity of samples in the same cluster and samples in different clusters; Secondly, from the perspective of clustering, we stick to the principle that the samples in the same cluster are as close as possible, and the samples in different clusters are as far away as possible, then a feature selection model of knowledge granularity (in short SKG) based on the clustering background is designed; Thirdly, in order to make the SKG model adapt to the reduction of dynamic data sets, we discuss the incremental learning mechanism of sample and feature changes, and two incremental models SKGOA and SKGAA are designed to deal with the dynamic feature reduction when some samples and features are added into the decision system. Finally, some numerical experiments are conducted to assess the performance of the proposed algorithms, and the results shown that our approaches are of a prominent advantage in terms of computational time and classification accuracy.},
  archive      = {J_IJMLC},
  author       = {Liang, Baohua and Liu, Yong and Lu, Jiangyin and He, Houjiang},
  doi          = {10.1007/s13042-024-02113-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3647-3670},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A group incremental feature selection based on knowledge granularity under the context of clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient multi-source information fusion approach for
dynamic interval-valued data via fuzzy approximate conditional entropy.
<em>IJMLC</em>, <em>15</em>(9), 3619–3645. (<a
href="https://doi.org/10.1007/s13042-024-02112-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information fusion enables the integration and transformation of complimentary data from different sources, providing a unified representation for centralized knowledge discovery, which can contribute to effective decision-making, classification, prediction, and more. Multi-source interval-valued data, represented in the form of intervals to capture uncertainty phenomenons, is a common type of symbolic data that finds extensive applications in the real world. This paper aims to investigate the effective fusion of multi-source interval-valued data and to design dynamic updating algorithms for the situations involving multiple dimensions. The objective is to enhance the efficiency of fusion processes. Firstly, this paper use the Kullback–Leibler divergence to measure the dissimilarity between interval distributions, and construct fuzzy similarity relation. Furthermore, we define a fuzzy information granule structure of interval-valued. Secondly, the concept of fuzzy similarity relations is utilized to construct fuzzy decision-making for objects. Subsequently, based on the aforementioned fuzzy information granule structure and fuzzy decision-making, we propose a novel measure called fuzzy approximate conditional entropy and design a corresponding entropy fusion model. Finally, we discuss various scenarios where dynamic changes occur simultaneously in the attributes and information sources of dynamic multi-source interval-valued data. We design corresponding dynamic update algorithms for these situations. Numerical experiments are conducted on nine UCI datasets to validate our proposed fusion method. The experimental results indicate that our fusion approach exhibits improved classification performance compared to the common fusion methods. The designed dynamic update algorithms are also capable of reducing computation time and enhancing fusion efficiency.},
  archive      = {J_IJMLC},
  author       = {Cai, Ke and Xu, Weihua},
  doi          = {10.1007/s13042-024-02112-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3619-3645},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An efficient multi-source information fusion approach for dynamic interval-valued data via fuzzy approximate conditional entropy},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection with clustering probabilistic particle
swarm optimization. <em>IJMLC</em>, <em>15</em>(9), 3599–3617. (<a
href="https://doi.org/10.1007/s13042-024-02111-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dealing with high-dimensional data poses a significant challenge in machine learning. To address this issue, researchers have proposed feature selection as a viable solution. Due to the intricate search space involved in feature selection, swarm intelligence algorithms have gained popularity for their exceptional search capabilities. This study introduces a method called Clustering Probabilistic Particle Swarm Optimization (CPPSO) to revolutionize the traditional particle swarm optimization approach by incorporating probabilities to represent velocity and incorporating an elitism mechanism. Furthermore, CPPSO employs a clustering strategy based on the K-means algorithm, utilizing the Hamming distance to divide the population into two sub-populations to improve the performance. To assess CPPSO’s performance, a comparative analysis is conducted against seven existing algorithms using twenty diverse datasets. These datasets are all based on real-world problems. Fifteen of these are frequently used in feature selection research, while the remaining five comprise imbalanced datasets as well as multi-label datasets. The experimental results demonstrate the superiority of CPPSO across a range of evaluation criteria, surpassing the performance of the comparative algorithms on the majority of the datasets.},
  archive      = {J_IJMLC},
  author       = {Gao, Jinrui and Wang, Ziqian and Lei, Zhenyu and Wang, Rong-Long and Wu, Zhengwei and Gao, Shangce},
  doi          = {10.1007/s13042-024-02111-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3599-3617},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection with clustering probabilistic particle swarm optimization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel swin transformer approach utilizing residual
multi-layer perceptron for diagnosing brain tumors in MRI images.
<em>IJMLC</em>, <em>15</em>(9), 3579–3597. (<a
href="https://doi.org/10.1007/s13042-024-02110-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Serious consequences due to brain tumors necessitate a timely and accurate diagnosis. However, obstacles such as suboptimal imaging quality, issues with data integrity, varying tumor types and stages, and potential errors in interpretation hinder the achievement of precise and prompt diagnoses. The rapid identification of brain tumors plays a pivotal role in ensuring patient safety. Deep learning-based systems hold promise in aiding radiologists to make diagnoses swiftly and accurately. In this study, we present an advanced deep learning approach based on the Swin Transformer. The proposed method introduces a novel Hybrid Shifted Windows Multi-Head Self-Attention module (HSW-MSA) along with a rescaled model. This enhancement aims to improve classification accuracy, reduce memory usage, and simplify training complexity. The Residual-based MLP (ResMLP) replaces the traditional MLP in the Swin Transformer, thereby improving accuracy, training speed, and parameter efficiency. We evaluate the Proposed-Swin model on a publicly available brain MRI dataset with four classes, using only test data. Model performance is enhanced through the application of transfer learning and data augmentation techniques for efficient and robust training. The Proposed-Swin model achieves a remarkable accuracy of 99.92%, surpassing previous research and deep learning models. This underscores the effectiveness of the Swin Transformer with HSW-MSA and ResMLP improvements in brain tumor diagnosis. This method introduces an innovative diagnostic approach using HSW-MSA and ResMLP in the Swin Transformer, offering potential support to radiologists in timely and accurate brain tumor diagnosis, ultimately improving patient outcomes and reducing risks.},
  archive      = {J_IJMLC},
  author       = {Pacal, Ishak},
  doi          = {10.1007/s13042-024-02110-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3579-3597},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel swin transformer approach utilizing residual multi-layer perceptron for diagnosing brain tumors in MRI images},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identification of subtypes in digestive system tumors based
on multi-omics data and graph convolutional network. <em>IJMLC</em>,
<em>15</em>(9), 3567–3577. (<a
href="https://doi.org/10.1007/s13042-024-02109-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the molecular subtype of cancer patients is of great significance for personalized diagnosis and treatment of cancer. The progress of a large amount of multi-omics data and data-driven methods is expected to promote the molecular subtyping of cancer. Existing methods are limited by their ability to deal with high-dimensional data and the influence of misleading and unrelated factors, resulting in ambiguous and overlapping subtypes. This article proposes a method called Multi-Omics Subtypes of Digestive System Tumors (MSDST), which is used for subtype identification of digestive system tumors. The method learns a new representation of the relationship between samples from multi-omics data, and uses a self-encoding model composed of omics-specific graph convolutional networks to learn the high-level representation of each omics data feature while considering the prognosis prediction results. Finally, k-means algorithm is used to cluster samples for analysis. Compared with other state-of-the-art methods, our proposed method performs better in identifying digestive system tumor subtypes. Subsequent clinical data analysis and functional enrichment analysis further confirm the specific biological characteristics and functional differences of the identified subtypes. This research provides new ideas and methods for precision medicine, and is expected to promote personalized treatment and improve the prognosis of digestive system tumors.},
  archive      = {J_IJMLC},
  author       = {Zhou, Lin and Wang, Ning and Zhu, Zhengzhi and Gao, Hongbo and Zhou, Yi and Fang, Mingxing},
  doi          = {10.1007/s13042-024-02109-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {3567-3577},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Identification of subtypes in digestive system tumors based on multi-omics data and graph convolutional network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast shrinking parents-children learning for markov
blanket-based feature selection. <em>IJMLC</em>, <em>15</em>(8),
3553–3566. (<a
href="https://doi.org/10.1007/s13042-024-02108-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional data leads to degraded performance of machine learning algorithms and weak generalization of models, so feature selection is of great importance. In a Bayesian network (BN), the Markov blanket (MB) of a target node (T) is the best feature subset of that node. Therefore, this paper proposes Fast Shrinking parents-children learning for Markov blanket-based feature selection (FSMB), which first determines the parents-children of the target node, and then discovers spouses while checking candidate parents-children set. In spouse determination process, a secondary screening strategy is proposed to remove false-positive spouses effectively. In this process, once the spouses of T with respect to T’s child are determined, the parents-children set is immediately tested and the false-positive parents-children are removed in time, which not only can avoid the influence of false-positive parents-children on the subsequent spouse discovery, but also do not need to determine the spouses for false-positive parents-children. To verify the effectiveness of FSMB, experiments were performed on eight state-of-the-art MB algorithms on six standard networks and eight real datasets, the results show that FSMB outperforms other algorithms in terms of accuracy and efficiency.},
  archive      = {J_IJMLC},
  author       = {Liu, Haoran and Shi, Qianrui and Cai, Yanbin and Wang, Niantai and Zhang, Liyue and Liu, Dayan},
  doi          = {10.1007/s13042-024-02108-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3553-3566},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fast shrinking parents-children learning for markov blanket-based feature selection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An evolutionary feature selection method based on
probability-based initialized particle swarm optimization.
<em>IJMLC</em>, <em>15</em>(8), 3533–3552. (<a
href="https://doi.org/10.1007/s13042-024-02107-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a common data preprocessing technique that aims to construct better models by selecting the most predictive features. Existing particle swarm optimization-based feature selection algorithms encounter two challenges when dealing with high-dimensional problems: easy to fall into local optimum and high computational cost. Therefore, this paper proposes an evolutionary dual-task feature selection method based on probability-based initialization particle swarm optimization (PPSO-EDT), which aims to find optimal solutions by transferring knowledge between two related tasks. Firstly, a probability-based initialization strategy is designed to accelerate population convergence by fully utilizing the correlation between labels and features. Secondly, a task generation strategy based on feature correlation was designed, which constructs the main task and auxiliary task by selecting feature subsets with highly correlated values and feature subsets without redundancy, respectively. Finally, an multi-task transfer mechanism is used to transfer knowledge and find optimal solutions. The results on 12 high-dimensional datasets indicate that the proposed method achieves high classification performance with a small feature subset in a relatively short amount of time.},
  archive      = {J_IJMLC},
  author       = {Pan, Xiaoying and Lei, Mingzhu and Sun, Jia and Wang, Hao and Ju, Tong and Bai, Lin},
  doi          = {10.1007/s13042-024-02107-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3533-3552},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An evolutionary feature selection method based on probability-based initialized particle swarm optimization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey and open problems in privacy-preserving knowledge
graph: Merging, query, representation, completion, and applications.
<em>IJMLC</em>, <em>15</em>(8), 3513–3532. (<a
href="https://doi.org/10.1007/s13042-024-02106-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph (KG) has attracted more and more companies’ attention for its ability to connect different types of data in meaningful ways and support rich data services. However, due to privacy concerns, different companies cannot share their own KGs with each other. Such data isolation problem limits the performance of KG and prevents its further development. Therefore, how to let multiple parties conduct KG-related tasks collaboratively on the basis of privacy protection becomes an important research question to answer. In this paper, to fill this gap, we summarize the open problems for privacy-preserving KG in the data isolation setting and propose possible solutions for them. Specifically, we summarize the open problems in privacy-preserving KG from four aspects, i.e., merging, query, representation, and completion. We present these problems in detail and propose possible technical solutions for them, along with the datasets, evaluation methods, and future research directions. We also provide three privacy-preserving KG application scenarios.},
  archive      = {J_IJMLC},
  author       = {Chen, Chaochao and Zheng, Fei and Cui, Jamie and Cao, Yuwei and Liu, Guanfeng and Wu, Jia and Zhou, Jun},
  doi          = {10.1007/s13042-024-02106-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3513-3532},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Survey and open problems in privacy-preserving knowledge graph: Merging, query, representation, completion, and applications},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistent multi-view subspace clustering with local
structure information. <em>IJMLC</em>, <em>15</em>(8), 3495–3512. (<a
href="https://doi.org/10.1007/s13042-024-02105-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering has attracted extensive attention in recent years because it can fully utilize the inherent characteristics of each view data. The low-rank structure in many current successful multi-view subspace clustering methods to describe the consistency is based on the minimization of the nuclear norm, but it is easily dominated by large eigenvalues, thereby resulting in an inaccurate low-rank structure. Besides, local structural information, which can reduce the distance between similar points, has not been fully employed in multi-view subspace clustering algorithms. In this article, an improved consistent multi-view subspace clustering model with local structure information (CLSI-MSC) is proposed to overcome the aforementioned limitations. Firstly, the Schatten-p norm is substituted for the nuclear norm, thus ensuring that the low-rank structure of the consistency component can mine the consistency information better. Additionally, the group effect to preserve the local structural information between data points is introduced into the model to reduce the distance between similar points. Finally, $$l_{2,1}$$ regularization is introduced to make the model more robust against noise and outliers. The experimental results demonstrate that the proposed method is superior or comparable to other comparison methods on five benchmark datasets.},
  archive      = {J_IJMLC},
  author       = {Zhao, Kang and Zhou, Shuisheng and Zhang, Ying and Zhang, Junna},
  doi          = {10.1007/s13042-024-02105-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3495-3512},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Consistent multi-view subspace clustering with local structure information},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast DBSCAN algorithm using a bi-directional HNSW index
structure for big data. <em>IJMLC</em>, <em>15</em>(8), 3471–3494. (<a
href="https://doi.org/10.1007/s13042-024-02104-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Density Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm is one of the most popular and effective density-based clustering algorithms at present. Although it can effectively identify clusters and noise points of arbitrary shapes, it is very difficult to efficiently address the tasks with large scale data. The time complexity of the DBSCAN is $$O(n^2)$$ where its main computation time lies in $$\varepsilon$$ -neighbor range query, which becomes the bottleneck of DBSCAN performance. To solve this problem, we propose a simple fast DBSCAN algorithm, called bh-DBSCAN, using a bi-directional HNSW index structure to improve the efficiency of DBSCAN by reducing redundant $$\varepsilon$$ -neighbor range queries. Specifically, we first distinguish a point’s property (core point or border point). Next, we apply the filtNoise algorithm to filter the noise points that without core points in $$neighbor_x$$ . Finally, we utilized the MergeCore algorithm to merge the cluster of border points in it’s core neighbor points. The experimental results show that our proposed algorithm could greatly improve the clustering efficiency without losing much accuracy based on the datasets tested.},
  archive      = {J_IJMLC},
  author       = {Weng, Shaoyuan and Fan, Zongwen and Gou, Jin},
  doi          = {10.1007/s13042-024-02104-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3471-3494},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A fast DBSCAN algorithm using a bi-directional HNSW index structure for big data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven quantification and intelligent decision-making
in traditional chinese medicine: A review. <em>IJMLC</em>,
<em>15</em>(8), 3455–3470. (<a
href="https://doi.org/10.1007/s13042-024-02103-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Chinese medicine (TCM) originates from the practical experience of human beings’ constant struggle with nature. In five thousand years, TCM has gradually risen from empirical medicine to modern evidence-based medicine with complete scientific principles such as fundamental systematic theories, treatment principles and methods, classic prescriptions, famous medicines. The development of information science, data science, and computer technology has provided effective models, methods, and technologies for modern TCM’s quantitative and intelligent diagnosis and treatment decision-making. And it also has promoted the development of TCM from evidence-based medicine to intelligent TCM. Starting from the development of TCM, we introduce the rise and connotation of ancient, modern, and intelligent TCM. Moreover, we emphatically analyze the research status of quantification and intelligent decisions for the whole disease cycle, including data-driven modern TCM diagnosis, program optimization, and treatment program evaluation. In addition, we discuss the critical issues of data-driven TCM quantification and intelligent decision research and briefly elaborate on the new ideas of data-driven intelligent TCM research. In conclusion, compared with traditional research paradigms, the advantages of data-driven medical decision research paradigms are as follows: (1) From the perspective of decision-making subjects, the data-driven research paradigm describes the clinical decision-making mechanism in real scenarios with rigorous mathematical theories, which will break through the difference between the conclusions drawn by clinical design research methods and clinical practice. (2) By applying the results of basic theoretical research to clinical decision-making practice in real scenarios, the data-driven medical decision-making research paradigm will contribute to getting out of the dilemma that the conclusions drawn by traditional AI models are difficult to explain in clinical practical decision-making.},
  archive      = {J_IJMLC},
  author       = {Chu, Xiaoli and Wu, Simin and Sun, Bingzhen and Huang, Qingchun},
  doi          = {10.1007/s13042-024-02103-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3455-3470},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Data-driven quantification and intelligent decision-making in traditional chinese medicine: A review},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DBHC: Discrete bayesian HMM clustering. <em>IJMLC</em>,
<em>15</em>(8), 3439–3454. (<a
href="https://doi.org/10.1007/s13042-024-02102-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequence data mining has become an increasingly popular research topic as the availability of data has grown rapidly over the past decades. Sequence clustering is a type of method within this field that is in high demand in the industry, but the sequence clustering problem is non-trivial and, as opposed to static cluster analysis, interpreting clusters of sequences is often difficult. Using Hidden Markov Models (HMMs), we propose the Discrete Bayesian HMM Clustering (DBHC) algorithm, an approach to clustering discrete sequences by extending a proven method for continuous sequences. The proposed algorithm is completely self-contained as it incorporates both the search for the number of clusters and the search for the number of hidden states in each cluster model in the parameter inference. We provide a working example and a simulation study to explain and showcase the capabilities of the DBHC algorithm. A case study illustrates how the hidden states in a mixture of HMMs can aid the interpretation task of a sequence cluster analysis. We conclude that the algorithm works well as it provides well-interpretable clusters for the considered application.},
  archive      = {J_IJMLC},
  author       = {Budel, Gabriel and Frasincar, Flavius and Boekestijn, David},
  doi          = {10.1007/s13042-024-02102-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3439-3454},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DBHC: Discrete bayesian HMM clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual flow fusion graph convolutional network for traffic
flow prediction. <em>IJMLC</em>, <em>15</em>(8), 3425–3437. (<a
href="https://doi.org/10.1007/s13042-024-02101-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, motor vehicle ownership has increased worldwide year by year, which causes that the accurate prediction of traffic flow on urban road networks becomes more important. However, the dual dependence on the micro layer and the macro layer creates a huge challenge for the prediction task. Previous models lack comprehensive analysis of the macro features at different time granularities. In this paper, we propose a novel Dual Flow Fusion Graph Convolutional Network (DFFGCN) to solve this problem. For capturing more macro features, we build the interactions between the micro layer and the macro layer at more time granularities. Then the spatial-temporal normalization model is introduced to separate the temporal and spatial influences. Therefore, the proposed DFFGCN has a better learning ability compared with other advanced models. Finally, we give experiments to show the effectiveness and superiority of our proposed model. Experimental results on three traffic datasets demonstrate that DFFGCN can achieve state-of-the-art performance consistently. And the ablation studies confirm the importance of each element of DFFGCN.},
  archive      = {J_IJMLC},
  author       = {Zhao, Yuan and Li, Mingxin and Wen, Haoyang and Zhao, Hui and Wang, Yongjian and Wen, Shixi},
  doi          = {10.1007/s13042-024-02101-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3425-3437},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual flow fusion graph convolutional network for traffic flow prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A data-centric graph neural network for node classification
of heterophilic networks. <em>IJMLC</em>, <em>15</em>(8), 3413–3423. (<a
href="https://doi.org/10.1007/s13042-024-02100-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, numerous heterophilic networks effectively model the tendency of similar entities to repel each other and dissimilar entities to be attracted to each other within complex systems. Concerning the node classification problem in heterophilic networks, a plethora of heterophilic Graph Neural Networks (GNNs) have emerged. However, these GNNs demand extensive hyperparameter tuning, activation function selection, parameter initialization, and other configuration settings, particularly when dealing with diverse heterophilic networks and resource constraints. This situation raises a fundamental question: Can a method be designed to directly preprocess heterophilic networks and then leverage the trained models in network representation learning systems? In this paper, we propose a novel approach to transform heterophilic network structures. Specifically, we train an edge classifier and subsequently employ this edge classifier to transform a heterophilic network into its corresponding homophilic counterpart. Finally, we conduct experiments on heterophilic network datasets with variable sizes, demonstrating the effectiveness of our approach. The code and datasets are publicly available at https://github.com/xueyanfeng/D_c_GNNs .},
  archive      = {J_IJMLC},
  author       = {Xue, Yanfeng and Jin, Zhen and Gao, Wenlian},
  doi          = {10.1007/s13042-024-02100-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3413-3423},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A data-centric graph neural network for node classification of heterophilic networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drfnet: Dual stream recurrent feature sharing network for
video dehazing. <em>IJMLC</em>, <em>15</em>(8), 3397–3412. (<a
href="https://doi.org/10.1007/s13042-024-02099-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary effects of haze on captured images/frames are visibility degradation and color disturbance. Even though extensive research has been done on the tasks of video dehazing, they fail to perform better on varicolored hazy videos. The varicolored haze is still a challenging problem in video de-hazing. To tackle the problem of varicolored haze, the contextual information alone is not sufficient. In addition to adequate contextual information, color balancing is required to restore varicolored hazy images/videos. Therefore, this paper proposes a novel lightweight dual stream recurrent feature sharing network (with only 1.77 M parameters) for video de-hazing. The proposed framework involves: (1) A color balancing module to balance the color of input hazy frame in YCbCr space, (2) A multi-receptive multi-resolution module (MMM), which interlinks the RGB and YCbCr based features to learn global and rich contextual data, (3) Further, we have proposed a feature aggregation residual module (FARM) to strengthen the representative capability during reconstruction, (4) A channel attention module is proposed to resist redundant features by recalibrating weights of input features. Experimental results and ablation study show that the proposed model is superior to existing state-of-the-art approaches for video de-hazing.},
  archive      = {J_IJMLC},
  author       = {Galshetwar, Vijay M. and Saini, Poonam and Chaudhary, Sachin},
  doi          = {10.1007/s13042-024-02099-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3397-3412},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Drfnet: Dual stream recurrent feature sharing network for video dehazing},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic multi-label feature selection algorithm based on
label importance and label correlation. <em>IJMLC</em>, <em>15</em>(8),
3379–3396. (<a
href="https://doi.org/10.1007/s13042-024-02098-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label distribution is a popular direction in current machine learning research and is relevant to many practical problems. In multi-label learning, samples are usually described by high-dimensional features, many of which are redundant or invalid. This paper proposes a multi-label static feature selection algorithm to solve the problems caused by high-dimensional features of multi-label learning samples. This algorithm is based on label importance and label relevance, and improves the neighborhood rough set model. One reason for using neighborhood rough sets is that feature selection using neighborhood rough sets does not require any prior knowledge of the feature space structure. Another reason is that it does not destroy the neighborhood and order structure of the data when processing multi-label data. The method of mutual information is used to achieve the extension from single labels to multiple labels in the multi-label neighborhood; through this method, the label importance and label relevance of multi-label data are connected. In addition, in the multi-label task scenario, features may be interdependent and interrelated, and features often arrive incrementally or can be extracted continuously; we call these flow features. Traditional static feature selection algorithms do not handle flow features well. Therefore, this paper proposes a dynamic feature selection algorithm for flow features, which is based on previous static feature selection algorithms. The proposed static and dynamic algorithms have been tested on a multi-label learning task set and the experimental results show the effectiveness of both algorithms.},
  archive      = {J_IJMLC},
  author       = {Chen, Weiliang and Sun, Xiao},
  doi          = {10.1007/s13042-024-02098-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3379-3396},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic multi-label feature selection algorithm based on label importance and label correlation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual stage black-box adversarial attack against vision
transformer. <em>IJMLC</em>, <em>15</em>(8), 3367–3378. (<a
href="https://doi.org/10.1007/s13042-024-02097-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relying on wide receptive fields, Vision Transformers (ViTs) are more robust than Convolutional Neural Networks (CNNs). Consequently, some transfer-based attack methods that perform well on CNNs perform poorly when attacking ViTs. To address the aforementioned issues, we propose dual-stage attack framework named DSA. More specifically, we introduce a dual spatial optimization strategy involving both decision space and feature space optimization to improve the transferability of adversarial examples across different ViTs. Adversarial perturbations are generated by our proposed semi self-integrated module in the first stage and optimized by the feature extractor in the second stage. During this process, our proposed integrated model makes full use of the discriminative information in the deep transformer blocks and achieves significant improvements in transferability. To further enhance the transferability, we design the random perturbation masking module to alleviate the over-fitting of adversarial examples to the surrogate model. We evaluate the transferability of attacks on state-of-the-art ViTs, CNNs, and robustly trained CNNs. Extensive experiments demonstrate that the proposed dual-stage attack can greatly boost transferability between ViTs and from ViTs to CNNs.},
  archive      = {J_IJMLC},
  author       = {Wang, Fan and Shao, Mingwen and Meng, Lingzhuang and Liu, Fukang},
  doi          = {10.1007/s13042-024-02097-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3367-3378},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual stage black-box adversarial attack against vision transformer},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensor discriminant analysis on grassmann manifold with
application to video based human action recognition. <em>IJMLC</em>,
<em>15</em>(8), 3353–3365. (<a
href="https://doi.org/10.1007/s13042-024-02096-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representing videos as linear subspaces on Grassmann manifolds has made great strides in action recognition problems. Recent studies have explored the convenience of discriminant analysis by making use of Grassmann kernels. However, traditional methods rely on the matrix representation of videos based on the temporal dimension and suffer from not considering the two spatial dimensions. To overcome this problem, we keep the natural form of videos by representing video inputs as multidimensional arrays known as tensors and propose a tensor discriminant analysis approach on Grassmannian manifolds. Because matrix algebra does not handle tensor data, we introduce a new Grassmann projection kernel based on the tensor-tensor decomposition and product. Experiments with human action databases show that the proposed method performs well compared with the state-of-the-art algorithms.},
  archive      = {J_IJMLC},
  author       = {Ozdemir, Cagri and Hoover, Randy C. and Caudle, Kyle and Braman, Karen},
  doi          = {10.1007/s13042-024-02096-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3353-3365},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Tensor discriminant analysis on grassmann manifold with application to video based human action recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep bilinear koopman realization for dynamics modeling and
predictive control. <em>IJMLC</em>, <em>15</em>(8), 3327–3352. (<a
href="https://doi.org/10.1007/s13042-023-02095-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data-driven approaches based on the Koopman operator theory have promoted the analysis and control of the nonlinear dynamics by providing an equivalent Koopman-based linear system associated with nonlinear systems. To facilitate the use of the Koopman framework for nonlinear systems with control inputs and to improve the prediction accuracy of the Koopman approximation, this work proposes a deep learning-based bilinear Koopman modeling framework. In this framework, we first deploy a deep neural network structure consisting of a lifting network, a control network, a linear layer, and a recovery network to fulfill the identification of the bilinear Koopman realization. During the neural network training process, the model uncertainty naturally arises from the data-driven setting variation. Then, to represent the impact of this implicit uncertainty, we integrate a variable parameter into the output of the control network to identify a relatively accurate model, thereby enhancing the prediction ability of the learned model. The non-convex property caused by the bilinear term is resolved using a linear approximation. After that, we apply a Koopman-based model predictive control scheme to the identified bilinear model with the parameter estimation to realize the control of the nonlinear dynamical system.},
  archive      = {J_IJMLC},
  author       = {Wang, Meixi and Lou, Xuyang and Cui, Baotong},
  doi          = {10.1007/s13042-023-02095-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3327-3352},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep bilinear koopman realization for dynamics modeling and predictive control},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient evolutionary neural architecture search based on
hybrid search space. <em>IJMLC</em>, <em>15</em>(8), 3313–3326. (<a
href="https://doi.org/10.1007/s13042-023-02094-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manually designed convolutional neural networks have demonstrated excellent performance in various domains, but designing neural networks suitable for specific tasks poses significant challenges, and the emergence of Neural Structure Search (NAS) provides a new solution to this problem. However, existing algorithms either focus solely on network lightweight, resulting in subpar network performance, or excessively emphasize performance, leading to substantial network redundancy. With consideration for both network parameters and performance, this paper designs a hybrid search space based on residual modules and RepVGG modules using genetic algorithm, and stacks them together to form a more efficient network. To achieve this, we propose an efficient variable-length encoding strategy, utilizing units as the fundamental encoding space to encode variable-length individuals; we design evolutionary operations encompassing single-point crossover and three types of mutation operators to ensure population diversity; during training, a random forest-based performance predictor is employed to significantly shorten the network search time. To demonstrate the effectiveness of the proposed algorithm, we introduce the concept of transfer learning, which involves decoding the globally optimal solution, fine-tuning it, and then transferring it to three categories of real-world application datasets. Through comparisons with various algorithms, our approach consistently achieved leading performance.},
  archive      = {J_IJMLC},
  author       = {Gong, Tao and Ma, Yongjie and Xu, Yang and Song, Changwei},
  doi          = {10.1007/s13042-023-02094-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3313-3326},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Efficient evolutionary neural architecture search based on hybrid search space},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pedestrian trajectory prediction based on spatio-temporal
attention mechanism. <em>IJMLC</em>, <em>15</em>(8), 3299–3312. (<a
href="https://doi.org/10.1007/s13042-023-02093-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining and modeling city residents’ long-term and short-term preferences from their historical trajectory data is a key issue in trajectory prediction. People show different preferences in the long and short terms, but existing methods fail to fully consider the periodicity of residents’ long-term preferences and the abruptness of their short-term preferences, leading to unsatisfactory prediction results. To tackle this issue, we proposes a novel Spatio-Temporal Attention Mechanism Model to effectively capture the long- and short-term preferences of residents. Specifically, for the long-term preferences, we integrate the temporal context information generated during the user’s movement through an improved time-weighting operation to obtain the representation of temporal preferences. Then, we utilize a self-attention mechanism that combines geographic location factor to obtain the representation of long-term preferences. And for the short-term preferences, the dynamic programming is employed to capture the abruptness of residents’ access and obtain the representation of short-term preferences. Our experimental results on three benchmark datasets show the superiority of our proposed model over the state-of-the-art trajectory prediction models. It outperforms them in terms of Recall and NDCG, while also demonstrating superior robustness.},
  archive      = {J_IJMLC},
  author       = {Hu, Jun and Yang, Xinyu and Yan, Liang and Zhang, Qinghua},
  doi          = {10.1007/s13042-023-02093-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3299-3312},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pedestrian trajectory prediction based on spatio-temporal attention mechanism},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancing ASD detection: Novel approach integrating
attention graph neural networks and crossover boosted meerkat
optimization. <em>IJMLC</em>, <em>15</em>(8), 3279–3297. (<a
href="https://doi.org/10.1007/s13042-023-02092-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a neurodevelopmental condition that significantly impacts the lives of many children due to its hidden symptoms. Early detection of ASD is challenging because of its complex and heterogeneous nature. Magnetic resonance imaging (MRI) has emerged as a crucial tool for early detection, offering non-invasive imaging with detailed soft tissue information. However, existing approaches face limitations such as overfitting, underfitting, class imbalance, control, domain shift, and behavioral issues. To address these challenges, this paper proposes a novel ASD detection and classification model called the Autism Spectrum Disorder-based Attention Graph Neural Network and Crossover Boosted Meerkat Optimization (ASD-AttGCBMO) algorithm. The proposed method utilizes structural Magnetic Resonance Imaging (sMRI) data from the ABIDE 1 dataset. The data undergoes preprocessing to remove artifacts and noise, ensuring high image quality and consistency. Node feature extraction employs voxel-based morphometry (VBM) and surface-based analysis, which extract relevant features such as surface area, cortical thickness, shape descriptors, and brain volumes. The ASD-AttGCBMO model is trained using preprocessed sMRI images, employing the Adam and Stochastic Gradient Descent (SGD) optimizers to prevent overfitting, reduce classification loss, and improve convergence. The model is designed to enhance the learning process and capture complex patterns for accurate feature classification between ASD and control subjects. To optimize the hyperparameters in the attention-based neural network model, the CBMO algorithm is employed. Experimental validation is conducted using essential performance evaluation measures. The proposed method achieves impressive results, with accuracy, precision, recall, specificity, F1-score, Area under Receiver Operating curve (AUC/ROC), and computational time values of 98.8%, 99%, 98.5%, 98.6%, 98.2%, 0.989, and 3.05 s, respectively. Comparative analysis demonstrates that the proposed method outperforms other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Goel, Lipika and Gupta, Sonam and Gupta, Avdhesh and Rajan, Siddhi Nath and Gupta, Vishan Kumar and Singh, Arjun and Gupta, Pradeep},
  doi          = {10.1007/s13042-023-02092-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3279-3297},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Advancing ASD detection: Novel approach integrating attention graph neural networks and crossover boosted meerkat optimization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BPSO-SLM: A binary particle swarm optimization-based
self-labeled method for semi-supervised classification. <em>IJMLC</em>,
<em>15</em>(8), 3255–3277. (<a
href="https://doi.org/10.1007/s13042-023-02091-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-labeled methods have been favored by scholars in semi-supervised classification. Mislabeling is a great challenge for self-labeled methods and one of the reasons for mislabeling is that high-confidence unlabeled samples are found by mistake. While multiple variations of self-labeled methods have been developed, most existing strategies for finding high-confidence unlabeled samples heavily rely on specific assumptions. To solve the above issue, a binary particle swarm optimization-based self-labeled method (BPSO-SLM) is proposed and includes the following iterative self-labeled process: (a) A given classifier is trained on the set of labeled data; (b) The binary particle swarm optimization-based sample subspace optimization (BPSOSSO) is innovatively proposed to help BPSO-SLM find high-confidence unlabeled samples and low-confidence unlabeled samples from the set of unlabeled data; (c) The trained classifier is used to predict found high-confidence unlabeled samples; (d) High-confidence samples with pseudo labels are added to the set of labeled data, while low-confidence samples are returned to the set of unlabeled data and will be predicted again in the next iteration. The above process repeats until no high-confidence samples are found. After that, BPSO-SLM outputs the trained classifier during the iterative self-labeled process. The main characteristic of BPSO-SLM is that the strategy of finding high-confidence unlabeled samples makes little or no specific hypothesis about the geometric, distribution, and others of the selected high-confidence unlabeled samples. Intensive experiments on benchmark data prove that BPSO-SLM outperforms 8 state-of-the-art self-labeled methods in classification accuracy, Marco F-measure, and labeling error rate with various ratios of labeled data.},
  archive      = {J_IJMLC},
  author       = {Liu, Ruijuan and Li, Junnan},
  doi          = {10.1007/s13042-023-02091-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3255-3277},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BPSO-SLM: A binary particle swarm optimization-based self-labeled method for semi-supervised classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Novel multi-label feature selection via label enhancement
and relative maximal discernibility pairs. <em>IJMLC</em>,
<em>15</em>(8), 3237–3253. (<a
href="https://doi.org/10.1007/s13042-023-02090-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is an effective solution to the multi-label data dimensionality disaster problem. However, there are few studies on multi-label feature selection considering label enhancement methods. Meanwhile, most existing label enhancement methods neglect the relative importance of labels, which can degrade the classification performance of the model. To address this issue, we propose a novel multi-label feature selection algorithm based on label enhancement and relative maximal discernibility pairs. Firstly, we propose the label importance weight based on relative discernibility pairs and design the concept of soft relevance between objects and labels via fuzzy rough sets. Secondly, we propose a novel label enhancement algorithm by combining the soft relevance and the label importance weight. Thirdly, we define a relative maximal discernibility pair model for evaluating features in label distribution information systems. Additionally, based on the relative maximal discriminative pair model and label enhancement, we present a multi-label feature selection algorithm which can continuously reduce the universe of object pairs in the selection process. Finally, to validate the effectiveness and stability of our algorithm, we conduct extensive comparison experiments with 7 representative multi-label feature selection algorithms on 13 datasets. Experimental results show that our algorithm performs better than the compared 7 algorithms in 5 evaluation metrics.},
  archive      = {J_IJMLC},
  author       = {Dai, Jianhua and Wang, Zhiyang and Huang, Weiyi},
  doi          = {10.1007/s13042-023-02090-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3237-3253},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Novel multi-label feature selection via label enhancement and relative maximal discernibility pairs},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aspect category sentiment classification via document-level
GAN and POS information. <em>IJMLC</em>, <em>15</em>(8), 3221–3235. (<a
href="https://doi.org/10.1007/s13042-023-02089-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of aspect-category sentiment classification (ACSC) is to determine the sentiment polarity of the predefined aspect category from the texts. Current methods for ACSC have two main limitations. Since the aspect categories are not presented in the given texts, the establishment of relation between the aspect-category and its sentiment opinion expression is challenging using the widely-applied aspect-term sentiment classification approaches. Besides, the aspect-category-related information on document level are ignored during processing. In this work, we focus on dealing with the part-of-speech information based on gated-activation functions. Furthermore, two graph attention networks (GANs) are employed to exploit the document-level sentiment of both the entity and the attribute (intra-entity sentiment tendency and intra-attribute sentiment tendency). The aspect-category detection (ACD) is taken as a auxiliary task to capture the relevant semantic information. Besides, contrastive learning is receiving an increasing amount of interest due to its success in self-supervised representation learning in the field of NLP. By performing contrastive learning, representations of positive examples are drawn closer while those of negative samples are distanced. Comparing with the baseline methods, experimental results reveal that our model achieves the state-of-the-art performance in ACSC tasks.},
  archive      = {J_IJMLC},
  author       = {Zhao, Haoliang and Xiao, Junyang and Xue, Yun and Zhang, Haolan and Cai, Shao-Hua},
  doi          = {10.1007/s13042-023-02089-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3221-3235},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Aspect category sentiment classification via document-level GAN and POS information},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Recursive noisy label learning paradigm based on confidence
measurement for semi-supervised depth completion. <em>IJMLC</em>,
<em>15</em>(8), 3201–3219. (<a
href="https://doi.org/10.1007/s13042-023-02088-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth completion is a critical task for extensive applications such as 3D reconstruction and object detection. Recent semi-supervised depth completion techniques based on Stereo-LiDAR fusion has gradually attracted attention due to its ability to realize semi-supervised training under the weakly supervised constraints provided by the sparse LiDAR points as well as the view synthesis consistency provided by the stereo images. However, among these methods, noisy label as a conventional supervised signal for semi-supervised learning have not been taken seriously. To this end, we first propose a semi-supervised learning framework called Recursive Noise Label Learning (RNLL), which is able to maximize the potential of noisy label learning by establishing a recursive noisy label optimization and model learning mechanism. Second, based on the proposed RNLL framework, we come up with a novel semi-supervised depth completion model, UAMD-Net-RNLL, which integrates the CCNN model to accomplish the confidence measure of depth prediction on the basis of the original UAMD-Net model, and realizes the noise filtering of the noisy depth maps and adaptive loss computation by constructing the confidence-guided noisy label loss function. Finally, for the noisy label and photometric consistency loss constraints in multiple rounds of training, we utilize dynamic loss weights to describe their importance changes, and realize the continuous improvement of the prediction performance of the semi-supervised depth completion model. Extensive experimental results conducted on KITTI and DrivingStereo depth completion datasets prove that our technique achieves large performance gain, clearly outperforming competing methods and setting a new state-of-the-art for semi-supervised depth completion.},
  archive      = {J_IJMLC},
  author       = {Chen, Guancheng and Qin, Huabiao and Huang, Linyi},
  doi          = {10.1007/s13042-023-02088-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3201-3219},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recursive noisy label learning paradigm based on confidence measurement for semi-supervised depth completion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hospitalization mechanism based immune plasma algorithm
for path planning of unmanned aerial vehicles. <em>IJMLC</em>,
<em>15</em>(8), 3169–3199. (<a
href="https://doi.org/10.1007/s13042-023-02087-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) and their specialized variants known as unmanned combat aerial vehicles (UCAVs) have triggered a profound change in the well-known military concepts and researchers from different disciplines tried to solve challenging problems of the mentioned vehicles. Path planning is one of these challenging problems about the UAV or UCAV systems and should be solved carefully by considering some optimization requirements defined for the enemy threats, fuel or battery usage, kinematic limitations on the turning and climbing angles in order to further improving the task success and safety of autonomous flight. Immune plasma algorithm (IP algorithm or IPA) modeling the details of a medical method gained popularity with the COVID-19 pandemic has been introduced recently and showed promising performance on solving a set of engineering problems. However, IPA requires setting the control parameters appropriately for maintaining a balance between the exploration and exploitation characteristics and does not design the particular treatment and hospitalization procedures by taking into account the implementation simplicity. In this study, IP algorithm was supported with a newly designed and realistic hospitalization mechanism that manages when an infected population member enters and discharges from the hospital. Moreover, the existing treatment schema of the algorithm was changed completely for improving the efficiency of the plasma transfer operations and removing the necessity of IPA specific control parameters and then a novel path planner called hospital IPA (hospIPA) was presented. For investigating the performance of hospIPA on solving path planning problem, a set of detailed experiments was carried out over twenty test cases belonging to both two and three-dimensional battlefield environments. The paths calculated by hospIPA were also compared with the calculated paths of other fourteen meta-heuristic based path planners. Comparative studies proved that the hospitalization mechanism making an exact discrimination between the poor and qualified solutions and modified treatment schema collecting the plasma being transferred by guiding the best solution give a tremendous contribution and allow hospIPA to obtain more safe and robust paths than other meta-heuristics for almost all test cases.},
  archive      = {J_IJMLC},
  author       = {Aslan, Selcuk},
  doi          = {10.1007/s13042-023-02087-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3169-3199},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hospitalization mechanism based immune plasma algorithm for path planning of unmanned aerial vehicles},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ConDA: State-based data augmentation for context-dependent
text-to-SQL. <em>IJMLC</em>, <em>15</em>(8), 3157–3168. (<a
href="https://doi.org/10.1007/s13042-023-02086-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The context-dependent text-to-SQL task has profound real-world implications, as it facilitates users in extracting knowledge from vast databases, which allows users to acquire the information interactively for better accuracy. Unfortunately, current models struggle to address this task effectively due to the scarcity of data led by the high annotation overhead. The most straightforward method for addressing this problem is data augmentation, which aims at scaling up the parsing corpus. However, the naive methods suffer from the low diversity of the augmented data. To address this limitation, we propose the state-based CONtext-dependent text-to-SQL Data Augmentation (ConDA), which generate and filter augmented data based on the dialogue state, which has higher diversity. Experimental results show that ConDA yields performance improvement on all experimental datasets with an average boosting of $$1.6\%$$ , proving the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Wang, Dingzirui and Dou, Longxu and Che, Wanxiang and Wang, Jiaqi and Liu, Jinbo and Li, Lixin and Shang, Jingan and Tao, Lei and Zhang, Jie and Fu, Cong and Song, Xuri},
  doi          = {10.1007/s13042-023-02086-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3157-3168},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ConDA: State-based data augmentation for context-dependent text-to-SQL},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long-short interest network with graph-based method for
sequential recommendation. <em>IJMLC</em>, <em>15</em>(8), 3143–3155.
(<a href="https://doi.org/10.1007/s13042-023-02085-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, sequence information is crucial. Sequence data contains user preferences and reflects the evolution of user interests over time. Therefore, how to utilize sequence information to capture dynamic user interests is a critical issue in sequential recommender systems (SRSs). Attention-based methods are commonly used in SRSs and achieve state-of-the-art results. However, attention mechanisms lack the ability to represent the temporal dimension and cannot use sequence order effectively. To this end, this paper proposes a novel model structure called Long-Short Interest Network (LSIN), which fuses Long Short Term Memory (LSTM) and Transformer encoder. We use two LSTM layers to capture the user’s long-term and short-term interests, respectively. Furthermore, adding the LSTM can help the self-attention mechanism better model the sequential relationship between items. In addition, most embedding models generate embedding vectors based on individual items without considering the connection between items and users. This will be an obstacle and bring difficulty for later models to capture the evolution of user interests. Therefore, we use a heterogeneous graph to model the interactions between users and items. And design a weight-based graph embedding for generating embedding vectors, which can encode higher-order structural information by propagating on the graph. Finally, we propose LSRec, a framework that unites the above two structures to achieve more accurate recommendations. The new model yielded significant benefits. The experiments on four benchmark data sets demonstrate the effectiveness of LSRec, which achieves almost 5 $$\%$$ improvement in NDCG@10 compared with Self-Attention based Sequential Recommendation model (SASRec).},
  archive      = {J_IJMLC},
  author       = {Mu, Wangdong and Liu, Qihe and Cheng, Hongrong and Zhuo, Ming},
  doi          = {10.1007/s13042-023-02085-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3143-3155},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Long-short interest network with graph-based method for sequential recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combining core points and cluster-level semantic similarity
for self-supervised clustering. <em>IJMLC</em>, <em>15</em>(8),
3127–3142. (<a
href="https://doi.org/10.1007/s13042-023-02084-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning utilizes data augmentation to guide network training. This approach has attracted considerable attention for clustering, object detection, and image segmentation. However, previous studies have ignored the impact of false-negative pairs, resulting in the dissimilarity of the semantic representations of the same cluster. Some researchers have attempted to address this problem; however, only considering the image level has provided unsatisfactory results. To this end, we propose a novel feature extraction algorithm suitable for clustering, combining core points and semantic similarity at the cluster level to restructure positive and negative pairs. Specifically, the core points consisting of the n-nearest neighbors of the cluster center are considered the semantic sample relations of the cluster. This information is explored to reconstruct semantic positive and negative pairs to maximize intra-cluster similarity and inter-cluster variability. More accurate cluster centers offer a sub-optimal initialization for updating the feature model and clustering assignment, which is optimized by the expectation-maximization framework. Extensive experiments conducted on six benchmark datasets show promising clustering performances with relatively few training epochs. The proposed method outperforms the best baseline by 4 $$\%$$ (1.5 $$\%$$ ) on CIFAR-100 (CIFAR-10). The CPCS code is open-sourced at https://github.com/Cappuccino-Sugar/CPCS .},
  archive      = {J_IJMLC},
  author       = {Wang, Wenjie and Chen, Junfen and Zhang, Xiao and Xie, Bojun},
  doi          = {10.1007/s13042-023-02084-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3127-3142},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Combining core points and cluster-level semantic similarity for self-supervised clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fairness issues, current approaches, and challenges in
machine learning models. <em>IJMLC</em>, <em>15</em>(8), 3095–3125. (<a
href="https://doi.org/10.1007/s13042-023-02083-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing influence of machine learning algorithms in decision-making processes, concerns about fairness have gained significant attention. This area now offers significant literature that is complex and hard to penetrate for newcomers to the domain. Thus, a mapping study of articles exploring fairness issues is a valuable tool to provide a general introduction to this field. Our paper presents a systematic approach for exploring existing literature by aligning their discoveries with predetermined inquiries and a comprehensive overview of diverse bias dimensions, encompassing training data bias, model bias, conflicting fairness concepts, and the absence of prediction transparency, as observed across several influential articles. To establish connections between fairness issues and various issue mitigation approaches, we propose a taxonomy of machine learning fairness issues and map the diverse range of approaches scholars developed to address issues. We briefly explain the responsible critical factors behind these issues in a graphical view with a discussion and also highlight the limitations of each approach analyzed in the reviewed articles. Our study leads to a discussion regarding the potential future direction in ML and AI fairness.},
  archive      = {J_IJMLC},
  author       = {Jui, Tonni Das and Rivas, Pablo},
  doi          = {10.1007/s13042-023-02083-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3095-3125},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fairness issues, current approaches, and challenges in machine learning models},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unsupervised domain adaptation via feature transfer learning
based on elastic embedding. <em>IJMLC</em>, <em>15</em>(8), 3081–3094.
(<a href="https://doi.org/10.1007/s13042-023-02082-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised classification algorithms usually require a large quantity of well-labeled samples for training to achieve satisfied performance. Nevertheless, it is prohibitively difficult to create such datasets with complete annotation. Unsupervised domain adaptation is able to deal with this problem via transferring knowledge from a relevant dataset with rich labels to an unlabeled target dataset. In this paper, a novel unsupervised domain adaptation method named feature transfer learning based on elastic embedding (EEFTL) is presented for image classification. Rather than make a rigid embedding that the binary label matrix is exactly equal to a linear function, EEFTL adopts an elastic embedding induced by the prediction label matrix. Specifically, EEFTL introduces a flexible regression residue term to model the mismatch between the embedded features of samples and the prediction labels. In addition, EEFTL integrates a label fitness term to effectively utilize the label information from the source samples, a distribution matching term to reduce the distances between domains in both the marginal and conditional distributions, and a manifold regularization term to preserve the sample-wise structure information under the elastic embedding. Extensive experiments are carried out on multiple benchmark datasets, and the results prove the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Yang, Liran and Lu, Bin and Zhou, Qinghua and Su, Pan},
  doi          = {10.1007/s13042-023-02082-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3081-3094},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised domain adaptation via feature transfer learning based on elastic embedding},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A general framework for improving cuckoo search algorithms
with resource allocation and re-initialization. <em>IJMLC</em>,
<em>15</em>(8), 3061–3080. (<a
href="https://doi.org/10.1007/s13042-023-02081-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuckoo search (CS) has currently become one of the most favorable meta-heuristic algorithms (MHAs). In this article, a simple yet effective framework is proposed for CS algorithms to reinforce their performance, which contains two core mechanisms: computational resource allocation (CRA) and Gaussian sampling based re-initialization (GSR). The CRA is responsible for allocating more computational resources to promising individuals, thus promoting search efficiency and speeding up convergence, whilst the GSR is introduced to help the algorithm in maintaining population diversity. For testifying the effectiveness and generality of this framework (referred to as AR framework), it is embedded into nine well-established CS algorithms and extensive experiments are conducted on CEC 2013, CEC 2014, and CEC 2017 test suites. Experimental results indicate that the AR framework could bring a significant improvement on the performance of the classical CS as well as its variants, achieving an average efficient rate of 78.97%, 72.59%, and 86.21% on the three test suites, respectively. Besides, the comparisons between the classical CS, its AR framework version, and several other classical MHAs validate the effectiveness of the AR framework again. Additionally, the benefit of each mechanism (i.e., CRA and GSR) and their combination is also ascertained.},
  archive      = {J_IJMLC},
  author       = {Yang, Qiangda and Chen, Yongxu and Zhang, Jie and Wang, Yubo},
  doi          = {10.1007/s13042-023-02081-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {8},
  pages        = {3061-3080},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A general framework for improving cuckoo search algorithms with resource allocation and re-initialization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: Different treatments of pixels in unlabeled
images for semi-supervised sonar image segmentation. <em>IJMLC</em>,
<em>15</em>(7), 3059–3060. (<a
href="https://doi.org/10.1007/s13042-023-02065-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Xu, Huipu and Tong, Pengfei and Li, Yongzhi},
  doi          = {10.1007/s13042-023-02065-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {3059-3060},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: Different treatments of pixels in unlabeled images for semi-supervised sonar image segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction to: IntelPVT: Intelligent patch-based pyramid
vision transformers for object detection and classification.
<em>IJMLC</em>, <em>15</em>(7), 3057. (<a
href="https://doi.org/10.1007/s13042-023-02052-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Nimma, Divya and Zhou, Zhaoxian},
  doi          = {10.1007/s13042-023-02052-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {3057},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: IntelPVT: intelligent patch-based pyramid vision transformers for object detection and classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fine-grained convolutional recurrent model for obstructive
sleep apnea detection. <em>IJMLC</em>, <em>15</em>(7), 3043–3056. (<a
href="https://doi.org/10.1007/s13042-023-02080-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive Sleep Apnea (OSA) is a prevalent sleep-related breathing disorder that leads to various health issues such as hypertension, heart disease, diabetes, and stroke. In order to achieve a convenient, robust and accurate OSA detection, we analyze the cardiopulmonary coupling mechanism of OSA from single-lead electrocardiogram (ECG) signals. Then we propose a fine-grained convolutional recurrent model (FCRM) for obstructive sleep apnea detection to learn the variation of cardiopulmonary coupling (CPC) features for OSA detection. Finally, we offer interpretable insights into the model’s decisions using respiration signal and achieve fine-grained apnea classification based on attention score. The proposed model’s performance on the Apnea-ECG dataset achieved 93.2% accuracy, 89.2% sensitivity, and 96.4% specificity. This demonstrates that the method effectively extracts cardiopulmonary characteristics during sleep apnea and outperforms other methods.},
  archive      = {J_IJMLC},
  author       = {Zhang, Enming and Yao, Yuan and Zhou, Nan and Chen, Yu and Zhang, Haibo and Guo, Jinhong and Teng, Fei},
  doi          = {10.1007/s13042-023-02080-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {3043-3056},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A fine-grained convolutional recurrent model for obstructive sleep apnea detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated catastrophic optical damage inspection of
semiconductor laser chip based on multi-scale strip convolution
aggregation. <em>IJMLC</em>, <em>15</em>(7), 3027–3042. (<a
href="https://doi.org/10.1007/s13042-023-02079-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catastrophic optical damage (COD) is one of the reasons limiting the output power and lifetime of semiconductor lasers. Nevertheless, the automatic defects inspection of the COD is a challenging task due to several factors, including the micron-scale size of the laser chip, poor contrast, the notable similarities in defect features across different categories, and the fact that defects occupy a minimal portion of image pixels in the images. In this work, We first design and implement a data acquisition and inspection system to collect micron-scale laser chip electroluminescence (EL) images. Secondly, we establish a laser chip COD dataset for training. Finally, a novel COD detection network (CODDNet) is proposed to construct an end-to-end defect detection method. To better extract strip-like COD features under poor contrast, a strip convolution is proposed to acquire more discriminative features and reduce the parameters. A multi-scale strip convolution aggregation structure is proposed to extract richer information across different defect categories from the network to obtain multi-scale feature maps. To address the class imbalance issue between defect and the background, an attention module is embedded into the block to emphasize the COD defects. The experimental results demonstrated that the proposed CODDNet could achieve a higher inspection accuracy and faster inference speed with fewer parameters. Based on the proposed method, manufacturers could take corresponding effective measures to improve the stability of laser chips. In the future, we will continue to expand the COD dataset and conduct research on defect detection for different types of laser chips.},
  archive      = {J_IJMLC},
  author       = {Guo, Shuai and Li, Dengao and Zhao, Jumin and Jia, Huayu and Luo, Biao and Tang, Bao and Lv, Yuxiang},
  doi          = {10.1007/s13042-023-02079-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {3027-3042},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Automated catastrophic optical damage inspection of semiconductor laser chip based on multi-scale strip convolution aggregation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entropy based optimal scale selection and attribute
reduction in multi-scale interval-set decision tables. <em>IJMLC</em>,
<em>15</em>(7), 3005–3026. (<a
href="https://doi.org/10.1007/s13042-023-02078-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the current research gaps in multi-scale data analysis is studying information systems characterized by attributes with interval sets as attribute values and multiple scales. To address this gap, we first introduce the concepts of a multi-scale interval-set information system (MISIS) and a multi-scale interval-set decision table (MISDT). We then define the similarity relation between objects in an MISIS and the corresponding rough approximations. We further propose the positive region optimal scale, the modified conditional entropy optimal scale, and the positive complementary conditional entropy optimal scale in an MISDT. We examine the relationships among these optimal scales in consistent and inconsistent MISDTs and show that the positive region optimal scale and the modified conditional entropy optimal scale are equivalent in a consistent MISDT, while in an inconsistent MISDT, the positive region optimal scale is the same as the positive complementary conditional entropy optimal scale, and the modified conditional entropy optimal scale is not greater than the positive complementary conditional entropy optimal scale. Based on the optimal scale, we also develop attribute reduction approaches in MISDTs. Finally, through experimental analysis of data on the UCI dataset, we verify the effectiveness and reasonableness of our proposed methods.},
  archive      = {J_IJMLC},
  author       = {Xie, Zhen-Huang and Wu, Wei-Zhi and Wang, Lei-Xi and Tan, Anhui},
  doi          = {10.1007/s13042-023-02078-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {3005-3026},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Entropy based optimal scale selection and attribute reduction in multi-scale interval-set decision tables},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ULAF-net: Ultra lightweight attention fusion network for
real-time semantic segmentation. <em>IJMLC</em>, <em>15</em>(7),
2987–3003. (<a
href="https://doi.org/10.1007/s13042-023-02077-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time semantic segmentation, laying the foundation of mobile robots and autonomous driving, has attracted much attention in recent years. Currently, most deep models suffer high computational costs due to their complex architectures, making them impractical on resource-limited devices. Some lightweight models have been designed by reducing model complexity at the expense of segmentation accuracy. We propose an ultra-lightweight network, called ULAF-Net, to achieve a balance between segmentation accuracy, model complexity, and inference speed. This network abandons the straightforward concatenation of simple multi-scale fusion methods. First, we employ a parameter-free attention mechanism to process two large-scale feature maps, followed by the initial fusion. Furthermore, we consider the characteristics of varying scales and utilize lightweight spatial and channel attention modules to perform secondary processing on the fused large-scale feature map and the small-scale feature map, respectively, further highlighting important features. Finally, we combine both of them. In addition, we integrate multiple specialized convolutional methods and attention mechanisms to design a new residual module, which can make full use of the contextual features. The parameter quantity of ULAF-Net is merely 0.60M. It possesses the capability of real-time segmentation and achieves competitive segmentation outcomes on public datasets.},
  archive      = {J_IJMLC},
  author       = {Hu, Kaidi and Xie, Zongxia and Hu, Qinghua},
  doi          = {10.1007/s13042-023-02077-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2987-3003},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ULAF-net: Ultra lightweight attention fusion network for real-time semantic segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fpar: Filter pruning via attention and rank enhancement for
deep convolutional neural networks acceleration. <em>IJMLC</em>,
<em>15</em>(7), 2973–2985. (<a
href="https://doi.org/10.1007/s13042-023-02076-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning deep neural networks is crucial for enabling their deployment on resource-constrained edge devices, where the vast number of parameters and computational requirements pose significant challenges. However, many of these methods consider only the importance of a single filter to the network and neglect the correlation between filters. To solve this problem, we propose a novel filter pruning method, called Filter Pruning via Attention and Rank Enhancement for Deep Convolutional Neural Networks Acceleration (FPAR), based on the attention mechanism and rank of feature maps. Moreover, the inspiration for it comes from a discovery: for a network with attention modules, irrespective of the batch of input images, the mean of channel-wise weights of the attention module is almost constant. Thus, we can use a few batches of input data to obtain this indicator to guide pruning. A large number of experiments have proved that our method outperforms the most advanced methods with similar accuracy. For example, using VGG-16, our method removes 62.8% of floating-point operations (FLOPs) even with a 0.24% of the accuracy increase on CIFAR-10. With ResNet-110, our FPAR method can reduce FLOPs by 61.7% by removing 62.7% of the parameters, with slight improvement of 0.05% in the top 1 accuracy on CIFAR-10.},
  archive      = {J_IJMLC},
  author       = {Chen, Yanming and Wu, Gang and Shuai, Mingrui and Lou, Shubin and Zhang, Yiwen and An, Zhulin},
  doi          = {10.1007/s13042-023-02076-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2973-2985},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fpar: Filter pruning via attention and rank enhancement for deep convolutional neural networks acceleration},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-target regression via stochastic configuration
networks with modular stacked structure. <em>IJMLC</em>, <em>15</em>(7),
2957–2972. (<a
href="https://doi.org/10.1007/s13042-023-02075-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-target regression (MTR) has been widely studied in data analytics and its main challenge is to jointly model the input-output relationships and the intrinsic inter-target correlations. As a novel learner model, stochastic configuration network (SCN) is an effective tool to solve the regression problem. This paper develops a modular stacked structure for SCN to address the MTR tasks. The SCN with modular stacked structure is composed of multiple modules, which could well explore the inter-target hidden information by the strategy of expanding the input space. There are multiple nets using two implementation algorithms named as synchronous stacked SCN (SS-SCN) and asynchronous stacked SCN (AS-SCN) in each module, and SS-SCN models all targets simultaneously while AS-SCN models multiple targets sequentially. The convergence of the two proposed algorithms is theoretically guaranteed via approaching the residuals step by step. Finally, extensive experimental examples have been carried out on both synthetic datasets and real-world datasets, revealing the effectiveness and usefulness of the proposed algorithms for the multivariate prediction tasks.},
  archive      = {J_IJMLC},
  author       = {Wu, Shang and Liu, Xin and Yu, Gang and Dai, Wei},
  doi          = {10.1007/s13042-023-02075-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2957-2972},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-target regression via stochastic configuration networks with modular stacked structure},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-granularity network representation learning on
overlapping communities. <em>IJMLC</em>, <em>15</em>(7), 2935–2955. (<a
href="https://doi.org/10.1007/s13042-023-02074-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-granularity attributed network representation learning constructs a multi-granularity attributed network to extract multi-granularity features of an attributed network while preserving network’s structure and attributes’ informance. Note that the construction of multi-granularity attributed network affects the performance of multi-granularity attributed network representation learning applied to the node classification task. The existing methods of constructing multi-granularity attributed network ignore the information of overlapping nodes and weaken node classification ability. To solve this problem, we make full use of the overlapping nodes’ information to construct a multi-granularity attributed network, use the least information loss to define the optimal granularity, and propose a multi-granularity attributed network representation learning method (MANOC) for preserving overlapping community structure. Specifically, our method can quickly construct attributed networks of different granularities through overlapping nodes to learn node representations. That is, in the coarsening module, an overlapping community detection algorithm is adopted to find overlapping nodes and then we increase the weights of the edges formed by overlapping nodes. Furthermore, based on the similarity between nodes and communities, the attribute values of overlapping nodes are reasonably allocated, and information entropy and cross entropy are integrated to select the optimal granularity. Finally, we compare the proposed method with six representative network representation learning methods in achieving node classification tasks on five real network datasets. The experiments reveal that our method improves the average node classification accuracy by 30.67%, 24.05%, 11.19%, 18.80%, 21.55% and 0.46% compared to DeepWalk, Node2Vec, CAN, MILE, GraphZoom and HANE, respectively. In addition, we also demonstrate that node classification accuracies reach the maximum on the networks with optimal granularities.},
  archive      = {J_IJMLC},
  author       = {Zhou, Rongrong and Li, Jinhai},
  doi          = {10.1007/s13042-023-02074-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2935-2955},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-granularity network representation learning on overlapping communities},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tabular reasoning via two-stage knowledge injection.
<em>IJMLC</em>, <em>15</em>(7), 2915–2933. (<a
href="https://doi.org/10.1007/s13042-023-02073-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tabular reasoning presents a significant challenge in understanding natural language queries in the context of provided tables, mainly because of the complex logical operations involved. Pre-trained language models have demonstrated their capabilities in various tasks. However, performing pre-training specifically for tabular reasoning is difficult due to the diverse range of reasoning abilities required beyond contextual understanding. In this work, we propose Tabular Reasoning with Two-stage Knowledge Injection (TsKI). TsKI consists of two components: TsKI $$_{\textsc {Stage1}}$$ and TsKI $$_{\textsc {Stage2}}$$ . The primary objective of TsKI $$_{\textsc {Stage1}}$$ is to incorporate symbolic knowledge into pre-trained language models by utilizing synthesized programs. It begins by generating high-quality programs using a specific program synthesis algorithm. Next, TsKI $$_{\textsc {Stage1}}$$ conducts pre-training on the automatically generated corpus, enabling the model to learn how to query tables using the generated programs. On the other hand, TsKI $$_{\textsc {Stage2}}$$ aims to inject step-wise knowledge into the model. It starts by decomposing natural language queries into multiple sub-queries using heuristic rules and a constituency parser. Then, it employs pre-trained language models themselves to query tables with the obtained sub-queries, obtaining intermediate results that facilitate step-wise tabular reasoning. Experimental results demonstrate the effectiveness of our proposed approach. TsKI achieves significant improvements on two well-known tabular reasoning datasets, namely TabFact and WikiTableQuestions, in both TsKI $$_{\textsc {Stage1}}$$ and TsKI $$_{\textsc {Stage2}}$$ . Furthermore, in-depth analysis validates the effectiveness of each component of our approach. The code is available at https://github.com/qshi95/TsKI .},
  archive      = {J_IJMLC},
  author       = {Shi, Qi and Zhang, Yu and Liu, Ting},
  doi          = {10.1007/s13042-023-02073-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2915-2933},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Tabular reasoning via two-stage knowledge injection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Click-through rate prediction based on feature interaction
and behavioral sequence. <em>IJMLC</em>, <em>15</em>(7), 2899–2913. (<a
href="https://doi.org/10.1007/s13042-023-02072-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate prediction is one of the hot topics in the recommendation and advertising systems field. The existing click-through rate prediction models can be classified into feature interactions and behavior sequences. Feature interaction models form new feature combinations by fusing different features. The behavior sequence models capture the user’s interests by considering the historical behavior and using an attention mechanism to model the relationship between the target item and the behavior sequence. However, the existing click-through rate prediction techniques either ignore both aspects or only consider one, limiting prediction performance. In order to solve the above problems, we propose a click-through prediction model (CFIBS) that combines feature interaction and behavioral sequence in this paper. Firstly, the Global-Local Gate Module and Post-LN Informer are proposed to extract the user’s interests from user behavior sequences to improve training efficiency. In addition, we introduce auxiliary losses to supervise the extraction of user interest features. Secondly, in the interest update layer, we introduce an attention mechanism based gated recurrent unit to enhance the relationship between interest representation and the target item. Finally, for non-temporal features, we propose a Multi-Cross Layer to increase the nonlinear ability of the model. Experiments show that our model can effectively improve the click-through rate prediction accuracy of advertisements. The codes will be available at https://github.com/jihuiqin2/sequence_ctr .},
  archive      = {J_IJMLC},
  author       = {Wang, Yingqi and Ji, Huiqin and Yu, Junyang and Han, Hongyu and Zhai, Rui},
  doi          = {10.1007/s13042-023-02072-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2899-2913},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Click-through rate prediction based on feature interaction and behavioral sequence},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rlm-tracking: Online multi-pedestrian tracking supported by
relative location mapping. <em>IJMLC</em>, <em>15</em>(7), 2881–2897.
(<a href="https://doi.org/10.1007/s13042-023-02070-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of multi-object tracking stands as a fundamental focus in computer vision research, finding widespread applications in areas such as public safety, transportation, autonomous vehicles, robotics, and other domains involving artificial intelligence. Given the intricate nature of natural scenes, the occurrence of object occlusion and semi-occlusion is commonplace in basic tracking tasks. These factors often result in challenges such as ID switching, object loss, detection errors, and misaligned bounding boxes, thereby significantly impacting the precision of multi-object tracking.This paper aims to address the aforementioned issues and proposes a novel multi-object tracker, incorporating Relative location mapping (RLM) and Target region density (TRD) modeling. The new tracker is more sensitive to differences in the spatial relationships between targets, allowing it to dynamically introduce low-scoring detection boxes into different regions based on the density of target regions in the image. This improves the accuracy of target tracking while avoiding the consumption of a significant amount of computational resources.Our research results indicate that when applying this method to state-of-the-art multi-object tracking approaches, the proposed model achieves improvements of 0.4 to 0.8 points in the HOTA and IDF1 metrics on the MOT17 and MOT20 datasets. This demonstrates the effectiveness of the proposed method in enhancing multi-object tracking performance.},
  archive      = {J_IJMLC},
  author       = {Ren, Kai and Hu, Chuanping and Xi, Hao},
  doi          = {10.1007/s13042-023-02070-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2881-2897},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Rlm-tracking: Online multi-pedestrian tracking supported by relative location mapping},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on fuzzy dynamic route choice model and algorithm
of wargame. <em>IJMLC</em>, <em>15</em>(7), 2863–2880. (<a
href="https://doi.org/10.1007/s13042-023-02069-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at automatic route choice in wargame deduction, that is, using computer algorithms to mimic the route choice of human players. Route choice is the process by which a player of a game chooses the optimal route from a set of candidate routes. Essentially, it can be viewed as a multi-attribute decision making problem. However, due to the uncertain and dynamic decision making environment in wargaming, the existing decision making theory and methods face some challenges in addressing such problems. We summarize these challenges in two aspects. On the one hand, from a psychological point of view, the process of route choice by a human player is a dynamic decision making process. However, most of the multi-attribute decision making methods widely used today were developed under static conditions and do not accurately describe the decision making behaviors of individuals in dynamic and real-world settings. On the other hand, in the real dynamic decision making environment of wargaming, there is a large amount of ambiguous and uncertain information. How to imitate human thinking to quantify the information is crucial for making scientific decisions and for automating decision making. Based on the above two aspects of the analysis, in this paper, we first construct a fuzzy dynamic route choice model of wargame. The model simulates the decision making process of humans from two stages of “information preprocessing” and “information processing”. Then we propose a fuzzy dynamic route choice algorithm of wargame. Furthermore, the model is applied to a practical case of route choice of wargame, and the effectiveness and advantages of the model are illustrated through a comparative analysis. Finally, the model is further quantitated and analyzed in combination with the actual case, and the approximation of the model to human decision making psychology is illustrated from both a simulation and a mathematical justification perspective. These results demonstrate that the proposed model can not only handle a large amount of fuzzy and uncertain information, but also simulate the decision making psychology of wargame players. This research result is expected to provide a new effective method for automatic route choice in wargame simulations.},
  archive      = {J_IJMLC},
  author       = {Ma, Rufei and Liu, Shousheng and Xu, Zeshui and Zhang, Yan and Ni, Yan},
  doi          = {10.1007/s13042-023-02069-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2863-2880},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Research on fuzzy dynamic route choice model and algorithm of wargame},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ClKI: Closed-loop and knowledge iterative via
self-distillation for image sentiment analysis. <em>IJMLC</em>,
<em>15</em>(7), 2843–2862. (<a
href="https://doi.org/10.1007/s13042-023-02068-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image sentiment analysis has received a lot of attention due to the fact that users prefer to express their private emotions using images on social platforms. Researchers strive to obtain more discriminative features to characterize these images by designing diverse networks, such as convolutional neural networks (CNNs) and Transformer. This method requires prior knowledge in advance and its feature fusion ignores the correlation between heterogeneous networks. An efficient but effective integration of heterogeneous Transformer and CNN deserves further study. To this end, we propose a novel model called Closed-loop and Knowledge Iterative (ClKI) via self-distillation for image sentiment analysis. First, CNN features at different scales are extracted to capture the complementary multi-scale information, and then input into a Transformer stacked by multiple encoders with the ProbSparse self-attention to acquire more discriminative representations. Second, we adopt the true labels and deepest classification results jointly guide the training procedure of shallow modules via self-distillation. Thus, the ClKI model achieves an efficient interaction between the deep and shallow modules, providing sufficient knowledge for image sentiment analysis. Our model achieves 83.35%, 65.64%, and 91.01% accuracy on the FI, Emotion 6, and Twitter I datasets respectively, which outperforms state-of-the-art methods. Additional experiments further validate that ClKI can resolve the data imbalance problem to some degree and it has good generalization ability. Notably, ClKI is plug-and-play, promoting its practicality. Briefly, this study provides an innovative approach in image sentiment analysis, offering valuable insights for the integration of heterogeneous networks as well as knowledge iterative method.},
  archive      = {J_IJMLC},
  author       = {Zhang, Hongbin and Yuan, Meng and Hu, Lang and Wang, Wengang and Li, Zhijie and Ye, Yiyuan and Ren, Yafeng and Ji, Donghong},
  doi          = {10.1007/s13042-023-02068-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2843-2862},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ClKI: Closed-loop and knowledge iterative via self-distillation for image sentiment analysis},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSSTN: A multi-scale spatio-temporal network for traffic
flow prediction. <em>IJMLC</em>, <em>15</em>(7), 2827–2841. (<a
href="https://doi.org/10.1007/s13042-023-02067-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatio-temporal feature extraction and fusion are crucial to traffic prediction accuracy. However, the complicated spatio-temporal correlations and dependencies between traffic nodes make the problem quite challenging. In this paper, a multi-scale spatio-temporal network (MSSTN) is proposed to exploit complicated local and nonlocal correlations in traffic flow for traffic prediction. In the proposed method, a convolutional neural network, a self-attention module, and a graph convolution network (GCN) are integrated to extract and fuse multi-scale temporal and spatial features to make predictions. Specifically, a self-adaption temporal convolutional neural network (SATCN) is first employed to extract local temporal correlations between adjacent time slices. Furthermore, a self-attention module is applied to capture the long-range nonlocal traffic dependence in the temporal dimension and fuse it with the local features. Then, a graph convolutional network module is utilized to learn spatio-temporal features of the traffic flow to exploit the mutual dependencies between traffic nodes. Experimental results on public traffic datasets demonstrate the superiority of our method over compared state-of-the-art methods. The ablation experiments confirm the effectiveness of each component of the proposed model. Our implementation on Pytorch is publicly available at https://github.com/csust-sonie/MSSTN .},
  archive      = {J_IJMLC},
  author       = {Song, Yun and Bai, Xinke and Fan, Wendong and Deng, Zelin and Jiang, Cong},
  doi          = {10.1007/s13042-023-02067-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2827-2841},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MSSTN: A multi-scale spatio-temporal network for traffic flow prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dialogue emotion model based on local–global context encoder
and commonsense knowledge fusion attention. <em>IJMLC</em>,
<em>15</em>(7), 2811–2825. (<a
href="https://doi.org/10.1007/s13042-023-02066-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion Recognition in Conversation (ERC) is a task aimed at predicting the emotions conveyed by an utterance in a dialogue. It is common in ERC research to integrate intra-utterance, local contextual, and global contextual information to obtain the utterance vectors. However, there exist complex semantic dependencies among these factors, and failing to model these dependencies accurately can adversely affect the effectiveness of emotion recognition. Moreover, to enhance the semantic dependencies within the context, researchers commonly introduce external commonsense knowledge after modeling it. However, injecting commonsense knowledge into the model simply without considering its potential impact can introduce unexpected noise. To address these issues, we propose a dialogue emotion model based on local–global context encoder and commonsense knowledge fusion attention. The local–global context encoder effectively integrates the information of intra-utterance, local context, and global context to capture the semantic dependencies among them. To provide more accurate external commonsense information, we present a fusion module to filter the commonsense information through multi-head attention. Our proposed method has achieved competitive results on four datasets and exhibits advantages compared with mainstream models using commonsense knowledge.},
  archive      = {J_IJMLC},
  author       = {Yu, Weilun and Li, Chengming and Hu, Xiping and Zhu, Wenhua and Cambria, Erik and Jiang, Dazhi},
  doi          = {10.1007/s13042-023-02066-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2811-2825},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dialogue emotion model based on local–global context encoder and commonsense knowledge fusion attention},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fuzzy rough set-based undersampling approach for
imbalanced data. <em>IJMLC</em>, <em>15</em>(7), 2799–2810. (<a
href="https://doi.org/10.1007/s13042-023-02064-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively handle imbalanced data is one of the hot issues in the fields of machine learning and data mining. Undersampling is a popular technique of dealing with imbalanced data. The aim of undersampling is to select an instance subset from the majority class of an imbalanced dataset and then make the dataset balanced. However, the traditional undersampling approaches may lead to the information loss of majority class instances. Therefore, on the basis of the concept of the importance degree of a fuzzy granule, a measure criterion of selecting representative instances from the majority class is presented in this paper by considering the fuzzy relations between the k-nearest neighbors of a majority class instance and the minority class instances. Then, we put forward an undersampling approach based on fuzzy rough sets (USFRS). With the proposed USFRS, the representativeness of the selected majority class instances can be guaranteed and the information loss due to undersampling can be reduced to the utmost extent. Furthermore, USFRS is compared with the relative undersampling methods, and the difference of the experimental results is analyzed by the statistic test. The experimental results demonstrate that USFRS performs well in classification for imbalanced data.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xiao and He, Zhaoqian and Yang, Yanyan},
  doi          = {10.1007/s13042-023-02064-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2799-2810},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A fuzzy rough set-based undersampling approach for imbalanced data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Expected lenient q-learning: A fast variant of the lenient
q-learning algorithm for cooperative stochastic markov games.
<em>IJMLC</em>, <em>15</em>(7), 2781–2797. (<a
href="https://doi.org/10.1007/s13042-023-02063-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lenient Multiagent Reinforcement Learning 2 (LMRL2) is an Independent Learners Algorithm for cooperative multiagent systems that is known to outperform other Independent Learners Algorithms in terms of convergence. However, the algorithm takes longer to converge. In this paper, we first present a new formulation of LMRL2, and then, based on this new formulation, we introduce Expected Lenient Q-learning Algorithm ( $${\mathbb {E}}$$ LQL). The new formulation demonstrates that LMRL2 performs the same update of Q-values as in standard Q-learning, but with a stochastic learning rate that follows a specified probability distribution. Based on this new formulation, $${\mathbb {E}}$$ LQL addresses the low speed and instabilities in LMRL2 by updating Q-values using a deterministic and evolving learning rate that equals the expected value of LMRL2 learning rate. We compared $${\mathbb {E}}$$ LQL with Decentralized Q-learning, Distributed Q-learning with and without coordination mechanism, Hysteretic Q-learning, and LMRL2. Our experiments on various test problems demonstrated that $${\mathbb {E}}$$ LQL is highly effective and surpasses all other algorithms in terms of convergence, especially in stochastic domains. Moreover, $${\mathbb {E}}$$ LQL outperforms LMRL2 in terms of convergence speed, which is why we regard $${\mathbb {E}}$$ LQL as a faster variant of LMRL2.},
  archive      = {J_IJMLC},
  author       = {Amhraoui, Elmehdi and Masrour, Tawfik},
  doi          = {10.1007/s13042-023-02063-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2781-2797},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Expected lenient Q-learning: A fast variant of the lenient Q-learning algorithm for cooperative stochastic markov games},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Time series clustering of dynamical systems via
deterministic learning. <em>IJMLC</em>, <em>15</em>(7), 2761–2779. (<a
href="https://doi.org/10.1007/s13042-023-02062-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent deterministic learning theory has achieved locally-accurate identification of unknown system dynamics. This article presents a novel application of deterministic learning theory to unsupervised learning for the first time. Specifically, a new time series clustering strategy with a dynamics-based similarity measure is proposed. Firstly, the dynamics knowledge learned from the time series is represented and stored in the form of constant weights through deterministic learning theory. Secondly, dynamical estimators constructed with the learned dynamics knowledge are used to generate recognition errors, forming a similarity measure matrix to characterize the dynamics-based similarity between time series. Finally, the clustering of time series data with different dynamical behaviors is achieved based on the K-medoids prototype according to the dynamics-based similarity measure matrix. To verify the effectiveness of the proposed method, a dynamical pattern dataset based on benchmark dynamical systems (e.g., Lorenz, Chen, and Lü systems) is also constructed. The experimental results on a synthetic dataset and two real datasets demonstrate that the proposed method is superior to other well-known clustering algorithms in the clustering task for dynamical systems.},
  archive      = {J_IJMLC},
  author       = {Sun, Chen and Wu, Weiming and Zhang, Zirui and Li, Zhirui and Ji, Bing and Wang, Cong},
  doi          = {10.1007/s13042-023-02062-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2761-2779},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Time series clustering of dynamical systems via deterministic learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Centrosymmetric constrained convolutional neural networks.
<em>IJMLC</em>, <em>15</em>(7), 2749–2760. (<a
href="https://doi.org/10.1007/s13042-023-02061-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex signals can be viewed as compositions of numerous sine waves with different frequencies and amplitudes. As the fundamental unit of perceiving image features, traditional Convolutional Neural Networks (CNNs) typically employ convolutional kernels without direct constraints. However, human perception of the world is inherently structured, relevant studies have indicated that considering the potential underlying correlation structures among data features or variables holds significant value, with particular emphasis on symmetric transformations in representation learning gaining attention in the field of neuroscience. Inspired by the process of human visual concept perception and classic image feature detection operators, when the convolution kernels have a similar scale to the objects, they produce larger responses. This paper introduces constraints on model parameters using centrosymmetric convolutional kernels. Under the influence of nonlinear combinations and local connections in neural networks, these kernels can diversely represent or perceive local image features. Experimental comparisons are conducted, and it is observed that the approach proposed in this paper not only enhances the convergence and accuracy of model, but also reduces the model solution space, resulting in an interpretable perception of local concepts. Furthermore, comparative experiments with classic deep CNNs have demonstrated comparable performance.},
  archive      = {J_IJMLC},
  author       = {Zheng, Keyin and Qian, Yuhua and Yuan, Zhian and Peng, Furong},
  doi          = {10.1007/s13042-023-02061-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2749-2760},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Centrosymmetric constrained convolutional neural networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy information gain ratio-based multi-label feature
selection with label correlation. <em>IJMLC</em>, <em>15</em>(7),
2737–2747. (<a
href="https://doi.org/10.1007/s13042-023-02060-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection aims to mitigate the curse of dimensionality in multi-label data by selecting a smaller subset of features from the original set for classification. Existing multi-label feature selection algorithms frequently neglect the inherent uncertainty in multi-label data and fail to adequately consider the relationships between features and labels when assessing the importance of features. In response to this challenge, a Fuzzy Information Gain Ratio-based multi-label feature selection considering Label Correlation (FIGR_LC) algorithm is proposed. FIGR_LC evaluates feature importance by combining the relationship between features and individual labels, as well as the correlation between features and label sets. Subsequently, a feature ranking is established based on these feature weights. Experimental results substantiate the effectiveness of FIGR_LC, showcasing its superiority over several established feature selection methods.},
  archive      = {J_IJMLC},
  author       = {Yu, Ying and Lv, Meiyue and Qian, Jin and Lv, Jingqin and Miao, Duoqian},
  doi          = {10.1007/s13042-023-02060-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2737-2747},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fuzzy information gain ratio-based multi-label feature selection with label correlation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning to detect extreme objects for remote sensing
images. <em>IJMLC</em>, <em>15</em>(7), 2719–2736. (<a
href="https://doi.org/10.1007/s13042-023-02059-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scale and shape of objects in remote sensing images varies greatly, and thus the object detection of remote sensing image has always been a relatively challenging task. Focusing on the problem of multi-scale and extreme aspect ratio object detection, this paper proposes the extreme object detection net (EODNet). Firstly, we design a fractal-based feature fusion network (FFFN) by stacking different multilayer elementary convolutional blocks based on the self-similarity feature of fractals, so that the fused feature maps can fully retain the original features to facilitate the extraction of objects of different sizes. The parallel and serial asymmetric convolution block is fitted objects by forming receptive fields that approximate the shape of the object for feature maps used to detect large-sized objects. Following this, the width-height sensitive loss function is designed, which adapts to multi-scale objects and is sensitive to shape. Finally, the Extreme-soft- non maximum suppression (NMS) realizes the removal of extreme overlapping boxes and avoids the accidental deletion of dense object prediction boxes. The proposed method is tested on the NWPU VHR-10 and RSOD datasets, and the results are compared with mainstream object detection algorithms, verifying the effectiveness of the proposed method, as the mAP on the two datasets is 96.1% and 95.4%, respectively.},
  archive      = {J_IJMLC},
  author       = {He, Qiang and Li, Meng and Huo, Lianzhi and Chen, Linlin},
  doi          = {10.1007/s13042-023-02059-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2719-2736},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning to detect extreme objects for remote sensing images},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multidta: Drug-target binding affinity prediction via
representation learning and graph convolutional neural networks.
<em>IJMLC</em>, <em>15</em>(7), 2709–2718. (<a
href="https://doi.org/10.1007/s13042-023-02058-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of Drug-Target Interactions (DTI) plays a pivotal role in drug repositioning research. While recent years have witnessed the proliferation of neural network-based methods for Drug-Target Affinity (DTA) prediction, existing models predominantly rely on either sequence-based or graph-based approaches to model drug-target pairs. This limitation obstructs models from harnessing more valuable information from various data sources for downstream predictions. To overcome this constraint, this paper introduces an innovative end-to-end learning framework for DTA prediction, named MultiDTA. Firstly, we construct four channels tailored to comprehensively mine representations embedded within drug-target pair sequences and model them through graph structures to learn spatial structural information. Secondly, after capturing latent high-level representations from different data structures across these four channels, we employ an attention mechanism to discern each channel’s contributions to downstream tasks. Experimental results demonstrate that our proposed model surpasses sequence-based and graph-based methods, affirming our model’s capacity to simultaneously capture high-level representations from multiple data structures. Furthermore, we enhance the model’s interpretability by visualizing the contributions of these four channels using the attention mechanism. The code of MultiDTA and the relevant data are available at: https://github.com/dengjiejin/MultiDTA .},
  archive      = {J_IJMLC},
  author       = {Deng, Jiejin and Zhang, Yijia and Pan, Yaohua and Li, Xiaobo and Lu, Mingyu},
  doi          = {10.1007/s13042-023-02058-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2709-2718},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multidta: Drug-target binding affinity prediction via representation learning and graph convolutional neural networks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale pyramidal hash learning for traditional building
facade image retrieval. <em>IJMLC</em>, <em>15</em>(7), 2695–2707. (<a
href="https://doi.org/10.1007/s13042-023-02057-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving images captured of buildings is a critical need for intelligent urban management and tourism services. The different shooting angles, locations and distances lead to images under the same building object with cross-scale attributes, resulting in the existing retrieval methods being susceptible to interference from inter-class attributes, leading to low retrieval accuracy. In this work, we propose a deep multi-scale spatial pyramidal hash-learning framework (DMPH). The framework integrates the multi-scale representation and local perception capabilities of CNNs with the global perception capabilities of transformers. This framework will provide a multi-scale spatially preserved hash code for images. Further, we explore pyramid space matching to achieve cross-scale building retrieval without object annotation. Our framework is evaluated on two publicly available architectural retrieval datasets and achieves better performance than the comparison methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Chongyan and Wang, Yupeng and Deng, Daojie and Cao, Jiahe and Zhao, Wanqing},
  doi          = {10.1007/s13042-023-02057-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2695-2707},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-scale pyramidal hash learning for traditional building facade image retrieval},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Smart parking systems technologies, tools, and challenges
for implementing in a smart city environment: A survey based on IoT
&amp; ML perspective. <em>IJMLC</em>, <em>15</em>(7), 2673–2694. (<a
href="https://doi.org/10.1007/s13042-023-02056-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart Parking systems are inevitable considering the growing population, particularly in the urban areas. Most of the people prefer to use private transportation for their convenience which results in an increased number of vehicles and hence increased traffic. Also cruising for parking is one of the most chaotic tasks leading to traffic congestion and increased consumption of time, fuel, and energy. This paper analyzes the smart parking solutions from a technical perspective related to Internet of Things and Machine Learning which are the two popular advancing areas. A detailed survey on the current state of art developments in smart parking systems incorporating the above-mentioned areas is included. In addition, the paper explores the role of smart parking in a smart city environment and the benefits of espousing parking 4.0. Furthermore, the current challenges in SPS, the possible solutions and future scopes in its implementation are also presented.},
  archive      = {J_IJMLC},
  author       = {Raj, Aparna and Shetty, Sujala D.},
  doi          = {10.1007/s13042-023-02056-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2673-2694},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Smart parking systems technologies, tools, and challenges for implementing in a smart city environment: A survey based on IoT &amp; ML perspective},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-branch feature fusion dehazing network via
multispectral channel attention. <em>IJMLC</em>, <em>15</em>(7),
2655–2671. (<a
href="https://doi.org/10.1007/s13042-023-02055-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image information degradation significantly complicates single-image dehazing. Despite the noteworthy progress of learning-based methods in removing haze, many existing algorithms focus solely on haze removal while neglecting the crucial aspect of image texture recovery, often resulting in the loss of image details and texture blurring. To tackle this issue, we propose a dual-branch feature fusion dehazing network via multi-spectral channel attention (MS-DBFFN). First, we design a multi-spectral image pre-processing module (MS-PPM), maximizing the utilization of correlation features in hazy images by introducing additional frequency components. This process results in preliminary dehazing images. Second, a dual-branch feature fusion module (DBFF) adaptively fuses features from both the hazy image and preliminary dehazing image via an iterative update strategy. During this gradual iterative updating process, the structural features of the preliminary dehazing image become richer as more feature information is assimilated. Third, our backbone network facilitates the sharing of valuable information across multiple scales from the feature map generated by the DBFF module. Finally, an improved contrastive regularization loss (ICR) generates sharper images with enhanced details and textures. Extensive experiments on both real and synthetic datasets demonstrate that the proposed method, MS-DBFFN, achieves state-of-the-art performance on several image dehazing benchmarks.},
  archive      = {J_IJMLC},
  author       = {Jian, Huachun and Zhang, Yongjun and Gao, Weihao and Wang, Bufan and Wang, Guomei},
  doi          = {10.1007/s13042-023-02055-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2655-2671},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual-branch feature fusion dehazing network via multispectral channel attention},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CrackUnet: A novel network with joint network-in-network
structure and deformable convolution for pavement crack detection.
<em>IJMLC</em>, <em>15</em>(7), 2643–2654. (<a
href="https://doi.org/10.1007/s13042-023-02054-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic pavement crack detection is a critical technique in the intelligent transportation system, which can effectively replace the person with a machine to detect the pavement crack automatically. This task is excellently challenging due to the tiny texture and the various shapes of each crack object. Previous crack detection networks mainly aim to perform complicated multi-scale feature fusion to learn the semantic information of cracks. However, the typical symmetrical networks with high-to-low resolution are undesirable to extract detailed crack texture information, and these existing methods cannot effectively deal with the issue of the various shapes.This paper proposes a novel end-to-end U-shaped convolutional neural network, termed CrackUNet, for the pavement crack detection task. To extract the information of the tiny texture, we design a novel network-in-network structure, which can enlarge the receptive field and obtain multi-scale features by putting a sub-network into each convolutional layer. Besides, to handle the issue of the various shapes for the crack object, we exploit the deformable convolution to capture contextual information of each crack, which can further improve the performance of crack detection. We train and evaluate the proposed CrackUNet on three public pavement crack datasets. The quantitative experimental results illustrate that our network outperforms the current state-of-the-art methods with almost the same efficiency. Specifically, the precision, recall, and F1-score of the CrackUNet are approximately 92.27%, 93.99%, and 92.94%, respectively.},
  archive      = {J_IJMLC},
  author       = {Qi, Lei and Li, Chenhao and Mei, Tao},
  doi          = {10.1007/s13042-023-02054-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2643-2654},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CrackUnet: A novel network with joint network-in-network structure and deformable convolution for pavement crack detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid depression detection model and correlation analysis
for social media based on attention mechanism. <em>IJMLC</em>,
<em>15</em>(7), 2631–2642. (<a
href="https://doi.org/10.1007/s13042-023-02053-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a serious mental illness, depression can be extremely harmful to the physical and mental health of individuals. However, detecting depression can be challenging due to the reluctance of the depressed to actively express themselves. Fortunately, in modern society, online social platforms provide an opportunity for genuine self-expression in our daily lives. Leveraging the power of social data, we can identify potentially depressed users efficiently and accurately. This lays a strong foundation for subsequent interventions. In this paper, we propose a hybrid model that comprehensively considers the features and post texts of users by utilizing a simplified multi-head attention mechanism for detecting user depression. Compared to traditional models, such as Decision Tree and Random Forest, the simplified multi-head attention mechanism achieves higher classification accuracy while offering enhanced interpretability at the individual level. To verify the validity of our model, we apply it to the Weibo User Depression Detection Dataset (WU3D) containing approximately 1,150,000 posts from around 21,000 users. The dataset has been classified by human experts as either depressed or not. The results show that our model both explains the association of each feature of a single user well and achieves better performance than traditional methods. Notably, the final F1-score of our new model on the test set is 0.9473. Furthermore, by visualizing attention scores, we conduct a correlation analysis between different features and results for individual users, which can facilitate further analysis of the behavior and psychological characteristics of specific depressed users by professionals.},
  archive      = {J_IJMLC},
  author       = {Liu, Jiacheng and Chen, Wanzhen and Wang, Liangxu and Ding, Fangyikuang},
  doi          = {10.1007/s13042-023-02053-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2631-2642},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid depression detection model and correlation analysis for social media based on attention mechanism},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convolutional neural networks with attention module and
compression strategy based on second-order information. <em>IJMLC</em>,
<em>15</em>(7), 2619–2629. (<a
href="https://doi.org/10.1007/s13042-023-02051-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In convolutional neural networks, the second-order representation can effectively enhance the nonlinear modeling capability of first-order models, while the scale of parameters also increases significantly, resulting in overfitting and low efficiency. In this paper, a lightweight attention module with second-order information as well as a compression strategy of information matrix are developed to improve the classification ability of typical models without affecting or even improving the convergence speed. Specifically, the main contributions are (1) a novel module based on second-order channel attention is proposed, which utilizes multilayer one-dimensional convolution for feature representation, and directly learns the long-distance correlation between feature channels by adding a small number of parameters; (2) a Cholesky-DLT compression strategy is established for the second-order information matrix, which significantly reduces the parameter scale of the fully connected layer. These two modules can be easily integrated into end-to-end network structures and then applied to typical network models. The experimental results show that the combination of the proposed modules with the most common used first-order and second-order models can effectively improve the generalization performance without increasing the involved parameters.},
  archive      = {J_IJMLC},
  author       = {Hua, Qiang and Li, Yan and Zhang, Jing and Qian, Guanyu},
  doi          = {10.1007/s13042-023-02051-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2619-2629},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Convolutional neural networks with attention module and compression strategy based on second-order information},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Remote assessment of parkinson’s disease symptom severity
based on group interaction feature assistance. <em>IJMLC</em>,
<em>15</em>(7), 2595–2618. (<a
href="https://doi.org/10.1007/s13042-023-02050-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Telemonitoring is an effective way to assess the severity of Parkinson&#39;s disease (PD). Due to heterogeneity and small sample sizes, the multi-task learning is applied to build the specific model for PD patients and prevent overfitting. However, the existing multi-task learning methods don&#39;t consider the nonlinear interaction between patients. Therefore, to improve the performance of the patient-specific prediction model, this paper proposes a group interaction feature assistance method (GIFA) for remote assessment of PD symptom severity. First, GIFA employs the nonlinear bidirectional long short-term memory network to explore the correlation among patient groups. Next, the incremental association Markov boundary is adopted to select causal features from group interaction features obtained by the bidirectional long short-term memory network to reduce negative transfer. Finally, the causal interaction features learned by the incremental association Markov boundary are input into the patient-specific prediction model to assist disease assessment, which is conducive to increasing the complementary information and improving the prediction performance. Experiment results on the public Parkinson&#39;s telemonitoring and mPower voice datasets show that GIFA model outperforms the cited state-of-the-art comparison methods for predicting Parkinson&#39;s disease symptom severity.},
  archive      = {J_IJMLC},
  author       = {Xue, Zaifa and Lu, Huibin and Zhang, Tao and Guo, Xiaonan and Gao, Le},
  doi          = {10.1007/s13042-023-02050-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2595-2618},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Remote assessment of parkinson’s disease symptom severity based on group interaction feature assistance},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Outlier based intrusion detection in databases for user
behaviour analysis using weighted sequential pattern mining.
<em>IJMLC</em>, <em>15</em>(7), 2573–2593. (<a
href="https://doi.org/10.1007/s13042-023-02049-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of traffic over wide networks, particularly the internet, and the cloud-based transactions and interactions, database security is important for any organisation. The detection of, and protection from, unauthorised external attacks and insiders abusing privileges is an integral part of database security. To that end, we propose Outlier based Intrusion Detection in Databases for User Behaviour Analysis using Weighted Sequential Pattern Mining (BWSPM), a novel method for the detection of malicious transactions through a sequential flow from outlier detection followed by different behavioural checks at the role-based rule mining component, and finally a user level behavioural check. In the worst case, a transaction has to go through a triple-fold security validation directing the model from generalisation to specification. The Outlier Detection module generates clusters based on the syntactic characteristics of transactions and detects transactions that do not adhere to their closest cluster. Role-level analysis is based upon mining rules that capture dynamic usage of attributes local to every role domain, and the transactions are verified against these rules. Finally, User behaviour profiling models user behaviour based on past transactions, and the incoming transaction is flagged if it diverges from that. Security checks are made at every level to prevent further transaction analysis to reduce false positive rate and achieve a higher degree of optimisation. Encouraging results, with levels of accuracy of around 86.4%, were obtained through our approach after conducting experiments on a dataset generated using the TPC-C (Transaction Processing Performance Council) benchmark.},
  archive      = {J_IJMLC},
  author       = {Singh, Indu and Jindal, Rajni},
  doi          = {10.1007/s13042-023-02049-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2573-2593},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Outlier based intrusion detection in databases for user behaviour analysis using weighted sequential pattern mining},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An intra-class distribution-focused generative adversarial
network approach for imbalanced tabular data learning. <em>IJMLC</em>,
<em>15</em>(7), 2551–2572. (<a
href="https://doi.org/10.1007/s13042-023-02048-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance is a critical factor that adversely affects the performance of machine learning algorithms. It leads to deviations in decision boundaries, resulting in biased predictions towards the majority class and inaccurate classification of the minority class. Although oversampling the minority class using deep generative models is a popular strategy, many existing methods focus solely on enhancing data for the minority class while overlooking the distribution relationship within and between classes. Therefore, we propose an oversampling method that merges unsupervised clustering and generative adversarial network (GAN) to facilitate the imbalanced tabular data learning. First, we perform preprocessing (clustering) on the original data, remove clusters that do not require sampling and generate more samples for sparsely distributed minority class clusters to achieve sample balance within the minority class. Moreover, we design a CTGAN-based auxiliary classifier GAN (ACCTGAN) to generate the minority class. It enhances the semantic integrity of the synthetic data and avoids generating noisy samples. We conducted validation experiments comparing our approach to 7 typical methods on 12 real tabular datasets. Our method shows excellent performance in F1-measure and area under the curve (AUC), obtaining 19 and 20 best results on the three classifiers, respectively. It significantly enhances classification results and demonstrates good robustness and stability.},
  archive      = {J_IJMLC},
  author       = {Chen, Qiuling and Ye, Ayong and Zhang, Yuexin and Chen, Jianwei and Huang, Chuan},
  doi          = {10.1007/s13042-023-02048-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {7},
  number       = {7},
  pages        = {2551-2572},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An intra-class distribution-focused generative adversarial network approach for imbalanced tabular data learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Microbial data augmentation combining feature extraction and
transformer network. <em>IJMLC</em>, <em>15</em>(6), 2539–2550. (<a
href="https://doi.org/10.1007/s13042-023-02047-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microbial data exhibit high dimensionality, feature sparseness, and class imbalance. Popular data augmentation strategies typically generate intersecting or overlapping samples with low diversity. In this paper, we propose a two-stage data augmentation method to synthesize high-quality samples. First, we train a feature extractor by minimizing the cross-entropy. Positive training instances are oversampled to achieve class balance. Second, a transformer network is trained for data augmentation to balance diversity and discernibility. A dropout technique is designed to randomly set some feature values as missing. Experiments were carried out on 10 microbial datasets. The results show that: (1) the constructed feature extraction neural network can effectively reduce the dimension of the data, make the data no longer sparse, improve the distinguishability of the samples, and obtain more obvious classification boundaries, and (2) The trained data augmentation transformer network with dropout technique can generate high quality samples, improve the performance of the classifier and reduce the cost of misclassification.},
  archive      = {J_IJMLC},
  author       = {Wen, Liu-Ying and Chen, Zhu and Xie, Xiao-Nan and Min, Fan},
  doi          = {10.1007/s13042-023-02047-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2539-2550},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Microbial data augmentation combining feature extraction and transformer network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Debiased graph contrastive learning based on positive and
unlabeled learning. <em>IJMLC</em>, <em>15</em>(6), 2527–2538. (<a
href="https://doi.org/10.1007/s13042-023-02046-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) is one of the mainstream techniques for unsupervised graph representation learning, which reduces the distance between positive pairs and increases the distance between negative pairs in the embedding space to obtain discriminative representation. However, most existing GCL methods mainly focus on graph augmentation for positive samples, while the effect of negative samples is less explored, and they regard all samples except anchors as negative samples, which may push away latent positive samples that belong to the same class as the anchor, thus introducing false negative samples. To this end, this paper proposes a novel framework called Debiased Graph Contrastive Learning Based on Positive and Unlabeled Learning (DGCL-PU). Firstly, in this framework, we cluster the nodes by using the K-means algorithm and then treat the samples that are the same as the anchor as positive samples and the others as unlabelled samples. In this way, PU learning can be applied to assign scores for samples to determine the propensity of becoming negative samples relative to the anchor point. Secondly, we integrate the similarity between samples and the negative propensity score of samples, thereby obtaining reasonable weights for negative samples. Finally, the weighted graph contrastive loss is designed to obtain more discriminative feature representations and alleviate the bias of false negative samples. Moreover, DGCL-PU is a general framework, and it can be embedded into most existing GCL methods to improve their performance. Experiments on multiple benchmark datasets demonstrate that our method achieves state-of-the-art performance on multiple downstream tasks, including graph node classification, node clustering, and link prediction.},
  archive      = {J_IJMLC},
  author       = {Li, Zhiqiang and Wang, Jie and Liang, Jiye},
  doi          = {10.1007/s13042-023-02046-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2527-2538},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Debiased graph contrastive learning based on positive and unlabeled learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cascaded embedding method with graph neural network for
multi-behavior recommendation. <em>IJMLC</em>, <em>15</em>(6),
2513–2526. (<a
href="https://doi.org/10.1007/s13042-023-02045-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommender systems, implicit feedback data is relatively cheap and easy to obtain compared to explicit feedback data, making it widely used in modeling. However, some works consider only single type of user behavior, while in reality, user feedback types are complex and diverse, with great semantic uncertainty. Graph neural networks (GNN) have gradually become a new paradigm in the recommendation field due to their excellent information extraction capabilities and good scalability. The common recommendation models based on GNN have high time complexity and ignore the contribution of different behaviors to user preferences. To address these challenges, we propose a Cascading Embedding method for Multi-Behavior Recommendation to explore high-order multi-relation interaction signals between users and items. Specifically, we associate different user behaviors in a specific order and design a relation-aware gating unit to extract user behavior patterns, learn node (user and item) and relation representations. To investigate the differential effects of different types of behavior on different users, a relation-level attention mechanism is proposed to automatically capture the importance of each behavior to user preferences. Finally, we perform the non-sampling optimization strategy based on the multi-task learning framework to fully utilize auxiliary behaviors in better predicting target behaviors. Experimental results on real datasets demonstrate that the proposed model outperforms current mainstream recommendation methods. Further analysis and verification show that multi-behavior modeling can provide more effective recommendations for users with sparse target behaviors. Our implementation code is available in https://github.com/jsp666/CEMBR .},
  archive      = {J_IJMLC},
  author       = {Jiang, Shaopeng and Zhao, Chao},
  doi          = {10.1007/s13042-023-02045-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2513-2526},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A cascaded embedding method with graph neural network for multi-behavior recommendation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-label learning with incomplete labels via dual
manifold mappings. <em>IJMLC</em>, <em>15</em>(6), 2495–2511. (<a
href="https://doi.org/10.1007/s13042-023-02044-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, effective exploitation of the label correlations can improve classification performance. However, due to the subjectivity of manual labeling and the similarity of label semantics in real applications, it is common that only the incomplete label space is observed, which usually leads to inaccurate estimation of the label correlations and thus results in performance degradation. In This paper, a new multi-label learning algorithm based on dual manifold mappings (DMM) is proposed to deal with missing labels. In DMM, the original feature space and label space are mapped to a low-dimensional manifold, forming the dual manifold mappings. During the mappings, the label correlations are learned and utilized to enhance the consistency between the manifold and label distribution by augmenting the incomplete label matrix, and guide the learning of the regression coefficients by introducing the Laplacian regularizer of the learned label correlations. The experimental results demonstrate that the proposed method has a competitive and effective performance compared with other state-of-the-art methods for multi-label learning with incomplete labels.},
  archive      = {J_IJMLC},
  author       = {Huang, Rui and Xu, Zhilei},
  doi          = {10.1007/s13042-023-02044-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2495-2511},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-label learning with incomplete labels via dual manifold mappings},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional contrastive learning for unpaired global mosaic
removal with a few samples. <em>IJMLC</em>, <em>15</em>(6), 2481–2493.
(<a href="https://doi.org/10.1007/s13042-023-02043-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advances in adversarial learning and self-supervised learning, global mosaic removal no longer requires paired samples to achieve superior results. However, most existing methods require a large number of samples to capture the distribution of mosaic characteristics, which severely limits their scope of application. To solve this problem, this paper proposes a conditional contrastive learning model for unpaired global mosaic removal with a few samples. Firstly, a conditional contrastive learning loss function is proposed to eliminate inappropriate negative samples in current contrastive learning methods and improve unpaired global mosaic removal results. Then, in addition to conditional contrastive learning loss, a global contrastive loss function is proposed to obtain global features from all layers, and a local contrastive loss function is proposed to obtain correct block-level feature representations. Finally, they work together to obtain the best unpaired global mosaic removal results with a few samples. Experiments on three datasets show that the proposed model has achieved leading results in both quantitative and qualitative analysis of three state-of-the-art models for global mosaic removal.},
  archive      = {J_IJMLC},
  author       = {Cao, Zhiyi and Xie, Bin and Huo, Lina and Shao, Mingwen},
  doi          = {10.1007/s13042-023-02043-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2481-2493},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Conditional contrastive learning for unpaired global mosaic removal with a few samples},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prefilters and fuzzy prefilters on pseudo EQ-algebras.
<em>IJMLC</em>, <em>15</em>(6), 2457–2479. (<a
href="https://doi.org/10.1007/s13042-023-02042-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we mainly study prefilters and fuzzy prefilters on pseudo EQ-algebras, and give a series of properties of them. To begin with, we give some new results about prefilters on pseudo EQ-algebras and present that the set PF( $${\mathcal {E}}$$ ) of all prefilters on a good pseudo $$\ell$$ EQ-algebra forms a Heyting algebra. In the following, we introduce three types of prefilters on pseudo EQ-algebras, which are implicative prefilters, positive implicative prefilters and fantastic prefilters, investigate their related properties, and discuss the relationships among them. We give some conditions under which positive implicative prefilters and implicative prefilters can be mutually induced and some conditions under which each implicative prefilter coincides with a fantastic prefilter. Moreover, we give the fuzzy versions of prefilters and these three special prefilters, investigate their related properties, and discuss the algebraic structures of the set of all fuzzy prefilters. It is proved that the set FPF( $${\mathcal {E}}$$ ) of all fuzzy prefilters on a residuated pseudo EQ-algebra forms a residuated lattice, and also a Heyting algebra. In the last, we investigate their relationships among fuzzy implicative prefilters, fuzzy positive implicative prefilters and fuzzy fantastic prefilters. We give some conditions under which fuzzy implicative prefilters are equivalent to fuzzy positive implicative prefilters, and some conditions under which a fuzzy implicative prefilter is coincident with a fuzzy fantastic prefilter.},
  archive      = {J_IJMLC},
  author       = {Shi, Jieqiong and Zhao, Bin},
  doi          = {10.1007/s13042-023-02042-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2457-2479},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Prefilters and fuzzy prefilters on pseudo EQ-algebras},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Affinity-based elastic net intuitionistic fuzzy twin support
vector machines. <em>IJMLC</em>, <em>15</em>(6), 2439–2455. (<a
href="https://doi.org/10.1007/s13042-023-02041-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy twin support vector machines (IFTWSVM) combined the concept of intuitionistic fuzzy sets with twin support vector machines (TWSVM) and showed excellent performance in classification. However, the existing intuitionistic fuzzy number schemes based on the single center and the local neighborhood of the sample are difficult to accurately reflect the location information of the sample, and the L1-norm penalty of the slack variable is not well defined from the point of view of geometric points. In view of the above deficiencies, we design a noval intuitionistic fuzzy number scheme and adopt elastic net to penalize the slack variables, propose Affinity-Based Elastic Net Intuitionistic Fuzzy Twin Support Vector Machines (AENIFTWSVM). It calculates the affinity of different classes of samples according to the Support Vector Data Description (SVDD) model in the kernel space, and considers the contribution of samples to the two classes, and the obtained affinity can be used to identify noise information. A series of experimental outcomes on benchmark datasets and handwritten digit dataset support that the proposed model outperforms some existing models.},
  archive      = {J_IJMLC},
  author       = {Li, Zhishen and Zhang, Peiai},
  doi          = {10.1007/s13042-023-02041-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2439-2455},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Affinity-based elastic net intuitionistic fuzzy twin support vector machines},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring and exploiting hierarchical structures for
large-scale classification. <em>IJMLC</em>, <em>15</em>(6), 2427–2437.
(<a href="https://doi.org/10.1007/s13042-023-02039-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification and recognition tasks confronted by intelligent systems are becoming complicated as the sizes of samples, dimensionality and labels dramatically increase in the past few years. Learning machines have to deal with modeling tasks with millions of samples and ten of thousand of labels in high-dimensional feature spaces. These tasks pose great challenges for traditional learning paradigms. Inspired by the progress in cognitive and neural science, we propose an end-to-end deep hierarchical classification framework and integrate the processes of representation learning, hierarchical structure construction, and hierarchical classification modeling in this work. This integrative framework brings several advantages: (1) the learned features are good for hierarchical structure construction and classification; (2) the learned hierarchical structure is beneficial for the subsequent hierarchical classification; (3) the learned hierarchical classification model supervises and guides the representation learning and hierarchical structure construction. This new hierarchical paradigm can not only well deal with large-scale classification tasks but also provide new inspirations to other research fields of artificial intelligence.},
  archive      = {J_IJMLC},
  author       = {Zheng, Junyan and Wang, Yu and Pei, Shenglei and Hu, Qinghua},
  doi          = {10.1007/s13042-023-02039-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2427-2437},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Exploring and exploiting hierarchical structures for large-scale classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating curriculum learning with meta-learning for
general rhetoric identification. <em>IJMLC</em>, <em>15</em>(6),
2411–2425. (<a
href="https://doi.org/10.1007/s13042-023-02038-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rhetoric is abundant and universal across different human languages. In this paper, we propose a novel curriculum learning integrated with meta-learning (CLML) model to address the task of general rhetorical identification. Specifically, we first leverage inter-category similarities to construct a dataset with curriculum characteristics for facilitating more natural easy-to-difficult learning process. Then we imitate human cognitive thinking that uses the query set in meta-learning to guide inductive network for inducing accurate class-level representations which are further improved by leveraging external class label knowledge into TapNet to construct a mapping function. Extensive experimental results demonstrate that our proposed model outperforms existing state-of-the-art models across four datasets consistently.},
  archive      = {J_IJMLC},
  author       = {Wang, Dian and Li, Yang and Wang, Suge and Li, Xiaoli and Chen, Xin and Li, Shuqi and Liao, Jian and Li, Deyu},
  doi          = {10.1007/s13042-023-02038-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2411-2425},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Integrating curriculum learning with meta-learning for general rhetoric identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). “What” and “where” both matter: Dual cross-modal graph
convolutional networks for multimodal named entity recognition.
<em>IJMLC</em>, <em>15</em>(6), 2399–2409. (<a
href="https://doi.org/10.1007/s13042-023-02037-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal named entity recognition (MNER) aims to use visual information to assist in extracting and classifying entities in the textual content. However, it is currently facing the following challenges: (1) How to effectively use image information with different granularities and various types; (2) How to model the interaction between texts and images more properly, so that the information within and between modals can be fully considered. To solve the above problems, we propose a dual cross-modal graph convolutional networks (DCM-GCN) in this paper. Specifically, to model image information from different views, we construct a dual channel model by simulating vision processing mechanism in human brains, and use image information in two different types (‘what’ and ‘where’). In addition, we propose a cross-modal graph convolutional network structure, to complete the high-order aggregation intra- and inter-modals. We have conducted extensive experiments on two benchmark multimodal datasets to show the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Zhang, Zhengxuan and Chen, Jianying and Liu, Xuejie and Mai, Weixing and Cai, Qianhua},
  doi          = {10.1007/s13042-023-02037-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2399-2409},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {‘What’ and ‘Where’ both matter: Dual cross-modal graph convolutional networks for multimodal named entity recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PEN-DS: Progressive enhancement network based on detail
supplementation for low-light image enhancement. <em>IJMLC</em>,
<em>15</em>(6), 2383–2398. (<a
href="https://doi.org/10.1007/s13042-023-02036-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured in low-light environments suffer from severe degradation, which can be unfavorable for human observation and subsequent computer vision tasks. Although many enhancement methods based on deep learning have been proposed, the obtained enhancement images still suffer from drawbacks such as color distortion, noise, and blur. To solve these problems, we propose a progressive enhancement network based on detail supplementation (PEN-DS), which is implemented by building two modules: an image preprocessing module (IPM) and a progressive image enhancement module (PIEM). The IPM can obtain low-light images and low-detail maps at different scales by building an image pyramid structure. PIEM can enhance images at different scales progressively based on detail supplementation and luminance enhancement. In addition, to better train the network, the proposed method employs a multi-supervised joint loss function for the enhanced images of different scales. Experimental results show that the proposed method outperforms state-of-the-art approaches in terms of visual observation and objective evaluation.},
  archive      = {J_IJMLC},
  author       = {Yang, Yong and Xu, Wenzhi and Huang, Shuying and Wan, Weiguo},
  doi          = {10.1007/s13042-023-02036-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2383-2398},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PEN-DS: Progressive enhancement network based on detail supplementation for low-light image enhancement},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep adversarial reconstruction classification network for
unsupervised domain adaptation. <em>IJMLC</em>, <em>15</em>(6),
2367–2382. (<a
href="https://doi.org/10.1007/s13042-023-02035-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the existing adversarial domain adaptation methods have been successfully applied in the unsupervised domain adaptation community, their performances may perhaps be weakened due to a significant distributional diversity of the target domain caused by the absence of the local features of samples in the target domain after the domain adaptation process. In this paper, based on the well-known autoencoder, a single-input with multi-output model called deep adversarial reconstruction classification network (DARCN) is developed to circumvent the above issue. The proposed DARCN mainly consists of the following four modules: a feature extractor for extracting the domain-invariant features along with the local features of the target domain, a predictor for estimating the label, a domain discriminator for distinguishing between the source and target domains, and a decoder for reconstructing the original data. The standard backpropagation method can be effectively used to optimize the proposed model. The experimental results indicate that DARCN realizes the improved classification performances in most cases in contrast to some existing comparative methods.},
  archive      = {J_IJMLC},
  author       = {Lin, Jiawei and Bian, Zekang and Wang, Shitong},
  doi          = {10.1007/s13042-023-02035-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2367-2382},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep adversarial reconstruction classification network for unsupervised domain adaptation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BCT-OFD: Bridging CNN and transformer via online feature
distillation for COVID-19 image recognition. <em>IJMLC</em>,
<em>15</em>(6), 2347–2366. (<a
href="https://doi.org/10.1007/s13042-023-02034-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided systems can assist radiologists in improving the efficiency of COVID-19 diagnosis. Current work adopts complex structures and the correlations between convolutional neural network (CNN) and Transformer haven’t been explored. We propose a novel model named bridging CNN and Transformer via online feature distillation (BCT-OFD). First, lightweight Mpvit-tiny and MobileNetV3-small are chosen as the teacher and student networks, respectively. Sufficient pathological knowledge is smoothly transferred from the teacher to the student using OFD. Then, a adaptive feature fusion module is designed to efficiently fuse the heterogeneous CNN and Transformer features. The implicit correlations between the two networks are fully mined to generate more discriminative fused features. And coordinate attention is adopted to make further feature refinement. The accuracy on three public avaliable datasets reach 97.76%, 98.12% and 96.96%, respectively. It validates that BCT-OFD outperforms state-of-the-art baselines in terms of effectiveness and generalization ability. Notably, BCT-OFD is relatively more lightweight and easier to deploy on those resource-constrained devices, making it the bridge that links theory to application as well as narrowing the gap between them. This study provides an innovative approach in the field of COVID-19 image recognition, offering valuable insights for further improvements in performance.},
  archive      = {J_IJMLC},
  author       = {Zhang, Hongbin and Hu, Lang and Liang, Weinan and Li, Zhijie and Yuan, Meng and Ye, Yiyuan and Wang, Zelin and Ren, Yafeng and Li, Xiong},
  doi          = {10.1007/s13042-023-02034-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2347-2366},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {BCT-OFD: Bridging CNN and transformer via online feature distillation for COVID-19 image recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Epistemic uncertainty based linear programming problem and
its solution. <em>IJMLC</em>, <em>15</em>(6), 2337–2346. (<a
href="https://doi.org/10.1007/s13042-023-02033-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epistemic uncertainty such as fuzzy based linear programming problem with equality constraints has been considered here. Fuzziness presents in system parameters are modelled using Trapezoidal Fuzzy Number (TrFN). In the considered problem the coefficients are defined as crisp while the decision variables as well as the right-hand side of the constraints are taken as fuzzy. Accordingly, a new method to solve the problem based on the fuzzy centre and radius has been proposed here. First the problem is solved for fuzzy centre and next the bounds of the fuzzy variable are replaced in terms of fuzzy centre and radius. Then using the obtained fuzzy centre solution there one can have the radius of the solution. Finally using the results for centre and radius one can get the final solution. For the implementation of this proposed methodology LINGO 18.0 software has been used. Consequently, optimal fuzzy feasible solution has been obtained to get the optimal value (maximum/minimum) of the fuzzy objective function. Moreover, various numerical examples have been solved using the proposed method and the obtained solutions are compared with the solution of existing methods for validation. Moreover, it has been observed that present methods overcome the limitations of Maleki (Maleki in Far East J Math Sci 4:283–301, 2002), Nasseri (Nasseri in Appl Math Sci 2:2473–2480, 2008), Mahdavi-Amiri and Nasseri (Mahdavi-Amiri and Nasseri in Fuzzy Sets Syst 158:1961–1978, 2007) and Saati et al. (Saati et al. in Int J Inf Decis Sci 7:312–333, 2015), and clearly the advantages of the proposed method are discussed in conclusion section.},
  archive      = {J_IJMLC},
  author       = {Behera, Diptiranjan and Thomas, Romane},
  doi          = {10.1007/s13042-023-02033-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2337-2346},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Epistemic uncertainty based linear programming problem and its solution},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DSSE-net: Dual stream skip edge-enhanced network with
forgery loss for image forgery localization. <em>IJMLC</em>,
<em>15</em>(6), 2323–2335. (<a
href="https://doi.org/10.1007/s13042-023-02031-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep learning has continuously made breakthroughs in computer vision, Image Forgery Localization (IFL) task has also started using deep learning frameworks. Currently, most deep learning-based IFL methods use binary cross entropy as the loss function during model training. However, the number of tampered pixels in image forgery is significantly smaller than the number of real pixels. This disparity makes it easier for the model to classify samples as real pixels during training, leading to a reduced F1 score. Therefore, in this paper, we have proposed a loss function for the IFL task: Forgery Loss. The Forgery Loss assigns weight to the classification loss of tampered pixels and edges, enhances tampered pixel constraints in the model, and amplifies the importance of difficult-to-classify samples. These enhancements facilitate the model to acquire more productive information. Consequently, the F1 score of the model is enhanced. Additionally, we designed an end-to-end, pixel-level detection network DSSE-Net. It comprises of a dual-stream codec network that extracts high-level and low-level features of images, and an edge attention stream. The edge attention stream have a Edge Attention Model which enhances the network’s attention to the high frequency edges of the image and, in conjunction with the edge enhancement algorithm in Forgery Loss, improves the model’s ability to detect tampered edges. Experiments demonstrate that Forgery Loss can effectively improve the F1 score, while the DSSE-Net accuracy outperforms the current SOTA algorithm.},
  archive      = {J_IJMLC},
  author       = {Zheng, Aokun and Huang, Tianqiang and Huang, Wei and Huang, Liqing and Ye, Feng and Luo, Haifeng},
  doi          = {10.1007/s13042-023-02031-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2323-2335},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DSSE-net: Dual stream skip edge-enhanced network with forgery loss for image forgery localization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Single image super-resolution via global aware external
attention and multi-scale residual channel attention network.
<em>IJMLC</em>, <em>15</em>(6), 2309–2321. (<a
href="https://doi.org/10.1007/s13042-023-02030-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep convolutional neural networks (CNNs) have shown significant advantages in improving the performance of single image super-resolution (SISR). To build an efficient network, multi-scale convolution is commonly incorporated into CNN-based SISR methods via scale features with different perceptive fields. However, the feature correlations of the same sample are not fully utilized by the existing multi-scale SISR approaches, impeding the further improvement of reconstruction performance. In addition, the correlations between different samples are still left unexplored. To address these problems, this paper proposes a deep-connected multi-scale residual attention network (DMRAN) by virtue of the feature correlations of the same sample and the correlations between different samples. Specifically, we propose a deep-connected multi-scale residual attention block (DMRAB) to take fully advantage of the multi-scale and hierarchical features, which can effectively learn the local interdependencies between channels by adjusting the channel features adaptively. Meanwhile, a global aware external attention (GAEA) is introduced to boost the performance of SISR by learning the correlations between all the samples. Furthermore, we develop a deep feature extraction structure (DFES), which seamlessly combines the stacked deep-connected multi-scale residual attention groups (DMRAG) with GAEA to learn deep feature representations incrementally. Extensive experimental results on the public benchmark datasets show the superiority of our DMRAN to the state-of-the-art SISR methods.},
  archive      = {J_IJMLC},
  author       = {Liu, Mingming and Li, Sui and Liu, Bing and Yang, Yuxin and Liu, Peng and Zhang, Chen},
  doi          = {10.1007/s13042-023-02030-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2309-2321},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Single image super-resolution via global aware external attention and multi-scale residual channel attention network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on boundary-aware waters segmentation network for
unmanned surface vehicles in complex inland waters. <em>IJMLC</em>,
<em>15</em>(6), 2297–2308. (<a
href="https://doi.org/10.1007/s13042-023-02029-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A speedy and reliable system detecting safe waters is essential to enable autonomous navigation of unmanned surface vessels (USVs). However, existing detection methods are prone to misidentifying trees and buildings on river banks as water and blurring water boundaries due to reflections from the water surface. This study proposes a dual-task network architecture for boundary-aware and waters segmentation(BAWS network) to address the above issues. The BAWS network consists of an encoder module, a decoder module and a boundary-aware module. The attention refinement module (ARM) focuses on water information to improve water detection. A feature fusion module (FFM) is introduced better to integrate visual features with boundary features in the decoder. In addition, boundary-aware modules and boundary loss functions are proposed to force the network to focus on detailed information about the boundary of the waters. To validate the effectiveness of the algorithm, this study was tested using three different types of typical inland river datasets. The results show that the method achieves a maximum of 97.19% mean intersection ratio (MIoU) and 0.776 root mean square error (RMSE) of the boundary on the USVInland dataset. This indicates that the method can produce clearer predictions at the watershed boundary and improve the performance of watershed segmentation with good generalisation performance.},
  archive      = {J_IJMLC},
  author       = {Ding, Yunshuai and Xu, Yongjian and Liu, Qiqin and Sun, Hongwei and Chen, Fengnong},
  doi          = {10.1007/s13042-023-02029-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2297-2308},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Research on boundary-aware waters segmentation network for unmanned surface vehicles in complex inland waters},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simpler large margin distribution machine via weighted
linear loss for large-scale classification. <em>IJMLC</em>,
<em>15</em>(6), 2283–2296. (<a
href="https://doi.org/10.1007/s13042-023-02028-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large margin distribution machine (LDM) with margin distribution optimization guarantees the good generalization performance of the model. However, the existing LDM model uses a hinge loss, which suffers from low computational efficiency. To solve this problem, we propose a simpler weighted linear loss LDM model (SWLLDM). Our SWLLDM is based on weighted linear loss and LDM, but it is not a simple combination. On the one hand, our SWLLDM has the margin distribution optimization, which leads to better generalization performance. In SWLLDM, the margin variance terms are reduced and the margin mean is eliminated. On the other hand, our SWLLDM has better computational efficiency. In SWLLDM, the inequality constraint is removed. All samples are used to optimize the QPP with equality constraints. Finally, we perform a series of numerical experiments on UCI benchmark datasets, NDC datasets and steel surface defect dataset. The final results illustrate the feasibility and effectiveness of the SWLLDM algorithm.},
  archive      = {J_IJMLC},
  author       = {Chu, Maoxiang and Liu, Liming and Liu, Ling and Gong, Rongfen},
  doi          = {10.1007/s13042-023-02028-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2283-2296},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Simpler large margin distribution machine via weighted linear loss for large-scale classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Clustering-based gradual pattern mining. <em>IJMLC</em>,
<em>15</em>(6), 2263–2281. (<a
href="https://doi.org/10.1007/s13042-023-02027-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, the classical problem of gradual pattern mining involves generating pattern candidates and determining the number of concordant object pairs associated with them. Given a numeric data set with n objects and m features, each feature yields two gradual items. Gradual pattern candidates can be formed by combining different sets of gradual items. In fact, a gradual pattern is composed of gradual items with similar concordant object pairs. However, computing the object pairs for each item has a complexity that is approximately quadratic in terms of the number of objects. As the main contribution of this paper, we propose finding gradual patterns by clustering gradual items based on their similarity in object pairs. First, we project the object pairs of each gradual item onto an n-dimensional subspace, thus reducing the complexity of computing object pairs from a quadratic function to a linear function. Second, we group gradual items into r clusters based on the similarity of object pairs in the n-dimensional subspace. As part of our experiments, we evaluated our approach using a variety of clustering algorithms. We found that the best clustering algorithms (across all the data sets we used) achieved precision scores above 55%, recall scores close to 100%, and F1 scores above 71%.},
  archive      = {J_IJMLC},
  author       = {Owuor, Dickson Odhiambo and Runkler, Thomas and Laurent, Anne and Bonyo, Lesley},
  doi          = {10.1007/s13042-023-02027-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2263-2281},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clustering-based gradual pattern mining},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lightweight fungal spore detection based on improved YOLOv5
in natural scenes. <em>IJMLC</em>, <em>15</em>(6), 2247–2261. (<a
href="https://doi.org/10.1007/s13042-023-02026-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant disease diagnosis plays a crucial role in precision agriculture, and detecting fungal spores in complex scenes is essential for disease diagnosis. The spores of downy mildew obtained in the natural scene carry a lot of impurities such as dust, and bacteria, and the small size of downy mildew spores themselves also pose challenges for accurate detection. At the same time, it is necessary to improve the real-time detection of a large number of images of downy mildew spores collected by the microscope. This study addresses the challenges of low accuracy and complex detection algorithms in fungal spore detection under complex backgrounds. We propose a high-precision and lightweight detection method based on YOLOv5. Our approach incorporates the Ghost module and its optimization module GhostC3 to reduce model complexity and improve detection efficiency. Additionally, the Normalization-based Attention module (NAM) is embedded in the backbone network to enhance the model&#39;s ability to extract fungal spore features at different depths, mitigating the negative impact of complex backgrounds. Meanwhile, we introduce the Receptive Field Block with dilated convolution (RFB-s) to improve the detection accuracy of tiny target spores by increasing the receptive field and extracting detailed information on fungal spore location. Experimental evaluations using spores of downy mildew fungi collected in natural scenes demonstrate that our proposed method achieves an Average Precision (AP) of 0.956, with a model size of 2.8 M. Compared to the baseline model, our approach reduces parameters by 34.9% while improving AP by 1.4%. Notably, our model outperforms mainstream detection algorithms such as YOLOv3, SSD, YOLOv4, YOLOv5, and YOLOv7 regarding AP. This method offers significant technical support for automating the detection of downy mildew spores and early prediction of downy mildew outbreaks in complex field environments.},
  archive      = {J_IJMLC},
  author       = {Li, Kaiyu and Qiao, Chen and Zhu, Xinyi and Song, Yuzhaobi and Zhang, Lingxian and Gao, Wei and Wang, Yong},
  doi          = {10.1007/s13042-023-02026-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2247-2261},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight fungal spore detection based on improved YOLOv5 in natural scenes},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prototype equilibrium network with group emotional contagion
for few-shot emotion recognition in conversation. <em>IJMLC</em>,
<em>15</em>(6), 2229–2246. (<a
href="https://doi.org/10.1007/s13042-023-02025-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot emotion recognition in conversation (FSERC) aims to classify the emotion of utterances in conversations with only a few labeled conversations. However, there is limited research on FSERC at present, and the few existing approaches for this task suffer from an imbalance of the utterance number of various classes. In addition, they ignore the impact of group emotional contagion and the representation of intra- and inter-conversation class prototypes. In this paper, we address these issues by proposing the prototype equilibrium network with group emotional contagion (ProEq-GEC). Firstly, we construct adaptive cross-sampling to form support set and query set samples in the way of adaptive classification and grouping sampling. Secondly, we introduce group emotional contagion and build a weighted directed acyclic graph neural network to capture the conversation context information more comprehensively by distinguishing the emotional impact of others and the speaker himself on the current utterance. Thirdly, we propose the prototype equilibrium network to enhance the representation of class prototypes by calculating intra- and inter-conversation class prototypes. Finally, experimental results show that our model is highly effective for the FSERC and significantly outperforms the existing models.},
  archive      = {J_IJMLC},
  author       = {Jiang, Min and Wang, Mengdi and Kong, Jun},
  doi          = {10.1007/s13042-023-02025-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2229-2246},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Prototype equilibrium network with group emotional contagion for few-shot emotion recognition in conversation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-adaptive interval dominance-based feature selection for
monotonic classification of interval-valued attributes. <em>IJMLC</em>,
<em>15</em>(6), 2209–2228. (<a
href="https://doi.org/10.1007/s13042-023-02024-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dominance rough set theory is a key mathematical tool for addressing monotonic classification tasks (MCTs). However, current dominance rough set models for feature selection are highly sensitive to noise. Furthermore, in practical applications, conditional feature attributes are often expressed as interval values. The endpoints of these intervals are susceptible to noise pollution, resulting in incomplete knowledge and interference with feature selection. To address these issues, this paper proposes a feature selection approach named SIDDM-FDNRS with three distinctive characteristics: (i) An interval-valued fuzzy dominance neighborhood rough set (IV-FDNRS) model is established to reduce noise interference by introducing adaptive neighborhood parameters. (ii) Definition of a novel self-adaptive interval dominance discernibility matrix (SIDDM) based on the IV-FDNRS model, used for selecting the optimal monotonic features. (iii) Comprehensive consideration of interval dominance relationships, the strength of global dominance relationships, and noise interference factors in the proposed feature selection model. Extensive experiments demonstrate that the proposed feature selection algorithm leads to superior classification performance.},
  archive      = {J_IJMLC},
  author       = {Chen, Jiankai and Li, Zhongyan and Su, Han and Zhai, Junhai},
  doi          = {10.1007/s13042-023-02024-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2209-2228},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-adaptive interval dominance-based feature selection for monotonic classification of interval-valued attributes},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local or global? A novel transformer for chinese named
entity recognition based on multi-view and sliding attention.
<em>IJMLC</em>, <em>15</em>(6), 2199–2208. (<a
href="https://doi.org/10.1007/s13042-023-02023-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer is widely used in natural language processing (NLP) tasks due to the parallel and modeling of long texts. However, its performance in Chinese named entity recognition (NER) is not effective. While distance, direction, and information on global and local perspectives of sequence are all important for NER tasks, the traditional transformer structure only focus on distance and partial global information by fully connected self-attention mechanism. In this paper, we propose a multi-view and sliding attention (MVSA) model to enhance transformer’s ability to model Chinese character-word features in NER task. MVSA combines directional information to extract character-word features from multiple views, proposes a weighted ternary fusion method for feature fusion and uses slider attention mechanisms to enhance the local representation ability of the model. Experiments on five Chinese NER datasets show that MVSA achieves superior performance than CNN-based, LSTM-based and traditional transformer-based models.},
  archive      = {J_IJMLC},
  author       = {Wang, Yuke and Lu, Ling and Yang, Wu and Chen, Yinong},
  doi          = {10.1007/s13042-023-02023-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2199-2208},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Local or global? a novel transformer for chinese named entity recognition based on multi-view and sliding attention},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scalable memory-enhanced swarm intelligence optimization
method: Fractional-order bat-inspired algorithm. <em>IJMLC</em>,
<em>15</em>(6), 2179–2197. (<a
href="https://doi.org/10.1007/s13042-023-02022-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bat-inspired algorithm (BA), as one of the swarm intelligence algorithms, has a high potential for solving global optimization problems. This algorithm possesses an additional inherent capability compared to other swarm intelligence algorithms, which is the inclusion of a local search mechanism. Although this increases the convergence speed of the algorithm, excessive focus on exploitation, especially in the initial iterations, may lead to premature convergence and stagnation at the local optimum. In this paper, to address this drawback and strengthen the exploration capability while also achieving a balance between it and the exploitation capability, an improved version of BA, called fractional-order BA (FOBA), is introduced. The development of velocity and position vectors in FOBA, using the concept of fractional-order derivatives, extends the memory related to the previous behaviors of artificial bats and controls the convergence of the algorithm. To evaluate the proposed algorithm, ten well-known benchmark functions are used, and the results are compared with standard and state-of-the-art metaheuristic algorithms that have been introduced recently. Experimental results show that FOBA performs better than all compared algorithms. Furthermore, the proposed algorithm is used to optimize the weights and bias of the MLP neural network using six classification datasets. The results demonstrate the effectiveness and efficiency of FOBA.},
  archive      = {J_IJMLC},
  author       = {Esfandiari, Ahmad and Khaloozadeh, Hamid and Farivar, Faezeh},
  doi          = {10.1007/s13042-023-02022-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2179-2197},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A scalable memory-enhanced swarm intelligence optimization method: Fractional-order bat-inspired algorithm},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dissimilarity measure on intuitionistic fuzzy sets from an
optimistic viewpoint of the information and its diverse applications.
<em>IJMLC</em>, <em>15</em>(6), 2149–2177. (<a
href="https://doi.org/10.1007/s13042-023-02021-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dissimilarity measure on intuitionistic fuzzy sets (IFS) are often used in various problems of decision-making, pattern recognition and clustering problems. Numerous dissimilarity measures are constructed based on diverse mathematical concepts. However, not all dissimilarity measure might be suitable for a specific problem or definition. Hence, one should be specific about the nature of the decision to be drawn and choose an appropriate dissimilarity measure. This article aims to classify the dissimilarity measure as moderate, pessimistic and optimistic based on the information held by the IFS. The majority of the currently available dissimilarity measures take into account the moderate viewpoint of information in the IFS. There are a few dissimilarity measures that account for the pessimistic viewpoint of information in the IFSs. However, in some cases, the optimistic viewpoint of the information in the IFSs is also required. In addition, the cross-information factor is an important element of a dissimilarity measure. Consequently, a new dissimilarity measure is being developed that is optimistic and also takes the cross-information factor into account by calculating the change between the maximum and minimum cross-information factors. Furthermore, the dissimilarity measure is designed in such a way that it satisfies the dissimilarity properties under the complete containment relation. Moreover, a method for generating induced dissimilarity measures from a given dissimilarity measure using monotonic functions has been proposed. Numerical and comparative studies demonstrate the out-performance and superiority of the proposed dissimilarity measure, as well as highlights the unique characteristic of an optimistic nature. Finally, the proposed dissimilarity measure is being used to solve variety of application problems, including decision-making, pattern recognition, and clustering.},
  archive      = {J_IJMLC},
  author       = {Gohain, Brindaban and Gogoi, Surabhi and Chutia, Rituparna and Dutta, Palash},
  doi          = {10.1007/s13042-023-02021-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2149-2177},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dissimilarity measure on intuitionistic fuzzy sets from an optimistic viewpoint of the information and its diverse applications},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel overlapping community detection strategy based on
core-bridge seeds. <em>IJMLC</em>, <em>15</em>(6), 2131–2147. (<a
href="https://doi.org/10.1007/s13042-023-02020-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last decade has witnessed the advance of overlapping community detection based on local expansion. In this paper, we propose a novel local expanding-based overlapping community detection algorithm, denoted by Core and Bridge Seeds Extension, that aims to improve the quality of communities. Instead of the traditional approaches to select the cores of communities as seeds, a new Core-Bridge triplet strategy is suggested to select seeds to generate the initial backbone and framework of the community. In the optimization stage, a stepwise refinement approach is adopted to solve the issue of unreasonable division and unassigned node allocation. A merge index is designed to merge communities reasonably. The comparisons about the methods to improve accuracy of community numbers based on the known algorithms are also presented. Experimental results on synthetic networks and real networks show that our strategy outperforms the state-of-art algorithms in stability and effectiveness.},
  archive      = {J_IJMLC},
  author       = {Chen, Gaolin and Zhou, Shuming},
  doi          = {10.1007/s13042-023-02020-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2131-2147},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel overlapping community detection strategy based on core-bridge seeds},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid generative adversarial network based on a mixed
attention fusion module for multi-modal MR image synthesis algorithm.
<em>IJMLC</em>, <em>15</em>(6), 2111–2130. (<a
href="https://doi.org/10.1007/s13042-023-02019-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, medical image synthesis has attracted the attention of an increasing number of researchers. However, most of current approaches suffer from the loss of multi-modal complementary information and thus fail to preserve the property of each modality, resulting in image distortion and texture detail loss. To alleviate this issue, a multi-modal magnetic resonance (MR) image synthesis algorithm based on a mixed attention fusion module in hybrid generative adversarial network is proposed. Firstly, a novel mixed attention fusion (MAF) module aggregating an adaptive fusion strategy (AFS) and a soft attention module is proposed to fuse the high-level semantic information and the low-level fine-grained feature at different scales between different layers to exploit rich representative complementary information adaptively. Subsequently, Resnet-bottlenect attention mechanism (Res-BAM) is designed to perform adaptive optimization and exploit mutual information while preserving the original property of each modality. Thereafter, the attention weight is inferred by a 1D channel feature map and a 2D spatial feature map, and multiplied with the original feature map in order to get the adaptive feature map, which is integrated with the original feature map in a residual connection to preserve the original property of each modality and prevent network degradation. Finally, the structural similarity (SSIM) and $${\text{L}}_{1}$$ -norm are point-wise combined by an optimal weighting impact factor to preserve the high frequency information, brightness, color and SSIM, which are viewed as the original property of each modality. The experimental results demonstrate the superiority of our model on the state of the art in quantitative measures, reasonable visual quality and clinic significance.},
  archive      = {J_IJMLC},
  author       = {Li, Haiyan and Han, Yongqiang and Chang, Jun and Zhou, Liping},
  doi          = {10.1007/s13042-023-02019-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2111-2130},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hybrid generative adversarial network based on a mixed attention fusion module for multi-modal MR image synthesis algorithm},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-order attribute network representation learning via
constructing hierarchical graphs. <em>IJMLC</em>, <em>15</em>(6),
2095–2110. (<a
href="https://doi.org/10.1007/s13042-023-02018-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network representation learning (NRL) is widely used for such tasks as link prediction, node classification in network analysis. For NRL, it is a challenge in effectively fusing structural features and attribute information. To address the problem, this paper proposes a multi-order attribute network representation learning model via constructing hierarchical graphs (Multi-NRL). Firstly, the model constructs a series of hierarchical graphs on the original network through structure merging and attribute merging, which contain multi-order structural feature and attribute information from detailed to sketchy. Then, it performs hierarchical network representation on these graphs. Finally, it gains the final network representation through concatenating of the hierarchical network representation. Experimental results show Multi-NRL outperforms the best baseline by up-to 9.6% improvement in link prediction, and 13.9% in node classification with six real-world networks, which demonstrates the effectiveness of our model.},
  archive      = {J_IJMLC},
  author       = {Zhou, Mingqiang and Han, Qizhi and Liu, Dan and Wu, Quanwang},
  doi          = {10.1007/s13042-023-02018-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2095-2110},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-order attribute network representation learning via constructing hierarchical graphs},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sharp dense u-net: An enhanced dense u-net architecture for
nucleus segmentation. <em>IJMLC</em>, <em>15</em>(6), 2079–2094. (<a
href="https://doi.org/10.1007/s13042-023-02017-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning-based algorithms have shown that they are the best at segmenting, processing, detecting, and classifying medical images. U-Net is a famous Deep Learning (DL) approach for these applications. U-Net conducts four down-samplings before the concatenate process, resulting in low resolution. The dense U-Net design overcomes this problem, but the huge semantic gap between low-level and high-level down-sampling and up-sampling features remains a key concern. This work designed Sharp Dense U-Net, an improved U-Net architecture for nucleus segmentation, to solve these constraints. In the down-sampling path, dense and transition operations are used instead of max pooling and convolution to extract more informative information. In the up-sampling path, a new up-sampling layer, merging, and dense blocks reconstitute high-resolution images. Sharpening spatial filters take the place of skip connections to stop feature mismatches between the decoder and encoder paths. The proposed model is trained on the combined dataset and obtains dice coefficients, IoU, and accuracy of 0.6856, 0.5248, and 84.49, respectively. For nucleus segmentation from histopathology images, the Sharp Dense U-Net model is better than the U-Net, Dense U-Net, SCPP-Net, and LiverNet.},
  archive      = {J_IJMLC},
  author       = {Senapati, Pradip and Basu, Anusua and Deb, Mainak and Dhal, Krishna Gopal},
  doi          = {10.1007/s13042-023-02017-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2079-2094},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sharp dense U-net: An enhanced dense U-net architecture for nucleus segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformer embedded spectral-based graph network for facial
expression recognition. <em>IJMLC</em>, <em>15</em>(6), 2063–2077. (<a
href="https://doi.org/10.1007/s13042-023-02016-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph convolution networks which exploit relations among facial muscle movements for facial expression recognition (FER) have achieved great success. Due to the limited receptive field, existing graph convolution operations are difficult to model long-range muscle movement relations which plays a crucial role in FER. To alleviate this issue, we introduce the transformer encoder into graph convolution networks, in which the vision transformer enables all facial muscle movements to interact in the global receptive field and model more complex relations. Specifically, we construct facial graph data by cropping regions of interest (ROIs) which are associated with facial action units, and each ROI is represented by the representation of hidden layers from deep auto-encoder. To effectively extract features from the constructed facial graph data, we propose a novel transformer embedded spectral-based graph convolution network (TESGCN), in which the transformer encoder is exploited to interact with complex relations among facial RIOs for FER. Compared to vanilla graph convolution networks, we empirically show the superiority of the proposed model by conducting extensive experiments across four facial expression datasets. Moreover, our proposed TESGCN only has 80K parameters and 0.41MB model size, and achieves comparable results compared to existing lightweight networks.},
  archive      = {J_IJMLC},
  author       = {Jin, Xing and Song, Xulin and Wu, Xiyin and Yan, Wenzhu},
  doi          = {10.1007/s13042-023-02016-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {6},
  pages        = {2063-2077},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Transformer embedded spectral-based graph network for facial expression recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Skeleton-based 3D human pose estimation with low-resolution
infrared array sensor using attention based CNN-BiGRU. <em>IJMLC</em>,
<em>15</em>(5), 2049–2062. (<a
href="https://doi.org/10.1007/s13042-023-02015-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human sensing based on the low-resolution infrared sensor is widely used in hand gestures recognition, activity recognition, intrusion detection, etc. However, the information about humans acquired by the previous human sensing system using the infrared sensor is limited. In this paper, a human pose estimation system is proposed to realize the three-dimensional skeleton information acquisition by low-resolution infrared sensors. It is a difficult task to acquire human pose estimation with more rich human information from low-resolution infrared sensors. The system leverages the $$8 \times 8$$ pixels low-resolution infrared array sensor to collect the activity data and the Kinect v2 camera to capture the three-dimensional skeleton of the human body as annotations of the infrared data. The convolutional neural network-bidirectional gated recurrent unit model with attention mechanism (CNN-BiGRU-AM) model is employed for model training to effectively extract the characteristics of the infrared data from spatial and temporal dimensions. The attention mechanism (AM) can improve the ability of the model to capture important local information. The bone joint point data predicted by the model are utilized to draw the three-dimensional skeleton diagram. The k-means clustering algorithm is applied to eliminate the outliers that affect the overall visualization effect in the prediction. The accuracy and completeness of human pose estimation are measured by the euclidean distance between the real coordinates of the bone joint points obtained by Kinect v2 camera and the coordinates predicted by the model. The proportion of the number of predictions with euclidean distance less than a threshold 20 mm is 90.151%, representing the accuracy of human pose estimation. The experimental results show that three-dimensional skeleton information can be acquired accurately by the low-resolution infrared array sensor and the subtle difference within each activity can be observed through the 3D human pose to improve the effect of activity recognition.},
  archive      = {J_IJMLC},
  author       = {Chen, Jing and Chen, Deying and Jiang, Hao and Miao, Xiren and Yin, Cunyi},
  doi          = {10.1007/s13042-023-02015-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {2049-2062},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Skeleton-based 3D human pose estimation with low-resolution infrared array sensor using attention based CNN-BiGRU},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised learning-leveraged boosting ultrasound image
segmentation via mask reconstruction. <em>IJMLC</em>, <em>15</em>(5),
2039–2048. (<a
href="https://doi.org/10.1007/s13042-023-02014-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have improved universal machine learning tasks due to their excellent ability to learn rich semantic features from high-dimensional data. However, large manually labeled datasets are usually required for machine learning. These datasets are often expensive and impractical to obtain due to the time required by professionals to label the data and data protection issues. Self-supervised pretraining can be used to initialize the model, which can then be fine-tuned on a small amount of labeled data. In this study, we aimed to develop a self-supervised learning algorithm that could be used to segment ultrasound images automatically. To achieve this aim, we proposed an pretext task of mask reconstruction to extract relevant semantic features from unlabeled data. Additionally, we also present a novel segmentation network named SEAT-U-Net for further improve the segmentation ability of the model. This network utilizes the Transformer Encoder and U-Net Encoder to extract and fuse relevant features through channel attention mechanisms. The training and validation of the algorithm were performed on breast and thyroid datasets. Our algorithm achieved a higher segmentation accuracy with less labeled data for thyroid datasets. When we apply the model trained in the thyroid dataset to the breast dataset, it also achieves very good result, which validates the effectiveness and robustness of our SEAT-U-Net.},
  archive      = {J_IJMLC},
  author       = {Sang, Qingbing and Hou, Yajie and Qian, Pengjiang and Wu, Qin},
  doi          = {10.1007/s13042-023-02014-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {2039-2048},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-supervised learning-leveraged boosting ultrasound image segmentation via mask reconstruction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). SSGCN: A sampling sequential guided graph convolutional
network. <em>IJMLC</em>, <em>15</em>(5), 2023–2038. (<a
href="https://doi.org/10.1007/s13042-023-02013-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks(GCNs) have become one of the important technologies for solving graph structured data problems. GCNs utilize convolutional networks to learn node and spatial features in the graph, and fully fuse them for node classification tasks. Consequently, for most GCNs, “graph convolution” operation over the set of nodes is the key. Nevertheless, such an operation is frequently embedded into a fixed graph without considering the dynamic variation of the set of nodes. Immediately, the incremental learning mechanism can be considered. From this viewpoint, a Sampling Sequential Guided Graph Convolutional Network (SSGCN) is developed. Firstly, through random sampling over the set of nodes, multiple minibatch graphs can be obtained. Secondly, by the proposed sequential guidance, the weight matrices can be updated incrementally by using “graph convolution” over minibatch graphs one by one. That is, the trained weight matrix of the previous minibatch graph is saved, which in turn is used as an input for training the next minibatch graph. Finally, the prediction results from all minibatch graph learners are integrated. We conducted experiments based on the standard variance of different $$\tau$$ number of losses, and over three common citation network datasets (Cora, Citeseer and Pubmed) to evaluate the performance of SSGCN in node classification tasks. The experimental results show that, in comparison study and ablation study,in terms of both efficiency and effectiveness, the performance of SSGCN is superior to most state-of-the-art methods. In addition, SSGCN shows good convergence in visualization.},
  archive      = {J_IJMLC},
  author       = {Wang, Xiaoxiao and Yang, Xibei and Wang, Pingxin and Yu, Hualong and Xu, Taihua},
  doi          = {10.1007/s13042-023-02013-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {2023-2038},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SSGCN: A sampling sequential guided graph convolutional network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hessian unsupervised extreme learning machine.
<em>IJMLC</em>, <em>15</em>(5), 2013–2022. (<a
href="https://doi.org/10.1007/s13042-023-02012-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machines (ELMs) are shown to be efficient and effective learning algorithms for regression and classification tasks. ELMs, however, are typically utilized to solve supervised learning problems. Only a handful of research on ELMs focuses on exploring unlabeled data. One representative work is the unsupervised extreme learning machine (US-ELM), where the standard ELM is expanded for unsupervised learning based on Laplacian regularization. However, Laplacian regularization has poor extrapolation power since it tends to bias the solution towards a constant function. In this paper, we propose a new framework termed Hessian unsupervised ELM (HUS-ELM) to enhance the unsupervised learning of ELM. In particular, Hessian regularization can properly exploit the intrinsic local geometry of the data manifold compared to Laplacian regularization. This leverages the performance of HUS-ELM in unsupervised learning problems since the Hessian regularization can correctly reflect the positional relationship between the unlabeled samples. Six publicly available datasets are used to evaluate the proposed algorithm. The experimental results indicate that the proposed method performs better than other unsupervised learning methods in terms of clustering accuracy.},
  archive      = {J_IJMLC},
  author       = {Dass, Sharana Dharshikgan Suresh and Krishnasamy, Ganesh and Paramesran, Raveendran and C.-W. Phan, Raphaël},
  doi          = {10.1007/s13042-023-02012-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {2013-2022},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hessian unsupervised extreme learning machine},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-perspective global–local interaction framework for
identifying dialogue acts and sentiments of dialogue utterances jointly.
<em>IJMLC</em>, <em>15</em>(5), 1995–2011. (<a
href="https://doi.org/10.1007/s13042-023-02010-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue act recognition (DAR) and sentiment classification (SC) are crucial tasks in dialogue systems, aiming to uncover speakers’ implicit intentions and sentiment by analyzing contextual information. Recent approaches have sought to improve accuracy by jointly modeling dialogue acts and sentiments, considering complex relationships and latent structures. However, these methods often neglect two critical challenges. Firstly, real-world dialogues follow a chronological order, with interlocutors discussing one or more topics. Secondly, the joint task of dialogue act recognition and sentiment classification operates at a sentence level, making it essential to effectively utilize fine-grained word-level information from utterances. To tackle these challenges, we propose a multi-perspective global–local interaction framework. It captures overall contextual information and simulates the flow of dialogue acts and sentiments for each speaker. We delve into explicit intra-task interactions, cross-task collaborations, and token-level information reuse from three perspectives. We also incorporate a time span to accommodate real-world scenarios with chronological and multi-topic dialogues. Experimental results on widely-used benchmark datasets demonstrate the superiority of our framework over mainstream approaches. Comprehensive analysis validates the effectiveness of each component, showcasing the potential for enhancing DAR and SC tasks.},
  archive      = {J_IJMLC},
  author       = {Zhang, Qichen and Li, Jingmei},
  doi          = {10.1007/s13042-023-02010-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1995-2011},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-perspective global–local interaction framework for identifying dialogue acts and sentiments of dialogue utterances jointly},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using AI to decode the behavioral responses of an insect to
chemical stimuli: Towards machine-animal computational technologies.
<em>IJMLC</em>, <em>15</em>(5), 1985–1994. (<a
href="https://doi.org/10.1007/s13042-023-02009-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthoptera are insects with excellent olfactory sense abilities due to their antennae richly equipped with receptors. This makes them interesting model organisms to be used as biosensors for environmental and agricultural monitoring. Herein, we investigated if the house cricket Acheta domesticus can be used to detect different chemical cues by examining the movements of their antennae and attempting to identify specific antennal displays associated to different chemical cues exposed (e.g., sucrose or ammonia powder). A neural network based on state-of-the-art techniques (i.e., SLEAP) for pose estimation was built to identify the proximal and distal ends of the antennae. The network was optimised via grid search, resulting in a mean Average Precision (mAP) of 83.74%. To classify the stimulus type, another network was employed to take in a series of keypoint sequences, and output the stimulus classification. To find the best one-dimensional convolutional and recurrent neural networks, a genetic algorithm-based optimisation method was used. These networks were validated with iterated K-fold validation, obtaining an average accuracy of 45.33% for the former and 44% for the latter. Notably, we published and introduced the first dataset on cricket recordings that relate this animal’s behaviour to chemical stimuli. Overall, this study proposes a novel and simple automated method that can be extended to other animals for the creation of Biohybrid Intelligent Sensing Systems (e.g., automated video-analysis of an organism’s behaviour) to be exploited in various ecological scenarios.},
  archive      = {J_IJMLC},
  author       = {Fazzari, Edoardo and Carrara, Fabio and Falchi, Fabrizio and Stefanini, Cesare and Romano, Donato},
  doi          = {10.1007/s13042-023-02009-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1985-1994},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Using AI to decode the behavioral responses of an insect to chemical stimuli: Towards machine-animal computational technologies},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stock price prediction through GRA-WD-BiLSTM model with air
quality and weather factors. <em>IJMLC</em>, <em>15</em>(5), 1967–1984.
(<a href="https://doi.org/10.1007/s13042-023-02008-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting stock prices is crucial for reducing investment-related risks in decision-making. Contemporary challenges to financial behavior, posed by environmental issues such as pollution and climate change, have received limited attention in existing studies on capital market predictability. This paper focuses on the Shanghai Stock Exchange Composite Index (SSEC) and employs air quality and weather data from the Shanghai area as input variables. Subsequently, a hybrid prediction model is constructed by integrating Grey Relational Analysis (GRA), Wavelet Decomposition (WD), and Bidirectional Long Short-Term Memory (BiLSTM) neural networks. The objective is to achieve precise predictions of closing prices. Additionally, this study validates the feasibility of incorporating environmental factors as input variables for stock price prediction, using the Shenzhen Component Index (SZI) and Hang Seng Index (HSI) as case studies, while also assessing the applicability of the GRA-WD-BiLSTM model. The findings demonstrate that the GRA-WD-BiLSTM model exhibits superior applicability and prediction performance in stock price forecasting, with respective prediction accuracies of 95.93%, 93.02%, and 97.07% when accounting for environmental factors. The incorporation of GRA and WD contributes to enhancing single models’ performance while integrating air quality and weather factors, which prove valuable in accurately predicting stock prices. The findings also indicate that the impact of regional environmental factors on local stock exchange index prices shows variability.},
  archive      = {J_IJMLC},
  author       = {Liu, Bingchun and Pei, Jiayi and Yu, Zhecheng},
  doi          = {10.1007/s13042-023-02008-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1967-1984},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stock price prediction through GRA-WD-BiLSTM model with air quality and weather factors},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PDCNN-MRW: A parallel winograd convolutional neural network
algorithm base on MapReduce. <em>IJMLC</em>, <em>15</em>(5), 1949–1966.
(<a href="https://doi.org/10.1007/s13042-023-02007-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel deep convolutional neural network (DCNN) algorithms have been widely used in the field of big data, but there are still some problems: excessive computation of redundant features, insufficient performance of convolution operation, and poor merging ability of parameter parallelization. Based on the above problems, a parallel DCNN algorithm based on MapReduce and Winograd convolution (PDCNN-MRW) is proposed in this paper, which contains three parts. First, a feature selection method based on cosine similarity and normalized mutual information (FS-CSNMI) is proposed, which reduces redundant feature computation between channels and avoids excessive redundant feature computation. Next, a parallel Winograd convolution method base on MapReduce (PWC-MR) is presented to address the insufficient convolution performance by reducing the number of multiplications. Finally, a load balancing method based on multiway tree and task migration (LB-MTTM) is developed, which improves the capability of parameter merging by balancing the load between nodes and reducing the response time of the cluster. We compared the PDCNN-MRW algorithm with other algorithms on four datasets, including ISIC 2019, BloodCellImages, PatchCamelyon, and ImageNet 1K. Experiment shows that the proposed algorithm has lower training costs and higher efficiency than other parallel DCNN algorithms.},
  archive      = {J_IJMLC},
  author       = {Wen, Zhanqing and Mao, Yimin and Dai, Jingguo},
  doi          = {10.1007/s13042-023-02007-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1949-1966},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PDCNN-MRW: A parallel winograd convolutional neural network algorithm base on MapReduce},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-granular general evolutionary computation framework
by fully utilizing the eliminated particles. <em>IJMLC</em>,
<em>15</em>(5), 1927–1948. (<a
href="https://doi.org/10.1007/s13042-023-02006-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolutionary algorithm, an intuitive phenomenon is that the eliminated bad particles are also beneficial to convergence in evolutionary algorithms by preventing the generated particles from being close to those eliminated bad particles. Most existing algorithms do not take full advantage of the historical information of these particles or use surrogate models without guaranteeing approximation accuracy. In this study, we propose a multi-granularity general framework to divide the feasible region into different granularities by utilizing completely random trees and computing the spatial distribution of individuals. Secondly, through the sampling and migration strategy, make full use of the sparsity of the calculated individual space distribution and the locality of the best individual in history to replace the poor individual in the current population to speed up the local convergence speed of the algorithm. The time complexity of the algorithm using this framework is equal to the maximum between the time complexity of the evolutionary algorithm using this framework and O(tMlogM), where M denotes the number of points and historical particles generated in an iteration and t denotes the number of iterations. Therefore, the additional computational cost incurred by this framework is very low. Experiments on 12 classical functions, including high-dimensional functions, show that the proposed framework can improve four respective evolutionary algorithms and achieve significantly better results in terms of convergence performance and optimization accuracy.},
  archive      = {J_IJMLC},
  author       = {Xiong, Yiping and Xia, Shuyin and Li, Caoxiao and Lian, Xiaoyu and Hou, Bin and Wang, Guoyin},
  doi          = {10.1007/s13042-023-02006-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1927-1948},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-granular general evolutionary computation framework by fully utilizing the eliminated particles},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The fusion feature wavelet pyramid based on FCIS and GLCM
for texture classification. <em>IJMLC</em>, <em>15</em>(5), 1907–1926.
(<a href="https://doi.org/10.1007/s13042-023-02005-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local binary pattern (LBP) is an effective texture feature extraction algorithm, but sensitive to noise. This paper proposes an improved LBP algorithm named fusion center interval strategy (FCIS) for this problem. FCIS introduces the fuzzy method and presents an adaptive fusion center interval selection based on the local statistical information. To improve the completeness of feature extraction, a systematic texture feature extraction algorithm named the fusion feature wavelet pyramid (FFWP) has been proposed. FFWP is built on a set of flexible selectable filters of non-separable bidimensional Shannon type wavelets and fuses FCIS and gray-level co-occurrence matrix (GLCM). The FCIS and GLCM fusion features provide information on contrast, homogeneity, and local anisotropy. The wavelet pyramid with multi-level decomposition makes for multi-scale FCIS and GLCM fusion features with no need for the fixed radii. Validation experiments are performed on publicly available datasets, Kylberg, UMD, and UIUC datasets. Compared with 18 relative algorithms, the results show the effectiveness of FCIS with less time consumption and the supremacy of FFWP on robust and comprehensive texture representation.},
  archive      = {J_IJMLC},
  author       = {Su, Han and Chen, Jiankai and Li, Zhongyan and Meng, Huixian and Wang, Xin},
  doi          = {10.1007/s13042-023-02005-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1907-1926},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {The fusion feature wavelet pyramid based on FCIS and GLCM for texture classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy large margin distribution machine for classification.
<em>IJMLC</em>, <em>15</em>(5), 1891–1905. (<a
href="https://doi.org/10.1007/s13042-023-02004-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a variant of Support Vector Machine (SVM), Large Margin Distribution Machine (LDM) has been validated to outperform SVM both theoretically and experimentally. Due to the inevitable noise in real applications, the credibility of different samples is not necessarily the same, which is neglected by most existing LDM models. To tackle the above problem, this paper first introduces fuzzy set theory into LDM, and proposes a Fuzzy Large Margin Distribution Machine (FLDM) with better robustness and performance. Considering the noise and uncertainty in datasets, sample points farther from the center of homogenous class are less reliable. Therefore, a fuzzy membership function based on the distance to the class center is utilized to characterize the confidence of each sample, i.e., the degree to which the sample belongs to a certain category. Furthermore, different strategies are developed to obtain class centers for linearly separable and linearly inseparable problems. Experiments conducted on both artificial and UCI datasets verified the superiority of FLDM from different perspectives.},
  archive      = {J_IJMLC},
  author       = {Dong, Denghao and Feng, Minyu and Kurths, Jürgen and Zhang, Libo},
  doi          = {10.1007/s13042-023-02004-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1891-1905},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fuzzy large margin distribution machine for classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel forecasting model based on the raised ordered pair
fuzzy time series and fuzzy implication. <em>IJMLC</em>, <em>15</em>(5),
1873–1890. (<a
href="https://doi.org/10.1007/s13042-023-02003-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In fuzzy time series (FTS) based forecasting models, FTS is utilized to depict the characteristic of time series. In the constructed FTS of the existing models, each moment consists of a fuzzy set to reflect the size range of data and aligns with people’s semantic description. However, this FTS ignores some essential fuzzy information, for example the membership degree of data to fuzzy set, and then it fails to describe the feature of time series accurately and limits forecasting performance. To address these issues, ordered pair FTS is proposed in this study. This FTS is consisted of ordered pairs, including two aspects: the fuzzified fuzzy set of data and corresponding membership degree. Worth noting that the ordered pair FTS not only captures the characteristic of data accurately by making use of the information of fuzzy set, but also maintains its interpretability. Following this, ordered pair fuzzy logical relationship (FLR) is derived from antecedent ordered pair(s) to a consequent ordered pair, it describes the association of time series effectively through capturing data information exactly. Based on the ordered pair FLR, a forecasting model is designed. This model applies fuzzy implication to measure the truth degree of FLR and indicate the importance of each fuzzy rule in prediction, ultimately produces reasonable prediction result. The superiorities of the proposed ordered pair FTS and forecasting model are demonstrated in experimental studies, where they are compared with other existing forecasting models.},
  archive      = {J_IJMLC},
  author       = {Li, Fang and Yang, Xiyang},
  doi          = {10.1007/s13042-023-02003-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1873-1890},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel forecasting model based on the raised ordered pair fuzzy time series and fuzzy implication},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive intuitionistic fuzzy neighborhood classifier.
<em>IJMLC</em>, <em>15</em>(5), 1855–1871. (<a
href="https://doi.org/10.1007/s13042-023-02002-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the diversity and complexity of the actual data distribution, the traditional neighborhood classifier (NEC) is weak in adapting to the global data and has low utilization of local information, which leads to the degradation of the classifier&#39;s effectiveness. To adapt NEC to the differences of different dimensions in data distribution, this paper defines attribute sensitivity and improves the purity of neighborhood information granules by weighted distance. To improve the resolution of local information, this paper constructs an intuitionistic fuzzy neighborhood classifier (IFNEC) by combining NEC with the intuitionistic fuzzy set (IFS) and defines the membership degree and non-membership degree of the object in the neighborhood to depict characteristics of local data. In IFNEC, the multi-attribute decision matrix is used in the decision-making process, which is constructed by a support function and intuitionistic fuzzy aggregation operator to filter the information with large uncertainty. Finally, taking seven data sets from UCI, and using accuracy and F1-score as evaluation indicators, we conduct a comparative experiment between NEC and IFNEC. The experimental results show that IFNEC has better performance than NEC.},
  archive      = {J_IJMLC},
  author       = {Yuzhang, Bai and Jusheng, Mi},
  doi          = {10.1007/s13042-023-02002-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1855-1871},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive intuitionistic fuzzy neighborhood classifier},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view subspace clustering using drop out technique on
points. <em>IJMLC</em>, <em>15</em>(5), 1841–1854. (<a
href="https://doi.org/10.1007/s13042-023-02001-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering methods have been very popular among all the multi-view clustering approaches. Overall, in the subspace clustering methods, self-expressive representation of data points gives a coefficient matrix. In multi-view approaches coefficient matrices of all views are utilized to achieve one coefficient matrix that gives a clustering of points. In the previous proposed methods, to determine clusters, the focus was often on the sparsity among different clusters. However, the sparsity may cause that data points of the same clusters does not have strong connections, i.e. some points in the same cluster may not be connected that causes a cluster to be a union of two components and it causes the increase of over-segmentation. To address this problem, we apply drop out technique on columns for all views for several times. In each step, some columns are dropped out and just the remaining points have role in the self-representative combinations of points. Then we consider all self-expressive representations, simultaneously. This method improves the intra-clusters connectivity as well as some other criteria. Our method is evaluated on some real world multi-views data set for confirming its performance. The results depict that the method works well and the proposed algorithm has excellent connectivity. Moreover, some other criteria, which have been improved, are compared with some other contemporary approaches.},
  archive      = {J_IJMLC},
  author       = {Sadjadi, Fatemeh and Jamshidi, Mina and Kang, Zhao},
  doi          = {10.1007/s13042-023-02001-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1841-1854},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view subspace clustering using drop out technique on points},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection for label distribution learning under
feature weight view. <em>IJMLC</em>, <em>15</em>(5), 1827–1840. (<a
href="https://doi.org/10.1007/s13042-023-02000-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) is a fine-grained learning paradigm that addresses label ambiguity, yet it confronts the curse of dimensionality. Feature selection is an effective method for dimensionality reduction, and several algorithms have been proposed for LDL that tackle the problem from different views. In this paper, we propose a novel feature selection method for LDL. First, an effective LDL model is trained through a classical LDL loss function, which is composed of the maximum entropy model and KL divergence. Then, to select common and label-specific features, their weights are enhanced by $$l_{21}$$ -norm and label correlation, respectively. Considering that direct constraint on the parameter by label correlation will make the label-specific features between relevant labels tend to be the same, we adopt the strategy of constraining the maximum entropy output model. Finally, the proposed method will introduce Mutual Information (MI) for the first time in the optimization model for LDL feature selection, which distinguishes similar features thus reducing the influence of redundant features. Experimental results on twelve datasets validate the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Lin, Shidong and Wang, Chenxi and Mao, Yu and Lin, Yaojin},
  doi          = {10.1007/s13042-023-02000-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1827-1840},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection for label distribution learning under feature weight view},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GCAM: Lightweight image inpainting via group convolution and
attention mechanism. <em>IJMLC</em>, <em>15</em>(5), 1815–1825. (<a
href="https://doi.org/10.1007/s13042-023-01999-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, image inpainting techniques tend to be more concerned with how to enhance the quality of restoration than with how to function on various platforms with limited processing power. In this paper, we propose a lightweight method that combines group convolution and attention mechanism to improve or replace the traditional convolution module. Group convolution was used to achieve multi-level image inpainting, and the authors proposed the rotating attention mechanism for allocation to deal with the issue of information mobility between channels in traditional convolution processing. The parallel discriminator structure was utilized throughout the network&#39;s overall design phase to guarantee both local and global consistency of the image inpainting process. The experimental results can demonstrate that, while the quality of image inpainting has been ensured, the proposed image inpainting network&#39;s inference time and resource usage are significantly lower than those of comparable lightweight approaches.},
  archive      = {J_IJMLC},
  author       = {Chen, Yuantao and Xia, Runlong and Yang, Kai and Zou, Ke},
  doi          = {10.1007/s13042-023-01999-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1815-1825},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GCAM: Lightweight image inpainting via group convolution and attention mechanism},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deep reinforcement learning approach incorporating genetic
algorithm for missile path planning. <em>IJMLC</em>, <em>15</em>(5),
1795–1814. (<a
href="https://doi.org/10.1007/s13042-023-01998-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flight path planning of the missile is important in long-range air-to-ground strike missions. Constraints about missile guidance and guidance handover are considered, and path planning is required to conform to the missile motion model. Therefore, the missile’s allowable flight space and flight mode are further restricted, and the decision-making scale and difficulty of the path planning problem are significantly increased. A genetic algorithm incorporated twin delayed deep deterministic policy gradient (GA-TD3) algorithm is proposed for missile path planning, which uses high-quality data generated by GA to improve the TD3 training effect. Firstly, a missile path planning model is established based on the missile’s motion equations, and the missile guidance and guidance handover constraints are stated in detail. Then a fast path generation method is proposed, which uses several leading points to generate a leading path based on the optimal control theory, and the genetic algorithm is used to improve the leading path quality. Finally, the deep reinforcement learning model for the missile path planning problem is established based on the TD3 framework, and the leading paths participate in the leading training to improve the training effect. Simulation cases of 4 threat areas and 3 guidance platforms demonstrate the efficiency of the GA-TD3. Furthermore, the influence of three factors on the algorithm’s performance is tested, including the leading path quality, leading path number, and leading training cycle.},
  archive      = {J_IJMLC},
  author       = {Xu, Shuangfei and Bi, Wenhao and Zhang, An and Wang, Yunong},
  doi          = {10.1007/s13042-023-01998-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1795-1814},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A deep reinforcement learning approach incorporating genetic algorithm for missile path planning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new robust contrastive learning for unsupervised person
re-identification. <em>IJMLC</em>, <em>15</em>(5), 1779–1793. (<a
href="https://doi.org/10.1007/s13042-023-01997-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised person re-identification (Re-ID) is more substantial than the supervised one because it does not require any labeled samples. Currently, the most advanced unsupervised Re-ID models generate pseudo-labels to group images into different clusters and then establish a memory bank to calculate contrastive loss between instances and clusters. This framework has been proven to be remarkably efficient for unsupervised person Re-ID tasks. However, clustering operation inevitably produces misclassification, which brings noises and difficulties to contrastive learning and affects the initialization and updating of the prototype features stored in the memory bank. To solve this problem, we propose a new robust unsupervised person Re-ID model with two developed modules: Cluster Sample Aggregation module (CSA) and Hard Positive Sampling strategy (HPS). The CSA module aggregates each sample in the same cluster through the multi-head self-attention mechanism. This process enables the initialization of prototypes based on the similarities observed within clusters. Additionally, the HPS strategy extracts the dispersion degree of each sample by means of a self-attention aggregation module (SAA) that has been trained by CSA module. According to the obtained indicators, the hardest positive sample is sampled to update the prototype feature stored in the memory bank. With the self-attention mechanism fusing the information among instances in each cluster, the implicit relationships between samples can be better explored in a more refined way. Experiments show that our method achieves state-of-the-art results against existing unsupervised baselines on Market-1501, PersonX, and MSMT17 datasets.},
  archive      = {J_IJMLC},
  author       = {Lin, Huibin and Fu, Hai-Tao and Zhang, Chun-Yang and Chen, C. L. Philip},
  doi          = {10.1007/s13042-023-01997-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1779-1793},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new robust contrastive learning for unsupervised person re-identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). IntelPVT: Intelligent patch-based pyramid vision
transformers for object detection and classification. <em>IJMLC</em>,
<em>15</em>(5), 1767–1778. (<a
href="https://doi.org/10.1007/s13042-023-01996-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the advent of Transformers followed by Vision Transformers (ViTs), enormous success has been achieved by researchers in the field of computer vision and object detection. The difficulty mechanism of splitting images into fixed patches posed a serious challenge in this arena and resulted in loss of useful information at the time of object detection and classification. To overcome the challengers, we propose an innovative Intelligent-based patching mechanism and integrated it seamlessly into the conventional Patch-based ViT framework. The proposed method enables the utilization of patches with flexible sizes to capture and retain essential semantic content from input images and therefore increases the performance compared with conventional methods. Our method was evaluated with three renowned datasets Microsoft Common Objects in Context (MSCOCO-2017), Pascal VOC (Visual Object Classes Challenge) and Cityscapes upon object detection and classification. The experimental results showed promising improvements in specific metrics, particularly in higher confidence thresholds, making it a notable performer in object detection and classification tasks.},
  archive      = {J_IJMLC},
  author       = {Nimma, Divya and Zhou, Zhaoxian},
  doi          = {10.1007/s13042-023-01996-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1767-1778},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {IntelPVT: Intelligent patch-based pyramid vision transformers for object detection and classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-aware tensor factorization convolutional network for
knowledge graph completion. <em>IJMLC</em>, <em>15</em>(5), 1755–1766.
(<a href="https://doi.org/10.1007/s13042-023-01995-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructed by millions of triples, knowledge graph is a commonly used structured representation of information encoding both the entities of the real-world facts and their corresponding relations. Although knowledge graph contains rich information, it is often far from complete. Knowledge graph completion algorithms are able to fill in the missing information efficiently by inferring missing or correcting wrong facts based on existing ones. However, as a kind of graph structure data, the knowledge graph includes not only the attributes of entities and relationships but also the entire graph structure information. Graph convolutional networks can learn better embedding of entities and relationships by using the connectivity structure of graphs, which is conducive to the knowledge graph complement. Although the existing methods based on graph convolutional networks can simultaneously capture the graph structure information and the attributes of entities and relationships from the knowledge graph, there is still a lack of better information decoupling and representation methods. In this article, we propose a novel Graph-Aware Tensor Factorization Convolutional Network (GATFCN) for knowledge graph completion. GATFCN combines a graph convolutional network and a tucker decomposition as the encoder and decoder. It leverages the advantages of graph convolutional network and tensor decomposition in an end-to-end manner to enrich the representation of facts. For the encoder, the GCN model is used to utilize the local information of the graph structure and graph nodes. For the decoder, tensor factorization can decode the information encoded by GCN while enriching the data representation. According to the comprehensive numerical experiments performed, GATFCN outperforms previous state-of-the-art methods across a number of different benchmark datasets, illustrating its effectiveness in knowledge graph completion.},
  archive      = {J_IJMLC},
  author       = {Jin, Yuzhu and Yang, Liu},
  doi          = {10.1007/s13042-023-01995-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1755-1766},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Graph-aware tensor factorization convolutional network for knowledge graph completion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recursive residual fourier transformation for single image
deraining. <em>IJMLC</em>, <em>15</em>(5), 1743–1754. (<a
href="https://doi.org/10.1007/s13042-023-01994-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing a rain-free image from its degraded counterpart requires transforms regarding information from diverse frequency levels. On the frequency domain perspective, despite current CNNs-based methods exhibit excellent abilities in capturing the high-frequency components of images, they often fail to adequately consider or overlook the low-frequency information. To address this challenge, we introduce a fast Fourier transform block (FFTB) which can effectively capture both long-term and short-term interactions, while integrating high- and low-frequency residual information. Our FFTB is a conceptually simple yet computationally efficient block, leading to remarkable performance gains. Based on FFTB, we further develop a multi-stage architecture termed recursive residual fourier network (RRFNet) to enhance the ability of capturing and modeling spatial and frequency domain visual cues. To fully maximize the performance of RRFNet, a novel global–local convert test strategy is employed to alleviate the training–testing inconsistency. Experimental results on the synthetic and real-world datasets demonstrate that our RRFNet performs favorably against state-of-the-art methods while enjoying faster inference speed.},
  archive      = {J_IJMLC},
  author       = {Bao, Zhiyuan and Shao, Mingwen and Wan, Yecong and Qiao, Yuanjian},
  doi          = {10.1007/s13042-023-01994-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1743-1754},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Recursive residual fourier transformation for single image deraining},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global relational attention with a maximum suppression
constraint for vehicle re-identification. <em>IJMLC</em>,
<em>15</em>(5), 1729–1742. (<a
href="https://doi.org/10.1007/s13042-023-01993-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of vehicle re-identification is to identify the same vehicle from multiple cameras, which is a challenging task. There are many solutions to this problem, among which the self-attention mechanism is very popular. It can capture the long-range dependence in an image, thereby suppressing the irrelevant features. Most of the existing designs are based on isolated pairwise query-key interactions to refine a node. They implicitly mine attention patterns without explicitly modeling node weights. In this paper, we propose a global relational attention mechanism, which makes full use of the global dependence of a node to learn and infer its weight value. Global dependence can measure the importance of nodes more robustly and efficiently. To capture more discriminative features, we propose a maximum suppression constraint to adaptively adjust weight values to expand the range of attention. In addition, we design a pair of effective attention modules based on the proposed attention mechanism, that focus on mining the discriminative features related to vehicle identities from the spatial and channel dimensions. We conduct a large number of experiments on the VeRi-776 and VehicleID datasets, and the experimental results demonstrate the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Pang, Xiyu and Yin, Yilong and Tian, Xin},
  doi          = {10.1007/s13042-023-01993-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1729-1742},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Global relational attention with a maximum suppression constraint for vehicle re-identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-tuning pretrained transformer encoders for
sequence-to-sequence learning. <em>IJMLC</em>, <em>15</em>(5),
1711–1728. (<a
href="https://doi.org/10.1007/s13042-023-01992-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce s2s-ft, a method for adapting pretrained bidirectional Transformer encoders, such as BERT and RoBERTa, to sequence-to-sequence tasks like abstractive summarization and question generation. By employing a unified modeling approach and well-designed self-attention masks, s2s-ft leverages the generative capabilities of pretrained Transformer encoders without the need for an additional decoder. We conduct extensive experiments comparing three fine-tuning algorithms (causal fine-tuning, masked fine-tuning, and pseudo-masked fine-tuning) and various pretrained models for initialization. Results demonstrate that s2s-ft achieves strong performance across different tasks and languages. Additionally, the method is successfully extended to multilingual pretrained models, such as XLM-RoBERTa, and evaluated on multilingual generation tasks. Our work highlights the importance of reducing the discrepancy between masked language model pretraining and sequence-to-sequence fine-tuning and showcases the effectiveness and expansibility of the s2s-ft method.},
  archive      = {J_IJMLC},
  author       = {Bao, Hangbo and Dong, Li and Wang, Wenhui and Yang, Nan and Piao, Songhao and Wei, Furu},
  doi          = {10.1007/s13042-023-01992-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1711-1728},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fine-tuning pretrained transformer encoders for sequence-to-sequence learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RDMA: Low-light image enhancement based on retinex
decomposition and multi-scale adjustment. <em>IJMLC</em>,
<em>15</em>(5), 1693–1709. (<a
href="https://doi.org/10.1007/s13042-023-01991-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images are often affected by insufficient illumination and suffer from degradation problems such as low brightness, noise, and color distortion, which results in reduced image quality. Existing low-light image enhancement methods based on Retinex theory decompose images into reflectance and illumination components, which are adjusted separately; however, the intrinsic connection between reflectance and illumination during decomposition is not considered, and multi-scale information during subsequent adjustments is inadequately utilized. In this study, we propose a low-light image enhancement network based on Retinex decomposition and multi-scale adjustment (RDMA), which performs initial decomposition followed by subsequent adjustment. We utilized prior knowledge to design the feature interaction module (FIM) and the feature fusion module (FFM) for image decomposition. Furthermore, a coarse-to-fine multi-scale network with residual channel and spatial attention (RCSA) was designed to remove noise from reflectance, suppress color distortion, preserve image details, and adjust the brightness of illumination. An evaluation of various low-light image datasets and comparisons with state-of-the-art methods showed that the proposed network is superior in terms of enhancement results.},
  archive      = {J_IJMLC},
  author       = {Li, Jiafeng and Hao, Shuai and Li, Tianshuo and Zhuo, Li and Zhang, Jing},
  doi          = {10.1007/s13042-023-01991-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1693-1709},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RDMA: Low-light image enhancement based on retinex decomposition and multi-scale adjustment},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Filtering level-set model based on saliency and gradient
information for sonar image segmentation. <em>IJMLC</em>,
<em>15</em>(5), 1677–1692. (<a
href="https://doi.org/10.1007/s13042-023-01990-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of the acquired sonar image is generally poor because of the influences of various marine environments, mainly in terms of low resolution and incomplete target edges. To address the difficulties of sonar image segmentation caused by the reasons above, this paper proposes a filtering level-set model for underwater sonar image based on saliency information and gradient information. The model consists of the following three modules. First, the filter fusion module can selectively smooth the noise of sonar image, which reduces the difficulty of subsequent segmentation. Next, the local enhancement module can effectively improve the over-segmentation problem caused by the weak boundary of the target in sonar image. Finally, the level-set segmentation module is proposed in this paper. Weakening the shadow on the results of the above modules can obtain the initial contour closer to the target boundary, which makes the evolution results more accurate. The experimental results show that our model is effective, accurate, and superior to the state of the art.},
  archive      = {J_IJMLC},
  author       = {Xu, Huipu and Zhu, Ziqi and Yu, Ying},
  doi          = {10.1007/s13042-023-01990-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1677-1692},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Filtering level-set model based on saliency and gradient information for sonar image segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consistent epistemic planning for multiagent deep
reinforcement learning. <em>IJMLC</em>, <em>15</em>(5), 1663–1675. (<a
href="https://doi.org/10.1007/s13042-023-01989-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiagent cooperation in a partially observable environment without communication is difficult because of the uncertainty of agents. Traditional multiagent deep reinforcement learning (MADRL) algorithms fail to address this uncertainty. We proposed a MADRL-based policy network architecture called shared mental model-multiagent epistemic planning policy (SMM-MEPP) to resolve this issue. Firstly, this architecture combines multiagent epistemic planning and MADRL to create a “perception–planning–action” multiagent epistemic planning framework, helping multiple agents better handle uncertainty in the absence of coordination. Additionally, by introducing mental models and describing them as neural networks, the parameter-sharing mechanism is used to create shared mental models, maintain the consistency of multiagent planning under the condition of no communication, and improve the efficiency of cooperation. Finally, we applied the SMM-MEPP architecture to three advanced MADRL algorithms (i.e., MAAC, MADDPG, and MAPPO) and conducted comparative experiments in multiagent cooperation tasks. The results show that the proposed method can provide consistent planning for multiple agents and improve the convergence speed or training effect in a partially observable environment without communication.},
  archive      = {J_IJMLC},
  author       = {Wu, Peiliang and Luo, Shicheng and Tian, Liqiang and Mao, Bingyi and Chen, Wenbai},
  doi          = {10.1007/s13042-023-01989-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {5},
  number       = {5},
  pages        = {1663-1675},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Consistent epistemic planning for multiagent deep reinforcement learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint weighted knowledge distillation and multi-scale
feature distillation for long-tailed recognition. <em>IJMLC</em>,
<em>15</em>(4), 1647–1661. (<a
href="https://doi.org/10.1007/s13042-023-01988-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data in the natural open world tends to follow a long-tailed class distribution, leading deep models trained on such datasets to frequently exhibit inferior performance on the tail classes. Although existing approaches improve a model’s performance on tail categories through strategies such as class rebalancing, they often sacrifice the deep features that the model has already learned. In this paper, we propose a new joint distillation framework called JWAFD (Joint weighted knowledge distillation and multi-scale feature distillation) to address the long-tailed recognition problem from the perspective of knowledge distillation. The framework comprises two effective modules. Firstly, the weighted knowledge distillation module, which uses a category prior to adjust the weights of each category. By doing so, the training process becomes more balanced across all categories. Then, the multi-scale feature distillation module, which helps to further optimize the feature representation, thus solving the problem of under-learning of features encountered in previous studies. Compared with previous studies, the proposed framework significantly improves the performance of rare classes while maintaining the performance of head classes recognition. Extensive experiments on three benchmark datasets(CIFAR-100-LT, ImageNet-LT and iNaturalist2018) have demonstrated that the proposed novel distillation framework achieves comparable performance to the state-of-the-art long-tailed recognition methods. Our code is available at: https://github.com/xiaohe6/JWAFD .},
  archive      = {J_IJMLC},
  author       = {He, Yiru and Wang, Shiqian and Yu, Junyang and Liu, Chaoyang and He, Xin and Li, Han},
  doi          = {10.1007/s13042-023-01988-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1647-1661},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Joint weighted knowledge distillation and multi-scale feature distillation for long-tailed recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LM-net: A dynamic gesture recognition network with long-term
aggregation and motion excitation. <em>IJMLC</em>, <em>15</em>(4),
1633–1645. (<a
href="https://doi.org/10.1007/s13042-023-01987-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a growing interest in dynamic hand gestures as a natural means of human–computer interaction. However, existing methods for recognizing dynamic gestures have certain limitations, particularly in consistently capturing and focusing on the hand movement region across various motion patterns. This research paper presents LMNet, an innovative and efficacious network comprising the Long-term Aggregation Module and the Motion Excitation Module. The Motion Excitation Module exploits motion information extracted from neighboring frames to amplify motion-sensitive channels, while the Long-term Aggregation Module harnesses dynamic convolution to assimilate temporal information from diverse motion patterns. Rigorous experimentation conducted on the EgoGesture and Jester datasets demonstrates that LMNet surpasses the majority of prevailing approaches in terms of accuracy, while concurrently upholding an optimal computational cost.},
  archive      = {J_IJMLC},
  author       = {Chang, Shaopeng and Huang, Xueyu},
  doi          = {10.1007/s13042-023-01987-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1633-1645},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LM-net: A dynamic gesture recognition network with long-term aggregation and motion excitation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessment of patients with parkinson’s disease based on
federated learning. <em>IJMLC</em>, <em>15</em>(4), 1621–1632. (<a
href="https://doi.org/10.1007/s13042-023-01986-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents federated Learning (FL), which is based on wearable devices, and applies the actual leg agility data that has been collected from people living with Parkinson’s disease (PD) to the model. Studies have shown that the implementation of FL can effectively protect the data privacy of PD patients. The classification accuracy of leg agility data is reduced by 2.72% when compared to the conventional method of summarizing all the data. However, it is higher than the model accuracy of each data owner, having increased by 22.68%. Secondly, during the communication process, the upload or download of the model parameters of each terminal node is interrupted for N times at the same time, and it is found that interrupting the upload of parameters reduces the accuracy of the central model. The impact of interrupting the download parameters on the central model is negligible. Then, the communication process of the terminal nodes with different data amounts was interrupted respectively, and it was found that the accuracy of the central model was basically not affected. Finally, noise is introduced to the various parameters in the communication process. The accuracy of the central model begins to gradually deteriorate as soon as the noise intensity reaches 0.012 or higher.},
  archive      = {J_IJMLC},
  author       = {Guan, Bo and Yu, Lei and Li, Yang and Jia, Zhongwei and Jin, Zhen},
  doi          = {10.1007/s13042-023-01986-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1621-1632},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Assessment of patients with parkinson’s disease based on federated learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge structures construction and learning paths
recommendation based on formal contexts. <em>IJMLC</em>, <em>15</em>(4),
1605–1620. (<a
href="https://doi.org/10.1007/s13042-023-01985-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge structure is a valid characteristic for assessing individuals’ knowledge and guiding their future learning. Based on formal context, there are methods to construct a knowledge structure delineated by skill function and find learning paths. However, the skill functions considered in these methods are well-formed and the skills are independent. To overcome these limitations, this paper transforms a general skill function into a formal context to extend the methods of constructing knowledge structures and recommending learning paths. The construction method of knowledge structures is discussed based on the quasi-order relation among skills, which is suitable for the situation that skills are not independent. The recommendation method of learning paths is investigated based on the subsequent states and learning complexity of skills, which can realize personalized learning. Moreover, simulation experiments are performed on five data sets and show that it is necessary to consider the quasi-order relation among skills and that the methods proposed for finding and recommending learning paths are feasible.},
  archive      = {J_IJMLC},
  author       = {Zhou, Yinfeng and Li, Jinjin and Yang, Hailong and Xu, Qingyuan and Yang, Taoli and Feng, Danlu},
  doi          = {10.1007/s13042-023-01985-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1605-1620},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge structures construction and learning paths recommendation based on formal contexts},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Depth color correlation-guided dark channel prior for
underwater image enhancement. <em>IJMLC</em>, <em>15</em>(4), 1591–1604.
(<a href="https://doi.org/10.1007/s13042-023-01984-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the attenuation of underwater light, obtained images often suffer from low contrast, noise interference, and hazy content. In the field of underwater image enhancement, dark channel prior dehazing algorithms have achieved initial success, but they often do not take into account the correlation between different colors and depth. In this paper, we introduce the concept of depth-color correlation based on dark channel prior (DCP), additionally embedding a multi-scale dehazing and denoising module to effectively solve hazy content and noise interference. In particular, the depth-color correlation means that light from different color channels tends to have larger or smaller values as the depth increases. Therefore, we employ the three-bit indicator to represent the depth-color correlation and then further estimate the background light from the different color channels. Because the pyramid layers of the haze image contain varying degrees of noise, our multi-scale dehazing and denoising module decomposes the haze image into a Gaussian pyramid layer and a Laplacian pyramid layer, then dehazes and denoises them layer by layer. Thereafter, the pyramid layers are collapsed to obtain the enhanced image. Finally, in order to reduce the morphological artifacts, we employ the weighted guided filter. Results demonstrate that our method has superior enhancement capabilities compared to other state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Xu, Huipu and Wang, Min},
  doi          = {10.1007/s13042-023-01984-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1591-1604},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Depth color correlation-guided dark channel prior for underwater image enhancement},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient low-light image enhancement with model parameters
scaled down to 0.02M. <em>IJMLC</em>, <em>15</em>(4), 1575–1589. (<a
href="https://doi.org/10.1007/s13042-023-01983-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of low-light image enhancement, existing deep learning methods face three significant challenges: inaccurate reflection component estimation, poor image enhancement capabilities, and high computational costs. This study introduces a novel, efficient solution to these problems in the form of an Ultra-Lightweight Enhancement Network (ULENet). Our primary contributions are twofold. First, we propose the combination of channel-wise context mining and spatial-wise reinforcement for improved low-light image enhancement. Second, we introduce a novel lightweight neural architecture, ULENet, designed specifically for this purpose. ULENet features two innovative subnetworks: the channel-wise context mining subnetwork for extracting rich context from low-light images, and the spatial-wise reinforcement subnetwork for extensive spatial feature extraction and detail reconstruction. We use the deep-learning framework PyTorch for training and evaluating our model. Extensive experiments demonstrate that ULENet significantly outperforms nine state-of-the-art low-light enhancement methods in terms of speed, accuracy, and adaptability in complex low-light scenarios. These results validate our initial hypothesis and underscore the effectiveness of the proposed approach.},
  archive      = {J_IJMLC},
  author       = {Yang, Shaoliang and Zhou, Dongming},
  doi          = {10.1007/s13042-023-01983-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1575-1589},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Efficient low-light image enhancement with model parameters scaled down to 0.02M},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing framelet GCNs with generalized p-laplacian
regularization. <em>IJMLC</em>, <em>15</em>(4), 1553–1573. (<a
href="https://doi.org/10.1007/s13042-023-01982-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved remarkable results for various graph learning tasks. However, one of the recent challenges for GNNs is to adapt to different types of graph inputs, such as heterophilic graph datasets in which linked nodes are more likely to contain a different class of labels and features. Accordingly, an ideal GNN model should adaptively accommodate all types of graph datasets with different labeling distributions. In this paper, we tackle this challenge by proposing a regularization framework on graph framelet with the regularizer induced from graph p-Laplacian. By adjusting the value of p, the p-Laplacian based regularizer restricts the solution space of graph framelet into the desirable region based on the graph homophilic features. We propose an algorithm to effectively solve a more generalized regularization problem and prove that the algorithm imposes a (p-Laplacian based) spectral convolution and diagonal scaling operation to the framelet filtered node features. Furthermore, we analyze the denoising power of the proposed model and compare it with the predefined framelet denoising regularizer. Finally, we conduct empirical studies to show the prediction power of the proposed model in both homophily undirect and heterophily direct graphs with and without noises. Our proposed model shows significant improvements compared to multiple baselines, and this suggests the effectiveness of combining graph framelet and p-Laplacian.},
  archive      = {J_IJMLC},
  author       = {Shao, Zhiqi and Shi, Dai and Han, Andi and Vasnev, Andrey and Guo, Yi and Gao, Junbin},
  doi          = {10.1007/s13042-023-01982-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1553-1573},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing framelet GCNs with generalized p-laplacian regularization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view reinforcement learning for sequential
decision-making with insufficient state information. <em>IJMLC</em>,
<em>15</em>(4), 1533–1552. (<a
href="https://doi.org/10.1007/s13042-023-01981-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most reinforcement learning methods describe sequential decision-making as a Markov decision process where the effect of action is only decided by the current state. But this is reasonable only if the state is correctly defined and the state information is sufficiently observed. Thus the learning efficiency of reinforcement learning methods based on Markov decision process is limited when the state information is insufficient. Partially observable Markov decision process and history-based decision process are respectively proposed to describe sequential decision-making with insufficient state information. However, these two processes are easy to ignore the important information from the current observed state. Therefore, the learning efficiency of reinforcement learning methods based on these two processes is also limited when the state information is insufficient. In this paper, we propose a multi-view reinforcement learning method to solve this problem. The motivation is that the interaction information between the agent and its environment should be considered from the views of history, present, and future to overcome the insufficiency of state information. Based on these views, we construct a multi-view decision process to describe sequential decision-making with insufficient state information. A multi-view reinforcement learning method is proposed by combining the multi-view decision process and the actor-critic framework. In the proposed method, multi-view clustering is performed to ensure that each type of sample can be sufficiently exploited. Experiments illustrate that the proposed method is more effective than the compared state-of-the-arts. The source code can be downloaded from https://github.com/jamieliuestc/MVRL.},
  archive      = {J_IJMLC},
  author       = {Li, Min and Zhu, William and Wang, Shiping},
  doi          = {10.1007/s13042-023-01981-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1533-1552},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view reinforcement learning for sequential decision-making with insufficient state information},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel autism spectrum disorder identification method:
Spectral graph network with brain-population graph structure joint
learning. <em>IJMLC</em>, <em>15</em>(4), 1517–1532. (<a
href="https://doi.org/10.1007/s13042-023-01980-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a prevalent neurodevelopmental condition. Its early and accurate diagnosis is critical in enhancing the quality of life for affected individuals. Graph neural networks supply promising approaches for ASD diagnosis. However, existing works typically focus on brain-level or population-level classification methods, where the former usually disregards subjects’ non-imaging information and inter-subject relationships, and the latter generally fails to adequately evaluate and detect disease-associated brain regions and biomarkers. Furthermore, relatively static graph structures and shallow network architectures hinder the abundant extraction of information, affecting the performance of ASD identification. Accordingly, this paper proposes a new spectral graph network with brain-population graph structure joint learning (BPGLNet) for ASD diagnosis. This new framework involves two main components. Firstly, a brain-level graph learning module is designed to acquire valuable features of brain regions and identify effective biomarkers for each subject. In particular, it constructs a brain-aware representation learning network by fusing an improved graph pooling strategy and spectral graph convolution to learn subgraph structures and features of brain regions. Subsequently, based on these generated features, a population-level graph learning module is developed to capture relationships between different subjects. It builds an adaptive edge generator network by integrating non-imaging and imaging data, forming a learnable population graph. Further, this module also devises a deep cascade spectral graph network to enrich high-level feature representation of data and complete ASD identification. Experiments on the benchmark dataset reveal the state-of-the-art performance of BPGLNet.},
  archive      = {J_IJMLC},
  author       = {Li, Sihui and Li, Duo and Zhang, Rui and Cao, Feilong},
  doi          = {10.1007/s13042-023-01980-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1517-1532},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel autism spectrum disorder identification method: Spectral graph network with brain-population graph structure joint learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cost-sensitive sparse subset selection. <em>IJMLC</em>,
<em>15</em>(4), 1503–1515. (<a
href="https://doi.org/10.1007/s13042-023-01979-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting a few important representatives that could reveal the intrinsic structure of a data set with massive data samples, i.e., subset selection, is very useful for different applications in machine learning and information retrieval domains. In this paper, we propose a cost-sensitive sparse regression-based subset selection method, termed cost-sensitive sparse subset selection (CS4). CS4 considers the cost of different subsets for the prediction of all the data samples in a given data set and can choose a subset that has minimal prediction cost. Hence, compared to the related sparse regression-based methods, CS4 is capable of selecting the most informative representatives to characterize the structures of data sets. Moreover, we present an optimization algorithm for solving CS4 problem. The convergence and computation complexity of the algorithm have been analyzed. The relationships between CS4 and the related algorithms have been also discussed. Finally, the experiments on representative selection and classification show the effectiveness and superiorities of CS4.},
  archive      = {J_IJMLC},
  author       = {Wei, Lai and Liu, Shiteng},
  doi          = {10.1007/s13042-023-01979-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1503-1515},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cost-sensitive sparse subset selection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interpretable neural network for robustly determining the
location and number of cluster centers. <em>IJMLC</em>, <em>15</em>(4),
1473–1501. (<a
href="https://doi.org/10.1007/s13042-023-01978-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {K-means is a clustering method with an interpretable mechanism. However, its clustering results are significantly affected by the location of the initial cluster centers. More importantly, for it and its improved versions, it is extremely hard to adaptively determine the number of cluster centers. In contrast, ordinary neural networks have powerful information representation ability but lack interpretability. Moreover, to the best of our knowledge, the use of interpretable neural networks to determine the number of cluster centers of K-means is absent. This paper proposes K-meaNet that combines the interpretable mechanism of K-means and the powerful information representation ability of neural networks. For the neural network in K-meaNet, its inputs, weights, and mathematical expressions of each layer have clear meanings. During training, if one cluster center is critical, the value of one of the weights in the neural network, the gate, corresponding to this cluster center will increase. At the same time, the position of this cluster center will be close to the ideal cluster center. Besides, the location of the cluster center(s) and the value(s) of the corresponding gate(s) will not change significantly. This endows K-meaNet with the ability to adaptively determine the location and number of cluster centers compared with K-means and its improved versions. Moreover, this adaptive ability is robust to the location of the initial cluster centers, the number of the initial cluster centers, and the number of features. On six synthetic datasets and three real datasets, numerical experiments verify that K-meaNet can adaptively determine the number of cluster centers and is robust to the location of the initial cluster centers, the number of the initial cluster centers, and the number of features.},
  archive      = {J_IJMLC},
  author       = {Xie, Xuetao and Pu, Yi-Fei and Zhang, Huaqing and Mańdziuk, Jacek and El-Alfy, El-Sayed M. and Wang, Jian},
  doi          = {10.1007/s13042-023-01978-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1473-1501},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An interpretable neural network for robustly determining the location and number of cluster centers},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental feature selection based on uncertainty measure
for dynamic interval-valued data. <em>IJMLC</em>, <em>15</em>(4),
1453–1472. (<a
href="https://doi.org/10.1007/s13042-023-01977-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important strategy for knowledge reduction in rough set. Interval-valued data, as an extension of single values, can better express uncertain information from the perspective of uncertainty measure. However, for applications in the real world, feature values in interval-valued data vary with time evolving. For dynamic interval-valued data, it is time-consuming to employ existing approaches to choose the feature subset because they need to recalculate the interval-valued data from scratch when feature values vary. Motived by this, we research the incremental methods of feature selection in dynamic interval-valued data environment, which can select new feature subset according to previous results. At first, the incremental updatings of $$\theta$$ -conditional entropy are proposed, which measures the significance of candidate features along with the change of feature values of a single object and multiple objects, respetively. On this basis, aiming at dynamic interval-valued data, the homologous incremental feature selection algorithms are put forward. Finally, by comparing the results of feature subset selection between incremental algorithm and non-incremental algorithm on public data sets, it can be concluded that the proposed two incremental algorithms are more efficient and effective, especially, as multiple objects change feature values, two incremental algorithms proposed in this paper have achieved satisfactory results in computing time.},
  archive      = {J_IJMLC},
  author       = {Shu, Wenhao and Chen, Ting and Cao, Dongtao and Qian, Wenbin},
  doi          = {10.1007/s13042-023-01977-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1453-1472},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Incremental feature selection based on uncertainty measure for dynamic interval-valued data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent cooperation policy gradient method based on
enhanced exploration for cooperative tasks. <em>IJMLC</em>,
<em>15</em>(4), 1431–1452. (<a
href="https://doi.org/10.1007/s13042-023-01976-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent cooperation and coordination are often essential for task fulfillment. Multi-agent deep reinforcement learning (MADRL) can effectively learn the solutions to problems, but its application is still primarily restricted by the exploration–exploitation trade-off. Therefore, the focus of MADRL research is placed on how to effectively explore the environment and collect good experience with rich information to strengthen cooperative behaviors and optimize policy learning. To address this problem, we propose a novel multi-agent cooperation policy gradient method called multi-agent proximal policy optimization based on self-imitation learning and random network distillation (MAPPOSR). MAPPOSR consists of two policy gradient-based additional components, namely (1) random network distillation (RND) exploration bonus component that produces intrinsic rewards and encourages agents to access new states and actions, thereby helping them explore better trajectories and avoiding the algorithm prematurely converging or getting stuck in local optima; and (2) self-imitation learning (SIL) policy update component that stores and reuses high-return trajectory samples generated by agents themselves, thereby strengthening their cooperation and boosting learning efficiency. The experimental results show that in addition to effectively solving the hard-exploration problem, the proposed method significantly outperforms other SOTA MADRL algorithms in learning efficiency as well as in escaping local optima. Moreover, the effect of different function inputs on algorithm performance is investigated in the centralized training and decentralized execution (CTDE) framework, based on which a joint-observation coding method based on individual is developed. By encouraging the agent to focus more on the local observation information of other agents related to it and abandon global state information provided by the environment, the developed coding method can remove the effects of excessive value function input dimensions and redundant feature information on algorithm performance.},
  archive      = {J_IJMLC},
  author       = {Zhao, Li-yang and Chang, Tian-qing and Zhang, Lei and Zhang, Xin-lu and Wang, Jiang-feng},
  doi          = {10.1007/s13042-023-01976-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1431-1452},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-agent cooperation policy gradient method based on enhanced exploration for cooperative tasks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Subspace clustering based on a multichannel attention
mechanism. <em>IJMLC</em>, <em>15</em>(4), 1415–1430. (<a
href="https://doi.org/10.1007/s13042-023-01975-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing self-representation models based on multilayer perceptrons (MLPs) have gained widespread attention for their outstanding clustering performance in subspace clustering. However, when images contain rich spatial information, the use of fully connected neural networks that only accept vector inputs results in a significant loss of spatial information, thereby greatly reducing the clustering performance of the models. To address the clustering problem of data with rich spatial information, this paper proposes a multichannel subspace clustering method based on a self-representation network (CGSNet). This method incorporates modules capable of mining spatial features into the self-representation network to highlight different data characteristics and supplement the spatial information lost by the MLP. CGSNet successfully uncovers the latent features within the input data samples and extracts the spatial relationships among different image features by employing channel and spatial attention modules. Additionally, static parameterized channel mapping and spatial mapping are used to refine and filter the obtained spatial information, further enhancing the quality of self-representation. Finally, by leveraging the self-representation network, the clustering task is completed by learning the affinity matrix. The experimental results demonstrate that CGSNet outperforms the self-expressive network (SENet), achieving improvements of 1.5%, 3.3%, 0.9%, and 4.4% in terms of the clustering accuracy with the MNIST, FashionMNIST, CIFAR-10, and EMNIST datasets, respectively. CGSNet achieves the highest accuracy among competitive clustering methods, including EnSC, SENet, and 14 others.},
  archive      = {J_IJMLC},
  author       = {Zhao, Yuxi and Wang, Longge and Yu, Junyang and Zuo, Fang and Wang, Tingyu and Wang, Zhicheng and Li, Han},
  doi          = {10.1007/s13042-023-01975-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1415-1430},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Subspace clustering based on a multichannel attention mechanism},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Contrastive sequential interaction network learning on
co-evolving riemannian spaces. <em>IJMLC</em>, <em>15</em>(4),
1397–1413. (<a
href="https://doi.org/10.1007/s13042-023-01974-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sequential interaction network usually find itself in a variety of applications, e.g., recommender system. Herein, inferring future interaction is of fundamental importance, and previous efforts are mainly focused on the dynamics in the classic zero-curvature Euclidean space. Despite the promising results achieved by previous methods, a range of significant issues still largely remains open: On the bipartite nature, is it appropriate to place user and item nodes in one identical space regardless of their inherent difference? On the network dynamics, instead of a fixed curvature space, will the representation spaces evolve when new interactions arrive continuously? On the learning paradigm, can we get rid of the label information costly to acquire? To address the aforementioned issues, we propose a novel Contrastive model for Sequential Interaction Network learning on Co-Evolving RiEmannian spaces, CSincere. To the best of our knowledge, we are the first to introduce a couple of co-evolving representation spaces, rather than a single or static space, and propose a co-contrastive learning for the sequential interaction network. In CSincere, we formulate a Cross-Space Aggregation for message-passing across representation spaces of different Riemannian geometries, and design a Neural Curvature Estimator based on Ricci curvatures for modeling the space evolvement over time. Thereafter, we present a Reweighed Co-Contrast between the temporal views of the sequential network, so that the couple of Riemannian spaces interact with each other for the interaction prediction without labels. Empirical results on 5 public datasets show the superiority of CSincere over the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Sun, Li and Ye, Junda and Zhang, Jiawei and Yang, Yong and Liu, Mingsheng and Wang, Feiyang and Yu, Philip S.},
  doi          = {10.1007/s13042-023-01974-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1397-1413},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Contrastive sequential interaction network learning on co-evolving riemannian spaces},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation model of aluminum electrolysis cell condition
based on multi-source heterogeneous data fusion. <em>IJMLC</em>,
<em>15</em>(4), 1375–1396. (<a
href="https://doi.org/10.1007/s13042-023-01973-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial process data have the characteristics of heterogeneity, dimensional inconsistency and multi time scales, which increase the difficulty of condition evaluation in industrial process using multi-source data. To address these problems, a multi-source heterogeneous data fusion model is proposed for the condition evaluation of aluminum electrolysis cell. Firstly, the deep residual network (ResNet) is used to extract the superheat degree features of the fire hole video, the ResNet and wavelet packet are used to extract the cell voltage features, thereby achieving the isomorphism of heterogeneous data. An anode current features extraction method based on dynamic pivotal sequence is used to reduce the dimension of anode current data and extract features. Then, a fusion model of feature layer and data layer based on CatBoost is proposed, which comprehensively considers the material-energy balance mechanism knowledge and current efficiency to describe the dynamic coupling relationship between various data sources. The experimental evaluation results on the actual industrial aluminum electrolysis dataset show that our method improves the performance by 2.3% compared with existing multi-source data fusion method.},
  archive      = {J_IJMLC},
  author       = {Sun, Yubo and Gui, Weihua and Chen, Xiaofang and Xie, Yongfang},
  doi          = {10.1007/s13042-023-01973-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1375-1396},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Evaluation model of aluminum electrolysis cell condition based on multi-source heterogeneous data fusion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal sparse support tensor machine for multiple
classification learning. <em>IJMLC</em>, <em>15</em>(4), 1361–1373. (<a
href="https://doi.org/10.1007/s13042-023-01972-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops new multiple classification approaches in a direct manner for high-dimensional multimodal data. Firstly, we construct multiple hyperplanes via the tensor multimodal product and design a novel piecewise quadratic loss function ‘ $$\ell _{cC}$$ ’ in the soft-margin scheme to propose the multimodal support tensor machine model (MSTM). Furthermore, to alleviate the overfitting phenomenon in small-size sampling instances, we construct a multimodal sparsity constrained support tensor machine model (MSSTM) by subtly imposing the sparsity constraint on the decision variables of the dual problem. In addition, the Newton method and subspace Newton method are employed to solve the MSTM and MSSTM models from the dual perspective, taking advantage of the differentiation properties of ‘ $$\ell _{cC}$$ ’ and the hard-thresholding operator, respectively. Numerical experiments on four image datasets demonstrate the efficiency of the proposed methods in terms of classification accuracy and training time for multiple classification.},
  archive      = {J_IJMLC},
  author       = {Wang, Shuangyue and Zhang, Xinrong and Luo, Ziyan and Wang, Yingnan},
  doi          = {10.1007/s13042-023-01972-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1361-1373},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multimodal sparse support tensor machine for multiple classification learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dissipativity-based asynchronous control for time-varying
delay t–s fuzzy markov jump systems with multisource disturbances and
input saturation. <em>IJMLC</em>, <em>15</em>(4), 1343–1359. (<a
href="https://doi.org/10.1007/s13042-023-01971-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of asynchronous dissipative control for a class of Takagi–Sugeno (T–S) fuzzy Markov jump systems with multiple sources disturbances is studied. Compared with the previous conclusions, the parameter uncertainty, time-varying delay and input saturation are taken into account in nonlinear system. And a new fuzzy disturbance rejection control structure is proposed by setting the disturbance observer and controller. The Hidden Markov model (HMM) is used to detect the mode information in the case that the modes mismatch between the system and controller, which ensures that the system is exponentially mean-square stable and has a satisfactory dissipative performance. Then, the sufficient conditions for the stability and dissipative of the augmented system are given in the form of linear matrix inequalities (LMIs), and the gain matrices of the observer and controller can be directly calculated. Finally, the practicability and effectiveness of the proposed method are verified by two examples.},
  archive      = {J_IJMLC},
  author       = {Guo, Yuxin and Ma, Xu and Ma, Yuechao and Fu, Lei},
  doi          = {10.1007/s13042-023-01971-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1343-1359},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dissipativity-based asynchronous control for time-varying delay T–S fuzzy markov jump systems with multisource disturbances and input saturation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Underwater image enhancement based on multiscale fusion
generative adversarial network. <em>IJMLC</em>, <em>15</em>(4),
1331–1341. (<a
href="https://doi.org/10.1007/s13042-023-01970-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The underwater optical imaging environment presents unique challenges due to its complexity. This paper addresses the limitations of existing algorithms in handling underwater images captured in artificial light scenes. We proposed an underwater artificial light optimization algorithm to preprocess images with uneven lighting, mitigating the effects of light distortion. Furthermore, we proposed a novel underwater image enhancement algorithm based the Multiscale Fusion Generative Adversarial Network, named UMSGAN, to address the issues of low contrast and color distortion. UMSGAN uses the generative adversarial network as the underlying framework and first extracts information from the degraded image through three parallel branches separately, and adds residual dense blocks in each branch to learn deeper features. Subsequently, the features extracted from the three branches are fused and the detailed information of the image is recovered by the reconstruction module, named RM. Finally, multiple loss functions are linearly superimposed, and the adversarial network is trained iteratively to obtain the enhanced underwater images. The algorithm is designed to accommodate various underwater scenes, providing both color correction and detail enhancement. We conducted a comprehensive evaluation of the proposed algorithm, considering both qualitative and quantitative aspects. The experimental results demonstrate the effectiveness of our approach on a diverse underwater image dataset. The proposed algorithm exhibits superior performance in terms of enhancing underwater image quality, achieving significant improvements in contrast, color accuracy, and detail preservation. The proposed methodology exhibits promising results, offering potential applications in various domains such as underwater photography, marine exploration, and underwater surveillance.},
  archive      = {J_IJMLC},
  author       = {Dai, Yating and Wang, Jianyu and Wang, Hao and He, Xin},
  doi          = {10.1007/s13042-023-01970-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1331-1341},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Underwater image enhancement based on multiscale fusion generative adversarial network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiple kinds of information extraction method for
multi-view low-rank subspace clustering. <em>IJMLC</em>, <em>15</em>(4),
1313–1330. (<a
href="https://doi.org/10.1007/s13042-023-01969-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multi-view subspace clustering has attracted intensive attentions due to the remarkable clustering performance by extracting abundant complementary information from multi-view data, making its clustering performance much better than that of single view data. However, at present, multi-view subspace clustering methods develop either a shared consistency representation that models the common properties from all views, or a series of specificity representations each of which mines the intrinsic difference in each view, or global spatial structure of all features, or local geometric structure of multiple features. More seriously, only one kind of information is extracted and utilized in some research work. In this paper, to cope with the issue, we present a multiple kinds of information extraction method (MKIE) for multi-view subspace clustering, which combines the consistency and specificity regularizations with the graph regularizations. We construct some graph structures for the shared consistency representation and all the specificity representations, which model the local geometric structures of multiple features. The model of MKIE makes full use of four kinds of valid information: global spatial structure information, local geometric structure information, consistent feature information and specific feature information. In addition, we design an effective optimization algorithm based on Alternating Direction Method of Multipliers. Extensive experiments performed on four benchmark multi-view datasets validate the effectiveness of MKIE which is compared with ten state-of-the-art multi-view clustering methods.},
  archive      = {J_IJMLC},
  author       = {Zhao, Jianxi and Wang, Xiaonan and Zou, Qingrong and Kang, Fangyuan and Wang, Fan and Peng, Jingfu},
  doi          = {10.1007/s13042-023-01969-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1313-1330},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multiple kinds of information extraction method for multi-view low-rank subspace clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid similarity measure-based clustering approach for
mixed attribute data. <em>IJMLC</em>, <em>15</em>(4), 1295–1311. (<a
href="https://doi.org/10.1007/s13042-023-01968-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mixed attribute clustering, the similarity measure superposition is skewed due to the difference of measuring different attribute types. In this paper, a new clustering approach for mixed attribute data is proposed using hybrid similarity measure. Firstly, a hybrid similarity measure formula is defined using the information entropy, therefore the similarity difference among various attribute types is effectively reduced, and the inclination of similarity measure superposition is alleviated. Secondly, a calculation formula of similarity mean for mixed attributes is defined, which can describe the centralized trend of data distribution, and can be effectively used to merge of clustering clusters. Thus, artificial setting of similarity threshold parameters can be avoided. Thirdly, a novel clustering analysis algorithm for mixed attributes is proposed using hybrid similarity measure and allocation strategy of boundary data objects. In the end, experimental results validate that the algorithm performs well on clustering effect, scalability and anti-noise, as well as the stability and effectiveness of the similarity mean by using UCI, artificial data sets and stellar spectral data sets.},
  archive      = {J_IJMLC},
  author       = {Chu, Kexin and Zhang, Min and Xun, Yaling and Zhang, Jifu},
  doi          = {10.1007/s13042-023-01968-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1295-1311},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid similarity measure-based clustering approach for mixed attribute data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-criteria group decision-making methods with dynamic
probabilistic linguistic information characterized by multiple
consecutive time points. <em>IJMLC</em>, <em>15</em>(4), 1277–1293. (<a
href="https://doi.org/10.1007/s13042-023-01967-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the evolution of complexity in decision-making problems, information is increasingly characterized by dynamic updates. Therefore, we introduce the concept of dynamic probabilistic linguistic term set (DPLTS) to solve the multi-criteria group decision-making (MCGDM) problems with dynamic probabilistic linguistic information characterized by multiple consecutive time points. DPLTS can help experts provide theoretical basis for dynamic decision-making problems. By combining real-time data with analytical models, it can provide decision-makers with effective strategies. Then we present some basic operations and aggregation operators for DPLTSs. The belief interval (BI) interpretation based on Dempster-Shafer evidence theory and BI measure of DPLTSs are also presented to reduce information uncertainty. After that, we construct two MCGDM methods, including the aggregation-based method and the BI method. We use the concept of time degree to reflect the cognition of the importance of multiple consecutive time points for decision-makers and obtain the time weight vector with the help of a nonlinear programming model. Finally, the proposed methods are applied to a case of pharmaceutical innovation capacity evaluation. By the sensitivity analysis of time degree, the characteristics of the methods are summarized and compared, then the effectiveness of the methods is proved.},
  archive      = {J_IJMLC},
  author       = {Dong, Yuanxiang and Cheng, Xiaoting and Xu, Zeshui and Ma, Tianjiao},
  doi          = {10.1007/s13042-023-01967-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1277-1293},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-criteria group decision-making methods with dynamic probabilistic linguistic information characterized by multiple consecutive time points},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Uncertain mean-risk index portfolio selection considering
inflation: Chaos adaptive genetic algorithm. <em>IJMLC</em>,
<em>15</em>(4), 1261–1275. (<a
href="https://doi.org/10.1007/s13042-023-01966-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses a mean-risk index model and the solution algorithm for portfolio selection considering inflation under the uncertain environment. Firstly, we propose an uncertain mean-risk index model considering inflation which is one of the most general multiplicative background risks. To get the optimal solution of the proposed model, we provide a chaos adaptive genetic algorithm (CAGA), which is an improvement of the adaptive genetic algorithm (AGA). Through numerical experiments, the performances of the proposed algorithm are tested. Comparison with other genetic algorithms shows the better performance of the proposed algorithm. Finally, a numerical example is given to demonstrate the application of the proposed model.},
  archive      = {J_IJMLC},
  author       = {Choe, Kwang-Il and Huang, Xiaoxia and Ma, Di},
  doi          = {10.1007/s13042-023-01966-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1261-1275},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uncertain mean-risk index portfolio selection considering inflation: Chaos adaptive genetic algorithm},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quick reduct with multi-acceleration strategies in
incomplete hybrid decision systems. <em>IJMLC</em>, <em>15</em>(4),
1227–1260. (<a
href="https://doi.org/10.1007/s13042-023-01965-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, discovering knowledge from incomplete and mixed complex systems is an important research topic that has always been the focus and favor of researchers. Attribute reduction is one of the important research contents in the fields of knowledge discovery, data mining and etc. For improving the performance of attribute reduction, some scholars have proposed many approaches and acceleration mechanisms. As an effective data processing model, the matrix has some bottlenecks in obtaining the reduct efficiently, and there is less research on its accelerated reduction strategies and algorithms. Therefore, the main motivation of this article is to explore and apply various acceleration strategies in matrix reduction methods to improve the efficiency of knowledge discovery in incomplete hybrid decisions systems (IHDSs). First, for incomplete mixed data, the combination tolerance relation is presented. Based on the combination tolerance relation, the corresponding operations and properties of the related matrix are studied, and a matrix-based positive region reduction method is proposed. Next, we develop the incremental computing strategy for updating the matrices to avoid re-calculation and the gradually reducing processing scale strategy for compressing the processing volume in the reduction process; then, two types of matrix-based heuristic reduction acceleration algorithms are designed to obtain a reduct of IHDSs. Finally, some experiments are carried out on nine typical data sets in 15 UCI data sets to verify the effectiveness and efficiency of proposed algorithms.},
  archive      = {J_IJMLC},
  author       = {Ge, Hao and Yang, Chuanjian and Xu, Yi and Peng, Gongjian},
  doi          = {10.1007/s13042-023-01965-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1227-1260},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Quick reduct with multi-acceleration strategies in incomplete hybrid decision systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CoDF-net: Coordinated-representation decision fusion network
for emotion recognition with EEG and eye movement signals.
<em>IJMLC</em>, <em>15</em>(4), 1213–1226. (<a
href="https://doi.org/10.1007/s13042-023-01964-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physiological signals, such as EEG and eye movements, have emerged as promising research topics in emotion recognition due to their inherent advantages of objectivity, high recognition accuracy, and cost-effectiveness. However, most existing methods for fusing EEG and eye movement signals use concatenation or weighted summation, which may lead to information loss and limited ability to resist noise. To tackle this issue, in this paper, we propose a Coordinated-representation Decision Fusion Network (CoDF-Net) to efficiently fuse the representation of EEG and eye movement signals. Specifically, CoDF-Net first learns personalized information by maximizing the correlation between modalities. Next, the Decision-level Fusion Broad Learning System (DF-BLS) is developed to construct multiple sub-systems to obtain the final emotional states via the effective decision-making mechanism. To evaluate the performance of the proposed method, subject-dependent and subject-independent experiments are designed on two public datasets. Extensive experiments demonstrate that the proposed method has superior emotion recognition performance over traditional approaches and current state-of-the-art methods. The CoDF-Net achieves 94.09 and 91.62% in the subject-dependent setting and 87.04 and 83.87% in the subject-independent setting on the SEED-CHN and SEED-GER datasets, respectively. Moreover, it is found that the proposed method exhibits a more significant ability to resist noise by adding Gaussian noise with different standard deviations.},
  archive      = {J_IJMLC},
  author       = {Gong, Xinrong and Dong, Yihan and Zhang, Tong},
  doi          = {10.1007/s13042-023-01964-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1213-1226},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CoDF-net: Coordinated-representation decision fusion network for emotion recognition with EEG and eye movement signals},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A k-nearest neighbor attentive deep autoregressive network
for electricity consumption prediction. <em>IJMLC</em>, <em>15</em>(4),
1201–1212. (<a
href="https://doi.org/10.1007/s13042-023-01963-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electricity is vital in daily life and crucial for sustainable economic development. Accurate forecasting of energy consumption ensures efficient electricity system operation and supports strategic decision-making for energy distribution. Current time-series methods neglect the influence of neighboring regions’ electricity consumption and the varying impact levels caused by multiple factors on the target area. Therefore, we propose the k-nearest neighbor attentive deep autoregressive network (KNNA-DeepAR) model, which combines a k-nearest neighbor approach with an attentive deep autoregressive network, to achieve precise short-term electricity consumption predictions. By extracting informative features from historical time-series data, we incorporate electricity consumption data from the k regions closest to the target area as additional variables. Leveraging the attention mechanism, we assign varying weights to each variable to capture their interdependencies. Experimental results on a public dataset of electricity loads in fourteen U.S. regions demonstrate the superiority of our model. Compared to state-of-the-art time-series models, our model achieves higher predictive accuracy and exhibits significant potential as an effective approach for accurately predicting electricity consumption and other time-series tasks.},
  archive      = {J_IJMLC},
  author       = {Qiu, Xihe and Ru, Yajun and Tan, Xiaoyu and Chen, Jue and Chen, Bin and Guo, Yun},
  doi          = {10.1007/s13042-023-01963-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1201-1212},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A k-nearest neighbor attentive deep autoregressive network for electricity consumption prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entropy based swarm intelligent searching for scheduling
deadline constrained workflows in hybrid cloud. <em>IJMLC</em>,
<em>15</em>(4), 1183–1199. (<a
href="https://doi.org/10.1007/s13042-023-01962-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of scheduling tasks of workflows to heterogeneous VMs (virtual machine) in a hybrid cloud. Workflow scheduling in a hybrid cloud is complex due to factors such as varying electricity prices, uncertain resource requirements, and workflow-specific budget and deadline constraints. To address these challenges, we propose a novel intelligent searching algorithm framework, SEPSO (Swarm Entropy based Particle Swarm Optimization). SEPSO enhances the scheduling process by introducing a swarm entropy, a measure that takes into account the diversification of each iteration. Additionally, we develop rules for sorting workflows and tasks that consider the budget and deadline constraints of each workflow. An iteration-varying flight parameter mechanism is also introduced to balance intensification and diversification during the search process. The components and parameters of our proposed algorithm were statistically calibrated using a comprehensive set of random instances. We then compared SEPSO to adapted existing algorithms for similar problems. Our experimental results demonstrate that SEPSO is effective for the considered problem, offering a solution to workflow scheduling that is more time efficient than traditional particle swarm optimization (PSO) algorithms.},
  archive      = {J_IJMLC},
  author       = {Li, He and Li, Xiaoping and Xu, Jingwen and Chen, Long},
  doi          = {10.1007/s13042-023-01962-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1183-1199},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Entropy based swarm intelligent searching for scheduling deadline constrained workflows in hybrid cloud},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A literature review on deep learning algorithms for analysis
of x-ray images. <em>IJMLC</em>, <em>15</em>(4), 1165–1181. (<a
href="https://doi.org/10.1007/s13042-023-01961-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the invention of the X-ray beam, it has been used for useful applications in various fields, such as medical diagnosis, fluoroscopy, radiation therapy, and computed tomography. In addition, it is also widely used to identify prohibited or illegal materials using X-ray imaging in the security field. However, these procedures are generally dependent on the human factor. An operator detects prohibited objects by projecting pseudo-color images onto a computer screen. Because these processes are prone to error, much work has gone into automating the processes involved. Initial research on this topic consisted mainly of machine learning and methods using hand-crafted features. The newly developed deep learning methods have subsequently been more successful. For this reason, deep learning algorithms are a trend in recent studies and the number of publications has increased in areas such as X-ray imaging. Therefore, we surveyed the studies published in the literature on Deep Learning-based X-ray imaging to attract new readers and provide new perspectives.},
  archive      = {J_IJMLC},
  author       = {Seyfi, Gokhan and Esme, Engin and Yilmaz, Merve and Kiran, Mustafa Servet},
  doi          = {10.1007/s13042-023-01961-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {1165-1181},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A literature review on deep learning algorithms for analysis of X-ray images},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-source credit data fusion approach based on
federated distillation learning. <em>IJMLC</em>, <em>15</em>(3),
1153–1164. (<a
href="https://doi.org/10.1007/s13042-023-02032-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance and privacy disclosure shortcomings have become the main problems in the process of multi-source credit data fusion, the former causes conflicts during the fusion process, the latter brings huge security risks. While federated learning is used for data privacy protection, communication cost defects and inaccurate fusion results will follow. In order to effectively unify data fusion, the paper proposes an approach based on federated distillation learning, which uses synthetic distillation data instead of traditional parameter transfer models to fuse to reduce time cost and improve accuracy without compromising data privacy,simultaneously utilizing local data to train the model and conducting interactive learning with the server&#39;s model. Specifically, it uses a decision tree model to distill knowledge from credit data, replacing the traditional parameter transfer model. At the same time, the Generic Adversarial Network is used to balance data distribution and solve the problem of data imbalance on the server. The experimental results show that the method proposed has improved both utilization performance and unbalanced data processing by at least 3%.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xiaodong and Sun, Zhoubao and Mao, Lin and Li, Xiaoping},
  doi          = {10.1007/s13042-023-02032-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1153-1164},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-source credit data fusion approach based on federated distillation learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PaIaNet: Position-aware and identification-aware network for
low-light salient object detection. <em>IJMLC</em>, <em>15</em>(3),
1137–1151. (<a
href="https://doi.org/10.1007/s13042-023-01960-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to insufficient photons and undesirable noise, salient objects in low-light scenes are ambiguous, thus limiting the performance of existing salient object detection (SOD) works. To solve this problem, inspired by the hunting mechanism of predators in biology, we propose a position-aware and identification-aware network (PaIaNet) for SOD. First, we design a position-aware decoder (PaD) for obtaining position encodes by locating the edges and main bodies of salient objects. Second, we construct an identification-aware decoder (IaD) to reason accurate saliency maps by aggregating adjacent features under the guidance of position encodes. Moreover, we propose a reverse loss to suppress background interference effectively. Extensive experiments demonstrate that our method performs favorably from comparisons of qualitative and quantitative evaluations against other state-of-the-art methods in SOD of low-light images, and even achieves competitive performance when extended to normal-light scenes. Code will be available at https://github.com/yuehuihui000/PaIaNet .},
  archive      = {J_IJMLC},
  author       = {Yue, Huihui and Guo, Jichang and Yin, Xiangjun and Zhang, Yi and Zheng, Sida},
  doi          = {10.1007/s13042-023-01960-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1137-1151},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PaIaNet: Position-aware and identification-aware network for low-light salient object detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MFGAN: Towards a generic multi-kernel filter based
adversarial generator for image restoration. <em>IJMLC</em>,
<em>15</em>(3), 1113–1136. (<a
href="https://doi.org/10.1007/s13042-023-01959-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a growing interest in the use of Generative Adversarial Networks (GANs). Thanks to their outstanding performance in image translation and generation, they play an increasingly important role in computer vision applications. Most approaches based on GAN focus on proposing task-specific auxiliary modules or loss functions that are tailored to address various challenges of a single application, but often do not perform better when evaluated to improve other image generation tasks. Moreover, the basic ResNet and U-Net based GAN generators reach their limits in many image restoration and enhancement use cases. Therefore, in this paper, we propose a generic GAN referred to as Multi-Kernel Filter-based Conditional Generative Adversarial Network (MFGAN). We develop a new GAN generator with multiple CNN streams to extract more relevant and discriminative features related to the studied task. The proposed MFNet generator consists of two CNN modules, feature extraction and feature compression, which are combined to connect both the GAN encoder and decoder. It considers the strengths of conventional layers at different scale levels with multi-kernel filtering to capture high to low feature frequencies that reflect the complex image degradations and structural image details. Extensive experiments on five challenging applications for image enhancement, image restoration, and infrared image translation demonstrate the superiority and effectiveness of the proposed MFGAN in removing image degradation and generating visually appealing fake images. Our MFGAN quantitatively outperforms both state-of-the-art GANs and other CNN-based architectures in all tested benchmarks.},
  archive      = {J_IJMLC},
  author       = {Chahi, Abderrazak and Kas, Mohamed and Kajo, Ibrahim and Ruichek, Yassine},
  doi          = {10.1007/s13042-023-01959-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1113-1136},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MFGAN: Towards a generic multi-kernel filter based adversarial generator for image restoration},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new formulation for second-order cone programming support
vector machine. <em>IJMLC</em>, <em>15</em>(3), 1101–1111. (<a
href="https://doi.org/10.1007/s13042-023-01958-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new second-order cone programming (SOCP) formulation inspired by the soft-margin linear programming support vector machine (LP-SVM) formulation and cost-sensitive framework is proposed. Our proposed method maximizes the slack variables related to each class by appropriately relaxing the bounds on the VC dimension using the l $$_{\infty }$$ -norm, and penalizes them using the corresponding regularization parametrization to control the trade-off between margin and slack variables. The proposed method has two main advantages: firstly, a flexible classifier is constructed that extends the advantages of the soft-margin LP-SVM problem to the second-order cone; secondly, due to the elimination of a conic restriction, only two SOCP problems containing second-order cone constraints need to be solved. Thus similar results to the SOCP-SVM problem are obtained with less calculational effort. Numerical experiments show that our method achieves the better classification performance than the conventional SOCP-SVM formulations and standard linear SVM formulations.},
  archive      = {J_IJMLC},
  author       = {Zong, Zemin and Mu, Xuewen},
  doi          = {10.1007/s13042-023-01958-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1101-1111},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new formulation for second-order cone programming support vector machine},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-domain transferable discriminant dictionary based
sparse representation approach for EEG emotion-level recognition.
<em>IJMLC</em>, <em>15</em>(3), 1087–1099. (<a
href="https://doi.org/10.1007/s13042-023-01957-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion is usually caused by complex psychological and physiological changes triggered by external stimuli. It is considered one of the abilities to guide one&#39;s thinking and action. Emotion-level recognition realizes psychological perception and evaluation by collecting various data characteristics of individual behavior and physiological level, and reversely deriving complex physiological psychological mapping. Emotional Electroencephalogram (EEG) signals are not easy to be hidden and forged, and using them for emotion-level recognition has high application value. However, EEG data are often collected in complex environments and scenes, and there are strong time and individual differences in EEG signals. This study proposes a cross-domain transferable discriminant dictionary based sparse representation (CTDDSR) approach for EEG emotion-level recognition. CTDDSR utilizes subspace projection strategy to find a suitable projection subspace. In this subspace, CTDDSR learns the shared dictionary to construct a strong connection between the source and target domains in the framework of dictionary based sparse representation. Different from the traditional projection matrices are completely domain-specific, our projection matrix for each domain is the combination of the domain-specific component and domain-invariable component. The former component is used to retain the individual domain information. By maximizing the cross-domain reconstruction error, the latter component is used to exploit the discriminant knowledge across domains in the shared latent subspace. In addition, to obtain the discriminant dictionary in the subspace, CTDDSR introduces linear discriminant analysis (LDA) to ensure the minimum of the intra-class reconstruction error and the maximum of the inter-class reconstruction error on sparse coding coefficients within each domain. Cross-domain EEG emotion-level recognition experiments are performed on the real EEG emotion dataset and verified that CTDDSR has excellent recognition performance.},
  archive      = {J_IJMLC},
  author       = {Ni, Tongguang and He, Chengbing and Jiang, Yizhang and Gu, Xiaoqing},
  doi          = {10.1007/s13042-023-01957-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1087-1099},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cross-domain transferable discriminant dictionary based sparse representation approach for EEG emotion-level recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fedmpo: Federated optimization based on multidimensional
especially 3-dimensional proximal operator. <em>IJMLC</em>,
<em>15</em>(3), 1075–1085. (<a
href="https://doi.org/10.1007/s13042-023-01956-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning is a cutting-edge machine learning framework that enables multiple organizations to model data usage and conduct learning tasks while ensuring user privacy protection, data security, and compliance with government regulations. In this study, we propose a novel federated learning algorithm, FedMPO, to address the critical challenge of data heterogeneity among clients, which can lead to inconsistent optimized local models. FedMPO is a versatile multi-dimensional loss function that leverages the 3-dimensional proximal operator to fit a stationary and rapidly convergent loss function using Taylor expansion. As a general loss function, FedMPO can be applied to popular federated learning algorithms, such as FedAvg, FedProx, SCAFFOLD, FedDyn, and FedDC, to enhance the accuracy and stability of secure aggregation. Extensive experiments show that FedMPO can improve accuracy scores(almost 0.02–0.33 and 0.02–0.45 percent improvements on full and partial client participation, respectively) on some common evaluation data sets with various settings and also has robust in partial participation settings, non-iid data and heterogeneous clients in the same time.},
  archive      = {J_IJMLC},
  author       = {Jiang, Fazhen and Yang, Xiaoyuan and Li, Yixiao and Li, Luxuan},
  doi          = {10.1007/s13042-023-01956-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1075-1085},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fedmpo: Federated optimization based on multidimensional especially 3-dimensional proximal operator},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new compatibility model for fuzzy group decision making by
using trapezoidal fuzzy preference relations with COWA operator.
<em>IJMLC</em>, <em>15</em>(3), 1055–1073. (<a
href="https://doi.org/10.1007/s13042-023-01955-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the conflicting opinions and different risk attitudes among decision-makers (DMs) in group decision making (GDM), this paper develops a novel compatibility model with additive trapezoidal fuzzy environment based on continuous ordered weighted averaging (COWA) operator to handle the conflicts. First, some concepts of COWA operator-based compatibility index and characteristic preference relation for additive trapezoidal fuzzy preference relation (ATFPR) are discussed. Then a compatibility reaching algorithm is designed to assist each ATFPR in achieving acceptable compatibility. Moreover, the expert weight optimization model based on the criterion of minimum compatibility of preference relation in GDM is established. Furthermore, a GDM process based on compatibility measures with ATFPRs is introduced, and an application of the proposed approach is put forward. The novelties of our approach are that: (1) COWA operator can deal with the compatibility of all arguments by using controlled parameters that consider the risk attitudes of DMs rather than the compatibility of the simply two points in intervals; (2) compatibility improving algorithm makes sure that the original opinions are retained as much as possible because only one pair of preference relation elements are revised in each round; (3) optimal weights model ensures that weights of DMs in group aggregation are determined availably.},
  archive      = {J_IJMLC},
  author       = {Zhou, Yuanyuan and Zheng, Chengli and Wu, Peng and Zhou, Ligang},
  doi          = {10.1007/s13042-023-01955-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1055-1073},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new compatibility model for fuzzy group decision making by using trapezoidal fuzzy preference relations with COWA operator},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast fixed granular-ball for attribute reduction in label
noise environments and its application in medical diagnosis.
<em>IJMLC</em>, <em>15</em>(3), 1039–1054. (<a
href="https://doi.org/10.1007/s13042-023-01954-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although neighborhood rough set(NRS) based attribute reduction methods have achieved excellent performance in many scenarios, the efficiency and robustness of these methods have not attracted much attention. In this study, we propose a fast fixed granular-ball model (FFGB) for attribute reduction in label noise environments. In FFGB, we propose a fast neighborhood search mechanism to improve the efficiency of NRS. This fast mechanism reduces the neighborhood search range from the universe to a neighborhood and reduces the time complexity of the neighborhood calculation to much less than $$O(n^2)$$ . Based on the fast mechanism, we propose FFGB model whose definitions are relaxed to be robust to against label noise. In addition, a FFGB attribute reduction algorithm is designed. Finally, we apply the FFGB attribute reduction to medical diagnosis. The experimental results indicate that FFGB is more efficient and robust than the comparison methods.},
  archive      = {J_IJMLC},
  author       = {Peng, Xiaoli and Wang, Ping and Shao, Yabin and Gong, Yuanlin and Qian, Jie},
  doi          = {10.1007/s13042-023-01954-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1039-1054},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fast fixed granular-ball for attribute reduction in label noise environments and its application in medical diagnosis},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel model for enhancing cloud security and data
deduplication using fuzzy and refraction learning based chimp
optimization. <em>IJMLC</em>, <em>15</em>(3), 1025–1038. (<a
href="https://doi.org/10.1007/s13042-023-01953-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the digitalization process generates an enormous amount of multimedia data that turn out to be further difficult to manage. The current developments in big data technology and the cloud computing (CC) field produce massive growth in cloud data. The accessible memory space was used by the enormous replication data and generates the highest computation cost which is the most important problem in the constrained cloud storage space. Therefore, in this study, we introduced a novel secure cloud data deduplication (SCDD) approach to improve data security and data storage of the cloud environment by generating optimal key and deduplicating files respectively. The proposed approach mainly focuses on reducing computational cost and memory utilization of the cloud application. Here, the utilized data files are encrypted using the proxy re-encryption approach, and the refraction learning-based chimp optimization (RL-CO) algorithm is utilized for optimal key generation process as a result it guarantees better cloud security to the end users to store data on the cloud. Subsequently, the optimal verified fuzzy keyword search (OVFKS) approach is proposed to eliminate duplicate files or copies of actual data thereby enhancing the cloud storage space considerably. The proposed secure cloud data deduplication-based optimal verified fuzzy keyword search (SCDD-OVFKS)approach utilizes three different data files namely android application data, audio files, and mixed application data files, audio files, and other relevant files as the input. Furthermore, the proposed approach’s performance is validated using different performance measures namely computational time, computational cost, search time cost, memory utilization, and deduplication rate by examining other state-of-art approaches. As a result, the proposed SCDD-OVFKS approach achieves a maximum deduplication rate of about 28.6% for 8 MB along with minimum computational cost and reduced memory utilization than other state-of-art approaches.},
  archive      = {J_IJMLC},
  author       = {Thottipalayam Andavan, Mohanaprakash and Parameswari, M. and Subramanian, Nalini and Vairaperumal, Nirmalrani},
  doi          = {10.1007/s13042-023-01953-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1025-1038},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel model for enhancing cloud security and data deduplication using fuzzy and refraction learning based chimp optimization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-discriminator conditional giza pyramids construction
generative adversarial network based traffic density recognition using
road vehicle images. <em>IJMLC</em>, <em>15</em>(3), 1007–1024. (<a
href="https://doi.org/10.1007/s13042-023-01952-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic density recognition is a computer vision task that involves detecting and estimating the density of vehicles in a given traffic scene. Traffic jam is a problem regularly faced by the public, mainly those living in crowded cities. For effective traffic management and signal control, it is necessary to know the road traffic density, particularly in overcrowded cities. Several methods were proposed for traffic density recognition, but the existing approaches inaccurately recognize the traffic density. Therefore, a Dual-discriminator Conditional giza pyramids construction Generative Adversarial Network based-Traffic Density Recognition (DCGAN-TDR) using road vehicle images is proposed for effective homogeneous and heterogeneous traffic density recognition. The input data is taken from the road vehicle images dataset, and its undesirable noises are removed with the help of anisotropic diffusion kuwahara filtering based preprocessing. For effective segmentation, the hesitant fuzzy linguistic bi-objective clustering method is used. Then the histogram of block multi-scale uniform local binary pattern is used for local feature representation, and for feature reduction two-directional two-dimension principal component analysis is used. The Dual-discriminator Conditional Generative Adversarial Network (DCGAN) is used to classify the data as homogeneous and heterogeneous. Giza pyramids construction optimization is used to optimize the loss function of DCGAN to reduce the loss function and to enhance the accuracy. Then, the performance metrics such as accuracy, precision, recall, computational time and loss are evaluated to estimate the efficiency of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Gawali, Tukaram K. and Deore, Shailesh S.},
  doi          = {10.1007/s13042-023-01952-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1007-1024},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual-discriminator conditional giza pyramids construction generative adversarial network based traffic density recognition using road vehicle images},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hierarchical algorithm for calculating approximation regions
based on granular computing. <em>IJMLC</em>, <em>15</em>(3), 985–1005.
(<a href="https://doi.org/10.1007/s13042-023-01951-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three approximation regions, namely positive region, negative region, and boundary region are fundamental concepts in rough set theory. How to calculate three approximation regions effectively is a crucial issue. Granular computing emphasizes solving a complex problem at multiple levels of granularity or abstraction, which can simplify the problem solving. Based on granular computing, we propose a hierarchical algorithm to calculate three approximation regions, which is fast and cost-sensitive. First, we construct three knowledge representation levels. Second, based on three knowledge representation levels, we calculate three approximation regions hierarchically. Considering the dynamic variation of objects is very common in real applications, we propose incremental hierarchical algorithms to calculate three approximation regions dynamically. At a high level of knowledge representation levels with coarse granularity, the proposed hierarchical algorithms can obtain inaccurate results with high efficiency and low cost. At a low level of knowledge representation levels with fine granularity, the proposed hierarchical algorithms can obtain accurate results with low efficiency and high cost. From high level to low level, we calculate three approximation regions hierarchically, reducing the computational complexity and cost. Experimental results demonstrate the effectiveness of the proposed algorithms.},
  archive      = {J_IJMLC},
  author       = {Xu, Yi and Zhang, Jie and Sun, Weikang},
  doi          = {10.1007/s13042-023-01951-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {985-1005},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical algorithm for calculating approximation regions based on granular computing},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Segmentation-based context-aware enhancement network for
medical images. <em>IJMLC</em>, <em>15</em>(3), 963–983. (<a
href="https://doi.org/10.1007/s13042-023-01950-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic medical image segmentation plays a pivotal role in clinical diagnosis. In the past decades, medical image segmentation has made remarkable improvements with the aid of convolutional neural networks (CNNs). However, extracting context information and disease features for dense segmentation remains a challenging task because of the low contrast between lesions and the background of the medical images. To address this issue, we propose a novel enhanced feature fusion scheme in this work. First, we develop a global feature enhancement modTule, which captures the long-range global dependencies of the spatial domains and enhances global features learning. Second, we propose a channel fusion attention module to extract multi-scale context information and alleviate the incoherence of semantic information among different scale features. Then, we combine these two schemes to produce richer context information and to enhance the feature contrast. In addition, we remove the decoder with the progressive deconvolution operations from classical U-shaped networks, and only utilize the features of the last three layers to generate predictions. We conduct extensive experiments on three public datasets: the poly segmentation dataset, ISIC-2018 dataset, and the Synapse Multi-Organ Segmentation dataset. The experimental results demonstrate superior performance and robustness of our method in comparison with state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Bao, Hua and Li, Qing and Zhu, Yuqing},
  doi          = {10.1007/s13042-023-01950-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {963-983},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Segmentation-based context-aware enhancement network for medical images},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A top-k formal concepts-based algorithm for mining positive
and negative correlation biclusters of DNA microarray data.
<em>IJMLC</em>, <em>15</em>(3), 941–962. (<a
href="https://doi.org/10.1007/s13042-023-01949-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing and understanding large and complex volumes of biological data is a challenging task as data becomes more widely available. In biomedical research, gene expression data are among the most commonly used biological data. Formal concept analysis frequently identifies deferentially expressed genes in microarray data. Top-K formal concepts are effective at producing effective Formal Concepts. To our knowledge, no existing algorithm can complete the difficult task of identifying only important biclusters. For this purpose, a new Top-K formal concepts-based algorithm for mining biclusters from gene expression data is proposed: Top-BicMiner. It extracts biclusters’ sets with positively and negatively correlated genes according to distinct correlation measures. The proposed method is applied to both synthetic and real-life microarray datasets. The experimental results highlight the Top-BicMiner’s ability to identify statistically and biologically significant biclusters.},
  archive      = {J_IJMLC},
  author       = {Houari, Amina and Ben Yahia, Sadok},
  doi          = {10.1007/s13042-023-01949-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {941-962},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A top-K formal concepts-based algorithm for mining positive and negative correlation biclusters of DNA microarray data},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FF-GLAM-cs: A fusion framework based on GLAM with channel
shuffle for speech emotion recognition. <em>IJMLC</em>, <em>15</em>(3),
929–940. (<a href="https://doi.org/10.1007/s13042-023-01948-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the support of artificial intelligence, speech emotion recognition is integrated into people’s daily lives in the form of smart speakers. Some high-accuracy models have poor applicability due to their large size. However, the accuracy of lightweight models is unsatisfactory. In this article, an integrated framework based on GLobal-Aware Multiscale with channel shuffle (FF-GLAM-cs) is proposed, fusing multiple lightweight models to ensure a small size and high accuracy. Channel shuffle is added to solve the computational duplication caused by multiscale convolution. In addition, a fuzzy integral fusion method is adopted that describes the interactions of classifiers ignored by traditional methods. The impact of different combinations of classifiers is analyzed. In experiments, the performance of the new model and the effect of fusion are verified by the model to four speech emotion datasets. The model is validated and analyzed with parameter and ablation testing, kernel model comparisons and fusion verification. The results show that FF-GLAM-cs is superior to state-of-the-art methods in terms of accuracy and efficiency. In particular, the fusion module presents excellent improvements in accuracy. The source code of this work is available at https://github.com/zhishen33/GLAM-cs-and-FI-for-SER.git .},
  archive      = {J_IJMLC},
  author       = {Wang, Jinfeng and Zheng, Zhishen and Liang, Yong and Qin, Jing and Wang, Wenzhong},
  doi          = {10.1007/s13042-023-01948-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {929-940},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {FF-GLAM-cs: A fusion framework based on GLAM with channel shuffle for speech emotion recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Target adaptive extreme learning machine for transfer
learning. <em>IJMLC</em>, <em>15</em>(3), 917–927. (<a
href="https://doi.org/10.1007/s13042-023-01947-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme learning machines (ELM) have been applied in several fields due to their simplicity and computational efficiency. However, ELM hurts the performance in cross-domain learning problems similar to most machine learning algorithms. In this paper, we mainly focus on the semi-supervised transfer learning algorithm under ELM framework. Unlike other transfer learning methods employed both source and target domains, we propose a target adaptive ELM (TAELM) of learning a high-quality target-specific classifier with less resources. We formulate a novel objective function to obtain a target-specific classifier by introducing a knowledge transfer term on a pre-trained source model and a graph laplacian-based manifold regularization term on the target domain, while its solution are analytically determined without loss of the computing efficiency and learning ability of traditional ELM. In our experiments, we verify the effectiveness of the proposed approach by using a deep neural network model as feature extractor for both domains. Experimental results demonstrate that our method with less resources significantly outperforms other state-of-the-art algorithms.},
  archive      = {J_IJMLC},
  author       = {Ri, Jong Hyok and Kang, Tok Gil and Choe, Chol Ryong},
  doi          = {10.1007/s13042-023-01947-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {917-927},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Target adaptive extreme learning machine for transfer learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on a hierarchical intervention algorithm for
violent crime based on CLGA-net. <em>IJMLC</em>, <em>15</em>(3),
897–915. (<a href="https://doi.org/10.1007/s13042-023-01946-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve scientific and intelligent hierarchical intervention of violent criminals, this paper proposes a deep feature fusion model called the Convolutional Long Short Term Gated Attention Network (CLGA-Net), for violent crime temperament classification. First, the CNN is reconstructed to improve local feature extraction. We combine eigenvectors by filtering word vectors with multiple kernel sizes and convoluting separately to obtain feature maps with different granularities. Second, a multi-model fusion algorithm with attention mechanism is proposed by reconstructing CNN. After concatenate layer, Bi-LSTM and Bi-GRU are combined with Multi-Head Attention, and parallelly combined LSTM and GRU with Self-Attention to capture various structural patterns effectively in text sequences. Then, global average pooling layer is used to solve the overfitting of the traditional fully connected layer. Finally, after the softmax classifier, the arithmetic average algorithm is used to obtain the final classification result. To verify the performance of the proposed model, CLGA-Net was compared with other baseline models. The results show that CLGA-Net achieves the optimal effect under all evaluation indices with an accuracy of 99.25%. The AUC values under the macro average and micro average are 99.03% and 99.81%, respectively. By analyzing crime facts, CLGA-Net shows good violent crime temperament classification ability. Regulatory departments can develop a personalized correctional education program according to the type of attribution obtained. Therefore, the CLGA-Net model proposed in this paper can provide an accurate and scalable computerized hierarchical intervention service for offenders.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jiawei and Gao, Guandong and Xiao, Ke and Song, Shengzun},
  doi          = {10.1007/s13042-023-01946-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {897-915},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Research on a hierarchical intervention algorithm for violent crime based on CLGA-net},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiformer-based hybrid learning with outlier re-assignment
for unsupervised person re-identification. <em>IJMLC</em>,
<em>15</em>(3), 879–896. (<a
href="https://doi.org/10.1007/s13042-023-01945-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown the effectiveness of generating pseudo-labels by measuring feature similarity in unsupervised person re-identification (ReID). However, most of these methods ignore the distribution discrepancy among cameras, which leads to degraded accuracy in generated pseudo-labels. Besides, limited by the small receptive field and downsampling operations, the convolution-based schemes cannot effectively capture fine-grained information and global dependencies. In this paper, we propose multiformer-based hybrid learning with outlier re-assignment (MHOR) for unsupervised person ReID. Firstly, to mitigate the distribution discrepancy among cameras, we design a multi-branch transformer (Multiformer) network, including inter-camera transformer (Interformer) and intra-camera transformer (Intraformer). The Multiformer network allows the computation of feature similarity to be performed separately for inter-camera and intra-camera scenarios. Secondly, to further enhance the fine-grained information and global dependencies feature representation in the context of Multiformer, a dynamic outlier re-assignment (DORA) strategy is proposed to reassign pseudo-labels by computing the affinity matrix of outlier samples with cluster centers. Thirdly, to improve the quality of pseudo-labels, we propose hybrid contrastive learning (HCL), which uses instance-level contrastive learning to distinguish different pedestrian features and introduces cluster-level contrastive learning to alleviate the unreliability problem caused by noisy labels. Finally, extensive experiments show that MHOR can significantly surpass the performance of previous works on unsupervised tasks for person ReID.},
  archive      = {J_IJMLC},
  author       = {Jiang, Min and Zhang, Qian and Kong, Jun},
  doi          = {10.1007/s13042-023-01945-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {879-896},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multiformer-based hybrid learning with outlier re-assignment for unsupervised person re-identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A double-layer attentive graph convolution networks based on
transfer learning for dynamic graph classification. <em>IJMLC</em>,
<em>15</em>(3), 863–877. (<a
href="https://doi.org/10.1007/s13042-023-01944-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical scenarios, many graphs dynamically evolve over time. The new node classification without labels and historical information is challenging. To address this challenge, we design a double-layer attentive graph convolutional network (DLA-GCN) based on the transfer learning, which mainly includes three deep learning components: the double-layer graph convolutional network (DLGCN), node multi-parameter learning (NMPL) algorithm, and domain-adversarial transfer learning (DATL) method. In terms of dynamic spatial correlation, DLGCN jointly exploits the pre-defined and adaptive adjacency matrix to capture local and global feature aggregation. An inter-graph attention mechanism is further used to produce a unified representation for each node in graphs by automatically merging different spatial correlations. To reduce the complexity and improve accuracy, the matrix decomposition method is designed to learn the node-specific patterns of nodes in the NMPL component. In terms of dynamic time correlation, DATL is proposed to learns and transfers similar features as historical information of new nodes by optimizing three different loss functions, namely source classifier loss, domain classifier loss, and target classifier loss as a whole. The experimental results on two real-world graph classification datasets show that the proposed approach can improve the accuracy by 18% and 10%, respectively, compared with the state-of-art baselines.},
  archive      = {J_IJMLC},
  author       = {Yao, Lei and Guo, Da and Wang, Xing and Zhu, Lin and Feng, Junlan and Zhang, Yong},
  doi          = {10.1007/s13042-023-01944-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {863-877},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A double-layer attentive graph convolution networks based on transfer learning for dynamic graph classification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature augmentation and scale penalty for tiny floating
detection. <em>IJMLC</em>, <em>15</em>(3), 853–862. (<a
href="https://doi.org/10.1007/s13042-023-01943-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapidly increasing concerns about the impact of tiny floating objects on water health has prompted the need for more effective detection methods. The main challenge in detecting these objects is their small size, accounting for only 0.5% of the image, which significantly hampers detection efforts. Moreover, existing object detectors utilize the intersection over union (IOU) as the bounding box regression loss to enhance object localization accuracy. However, this approach penalizes larger objects more heavily than smaller ones, leading to imbalanced regression losses. To address these issues, we propose enhancements to the YOLOv4 model. Our approach incorporates the following key improvements. Firstly, we introduce a feature augmentation module (FAM) to capture multi-scale contextual features of tiny objects and low-level features. This helps overcome the challenge of limited representation of tiny objects in the deeper layers of the network. Additionally, we integrate a convolutional block attention module (CBAM) into the path aggregation network to prevent the flooding of conflicting information in the fusion of features at different levels, ensuring an accurate representation of tiny object features. Finally, we propose a scale penalty function to address the issue of imbalanced regression loss. Experimental results demonstrate that our improved model achieves impressive detection performance on the Flow-RI dataset, specifically for detecting small-scale objects. These findings highlight the efficacy of our proposed methodology in enhancing the detection of tiny floating objects and contribute to the overall goal of improving water health.},
  archive      = {J_IJMLC},
  author       = {Li, Ke and Wang, Yining and Li, Wang and Shen, Siyuan and Duan, Shukai and Wang, Lidan},
  doi          = {10.1007/s13042-023-01943-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {853-862},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature augmentation and scale penalty for tiny floating detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HFAN: High-frequency attention network for hyperspectral
image denoising. <em>IJMLC</em>, <em>15</em>(3), 837–851. (<a
href="https://doi.org/10.1007/s13042-023-01942-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last decades, learning-based deep neural network (DNN) has shown its advantages on hyperspectral image (HSI) denoising. Compared to classical prior-based methods, DNN-based algorithms employ a larger scale of training samples for learning to simulate the complex image generation process with higher accuracy. However, most DNN-based HSI denoising methods are designed by a superposition convolution layer, which cannot fully use the frequency information in the image itself, especially the information containing a strong response to noise in high-frequency domain. Thus, we propose a high-frequency attention network (HFAN) assisted by both spectral and spatial high-frequency information to achieve accurate HSIs denoising in this paper. Our proposed HFAN comprises a high-frequency and denoising branch, and the auxiliary function of high-frequency information is realized by transmitting the characteristic information of the high-frequency component to the denoising branch. Specifically, the spatial-spectral attention (SSA) module is presented to recover more detail in space and spectra. Experiments on synthetic and real HSI data show that our proposed HFAN achieves better denoising results compare to the other advanced methods.},
  archive      = {J_IJMLC},
  author       = {Yang, Chuansheng and Zhang, Chao and Shen, Haozhen and Peng, Tong and Wang, Chao and Deng, Liangjian and Chen, Hongming and He, Liangtian},
  doi          = {10.1007/s13042-023-01942-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {837-851},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {HFAN: High-frequency attention network for hyperspectral image denoising},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep feature network with multi-scale fusion for highly
congested crowd counting. <em>IJMLC</em>, <em>15</em>(3), 819–835. (<a
href="https://doi.org/10.1007/s13042-023-01941-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a deep feature network with multi-scale fusion (DFNet) for addressing the problem of crowd counting in highly congested noisy scenes. DFNet contains three modules: feature encoder, feature decoder and feature fusion. The feature encoder uses a VGG-16-based convolutional neural network (CNN) that encodes features from images and forms a kind of low-level spatial information. The feature decoder is a multi-column dilated convolutional neural network (McDCNN) with different dilation rates that can capture a multi-scale contextual information, decode the low-level spatial information and generate a kind of high-level semantic information. Furthermore, the multi-column architecture in McDCNN can effectively relieve the “gridding” issue presented in the dilated convolution framework. The feature fusion block uses a simple and effective network architecture to sufficiently incorporate the low-level spatial and the high-level semantic information for facilitating high-quality density map estimation and performing accurate crowd counting. Extensive experiments on several highly challenging crowd counting datasets are conducted. Experimental results show that DFNet is comparable with recent state-of-the-art approaches.},
  archive      = {J_IJMLC},
  author       = {Yan, Leilei and Zhang, Li and Zheng, Xiaohan and Li, Fanzhang},
  doi          = {10.1007/s13042-023-01941-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {819-835},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep feature network with multi-scale fusion for highly congested crowd counting},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new self-augment CNN for 3D point cloud classification and
segmentation. <em>IJMLC</em>, <em>15</em>(3), 807–818. (<a
href="https://doi.org/10.1007/s13042-023-01940-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud classification and segmentation are challenging tasks due to the irregular structures, especially when there is translation variance in the point clouds. To overcome this barrier, this paper proposes a self-augment convolutional neural network (SACNN), which can not only extract more discriminative features from the points cloud but also alleviate the translation variance problem. Specifically, we first represent the point cloud through the dynamic graph, with the intention to keep the number of point clouds during the feature learning to avoid information loss. Benefiting from the dynamic graph, the global and local features of point clouds can be learned. Then, to reduce the translation variance in the dynamic graphs, a self-augment convolution (SAConv) module is designed to make points align their coordinates based on learned features. Finally, the local mixed aggregation module is proposed to combine the overview and the detailed descriptor of the neighbors. Experiments on several standard benchmarks verify the superiority of the SACNN over state-of-the-art methods in both 3D point cloud classification and segmentation tasks.},
  archive      = {J_IJMLC},
  author       = {Meng, Xinhong and Lu, Xinyu and Ye, Hailiang and Yang, Bing and Cao, Feilong},
  doi          = {10.1007/s13042-023-01940-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {807-818},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new self-augment CNN for 3D point cloud classification and segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deformation prediction of rock cut slope based on long
short-term memory neural network. <em>IJMLC</em>, <em>15</em>(3),
795–805. (<a href="https://doi.org/10.1007/s13042-023-01939-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cut slope graben is affected by the lithology of strata, rainfall, and man-made excavation, which is a complex geotechnical system. Deformation of a cut slope changes irregularly with time, and, if too large, the deformation causes geological disasters such as landslides. Thus, it is crucial to establish an accurate slope deformation prediction model for control and safety. We used wavelet decomposition (WD) to process the time series of slope deformation to obtain an approximate series and detailed series. Then to predict each sub-series, we used the improved particle swarm optimization (IPSO) algorithm to optimize the number of neurons in the hidden layer, the learning rate, and the number of iterations of a long short-term memory (LSTM) neural network. The prediction results were summed to obtain the final prediction. The hybrid WD-IPSO-LSTM prediction model had a mean absolute error of 0.047, 0.067, and 0.094 at 1, 3, and 6 steps, respectively. These errors were 47.19%, 49.62%, and 57.47% lower than the LSTM-alone model errors. The hybrid WD-IPSO-LSTM prediction model had greater accuracy compared with a back propagation neural network, recurrent neural network, LSTM alone, PSO-LSTM, and IPSO-LSTM in 1-step, 3-step, and 6-step prediction. In addition, our hybrid model for prediction of slope deformation was more realistic and credible compared with other models.},
  archive      = {J_IJMLC},
  author       = {Wang, Sichang and Lyu, Tian-le and Luo, Naqing and Chang, Pengcheng},
  doi          = {10.1007/s13042-023-01939-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {795-805},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deformation prediction of rock cut slope based on long short-term memory neural network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-triggered consensus control for DC microgrids based on
MKELM and state observer against false data injection attacks.
<em>IJMLC</em>, <em>15</em>(3), 775–793. (<a
href="https://doi.org/10.1007/s13042-023-01938-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an event-triggered distributed control method based on state observer and multi-kernel extreme learning machine (MKELM) for direct current microgrid, which can suppress the false data injection attacks (FDIA) in system. Firstly, considering the problem that most of the methods have poor suppression capability for discrete attacks in sensor signals, an MKELM-based suppression method for sensor attack is proposed. MKELM is used to model the microgrid system, the output current estimated by MKELM is employed in the controller instead of the current value measured by sensors, thus avoiding the FDIA present in sensors. Secondly, an event-triggered state observer-based distributed secondary control method with H∞ consensus performance is designed for suppressing the FDIA in communication link. In the controller, a state variable is constructed by deriving the microgrid system expression as a first-order multi-agent system, and then a state observer is designed to observe the transmitted information for isolating and suppressing the attack signals. And it is proved theoretically that the proposed event-triggered controller can achieve H∞ consensus convergence. Finally, simulation analyses verify the effectiveness of the method for suppressing FDIA in DC microgrid system.},
  archive      = {J_IJMLC},
  author       = {Xie, Zongkui and Wu, Zhongqiang},
  doi          = {10.1007/s13042-023-01938-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {775-793},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Event-triggered consensus control for DC microgrids based on MKELM and state observer against false data injection attacks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust <span
class="math display"><em>H</em><sub>∞</sub></span> asynchronous fault
detection for uncertain singular hybrid systems based on hmm strategy.
<em>IJMLC</em>, <em>15</em>(3), 757–773. (<a
href="https://doi.org/10.1007/s13042-023-01937-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper researches robust $$H_\infty $$ asynchron-ous fault detection for uncertain singular Markov jump systems with time-varying delays based on hidden Marko-v model strategy. The aim is to implement asynchronous fault detection for uncertain singular Markov jump system and realize stochastic admissibility with $$H_\infty $$ performance level for augmented uncertain singular Markov jump fault detection system. By applying singular value decomposition method and free weighting matrix technique, modified admissibility conditions are addressed based on Lyapunov stability theory. Robust fault detection problem is translated into $$H_\infty $$ filter design in this work. A hidden Markov model is used to describe a kind of asynchronous phenomenon produced by original system’s modes and fault detection filter’s modes, and the desired filter gains are obtained by solving linear matrix inequalities. Finally, a numerical example and a direct current motor system are used to verify the effectiveness of this approach.},
  archive      = {J_IJMLC},
  author       = {Yin, Yuexia and Zhuang, Guangming and Xia, Jianwei and Feng, Jun-e and Lu, Junwei},
  doi          = {10.1007/s13042-023-01937-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {757-773},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust $$H_\infty $$ asynchronous fault detection for uncertain singular hybrid systems based on hmm strategy},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fast attribute reduction by neighbor inconsistent pair
selection for dynamic decision tables. <em>IJMLC</em>, <em>15</em>(3),
739–756. (<a href="https://doi.org/10.1007/s13042-023-01931-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is capable of reducing the dimensionality of data and improving the performance of data mining. As a reasonable representative of relationships between samples, neighbor inconsistent pair focuses on measuring uncertainty in information systems. Nevertheless, classical attribute reduction methods are static and unsuitable for data with variations. Additionally, it is inevitable for data to undergo changes in real-life scenarios, such as an increase in the number of samples. Therefore, it is essential to identify an efficient method for reducing the dimensionality of the dataset while preserving the classification accuracy. Inspired by these deficiencies, our focus lies on developing effective and efficient incremental methods that employ the neighbor inconsistent pair selection strategy for decision tables involving object variations. At first, some concepts related to rough sets, simplified decision tables and neighbor inconsistent pairs are introduced. Then, the heuristic attribute reduction algorithms for dynamic decision tables with the variation of object sets are designed by neighbor inconsistent pairs. Next, a novel feature selection procedure, which we refer to as incremental neighbor inconsistent pair selection, is proposed to update reducts for dynamic decision tables with the variation of object sets. Finally, two incremental attribute reduction algorithms based on neighbor inconsistent pair selection are designed. Furthermore, experiments are conducted on real datasets to validate the effectiveness and benefits of the proposed incremental algorithms. The results indicate that our algorithms exhibit minimal computing time requirements while achieving the highest classification accuracy among at least ten out of thirteen datasets when compared to the comparative algorithms.},
  archive      = {J_IJMLC},
  author       = {Zhang, Chucai and Liu, Hong and Lu, Zhengxiang and Dai, Jianhua},
  doi          = {10.1007/s13042-023-01931-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {739-756},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fast attribute reduction by neighbor inconsistent pair selection for dynamic decision tables},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stemming competitive influence spread in social networks
through binary ions motion optimization. <em>IJMLC</em>, <em>15</em>(2),
719–737. (<a href="https://doi.org/10.1007/s13042-023-01936-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of social networks has brought many conveniences, but it has also resulted in the wanton dissemination of negative information. Identifying key users in the network to block negative information in a timely and effective manner has become an urgent research task. For this purpose, this paper proposes a binary ions motion optimization algorithm to maximize the blocking of negative influence propagation under a competitive-based model. The algorithm adopts a degree-based heuristic initialization strategy by recoding search agents and blocking diffusion channels based on the negative seed location. To overcome the lack of crystal phase search ability, a crossover mechanism of anions and cations is introduced, which accelerates convergence and facilitates the discovery of optimal solution. Finally, the effectiveness of the proposed algorithm is demonstrated on real networks and synthetic networks, showing significant advancements compared to other algorithms.},
  archive      = {J_IJMLC},
  author       = {Kong, Ping and Wang, Chao and Ma, Liangliang and Ye, Ye and Wang, Lu and Xie, Nenggang},
  doi          = {10.1007/s13042-023-01936-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {719-737},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stemming competitive influence spread in social networks through binary ions motion optimization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive weighting function for weighted nuclear norm based
matrix/tensor completion. <em>IJMLC</em>, <em>15</em>(2), 697–718. (<a
href="https://doi.org/10.1007/s13042-023-01935-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted nuclear norm provides a simple yet powerful tool to characterize the intrinsic low-rank structure of a matrix, and has been successfully applied to the matrix completion problem. However, in previous studies, the weighting functions to calculate the weights are fixed beforehand, and do not change during the whole iterative process. Such predefined weighting functions may not be able to precisely characterize the complicated structure underlying the observed data matrix, especially in the dynamic estimation process, and thus limits its performance. To address this issue, we propose a strategy of adaptive weighting function, for low-rank matrix/tensor completion. Specifically, we first parameterize the weighting function as a simple yet flexible neural network, that can approximate a wide range of monotonic decreasing functions. Then we propose an effective strategy, by virtue of the bi-level optimization technique, to adapt the weighting function, and incorporate this strategy to the alternating direction method of multipliers for solving low-rank matrix and tensor completion problems. Our empirical studies on a series of synthetic and real data have verified the effectiveness of the proposed approach, as compared with representative low-rank matrix and tensor completion methods.},
  archive      = {J_IJMLC},
  author       = {Zhao, Qian and Lin, Yuji and Wang, Fengxingyu and Meng, Deyu},
  doi          = {10.1007/s13042-023-01935-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {697-718},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive weighting function for weighted nuclear norm based matrix/tensor completion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated domain generalization for intelligent fault
diagnosis based on pseudo-siamese network and robust global model
aggregation. <em>IJMLC</em>, <em>15</em>(2), 685–696. (<a
href="https://doi.org/10.1007/s13042-023-01934-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) based intelligent fault diagnosis has developed rapidly in recent years owing to the need for data privacy. However, models trained using FL may suffer from performance degradation when applied to unseen domains. In this regard, we propose a federated domain generalization approach using a pseudo-Siamese network (PSN) and robust model aggregation for intelligent fault diagnosis. Firstly, the proposed method employs PSN to calculate the discrepancy between client and global models at the local clients. This enhances the feature space boundary of fault diagnosis models. Then the proposed method computes cross-classification losses of locally trained global models on the central server for robust model aggregation. Finally, we evaluate our approach through experiments where local clients contain data from varying datasets. Experimental results on the proposed method and other transfer learning and federated learning methods prove the outperformance of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Song, Yan and Liu, Peng},
  doi          = {10.1007/s13042-023-01934-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {685-696},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Federated domain generalization for intelligent fault diagnosis based on pseudo-siamese network and robust global model aggregation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive occlusion hybrid second-order attention network for
head pose estimation. <em>IJMLC</em>, <em>15</em>(2), 667–683. (<a
href="https://doi.org/10.1007/s13042-023-01933-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Head pose estimation (HPE) is a challenging and critical research subject with a wide range of applications in areas such as driver monitoring, attention recognition, and human-computer interaction. However, there are two challenging problems in HPE, the first one is that in real application scenarios, occlusion is very common, which affects the accuracy of HPE to a great extent. The second is that most research works use Euler angles to represent the head pose, which may lead to problems in neural network optimization. To solve these problems, an adaptive occlusion hybrid second-order attention network model was proposed. First, facial landmarks were detected by the occlusion-aware module to generate heat maps reflecting the presence or absence of occlusion in the specific facial parts, thereby enhancing features in the non-occluded parts of the face and suppressing features in the occluded regions. Meanwhile, we designed a novel second-order information attention module to interact with spatial and channel information using second-order statistical information, such that the model learns the feature correlations of different facial parts while paying more attention to important channels and suppressing redundant ones to further reduce the effect of occlusion and excavate more powerful features. Furthermore, to avoid ambiguity in common head pose representation, we introduced an exponential map to represent the head pose and designed a prediction framework capable of capturing the geometry of the pose space. The results of the experiments showed that the proposed model was competitive with methods using depth information from the BIWI dataset and achieved obvious advantages on the challenging AFLW2000 dataset, with more robust performance under large poses and occlusion interference, and stronger robustness compared with other models.},
  archive      = {J_IJMLC},
  author       = {Fu, Qi and Xie, Kai and Wen, Chang and He, Jianbiao and Zhang, Wei and Tian, Hongling and Yang, Sheng},
  doi          = {10.1007/s13042-023-01933-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {667-683},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive occlusion hybrid second-order attention network for head pose estimation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MSIF: Multi-spectrum image fusion method for cross-modality
person re-identification. <em>IJMLC</em>, <em>15</em>(2), 647–665. (<a
href="https://doi.org/10.1007/s13042-023-01932-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch-RGB cross-modality person re-identification (ReID) is a challenging task that aims to match a sketch portrait drawn by a professional artist with a full-body photo taken by surveillance equipment to deal with situations where the monitoring equipment is damaged at the accident scene. However, sketch portraits only provide highly abstract frontal body contour information and lack other important features such as color, pose, behavior, etc. The difference in saliency between the two modalities brings new challenges to cross-modality person ReID. To overcome this problem, this paper proposes a novel dual-stream model for cross-modality person ReID, which is able to mine modality-invariant features to reduce the discrepancy between sketch and camera images end-to-end. More specifically, we propose a multi-spectrum image fusion (MSIF) method, which aims to exploit the image appearance changes brought by multiple spectrums and guide the network to mine modality-invariant commonalities during training. It only processes the spectrum of the input images without adding additional calculations and model complexity, which can be easily integrated into other models. Moreover, we introduce a joint structure via a generalized mean pooling (GMP) layer and a self-attention (SA) mechanism to balance background and texture information and obtain the regional features with a large amount of information in the image. To further shrink the intra-class distance, a weighted regularized triplet (WRT) loss is developed without introducing additional hyperparameters. The model was first evaluated on the PKU Sketch ReID dataset, and extensive experimental results show that the Rank-1/mAP accuracy of our method is 87.00%/91.12%, reaching the current state-of-the-art performance. To further validate the effectiveness of our approach in handling cross-modality person ReID, we conducted experiments on two commonly used IR-RGB datasets (SYSU-MM01 and RegDB). The obtained results show that our method achieves competitive performance. These results confirm the ability of our method to effectively process images from different modalities.},
  archive      = {J_IJMLC},
  author       = {Chen, Qingshan and Quan, Zhenzhen and Zheng, Yifan and Li, Yujun and Liu, Zhi and Mozerov, Mikhail G.},
  doi          = {10.1007/s13042-023-01932-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {647-665},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MSIF: Multi-spectrum image fusion method for cross-modality person re-identification},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Different treatments of pixels in unlabeled images for
semi- supervised sonar image segmentation. <em>IJMLC</em>,
<em>15</em>(2), 637–646. (<a
href="https://doi.org/10.1007/s13042-023-01930-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pseudo-labeling is an effective semi-supervised segmentation method. Most pseudo-labeling works were based on a common assumption: lower entropy means lower uncertainty. Hence many high entropy pseudo-labels are discarded and not involved in the training. Inadequate labeled data limit performance of model segmentation. In order to expand the labeled data capacity, we propose a new semi-supervised segmentation method, namely, different treatments of pixels in unlabeled images (DTP). Our DTP consists of three main components: labeled images segmentation, certain pixels segmentation, uncertain pixels segmentation. A sonar image with two different parallel segmentation networks will produce two one-hot segmentation maps. If the predictions of a pixel in the sonar image are consistent on two one-hot segmentation maps, this pixel is regarded as reliable in this segmentation and delineated as the certain pixel. On the contrary, if the prediction results are different, the pixel is delineated as the uncertain pixel. Then uncertain pixels are necessary to choose an advanced semi-supervised framework for label assignment to minimize the possible error propagation. Meanwhile, certain pixels are assessed in two extreme ways—radical segmentation and conservative segmentation. Compared with other methods, our method is novel in (1) indicating certain/uncertain pixels to expand the labeled data capacity (2) introducing other advanced semi-supervised methods for segmenting uncertain pixels to improve the segmentation performance. Experimental results show that our method achieves advanced semi-supervised segmentation performance in sonar dataset.},
  archive      = {J_IJMLC},
  author       = {Xu, Huipu and Tong, Pengfei and Li, Yongzhi},
  doi          = {10.1007/s13042-023-01930-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {637-646},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Different treatments of pixels in unlabeled images for semi- supervised sonar image segmentation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A pruning extreme learning machine with <span
class="math display"><em>L</em><sub>2, 1/2</sub></span> regularization
for multi-dimensional output problems. <em>IJMLC</em>, <em>15</em>(2),
621–636. (<a href="https://doi.org/10.1007/s13042-023-01929-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fast algorithm for training single-hidden layer feedforward neural networks, extreme learning machine (ELM) has been successfully applied to various classification and regression problems. In recent years, regularization techniques have been widely used in ELM to improve its stability, sparsity and generalization capability. In order to determine the appropriate number of hidden layer nodes, the ELM regularized by $$l _{\,\!1/2 }$$ quasi-norm (L $$_{1/2 }$$ -ELM) was developed to prune the redundant hidden nodes. However, in multi-dimensional output tasks, L $$_{1/2 }$$ -ELM only removes redundant weights of hidden nodes but cannot guarantee the sparsity at the node level. In this paper, we present the L $$_{2,1/2 }$$ -ELM, which is regularized by $$L _{2,1/2 }$$ quasi-norm to achieve sparsity in multi-dimensional output problems. With the generalization of $$L _{1/2 }$$ regularization to $$L _{2,1/2 }$$ regularization, L $$_{2,1/2 }$$ -ELM can prune the corresponding hidden nodes by setting some rows of the output weight matrix to zero. Since the proximal operator corresponding to $$L _{2,1/2 }$$ regularization has a closed-form solution, the powerful alternating direction method of multipliers (ADMM) is employed to achieve a fast solution of L $$_{2,1/2 }$$ -ELM. Furthermore, to face the challenge of distributed computing, we extend L $$_{2,1/2 }$$ -ELM to its distributed version, namely DL $$_{2,1/2 }$$ -ELM. DL $$_{2,1/2 }$$ -ELM is solved by the consensus ADMM algorithm. Experiments on multi-classification and multi-target regression datasets demonstrate that our proposed algorithms can achieve competitive sparsity without compromising accuracy.},
  archive      = {J_IJMLC},
  author       = {Dai, Yunwei and Zhang, Yuao and Wu, Qingbiao},
  doi          = {10.1007/s13042-023-01929-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {621-636},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A pruning extreme learning machine with $$L_{2, 1/2}$$ regularization for multi-dimensional output problems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TFEN: Two-stage feature enhancement network for single-image
super-resolution. <em>IJMLC</em>, <em>15</em>(2), 605–619. (<a
href="https://doi.org/10.1007/s13042-023-01928-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep convolution neural networks have made significant progress in single-image super-resolution (SISR). However, high-resolution (HR) images obtained by most SISR reconstruction methods still suffer from edge blur-ring and texture distortion. To address this issue, we propose a two-stage feature enhancement network (TFEN) for the SISR reconstruction to realize nonlinear mapping from low-resolution (LR) images to HR images. In the first stage, an initial feature reconstruction module (IFRM) is constructed by combining a feature attention enhancement block and multiple convolution layers that simulate degradation and reconstruction operations to reconstruct a coarse HR image. In the second stage, based on the extracted features and the coarse HR image in the first stage, multiple residual attention modules (RAMs) consisting of the proposed spatial feature enhancement blocks (SFEBs) and an attention interaction block (AIB) are cascaded to generate the final HR image. In RAM, the SFEB is designed to learn more refined features for the reconstruction by adopting dilated convolutions and constructing spatial feature enhancement block, and the AIB is built to enhance the important features learned by RAMs through constructing multi-directional attention maps. Extensive experiments show that the proposed method has better performance than some current state-of-the-art SISR networks.},
  archive      = {J_IJMLC},
  author       = {Huang, Shuying and Lai, Houzeng and Yang, Yong and Wan, Weiguo and Li, Wei},
  doi          = {10.1007/s13042-023-01928-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {605-619},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TFEN: Two-stage feature enhancement network for single-image super-resolution},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved deep network-based RGB-d semantic segmentation
method for indoor scenes. <em>IJMLC</em>, <em>15</em>(2), 589–604. (<a
href="https://doi.org/10.1007/s13042-023-01927-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a hot research issue in the field of image processing. The introduction of depth images improves the effect of semantic segmentation. However, most existing methods do not take into account the differences between RGB and depth features, leading to poor segmentation accuracy. To fully utilize the RGB and depth features, an asymmetric two-branch convolutional neural network structure is proposed in this paper. In the depth feature extraction branch, a feature enhancement module is proposed to reduce noise. Meanwhile, in the branch of RGB feature extraction, a skip connection structure is introduced to extract more abundant RGB features. In addition, a fusion module based on attention mechanism is proposed to make full use of the effective information from the two modals. Finally, extensive experiments are conducted, and the results show that the proposed model can complete the semantic segmentation task for indoor scenes efficiently.},
  archive      = {J_IJMLC},
  author       = {Ni, Jianjun and Zhang, Ziru and Shen, Kang and Tang, Guangyi and Yang, Simon X.},
  doi          = {10.1007/s13042-023-01927-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {589-604},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved deep network-based RGB-D semantic segmentation method for indoor scenes},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AFMPM: Adaptive feature map pruning method based on feature
distillation. <em>IJMLC</em>, <em>15</em>(2), 573–588. (<a
href="https://doi.org/10.1007/s13042-023-01926-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature distillation is a technology that uses the middle layer feature map of the teacher network as knowledge to transfer to the students. The feature information not only reflects the image information but also covers the feature extraction ability of the teacher network. However, the existing feature distillation methods lack theoretical guidance for feature map evaluation and suffer from the mismatch of sizes between high-dimensional feature maps and low-dimensional feature maps, and poor information utilization. In this paper, we propose an Adaptive Feature Map Pruning Method (AFMPM) for feature distillation, which transforms the problem of feature map pruning into the problem of optimization so that the valid information of the feature map is retained to the maximum extent. AFMPM has achieved significant improvements in feature distillation, and the advanced and generalized nature of the method has been verified by conducting experiments on the teacher-student distillation framework and the self-distillation framework.},
  archive      = {J_IJMLC},
  author       = {Guo, Yufeng and Zhang, Weiwei and Wang, Junhuang and Ji, Ming and Zhen, Chenghui and Guo, Zhengzheng},
  doi          = {10.1007/s13042-023-01926-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {573-588},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {AFMPM: Adaptive feature map pruning method based on feature distillation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Program synthesis algorithm based on context consistency
heuristic. <em>IJMLC</em>, <em>15</em>(2), 559–571. (<a
href="https://doi.org/10.1007/s13042-023-01925-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming-by-example (PBE) is a program synthesis technique that automatically synthesizes computer programs from input–output (I/O) examples. There are many approaches to program synthesis, and one of the most commonly used solutions is to perform a search over the space of programs. In this paper, we present a novel program synthesis algorithm based on context consistency heuristic (PSACC) that differs from previous heuristic methods. We consider the input–output example as a state and develop a deep neural network-based predictor called DHFnet. DHFnet has the ability to map the current state to the first two instructions of the program which achieves the current state. By considering the current state and its subsequent state obtained by executing the corresponding instruction, we design a context consistency-based search algorithm. Our search algorithm enables a more reasonable and efficient selection of instructions in the program, by judging whether the instructions maintain the context consistency between the current state and its subsequent state. Furthermore, under the same experimental and testing environments, PSACC successfully enhances the success rate of program synthesis by 2–5%, and reduces the synthesis time compared to the baseline method. PSACC also exhibits better synthesis efficiency in terms of comprehensive performance compared to existing program synthesis methods.},
  archive      = {J_IJMLC},
  author       = {Dou, Quansheng and Pan, Hao and Tang, Huanling and Jiang, Ping and Wang, Huixian},
  doi          = {10.1007/s13042-023-01925-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {559-571},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Program synthesis algorithm based on context consistency heuristic},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LEFSA: Label enhancement-based feature selection with
adaptive neighborhood via ant colony optimization for multilabel
learning. <em>IJMLC</em>, <em>15</em>(2), 533–558. (<a
href="https://doi.org/10.1007/s13042-023-01924-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, multilabel learning has garnered attention increased from scholars and has a significant effect on practical applications; however, most feature selection models with classification margin cannot fully reflect the correlations between the feature and label sets. This work constructs a label enhancement-based feature selection method via ant colony optimization (ACO) on multilabel data. First, by combining the feature cosine distance and label distance of the samples, a global distance between the samples is presented, and an adjustment parameter is defined to dynamically regulate the label distance between the samples. The discriminant relation between the samples is presented to distinguish the homogeneous or heterogeneous samples of the target sample. An average classification margin-based adaptive neighborhood radius of the target sample is designed. Thus, a new adaptive fuzzy neighborhood rough set is proposed. Second, by integrating the algebraic and information viewpoints, the roughness degree is fused with the multilabel fuzzy neighborhood mutual information. The weight of each label is generated based on the label distribution of all the samples. Label enhancement-based fuzzy neighborhood mutual information can be determined to generate the final correlation of each feature and label set. Finally, Pearson correlation coefficient with an upper approximation will be applied to construct the pheromone initialization of the feature. Two metrics can be used as the heuristic information of the ACO to guide the ants to select significant features. Thus, a label enhancement-based multilabel feature subset selection methodology will be provided to obtain a superior set of features. The results from experiments confirm the capability of the proposed methodology in implementing significant classification effects on 13 datasets.},
  archive      = {J_IJMLC},
  author       = {Sun, Lin and Chen, Yusheng and Ding, Weiping and Xu, Jiucheng},
  doi          = {10.1007/s13042-023-01924-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {533-558},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LEFSA: Label enhancement-based feature selection with adaptive neighborhood via ant colony optimization for multilabel learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sequence tagging with a rethinking structure for joint
entity and relation extraction. <em>IJMLC</em>, <em>15</em>(2), 519–531.
(<a href="https://doi.org/10.1007/s13042-023-01923-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint entity and relation extraction have become increasingly popular due to their knowledge graph construction advantages. Despite the promising results on this task, disregarding the multi-triple interaction poses a problem since multi-triples commonly appear in sentences and interact implicitly. This paper proposes a sequence tagging with a rethink structure method for joint extraction and builds upon a Seq2Seq framework. The model starts with a sentence encoder that vectorizes input text. Then the vectors are fed into a sequence tagging component to acquire pre-extracted triples. Afterward, a newly designed rethinking structure is utilized as a decoder, double-checking the pre-extracted triples. Specifically, the pre-extracted triples serve as the decoder’s query vector. Thus, the decoder can simultaneously generate triples in a non-autoregressive manner. Since the decoder is aware of the entire set of per-extracted triples, it can effectively model the interactions. The model was comprehensively compared to state-of-the-art (SOTA) benchmarks on widely used datasets, NYT and WebNLG. The result shows that the extraction performance of our model is superior to that of SOTA, especially when the sample contains sufficient triple interactions.},
  archive      = {J_IJMLC},
  author       = {Zeng, Daojian and Xu, Lu and Jiang, Chao and Zhu, Jianlin and Chen, Hongting and Dai, Jianhua and Jiang, Lincheng},
  doi          = {10.1007/s13042-023-01923-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {519-531},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sequence tagging with a rethinking structure for joint entity and relation extraction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel data-free continual learning method with contrastive
reversion. <em>IJMLC</em>, <em>15</em>(2), 505–518. (<a
href="https://doi.org/10.1007/s13042-023-01922-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While continual learning has shown its impressive performance in addressing catastrophic forgetting of traditional neural networks and enabling them to learn multiple tasks continuously, it still requires a large amount of input data to train neural networks with satisfactory classification performance. Since collecting a large amount of training data is a time-consuming and expensive procedure, this study attempts to propose a novel data-free contrastive reversion method for continual learning (DFCRCL) to significantly reduce the number of training data for continual learning, while maintaining or even improving the classification performance of continual learning. In order to achieve such a goal, DFCRCL uses contrastive reversion to generate high-semantic pseudo samples from the previous task to guide the training of the current task. DFCRCL has three merits: (1) knowledge distillation from the previous task model to the current task model guarantees both the reduction of training data and the avoidance of catastrophic forgetting, and thus DFCRCL can effectively learn a sequence of tasks continuously (2) contrastive reversion enhances the semantic diversity of pseudo samples by learning the distinguishability between distinct pseudo samples in the feature space (3) contrastive reversion improves the performance of knowledge distillation in DFCRCL by enhancing the semantic diversity of the pseudo samples generated from the previous task model. Compared to six mainstream continual learning methods, the proposed DFCRCL achieves at least comparable or even better classification performance and stability in four benchmarking continual learning scenarios. In addition, the effectiveness of DFCRCL is demonstrated by ablation experiments.},
  archive      = {J_IJMLC},
  author       = {Wu, Chu and Xie, Runshan and Wang, Shitong},
  doi          = {10.1007/s13042-023-01922-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {505-518},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel data-free continual learning method with contrastive reversion},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-local tensor sparse representation and tensor low rank
regularization for dynamic MRI reconstruction. <em>IJMLC</em>,
<em>15</em>(2), 493–503. (<a
href="https://doi.org/10.1007/s13042-023-01921-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Magnetic Resonance Imaging (DMRI) reconstruction is a challenging theme in image processing. A variety of dimensionality reduction methods using vectorization have been proposed. However, most of them gave rise to a loss of spatial and temporal information. To deal with this problem, this article develops a DMRI reconstruction method in a nonlocal framework by integrating the nonlocal sparse tensor with low-rank tensor regularization. The sparsity constraint employs the Tucker decomposition tensor sparse representation, and the t-product-based tensor nuclear norm is used to set the low-rank constraint. Both constraints are handled in a nonlocal framework, which can take advantage of data redundancy in DMRI. Furthermore, the nonlocal sparse tensor representation we proposed constructs a tensor dictionary in the spatio-temporal dimension, making sparsity more efficient. Consequently, our method can better exploit the multi-dimensional coherence of DMRI data due to its sparsity and lowrankness and the fact that it uses a different tensor decomposition-based method. The Alternating Direction Method of Multipliers (ADMM) has been used for optimization. Experimental results show that the performance of the proposed method is superior to several conventional methods.},
  archive      = {J_IJMLC},
  author       = {Gong, Minan and Zhang, Guixu},
  doi          = {10.1007/s13042-023-01921-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {493-503},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Non-local tensor sparse representation and tensor low rank regularization for dynamic MRI reconstruction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feature selection based on probability and mathematical
expectation. <em>IJMLC</em>, <em>15</em>(2), 477–491. (<a
href="https://doi.org/10.1007/s13042-023-01920-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many kinds of information entropy are employed for feature selection, but they lack corresponding probabilities to interpret; Despite many statistical indicators utilized in feature selection, neither probability nor mathematical expectation was applied to perform feature selection directly. To address such two problems, this article redefines three kinds of probabilities and their corresponding mathematical expectations from the perspective of granular computing and investigates their properties. These novel probabilities and mathematical expectations extend the meanings of classical probability and mathematical expectation and provide statistical interpretation for their corresponding information entropy, and then, attribute reducts based on probabilities and mathematical expectations are defined, which are proved to be equivalent to those based on their corresponding information entropy. A framework of feature selection algorithms based on probabilities and mathematical expectations (ARME) is designed after the presentation of their properties. Moreover, a novel definition form for feature selection is proposed, and another feature selection algorithm based on the mathematical expectation of conditional probability (ARMEC) is designed to reduce negative features on classification. Theoretical analysis and experimental results show that probabilities and mathematical expectations have super efficiency than their corresponding information entropy when they are considered as criteria of feature selection. Therefore, the novel method has the advantage over many state-of-the-art algorithms.},
  archive      = {J_IJMLC},
  author       = {Deng, Zhixuan and Li, Tianrui and Liu, Keyu and Zhang, Pengfei and Deng, Dayong},
  doi          = {10.1007/s13042-023-01920-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {477-491},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection based on probability and mathematical expectation},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Entropy regularized fuzzy nonnegative matrix factorization
for data clustering. <em>IJMLC</em>, <em>15</em>(2), 459–476. (<a
href="https://doi.org/10.1007/s13042-023-01919-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering high-dimensional data is very challenging due to the curse of dimensionality. To address this problem, low-rank matrix approximations are widely used to identify the underlying low-dimensional structure of a dataset. Among these, nonnegative matrix factorization (NMF) is the most popular because its decomposed factors are nonnegative and meaningful. However, the NMF problem has been proved to be nonconvex and NP-hard, thus resulting in many local minima. To obtain high-quality local minima, we propose an entropy regularized fuzzy nonnegative matrix factorization (ERF-NMF) model for high-dimensional data fuzzy clustering. First, probability simplex constraints on the decomposed weight components are added to achieve dimension reduction and fuzzy clustering of a dataset simultaneously. Based on the constraints, we also introduce entropy regularization to further reduce the search space for optimal solutions. Finally, we present multiplicative update rules for solving the ERF-NMF model and provide a complexity and convergence analysis. Comprehensive experiments show that the proposed ERF-NMF performs remarkably well with promising results, and its decomposition will be sparser because of entropy regularization and have a clearer physical meaning because of probability simplex constraints.},
  archive      = {J_IJMLC},
  author       = {Chen, Kun and Liang, Junchen and Liu, Junmin and Shen, Weilin and Xu, Zongben and Yao, Zhengjian},
  doi          = {10.1007/s13042-023-01919-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {459-476},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Entropy regularized fuzzy nonnegative matrix factorization for data clustering},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decision space information driven algorithm for dynamic
multiobjective optimization with a changing number of objectives.
<em>IJMLC</em>, <em>15</em>(2), 429–457. (<a
href="https://doi.org/10.1007/s13042-023-01918-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) with a changing number of objectives receive little attention, but they exist widely in real life. These type of dynamics not only lead to expansion or contraction of Pareto optimal front/set (PF/PS) manifold, but also pose great challenges to balancing diversity and convergence. However, the current dynamic response mechanism has difficulty adapting these kind of problems. To tackle these problems, a decision space information driven algorithm (DSID) is proposed. Once the number of objectives changes, an individual guidance strategy based on manifold learning (IGSML) is introduced to identify solutions suitable for changes. Then IGSML produces excellent solutions by learning the manifold of these solutions. Meanwhile, a variable layering reconstruction strategy (VLRS) is proposed to divide the decision variables into three layers: convergence, diversity and multi-functional variables. Afterwards, VLRS takes into account the different degrees of influence of variables at different layers in the process of objective change, and makes targeted operations on different variables to quickly respond to changes. These two strategies cooperate with each other to balance the diversity and convergence. Comprehensive experiments are conducted on 15 benchmark functions with a varying number of objectives. Simulation results verify the efficacy of the proposed algorithm.},
  archive      = {J_IJMLC},
  author       = {Ma, Xuemin and Sun, Hao and Hu, Ziyu and Wei, Lixin and Yang, Jingming},
  doi          = {10.1007/s13042-023-01918-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {429-457},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Decision space information driven algorithm for dynamic multiobjective optimization with a changing number of objectives},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Three-way conflict analysis with similarity degree on an
issue set. <em>IJMLC</em>, <em>15</em>(2), 405–427. (<a
href="https://doi.org/10.1007/s13042-023-01917-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper introduces a new model of three-way conflict analysis with similarity degree on an issue set. Specifically, we introduce an evaluation of similarity degree, from a relative quantitative point of view, to evaluate the attitude similarity between any two agents. Based on similarity degree, we define a trisection of all pairs of agents on an issue set, and propose a three-level conflict model induced by such a trisection. More importantly, we solve the threshold-selection problem for three-level conflict analysis on multiple issues. We prove that the trisection model (resp. the three-level conflict model) defined in this paper is a conservative extension of the corresponding trisection model (resp. three-level conflict model) defined in Yao 2019 on multiple issues. Therefore, the present paper extends and improves the results of Yao 2019 on multiple issues.},
  archive      = {J_IJMLC},
  author       = {Xu, Wenyan and Jia, Bing},
  doi          = {10.1007/s13042-023-01917-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {405-427},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Three-way conflict analysis with similarity degree on an issue set},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple-model and time-sensitive dynamic active learning
for recurrent graph convolutional network model extraction attacks.
<em>IJMLC</em>, <em>15</em>(2), 383–404. (<a
href="https://doi.org/10.1007/s13042-023-01916-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper explores the vulnerability of a popular deep learning model—recurrent graph convolutional network (RGCN)—from the view of model extraction attacks. As a commonly-used attack method, graph-based active learning strategies could perform black-box model extraction attacks for extracting high-fidelity deep learning models without the background knowledge of model structure and parameters. They still have two limitations—spatial-temporal information ignorance and lack of cost-effective node sampling constraints—on dynamic graphs, influencing the fidelity of extracted RGCN models. In this paper, the proposed multiple-model and time-sensitive dynamic active learning (MTDAL) strategy relied on an RGCN committee to solve the spatial-temporal information ignorance. It captures the time-sensitive dynamic node importance from dynamic node representatives and dynamic node informativeness. In the node sampling procedure, the dynamic node representative is measured by the time-sensitive and weighted distance between node embeddings and associated cluster centers achieved by semi-supervised clustering. The dynamic node informativeness is measured by the spatial-temporal disagreement of node embeddings output by the RGCN committee that includes RGCNs with multiple model structures. To overcome cost-effective node sampling difficulties, MTDAL configures the class-balance constraints and makes a trade-off between aggregated dynamic node importance and standardized nonequivalent node query cost. In the experiments, graph-based active learning strategies achieve node sampling for querying different-type oracle models and exploit labeled nodes for training multiple RGCN models in the RGCN committee. Compared with random, KcenterGreedy, and ALDG strategies, the proposed MTDAL strategy could effectively sample the most critical dynamic nodes for extracting higher-fidelity RGCN models, especially in dynamic node classification tasks.},
  archive      = {J_IJMLC},
  author       = {Zeng, Zhuo and Wang, Chengliang and Ma, Fei and Wang, Peng and Wang, Hongqian},
  doi          = {10.1007/s13042-023-01916-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {383-404},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multiple-model and time-sensitive dynamic active learning for recurrent graph convolutional network model extraction attacks},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formative semi-supervised learning based on adaptive
combined model for brain–computer interface. <em>IJMLC</em>,
<em>15</em>(2), 371–382. (<a
href="https://doi.org/10.1007/s13042-023-01914-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of Electroencephalogram (EEG) signals has been an important research field in Brain–computer interface. The semi-supervised classification can improve the classification performance of EEG. Formative Semi-Supervised Learning (FSSL) uses the affinity matrix between samples and Expectation-maximization (EM) to mine hidden features between samples. It isn’t effective to apply FSSL to EEG classification directly due to the non-stationary and nonlinear of EEG. FSSL only uses Euclidean distances in the affinity matrix, which is not sufficient to process EEG signals and may restrict the effect of subsequent feature extraction. In response to this problem, combined model formative Semi-Supervised Learning (CMFSSL) was proposed to construct a combined model based on Euclidean metric and Riemannian metric. The weight update strategy is designed to constrain the model in the EM algorithm, and the weights of the combined model are constantly adjusted to construct a better basic model. Then the hidden features extracted based on the combined model are used to construct the training set and the Broad Learning System is used for classification. The algorithm is verified on three BCI data sets and compared with several state-of-the-art methods. The experimental results show that the algorithm achieves better results on three data sets: 74.86%, 73.52%, 75.49% and has a good effect on cross-domain classification. The combined model uses adaptive weights to build a better data model for subsequent hidden features, which not only maintains the original security advantages, but also improves the classification results.},
  archive      = {J_IJMLC},
  author       = {Gao, Yunyuan and Li, Mengting and Cao, Zhen and Meng, Ming},
  doi          = {10.1007/s13042-023-01914-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {371-382},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Formative semi-supervised learning based on adaptive combined model for brain–computer interface},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RAMFAE: A novel unsupervised visual anomaly detection method
based on autoencoder. <em>IJMLC</em>, <em>15</em>(2), 355–369. (<a
href="https://doi.org/10.1007/s13042-023-01913-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods of visual anomaly detection based on reconstruction often use normal data to train autoencoder. Then the metric distance detection method is used to estimate whether the samples of detection belong to the exception class. However, this method has some problems that the autoencoder produces blurry images to cause false detection of normal pixel points. The model may still be able to fully reconstruct the undiscovered defects due to the large capacity of autoencoder, even if it is trained only on normal samples. Then, the metric distance detection method would ignore local key information. To solve this problem, this paper comes up with the random anomaly multi-scale feature focused autoencoder (RAMFAE), an innovative unsupervised visual anomaly detection technique, which incorporates three novel concepts. First, a multi-scale feature focused extraction (MFFE) network structure is designed and added between the encoder and decoder, which effectively solves the problem of reconstructing image blur and effectively improves the sensitivity of the model to normal regions. Second, this article employs Delete Paste, a novel data augmentation strategy for generating two different types of random anomalies, which pastes the cut part into a random location, while the pixels in the original position are filled with 0. In spite of the input anomalous images, the strategy makes the model be able to produce normal images to avoid the phenomenon of anomaly reconstruction, and then enables defect localization based on the error between the measured image and the reconstructed image. Third, the study adopts the image quality assessment with combining gradient magnitude similarity deviation (GMSD) and structural similarity (SSIM) to solve the problem that local key information and texture detail information are not easy to be paid attention to by the model, and alleviate the training pressure caused by Delete Paste enhancement. We perform an extensive evaluation on the challenging MVTec AD data set and compare it with the advanced visual anomaly detection methods in recent years as well. The AUC final result of RAMFAE in this text reaches 94.5, which is 3.6, 2.5 and 0.8 higher than the advanced IGD, FCDD and RIAD detection methods.},
  archive      = {J_IJMLC},
  author       = {Sun, Zhongju and Wang, Jian and Li, Yakun},
  doi          = {10.1007/s13042-023-01913-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {355-369},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RAMFAE: A novel unsupervised visual anomaly detection method based on autoencoder},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive unsupervised feature selection with robust graph
regularization. <em>IJMLC</em>, <em>15</em>(2), 341–354. (<a
href="https://doi.org/10.1007/s13042-023-01912-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection, aiming at finding a refined representation of the original data by filtering out irrelevant and redundant features, has attracted intensive attention. Due to the dilemma of unavailable labels, existing methods select relevant features that preserve the intrinsic structure of data. Despite they are proven effective, the fixed metric is utilized to measure the distances from the projected samples to the target representation in the reconstruction term, which means that existing methods can not possess sufficient flexibility to adapt to different types of data sources. Besides, conventional methods utilize the $$l_2$$ norm based Laplacian graph to preserve the local structure of data, which leads to the sensitivity to noisy data. Inspired by the effectiveness and flexibility of the $$l_{2,p}$$ norm metric, we propose adaptive unsupervised feature selection with robust graph regularization (AUFS). Specifically, we impose the $$l_{2,p}$$ norm on the feature reconstruction term, which enhance the adaptability of our method to different types of data sources by adjusting p. In addition, $$l_{2,1}$$ norm based Laplacian graph is designed to alleviate the negative impact of noisy data. To solve the optimization problem, a unified iterative algorithm with guaranteed convergence is proposed. A large number of experimental results on several benchmark datasets demonstrate that our method outperforms some latest and related methods.},
  archive      = {J_IJMLC},
  author       = {Cao, Zhiwen and Xie, Xijiong and Sun, Feixiang},
  doi          = {10.1007/s13042-023-01912-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {341-354},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive unsupervised feature selection with robust graph regularization},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal airport selection utilizing power muirhead mean
based group decision model with 2-tuple linguistic q-rung orthopair
fuzzy information. <em>IJMLC</em>, <em>15</em>(2), 303–340. (<a
href="https://doi.org/10.1007/s13042-023-01911-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The choice of an optimal airport for local businesses for any traveling purpose due to the complexity of the access to the global market could be considered a group decision-making problem. To cope with this type of problem, the goal of this research is to introduce the power Muirhead mean operators into the environment of a 2-tuple linguistic q-rung orthopair fuzzy set (2TLq-ROFS). This paper proposes four novel aggregation operators: the 2TLq-ROF power Muirhead mean (2TLq-ROFPMM) operator, the 2TLq-ROF dual power Muirhead mean (2TLq-ROFDPMM) operator, the 2TLq-ROF weighted power Muirhead mean (2TLq-ROFWPMM) operator, and the 2TLq-ROF weighted dual power Muirhead mean (2TLq-ROFWDPMM) operator. Then, two new frameworks are constructed by employing the 2TLq-ROFWPMM and the 2TLq-ROFWDPMM aggregation operators to address challenges involving multi-attribute group decision-making. However, the decision-making process is complicated due to the ambiguity over the outcomes of airport choice. The constructed frameworks are being used to solve the problem of choosing the optimal airport in Pakistan for resolving the complexity of the access to the global market in local businesses. To demonstrate the superiority of our approach, parameter analysis with parameters q and $$\mathbf {\eth }$$ is carried out. In addition, we compare our formulated approach with different aggregation operators in the literature to prove its effectiveness and efficiency. Finally, some research study conclusions are drawn, limitations are given, and future directions are revealed.},
  archive      = {J_IJMLC},
  author       = {Naz, Sumera and Akram, Muhammad and Shafiq, Aqsa and Akhtar, Kiran},
  doi          = {10.1007/s13042-023-01911-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {303-340},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Optimal airport selection utilizing power muirhead mean based group decision model with 2-tuple linguistic q-rung orthopair fuzzy information},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gaussian mixture model with local consistency: A
hierarchical minimum message length-based approach. <em>IJMLC</em>,
<em>15</em>(2), 283–302. (<a
href="https://doi.org/10.1007/s13042-023-01910-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian mixture model (GMM) is widely used in many domains, e.g. data mining. The unsupervised learning of the finite mixture (ULFM) model based on the minimum message length (MML) criterion for mixtures enables adaptive model selection and parameter estimates. However, some datasets have a hierarchical structure. If the MML criterion does not consider the hierarchical structure of the a priori, the a priori coding length in the criterion is inaccurate. It is difficult to achieve a good trade-off between the model’s complexity and its goodness of fitting. Therefore, a locally consistent GMM with the hierarchical MML criterion (GM-HMML) algorithm is proposed. Firstly, the MML criterion determines the mixing probability (annihilation of components). To accurately control the competition between these relative necessary components, a hierarchical MML is proposed. Secondly, the hierarchical MML criterion is regularized using the graph Laplacian. The manifold structure is incorporated into the parameter estimator to avoid possible overfitting problems caused by the fine-grained prior. The presented MML criterion enhances the degree of component annihilation, which not only does not annihilate the necessary components but also reduces the iterations. The proposed approach is testified on the real datasets and achieves good model order and clustering accuracy.},
  archive      = {J_IJMLC},
  author       = {Li, Min and Wang, Guoyin and Yu, Zeng and Wang, Hongjun and Wan, Jihong and Li, Tianrui},
  doi          = {10.1007/s13042-023-01910-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {283-302},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Gaussian mixture model with local consistency: A hierarchical minimum message length-based approach},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-scale adaptive networks for efficient inference.
<em>IJMLC</em>, <em>15</em>(2), 267–282. (<a
href="https://doi.org/10.1007/s13042-023-01908-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of deep neural networks has been impressive in many areas. However, the increase in model performance is usually accompanied by an increase in depth and width, which is not conducive to the model being deployed at the edge. To address this problem, a new inference framework, multi-scale adaptive networks (MSAN), is proposed. Specifically, several branches are added at different stages of the network, and a scalable attention as well as self-distillation are used to improve the performance of shallow branches. To enhance the distillation effect and to reuse features efficiently, the knowledge from shallow and deep layers is fused through selective feature connections. In addition, two adaptive distillation strategies are proposed to further improve the performance of self-distillation. MSAN can be used to promote the performance of networks, static model compression and dynamic inference. Extensive experiments have demonstrated the superior performance of MSAN in these three aspects.},
  archive      = {J_IJMLC},
  author       = {Li, Linfeng and Su, Weixing and Liu, Fang and He, Maowei and Liang, Xiaodan},
  doi          = {10.1007/s13042-023-01908-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {267-282},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-scale adaptive networks for efficient inference},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On generalization reducts in incomplete multi-scale decision
tables. <em>IJMLC</em>, <em>15</em>(2), 253–266. (<a
href="https://doi.org/10.1007/s13042-023-01906-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reality, data is always arranged at multiple granularity levels. Multi-scale information tables were introduced from the viewpoint of granular computing to represent such types of data sets. In the present paper, we focus on acquisition of if-then rules in incomplete multi-scale decision tables (IMSDT for short). The notion of generalization reducts is proposed to achieve the desired goal. By firstly considering the generalization reducts of an IMSDT and then calculating the generalization reducts for each object, a collection of optimal decision rules can be thus obtained. During the entire process of generalization reducts, both the number and the generalization ability of the original attribute set are taken into consideration. It is shown that a more general and simple set of decision rules can be obtained by using generalization reducts, compared with the approaches in the literature. Lastly, an explanatory example is employed to show the advantage of our approach, and an experiment is designed for performing a comparative study between different approaches.},
  archive      = {J_IJMLC},
  author       = {He, Xiaoli and Zhao, Lin and She, Yanhong},
  doi          = {10.1007/s13042-023-01906-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {253-266},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {On generalization reducts in incomplete multi-scale decision tables},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). FRS-SIFS: Fuzzy rough set session identification and feature
selection in web robot detection. <em>IJMLC</em>, <em>15</em>(2),
237–252. (<a href="https://doi.org/10.1007/s13042-023-01905-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, web robots are a big part of web and useful in many cases. But, there are malicious web robots that need to be detected. Web robots often conceal their navigations by sending requests with incorrect or no information. It can be quite difficult to correctly and precisely classify this kind of incomplete data, including missing values. Previous studies have used IP addresses and user agent names to overcome this challenge, but these methods are unreliable. In order to solve this challenge, this paper has presented a robust algorithm named FRS-SIFS (Fuzzy Rough Set Session Identification and Feature Selection). FRS-SIFS first identifies user sessions using fuzzy rough set clustering based on string similarity measures. It then determines important features for recognizing web users’ behavioral patterns using fuzzy rough set classification. FRS-SIFS labels the sessions using a novel precise heuristic method based on four phases. Moreover, two different feature selection methods are used which include fuzzy rough set quick reduction algorithm and a novel wrapper feature selection method. Finally, the multi-objective optimization algorithm NSGA-II (non-dominated sorting genetic algorithm II) is used to select the optimal set of features. The performance of the proposed method has been evaluated on a real-world dataset by the tenfold cross-validation method. The results of the experiments have been compared with state-of-the-art methods which show the superiority of the proposed method in terms of recall, precision, and F1 measures.},
  archive      = {J_IJMLC},
  author       = {Hamidzadeh, Javad and Rahimi, Samaneh and Zarif, Mohammad Ali},
  doi          = {10.1007/s13042-023-01905-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {237-252},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {FRS-SIFS: Fuzzy rough set session identification and feature selection in web robot detection},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MetaCL: A semi-supervised meta learning architecture via
contrastive learning. <em>IJMLC</em>, <em>15</em>(2), 227–236. (<a
href="https://doi.org/10.1007/s13042-023-01904-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta learning aims to endow models with the ability to quickly learn new tasks based on existing knowledge. However, recent works have relied on complex structures and prior information to improve performance on few-shot tasks. To this end, we propose MetaCL, a meta learning architecture that uses only a traditional backbone without any priors. MetaCL takes distorted versions of an episode of samples as input and outputs predictions respectively. Besides, we introduce an unsupervised loss to minimize component redundancy and maximize variability, achieving soft-whitening and soft-alignment constraints. We evaluate MetaCL on few-shot tasks of image classification datasets CUB and miniImageNet, and experimetal results proves that MetaCL outperforms other meta-learning methods. MetaCL can be treated as a simple yet effective baseline and also be easily integrated into other few-shot models for additional performance gains.},
  archive      = {J_IJMLC},
  author       = {Li, Chengyang and Xie, Yongqiang and Li, Zhongbo and Zhu, Liping},
  doi          = {10.1007/s13042-023-01904-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {227-236},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MetaCL: A semi-supervised meta learning architecture via contrastive learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 2D-THA-ADMM: Communication efficient distributed ADMM
algorithm framework based on two-dimensional torus hierarchical
AllReduce. <em>IJMLC</em>, <em>15</em>(2), 207–226. (<a
href="https://doi.org/10.1007/s13042-023-01903-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model synchronization refers to the communication process involved in large-scale distributed machine learning tasks. As the cluster scales up, the synchronization of model parameters becomes a challenging task that has to be coordinated among thousands of workers. Firstly, this study proposes a hierarchical AllReduce algorithm structured on a two-dimensional torus (2D-THA), which utilizes a hierarchical structure to synchronize model parameters and maximize bandwidth utilization. Secondly, this study introduces a distributed consensus algorithm called 2D-THA-ADMM, which combines the 2D-THA synchronization algorithm with the alternating direction method of multipliers (ADMM). Thirdly, we evaluate the model parameter synchronization performance of 2D-THA and the scalability of 2D-THA-ADMM on the Tianhe-2 supercomputing platform using real public datasets. Our experiments demonstrate that 2D-THA significantly reduces synchronization time by $$63.447\%$$ compared to MPI_Allreduce. Furthermore, the proposed 2D-THA-ADMM algorithm exhibits excellent scalability, with a training speed increase of over 3 $$\times $$ compared to the state-of-the-art methods, while maintaining high accuracy and computational efficiency.},
  archive      = {J_IJMLC},
  author       = {Wang, Guozheng and Lei, Yongmei and Zhang, Zeyu and Peng, Cunlu},
  doi          = {10.1007/s13042-023-01903-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {207-226},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {2D-THA-ADMM: Communication efficient distributed ADMM algorithm framework based on two-dimensional torus hierarchical AllReduce},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dimension-divided feature smoothing for graph neural
network. <em>IJMLC</em>, <em>15</em>(1), 189–206. (<a
href="https://doi.org/10.1007/s13042-023-01909-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks(GNNs) learn the node representation of multi-hops through stacking layers. However, deep GNNs often suffer from over-smoothing, which drives people to the road of model simplification. With the deepening of research, it is found that the representation of nodes is more related to feature smoothing. More and more simplified models show that the nonparametric feature smoothing scheme can not only reduce computational complexity but also improve performance. Because the features of nodes in GNNs propagate along the edges, the denoising of graph data mainly focuses on the modification of graph topology. Based on this, we propose a feature smoothing scheme on the topology modification graph named Topology-modified Feature Smoothing(TMFS). Experiments show that the smoothed features calculated by TMFS can improve the performance of GNNs. Graph data usually have high-dimension features. Some feature dimensions contribute more to node classification, while others may only be the personality features of specific nodes. However, the existing propagation schemes cause all dimensional features to propagate along the edge at the same time. Such schemes as dropedge and addedge cannot change this situation. This feature propagation method is very mechanized. To solve this problem, we divide the dimension of features according to commonality nature, and modify the graph topology respectively, to realize the Dimension-divided Feature Smoothing(DDFS) of personalized propagation. Our experiments show that the deep features obtained by DDFS can not only improve the performance of GNNs but also be more stable. Our feature smoothing scheme can be seen as a plug-and-play module. On the Cora dataset, the smoothed features of our DDFS have improved the accuracy of MLP by 27.88% and other GNNs by 2.29% at most.},
  archive      = {J_IJMLC},
  author       = {Wang, Zhensheng and Yang, Hongwei and Ahmad, Naveed and Zhao, Lina},
  doi          = {10.1007/s13042-023-01909-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {189-206},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dimension-divided feature smoothing for graph neural network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic rule-based information extraction for
meteorological reports. <em>IJMLC</em>, <em>15</em>(1), 177–188. (<a
href="https://doi.org/10.1007/s13042-023-01885-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meteorological reports are one of the most important means of recording the weather conditions of a place over a period of time, and the existence of a large number of meteorological reports creates a huge demand for text processing and information extraction. However, valuable data and information are still buried deep in the mountain of meteorological reports, and there is an urgent need for an automated information extraction technique to help people integrate data from multiple meteorological reports and perform data analysis for a more comprehensive understanding of a specific meteorological topic or domain. Named entity recognition (NER) technique can extract useful entity information from meteorological reports. By analyzing the characteristics of nested entities in meteorological reports, this paper further proposes to introduce Multi-Conditional Random Fields (Multi-CRF), which uses each layer of CRF to output the recognition results of each type of entities, which helps to solve the problem of identifying nested entities in meteorological reports. The experimental results show that our model achieves state-of-the-art results. The final recognition results provide effective data support for automatic text verification recognition in the meteorological domain and provide important practical value for the construction of knowledge graphs of related meteorological reports.},
  archive      = {J_IJMLC},
  author       = {Cui, Mengmeng and Huang, Ruibin and Hu, Zhichen and Xia, Fan and Xu, Xiaolong and Qi, Lianyong},
  doi          = {10.1007/s13042-023-01885-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {177-188},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semantic rule-based information extraction for meteorological reports},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated GCN-LSTM stock prices movement prediction based
on knowledge-incorporated graphs construction. <em>IJMLC</em>,
<em>15</em>(1), 161–176. (<a
href="https://doi.org/10.1007/s13042-023-01817-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock prices movement prediction has been a longstanding research topic. Many studies have introduced several kinds of external information like relations of stocks, combined with internal information of trading characteristics to promote forecasting. Different from previous cases, this article proposes a reasonable assumption that major fluctuations of stock prices are mainly triggered by high-volume transactions which usually occur on a group of stocks that share some common features (e.g., stocks in the same industry, region, concept or yield similar volatility), and further develops an integrated GCN-LSTM method to achieve more precise predictions from the perspective of modelling capital flows. First, we construct four kinds of graphs incorporating various relational knowledge (edge) and utilize graph convolutional network (GCN) to extract stock (node) embeddings in multiple time-periods. Then, the obtained temporal sequences of stock embeddings are put into long short-term memory recurrent neural network (LSTM) to discriminate the moving direction of prices. Extensive experiments on major Chinese stock indexes have demonstrated the effectiveness of our model with best accuracy of 57.81% acquired, which is much better than baselines. Moreover, experimental results of GCN-LSTM under different graphs and various node embedding dimensions have been compared and analyzed, indicating the selection of key parameters to achieve optimal performances. Our research findings provide an improved model to forecast stock prices movement directions with a reliable theoretical interpretation, and in depth exhibit insights for further applications of graph neural networks and graph data in business analytics, quantitative finance, and risk management decision-makings.},
  archive      = {J_IJMLC},
  author       = {Shi, Yong and Wang, Yunong and Qu, Yi and Chen, Zhensong},
  doi          = {10.1007/s13042-023-01817-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {161-176},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Integrated GCN-LSTM stock prices movement prediction based on knowledge-incorporated graphs construction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pathological image super-resolution using mix-attention
generative adversarial network. <em>IJMLC</em>, <em>15</em>(1), 149–159.
(<a href="https://doi.org/10.1007/s13042-023-01806-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) is a fundamental research task in low-level vision. Recently it has been applied to digital pathology to build transformations from low-resolution (LR) to super-resolved high-resolution (HR) images, which benefits pathological image sharing, storage, management, etc. However, existing studies on pathological image SR are mostly carried out on simulated dataset. It cannot fully reveal the challenge of real-world SR. Meanwhile, these studies rarely investigate SR models from a pathological-tailored perspective. This paper aims to promote studies on pathological image SR from the two aspects. Firstly, we construct PathImgSR, a dataset containing real-captured paired LR-HR pathological images by leveraging the progressively imaging property of pathological images. Second, we develop MASRGAN, a GAN-based mix-attention network to implement the SR. It devises a mix-attention block that is featured by modeling the channel and spatial attentions in parallel. Therefore it better captures the discriminative feature from pathological images spatially and channel-wisely. Furthermore, by formulating the learning processing in an adversarial learning manner, it also improves the subjective perception quality of the reconstructed HR image. Experiments on PathImgSR demonstrate that MASRGAN outperforms popular CNN-based and GAN-based SR methods in both quantitative metrics and visual subjective perception.},
  archive      = {J_IJMLC},
  author       = {Chen, Zhineng and Wang, Jing and Jia, Caiyan and Ye, Xiongjun},
  doi          = {10.1007/s13042-023-01806-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {149-159},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pathological image super-resolution using mix-attention generative adversarial network},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced neighborhood node graph neural networks for load
forecasting in smart grid. <em>IJMLC</em>, <em>15</em>(1), 129–148. (<a
href="https://doi.org/10.1007/s13042-023-01796-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning technology creates the condition for the optimization of the smart grid, and the big data analytical technique has the most efficient way to analyze and share the power load spatio-temporal data in the smart grid. Utilizing the graph-based method to learn the structure of load date distribution and load prediction has become hot-spot research. This paper proposes EnGAT-BiLSTM, an enhanced graph neural networks framework to realize short-term load prediction. The EnGAT-BiLSTM model aims to improve the prediction accuracy of the load and solve the sampled data sparsity in the short-term prediction. In this model, the Box-Cox transformation technology is used to denoise and obtain the effective load sampled data set; a dynamic load knowledge graph (DLKG) is designed to map the internal attribute of the various electrical load and the correlation of the external influencing factors; the graphic attention mechanism is introduced in the local network structure of graph neural network (GNN) to extract the high-quality load spatio-temporal features; the deep bi-directional long short-term memory (BiLSTM) framework is used for the lifelong learning of the load prediction. The extensive load-sampled datasets in the real world are employed to evaluate our method. The experimental results indicate that EnGAT-BiLSTM improves significantly in load prediction accuracy and has good robustness. The model will provide a valuable theoretical basis and guidance for the smart grid IoT system.},
  archive      = {J_IJMLC},
  author       = {Yanmei, Jiang and Mingsheng, Liu and Yangyang, Li and Yaping, Liu and Jingyun, Zhang and Yifeng, Liu and Chunyang, Liu},
  doi          = {10.1007/s13042-023-01796-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {129-148},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced neighborhood node graph neural networks for load forecasting in smart grid},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A graph-powered large-scale fraud detection system.
<em>IJMLC</em>, <em>15</em>(1), 115–128. (<a
href="https://doi.org/10.1007/s13042-023-01786-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-powered fraud detection is a common issue in various areas, such as e-commerce, banking, insurance and social networks, where data can be naturally formulated as graph structure. Especially in e-commerce, due to its large scale and enormous amount of real-time transactions over millions of merchandises, fraud detection has become an important and serious problem. The challenges lie in three aspects: sparse fraud samples, complex features in online transactions and extra-large scale of e-commerce data. To deal with above issues, in this paper, we propose an efficient graph-powered large-scale fraud detection framework. Concretely, we first present a heterogeneous label propagation algorithm to recall more potentially fraudulent samples for further model training; then, we design a novel multi-view heterogeneous graph neural network model to obtain more accurate fraud predictions; finally, a fraud pattern analysis approach is presented to discover hidden fraud groups. In addition, in order to improve the efficiency and scalability of our proposed fraud detection framework, we present a large-scale fraud detection system deployed on a general graph computing engine. We conduct experiments on two real-world datasets. Results show that the proposed graph-powered fraud detection framework achieves high accuracy and superior scalability on large-scale graph data.},
  archive      = {J_IJMLC},
  author       = {Li, Zhao and Wang, Biao and Huang, Jiaming and Jin, Yilun and Xu, Zenghui and Zhang, Ji and Gao, Jianliang},
  doi          = {10.1007/s13042-023-01786-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {115-128},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A graph-powered large-scale fraud detection system},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online handwritten scripts classification using fuzzy
attributed relational graphs. <em>IJMLC</em>, <em>15</em>(1), 97–114.
(<a href="https://doi.org/10.1007/s13042-023-01772-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs serve as highly powerful representational tools which are particularly well-suited for a great variety of computer applications such as computer vision and handwriting recognition. In this work, we set forward a novel fuzzy graph-based framework to model each script as a fuzzy attributed graph (FARG) and reformulate the task of classification as a fuzzy graph matching problem. In this respect, we start by modeling each script as a FARG where a segment represents a node and edges represent relations between segments. Hence, each node and edge is characterized by a set of fuzzy membership degrees describing their properties. The use of fuzzy attributes allows us to guarantee more robustness against uncertainty, ambiguity and vagueness. We model then the classification problem as a Multi-Criteria Decision Making (MCDM) problem. Given a pair of graphs as input, a similarity score between them is computed by reasoning on the pair through a tree-search based optimal matching algorithm. A full analysis is performed on two large datasets: MAYASTROUN and ADAB. Our approach achieved a 0.69% character error rate (CER) and a 1.45% word error rate (WER) against the MAYASTROUN data set and a 2.66% WER against the ADAB data set. Afterwards, we compare the results and the functionality that we obtain with the findings from existing state of the art approaches. In this regard, the accuracy and goodness of fit of the presented work is conclusively validated.},
  archive      = {J_IJMLC},
  author       = {Zitouni, Rabiaa and Bezine, Hala and Arous, Najet},
  doi          = {10.1007/s13042-023-01772-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {97-114},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Online handwritten scripts classification using fuzzy attributed relational graphs},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Label graph augmented soft cascade decoding model for
overlapping event extraction. <em>IJMLC</em>, <em>15</em>(1), 79–95. (<a
href="https://doi.org/10.1007/s13042-022-01760-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction (EE) is a fundamental information extraction task that aims to identify structured events, including event types, triggers and arguments, from unstructured texts. The overlapping EE, in which a trigger may be assigned to multiple event types, or an argument owns more than one role, is a more challenging task. Existing methods deconstruct the task in a pipeline-based cascade decoding paradigm, sequentially extracting overlapping event elements (triggers and arguments) based on the previous extracted results. On the one hand, this hard cascade decoding architecture is prone to serious error propagation in overlapping EE. On the other hand, they ignore the correlation between event types and argument roles, which is beneficial for this task. Facing these issues, we present an Event-Role label graph augmented cascade framework by modeling EE as a sub-task-dependent soft decoding architecture. To mitigate error propagation between sub-tasks, we propose a reliability-aware soft cascading module, which gradually transfers smoother features to downstream sub-tasks. To further enhance the model’s ability to classify overlapped elements, we design the Event-Role label graph representation learner to incorporate event-to-event and role-to-role association information into label space of event types and argument roles. It facilitates overlapped elements to be assigned to multiple labels with approximate feature space. We perform extensive experiments on two widely-used EE benchmark datasets, FewFC and ACE-2005, where our model outperforms state-of-the-art methods on the overlapping EE task and also adapts to the general EE without overlapped elements.},
  archive      = {J_IJMLC},
  author       = {Hei, Yiming and Wang, Lihong and Sheng, Jiawei and Liu, Jianwei and Li, Qian and Guo, Shu},
  doi          = {10.1007/s13042-022-01760-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {79-95},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Label graph augmented soft cascade decoding model for overlapping event extraction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view bayesian spatio-temporal graph neural networks
for reliable traffic flow prediction. <em>IJMLC</em>, <em>15</em>(1),
65–78. (<a href="https://doi.org/10.1007/s13042-022-01689-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is critically essential to transportation safety and Intelligent Transportation Systems (ITS). Existing approaches generally assume the traffic data are complete and reliable. However, in real scenarios, the traffic data are usually sparse and noisy due to the unreliability of the road sensors. Meanwhile, the global semantic traffic correlations among the road links over the road network are largely ignored by existing works. To address these issues, in this paper we study the novel problem of reliable traffic prediction with noisy and sparse traffic data and propose a Multi-View Bayesian Spatio-Temporal Graph Neural Network (MVB-STNet for short) to effectively address it. Specifically, we first construct the traffic flow graphs from two views, the structural traffic graph based on the topological closeness of the road sensors, and the semantic traffic graph which is constructed based on the traffic flow correlations among all the road sensors. Then the features of the two views are learned simultaneously to more broadly capture the spatial correlations. Inspired by the effectiveness of Bayesian neural networks in handling data uncertainty, we design the Bayesian Spatio-Temporal Long Short-Term Memory Net layer to more effectively learn the spatio-temporal features from the sparse and noisy traffic data. Extensive evaluations are conducted over two real traffic datasets. The results show that our proposal significantly improves current state-of-the-arts in terms of traffic flow prediction with sparse and noisy data.},
  archive      = {J_IJMLC},
  author       = {Xia, Jiangnan and Wang, Senzhang and Wang, Xiang and Xia, Min and Xie, Kun and Cao, Jiannong},
  doi          = {10.1007/s13042-022-01689-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {65-78},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view bayesian spatio-temporal graph neural networks for reliable traffic flow prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spatio-temporal graph cross-correlation auto-encoding
network for wind power prediction. <em>IJMLC</em>, <em>15</em>(1),
51–63. (<a href="https://doi.org/10.1007/s13042-022-01688-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rate of wind energy shows a sharp increase in recent years. Due to the instability, it is necessary to accurately predict the value of wind power over a period of time. Wind turbine cluster power prediction is an emerging form of wind power prediction in recent years, which can simultaneously predict the wind power value in a region. Recently, many researchers have utilized convolutional neural networks to process spatio-temporal representation constructed by multi-turbines’ data. However, the research to date has tended to focus on local spatial scale rather than global spatio-temporal scale. The wind has instability, drastic changes, and wake effects, but local features cannot cover the affected area in the entire wind propagation process. To address this problem, this paper proposes a Spatio-temporal Graph Cross-correlation Auto-encoding Network (STGCAN) for wind power prediction, which can extract global wind power features and improve the problem that convolution and its derived methods only extract local features. The STGCAN performs hierarchical feature extraction on wind turbine clusters through the hierarchical structure of the shallow spatio-temporal feature layer, the feature cohesion layer, as well as the spatio-temporal graph cross-correlation auto-encoding layer altogether. It can extract both the local and global features of wind power. Experiments show that the mean square error of wind power prediction of the new approach is on average reduced by 20.87% over all the baseline methods.},
  archive      = {J_IJMLC},
  author       = {Yu, Ruiguo and Sun, Yingzhou and He, Dongxiao and Gao, Jie and Liu, Zhiqiang and Yu, Mei},
  doi          = {10.1007/s13042-022-01688-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {51-63},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Spatio-temporal graph cross-correlation auto-encoding network for wind power prediction},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MORE: Toward improving author name disambiguation in
academic knowledge graphs. <em>IJMLC</em>, <em>15</em>(1), 37–50. (<a
href="https://doi.org/10.1007/s13042-022-01686-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Author name disambiguation (AND) is a fundamental task in knowledge alignment for building a knowledge graph network or an online academic search system. Existing AND algorithms tend to cause over-splitting and over-merging problems of papers, severely jeopardizing the performance of downstream tasks. In this paper, we demonstrate the problem of paper over-splitting and over-merging when constructing an academic knowledge graph. To address the problems, we systematically investigate and propose a unified architecture, MORE, which utilizes LightGBM and HAC FOR paper clusteRing as well as HGAT for both cluster alignmEnt and knowledge graph representation learning. Specifically, we first propose a novel representation learning method which leverages OAG-BERT to learn paper entity embedding and utilizes SimCSE to regularizes pre-trained embedding anisotropic space. We then apply LightGBM to calculate the similarity matrix of papers through entity embedding. We also use hierarchical agglomerative clustering (HAC) for grouping clusters to alleviate over-merging. Finally, considering co-author relationships, we improve the HGAT model using hard-cross graph attention mechanism to generate semantic and structural embedding. Experimental results on two large real-world datasets show that our proposed method achieves 6% $$\sim$$ 16% improvement against the baseline models on F1-score.},
  archive      = {J_IJMLC},
  author       = {Gong, Jibing and Fang, Xiaohan and Peng, Jiquan and Zhao, Yi and Zhao, Jinye and Wang, Chenlong and Li, Yangyang and Zhang, Jingyi and Drew, Steve},
  doi          = {10.1007/s13042-022-01686-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {37-50},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MORE: Toward improving author name disambiguation in academic knowledge graphs},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A descriptive human visual cognitive strategy using graph
neural network for facial expression recognition. <em>IJMLC</em>,
<em>15</em>(1), 19–35. (<a
href="https://doi.org/10.1007/s13042-022-01681-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the period of rapid development on the new information technologies, computer vision has become the most common application of artificial intelligence, which is represented by deep learning in the current society. As the most direct and effective application of computer vision, facial expression recognition (FER) has become a hot topic and used in many studies and domains. However, the existing FER methods focus on deep learning to generate increasingly complex attention structures, so they are unable to consider the connotative relationship between different parts of facial expressions. Moreover, the human expression recognition method based on complex deep learning network has serious interpretability issues. Therefore, in this paper, a novel Graph Neural Network (GNN) model is proposed to consider the systematic process of FER in human visual perception. Firstly, a region division mechanism is proposed, which divides the face region into six parts to unify the selection of key facial features. On this basis, in order to better consider the connotative relationship between different parts of facial expression, a human visual cognition strategy is proposed, which uses the divided six regions to learn facial expression features, and evenly selects the key features with high reliability as graph nodes. In combination with the human regional cooperative recognition process, the connotative relationship (such as relative position and similar structure) between graph nodes is extracted, so as to construct the GNN model. Finally, the effect of FER is obtained by the modeled GNN model. The experimental results compared with other related algorithms show that the model not only has stronger characterization and generalization ability, but also has better robustness compared with state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Liu, Shuai and Huang, Shichen and Fu, Weina and Lin, Jerry Chun-Wei},
  doi          = {10.1007/s13042-022-01681-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {19-35},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A descriptive human visual cognitive strategy using graph neural network for facial expression recognition},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Knowledge-based and data-driven underground pressure
forecasting based on graph structure learning. <em>IJMLC</em>,
<em>15</em>(1), 3–18. (<a
href="https://doi.org/10.1007/s13042-022-01650-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pressure prediction technology whereby represents the rock pressure law in the excavation is fundamental to safety in production and industrial intelligentization. A growing number of researchers dedicate that machine learning is used to accurate prediction of underground pressure changes. However, the existing research which based on the classical machine learning rarely considers the cause between inducement of underground pressure and the underground pressure change. In this paper, we propose a novel Reinforced and Causal Graph Neural Network, namely RC-GNN, for the prediction task, to overcome the shortage of causal logic. First, we build a causal graph by considering internal relations between inducement and display of pressure and employ prior knowledge to erect the early and properties of the graph. Second, we construct the prediction network for underground pressure by graph convolutional networks and long short-term memory. Finally, we use the performance index of underground pressure prediction to design a reinforcement learning algorithm, which achieves optimization of the causal graph. Compared to six representative methods, experimental results with 18–60% increases in performance on the real prediction task.},
  archive      = {J_IJMLC},
  author       = {Wang, Yue and Liu, Mingsheng and Huang, Yongjian and Zhou, Haifeng and Wang, Xianhui and Wang, Senzhang and Du, Haohua},
  doi          = {10.1007/s13042-022-01650-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {3-18},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge-based and data-driven underground pressure forecasting based on graph structure learning},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Introduction to the special issue on recent advances in
graph learning: Theory, algorithms, applications, and systems.
<em>IJMLC</em>, <em>15</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s13042-023-02011-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Peng, Hao and Wu, Jia and Cui, Jiaxu and Yu, Philip S.},
  doi          = {10.1007/s13042-023-02011-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Introduction to the special issue on recent advances in graph learning: Theory, algorithms, applications, and systems},
  volume       = {15},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
