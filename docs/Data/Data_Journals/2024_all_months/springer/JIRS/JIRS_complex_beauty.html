<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JIRS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jirs---170">JIRS - 170</h2>
<ul>
<li><details>
<summary>
(2024). Introduction of a framework for the integration of a
kinematic robot arm model in an artificial neural network - extended
kalman filter approach. <em>JIRS</em>, <em>110</em>(4), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02164-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to introduce a model in which systematic effects can be assigned according to their origin or mode of action. The approach intends to improve the positional accuracy of a robot arm. We show the impact of unaccounted model biases on estimated parameters when applying sequential approaches and conclude the necessity of jointly determining all influencing variables. Therefore, we propose a simultaneous estimation of transformation parameters, robot’s kinematic parameters and non-geometric parameters modelled by an artificial neural network (ANN) in further consequence. Thus, the main contribution of this paper is a new approach of the simultaneous estimation of the geometric and non-geometric components of a robot arm model. The integration of the geometric model (transformations, kinematic robot model) with the non-geometric one (ANN) is realised in the extended Kalman filter. The functionality of the algorithm has been proven on simulated data. The adaptive behaviour of machine learning approaches is made possible by an additional iteration of the ANN. The initialisation of the ANN parameters must not deviate from the nominal parameters by more than 10% so that the ANN can learn the non-geometric part. In this setup, the robot arm position corrections are reduced by 32.5%. A final sensitivity analysis proves the estimability of most kinematic parameters in the course of a future adaptive extension of the approach.},
  archive      = {J_JIRS},
  author       = {Horvath, Sabine and Neuner, Hans},
  doi          = {10.1007/s10846-024-02164-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Introduction of a framework for the integration of a kinematic robot arm model in an artificial neural network - Extended kalman filter approach},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel MPC formulation for dynamic target tracking with
increased area coverage for search-and-rescue robots. <em>JIRS</em>,
<em>110</em>(4), 1–24. (<a
href="https://doi.org/10.1007/s10846-024-02167-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are increasingly deployed for search-and-rescue (SaR), in order to speed up rescuing the victims in the aftermath of disasters. These robots require effective mission planning approaches to determine time and space-efficient trajectories that steer them faster towards (moving) victims, while dealing with uncertainties. Model predictive control (MPC) is an effective optimization-based control approach that has been used to steer robots along reference trajectories determined by higher level controllers. Determining the trajectory of the robots directly via MPC has the advantage of optimizing multiple SaR criteria while handling the constraints. We, thus, introduce a path planning approach based on MPC for indoor SaR robots that allows the robot to systematically chase the moving victims, when no reference trajectory is provided. The proposed approach combines target-oriented and coverage-oriented search, and allows for systematic handling of environmental uncertainties, by deploying a robust tube-based version of the introduced MPC formulation. In addition, we model the movements of the victims for MPC, by adopting an existing evacuation model. We present a case study, using Gazebo, MATLAB, and ROS, where the performance of the proposed MPC controller is evaluated compared to four state-of-the-art methods (two target-oriented methods based on MPC and A* and two heuristic algorithms for area coverage). The results show that, while robust to uncertainties, our approach overall outperforms the other methods, with regards to victim detection, area coverage, and mission time.},
  archive      = {J_JIRS},
  author       = {Baglioni, Mirko and Jamshidnejad, Anahita},
  doi          = {10.1007/s10846-024-02167-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-24},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A novel MPC formulation for dynamic target tracking with increased area coverage for search-and-rescue robots},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A traffic sign recognition system based on lightweight
network learning. <em>JIRS</em>, <em>110</em>(4), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02173-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the comprehensive performance of the traffic sign system, this paper proposes a lightweight and efficient network model for the existing traffic sign recognition system, which is characterized by the complex structure of the convolutional neural network, the number of parameters and the computational volume is too large, and the model is not lightweight enough. The model chooses the lighter MobileNetV1 as its backbone network, and redefines the output layer of MobileNetV1 to effectively reduce the overall number of parameters of the network, so as to achieve the purpose of simplifying the network structure. The experimental results show that the proposed model can reduce the number of parameters by 25.5%, 37.9% and 53.8%, compared with YOLOv5n, YOLOv8n and YOLOv3 respectively, and the model complexity/computation (GFLOPs) and image processing speed (FPS) show outstanding advantages compared with several models, under the premise that the detection accuracy of the proposed model is considerable. show outstanding advantages. Finally, by building an unmanned vehicle testbed configured with STM32F103 CPU and OV2640 camera, the model pre-training weights are deployed on the hardware testbed for real testing, and the results show that the proposed lightweight network model meets the requirements of traffic sign recognition accuracy and improves the model&#39;s operation efficiency on the computationally resource-constrained devices.},
  archive      = {J_JIRS},
  author       = {Zhang, Guangyin and Li, Zixu and Huang, Dan and Luo, Wenguang and Lu, Zhengjie and Hu, Yingbai},
  doi          = {10.1007/s10846-024-02173-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A traffic sign recognition system based on lightweight network learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative load transportation with quadrotors using
adaptive RISE control. <em>JIRS</em>, <em>110</em>(4), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02174-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of transporting cable-suspended payloads using two quadrotors is analyzed in this work. The system kinematics are treated using a virtual structure formation controller, which generates the acceleration references commanded to the aerial vehicles. The disturbances caused by the payload are treated as unmodeled disturbances and a novel robust integral of the sign of the error (RISE) controller is proposed, guaranteeing the asymptotic convergence of the tracking errors. A model reference adaptive control is also incorporated into the RISE controller, combining the advantages of adaptive and robust control. The proposal is validated by numerous experiments using two quadrotors to transport a bar-shaped payload in adverse conditions. The results allow the conclusion that the proposed system is capable of performing transportation and orientation tasks with the payload, subject to translational accelerations up to 3.5 m/s $$^2$$ .},
  archive      = {J_JIRS},
  author       = {K. D. Villa, Daniel and S. Brandão, Alexandre and Sarcinelli-Filho, Mário},
  doi          = {10.1007/s10846-024-02174-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Cooperative load transportation with quadrotors using adaptive RISE control},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimization on 2D-SLAM map construction algorithm based
on LiDAR. <em>JIRS</em>, <em>110</em>(4), 1–23. (<a
href="https://doi.org/10.1007/s10846-024-02123-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a mobile robot moves in an unknown environment, the emergence of Simultaneous Localization and Mapping (SLAM) technology becomes crucial for accurately perceiving its surroundings and determining its position in the environment. SLAM technology successfully addresses the issues of low localization accuracy and inadequate real-time performance of traditional mobile robots. In this paper, the Robot Operating System (ROS) robot system is used as a research platform for the 2D laser SLAM problem based on the scan matching method. The study investigates the following aspects: enhancing the scan matching process of laser SLAM through the utilization of the Levenberg–Marquardt (LM) method; improving the optimization map by exploring the traditional Hector-SLAM algorithm and 2D-SDF-SLAM algorithm, and employing the Weighted Signed Distance Function (WSDF) map for map enhancement and optimization; proposing a method for enhanced relocation using the Cartographer algorithm; establishing the experimental environment and conducting experiments utilizing the ROS robot system. Comparing and analyzing the improved SLAM method with the traditional SLAM method, the experiment proves that the improved SLAM method outperforms in terms of localization and mapping accuracy. The research in this paper offers a robust solution to the challenge of localizing and mapping mobile robots in unfamiliar environments, making a significant contribution to the advancement of intelligent mobile robot technology.},
  archive      = {J_JIRS},
  author       = {Li, Zhuoran and Chamran, Kazem and Alobaedy, Mustafa Muwafak and Sheikh, Muhammad Aman and Siddiqui, Tahir and Ahad, Abdul},
  doi          = {10.1007/s10846-024-02123-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-23},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {An optimization on 2D-SLAM map construction algorithm based on LiDAR},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing drone delivery paths from shared bases: A
location-routing problem with realistic energy constraints.
<em>JIRS</em>, <em>110</em>(4), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02129-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Amazon patented fulfillment centers for drones on a large scale in densely populated areas. A network of such shared centers can be used for landing and launching drones as an alternative to the traditional private bases in near future. This paper studies how a user of such a shared delivery infrastructure can optimally determine the required bases among the existing bases to perform her delivery tasks. To this end, a location-routing problem is studied where the problem determines the drone launching centers and their routes to deliver parcels. A realistic energy function is used that incorporates the effect of load weight for calculating energy consumption in all flight phases including take-off, level flight, hovering, and landing. Although the energy consumption is nonlinear, the problem is formulated as a mixed-integer linear programming model and strengthened by valid inequalities and a pre-processing algorithm that enables us to solve instances with up to 100 customers using off-the-shelf optimization solvers. Moreover, a heuristic method is presented to solve instances with up to 200 customers. Results indicate the importance of incorporating the load-dependent energy formula in contrast to using fixed flight duration constraints for drones. The value of allowing multiple visits on each trip versus only simple back-and-forth trips is also assessed. The advantage of using an integrated location-routing approach is shown over the sequential approach in which the locations of bases are decided first and the routes are constructed next. Moreover, to manage future demand uncertainty, the model is extended for the case that a number of demand scenarios are given.},
  archive      = {J_JIRS},
  author       = {Meskar, Mahla and Ahmadi-Javid, Amir},
  doi          = {10.1007/s10846-024-02129-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Optimizing drone delivery paths from shared bases: A location-routing problem with realistic energy constraints},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hazards, risks and selected security problems in unnmaned
aircraft vehicles operations. <em>JIRS</em>, <em>110</em>(4), 1–8. (<a
href="https://doi.org/10.1007/s10846-024-02157-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article pertains to hazards and risk as well as selected security problems in unmanned aircraft vehicles operations from legal and policy perspective. It covers regulations concerning drones, statistics, safety promotion in drone sector and key risk areas. In the current world, there is a need for new legal provisions and technical solutions that will bring stability and security to public airspace. With the rapid development of artificial intelligence, more reliable hardware, and efficient software, new threats for the public domain are emerging that we have never faced before. The usage of UAVs is limited only by human imagination. It is already used in search and rescue (SAR) missions (increasing search coverage and reducing the risk of rescuers), the professional movie industry (creating breathtaking shots), or the agricultural sector (plants optimization). Hence the need to identify key safety and security concerns that might disrupt such operations.},
  archive      = {J_JIRS},
  author       = {Osiecki, Mateusz and Cyran, Klaudia and Dębowski, Leon},
  doi          = {10.1007/s10846-024-02157-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-8},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Hazards, risks and selected security problems in unnmaned aircraft vehicles operations},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An emotional-based methodology to detect preferences in a
decision-making process applied to a virtual service robot.
<em>JIRS</em>, <em>110</em>(4), 1–20. (<a
href="https://doi.org/10.1007/s10846-024-02163-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multi-objective problem, no single solution optimally satisfies all objectives. Thus, the challenge is to find a balance between conflicting objectives. The decision-making necessarily requires human intervention. The person responsible for selecting the most appropriate solution among all the trade-off solutions is the decision maker (DM). The DM seeks to approach only the solutions that best suit her/his preferences. Since there is plenty of specialized literature showing that emotions play a critical role in decision-making, we aim to incorporate them into the decision-making process. To elicit emotions that can be quantifiable, we propose the Emotional Assessment Method. The method presents a simulation of the objectives to be optimized that represents the consequences of each decision. Using this methodology, the decision maker assesses the emotions evoked by each presented simulation to guide his/her search for solutions that satisfy his/her preferences. As a case study, we aim to identify subjects’ preferences towards robot behaviors. Seventy-two subjects with varying levels of familiarity with robots (divided into two datasets) participated in the experiments. We concluded that the method elicits subjects’ emotions while observing the consequences of the robot’s performance. Also, we found out that it is possible to identify subjects’ preferences based on both the context and the emotions to select the robot’s behavior.},
  archive      = {J_JIRS},
  author       = {Alvarado-González, Montserrat and López Jaimes, Antonio},
  doi          = {10.1007/s10846-024-02163-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {An emotional-based methodology to detect preferences in a decision-making process applied to a virtual service robot},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite-time dynamic event-triggered full-state constraints
consensus control for multiagent systems with switching topologies and
mismatched disturbances. <em>JIRS</em>, <em>110</em>(4), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02168-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates finite-time dynamic event-triggered full-state constraints consensus control for nonlinear multiagent systems with switching topologies and unknown disturbances. First, all the system states will not exceed the predefined range, which has guiding significance for the constraint control of velocity and position in multiagent systems. Second, to balance the control errors and event-triggered control, a novel finite-time dynamic event-triggered scheme is developed for multiagent systems, which can achieve fast convergence rates and save communication resources. Third, to improve the system performances, a finite-time command filter is designed to remove transient errors resulting from filtering errors and explosion of complexity. All closed-loop signals are proved to be bounded, and the tracking errors quickly converge into a narrow neighborhood of zero in finite-time. To sum up, the proposed control scheme balances the effects of unknown disturbances, unknown nonlinear dynamics, and limited communications bandwidth, which can improve the control performance for the multiagent systems under time-varying switching topologies. Finally, simulation results validate the suggested approach using a mechanical platform model.},
  archive      = {J_JIRS},
  author       = {Hao, Ruolan and Wang, Hongbin and Zheng, Wei},
  doi          = {10.1007/s10846-024-02168-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Finite-time dynamic event-triggered full-state constraints consensus control for multiagent systems with switching topologies and mismatched disturbances},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MULO: LiDAR odometry via MUlti-landmarks joint optimization.
<em>JIRS</em>, <em>110</em>(4), 1–10. (<a
href="https://doi.org/10.1007/s10846-024-02172-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the present stage, LiDAR-based SLAM solutions are dominated by ICP and its variants, while the BA optimization method that can improve the pose consistency has received little attention. Therefore, we propose MULO, a low-drift and robust LiDAR odometry using BA optimization with plane and cylinder landmarks. In the front-end, a coarse-to-fine direct pose estimation method provides the prior pose to the back-end. And in the back-end, we propose a novel three-stage landmark extraction and data association strategy for plane and cylinder, which is robust and efficient. Meanwhile, a stable minimum parameterization method for cylinder landmarks is proposed for optimization. In order to fully utilize the LiDAR information at long distances, we propose a new sliding window structure consisting of a TinyWindow and a SuperWindow. Finally, we jointly optimize the two kinds of landmarks and scan poses in this sliding window. The proposed system is evaluated on public dataset and our dataset, and experimental results show that our system is competitive compared with the state-of-the-art LiDAR odometrys.},
  archive      = {J_JIRS},
  author       = {Liu, Jun and He, Zhengnan and Zhao, Xiaoyu and Hu, Jun and Cheng, Shuai and Liu, Wei},
  doi          = {10.1007/s10846-024-02172-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-10},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {MULO: LiDAR odometry via MUlti-landmarks joint optimization},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Centralized vs. Decoupled dual-arm planning taking into
account path quality. <em>JIRS</em>, <em>110</em>(4), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02175-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of coordinated planning is to avoid robot-to-robot collisions in a multi-robot system, and there are two standard solution approaches: centralized planning and decoupled planning. Our first contribution is a decoupled planning approach that ensures $$\varvec{\mathcal {C}^2}$$ -continuous control commands with zero velocities and zero accelerations at the start and goal. We benchmark our decoupled approach with a centralized approach. Contrary to literature, we show that for a standard motion planning pipeline, such as the one used by MoveIt!, centralized planning is superior to decoupled planning in dual-arm manipulation: It has a lower computation time and a higher robustness. Our second contribution is an optimization that minimizes the rotational motion of an end-effector while considering obstacle avoidance. We derive the analytic gradients of this optimization problem, making the algorithm suitable for online motion planning. Our optimization extends an existing path quality improvement method. Integrating it into our decoupled approach overcomes its shortcomings and provides a motion planning pipeline that is robust at up to 99.9 % with a planning time of less than 1 s and that computes high-quality paths.},
  archive      = {J_JIRS},
  author       = {Wittmann, Jonas and Ochsenfarth, Franziska and Sonneville, Valentin and Rixen, Daniel},
  doi          = {10.1007/s10846-024-02175-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Centralized vs. decoupled dual-arm planning taking into account path quality},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motor fault detection and isolation for multi-rotor UAVs
based on external wrench estimation and recurrent deep neural network.
<em>JIRS</em>, <em>110</em>(4), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02176-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast detection of motor failures is crucial for multi-rotor unmanned aerial vehicle (UAV) safety. It is well established in the literature that UAVs can adopt fault-tolerant control strategies to fly even when losing one or more rotors. We present a motor fault detection and isolation (FDI) method for multi-rotor UAVs based on an external wrench estimator and a recurrent neural network composed of long short-term memory nodes. The proposed approach considers the partial or total motor fault as an external disturbance acting on the UAV. Hence, the devised external wrench estimator trains the network to promptly understand whether the estimated wrench comes from a motor fault (also identifying the motor) or from unmodelled dynamics or external effects (i.e., wind, contacts, etc.). Training and testing have been performed in a simulation environment endowed with a physic engine, considering different UAV models operating under unknown external disturbances and unexpected motor faults. To further assess this approach’s effectiveness, we compare our method’s performance with a classical model-based technique. The collected results demonstrate the effectiveness of the proposed FDI approach.},
  archive      = {J_JIRS},
  author       = {Cacace, Jonathan and Scognamiglio, Vincenzo and Ruggiero, Fabio and Lippiello, Vincenzo},
  doi          = {10.1007/s10846-024-02176-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Motor fault detection and isolation for multi-rotor UAVs based on external wrench estimation and recurrent deep neural network},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal pose representations for 6-DOF object tracking.
<em>JIRS</em>, <em>110</em>(4), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02181-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pose estimation methods for robotics should return a distribution of poses rather than just a single pose estimate. Motivated by this, in this work we investigate multi-modal pose representations for reliable 6-DoF object tracking. A neural network architecture for simultaneous object segmentation and estimation of fiducial points of the object on RGB images is proposed. Given a priori probability distribution of object poses a particle filter is employed to estimate the posterior probability distribution of object poses. An advanced observation model relying on matching the projected 3D model with the segmented object and a distance transform-based object representation is used to weight samples representing the probability distribution. Afterwards, the object pose determined by the PnP algorithm is included in the probability distribution via replacing a particle with the smallest weight. Next, a k-means++ algorithm is executed to determine modes in a multi-modal probability distribution. A multi-swarm particle swarm optimization is then executed to determine the finest modes in the probability distribution. A subset of particles for final pose optimization is found in a multi-criteria analysis using the TOPSIS algorithm. They are verified using conflicting criteria that are determined on the basis of object keypoints, segmented object, and the distance transform. On the challenging YCB-Video dataset it outperforms recent algorithms for both object pose estimation and object pose tracking.},
  archive      = {J_JIRS},
  author       = {Majcher, Mateusz and Kwolek, Bogdan},
  doi          = {10.1007/s10846-024-02181-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Multi-modal pose representations for 6-DOF object tracking},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-aware hierarchical control of joint velocities.
<em>JIRS</em>, <em>110</em>(4), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02182-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, robots are applied in dynamic environments. For a robust operation, the motion planning module must consider other tasks besides reaching a specified pose: (self) collision avoidance, joint limit avoidance, keeping an advantageous configuration, etc. Each task demands different joint control commands, which may counteract each other. We present a hierarchical control that, depending on the robot and environment state, determines online a suitable priority among those tasks. Thereby, the control command of a lower-prioritized task never hinders the control command of a higher-prioritized task. We ensure smooth control signals also during priority rearrangement. Our hierarchical control computes reference joint velocities. However, the underlying concepts of hierarchical control differ when using joint accelerations or joint torques as control signals instead. So, as a further contribution, we provide a comprehensive discussion on how joint velocity control, joint acceleration control, and joint torque control differ in hierarchical task control. We validate our formulation in an experiment on hardware.},
  archive      = {J_JIRS},
  author       = {Wittmann, Jonas and Hornung, Daniel and Griesbauer, Korbinian and Rixen, Daniel},
  doi          = {10.1007/s10846-024-02182-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Energy-aware hierarchical control of joint velocities},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid mobile robot path planning using safe JBS-a*b
algorithm and improved DWA based on monocular camera. <em>JIRS</em>,
<em>110</em>(4), 1–21. (<a
href="https://doi.org/10.1007/s10846-024-02179-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the formidable challenge of enabling autonomous navigation in Mobile Robots (MRs), focusing on the development of advanced path planning strategies. Despite their pivotal role in diverse applications, they face challenges in dynamic settings due to limitation in existing Global Path Planning (GPP) and Local Path Planning (LPP) techniques. In response to this, we propose an innovative hybrid path planning approach that enhances the A* algorithm with a risk-aware heuristic function and integrates the Jump Point Search (JPS) technique for route optimization. Additionally, B-spline smoothing is employed for perceptually global trajectory refinement. Our approach also includes an innovative improvement to the Dynamic Window Approach (DWA) to align with the proposed enhanced A* algorithm for effective local navigation. Acknowledging the importance of high-quality input in path planning, we present substantial improvements to the IRDC-Net, a monocular-image semantic-segmentation model that we studied previously. Novel improvements include the integration of quantization and the Adam optimizer, along with the implementation of the Balanced Cross-Entropy loss function. These enhancements not only elevate the output quality of IRDC-Net but also reduce the model’s training parameters. The experimental results demonstrate the performance and viability of the proposed algorithm. Ultimately, the hybrid MR’s path planning algorithm exhibits proficiency across various tasks, particularly in addressing the challenge of evading moving obstacles to ensure the robot’s safety while adhering to the global path.},
  archive      = {J_JIRS},
  author       = {Dang, Thai-Viet and Tan, Phan Xuan},
  doi          = {10.1007/s10846-024-02179-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Hybrid mobile robot path planning using safe JBS-A*B algorithm and improved DWA based on monocular camera},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient data collection strategy for modeling the dynamics
of floating robotic vehicles using neural networks. <em>JIRS</em>,
<em>110</em>(4), 1–12. (<a
href="https://doi.org/10.1007/s10846-024-02183-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the hydrodynamic model of a surface vehicle is highly nonlinear and of high dimension, an extensive set of experiments is required to estimate the parameters of the model. Typically, the dynamic behavior of a surface vehicle is investigated through experimental tests such as planar motion mechanisms or free running tests in specialized test facilities. However, the cost of such tests is very high, and it is challenging to design effective and efficient test conditions, especially when the model is represented by numerous parameters such as neural networks. In this paper, we propose an efficient data collection strategy for modeling the dynamics of a floating robotic vehicle using neural networks. For generalized modeling, it is important to collect diverse data by exploring all the reachable state space of the vehicle. To achieve this, a data collection policy is built based on sampling-based planning toward reducing the uncertainty of the neural network-based model. The proposed method allows for collecting more comprehensive data than other commonly used random-based data collection policies. We show experimentally that the proposed method enables more accurate modeling of both fully actuated and under-actuated floating robotic vehicles, as demonstrated by the effective execution of various tasks.},
  archive      = {J_JIRS},
  author       = {Jang, Junwoo and Do, Haggi and Ghaffari, Maani and Kim, Jinwhan},
  doi          = {10.1007/s10846-024-02183-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Efficient data collection strategy for modeling the dynamics of floating robotic vehicles using neural networks},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised online continual learning for 3D object
detection in mobile robotics. <em>JIRS</em>, <em>110</em>(4), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02178-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning addresses the challenge of acquiring and retaining knowledge over time across multiple tasks and environments. Previous research primarily focuses on offline settings where models learn through increasing tasks from samples paired with ground truth annotations. In this work, we focus on an unsolved, challenging, yet practical scenario, specifically, the semi-supervised online continual learning in autonomous driving and mobile robotics. In our settings, models are tasked with learning new distributions from streaming unlabeled samples and performing 3D object detection as soon as the LiDAR point cloud arrives. Additionally, we conducted experiments on both the KITTI dataset, our newly built IUSL dataset and Canadian Adverse Driving Conditions (CADC) Dataset. The results indicate that our method achieves a balance between rapid adaptation and knowledge retention, showcasing its effectiveness in the dynamic and complex environment of autonomous driving and mobile robotics. The developed ROS packages and IUSL dataset will be publicly available at: https://github.com/npu-ius-lab/OCL3D .},
  archive      = {J_JIRS},
  author       = {Liu, Binhong and Yao, Dexin and Yang, Rui and Yan, Zhi and Yang, Tao},
  doi          = {10.1007/s10846-024-02178-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Semi-supervised online continual learning for 3D object detection in mobile robotics},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GRID-FAST: A grid-based intersection detection for fast
semantic topometric mapping. <em>JIRS</em>, <em>110</em>(4), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02180-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel approach to constructing a topometric map that allows for efficient navigation and decision-making in mobile robotics applications. The method generates the topometric map from a 2D grid-based map. The topometric map segments areas of the input map into different structural-semantic classes: intersections, pathways, dead ends, and pathways leading to unexplored areas. This method is grounded in a new technique for intersection detection that identifies the area and the openings of intersections in a semantically meaningful way. The framework introduces two levels of pre-filtering with minimal computational cost to eliminate small openings and objects from the map which are unimportant in the context of high-level map segmentation and decision making. The topological map generated by GRID-FAST enables fast navigation in large-scale environments, and the structural semantics can aid in mission planning, autonomous exploration, and human-to-robot cooperation. The efficacy of the proposed method is demonstrated through validation on real maps gathered from robotic experiments: 1) a structured indoor environment, 2) an unstructured cave-like subterranean environment, and 3) a large-scale outdoor environment, which comprises pathways, buildings, and scattered objects. Additionally, the proposed framework has been compared with state-of-the-art topological mapping solutions and is able to produce a topometric and topological map with up to 92% fewer nodes than the next best solution. The method proposed in this article has been implemented in the robotics framework ROS and is open-sourced. The code is available at: https://github.com/LTU-RAI/GRID-FAST .},
  archive      = {J_JIRS},
  author       = {Fredriksson, Scott and Saradagi, Akshit and Nikolakopoulos, George},
  doi          = {10.1007/s10846-024-02180-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {GRID-FAST: A grid-based intersection detection for fast semantic topometric mapping},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A passenger detection and action recognition system for
public transport vehicles. <em>JIRS</em>, <em>110</em>(4), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02194-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, advances of autonomous driving technologies have made significant progress. One successful deployment with great potential is for the self-driving public transportation. Consequently, the safety of passengers under unmanned operations is an important issue for the future development. In this paper, we propose a vision system for the detection, counting and action recognition of passengers on board a bus. To have a complete coverage of the passenger area, a pair of cameras mounted on the ceiling is adopted for image acquisition. A new cross-camera CNN structure is proposed for passenger pose recognition and action classification. To deal with the double counting problem caused by the overlap of multiple viewpoints, a region prediction algorithm is developed for matching validation. The experiments carried out on a minibus have demonstrated the feasibility of our proposed techniques.},
  archive      = {J_JIRS},
  author       = {Lin, Huei-Yung and Kao, Shih-Feng and Wang, Chieh-Chih},
  doi          = {10.1007/s10846-024-02194-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A passenger detection and action recognition system for public transport vehicles},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Longitudinal and lateral cooperative control of preview
intelligent vehicles with stabilization. <em>JIRS</em>, <em>110</em>(4),
1–15. (<a href="https://doi.org/10.1007/s10846-024-02197-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the highly nonlinear and coupled longitudinal and transverse motion control problems of intelligent vehicle path tracking control, a new method of preview MPC path tracking control is proposed by combining visual preview model and model predictive control theory. The method first locally linearizes the nonlinear prediction model and transforms the MPC optimization solution problem into a quadratic programming problem. The longitudinal vehicle speed and the preview distance are then treated as known in each control time domain, an exponential model is applied to characterize the longitudinal vehicle speed, and a transverse angular velocity-center of mass lateral deflection ( $$r-\beta $$ ) phase plane plot is applied to characterize the vehicle stability. Finally, proportional integral differential stability controller is designed to improve vehicle stability. Simulation and test results show that: Compared with the MPC tracking control method, the preview MPC control method proposed in this paper can optimize the vehicle tracking performance on different adhesion coefficient road surfaces and improve the tracking accuracy, and this enhancement effect is more obvious at high speeds.},
  archive      = {J_JIRS},
  author       = {Tang, Minan and Chen, Xiaowei and Tang, Kunxi and Zhang, Yaqi and Wang, Wenjuan},
  doi          = {10.1007/s10846-024-02197-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Longitudinal and lateral cooperative control of preview intelligent vehicles with stabilization},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Evolving real-time stereo odometry for AUV
navigation in challenging marine environments. <em>JIRS</em>,
<em>110</em>(4), 1. (<a
href="https://doi.org/10.1007/s10846-024-02192-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIRS},
  author       = {Nordfeldt-Fiol, Bo Miquel and Bonin-Font, Francisco and Oliver, Gabriel},
  doi          = {10.1007/s10846-024-02192-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Correction to: Evolving real-time stereo odometry for AUV navigation in challenging marine environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous cooperative hunting with rule-based and
self-learning control for multiagent systems. <em>JIRS</em>,
<em>110</em>(4), 1–20. (<a
href="https://doi.org/10.1007/s10846-024-02177-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of autonomous cooperative hunting in an unknown dynamic environment, where a group of mobile agents collaborate to capture a moving target. Due to the decentralized decision-making nature of multi-agent systems and the presence of real-world constraints, it is a challenging task. To solve this problem, an artificial rule based hunting algorithm (AR-HA) is firstly developed based on the principles of attraction and repulsion with heading adjustment, and each agent is controlled by the designed rules. Then, to further enhance the stability of cooperative hunting, a self-learning algorithm based on Twin Delayed Deep Deterministic policy gradient (SL-TD3) is proposed. Each agent is governed by its own SL-TD3 controller and learns independently from its interaction with the environment, taking advantage of the reward function designed based on the control rules of AR-HA. Besides, in order to improve training efficiency, imitation learning is employed to initialize the actor network. Experiments on both virtual and real robots demonstrate the effectiveness of the proposed algorithms for autonomous cooperative hunting.},
  archive      = {J_JIRS},
  author       = {Luo, Jiaxiang and Xu, Bozhe and Li, Xiangyang and Yao, Zhannan},
  doi          = {10.1007/s10846-024-02177-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Autonomous cooperative hunting with rule-based and self-learning control for multiagent systems},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of artificial vision and image processing into a
pick and place collaborative robotic system. <em>JIRS</em>,
<em>110</em>(4), 1–27. (<a
href="https://doi.org/10.1007/s10846-024-02195-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of robotics, pick and place applications are becoming increasingly popular due to their ability to automate repetitive tasks that can create temporary or permanent injuries. To enhance the efficiency of these applications, object recognition using a fixed camera or one mounted on a robotic hand has been employed. This paper explores the possibilities of implementing a low-cost camera into a collaborative robotic system. A software architecture has been developed, including modules for perception, pick and place, and part transfer. A comprehensive overview of various intuitive drag-and-drop image processing technologies and their suitability for object recognition in a robotic context is provided. The challenges related to lighting and the effect of shadows in object recognition are discussed. A critical assessment is made of the architecture development platform as well as the study and the results are performed, and the effectiveness of the proposed solution based on the Niop architecture is verified.},
  archive      = {J_JIRS},
  author       = {Santos, Adriano A. and Schreurs, Cas and da Silva, António Ferreira and Pereira, Filipe and Felgueiras, Carlos and Lopes, António M. and Machado, José},
  doi          = {10.1007/s10846-024-02195-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-27},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Integration of artificial vision and image processing into a pick and place collaborative robotic system},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comprehensive review of mobile robot navigation using deep
reinforcement learning algorithms in crowded environments.
<em>JIRS</em>, <em>110</em>(4), 1–22. (<a
href="https://doi.org/10.1007/s10846-024-02198-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigation is a crucial challenge for mobile robots. Currently, deep reinforcement learning has attracted considerable attention and has witnessed substantial development owing to its robust performance and learning capabilities in real-world scenarios. Scientists leverage the advantages of deep neural networks, such as long short-term memory, recurrent neural networks, and convolutional neural networks, to integrate them into mobile robot navigation based on deep reinforcement learning. This integration aims to enhance the robot&#39;s motion control performance in both static and dynamic environments. This paper illustrates a comprehensive survey of deep reinforcement learning methods applied to mobile robot navigation systems in crowded environments, exploring various navigation frameworks based on deep reinforcement learning and their benefits over traditional simultaneous localization and mapping-based frameworks. Subsequently, we comprehensively compare and analyze the relationships and differences among three types of navigation: autonomous-based navigation, navigation based on simultaneous localization and mapping, and planning-based navigation. Moreover, the crowded environment includes static, dynamic, and a combination of obstacles in different typical application scenarios. Finally, we offer insights into the evolution of navigation based on deep reinforcement learning, addressing the problems and providing potential solutions associated with this emerging field.},
  archive      = {J_JIRS},
  author       = {Le, Hoangcong and Saeedvand, Saeed and Hsu, Chen-Chien},
  doi          = {10.1007/s10846-024-02198-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A comprehensive review of mobile robot navigation using deep reinforcement learning algorithms in crowded environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory planning and adaptive fuzzy PID control for
precision in robotic vertebral plate cutting: Addressing force dynamics
and deformation challenges. <em>JIRS</em>, <em>110</em>(4), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02199-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores trajectory planning and cutting force control for spinal surgical robots, focusing on managing cutting deformation and vibration during vertebral plate cutting—a critical challenge in robotic spinal surgery. Through theoretical analysis, simulation, and experimental validation, the research addresses the complexities of cutting force dynamics and the associated deformations. A dynamic equation for vertebral plate cutting is established, providing a theoretical foundation for trajectory planning. A new trajectory planning method using B-spline curves and an interpolation point constraint formula is introduced, enabling precise robot trajectory control. Additionally, an adaptive fuzzy PID control strategy with force feedback is proposed to dynamically adjust the feed rate, effectively suppressing cutting deformation and vibration in real time. Simulations and experiments validate the effectiveness of these methods in reducing force fluctuations and enhancing control stability. The findings offer valuable guidance for improving the performance and safety of spinal surgery robots, optimizing their trajectories, incorporating dynamic sensing, and enhancing safety controls. Future research should focus on refining control strategies for more complex surgical scenarios and validating their applicability under conditions closer to actual surgical environments. This work provides theoretical and practical insights into advancing robotic spinal surgery, contributing to better surgical outcomes and patient safety.},
  archive      = {J_JIRS},
  author       = {Tian, Heqiang and An, Jinchang and Ma, Hongqiang and Tian, Bin},
  doi          = {10.1007/s10846-024-02199-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Trajectory planning and adaptive fuzzy PID control for precision in robotic vertebral plate cutting: Addressing force dynamics and deformation challenges},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Comparison of middlewares in edge-to-edge and edge-to-cloud
communication for distributed ROS 2 systems. <em>JIRS</em>,
<em>110</em>(4), 1–12. (<a
href="https://doi.org/10.1007/s10846-024-02187-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased data transmission and number of devices involved in communications among distributed systems make it challenging yet significantly necessary to have an efficient and reliable networking middleware. In robotics and autonomous systems, the wide application of ROS 2 brings the possibility of utilizing various networking middlewares together with DDS in ROS 2 for better communication among edge devices or between edge devices and the cloud. However, there is a lack of comprehensive communication performance comparison of integrating these networking middlewares with ROS 2. In this study, we provide a quantitative analysis for the communication performance of utilized networking middlewares including MQTT and Zenoh alongside DDS in ROS 2 among a multiple host system. For a complete and reliable comparison, we calculate the latency and throughput of these middlewares by sending distinct amounts and types of data through different network setups including Ethernet, Wi-Fi, and 4G. To further extend the evaluation to real-world application scenarios, we assess the drift error (the position changes) over time caused by these networking middlewares with the robot moving in an identical square-shaped path. Our results show that CycloneDDS performs better under Ethernet while Zenoh performs better under Wi-Fi and 4G. In the actual robot test, the robot moving trajectory drift error over time (96 s) via Zenoh is the smallest. It is worth noting we have a discussion of the CPU utilization of these networking middlewares and the perfosrmance impact caused by enabling the security feature in ROS 2 at the end of the paper.},
  archive      = {J_JIRS},
  author       = {Zhang, Jiaqiang and Yu, Xianjia and Ha, Sier and Peña Queralta, Jorge and Westerlund, Tomi},
  doi          = {10.1007/s10846-024-02187-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Comparison of middlewares in edge-to-edge and edge-to-cloud communication for distributed ROS 2 systems},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online calibration for networked radar tracking of UAS.
<em>JIRS</em>, <em>110</em>(4), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02186-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for effective tracking mechanisms of small unmanned aircraft systems (sUAS) has become crucial as their use has increased in populated areas. This paper presents a practical tracking solution for sUAS using a network of phased array radars. Achieving optimal system performance while tracking the sUAS requires extrinsic calibration of the individual radar systems to a common frame of reference. We propose a straightforward calibration solution based upon the orthogonal Procrustes formulation that uses radar measurements from ground-mounted radar associated with real-time-kinematic global positioning system (RTK-GPS) data. Two variations of the calibration are provided: a batch processing method, and an online method for real-time adjustments. This paper provides a practical analysis of the advantages and disadvantages associated with both calibration methods. This assessment of the calibration methods, along with an evaluation of the radar network’s sUAS tracking ability, is validated by simulation studies and hardware tests. The hardware experiments especially provide valuable insights into the practical implications of the proposed tracking solution.},
  archive      = {J_JIRS},
  author       = {Graff, Douglas and Anderson, Brady and Buck, David and Peterson, Cameron K. and McLain, Tim W. and Warnick, Karl F.},
  doi          = {10.1007/s10846-024-02186-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Online calibration for networked radar tracking of UAS},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-modal and adaptive robot control through hierarchical
quadratic programming. <em>JIRS</em>, <em>110</em>(4), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02193-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel Hierarchical Quadratic Programming (HQP)-based framework that enables multi-tasking control under multiple Human-Robot Interaction (HRI) scenarios. The proposed controllers’ formulations are inspired by real-world contact-rich scenarios, which currently constitute one of the main limitations in terms of widespread practical deployment. Indeed, HRI can occur through different modalities, based on human’s needs. The objective is to create a unique framework for various types of possible interactions, avoiding the necessity of switching between different control architectures, which requires dealing with discontinuities. To achieve this, we firstly propose a HQP-based hybrid Cartesian/joint space impedance control formulation. Based on the robot’s dynamics, this controller enables an adaptive compliance behaviour, while achieving hierarchical motion control. This is validated through a series of experiments that show the accuracy of trajectory tracking, which remains in the order of 10mm during fast motions thanks to the addition of the robot dynamics. Besides, the hybrid compliance behaviour allows to deviate from such accuracy when an interaction is present. We then consider the case in which the human needs to move the robot directly, by proposing a hybrid admittance/impedance controller, that is again based on a HQP formulation and provides inherent softening when conflicting tasks are present, or in close-to-limit and near-singular configurationsa. This is validated through several experiments in which the human easily moves the robot in the workspace via direct physical interaction. Next, we formulate an additional hierarchy that enables force control and allows to maintain a specific interaction force at the end effector. We then extend this to simultaneous force and trajectory tracking. Overall, we obtain a multi-purpose HQP-based control framework, that seamlessly switchwes between interaction modes, enabling multiple hierarchical behaviours, and covering a wide spectrum of interaction types, essential for synergistic HRI.},
  archive      = {J_JIRS},
  author       = {Tassi, Francesco and Ajoudani, Arash},
  doi          = {10.1007/s10846-024-02193-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Multi-modal and adaptive robot control through hierarchical quadratic programming},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Safe navigation on path-following tasks: A study of
MPC-based collision avoidance schemes in distributed robot systems.
<em>JIRS</em>, <em>110</em>(4), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02202-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to enable distributed robot systems to follow time-varying paths safely. Artificial Vector Fields offer a viable alternative for addressing path-following challenges, yet collision avoidance among agents guided by such fields remains an open problem. To address this, we have designed a Model Predictive Control (MPC) setup that integrates an Artificial Vector Field reference with prominent collision avoidance methods, such as Optimal Reciprocal Collision Avoidance (ORCA) and Control Barrier Functions (CBF), to produce real-time, safe solutions. Our work involves a direct comparison between different MPC-based collision avoidance methods, and we have obtained results from various simulation scenarios as well as experiments on real robotic systems (Crazyflie 2.1). We aim to assess the applicability and limitations of these techniques through extracted metrics and insights.},
  archive      = {J_JIRS},
  author       = {da C. Vangasse, Arthur and J. R. Freitas, Elias and V. Raffo, Guilherme and C. A. Pimenta, Luciano},
  doi          = {10.1007/s10846-024-02202-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Safe navigation on path-following tasks: A study of MPC-based collision avoidance schemes in distributed robot systems},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DynaHull: Density-centric dynamic point filtering in point
clouds. <em>JIRS</em>, <em>110</em>(4), 1–11. (<a
href="https://doi.org/10.1007/s10846-024-02203-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of indoor robotics, accurately localizing and mapping in dynamic environments using point clouds can be a challenging task due to the presence of dynamic points. These dynamic points are often represented by people in indoor environments, but in industrial settings with moving machinery, there can be various types of dynamic points. This study introduces DynaHull, a novel technique designed to enhance indoor mapping accuracy by effectively removing dynamic points from point clouds. DynaHull works by leveraging the observation that, over multiple scans, stationary points have a higher density compared to dynamic ones. Furthermore, DynaHull addresses mapping challenges related to unevenly distributed points by clustering the map into smaller sections. In each section, the density factor of each point is determined by dividing the number of neighbors by the volume these neighboring points occupy using a convex hull method. The algorithm removes the dynamic points using an adaptive threshold based on the point count of each cluster, thus reducing the false positives. The performance of DynaHull was compared to state-of-the-art techniques, such as ERASOR, Removert, OctoMap + SOR , and Dynablox, by comparing each method to the ground truth map created during a low activity period in which only a few dynamic points were present. The results indicated that DynaHull outperformed these techniques in various metrics, noticeably in the Earth Mover’s Distance, false negatives and false positives. The data and code for DynaHull are available at https://github.com/Pejman712/DynaHull.git.},
  archive      = {J_JIRS},
  author       = {Habibiroudkenar, Pejman and Ojala, Risto and Tammi, Kari},
  doi          = {10.1007/s10846-024-02203-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-11},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {DynaHull: Density-centric dynamic point filtering in point clouds},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LR-SLAM: Visual inertial SLAM system with redundant line
feature elimination. <em>JIRS</em>, <em>110</em>(4), 1–12. (<a
href="https://doi.org/10.1007/s10846-024-02184-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study focuses on the simultaneous localization and mapping (SLAM) system based on point and line features. Aiming to address the prevalent issue of repeated detection during line feature extraction in low-texture environments, a novel method for merging redundant line features is proposed. This method effectively mitigates the problem of increased initial pose estimation error that arises when the same line is erroneously detected as multiple lines in adjacent frames. Furthermore, recognizing the potential for the introduction of line features to prolong the marginalization process of the information matrix, optimization strategies are employed to accelerate this process. Additionally, to tackle the issue of insufficient point feature accuracy, subpixel technology is introduced to enhance the precision of point features, thereby further reducing errors. Experimental results on the European Robotics Challenge (EUROC) public dataset demonstrate that the proposed LR-SLAM system exhibits significant advantages over mainstream SLAM systems such as ORB-SLAM3, VINS-Mono, and PL-VIO in terms of accuracy, efficiency, and robustness.},
  archive      = {J_JIRS},
  author       = {Jiang, Hao and Cang, Naimeng and Lin, Yuan and Guo, Dongsheng and Zhang, Weidong},
  doi          = {10.1007/s10846-024-02184-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {LR-SLAM: Visual inertial SLAM system with redundant line feature elimination},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intent-based task-oriented shared control for intuitive
telemanipulation. <em>JIRS</em>, <em>110</em>(4), 1–24. (<a
href="https://doi.org/10.1007/s10846-024-02185-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unique challenges in shared control for telemanipulation-beyond teleoperation-include physical discrepancy between human and robot hands and the fine manipulation constraints needed for task success. We present an intuitive shared-control strategy that generates robotic grasp poses better suited for human perception of success and feeling of control while ensuring a stable grasp for task success. The robot’s motion follows an arbitration between following the user’s motion constraints and accomplishing the inferred task. The arbitration adapts based on the physical discrepancy between the human and robot hands. We have conducted a user study with a telemanipulation scenario to analyze the effects of task predictability, following, and user preference. The results demonstrated that intent-based approaches provide advantages over direct motion mapping strategies.},
  archive      = {J_JIRS},
  author       = {Bowman, Michael and Zhang, Jiucai and Zhang, Xiaoli},
  doi          = {10.1007/s10846-024-02185-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-24},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Intent-based task-oriented shared control for intuitive telemanipulation},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global round-up strategy based on an improved hungarian
algorithm for multi-robot systems. <em>JIRS</em>, <em>110</em>(4), 1–14.
(<a href="https://doi.org/10.1007/s10846-024-02190-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a round-up strategy is proposed to optimize global target selection and improve the efficiency of multi-robot round-up behavior, which is applicable to the round-up situation with multiple pursuers and multiple evaders. Firstly, a constrained pursuer control strategy is designed to maintain the effectiveness of the area-minimizing round-up strategy. Additionally, a novel and detailed procedure is presented to make the area-minimizing round-up strategy based on Voronoi easier to understand. Then, an improved Hungarian algorithm-based global optimization strategy for target selection is proposed. This algorithm aims to reduce the efficiency due to the uneven position distribution of the robots. Finally, experimental results are given to demonstrate the proposed strategy can improve the global efficiency of multi-robot round-up.},
  archive      = {J_JIRS},
  author       = {Zhou, Meng and Li, Jianyu and Wang, Chang and Wang, Jing and Zhai, Weifeng and Puig, Vicenç},
  doi          = {10.1007/s10846-024-02190-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Global round-up strategy based on an improved hungarian algorithm for multi-robot systems},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Study on self-tuning of robot parameters for EMC vehicle
steering test. <em>JIRS</em>, <em>110</em>(4), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02200-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of electric vehicles and smart internet technologies, ensuring vehicle safety through electromagnetic compatibility (EMC) testing in complex electromagnetic environments has become increasingly critical. However, due to the significant variability in vehicle response characteristics under electromagnetic interference, traditional PID control methods for steering robots struggle to meet the high-precision requirements of such tests. In this study, a novel fuzzy PID parameter self-tuning method is proposed, leveraging a Sparrow Search Algorithm-Back Propagation (SSA-BP) neural network. This method optimizes the fuzzy controller&#39;s quantization factor by constructing a neural network system where the expected motor angle serves as the input and the quantization factor as the output. The quantization factor is then calibrated online through iterative training.The proposed approach enables the steering robot to achieve real-time, adaptive tuning of the PID parameters for the drive motor by adjusting the steering torque according to different vehicle characteristics, thereby enhancing the robot&#39;s anti-interference capability and robustness in EMC testing. The effectiveness of this method is validated through Matlab/Simulink simulations, experiments conducted on the Sensodrive platform, and tests performed in an EMC anechoic chamber. The results indicate that the method offers substantial improvements in control accuracy and anti-interference capabilities, highlighting its strong potential for practical application.},
  archive      = {J_JIRS},
  author       = {Liu, Xuan and Xing, Yuzhe and Liu, Yuqing and Wan, Yuan},
  doi          = {10.1007/s10846-024-02200-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {12},
  number       = {4},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Study on self-tuning of robot parameters for EMC vehicle steering test},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GreatBlue: A 55-pound vertical-takeoff-and-landing
fixed-wing sUAS for science; systems, communication, simulation, data
processing, payloads, package delivery, and mission flight performance.
<em>JIRS</em>, <em>110</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s10846-024-02052-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As small, uncrewed systems (sUAS) grow in popularity and in number, larger and larger drone aircraft will become more common–up to the FAA limit of 55 pound gross take-off weight (GTOW) and beyond. Due to their larger payload capabilities, longer flight time, and better safety systems, autonomous systems that maximize CFR 14 Part 107 flight drone operations regulations will become more common, especially for operations such as imagery or other data collection which scale well with longer flight times and larger flight areas. In this new paper, a unique all-electric 55-pound VTOL transition fixed-wing sUAS specifically engineered for scientific data collection named “GreatBlue” is presented, along with systems, communications, scientific payload, data collection and processing, package delivery payload, ground control station, and mission simulation system. Able to fly for up to 2.5 hours while collecting multispectral remotely-sensed imagery, the unique GreatBlue system is shown, along with a package delivery flight example, flight data from two scientific data collection flights over California almond fields and a Utah Reservoir are shown including flight plan vs. as-flown.},
  archive      = {J_JIRS},
  author       = {Coopmans, Calvin and Slack, Stockton and Schwemmer, Nathan and Vance, Chase and Beckwith, A. J. and Robinson, Daniel J.},
  doi          = {10.1007/s10846-024-02052-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {GreatBlue: A 55-pound vertical-takeoff-and-landing fixed-wing sUAS for science; systems, communication, simulation, data processing, payloads, package delivery, and mission flight performance},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Privacy’s sky-high battle: The use of unmanned aircraft
systems for law enforcement in the european union. <em>JIRS</em>,
<em>110</em>(3), 1–22. (<a
href="https://doi.org/10.1007/s10846-024-02071-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the rapid advancements in Unmanned Aircraft Systems (UAS) technology with enhanced tracking and data collection capabilities, law enforcement authorities re-discovered air as a dimension where state power can be exercised in a more affordable, accessible, and compact way. On the other hand, during law enforcement operations, UAS can collect various types of data that can be personal or sensitive, threatening the right to privacy and data protection of the data subjects. Risks include challenges related to data security, bulk data collection, the diminished transparency and fairness resulting from the inconspicuous nature of UAS, as well as ethical concerns intertwined with privacy and data protection. Upon examination of the legal framework including the General Data Protection Regulation the Law Enforcement Directive, various Aviation rules, and the new proposal for the Artificial Intelligence Act, it becomes apparent that the EU legal framework’s adequacy in safeguarding privacy and data protection against law enforcement use of UAS is context-dependent, varying across use cases. The current framework lacks clarity, leading to arbitrary application and limited protection for data subjects. Enforcement of safeguards is insufficient, and the Aviation Regulations, applicable to law enforcement UAS, require member states&#39; opt-in, which has not occurred as of the authors’ knowledge. The Artificial Intelligence Act addresses UAS operations but focuses on market risks rather than obligations imposed on law enforcement authorities. Consequently, the existing framework is rendered inadequate for medium to high-risk law enforcement operations, leaving individuals vulnerable and insufficiently protected against intrusive UAS surveillance. Rectifying this involves addressing the enforcement gap and making the necessary amendments to relevant regulatory aspects. Additionally, the implementation of specific technical measures and steps to foster effective cooperation among stakeholders in UAS deployment for law enforcement is imperative.},
  archive      = {J_JIRS},
  author       = {Kurtpınar, E. Öykü},
  doi          = {10.1007/s10846-024-02071-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Privacy’s sky-high battle: The use of unmanned aircraft systems for law enforcement in the european union},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). China’s new pattern of rule of law on UAS. <em>JIRS</em>,
<em>110</em>(3), 1–6. (<a
href="https://doi.org/10.1007/s10846-024-02105-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {China as the world’s prominent market for Unmanned Aircraft Systems (UAS) has just passed a new regulation on UAS. The new regulation is expected to form a new pattern of rule of law on UAS in China. With the need for harmonisation of laws internationally, this article highlights the three aspects out of China’s new UAS legislation against an international setting.},
  archive      = {J_JIRS},
  author       = {Zhang, Luping},
  doi          = {10.1007/s10846-024-02105-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-6},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {China’s new pattern of rule of law on UAS},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stereo-RIVO: Stereo-robust indirect visual odometry.
<em>JIRS</em>, <em>110</em>(3), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02116-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots and autonomous systems rely on advanced guidance modules which often incorporate cameras to enable key functionalities. These modules are equipped with visual odometry (VO) and visual simultaneous localization and mapping (VSLAM) algorithms that work by analyzing changes between successive frames captured by cameras. VO/VSLAM-based systems are critical backbones for autonomous vehicles, virtual reality, structure from motion, and other robotic operations. VO/VSLAM systems encounter difficulties when implementing real-time applications in outdoor environments with restricted hardware and software platforms. While many VO systems target achieving high accuracy and speed, they often exhibit high degree of complexity and limited robustness. To overcome these challenges, this paper aims to propose a new VO system called Stereo-RIVO that balances accuracy, speed, and computational cost. Furthermore, this algorithm is based on a new data association module which consists of two primary components: a scene-matching process that achieves exceptional precision without feature extraction and a key-frame detection technique based on a model of scene movement. The performance of this proposed VO system has been tested extensively for all sequences of KITTI and UTIAS datasets for analyzing efficiency for outdoor dynamic and indoor static environments, respectively. The results of these tests indicate that the proposed Stereo-RIVO outperforms other state-of-the-art methods in terms of robustness, accuracy, and speed. Our implementation code of stereo-RIVO is available at: https://github.com/salehierfan/Stereo-RIVO .},
  archive      = {J_JIRS},
  author       = {Salehi, Erfan and Aghagolzadeh, Ali and Hosseini, Reshad},
  doi          = {10.1007/s10846-024-02116-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Stereo-RIVO: Stereo-robust indirect visual odometry},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep model-based reinforcement learning for predictive
control of robotic systems with dense and sparse rewards. <em>JIRS</em>,
<em>110</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02118-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse rewards and sample efficiency are open areas of research in the field of reinforcement learning. These problems are especially important when considering applications of reinforcement learning to robotics and other cyber-physical systems. This is so because in these domains many tasks are goal-based and naturally expressed with binary successes and failures, action spaces are large and continuous, and real interactions with the environment are limited. In this work, we propose Deep Value-and-Predictive-Model Control (DVPMC), a model-based predictive reinforcement learning algorithm for continuous control that uses system identification, value function approximation and sampling-based optimization to select actions. The algorithm is evaluated on a dense reward and a sparse reward task. We show that it can match the performance of a predictive control approach to the dense reward problem, and outperforms model-free and model-based learning algorithms on the sparse reward task on the metrics of sample efficiency and performance. We verify the performance of an agent trained in simulation using DVPMC on a real robot playing the reach-avoid game. Video of the experiment can be found here: https://youtu.be/0Q274kcfn4c .},
  archive      = {J_JIRS},
  author       = {Antonyshyn, Luka and Givigi, Sidney},
  doi          = {10.1007/s10846-024-02118-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Deep model-based reinforcement learning for predictive control of robotic systems with dense and sparse rewards},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). XK-III: A spherical robot with redundant degrees of freedom.
<em>JIRS</em>, <em>110</em>(3), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02121-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spherical robot XK-III, designed with redundant degrees of freedom, addresses the limitations of existing pendulum spherical robot structures by enhancing mobility and environmental adaptability. A nonlinear dynamic model is developed for XK-III’s new drive structure, along with a nonlinear disturbance observer (NDOB) to mitigate perturbations. Additionally, a Fuzzy PID controller (FPID) is implemented to further enhance XK-III’s environmental adaptability. Experimental results confirm the effectiveness of the new design, showing that XK-III equipped with FPID and NDOB outperforms traditional control systems in terms of anti-disturbance capabilities. This research provides valuable insights for the use of spherical robots in complex environments.},
  archive      = {J_JIRS},
  author       = {Lin, Rui and Huo, Jianwen and Yang, Xin and Wang, Qiguan and Yang, Ruilin and Xu, Jinfei},
  doi          = {10.1007/s10846-024-02121-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {XK-III: A spherical robot with redundant degrees of freedom},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Teledrive: An embodied AI based telepresence system.
<em>JIRS</em>, <em>110</em>(3), 1–22. (<a
href="https://doi.org/10.1007/s10846-024-02124-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents ‘Teledrive’, a telepresence robotic system with embodied AI features that empowers an operator to navigate the telerobot in any unknown remote place with minimal human intervention. We conceive Teledrive in the context of democratizing remote ‘care-giving’ for elderly citizens as well as for isolated patients, affected by contagious diseases. In particular, this paper focuses on the problem of navigating to a rough target area (like ‘bedroom’ or ‘kitchen’) rather than pre-specified point destinations. This ushers in a unique ‘AreaGoal’ based navigation feature, which has not been explored in depth in the contemporary solutions. Further, we describe an edge computing-based software system built on a WebRTC-based communication framework to realize the aforementioned scheme through an easy-to-use speech-based human-robot interaction. Moreover, to enhance the ease of operation for the remote caregiver, we incorporate a ‘person following’ feature, whereby a robot follows a person on the move in its premises as directed by the operator. Moreover, the system presented is loosely coupled with specific robot hardware, unlike the existing solutions. We have evaluated the efficacy of the proposed system through baseline experiments, user study, and real-life deployment.},
  archive      = {J_JIRS},
  author       = {Banerjee, Snehasis and Paul, Sayan and Roychoudhury, Ruddradev and Bhattacharya, Abhijan and Sarkar, Chayan and Sau, Ashis and Pramanick, Pradip and Bhowmick, Brojeshwar},
  doi          = {10.1007/s10846-024-02124-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Teledrive: An embodied AI based telepresence system},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-encoder spatio-temporal feature fusion network for
electric vehicle charging load prediction. <em>JIRS</em>,
<em>110</em>(3), 1–11. (<a
href="https://doi.org/10.1007/s10846-024-02125-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicles (EVs) have been initiated as a preference for decarbonizing road transport. Accurate charging load prediction is essential for the construction of EV charging facilities systematically and for the coordination of EV energy demand with the requisite peak power supply. It is noted that the charging load of EVs exhibits high complexity and randomness due to temporal and spatial uncertainties. Therefore, this paper proposes a SEDformer-based charging road prediction method to capture the spatio-temporal characteristics of charging load data. As a deep learning model, SEDformer comprises multiple encoders and a single decoder. In particular, the proposed model includes a Temporal Encoder Block based on the self-attention mechanism and a Spatial Encoder Block based on the channel attention mechanism with sequence decomposition, followed by an aggregated decoder for information fusion. It is shown that the proposed method outperforms various baseline models on a real-world dataset from Palo Alto, U.S., demonstrating its superiority in addressing spatio-temporal data-driven load forecasting problems.},
  archive      = {J_JIRS},
  author       = {Chen, Yufan and Wang, Mengqin and Wei, Yanling and Huang, Xueliang and Gao, Shan},
  doi          = {10.1007/s10846-024-02125-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-11},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Multi-encoder spatio-temporal feature fusion network for electric vehicle charging load prediction},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic bandwidth allocation for collaborative multi-robot
systems based on task execution measures. <em>JIRS</em>,
<em>110</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s10846-024-02126-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-robot systems (MRSs) is a growing field of research that focuses on the collaboration of multiple robots to achieve a common global objective. Managing these systems poses several challenges, including coordination, task allocation, and communication. Among these challenges, a major area of focus is devising an effective communication scheme that ensures robots’ cooperation and adapts to varying conditions during task execution. In this paper, we develop a novel communication management framework tailored for MRSs, specifically addressing dynamic bandwidth distribution in networked teleoperated robotic systems. The algorithm is combined with semi-autonomous formation control based on the Artificial Potential Fields (APF) algorithm, which allows each individual robot to avoid local obstacles autonomously and tries to maintain a desired formation with its neighbors, while the operator is in charge of high-level control only. Common Dynamic Bandwidth Allocation (DBA) algorithms allocate bandwidth to different units based on network conditions and requirements. On the other hand, our proposed DBA scheme dynamically distributes the available bandwidth on communication streams based on factors related to task execution and system performance. In specific, bandwidth is allocated in a way that adapts to changes occurring in the system’s environment and its internal state, including the effect of the autonomous action taken by the path planner on the MRS and the performance of the controller of each individual robot. By addressing the limitations of existing approaches through shaping the communication behavior of the MRS based on performance measures, our proposed algorithm offers a promising solution for improving the performance and efficiency of MRSs. The proposed scheme is tested through simulations on a group of six unmanned aerial vehicles (UAVs) in the Robot Operating System (ROS)-Gazebo simulation environment. The obtained results show the scheme’s capability for enhancing the robotic system’s performance while significantly reducing bandwidth consumption. Experimental testing on two mobile robots further demonstrates the effectiveness of the proposed scheme.},
  archive      = {J_JIRS},
  author       = {Slim, Malak and Daher, Naseem and Elhajj, Imad H.},
  doi          = {10.1007/s10846-024-02126-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Dynamic bandwidth allocation for collaborative multi-robot systems based on task execution measures},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of deep q-learning with a grasp quality network
for robot grasping in cluttered environments. <em>JIRS</em>,
<em>110</em>(3), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02127-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the movement of a robotic arm, collisions can easily occur if the arm directly grasps at multiple tightly stacked objects, thereby leading to grasp failures or machine damage. Grasp success can be improved through the rearrangement or movement of objects to clear space for grasping. This paper presents a high-performance deep Q-learning framework that can help robotic arms to learn synchronized push and grasp tasks. In this framework, a grasp quality network is used for precisely identifying stable grasp positions on objects to expedite model convergence and solve the problem of sparse rewards caused during training because of grasp failures. Furthermore, a novel reward function is proposed for effectively evaluating whether a pushing action is effective. The proposed framework achieved grasp success rates of 92% and 89% in simulations and real-world experiments, respectively. Furthermore, only 200 training steps were required to achieve a grasp success rate of 80%, which indicates the suitability of the proposed framework for rapid deployment in industrial settings.},
  archive      = {J_JIRS},
  author       = {Huang, Chih-Yung and Shao, Yu-Hsiang},
  doi          = {10.1007/s10846-024-02127-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Integration of deep Q-learning with a grasp quality network for robot grasping in cluttered environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Depth-enhanced deep learning approach for monocular camera
based 3D object detection. <em>JIRS</em>, <em>110</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02128-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic 3D object detection using monocular cameras presents significant challenges in the context of autonomous driving. Precise labeling of 3D object scales requires accurate spatial information, which is difficult to obtain from a single image due to the inherent lack of depth information in monocular images, compared to LiDAR data. In this paper, we propose a novel approach to address this issue by enhancing deep neural networks with depth information for monocular 3D object detection. The proposed method comprises three key components: 1)Feature Enhancement Pyramid Module: We extend the conventional Feature Pyramid Networks (FPN) by introducing a feature enhancement pyramid network. This module fuses feature maps from the original pyramid and captures contextual correlations across multiple scales. To increase the connectivity between low-level and high-level features, additional pathways are incorporated. 2)Auxiliary Dense Depth Estimator: We introduce an auxiliary dense depth estimator that generates dense depth maps to enhance the spatial perception capabilities of the deep network model without adding computational burden. 3)Augmented Center Depth Regression: To aid center depth estimation, we employ additional bounding box vertex depth regression based on geometry. Our experimental results demonstrate the superiority of the proposed technique over existing competitive methods reported in the literature. The approach showcases remarkable performance improvements in monocular 3D object detection, making it a promising solution for autonomous driving applications.},
  archive      = {J_JIRS},
  author       = {Wang, Chuyao and Aouf, Nabil},
  doi          = {10.1007/s10846-024-02128-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Depth-enhanced deep learning approach for monocular camera based 3D object detection},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to: Research on real-time detection of stacked
objects based on deep learning. <em>JIRS</em>, <em>110</em>(3), 1. (<a
href="https://doi.org/10.1007/s10846-024-02130-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIRS},
  author       = {Geng, Kaiguo and Qiao, Jinwei and Liu, Na and Yang, Zhi and Zhang, Rongmin and Li, Huiling},
  doi          = {10.1007/s10846-024-02130-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Correction to: Research on real-time detection of stacked objects based on deep learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manipulation of a complex object using dual-arm robot with
mask r-CNN and grasping strategy. <em>JIRS</em>, <em>110</em>(3), 1–16.
(<a href="https://doi.org/10.1007/s10846-024-02132-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hot forging is one of the common manufacturing processes for producing brass workpieces. However forging produces flash which is a thin metal part around the desired part formed with an excessive material. Using robots with vision system to manipulate this workpiece has encountered several challenging issues, e.g. the uncertain shape of flash, color, reflection of brass surface, different lighting condition, and the uncertainty surrounding the position and orientation of the workpiece. In this research, Mask region-based convolutional neural network together with image processing is used to resolve these issues. The depth camera can provide images for visual detection. Machine learning Mask region-based convolutional neural network model was trained with color images and the position of the object is determined by the depth image. A dual arm 7 degree of freedom collaborative robot with proposed grasping strategy is used to grasp the workpiece that can be in inappropriate position and pose. Eventually, experiments were conducted to assess the visual detection process and the grasp planning of the robot.},
  archive      = {J_JIRS},
  author       = {Kijdech, Dumrongsak and Vongbunyong, Supachai},
  doi          = {10.1007/s10846-024-02132-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Manipulation of a complex object using dual-arm robot with mask R-CNN and grasping strategy},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlling a virtual structure involving a UAV and a UGV
for warehouse inventory. <em>JIRS</em>, <em>110</em>(3), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02134-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A control system based on the control paradigm of virtual structure is here proposed for a multi-robot system involving a quadrotor and a ground vehicle, operating in an automated warehouse. The ground robot can either provide extra power to the quadrotor, thus increasing its autonomy, or receive data from it. Therefore, the quadrotor is tethered to the ground robot through flexible cables, thus justifying the adoption of the virtual structure control paradigm, which allows controlling the two vehicles simultaneously. The control approach adopted aims at guiding the virtual vertical line joining the two robots to allow the quadrotor to produce an inventory of goods in an automated warehouse. Therefore, the two robots should visit a sequence of known positions, in front of cabinets of vertically arranged shelves. In each of them the quadrotor should read QR codes, bar-codes or RFID cards corresponding to the stored boxes, to produce the inventory. Therefore, the control objective, the focus of this paper, is to keep the shape of the virtual vertical line linking the two robots while moving. However, when an obstacle appears in the route, such as a box or other robot in the floor or another aerial robot, the formation changes its shape accordingly, to avoid the obstacle. An experiment in lab scale, mimicking a real situation, is run, whose results allow claiming that the proposed system is an effective solution for the problem of controlling a multi-robot system to produce an inventory in an automated warehouse.},
  archive      = {J_JIRS},
  author       = {Moreira, Mauro Sérgio Mafra and Villa, Daniel Khede Dourado and Sarcinelli-Filho, Mário},
  doi          = {10.1007/s10846-024-02134-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Controlling a virtual structure involving a UAV and a UGV for warehouse inventory},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel recursive algorithm for the implementation of
adaptive robot controllers. <em>JIRS</em>, <em>110</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02135-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel recursive and efficient algorithm for real-time implementation of the adaptive and passivity-based controllers in model-based control of robot manipulators is proposed. Many of the previous methods on these topics involve the computation of the regressor matrix explicitly or non-recursive computations, which remains as the main challenge in practical applications. The proposed method achieves a compact and fully recursive reformulation without computing the regressor matrix or its elements. This paper is based on a comprehensive literature review of the previously proposed methods, presented in a unified mathematical framework suitable for understanding the fundamentals and making comparisons. The considered methods are implemented on several processors and their performances are compared in terms of real-time computational efficiency. Computational results show that the proposed Adaptive Newton-Euler Algorithm significantly reduces the computation time of the control law per cycle time in the implementation of adaptive control laws. In addition, using the dynamic simulation of an industrial robot with 6-DoF, trajectory tracking performances of the adaptive controllers are compared with those of non-adaptive control methods where dynamic parameters are assumed to be known.},
  archive      = {J_JIRS},
  author       = {Kaya, Mertcan and Akbulut, Mehmet Ali and Bayraktaroglu, Zeki Yagiz and Kühnlenz, Kolja},
  doi          = {10.1007/s10846-024-02135-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A novel recursive algorithm for the implementation of adaptive robot controllers},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Verification and validation for a digital twin for
augmenting current SORA practices with air-to-air collision hazards
prediction from small uncooperative flying objects. <em>JIRS</em>,
<em>110</em>(3), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02136-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future autonomous Unmanned Aerial Vehicles (UAV) missions will take place in highly cluttered urban environments. As a result, the UAV must be able to autonomously evaluate risks and react to unforeseen hazards. The current regulatory framework for missions implements SORA guidelines for hazard detection, but its application to air-to-air collision is limited. This research defined a rigorous verification and validation framework (V&amp;V) for digital twins for use in future autonomous UAV missions. The researchers designed a sentry mission for a UAV to evaluate its capacity to detect small uncooperative flying objects. A digital twin of the DJI M300 vision system was built using a game engine and a V&amp;V framework was developed to assure the quality of results in both virtual and real-world scenarios. The results showed the capability of the digital twin to identify vulnerabilities and worst-case scenarios in UAV mission operations, and how it can assist remote pilots in identifying air-to-air collision hazards. Furthermore, the probability of air-to-air collision was calculated for three sentry patterns, and the results were validated in the field. This research demonstrated the capability to identify vulnerabilities and worst-case scenarios in UAV mission operations. We present how the digital twin of an operational theatre can be exploited to assist remote pilots with the identification of air-to-air collision hazards of small uncooperative objects. Furthermore, we discuss how these results can be used to enhance current SORA-based risk assessment practices.},
  archive      = {J_JIRS},
  author       = {Matalonga, Santiago and Black, Julie and Riordan, James},
  doi          = {10.1007/s10846-024-02136-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Verification and validation for a digital twin for augmenting current SORA practices with air-to-air collision hazards prediction from small uncooperative flying objects},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimization of joint space trajectories for assistive lower
limb exoskeleton robots: Real-time and flexible gait patterns.
<em>JIRS</em>, <em>110</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02137-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on designing a real-time, flexible gait planner for lower limb exoskeleton robots to assist patients with lower limb disabilities. Given the dynamic nature of gait parameters, which vary according to ground conditions and user intent, the challenge lies in developing a gait planner capable of adapting to these changes in real-time. To avoid planning complications in the cartesian space and to comply with the speed constraints of joint motors, this paper proposes planning in joint space. Furthermore, the approach also considers the maximum speed capabilities of the joint motors, aiming to generate an executable gait pattern and simultaneously enhance the robot’s walking speed by determining the minimum time required for implementation. The introduced gait planner optimizes joint trajectories for minimal angular acceleration. To provide flexibility, generalized boundary conditions suitable for different scenarios are defined. The effectiveness of the proposed planner is validated through comprehensive performance analysis, simulations, and successful implementation trials on the Exoped® robot in various scenarios.},
  archive      = {J_JIRS},
  author       = {Mohamad, Habib and Ozgoli, Sadjaad and Kazemi, Jafar},
  doi          = {10.1007/s10846-024-02137-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Optimization of joint space trajectories for assistive lower limb exoskeleton robots: Real-time and flexible gait patterns},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive optimization of hyper-parameters for robotic
manipulation through evolutionary reinforcement learning. <em>JIRS</em>,
<em>110</em>(3), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02138-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning applications are growing due to their capability of teaching the agent any task autonomously and generalizing the learning. However, this comes at the cost of a large number of samples and interactions with the environment. Moreover, the robustness of learned policies is usually achieved by a tedious tuning of hyper-parameters and reward functions. In order to address this issue, this paper proposes an evolutionary RL algorithm for the adaptive optimization of hyper-parameters. The policy is trained using an on-policy algorithm, Proximal Policy Optimization (PPO), coupled with an evolutionary algorithm. The achieved results demonstrate an improvement in the sample efficiency of the RL training on a robotic grasping task. In particular, the learning is improved with respect to the baseline case of a non-evolutionary agent. The evolutionary agent needs $$60$$ % fewer samples to completely learn the grasping task, enabled by the adaptive transfer of knowledge between the agents through the evolutionary algorithm. The proposed approach also demonstrates the possibility of updating reward parameters during training, potentially providing a general approach to creating reward functions.},
  archive      = {J_JIRS},
  author       = {Onori, Giulio and Shahid, Asad Ali and Braghin, Francesco and Roveda, Loris},
  doi          = {10.1007/s10846-024-02138-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Adaptive optimization of hyper-parameters for robotic manipulation through evolutionary reinforcement learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network design for a curved kicking mechanism with
obstacle avoidance in RoboCup small size league (SSL). <em>JIRS</em>,
<em>110</em>(3), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02140-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the RoboCup, a robotics soccer tournament, the Small Size League (SSL) is one of its leagues. The thought of a mechanism in this league that could perform unpredictable kicks and passes inspired study into both the physical mechanism required to do it and the algorithms needed to make the most of it.By introducing new ideas and utilizing a Deep Neural Network, this work contributes by improving a prior algorithm that aims to carry out a real-time inversion of the non-linear ordinary differential equation (ODE) that models the ball’s path in order to determine the parameters to hit a target with a curved kick mechanism (DNN). New techniques are also presented. The two suggested DNN achieved accuracy levels of more than 92% in the outcomes of simulation runs in MATLAB.},
  archive      = {J_JIRS},
  author       = {B. Azevedo, Francisco A. and C. Leão, Guilherme P. and Maximo, Marcos R. O. A.},
  doi          = {10.1007/s10846-024-02140-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Neural network design for a curved kicking mechanism with obstacle avoidance in RoboCup small size league (SSL)},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative robotics: A survey from literature and
practitioners perspectives. <em>JIRS</em>, <em>110</em>(3), 1–29. (<a
href="https://doi.org/10.1007/s10846-024-02141-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robotics possesses the potential to revolutionise industrial automation by offering affordable and accessible solutions with reasonable skill requirements. However, identifying the most valuable and appropriate applications for this technology remains a challenge. This study conducted a comprehensive literature review to analyse the existing collaborative robotics applications, and the results showed that only a limited number of applications can be considered true collaboration, with even fewer classified as intelligent collaboration. The study comprised a survey designed to offer valuable insights to not only enhance the state-of-the-art analysis in the identification of existing challenges in the field of collaborative robotics but also to provide motivation to guide future advancements. By leveraging the survey results, researchers and practitioners will be better equipped to navigate the complex landscape of collaborative robotics and develop innovative solutions to tackle the identified challenges. This study also informs on the latest research and development in the field.},
  archive      = {J_JIRS},
  author       = {Montini, Elias and Daniele, Fabio and Agbomemewa, Lorenzo and Confalonieri, Matteo and Cutrona, Vincenzo and Bettoni, Andrea and Rocco, Paolo and Ferrario, Andrea},
  doi          = {10.1007/s10846-024-02141-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-29},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Collaborative robotics: A survey from literature and practitioners perspectives},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven fault detection and isolation for multirotor
system using koopman operator. <em>JIRS</em>, <em>110</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s10846-024-02142-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a data-driven fault detection and isolation (FDI) for a multirotor system using Koopman operator and Luenberger observer. Koopman operator is an infinite-dimensional linear operator that can transform nonlinear dynamical systems into linear ones. Using this transformation, our aim is to apply the linear fault detection method to the nonlinear system. Initially, a Koopman operator-based linear model is derived to represent the multirotor system, considering factors like non-diagonal inertial tensor, center of gravity variations, aerodynamic effects, and actuator dynamics. Various candidate lifting functions are evaluated for prediction performance and compared using the root mean square error to identify the most suitable one. Subsequently, a Koopman operator-based Luenberger observer is proposed using the lifted linear model to generate residuals for identifying faulty actuators. Simulation and experimental results demonstrate the effectiveness of the proposed observer in detecting actuator faults such as bias and loss of effectiveness, without the need for an explicitly defined fault dataset.},
  archive      = {J_JIRS},
  author       = {Lee, Jayden Dongwoo and Im, Sukjae and Kim, Lamsu and Ahn, Hyungjoo and Bang, Hyochoong},
  doi          = {10.1007/s10846-024-02142-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Data-driven fault detection and isolation for multirotor system using koopman operator},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic informed bias RRT*-connect: Improving heuristic
guidance by dynamic informed bias using hybrid dual trees search.
<em>JIRS</em>, <em>110</em>(3), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02144-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The RRT*-Connect algorithm enhances efficiency through dual tree bias growth, yet this bias can be inherently blind, potentially affecting the algorithm’s heuristic performance. In contrast, the Informed RRT* algorithm narrows the planning problem’s scope by leveraging an informed region, thereby improving convergence efficiency towards optimal solutions. However, this approach relies on the prior establishment of feasible paths. Combining these two algorithms can address the challenges posed by Informed RRT while also accelerating convergence towards optimality, albeit without resolving the issue of blind bias in dual trees.In this paper, we proposed a novel algorithm: Dynamic Informed Bias RRT*-Connect. This algorithm, grounded in potential and explicit informed bias sampling, introduces a dynamical bias points set that guides dual tree growth with precision objectives. Additionally, we enhance the evaluation framework for algorithmic heuristics by introducing two innovative metrics that effectively capture the algorithm’s characteristics. The improvements observed in traditional indicators demonstrate that the proposed algorithm exhibits greater heuristic compared to RRT*-Connect and Informed RRT*-Connect. These findings also suggest the viability of the new metrics introduced in our evaluation framework.},
  archive      = {J_JIRS},
  author       = {Li, Haotian and Kang, Yiting and Han, Haisong},
  doi          = {10.1007/s10846-024-02144-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Dynamic informed bias RRT*-connect: Improving heuristic guidance by dynamic informed bias using hybrid dual trees search},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drones in the airspace of the republic of poland - steps to
safe flights of UAS over poland. <em>JIRS</em>, <em>110</em>(3), 1–8.
(<a href="https://doi.org/10.1007/s10846-024-02145-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of a new user of the airspace of the Republic of Poland, Unmanned Aerial Vehicles - drones, as part of regular flights, implies the need not only to provide an appropriate legal framework, but also to rebuild the entire air traffic management ecosystem for the integration of manned and unmanned aviation. The first attempts to include UAS in the integrated air traffic system in the Warsaw FIR were based on the electronic/digital planning, coordination and management of UAS flights called Pansa UTM (Polish Air Navigation Services Agency Unmanned Traffic Management). This system is an innovative solution used by the Polish Air Navigation Services Agency (PANSA) and potential drone users. The operation and development of the Pansa UTM system generates the need for air traffic management entities to take specific actions by planning and establishing regulations, rules, safety criteria and flight conditions for the new airspace user. This requires involvement in projects, pilotages and technology demonstrators aimed at creating adequate tools for the safe implementation of UAS flights in Poland. These activities, both already implemented and at the planning stage, aim to achieve a state in which it will be possible to talk about integrated and safe controlled air traffic over Poland. Due to the dynamic nature of the subject matter, this study is only an attempt to present a number of projects undertaken by a wide range of aviation-related entities that may allow achieving an acceptable level of air traffic management over the territory of the Republic of Poland.},
  archive      = {J_JIRS},
  author       = {Gugała-Szczerbicka, Agnieszka and Fortońska, Agnieszka},
  doi          = {10.1007/s10846-024-02145-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-8},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Drones in the airspace of the republic of poland - Steps to safe flights of UAS over poland},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Experimental assessment of a vision-based obstacle avoidance
strategy for robot manipulators: Off-line trajectory planning and
on-line motion control. <em>JIRS</em>, <em>110</em>(3), 1–21. (<a
href="https://doi.org/10.1007/s10846-024-02146-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-Robot Interaction is an increasingly important topic in both research and industry fields. Since human safety must be always guaranteed and accidental contact with the operator avoided, it is necessary to investigate real-time obstacle avoidance strategies. The transfer from simulation environments, where algorithms are tested, to the real world is challenging from different points of view, e.g., the continuous tracking of the obstacle and the configuration of different manipulators. In this paper, the authors describe the implementation of a collision avoidance strategy based on the potential field method for off-line trajectory planning and on-line motion control, paired with the Motion Capture system Optitrack PrimeX 22 for obstacle tracking. Several experiments show the performance of the proposed strategy in the case of a fixed and dynamic obstacle, disturbing the robot’s trajectory from multiple directions. Two different avoidance modalities are adapted and tested for both standard and redundant robot manipulators. The results show the possibility of safely implementing the proposed avoidance strategy on real systems.},
  archive      = {J_JIRS},
  author       = {Scoccia, Cecilia and Ubezio, Barnaba and Palmieri, Giacomo and Rathmair, Michael and Hofbaur, Michael},
  doi          = {10.1007/s10846-024-02146-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Experimental assessment of a vision-based obstacle avoidance strategy for robot manipulators: Off-line trajectory planning and on-line motion control},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Guidance-as-progressive in human skill training based on
deep reinforcement learning. <em>JIRS</em>, <em>110</em>(3), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02147-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve psychological inclusion and skill development orientation in human skill training, this paper proposes a haptic-guided training strategy generation method with Deep Reinforcement Learning (DRL)-based agent as the core and Zone of Proximal Development (ZPD) tuning as the auxiliary. The information of the expert and trainee is stored first with a designed database that can be accessed in real-time, which establishes the data foundation. Then, under the DRL framework, a strategy generation agent is designed, which consists of an actor-network and two Q-networks. The former network generates the agent’s decision policy, while the other two Q-networks work to approximate the state-action value function, and the parameters of all of them are administrated by the Soft Actor-Critic (SAC) algorithm. In addition, for the first time, the psychological ZPD evaluation method is integrated into the strategy generation of the DRL-based agent, which is utilized to describe the relationship between a trainees intrinsic skills and guidance. With it, the problem of transitional guidance or insufficient guidance can be handled well. Finally, simulation experiments validate the proposed method, demonstrating its efficiency in regulating the trainee under favorable training conditions.},
  archive      = {J_JIRS},
  author       = {Yang, Yang and Chen, Haifei and Liu, Xing and Huang, Panfeng},
  doi          = {10.1007/s10846-024-02147-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Guidance-as-progressive in human skill training based on deep reinforcement learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effects of the human presence among robots in the ARIAC 2023
industrial automation competition. <em>JIRS</em>, <em>110</em>(3), 1–15.
(<a href="https://doi.org/10.1007/s10846-024-02148-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ARIAC is a robotic simulation competition promoted by NIST annually since 2017, aiming to present competitors’ with contemporary industry problems to be solved using agile robotics. For the 2023 competition, ARIAC competitors must perform assembly and kitting tasks by controlling four autonomous ground vehicles (AGVs), one floor-based robot, and one ceiling-based (Gantry) robot in an attempt to overcome a range of agility challenges in the supplied simulated environment, itself based on the Robot Operating System (ROS 2) and Gazebo. The 2023 competition also included a “human” agility challenge, comprising a (simulated) human operator working among robots on the factory floor. This development was motivated by the fact that, while robots and automation play an increasingly significant role in modern manufacturing, there still remains a close relationship between machines and humans. They should complement each other’s strengths and cover each other’s limitations while also observing any required safety rules. For example, the ISO standard “Robots and Robotic Devices – Collaborative robots” (ISO 15066:2016) prescribes the distances required between humans and robots. Within the ARIAC simulation environment, each human operator is controlled using autonomous Belief-Desire-Intention (BDI) agents. At the same time, competitors can monitor the position of each human operator at any time by subscribing to the relevant ROS topic. In this article, we analyse the effects of this (simulated) human presence in the 2023 ARIAC competition and perform a detailed analysis of how the three different human personalities that were implemented affect the assembly tasks undertaken at the four different locations of the assembly stations. Given how the system is currently implemented, it appears that the influence of each encoded personality on the competitors is not as predictable as anticipated. We expand on why this may be a problem when addressing real collaborative spaces involving humans and industrial robots and the improvements that can be undertaken to mitigate the ensuing problems.},
  archive      = {J_JIRS},
  author       = {Buss Becker, Leandro and Downs, Anthony and Schlenoff, Craig and Albrecht, Justin and Kootbally, Zeid and Ferrando, Angelo and Cardoso, Rafael and Fisher, Michael},
  doi          = {10.1007/s10846-024-02148-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Effects of the human presence among robots in the ARIAC 2023 industrial automation competition},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Advancements and challenges in mobile robot navigation: A
comprehensive review of algorithms and potential for self-learning
approaches. <em>JIRS</em>, <em>110</em>(3), 1–24. (<a
href="https://doi.org/10.1007/s10846-024-02149-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robot navigation has been a very popular topic of practice among researchers since a while. With the goal of enhancing the autonomy in mobile robot navigation, numerous algorithms (traditional AI-based, swarm intelligence-based, self-learning-based) have been built and implemented independently, and also in blended manners. Nevertheless, the problem of efficient autonomous robot navigation persists in multiple degrees due to the limitation of these algorithms. The lack of knowledge on the implemented techniques and their shortcomings act as a hindrance to further development on this topic. This is why an extensive study on the previously implemented algorithms, their applicability, their weaknesses as well as their potential needs to be conducted in order to assess how to improve mobile robot navigation performance. In this review paper, a comprehensive review of mobile robot navigation algorithms has been conducted. The findings suggest that, even though the self-learning algorithms require huge amounts of training data and have the possibility of learning erroneous behavior, they possess huge potential to overcome challenges rarely addressed by the other traditional algorithms. The findings also insinuate that in the domain of machine learning-based algorithms, integration of knowledge representation with a neuro-symbolic approach has the capacity to improve the accuracy and performance of self-robot navigation training by a significant margin.},
  archive      = {J_JIRS},
  author       = {Al Mahmud, Suaib and Kamarulariffin, Abdurrahman and Ibrahim, Azhar Mohd and Mohideen, Ahmad Jazlan Haja},
  doi          = {10.1007/s10846-024-02149-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-24},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Advancements and challenges in mobile robot navigation: A comprehensive review of algorithms and potential for self-learning approaches},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid path planning technique for the time-efficient
navigation of unmanned vehicles in an unconstrained environment.
<em>JIRS</em>, <em>110</em>(3), 1–31. (<a
href="https://doi.org/10.1007/s10846-024-02150-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal path planning refers to choosing a collision-free, shortest, and smooth path, which is achieved by proposing a new technique, Optimized A* (OA*). The proposed OA* is the hybrid version of three techniques that are ABA* (Adaptive Bidirectional A*), VTM (Vector triangulation method), and PSF (Path smoothing filter which is the modification of Bezier curve technique). The conventional A* only deal with the heuristic values of concerned nodes, but the proposed ABA* algorithm also considers the occupied cells/ obstacles present near the starting and goal nodes in the grid cells to select the shortest path from start to destination. Due to the involvement of the occupied cells, the execution time, path curves, and the number of operations is primarily reduced because occupied nodes are considered as closed nodes, and its heuristic calculation is not considered in the conventional method. The trajectory generated by the proposed ABA* technique is also further made smoother by implementing a path smoothing filter that is the combination of VTM and modified Bezier curve technique based on selecting optimal control point for the collision free trajectory. While implementing the proposed OA* makes the path trajectory become smoother by reducing the number of sharp turns by 85.36% w.r.t traditional ACO, 73.91% w.r.t improved ACO, and 64.70% w.r.t hybrid solution of ACO+ A*. Due to the reduction in the number of sharp turns in the path trajectory, the acceleration of the mobile robot is increased by 52.96% w.r.t traditional ACO, 28.63% w.r.t improved ACO, and 19.96% w.r.t hybrid solution of ACO+ A*.},
  archive      = {J_JIRS},
  author       = {Singh, Ravinder},
  doi          = {10.1007/s10846-024-02150-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-31},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A hybrid path planning technique for the time-efficient navigation of unmanned vehicles in an unconstrained environment},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method of 3D lyapunov guidance vector field to avoid
intercepting satellite based on reinforcement learning. <em>JIRS</em>,
<em>110</em>(3), 1–8. (<a
href="https://doi.org/10.1007/s10846-024-02151-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new 3D Lyapunov guidance vector field(3D-LGV) avoidance strategy based on reinforcement learning for the satellite evasion and interception problem. Combining it with the interfered fluid dynamical system (IFDS) enables the satellite to evade and smoothly enter orbit according to the state of the intercepting satellite in real time. 3D-LGV provides an initial flow field approaching an elliptical orbit, while IFDS provides a perturbed flow field based on the intercepting satellite position. The combined potential field of the initial flow field and the disturbed flow field is the planned velocity direction of the satellite. As a decision-making layer, the proximal policy optimization (PPO) dynamically adjusts the perturbed flow field in the IFDS to increase the avoidance success rate in different scenarios. The experimental results show that, compared with the particle swarm optimization with rolling horizon control algorithm, the algorithm proposed in this paper has a shorter decision time and a higher avoidance success rate. At the same time, Monte Carlo simulation shows that the evasion success rate of the proposed algorithm reaches 98%.},
  archive      = {J_JIRS},
  author       = {Zhang, Yunfei and Wang, Honglun and Zhang, Menghua and Liu, Yiheng and Wu, Jianfa},
  doi          = {10.1007/s10846-024-02151-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-8},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A novel method of 3D lyapunov guidance vector field to avoid intercepting satellite based on reinforcement learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Barrier lyapunov function-based backstepping controller
design for path tracking of autonomous vehicles. <em>JIRS</em>,
<em>110</em>(3), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02152-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a novel BLF-based backstepping controller for path tracking of Autonomous Vehicles (AVs) with unknown dynamics and unmeasurable states. The proposed framework includes: (1) forming geometric-dynamic model of the vehicle by combining the dynamics of the vehicle with the kinematics of the visual measurement system, (2) designing a fixed-time Extended-State Observer (ESO) to estimate the unknown dynamics and unmeasurable states, and (3) introducing a BLF-based controller for faster response and more accurate path tracking compared to previous BLF-based controllers. Besides the novelty of the BLF-based controller, by transforming the closed-loop error dynamics into a unified proportional-derivative (PD)-type structure, an intuitive criterion is proposed to provide a systematic procedure for comparing BLF-based controllers. A combined BLF is further proposed based on this performance criterion to eliminate the sensitivity of BLF-based controllers to the magnitude of the constraint. The stability analysis is performed for the fixed-time ESO and the closed-loop control system. MATLAB/CarSim co-simulation is conducted to evaluate the performance of the proposed control system. The outcomes of the work show that the closed-loop control system is exponentially stable. In addition, it can provide a faster response and result in more accurate path tracking compared to previous BLF-based control systems.},
  archive      = {J_JIRS},
  author       = {Hosseinnajad, Alireza and Mohajer, Navid and Nahavandi, Saeid},
  doi          = {10.1007/s10846-024-02152-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Barrier lyapunov function-based backstepping controller design for path tracking of autonomous vehicles},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Memory efficient deep learning-based grasping point
detection of nontrivial objects for robotic bin picking. <em>JIRS</em>,
<em>110</em>(3), 1–23. (<a
href="https://doi.org/10.1007/s10846-024-02153-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picking up non-trivial objects from a bin with a robotic arm is a common task of modern industrial processes. Here, an efficient data-driven method of grasping point detection, based on an attention squeeze parallel U-shaped neural network (ASP U-Net) for the bin picking task, is proposed. The method directly provides all necessary information about the feasible grasping points of objects, which are randomly or regularly arranged in a bin with side walls. Moreover, the method is able to evaluate and select the optimal grasping point among the feasible ones for two types of end effectors, i.e., a vacuum cup and a parallel gripper. The key element of the utilized ASP U-Net neural network is the transformation of a single RGB-Depth image of the bin containing nontrivial objects into a schematic grey-scale frame, where the positions and poses of the grasping points are coded into gradient geometric shapes. The experiments carried out in this study include a comprehensive set of scenes with randomly scattered, ordered, and semi-ordered objects arranged in impeccable or deformed bins. The results indicate outstanding accuracy with more than acceptable computational requirements. Additionally, the scaling possibilities of the method can offer extremely lightweight implementations, applicable, for example, to battery-powered edge-computing devices with low RAM capacity.},
  archive      = {J_JIRS},
  author       = {Dolezel, Petr and Stursa, Dominik and Kopecky, Dusan},
  doi          = {10.1007/s10846-024-02153-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Memory efficient deep learning-based grasping point detection of nontrivial objects for robotic bin picking},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Six-degree-of-freedom pose estimation method for
multi-source feature points based on fully convolutional neural network.
<em>JIRS</em>, <em>110</em>(3), 1–12. (<a
href="https://doi.org/10.1007/s10846-024-02154-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An object’s six-degree-of-freedom (6DoF) pose information has great importance in various fields. Existing methods of pose estimation usually detect two-dimensional (2D)-three-dimensional (3D) feature point pairs, and directly estimates the pose information through Perspective-n-Point (PnP) algorithms. However, this approach ignores the spatial association between pixels, making it difficult to obtain high-precision results. In order to apply pose estimation based on deep learning methods to real-world scenarios, we hope to design a method that is robust enough in more complex scenarios. Therefore, we introduce a method for 3D object pose estimation from color images based on farthest point sampling (FPS) and object 3D bounding box. This method detects the 2D projection of 3D feature points through a convolutional neural network, matches it with the 3D model of the object, and then uses the PnP algorithm to restore the feature point pair to the object pose. Due to the global nature of the bounding box, this approach can be considered effective even in partially occluded or complex environments. In addition, we propose a heatmap suppression method based on weighted coordinates to further improve the prediction accuracy of feature points and the accuracy of the PnP algorithm in solving the pose position. Compared with other algorithms, this method has higher accuracy and better robustness. Our method yielded 93.8% of the ADD(-s) metrics on the Linemod dataset and 47.7% of the ADD(-s) metrics on the Occlusion Linemod dataset. These results show that our method is more effective than existing methods in pose estimation of large objects.},
  archive      = {J_JIRS},
  author       = {Wang, Junxiao and Wu, Peng and Zhang, Xiaoming and Xu, Renjie and Wang, Tao},
  doi          = {10.1007/s10846-024-02154-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Six-degree-of-freedom pose estimation method for multi-source feature points based on fully convolutional neural network},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ground, ceiling and wall effect evaluation of small
quadcopters in pressure-controlled environments. <em>JIRS</em>,
<em>110</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02155-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multicopters are used for a wide range of applications that often involve approaching buildings or navigating enclosed spaces. Opposed to the open spaces in obstacle-free environments commonly flown by fixed-wing unmanned aerial vehicles, multicopters frequently fly close to surfaces and must take into account the airflow variations caused by airflow rebound. Such disturbances must be identified in order to design algorithms capable of compensating them. The evaluation of ground, ceiling and wall effects using two different test stands is proposed in this work. Different propellers and sensors have been considered for testing. The first test setup used was placed inside terraXcube’s large climatic chamber allowing a precise control of temperature and pressure of around 20°C and 1000 hPa, respectively. The second test setup is located at the University of Denver (DU) Unmanned Systems Research Institute (DU $$^2$$ SRI) laboratory with a stable pressure of around 800 hPa. Two different fixed 6 degrees of freedom force-torque sensors have been used for the experiments, allowing to sample forces and moments in three orthogonal axes. The tests simulate a hovering situation of a quadcopter at different distances to either the ground, the ceiling or a wall. The influence of the propeller size, rotation speed, pressure and temperature have also been considered and used for later dimensionless coefficient comparison. A thorough analysis of the measurement uncertainty is also included based on experimental evaluations and manufacturer information. Experimental data collected in these tests can be used for the definition of a mathematical model in which the effect of the proximity to the different surfaces is evaluated.},
  archive      = {J_JIRS},
  author       = {David Du Mutel de Pierrepont Franzetti, Iris and Parin, Riccardo and Capello, Elisa and Rutherford, Matthew J. and Valavanis, Kimon P.},
  doi          = {10.1007/s10846-024-02155-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Ground, ceiling and wall effect evaluation of small quadcopters in pressure-controlled environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HOPE-g: A dual belt treadmill servo-pneumatic system for
gait rehabilitation. <em>JIRS</em>, <em>110</em>(3), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02158-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of robotic devices for gait neurological rehabilitation is growing, however, the available options are scarce, expensive, and with high complexity of construction and control. In this way, this paper presents the HOPE-G, a novel gait rehabilitation robot consisting of an active bodyweight support system and a dual belt treadmill servo-pneumatic module. This paper focuses on the development of the dual belt treadmill servo-pneumatic module, which has tipper movement to remove the physical barrier of the patient during the swing phase of the human gait rehabilitation. The mathematical models of the servo-pneumatic system and the treadmill module are provided. An impedance controller was designed to provide a compliant walking surface for the patient. Simulation and test rig results demonstrate the servo-pneumatic system’s capability to meet the application requirements and effectively control the surface stiffness. Therefore, it is evidenced that pneumatic systems have shock absorption capabilities, making them a cost-effective solution for application in human rehabilitation tasks.},
  archive      = {J_JIRS},
  author       = {Vigolo, Vinícius and Rodrigues, Lucas A. O. and Valdiero, Antonio Carlos and da Cruz, Daniel A. L. and Gonçalves, Rogerio S.},
  doi          = {10.1007/s10846-024-02158-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {HOPE-G: A dual belt treadmill servo-pneumatic system for gait rehabilitation},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards semantic interoperability: An information model for
autonomous mobile robots. <em>JIRS</em>, <em>110</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02159-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The collaboration among autonomous mobile robots (AMRs), including unmanned aerial vehicles (UAVs), unmanned ground vehicles (UGVs), and/or unmanned surface vehicles (USVs), significantly enhances their capabilities by enabling them to tackle more complex tasks exceeding those of individual robots. However, to fully exploit this collaboration, a common understanding of exchanged information—referred to as semantic interoperability—is crucial. Achieving semantic interoperability between these robots requires a deep understanding of relevant information and its underlying structure. To address this challenge, this paper presents a platform- and technology-independent information model developed specifically for AMRs. This model aims to facilitate collaboration by structuring information in a way that ensures semantic interoperability. The paper outlines the model&#39;s development process, beginning with a structured consolidation of information from pertinent scientific literature, resulting in a foundational framework for representing knowledge and semantics within the domain of AMRs. The practical application of the information model is demonstrated through a use case involving multiple AMRs. Additionally, the paper provides insights into the employed methodology, emphasizing the significance of systematic literature reviews and collaboration with practitioners to refine and validate the model. It also discusses theoretical and practical implications, addressing potential limitations encountered during the research.},
  archive      = {J_JIRS},
  author       = {Zager, Marvin and Sieber, Christoph and Fay, Alexander},
  doi          = {10.1007/s10846-024-02159-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Towards semantic interoperability: An information model for autonomous mobile robots},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design and development of a robust control platform for a
3-finger robotic gripper using EMG-derived hand muscle signals in NI
LabVIEW. <em>JIRS</em>, <em>110</em>(3), 1–27. (<a
href="https://doi.org/10.1007/s10846-024-02160-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are increasingly present in everyday life, replacing human involvement in various domains. In situations involving danger or life-threatening conditions, it is safer to deploy robots instead of humans. However, there are still numerous applications where human intervention remains indispensable. The strategy to control a robot can be developed based on intelligent adaptive programmed algorithms or by harnessing the physiological signals of the robot operator, such as body movements, brain EEG, and muscle EMG which is a more intuitive approach. This study focuses on creating a control platform for a 3-finger gripper, utilizing Electromyography (EMG) signals derived from the operator’s forearm muscles. The developed platform consisted of a Robotiq three-finger gripper, a Delsys Trigno wireless EMG, as well as an NI CompactRIO data acquisition platform. The control process was developed using NI LabVIEW software, which extracts, processes, and analyzes the EMG signals, which are subsequently transformed into control signals to operate the robotic gripper in real-time. The system operates by transmitting the EMG signals from the operator&#39;s forearm muscles to the robotic gripper once they surpass a user-defined threshold. To evaluate the system&#39;s performance, a comprehensive set of regressive tests was conducted on the forearm muscles of three different operators based on four distinct case scenarios. Despite of the gripper’s structural design weakness to perform pinching, however, the results demonstrated an impressive average success rate of 95% for tasks involving the opening and closing of the gripper to perform grasping. This success rate was consistent across scenarios that included alterations to the scissor configuration of the gripper.},
  archive      = {J_JIRS},
  author       = {Loskutova, Aleksandra and Roozbahani, Daniel and Alizadeh, Marjan and Handroos, Heikki},
  doi          = {10.1007/s10846-024-02160-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Design and development of a robust control platform for a 3-finger robotic gripper using EMG-derived hand muscle signals in NI LabVIEW},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Survey of recent results in privacy-preserving mechanisms
for multi-agent systems. <em>JIRS</em>, <em>110</em>(3), 1–27. (<a
href="https://doi.org/10.1007/s10846-024-02161-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-preserving communication in cooperative control is essential for effective operations of various systems where sensitive information needs to be protected. This includes systems such as smart grids, traffic management systems, autonomous vehicle networks, healthcare systems, financial networks, and social networks. Recent privacy-preserving cooperative control literature is categorized and discussed in this paper. Advantages and disadvantages of differential privacy and encryption-based privacy-preserving protocols are described. The objective of this work is to examine and analyze existing research and knowledge related to the preservation of privacy in the context of cooperative control. This paper aims to identify and present a range of approaches, techniques, and methodologies that have been proposed or employed to address privacy concerns in multi-agent systems. It seeks to explore the current challenges, limitations, and gaps in the existing literature. It also aims to consolidate the findings from various studies to provide an overview of privacy-preserving cooperative control in multi-agent systems. The goal is to assist in the development of novel privacy-preserving mechanisms for cooperative control.},
  archive      = {J_JIRS},
  author       = {Kossek, Magdalena and Stefanovic, Margareta},
  doi          = {10.1007/s10846-024-02161-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Survey of recent results in privacy-preserving mechanisms for multi-agent systems},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time monitoring of human and process performance
parameters in collaborative assembly systems using multivariate control
charts. <em>JIRS</em>, <em>110</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02162-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise in customized product demands, the production of small batches with a wide variety of products is becoming more common. A high degree of flexibility is required from operators to manage changes in volumes and products, which has led to the use of Human-Robot Collaboration (HRC) systems for custom manufacturing. However, this variety introduces complexity that affects production time, cost, and quality. To address this issue, multivariate control charts are used as diagnostic tools to evaluate the stability of several parameters related to both product/process and human well-being in HRC systems. These key parameters monitored include assembly time, quality control time, total defects, and operator stress, providing a more holistic view of system performance. Real-time monitoring of process performance along with human-related factors, which is rarely considered in statistical process control, provides comprehensive stability control over all customized product variants produced in the HRC system. The proposed approach includes defining the parameters to be monitored, constructing control charts, collecting data after product variant assembly, and verifying that the set of parameters is under control via control charts. This increases the system&#39;s responsiveness to both process inefficiencies and human well-being. The procedure can be automated by embedding control chart routines in the software of the HRC system or its digital twin, without adding additional tasks to the operator&#39;s workload. Its practicality and effectiveness are evidenced in custom electronic board assembly, highlighting its role in optimizing HRC system performance.},
  archive      = {J_JIRS},
  author       = {Verna, Elisa and Puttero, Stefano and Genta, Gianfranco and Galetto, Maurizio},
  doi          = {10.1007/s10846-024-02162-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Real-time monitoring of human and process performance parameters in collaborative assembly systems using multivariate control charts},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural network-based adaptive finite-time control for 2-DOF
helicopter systems with prescribed performance and input saturation.
<em>JIRS</em>, <em>110</em>(3), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02165-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose an adaptive neural network (NN) control approach for a 2-DOF helicopter system characterized by finite-time prescribed performance and input saturation. Initially, the NN is utilized to estimate the system’s uncertainty. Subsequently, a novel performance function with finite-time attributes is formulated to ensure that the system’s tracking error converges to a narrow margin within a predefined time span. Furthermore, adaptive parameters are integrated to address the inherent input saturation within the system. The boundedness of the system is then demonstrated through stability analysis employing the Lyapunov function. Finally, the effectiveness of the control strategy delineated in this investigation is validated through simulations and experiments.},
  archive      = {J_JIRS},
  author       = {Bi, Hui and Zhang, Jian and Wang, Xiaowei and Liu, Shuangyin and Zhao, Zhijia and Zou, Tao},
  doi          = {10.1007/s10846-024-02165-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Neural network-based adaptive finite-time control for 2-DOF helicopter systems with prescribed performance and input saturation},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatic robot hand-eye calibration enabled by
learning-based 3D vision. <em>JIRS</em>, <em>110</em>(3), 1–23. (<a
href="https://doi.org/10.1007/s10846-024-02166-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand-eye calibration, a fundamental task in vision-based robotic systems, is commonly equipped with collaborative robots, especially for robotic applications in small and medium-sized enterprises (SMEs). Most approaches to hand-eye calibration rely on external markers or human assistance. We proposed a novel methodology that addresses the hand-eye calibration problem using the robot base as a reference, eliminating the need for external calibration objects or human intervention. Using point clouds of the robot base, a transformation matrix from the coordinate frame of the camera to the robot base is established as “I=AXB.” To this end, we exploit learning-based 3D detection and registration algorithms to estimate the location and orientation of the robot base. The robustness and accuracy of the method are quantified by ground-truth-based evaluation, and the accuracy result is compared with other 3D vision-based calibration methods. To assess the feasibility of our methodology, we carried out experiments utilizing a low-cost structured light scanner across varying joint configurations and groups of experiments. The proposed hand-eye calibration method achieved a translation deviation of 0.930 mm and a rotation deviation of 0.265 degrees according to the experimental results. Additionally, the 3D reconstruction experiments demonstrated a rotation error of 0.994 degrees and a position error of 1.697 mm. Moreover, our method offers the potential to be completed in 1 second, which is the fastest compared to other 3D hand-eye calibration methods. We conduct indoor 3D reconstruction and robotic grasping experiments based on our hand-eye calibration method. Related code is released at https://github.com/leihui6/LRBO .},
  archive      = {J_JIRS},
  author       = {Li, Leihui and Yang, Xingyu and Wang, Riwei and Zhang, Xuping},
  doi          = {10.1007/s10846-024-02166-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Automatic robot hand-eye calibration enabled by learning-based 3D vision},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). UAV routing for enhancing the performance of a
classifier-in-the-loop. <em>JIRS</em>, <em>110</em>(3), 1–22. (<a
href="https://doi.org/10.1007/s10846-024-02169-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some human-machine systems are designed so that machines (robots) gather and deliver data to remotely located operators (humans) through an interface to aid them in classification. The performance of a human as a (binary) classifier-in-the-loop is characterized by probabilities of correctly classifying objects (or points of interest) as a true target or a false target. These two probabilities depend on the time spent collecting information at a point of interest (POI), known as dwell time. The information gain associated with collecting information at a POI is then a function of dwell time and discounted by the revisit time, i.e., the duration between consecutive revisits to the same POI, to ensure that the vehicle covers all POIs in a timely manner. The objective of the routing problem for classification is to route the vehicles optimally, which is a discrete problem, and determine the optimal dwell time at each POI, which is a continuous optimization problem, to maximize the total discounted information gain while visiting every POI at least once. Due to the coupled discrete and continuous problem, which makes the problem hard to solve, we make a simplifying assumption that the information gain is discounted exponentially by the revisit time; this assumption enables one to decouple the problem of routing with the problem of determining optimal dwell time at each POI for a single vehicle problem. For the multi-vehicle problem, since the problem involves task partitioning between vehicles in addition to routing and dwell time computation, we provide a fast heuristic to obtain high-quality feasible solutions.},
  archive      = {J_JIRS},
  author       = {Kumar, Deepak Prakash and Rajbhandari, Pranav and McGuire, Loy and Darbha, Swaroop and Sofge, Donald},
  doi          = {10.1007/s10846-024-02169-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {UAV routing for enhancing the performance of a classifier-in-the-loop},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). JIRS editorial, 3rd quarter 2024. <em>JIRS</em>,
<em>110</em>(3), 1–2. (<a
href="https://doi.org/10.1007/s10846-024-02170-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIRS},
  author       = {Valavanis, Kimon P.},
  doi          = {10.1007/s10846-024-02170-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-2},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {JIRS editorial, 3rd quarter 2024},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DFT-VSLAM: A dynamic optical flow tracking VSLAM method.
<em>JIRS</em>, <em>110</em>(3), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02171-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Simultaneous Localization and Mapping (VSLAM) technology can provide reliable visual localization and mapping capabilities for critical tasks. Existing VSLAM can extract accurate feature points in static environments for matching and pose estimation, and then build environmental map. However, in dynamic environments, the feature points extracted by the VSLAM system will become inaccurate points as the object moves, which not only leads to tracking failure but also seriously affects the accuracy of the environmental map. To alleviate these challenges, we propose a dynamic target-aware optical flow tracking method based on YOLOv8. Firstly, we use YOLOv8 to identify moving targets in the environment, and propose a method to eliminate dynamic points in the dynamic contour region. Secondly, we use the optical flow mask method to identify dynamic feature points outside the target detection object frame. Thirdly, we comprehensively eliminate the dynamic feature points. Finally, we combine the geometric and semantic information of static map points to construct the semantic map of the environment. We used ATE (Absolute Trajectory Error) and RPE (Relative Pose Error) as evaluation metrics and compared the original method with our method on the TUM dataset. The accuracy of our method is significantly improved, especially 96.92% on walking_xyz dataset. The experimental results show that our proposed method can significantly improve the overall performance of VSLAM systems under high dynamic environments.},
  archive      = {J_JIRS},
  author       = {Cai, Dupeng and Li, Shijiang and Qi, Wenlu and Ding, Kunkun and Lu, Junlin and Liu, Guangfeng and Hu, Zhuhua},
  doi          = {10.1007/s10846-024-02171-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {9},
  number       = {3},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {DFT-VSLAM: A dynamic optical flow tracking VSLAM method},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A UAV autonomous landing system integrating locating,
tracking, and landing in the wild environment. <em>JIRS</em>,
<em>110</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s10846-023-02041-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-reliability landing systems for unmanned aerial vehicles (UAVs) have gained extensive attention for their applicability in complex wild environments. Accurate locating, flexible tracking, and reliable recovery are the main challenges in drone landing. In this paper, a novel UAV autonomous landing system and its control framework are proposed and implemented. It’s comprised of an environmental perception system, an unmanned ground vehicle (UGV), and a Stewart platform to locate, track, and recover the drone autonomously. Firstly, a recognition algorithm based on multi-sensor fusion is developed to locate the target in real time with the help of a one-dimensional turntable. Secondly, a dual-stage tracking strategy composed of a UGV and a landing platform is proposed for dynamically tracking the landing drone. In a wide range, the UGV is in charge of fast-tracking through the artificial potential field (APF) path planning and the model predictive control (MPC) tracking algorithms. While the trapezoidal speed planning is employed in platform controller to compensate for the tracking error of the UGV, realizing the precise tracking to the drone in a small range. Furthermore, a recovery algorithm including an attitude compensation controller and an impedance controller is designed for the Stewart platform, ensuring horizontal and compliant landing of the drone. Finally, extensive simulations and experiments are dedicated to verifying the feasibility and reliability of the developed system and framework, indicating that it is a superior case of UAV autonomous landing in wild environments such as grasslands, slopes, and snow.},
  archive      = {J_JIRS},
  author       = {Si, Jinge and Li, Bin and Wang, Liang and Deng, Chencheng and Wang, Junzheng and Wang, Shoukun},
  doi          = {10.1007/s10846-023-02041-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A UAV autonomous landing system integrating locating, tracking, and landing in the wild environment},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regulating autonomy in civilian drones: Towards a spectral
approach. <em>JIRS</em>, <em>110</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02056-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Civilian drones are becoming more functionally independent from human involvement which sets them on a path towards “autonomous” status. When defining “autonomy,” the European Union (EU) regulations, among other jurisdictions, employ an all-or-nothing approach, according to which a drone is either able to operate fully autonomously or not at all. This dichotomous approach disregards the various levels of drone autonomy and fails to capture the complexity of civilian drone operation. Within the EU, this has regulatory implications, such as regulatory lag, hindrance in better safety regulation, and incoherence with the Union’s regulatory approach towards Artificial Intelligence (AI). This article argues that understanding autonomy as a spectrum, rather than in a dichotomous way, would be more coherent with the technical functioning of drone and would avoid potential regulatory problems caused by the current dichotomous approach. In delineating this spectral approach, this article (1) analyses manifestations of autonomy in drone operations, (2) delineates efforts in the technical literatures and drone standardization to conceptualize “autonomy”, and (3) explores definitional attempts for autonomy made in three other technologies: self-driving cars, autonomous weapon systems, and autonomous maritime ships.},
  archive      = {J_JIRS},
  author       = {Nawaz, Samar Abbas},
  doi          = {10.1007/s10846-024-02056-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Regulating autonomy in civilian drones: Towards a spectral approach},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Performance guarantee for autonomous robotic missions using
resource management: The PANORAMA approach. <em>JIRS</em>,
<em>110</em>(2), 1–27. (<a
href="https://doi.org/10.1007/s10846-024-02058-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the PANORAMA approach, which is designed to dynamically and autonomously manage the allocation of a robot’s hardware and software resources during fully autonomous mission. This behavioral autonomy approach guarantees the satisfaction of the mission performance constraints. This article clarifies the concept of performance for autonomous robotic missions and details the different phases of the PANORAMA approach. Finally, it focuses on an experimental implementation on a patrolling mission example.},
  archive      = {J_JIRS},
  author       = {Lambert, Philippe and Godary-Dejean, Karen and Lapierre, Lionel and Jaiem, Lotfi and Crestani, Didier},
  doi          = {10.1007/s10846-024-02058-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-27},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Performance guarantee for autonomous robotic missions using resource management: The PANORAMA approach},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Power transmission line inspections: Methods, challenges,
current status and usage of unmanned aerial systems. <em>JIRS</em>,
<em>110</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10846-024-02061-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condition monitoring of power transmission lines is an essential aspect of improving transmission efficiency and ensuring an uninterrupted power supply. Wherein, efficient inspection methods play a critical role for carrying out regular inspections with less effort &amp; cost, minimum labour engagement and ease of execution in any geographical &amp; environmental conditions. Earlier various methods such as manual inspection, roll-on wire robotic inspection and helicopter-based inspection are preferably utilized. In the present days, Unmanned Aerial System (UAS) based inspection techniques are gradually increasing its suitability in terms of working speed, flexibility to program for difficult circumstances, accuracy in data collection and cost minimization. This paper reports a state-of-the-art study on the inspection of power transmission line systems and various methods utilized therein, along with their merits and demerits, which are explained and compared. Furthermore, a review was also carried out for the existing visual inspection systems utilized for power line inspection. In addition to that, blockchain utilities for power transmission line inspection are discussed, which illustrates next-generation data management possibilities, automating an effective inspection and providing solutions for the current challenges. Overall, the review demonstrates a concept for synergic integration of deep learning, navigation control concepts and the utilization of advanced sensors so that UAVs with advanced computation techniques can be analyzed with different aspects of implementation.},
  archive      = {J_JIRS},
  author       = {Ahmed, Faiyaz and Mohanta, J. C. and Keshari, Anupam},
  doi          = {10.1007/s10846-024-02061-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Power transmission line inspections: Methods, challenges, current status and usage of unmanned aerial systems},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on reconfiguration strategies for
self-reconfiguring modular robots: A review. <em>JIRS</em>,
<em>110</em>(2), 1–23. (<a
href="https://doi.org/10.1007/s10846-024-02067-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progress of science and technology, the traditional robot workplace is fixed, single-function, and inflexible, and may not work properly in some special places, while the modular robot with self-reconfiguration function is a robot that can adapt to new environments and can rely on new task settings, which has a series of universal modules and relies on mutual communication between modules and autonomous reorganization movements to cope with changes in the environment or tasks and recover from the state of destruction. This paper summarizes the representative international research results from the perspective of the hardware design of robots in two aspects based on the design characteristics of self-reconfiguring modular robots around the reconfiguration strategy planning method. At the same time, some existing problems and shortcomings are pointed out on this basis to provide ideas as well as perspectives for future research development.},
  archive      = {J_JIRS},
  author       = {Dai, Ye and He, Shilong and Nie, XinLei and Rui, Xukun and Li, ShiKun and He, Sai},
  doi          = {10.1007/s10846-024-02067-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-23},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Research on reconfiguration strategies for self-reconfiguring modular robots: A review},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Legal dilemmas of drone development in poland.
<em>JIRS</em>, <em>110</em>(2), 1–8. (<a
href="https://doi.org/10.1007/s10846-024-02068-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to discuss in detail the legal aspects of drone use in Poland and demonstrate the need to establish a legal act (Drone Code) that would comprehensively regulate the principles of safe drone use, whether aerial, land or sea, as well as to show the importance of creating a public administration body competent for drone-related issues, or perhaps even an entirely new international organization to safeguard the legal and ethical use of drones.},
  archive      = {J_JIRS},
  author       = {Jasiuk, Ewa and Chochowska, Anna and Chochowski, Krzysztof},
  doi          = {10.1007/s10846-024-02068-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-8},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Legal dilemmas of drone development in poland},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinearly optimized dual stereo visual odometry fusion.
<em>JIRS</em>, <em>110</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s10846-024-02069-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual odometry (VO) is an important problem studied in robotics and computer vision in which the relative camera motion is computed through visual information. In this work, we propose to reduce the error accumulation of a dual stereo VO system (4 cameras) computing 6 degrees of freedom poses by fusing two independent stereo odometry with a nonlinear optimization. Our approach computes two stereo odometries employing the LIBVISO2 algorithm and later merge them by using image correspondences between the stereo pairs and minimizing the reprojection error with graph-based bundle adjustment. Experiments carried out on the KITTI odometry datasets show that our method computes more accurate estimates (measured as the Relative Positioning Error) in comparison to the traditional stereo odometry (stereo bundle adjustment). In addition, the proposed method has a similar or better odometry accuracy compared to ORB-SLAM2 and UCOSLAM algorithms.},
  archive      = {J_JIRS},
  author       = {Cabrera-Ávila, Elizabeth Viviana and da Silva, Bruno Marques Ferreira and Gonçalves, Luiz Marcos Garcia},
  doi          = {10.1007/s10846-024-02069-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Nonlinearly optimized dual stereo visual odometry fusion},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonsingular hierarchical approach for trajectory tracking
control of miniature helicopter with model uncertainties. <em>JIRS</em>,
<em>110</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02072-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on hierarchical inner-outer loop strategy, the tracking control for the helicopter system could be designed individually for the position loop and for the attitude loop, thus simplifying the underactuated control problem. However, due to the nonlinear coupling between the position dynamics and rotation dynamics, the performance of the position control is affected by attitude errors, especially when the attitude control can not tracks the reference attitude instantaneously. This work provides a hierarchical trajectory tracking control design for the helicopter with model uncertainties, ensuring the stability of the overall system considering the perturbation caused by attitude tracking errors and the nonlinear coupling. The attitude of the helicopter is descried by unit-quaternion, for which anti-unwinding control design is presented. Besides, the criteria for avoidance of singularity in generation of the reference attitude is derived. Simulation results demonstrate the effectiveness of the design.},
  archive      = {J_JIRS},
  author       = {Liu, Ce},
  doi          = {10.1007/s10846-024-02072-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Nonsingular hierarchical approach for trajectory tracking control of miniature helicopter with model uncertainties},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emerging frontiers in human–robot interaction.
<em>JIRS</em>, <em>110</em>(2), 1–26. (<a
href="https://doi.org/10.1007/s10846-024-02074-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective interactions between humans and robots are vital to achieving shared tasks in collaborative processes. Robots can utilize diverse communication channels to interact with humans, such as hearing, speech, sight, touch, and learning. Our focus, amidst the various means of interactions between humans and robots, is on three emerging frontiers that significantly impact the future directions of human–robot interaction (HRI): (i) human–robot collaboration inspired by human–human collaboration, (ii) brain-computer interfaces, and (iii) emotional intelligent perception. First, we explore advanced techniques for human–robot collaboration, covering a range of methods from compliance and performance-based approaches to synergistic and learning-based strategies, including learning from demonstration, active learning, and learning from complex tasks. Then, we examine innovative uses of brain-computer interfaces for enhancing HRI, with a focus on applications in rehabilitation, communication, brain state and emotion recognition. Finally, we investigate the emotional intelligence in robotics, focusing on translating human emotions to robots via facial expressions, body gestures, and eye-tracking for fluid, natural interactions. Recent developments in these emerging frontiers and their impact on HRI were detailed and discussed. We highlight contemporary trends and emerging advancements in the field. Ultimately, this paper underscores the necessity of a multimodal approach in developing systems capable of adaptive behavior and effective interaction between humans and robots, thus offering a thorough understanding of the diverse modalities essential for maximizing the potential of HRI.},
  archive      = {J_JIRS},
  author       = {Safavi, Farshad and Olikkal, Parthan and Pei, Dingyi and Kamal, Sadia and Meyerson, Helen and Penumalee, Varsha and Vinjamuri, Ramana},
  doi          = {10.1007/s10846-024-02074-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-26},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Emerging frontiers in Human–Robot interaction},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A real-time fuzzy interacting multiple-model velocity
obstacle avoidance approach for unmanned aerial vehicles. <em>JIRS</em>,
<em>110</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02075-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new fuzzy interacting multiple-model velocity obstacle (FIMVO) approach for collision avoidance of unmanned aerial vehicles (UAVs). The proposed approach adopts in one framework the advantages of geometric collision avoidance approaches, namely of the velocity (VO), reciprocal velocity (RVO), and hybrid reciprocal velocity obstacle (HRVO) avoidance approaches combined with fuzzy logic. This leads to a combined decision-making rule, with real-time efficiency. The developed approach is compared with geometric conventional velocity obstacle avoidance approaches: VO, RVO, and HRVO avoidance approaches. The proposed approach is carefully evaluated and validated in a simulation environment and over real UAVs. The case study includes three mini UAVs and a human teleoperator who can control only one of them. The other UAVs used the computer-based teleoperator with the proposed and compared approaches. The performance criteria have been defined in four parts: trajectory smoothness, task performance, algorithm simplicity, and reliability. In 1000 independently repeated simulations, the performance results showed that the proposed FIMVO approach was 10 times better than the VO approach in terms of the number of avoided collisions. The statistical analysis demonstrates that the proposed FIMVO approach outperforms geometric velocity obstacle avoidance approaches concerning reliability and real-time efficiency.},
  archive      = {J_JIRS},
  author       = {Candan, Fethi and Beke, Aykut and Mahfouf, Mahdi and Mihaylova, Lyudmila},
  doi          = {10.1007/s10846-024-02075-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A real-time fuzzy interacting multiple-model velocity obstacle avoidance approach for unmanned aerial vehicles},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient stacking and grasping in unstructured
environments. <em>JIRS</em>, <em>110</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02078-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics has been booming in recent years. Especially with the development of artificial intelligence, more and more researchers have devoted themselves to the field of robotics, but there are still many shortcomings in the multi-task operation of robots. Reinforcement learning has achieved good performance in manipulator manipulation, especially in grasping, but grasping is only the first step for the robot to perform actions, and it often ignores the stacking, assembly, placement, and other tasks to be carried out later. Such long-horizon tasks still face the problems of expensive time, dead-end exploration, and process reversal. Hierarchical reinforcement learning has some advantages in solving the above problems, but not all tasks can be learned hierarchically. This paper mainly solves the complex manipulation task of continuous multi-action of the manipulator by improving the method of hierarchical reinforcement learning, aiming to solve the task of long sequences such as stacking and alignment by proposing a framework. Our framework completes simulation experiments on various tasks and improves the success rate from 78.3% to 94.8% when cleaning cluttered toys. In the stacking toy experiment, the training speed is nearly three times faster than the baseline method. And our method can be generalized to other long-horizon tasks. Experiments show that the more complex the task, the greater the advantage of our framework.},
  archive      = {J_JIRS},
  author       = {Wang, Fei and Liu, Yue and Shi, Manyi and Chen, Chao and Liu, Shangdong and Zhu, Jinbiao},
  doi          = {10.1007/s10846-024-02078-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Efficient stacking and grasping in unstructured environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep visual-guided and deep reinforcement learning algorithm
based for multip-peg-in-hole assembly task of power distribution
live-line operation robot. <em>JIRS</em>, <em>110</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02079-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inspection and maintenance of power distribution network are crucial for efficiently delivering electricity to consumers. Due to the high voltage of power distribution network lines, manual live-line operations are difficult, risky, and inefficient. This paper researches a Power Distribution Network Live-line Operation Robot (PDLOR) with autonomous tool assembly capabilities to replace humans in various high-risk electrical maintenance tasks. To address the challenges of tool assembly in dynamic and unstructured work environments for PDLOR, we propose a framework consisting of deep visual-guided coarse localization and prior knowledge and fuzzy logic driven deep deterministic policy gradient (PKFD-DPG) high-precision assembly algorithm. First, we propose a multiscale identification and localization network based on YOLOv5, which enables the peg-hole close quickly and reduces ineffective exploration. Second, we design a main-auxiliary combined reward system, where the main-line reward uses the hindsight experience replay mechanism, and the auxiliary reward is based on fuzzy logic inference mechanism, addressing ineffective exploration and sparse reward in the learning process. In addition, we validate the effectiveness and advantages of the proposed algorithm through simulations and physical experiments, and also compare its performance with other assembly algorithms. The experimental results show that, for single-tool assembly tasks, the success rate of PKFD-DPG is 15.2% higher than the DDPG with functionized reward functions and 51.7% higher than the PD force control method; for multip-tools assembly tasks, the success rate of PKFD-DPG method is 17% and 53.4% higher than the other methods.},
  archive      = {J_JIRS},
  author       = {Zheng, Li and Ai, Jiajun and Wang, Yahao and Tang, Xuming and Wu, Shaolei and Cheng, Sheng and Guo, Rui and Dong, Erbao},
  doi          = {10.1007/s10846-024-02079-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Deep visual-guided and deep reinforcement learning algorithm based for multip-peg-in-hole assembly task of power distribution live-line operation robot},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bioinspired control strategy ensures maneuverability and
adaptability for dynamic environments in an underactuated robotic fish.
<em>JIRS</em>, <em>110</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02080-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bioinspired underwater robots can move efficiently, with agility, even in complex aquatic areas, reducing marine ecosystem disturbance during exploration and inspection. These robots can improve animal farming conditions and preserve wildlife. This study proposes a muscle-like control for an underactuated robot in carangiform swimming mode. The artifact exploits a single DC motor with a non-blocking transmission system to convert the motor’s oscillatory motion into the fishtail’s oscillation. The transmission system combines a magnetic coupling and a wire-driven mechanism. The control strategy was inspired by central pattern generators (CPGs) to control the torque exerted on the fishtail. It integrates proprioceptive sensory feedback to investigate the adaptability to different contexts. A parametrized control law relates the reference target to the fishtail’s angular position. Several tests were carried out to validate the control strategy. The proprioceptive feedback revealed that the controller can adapt to different environments and tail structure changes. The control law parameters variation accesses the robotic fish’s multi-modal swimming. Our solution can vary the swimming speed of 0.08 body lengths per second (BL/s), and change the steering direction and performance by an angular speed and turning curvature radius of 0.08 rad/s and 0.25 m, respectively. Performance can be improved with design changes, while still maintaining the developed control strategy. This approach ensures the robot’s maneuverability despite its underactuated structure. Energy consumption was evaluated under the robotic platform’s control and design. Our bioinspired control system offers an effective, reliable, and sustainable solution for exploring and monitoring aquatic environments, while minimizing human risks and preserving the ecosystem. Additionally, it creates new and innovative opportunities for interacting with marine species. Our findings demonstrate the potential of bioinspired technologies to advance the field of marine science and conservation.},
  archive      = {J_JIRS},
  author       = {Manduca, Gianluca and Santaera, Gaspare and Miraglia, Marco and Jansen Van Vuuren, Godfried and Dario, Paolo and Stefanini, Cesare and Romano, Donato},
  doi          = {10.1007/s10846-024-02080-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A bioinspired control strategy ensures maneuverability and adaptability for dynamic environments in an underactuated robotic fish},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A decomposition and a scheduling framework for enabling
aerial 3D printing. <em>JIRS</em>, <em>110</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02081-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aerial 3D printing is a pioneering technology yet in its conceptual stage that combines frontiers of 3D printing and Unmanned aerial vehicles (UAVs) aiming to construct large-scale structures in remote and hard-to-reach locations autonomously. The envisioned technology will enable a paradigm shift in the construction and manufacturing industries by utilizing UAVs as precision flying construction workers. However, the limited payload-carrying capacity of the UAVs, along with the intricate dexterity required for manipulation and planning, imposes a formidable barrier to overcome. Aiming to surpass these issues, a novel aerial decomposition-based and scheduling 3D printing framework is presented in this article, which considers a near-optimal decomposition of the original 3D shape of the model into smaller, more manageable sub-parts called chunks. This is achieved by searching for planar cuts based on a heuristic function incorporating necessary constraints associated with the interconnectivity between subparts, while avoiding any possibility of collision between the UAV’s extruder and generated chunks. Additionally, an autonomous task allocation framework is presented, which determines a priority-based sequence to assign each printable chunk to a UAV for manufacturing. The efficacy of the proposed framework is demonstrated using the physics-based Gazebo simulation engine, where various primitive CAD-based aerial 3D constructions are established, accounting for the nonlinear UAVs dynamics, associated motion planning and reactive navigation through Model predictive control.},
  archive      = {J_JIRS},
  author       = {Stamatopoulos, Marios-Nektarios and Banerjee, Avijit and Nikolakopoulos, George},
  doi          = {10.1007/s10846-024-02081-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A decomposition and a scheduling framework for enabling aerial 3D printing},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Developing computational thinking in middle school with an
educational robotics resource. <em>JIRS</em>, <em>110</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02082-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational Thinking has been recognized as an essential skill to be developed in individuals of the 21st Century. Various initiatives worldwide have been proposed to establish the most effective educational strategies and resources to support the development of these skills. With the publication of the Standards for Computing in Basic Education in Brazil (Complement to the National Base Common Curricular), Computer Science is expected to be taught as a fundamental science from Early Childhood Education to High School. In this context, this study presents the results of the students’ learning and the usability evaluation of the ThinkCarpet: an interactive educational robotics artifact built using alternative materials and Arduino, with the purpose of aiding in the development of the concept of algorithms in students from Middle School. Regarding the students’ learning, an average of 93.75% of valid solutions was observed for the algorithms validated through the use of the ThinkCarpet. In contrast, only 62% of valid solutions were identified in activities outside the proposed resource. As for the results of the application of the System Usability Scale (SUS), the results show a score of 83.59, which classifies the ThinkCarpet as excellent in a realistic scenario.},
  archive      = {J_JIRS},
  author       = {Costa Junior, Almir de O. and Guedes, Elloá B. and Lima e Silva, João Paulo F. and Rivera, José Anglada},
  doi          = {10.1007/s10846-024-02082-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Developing computational thinking in middle school with an educational robotics resource},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Very low level flight rules for manned and unmanned aircraft
operations. <em>JIRS</em>, <em>110</em>(2), 1–8. (<a
href="https://doi.org/10.1007/s10846-024-02084-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An analysis of the development of legal regulations regarding unmanned civil aviation leads to the conclusion that the current air traffic rules are among the key issues that require amending. Are drones allowed to fly at any height? Can drones fly freely over a person’s house or garden, several meters above the ground? What is the minimum allowable height for drone flights? The method of study consisted of content analysis of the existing legislation. Current doctrines were confronted with the existing regulations, documents, materials, safety reports, and statistics. The results of the study show that the existing air traffic rules, precisely in the case of aircraft operations performed by manned and unmanned aviation at very low heights, are definitely practical in nature. First, in most countries violations of air traffic rules are prohibited acts subject to criminal penalty. Second, determining the principles of air traffic for air operations is of crucial importance for determining legally permissible interference in property ownership. The urban air mobility is outside the scope of this research.},
  archive      = {J_JIRS},
  author       = {Konert, Anna and Kasprzyk, Piotr},
  doi          = {10.1007/s10846-024-02084-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-8},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Very low level flight rules for manned and unmanned aircraft operations},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trading-off safety with agility using deep pose error
estimation and reinforcement learning for perception-driven UAV motion
planning. <em>JIRS</em>, <em>110</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02085-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigation and planning for unmanned aerial vehicles (UAVs) based on visual-inertial sensors has been a popular research area in recent years. However, most visual sensors are prone to high error rates when exposed to disturbances such as excessive brightness and blur, which can lead to catastrophic performance drops in perception and motion planning systems. This study proposes a novel framework to address the coupled perception-planning problem in high-risk environments. This achieved by developing algorithms that can automatically adjust the agility of the UAV maneuvers based on the predicted error rate of the pose estimation system. The fundamental idea behind our work is to demonstrate that highly agile maneuvers become infeasible to execute when visual measurements are noisy. Thus, agility should be traded-off with safety to enable efficient risk management. Our study focuses on navigating a quadcopter through a sequence of gates on an unknown map, and we rely on existing deep learning methods for visual gate-pose estimation. In addition, we develop an architecture for estimating the pose error under high disturbance visual inputs. We use the estimated pose errors to train a reinforcement learning agent to tune the parameters of the motion planning algorithm to safely navigate the environment while minimizing the track completion time. Simulation results demonstrate that our proposed approach yields significantly fewer crashes and higher track completion rates compared to approaches that do not utilize reinforcement learning.},
  archive      = {J_JIRS},
  author       = {Kaymaz, Mehmetcan and Ayzit, Recep and Akgün, Onur and Atik, Kamil Canberk and Erdem, Mustafa and Yalcin, Baris and Cetin, Gürkan and Ure, Nazım Kemal},
  doi          = {10.1007/s10846-024-02085-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Trading-off safety with agility using deep pose error estimation and reinforcement learning for perception-driven UAV motion planning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attack detection and security control for UAVs against
attacks on desired trajectory. <em>JIRS</em>, <em>110</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02086-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a security control scheme for unmanned aerial vehicles (UAVs) against desired trajectory attacks. The key components of the proposed scheme are the attack detector, attack estimator, and integral sliding mode security controller (ISMSC). We focus on malicious tampering of the desired trajectory sent by the ground control station (GCS) to the UAV by attackers. Firstly, we model attacks by analyzing the characteristics of desired trajectory attacks. Secondly, an integrated attack detection scheme based on an unknown input observer (UIO) and an interval observer is presented. Subsequently, a robust adaptive observer (RAO) is employed to compensate for the impact of attacks on the control system. Thirdly, an ISMSC with an attack compensation mechanism is established. Finally, simulation results are provided to verify the effectiveness of the proposed scheme. The proposed detection scheme can not only detect desired trajectory attacks but also distinguish them from abrupt unknown disturbances (AUDs). By utilizing ISMSC method, UAVs under desired trajectory attacks can fly safely. The proposed comprehensive framework of detection, estimation and compensation provides a theoretical basis for ensuring cyber security in UAVs.},
  archive      = {J_JIRS},
  author       = {Pan, Kunpeng and Lyu, Yang and Yang, Feisheng and Tan, Zheng and Pan, Quan},
  doi          = {10.1007/s10846-024-02086-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Attack detection and security control for UAVs against attacks on desired trajectory},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online as-built building information model update for
robotic monitoring in construction sites. <em>JIRS</em>,
<em>110</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02087-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, automated techniques for the update of as-built Building Information Models (BIM) make use of offline algorithms restricting the update frequency to an extent where continuous monitoring becomes nearly impossible. To address this problem, we propose a new method for robotic monitoring that updates an as-built BIM in real-time by solving a Simultaneous Localization and Mapping (SLAM) problem where the map is represented as a collection of elements from the as-planned BIM. The suggested approach is based on the Rao-Blackwellized Particle Filter (RBPF) which enables explicit injection of prior knowledge from the building’s construction schedule, i.e., from a 4D BIM, or its elements’ spatial relations. In the methods section we describe the benefits of using an exact inverse sensor model that provides a measure for the existence probability of elements while considering the entire probabilistic existence belief map. We continue by outlining robustification techniques that include both geometrical and temporal dimensions and present how we account for common pose and shape mistakes in constructed elements. Additionally, we show that our method reduces to the standard Monte Carlo Localization (MCL) in known areas. We conclude by presenting simulation results of the proposed method and comparing it to adjacent alternatives.},
  archive      = {J_JIRS},
  author       = {Spinner, Alon and Degani, Amir},
  doi          = {10.1007/s10846-024-02087-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Online as-built building information model update for robotic monitoring in construction sites},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive non-singular fast terminal sliding mode control for
car-like vehicles with faded neighborhood information and actuator
faults. <em>JIRS</em>, <em>110</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02088-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the problem of cooperative control design for a group of car-like vehicles encountering fading channels, actuator faults, and external disturbances. It is presumed that certain followers lack direct access to the states of the leader via a directed graph. This arises challenges in maintaining synchronization and coordination within the network. The proposed control strategy utilizes non-singular fast terminal sliding mode control to accelerate consensus tracking and enhance the convergence of the overall system. This controller is designed to mitigate the impact of actuator faults in the presence of fading channels in the communication network. The effects of such issues on team performance are rigorously analyzed. Based on the Lyapunov stability principle, it has been demonstrated that the controller is capable of providing satisfactory performance for the entire system despite these challenges. Moreover, vehicle synchronization can be effectively maintained. Numerical simulations are conducted to verify the theoretical findings.},
  archive      = {J_JIRS},
  author       = {Hussein, Mahmoud and Zhang, Youmin and Liu, Zhaoheng},
  doi          = {10.1007/s10846-024-02088-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Adaptive non-singular fast terminal sliding mode control for car-like vehicles with faded neighborhood information and actuator faults},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Innovative exploration of a bio-inspired sensor fusion
algorithm: Enhancing micro satellite functionality through touretsky’s
decentralized neural networks. <em>JIRS</em>, <em>110</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02089-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insect-inspired sensor fusion algorithms have presented a promising avenue in the development of robust and efficient systems, owing to the insects&#39; ability to process numerous streams of noisy sensory data. The ring attractor neural network architecture has been identified as a noteworthy model for the optimal integration of diverse insect sensors. Expanding on this, our research presents an innovative bio-inspired ring attractor neural network architecture designed to augment the performance of microsatellite attitude determination systems through the fusion of data from multiple gyroscopic sensors.Extensive simulations using a nonlinear model of the microsatellite, while incorporating specific navigational disturbances, have been conducted to ascertain the viability and effectiveness of this approach. The results obtained have been superior to those of alternative methodologies, thus highlighting the potential of our proposed bio-inspired fusion technique. The findings indicate that this approach could significantly improve the accuracy and robustness of microsatellite systems across a wide range of applications.},
  archive      = {J_JIRS},
  author       = {Hassani. N, S. M. Mehdi. and Roshanian, Jafar},
  doi          = {10.1007/s10846-024-02089-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Innovative exploration of a bio-inspired sensor fusion algorithm: Enhancing micro satellite functionality through touretsky&#39;s decentralized neural networks},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A compact aerial manipulator: Design and control for
dexterous operations. <em>JIRS</em>, <em>110</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s10846-024-02090-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of aerial physical interaction capability is one of the choke points limiting the extension of aerial robot applications, such as rescue missions and aerial maintenance. We present a new aerial robotic manipulator (AEROM) for aerial dexterous operations in this work. It contains a robotic manipulator with 6-degree-of-freedom and a compact flight platform. Firstly, we propose a quantitative capability index to evaluate and guide the mechanical design of the AEROM. Based on the proposed quantitative index, we construct a lightweight bird-inspired manipulator to imitate a raptor hindlimb. An additional telescopic joint and an end-effector consisting of three soft fingers allow the AEROM to execute aerial interaction tasks. In addition, the wrist joints enable independent control of the end-effector attitude regardless of the flight platform. After explicitly analyzing the multi-source disturbances during the aerial operation tasks, we develop a refined anti-disturbance controller to compensate for the disturbances with different characteristics. The proposed controller further improves the position accuracy of end-effector to enable dexterous operations during aerial interaction tasks. Finally, the physical experiments verify the effectiveness of the proposed AEROM system.},
  archive      = {J_JIRS},
  author       = {Liu, Qianyuan and Liu, Yuhang and Chen, Zeshuai and Guo, Kexin and Yu, Xiang and Zhang, Youmin and Guo, Lei},
  doi          = {10.1007/s10846-024-02090-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A compact aerial manipulator: Design and control for dexterous operations},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Vision-state fusion: Improving deep neural networks for
autonomous robotics. <em>JIRS</em>, <em>110</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02091-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based deep learning perception fulfills a paramount role in robotics, facilitating solutions to many challenging scenarios, such as acrobatic maneuvers of autonomous unmanned aerial vehicles (UAVs) and robot-assisted high-precision surgery. Control-oriented end-to-end perception approaches, which directly output control variables for the robot, commonly take advantage of the robot’s state estimation as an auxiliary input. When intermediate outputs are estimated and fed to a lower-level controller, i.e., mediated approaches, the robot’s state is commonly used as an input only for egocentric tasks, which estimate physical properties of the robot itself. In this work, we propose to apply a similar approach for the first time – to the best of our knowledge – to non-egocentric mediated tasks, where the estimated outputs refer to an external subject. We prove how our general methodology improves the regression performance of deep convolutional neural networks (CNNs) on a broad class of non-egocentric 3D pose estimation problems, with minimal computational cost. By analyzing three highly-different use cases, spanning from grasping with a robotic arm to following a human subject with a pocket-sized UAV, our results consistently improve the R $$^{2}$$ regression metric, up to +0.51, compared to their stateless baselines. Finally, we validate the in-field performance of a closed-loop autonomous cm-scale UAV on the human pose estimation task. Our results show a significant reduction, i.e., 24% on average, on the mean absolute error of our stateful CNN, compared to a State-of-the-Art stateless counterpart.},
  archive      = {J_JIRS},
  author       = {Cereda, Elia and Bonato, Stefano and Nava, Mirko and Giusti, Alessandro and Palossi, Daniele},
  doi          = {10.1007/s10846-024-02091-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Vision-state fusion: Improving deep neural networks for autonomous robotics},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous multi-view object recognition and grasping in
open-ended domains. <em>JIRS</em>, <em>110</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02092-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To aid humans in everyday tasks, robots need to know which objects exist in the scene, where they are, and how to grasp and manipulate them in different situations. Therefore, object recognition and grasping are two key functionalities for autonomous robots. Most state-of-the-art approaches treat object recognition and grasping as two separate problems, even though both use visual input. Furthermore, the knowledge of the robot is fixed after the training phase. In such cases, if the robot encounters new object categories, it must be retrained to incorporate new information without catastrophic forgetting. To resolve this problem, we propose a deep learning architecture with an augmented memory capacity to handle open-ended object recognition and grasping simultaneously. In particular, our approach takes multi-views of an object as input and jointly estimates pixel-wise grasp configuration as well as a deep scale- and rotation-invariant representation as output. The obtained representation is then used for open-ended object recognition through a meta-active learning technique. We demonstrate the ability of our approach to grasp never-seen-before objects and to rapidly learn new object categories using very few examples on-site in both simulation and real-world settings. Our approach empowers a robot to acquire knowledge about new object categories using, on average, less than five instances per category and achieve $$95\%$$ object recognition accuracy and above $$91\%$$ grasp success rate on (highly) cluttered scenarios in both simulation and real-robot experiments. A video of these experiments is available online at: https://youtu.be/n9SMpuEkOgk},
  archive      = {J_JIRS},
  author       = {Kasaei, Hamidreza and Kasaei, Mohammadreza and Tziafas, Georgios and Luo, Sha and Sasso, Remo},
  doi          = {10.1007/s10846-024-02092-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Simultaneous multi-view object recognition and grasping in open-ended domains},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-agent cooperative camera-based semantic grid
generation. <em>JIRS</em>, <em>110</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02093-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The idea of cooperative perception for navigation assistance was introduced about a decade ago with the aim to increase safety on dangerous areas like intersections. In this context, roadside infrastructure appeared very recently to provide a new point of view of the scene. In this paper, we propose to combine the Vehicle-To-Vehicle (V2V) and Vehicle-To-Infrastructure (V2I) approaches in order to take advantage of the elevated points of view offered by the infrastructure and the in-scene points of view offered by the vehicles to build a semantic grid map of the moving elements in the scene. To create this map, we chose to use camera information and 2-Dimentional (2D) bounding boxes in order to minimize the impact on the network and ignored possible depth information as opposed to all state-of-the art methods. We propose a framework based on two fusion methods: one based on the Bayesian theory and the other on the Dempster-Shafer Theory (DST) to merge the information and chose a label for each cell of the semantic grid in order to assess the best fusion method. Finally, we evaluate our approach on a set of datasets that we generated from the CARLA simulator varying the proportion of Connected Vehicle (CV) and the traffic density. We also show the superiority of the method based on the DST with a gain on the mean intersection over union between the two methods of up to 23.35%.},
  archive      = {J_JIRS},
  author       = {Caillot, Antoine and Ouerghi, Safa and Dupuis, Yohan and Vasseur, Pascal and Boutteau, Rémi},
  doi          = {10.1007/s10846-024-02093-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Multi-agent cooperative camera-based semantic grid generation},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Persistent schedule evaluation and adaptive re-planning for
maritime search tasks. <em>JIRS</em>, <em>110</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02094-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Search operations performed by adaptive autonomous maritime vehicles have been a topic of considerable interest for many years. Such operations require carefully scheduled coordination of multiple vehicles performing search tasks across the region of interest. Due to the inherent uncertainty of the maritime environment, however, an initially planned search schedule may not be maintained if the vehicles have significant capability to adapt their tasks to match the environment they detect in real time. We propose a multi-vehicle adaptive algorithm for dynamic evaluation and elastic re-planning of variable-length tasks commonly found in the maritime environments. In adaptive evaluation and re-planning problems, a set of tasks are initially planned for execution by adaptive, autonomous search vehicles. Tasks are allocated to search vehicles under a pre-defined schedule based on prior knowledge and desired outcome. Because of the vehicles’ autonomy and reactivity to in situ conditions such as environment or target pose, the precise duration and actions required by each task are unknown a priori. We develop a hidden Markov model (HMM) for propagating task estimates, coupled with a quadratic-programming-based elastic re-scheduler. The result is an integrated estimate-and-schedule adaptation scheme that quickly and efficiently re-plans the vehicles’ schedules based on in situ observations. The numerical simulation results show that this novel HMM approach decreases avoidable schedule variation by over a factor of two compared to existing methods.},
  archive      = {J_JIRS},
  author       = {Bays, Matthew J. and Wettergren, Thomas A. and Shin, Jaejeong and Chang, Shi and Ferrari, Silvia},
  doi          = {10.1007/s10846-024-02094-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Persistent schedule evaluation and adaptive re-planning for maritime search tasks},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ROV-based autonomous maneuvering for ship hull inspection
with coverage monitoring. <em>JIRS</em>, <em>110</em>(2), 1–24. (<a
href="https://doi.org/10.1007/s10846-024-02095-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hull inspection is an important task to ensure sustainability of ships. To overcome the challenges of hull structure inspection in an underwater environment in an efficient way, an autonomous system for hull inspection has to be developed. In this paper, a new approach to underwater ship hull inspection is proposed. It aims at developing the basis for an end-to-end autonomous solution. The real-time aspect is an important part of this work, as it allows the operators and inspectors to receive feedback about the inspection as it happens. A reference mission plan is generated and adapted online based on the inspection findings. This is done through the processing of a multibeam forward looking sonar to estimate the pose of the hull relative to the drone. An inspection map is incrementally built in a novel way, incorporating uncertainty estimates to better represent the inspection state, quality, and observation confidence. The proposed methods are experimentally tested in real-time on real ships and demonstrate the applicability to quickly understand what has been done during the inspection.},
  archive      = {J_JIRS},
  author       = {Cardaillac, Alexandre and Skjetne, Roger and Ludvigsen, Martin},
  doi          = {10.1007/s10846-024-02095-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-24},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {ROV-based autonomous maneuvering for ship hull inspection with coverage monitoring},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Curvature scale space LiDAR odometry and mapping (LOAM).
<em>JIRS</em>, <em>110</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s10846-024-02096-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The LiDAR Odometry and Mapping (LOAM) algorithm ranks in second place in the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI), Visual Odometry/SLAM Evaluations. It utilizes a feature extraction algorithm based on the evaluation of the curvature of points under test, to produce estimated smooth and non-smooth regions within typically laser based Point Cloud Data (PCD). This feature extractor (FE) however, does not take into account PCD spatial or detection uncertainty, which can result in the divergence of the LOAM algorithm. Therefore, this article proposes the use of the Curvature Scale Space (CSS) algorithm as a replacement for LOAM’s current feature extractor. It justifies the substitution, based on the CSS algorithm’s similar computational complexity but improved feature detection repeatability. LOAM’s current feature extractor and the proposed CSS feature extractor are tested and compared with simulated and real data, including the KITTI odometry-laser data set. Additionally, a recent deep learning based LiDAR Odometry (LO) algorithm, the Convolutional Auto-Encoder (CAE)-LO algorithm, will also be compared, using this data set, in terms of its computational speed and performance. Performance comparisons are made based on the Absolute Trajectory Error (ATE) and Cardinalized Optimal Linear Assignment (COLA) metrics. Based on these metrics, the comparisons show significant improvements of the LOAM algorithm with the CSS feature extractor compared with the benchmark versions.},
  archive      = {J_JIRS},
  author       = {Gonzalez, Clayder and Adams, Martin},
  doi          = {10.1007/s10846-024-02096-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Curvature scale space LiDAR odometry and mapping (LOAM)},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Restoring connectivity in robotic swarms – a probabilistic
approach. <em>JIRS</em>, <em>110</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10846-024-02097-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity is an integral trait for swarm robotic systems to enable effective collaboration between the robots in the swarm. However, connectivity can be lost due to events that could not have been a priori accounted for. This paper presents a novel probabilistic connectivity-restoration strategy for swarms with limited communication capabilities. Namely, it is assumed that the swarm comprises a group of follower robots whose global connectivity to a base can only be achieved via a localized leader robot. In this context, the proposed strategy incrementally restores swarm connectivity by searching for the lost robots in regions-of-interest (RoIs) determined using probability theory. Once detected, newly found robots are either recruited to help the leader in the restoration process, or directly guided to their respective destinations through accurate localization and corrective motion commands. The proposed swarm-connectivity strategy, thus, comprises the following three stages: (i) identifying a discrete set of optimal RoIs, (ii) visitation of these RoIs, by the leader robot, via an optimal inter-region search path, and (iii) searching for lost robots within the individual RoIs via an optimal intra-region search path. The strategy is novel in its use of a probabilistic approach to guide the leader robot’s search as well as the potential recruitment of detected lost robots to help in the restoration process. The effectiveness of the proposed probabilistic swarm connectivity-restoration strategy is represented, herein, through a detailed simulated experiment. The significant efficiency of the strategy is also illustrated numerically via a comparison to a competing random-walk based method.},
  archive      = {J_JIRS},
  author       = {Eshaghi, Kasra and Sari, Naeimeh Najafizadeh and Haigh, Cameron and Roman, Darie and Nejat, Goldie and Benhabib, Beno},
  doi          = {10.1007/s10846-024-02097-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Restoring connectivity in robotic swarms – a probabilistic approach},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous and independent control of multiple swimming
magnetic microrobots by stabilizer microrobot. <em>JIRS</em>,
<em>110</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02098-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new strategy for simultaneous control of multiple magnetic Micro Robots (MRs) improving stability and robustness with respect to external disturbances. Independent control of multiple MRs, can enhance efficiency and allows for performing more challenging applications. In this study, we present a system consisting of a Helmholtz coil and 2N Permanent Magnets (PMs), rotated by servomotors, to control several MRs. We have also improved the system’s stability by adding a larger MR (stabilizer MR). This MR can be moved all around the workspace and works as a moving internal magnetic field source. Thanks to this moveable magnetic field, other MRs are more stable against environmental disturbances. By simulating simultaneous and independent control of multiple MRs, we demonstrate the advantages of using the stabilizer MR (more than 20 percent reduction in tracking error and control effort). In addition, we evaluate experimentally our proposed method to independently control the position of three MRs using a stabilizer MR demonstrating the efficacy of the strategy.},
  archive      = {J_JIRS},
  author       = {Khalesi, Ruhollah and Nejat Pishkenari, Hossein and Vossoughi, Gholamreza},
  doi          = {10.1007/s10846-024-02098-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Simultaneous and independent control of multiple swimming magnetic microrobots by stabilizer microrobot},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory tracking control of fixed-wing hybrid aerial
underwater vehicle subject to wind and wave disturbances. <em>JIRS</em>,
<em>110</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02099-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid aerial underwater vehicle (HAUV) could operate in the air and underwater might provide a great convenience for aerial and underwater exploration, and the fixed-wing HAUV (FHAUV) has time, space and cost advantages in future large-scale applications, while the large difference between the aerial and underwater environments is a challenge to control, especially in the air/water transition. However, for FHAUV control, there is a lack of research on phenomena or problems caused by large changes in the air/water transition. In addition, the effects of wind, wave, other factors and conditions on motion control are not investigated. This paper presents the first control study on the above issues. The motion model of FHAUV is developed, with the effects of wind and wave disturbances. Then, this paper improves a cascade gain scheduling (CGS) PID for different media environments (air and water) and proposes a cascade state feedback (CSF) control strategy to address the convergence problem of FHAUV control caused by large speed change in the air/water transition. In the comparisons of the two control schemes in various tracking cases including trajectory slopes, reference speeds, wind and wave disturbances, CSF has a better control effect, convergence rate and robustness; the key factors and conditions of the air/water transition are investigated, the critical relations and feasible domains of the trajectory slopes and reference speeds that the FHAUV must meet to successfully exit the water and enter the air are obtained, the critical slope decreases as the reference speed increases, and the feasible domain of CSF is larger than that of CGS, revealing that CSF is superior than CGS for exiting the water.},
  archive      = {J_JIRS},
  author       = {Li, Junping and Jin, Yufei and Hu, Rui and Bai, Yulin and Lu, Di and Zeng, Zheng and Lian, Lian},
  doi          = {10.1007/s10846-024-02099-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Trajectory tracking control of fixed-wing hybrid aerial underwater vehicle subject to wind and wave disturbances},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A stereovision-based approach for retrieving variable force
feedback in robotic-assisted surgery using modified inception ResNet v2
networks. <em>JIRS</em>, <em>110</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02100-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge of haptic technology has greatly impacted Robotic-assisted surgery in recent years due to its inspirational advancement in the field. Delivering tactile feedback to the surgeon has a significant role in improving the user experience in RAMIS. This work proposes a Modified inception ResNet network along with dimensionality reduction to regenerate the variable force produced during the surgical intervention. This work collects the relevant dataset from two ex vivo porcine skins and one ex vivo artificial skin for the validation of the results. The proposed framework is used to model both spatial and temporal data collected from the sensors, tissue, manipulators, and surgical tools. The evaluations are based on three distinct datasets with modest variations in tissue properties. The results of the proposed framework show an improvement of force prediction accuracy by 10.81% over RNN, 6.02% over RNN + LSTM, and 3.81% over the CNN + LSTM framework, and torque prediction accuracy by 12.41% over RNN, 5.75% over RNN + LSTM, and 3.75% over CNN + LSTM. The sensitivity study demonstrates that features such as torque (96.93%), deformation (94.02%), position (93.98%), vision (92.12%), stiffness (87.95%), tool diameter (89.24%), rotation (65.10%), and orientation (62.51%) have respective influences on the anticipated force. It was observed that the quality of the predicted force improved by 2.18% when performing feature selection and dimensionality reduction on features collected from tool, manipulator, tissue, and vision data and processing them simultaneously in all four architectures. The method has potential applications for online surgical tasks and surgeon training.},
  archive      = {J_JIRS},
  author       = {Sabique, P. V. and Pasupathy, Ganesh and Kalaimagal, S. and Shanmugasundar, G. and Muneer, V. K.},
  doi          = {10.1007/s10846-024-02100-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A stereovision-based approach for retrieving variable force feedback in robotic-assisted surgery using modified inception ResNet v2 networks},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PADRE – a repository for research on fault detection and
isolation of unmanned aerial vehicle propellers. <em>JIRS</em>,
<em>110</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s10846-024-02101-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles are being used increasingly in a variety of applications. They are more and more often operating in close proximity to people and equipment. This necessitates ensuring maximum stability and flight safety. A fundamental step to achieving this goal is timely and effective diagnosis of possible defects. Popular data-based methods require a large amount of data collected during flights in various conditions. This paper describes an open PADRE database of such measurements for the detection and classification of the most common faults - multirotor propeller failures. It presents the procedure of data acquisition, the structure of the repository and ways to use the various types of data contained therein. The repository enables research on drone fault detection to be undertaken without time-consuming preparation of measurement data. The database is available on GitHub at https://github.com/AeroLabPUT/UAV_measurement_data . The article also introduces new and universal quality indicators for evaluating classifiers with non-uniform parameters, are proposed. They allow comparison of methods tested for a variety of fault classes and with different processing times.},
  archive      = {J_JIRS},
  author       = {Puchalski, Radosław and Ha, Quang and Giernacki, Wojciech and Nguyen, Huynh Anh Duy and Nguyen, Lanh Van},
  doi          = {10.1007/s10846-024-02101-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {PADRE – a repository for research on fault detection and isolation of unmanned aerial vehicle propellers},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A soft supernumerary robotic limb with fiber-reinforced
actuators. <em>JIRS</em>, <em>110</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02102-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supernumerary robotic limbs (SRLs) have great potentials to assist human in daily activities and industrial manufacturing by providing extra limbs. However, current SRLs have heavy and rigid structures that may threaten the operator safety; moreover, their limited degrees of freedom and movement modes are not suitable for complicated tasks. Although soft SRLs have exhibited advantages in structure compliance and flexible manipulation to address these problems, it remains challenging to accurately design the geometrical parameters to adapt to specific tasks, and accurate control is also required to realize the expected movement. Inspired by the biological characteristics of the octopus arm muscle fibers, fiber-reinforced actuators (FRAs) are employed to realize various motions, including extension, expansion, bending, and twisting; multiple FRAs are assembled to implement the SRL to achieve complex movement trajectories. The analytic model of the FRA is established to reveal the relationship between its deformation and geometrical parameters as well as input air pressures, which is validated with finite element simulation. Trajectory and payload optimization algorithms are proposed to optimally design the SRL and its control strategy with meeting the prescribed requirement of movement trajectory and payload capacity. Finally, experiments are conducted to validate the proposed robotic system.},
  archive      = {J_JIRS},
  author       = {Xu, Jiajun and Zhang, Tianyi and Huang, Kaizhen and Zhao, Mengcheng and Hou, Xuyan and Li, Youfu},
  doi          = {10.1007/s10846-024-02102-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A soft supernumerary robotic limb with fiber-reinforced actuators},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image moment-based visual positioning and robust tracking
control of ultra-redundant manipulator. <em>JIRS</em>, <em>110</em>(2),
1–18. (<a href="https://doi.org/10.1007/s10846-024-02103-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image moment features can describe more general target patterns and have good decoupling properties. However, the image moment features that control the camera’s rotation motion around the x-axis and y-axis mainly depend on the target image itself. In this paper, the ultra-redundant manipulator visual positioning and robust tracking control method based on the image moments are advocated.First, six image moment features used to control camera motion around the x-axis and around the y-axis are proposed. And then, a novel method is proposed to use to select image features. For tracking a moving target, a kalman filter combined with adaptive fuzzy sliding mode control method is proposed to achieve tracking control of moving targets, which can estimate changes in image features caused by the target’s motion on-line and compensate for estimation errors. Finally, the experimental system based on Labview-RealTime system and ultra-redundant manipulator is used to verify the real-time performance and practicability of the algorithm. Experimental results are presented to illustrate the validity of the image features and tracking method.},
  archive      = {J_JIRS},
  author       = {Li, Zhongcan and Zhou, Yufei and Zhu, Mingchao and Chu, Yongzhi and Wu, Qingwen},
  doi          = {10.1007/s10846-024-02103-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Image moment-based visual positioning and robust tracking control of ultra-redundant manipulator},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotics in the construction sector: Trends, advances, and
challenges. <em>JIRS</em>, <em>110</em>(2), 1–30. (<a
href="https://doi.org/10.1007/s10846-024-02104-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction robots employ cutting-edge technology to perform tasks more accurately than traditional construction workers, producing higher-quality results and fewer mistakes. Moreover, although construction robotics is a demanding topic in construction sector research, more review studies that track and anticipate adoption trends are required in the construction sector. This study aims to bridge this gap by identifying the adoption challenges and limitations of construction robots and the opportunities offered to the construction sector. To achieve this aim, the study adopts a systematic literature review approach using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) protocol. Additionally, the systematic literature review focuses on the framework for categorizing technological advances and potential trends in development over the past decade. The review results reveal that: (a) current robotic technology covered four critical perspectives including perception, mobility, manipulation, and collaboration; (b) promoting the sector requires attention to safety and ethical issues because of the risks associated.},
  archive      = {J_JIRS},
  author       = {Liu, Yuming and A.H., Alias and Haron, Nuzul Azam and N.A., Bakar and Wang, Hao},
  doi          = {10.1007/s10846-024-02104-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-30},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Robotics in the construction sector: Trends, advances, and challenges},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the performance of the model-free adaptive control for a
novel moving-mass controlled flying robot. <em>JIRS</em>,
<em>110</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02107-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the performance of Model-Free Adaptive Control (MFAC) has been investigated on a novel and specific moving-mass controlled (MMC) flying robot system. The novel one-degree-of-freedom (1 DOF) MMC flying robot test bed presented in this paper has highly nonlinear and slow dynamics with a variable center of gravity (CoG) and moment of inertia. This makes the control of this system a challenging problem. One of the solutions to this challenge is the use of data-driven control methods, in particular, MFAC. This controller uses a data-driven model to control the system using only input and output (I/O) data. This paper compares this data-driven controller with proportional-integral-derivative (PID) control, and Linear Quadratic Regulator (LQR) as two model-free and model-based controllers which are widely used controllers in industry. The results of the comparison show that in the various scenarios applied, MFAC has a clear superiority over the PID and LQR, and its adaptive structure gives more freedom of action in the implementation of different scenarios and the presented noise. The results are obtained using the Integral Time Absolute Error (ITAE) criteria and the mean maximum error has also been compared in a Monte Carlo analysis. For a more detailed study, the amount of control energy consumption was also compared, which showed a clear superiority of the MFAC. Also, the robustness of the controller was demonstrated by introducing uncertainty in the plant parameters and by running 100 Monte Carlo simulations with random initial conditions. Finally, despite the PID controller, the MFAC followed the desired scenarios well and compared to LQR consumed less energy. The results demonstrate that the MFAC outperformed the PID and LQR controllers in the presence of random initial conditions and noise in terms of mean maximum error $$(70.4\%)$$ , mean ITAE $$(91\%)$$ , and energy consumption $$(46\%)$$ .},
  archive      = {J_JIRS},
  author       = {Heydari, Mohsen and Darvishpoor, Shahin and Novinzadeh, Alireza Basohbat and Roshanian, Jafar},
  doi          = {10.1007/s10846-024-02107-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {On the performance of the model-free adaptive control for a novel moving-mass controlled flying robot},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A minimalistic 3D self-organized UAV flocking approach for
desert exploration. <em>JIRS</em>, <em>110</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02108-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a minimalistic swarm flocking approach for multirotor unmanned aerial vehicles (UAVs). Our approach allows the swarm to achieve cohesively and aligned flocking (collective motion), in a random direction, without externally provided directional information exchange (alignment control). The method relies on minimalistic sensory requirements as it uses only the relative range and bearing of swarm agents in local proximity obtained through onboard sensors on the UAV. Thus, our method is able to stabilize and control the flock of a general shape above a steep terrain without any explicit communication between swarm members. To implement proximal control in a three-dimensional manner, the Lennard-Jones potential function is used to maintain cohesiveness and avoid collisions between robots. The performance of the proposed approach was tested in real-world conditions by experiments with a team of nine UAVs. Experiments also present the usage of our approach on UAVs that are independent of external positioning systems such as the Global Navigation Satellite System (GNSS). Relying only on a relative visual localization through the ultraviolet direction and ranging (UVDAR) system, previously proposed by our group, the experiments verify that our system can be applied in GNSS-denied environments. The degree achieved of alignment and cohesiveness was evaluated using the metrics of order and steady-state value.},
  archive      = {J_JIRS},
  author       = {Amorim, Thulio and Nascimento, Tiago and Chaudhary, Akash and Ferrante, Eliseo and Saska, Martin},
  doi          = {10.1007/s10846-024-02108-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A minimalistic 3D self-organized UAV flocking approach for desert exploration},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated data processing architecture applied to learning
objects repository for educational robotics: Proposing approach.
<em>JIRS</em>, <em>110</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02109-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational Robotics has emerged as a multidisciplinary field integrating Information and Communication Technologies, Engineering, and Artificial Intelligence areas in education. Furthermore, Educational Robotics offers an innovative approach to teaching and learning by incorporating the construction and programming of robots. However, the small number of platforms for sharing Educational Robotics Learning Objects with a large amount of well-described metadata poses a challenge for efficient search and retrieval of relevant educational content. This study presents an architecture for data processing and ingestion in the RepositORE system, a Learning Objects Repository for Educational Robotics that stores educational content and associated metadata based on the Dublin Core standard. Based on microservices architecture, the proposed system aims to facilitate the location and reuse of learning objects by adapting the RepositORE system to work as a client service. The theoretical framework explores the concepts of learning objects, repositories, and the significance of Educational Robotics in education, and reviews related works. The proposed architecture and system can potentially enhance the accessibility and discoverability of Educational Robotics Learning Objects, fostering effective teaching and learning experiences.},
  archive      = {J_JIRS},
  author       = {Marques de Santana Costa, Ryllari Raianne and Jales de Oliveira, Victor Benoiston and Nunes de Melo, Kefton David and Santos Costa, Cleyton Carlos and Alves Filho, Sebastião Emidio},
  doi          = {10.1007/s10846-024-02109-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Integrated data processing architecture applied to learning objects repository for educational robotics: Proposing approach},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhanced traffic light guidance for safe and
energy-efficient driving: A study on multiple traffic light advisor
(MTLA) and 5G integration. <em>JIRS</em>, <em>110</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s10846-024-02110-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Multiple Traffic Light Advisor (MTLA), a novel Green Light Optimal Speed Advisory (GLOSA) system that leverages 5G communication technology. GLOSA systems are emerging as a key component in intelligent transportation systems, thanks to the development of effective communication technologies. At its core, MTLA serves as a guidance system for drivers, providing real-time instructions to adjust vehicle speed to optimize the utilization of current and future states of traffic lights along their route.The work addresses several limitations in the current state-of-the-art approaches, including the use of an overly simplified velocity profile, the omission of potential grip and jerk in problem formulation, and the absence of a detailed description of the algorithm’s implementation aspects. Initially, we comprehensively present an optimization-free implementation of the overall control architecture based on an unconventional speed profile. Subsequently, MTLA is improved within a non-linear Model Predictive Control (MPC) framework which uses the latter nonoptimal solution as an initial guess and considers potential grip and jerk in the problem formulation. The developed systems are numerically tested and compared within a high-fidelity simulation environment using the IPG CarMaker simulator. The results demonstrate promising performance in terms of energy savings, with a significant reduction of 37% in energy usage, as well as improved overall comfort with respect to the case where no guidance is given to the driver. These findings suggest a high potential for future developments in this domain.},
  archive      = {J_JIRS},
  author       = {Khayyat, Michael and Gabriele, Alberto and Mancini, Francesca and Arrigoni, Stefano and Braghin, Francesco},
  doi          = {10.1007/s10846-024-02110-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Enhanced traffic light guidance for safe and energy-efficient driving: A study on multiple traffic light advisor (MTLA) and 5G integration},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-based vs. Error state kalman filter-based fusion of 5G
and inertial data for MAV indoor pose estimation. <em>JIRS</em>,
<em>110</em>(2), 1–27. (<a
href="https://doi.org/10.1007/s10846-024-02111-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G New Radio Time of Arrival (ToA) data has the potential to revolutionize indoor localization for micro aerial vehicles (MAVs). However, its performance under varying network setups, especially when combined with IMU data for real-time localization, has not been fully explored so far. In this study, we develop an Error State Kalman Filter (ESKF) and a Pose Graph Optimization (PGO) approach to address this gap. We systematically evaluate the performance of the derived approaches for real-time MAV localization in realistic scenarios with 5G base stations in Line-Of-Sight (LOS), demonstrating the potential of 5G technologies in this domain. In order to experimentally test and compare our localization approaches, we augment the EuRoC MAV benchmark dataset for visual-inertial odometry with simulated yet highly realistic 5G ToA measurements. Our experimental results comprehensively assess the impact of varying network setups, including varying base station numbers and network configurations, on ToA-based MAV localization performance. The findings show promising results for seamless and robust localization using 5G ToA measurements, achieving an accuracy of 15 cm throughout the entire trajectory within a graph-based framework with five 5G base stations, and an accuracy of up to 34 cm in the case of ESKF-based localization. Additionally, we measure the run time of both algorithms and show that they are both fast enough for real-time implementation.},
  archive      = {J_JIRS},
  author       = {Kabiri, Meisam and Cimarelli, Claudio and Bavle, Hriday and Sanchez-Lopez, Jose Luis and Voos, Holger},
  doi          = {10.1007/s10846-024-02111-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-27},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Graph-based vs. error state kalman filter-based fusion of 5G and inertial data for MAV indoor pose estimation},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Wireless communication-aware path planning and multiple
robot navigation strategies for assisted inspections. <em>JIRS</em>,
<em>110</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s10846-024-02112-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the many challenges robots encounter in the mining industry, exploring confined environments receives significant attention. This work tackles problems associated with robot communication in hazardous and confined environments, where its cluttered and extensive nature frequently precludes traditional cable-based and wireless solutions. Our methods resort to off-the-shelf long-range radio frequencies to profile the signal propagation behaviour over the geometrical map to assist navigation algorithms that seek to preserve the connection. We consider mathematical models to predict signal power behaviour and serve as input to path planning. We also propose a semi-autonomous leader-follower scheme, with signal repeater units forming a mobile wireless network to enable inspection in hard-to-reach locations. Finally, we present a multi-robot connection-aware system, combining path planning based on radio signal power with multiple robot navigation. Results show the applicability of the proposed solutions, generating single and multi-robot paths for optimal signal reception based on power estimation, thus enabling operations in remote and isolated areas with no line-of-sight between the command base and the robotic inspection device. Experiments conducted in long corridors and in a representative mining environment using the EspeleoRobô and Pioneer platforms demonstrate significant improvements over the traditional communication methods for robotic operation regarding communication quality and inspection range limits.},
  archive      = {J_JIRS},
  author       = {Cid, André and Vangasse, Arthur and Campos, Sofia and Delunardo, Mário and Cruz Júnior, Gilmar and Neto, Nilton and Pimenta, Luciano and Domingues, Jacó and Barros, Luiz and Azpúrua, Hector and Pessin, Gustavo and Freitas, Gustavo},
  doi          = {10.1007/s10846-024-02112-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Wireless communication-aware path planning and multiple robot navigation strategies for assisted inspections},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online bilateral predictive control for time-delayed
teleoperation of snake-like robots. <em>JIRS</em>, <em>110</em>(2),
1–16. (<a href="https://doi.org/10.1007/s10846-024-02113-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the teleoperation of snake-like robots is challenging due to complex nonlinear dynamics and communication delays. This research proposes an online bilateral predictive control architecture to address these issues. This control structure is established by predicting environment force and the user’s future motion. The former uses a model-mediated approach by creating a virtual environment on the master side and the latter adopts an artificial neural network (ANN) for online operator’s motion prediction. The slave controller utilizes transmitted data from ANN to generate required backbone lengths, which are then transformed into the slave&#39;s local bending and torsional degrees of freedom through the inverse kinematics of the robot. Motion prediction is examined in two scenarios: when the ANN predicts the trained motions, and when it predicts a different motion. Simulation studies demonstrate that the proposed online bilateral predictive teleoperation structure successfully achieves real-time position synchronization and force feedback, by effectively bypassing communication delays.},
  archive      = {J_JIRS},
  author       = {Ebrahimian, Mahdi and Pourmokhtari, Mina and Ghiyasi, Morteza and Yazdankhoo, Behnam and Beigzadeh, Borhan},
  doi          = {10.1007/s10846-024-02113-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Online bilateral predictive control for time-delayed teleoperation of snake-like robots},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OffRoadSynth open dataset for semantic segmentation using
synthetic-data-based weight initialization for autonomous UGV in
off-road environments. <em>JIRS</em>, <em>110</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02114-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article concerns the issue of image semantic segmentation for the machine vision system of an autonomous Unmanned Ground Vehicle (UGV) moving in an off-road environment. Determining the meaning (semantics) of the areas visible in the recorded image provides a complete understanding of the scene surrounding the autonomous vehicle. It is crucial for the correct determination of a passable route. Nowadays, semantic segmentation is generally solved using convolutional neural networks (CNN), which can take an image as input and output the segmented image. However, proper training of the neural network requires the use of large amounts of data, which becomes problematic in the situation of low availability of large, dedicated image data sets that consider various off-road situations - driving on various types of roads, surrounded by diverse vegetation and in various weather and light conditions. This study introduces a synthetic image dataset called “OffRoadSynth” to address the training data scarcity for off-road scenarios. It has been shown that pre-training the neural network on this synthetic dataset improves image segmentation accuracy compared to other methods, such as random network weight initialization or using larger, generic datasets. Results suggest that using a smaller but domain-dedicated set of synthetic images to initialize network weights for training on the target real-world dataset may be an effective approach to improving semantic segmentation results of images, including those from off-road environments.},
  archive      = {J_JIRS},
  author       = {Małek, Konrad and Dybała, Jacek and Kordecki, Andrzej and Hondra, Piotr and Kijania, Katarzyna},
  doi          = {10.1007/s10846-024-02114-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {OffRoadSynth open dataset for semantic segmentation using synthetic-data-based weight initialization for autonomous UGV in off-road environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards reliable identification and tracking of drones
within a swarm. <em>JIRS</em>, <em>110</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s10846-024-02115-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone swarms consist of multiple drones that can achieve tasks that individual drones can not, such as search and recovery or surveillance over a large area. A swarm’s internal structure typically consists of multiple drones operating autonomously. Reliable detection and tracking of swarms and individual drones allow a greater understanding of the behaviour and movement of a swarm. Increased understanding of drone behaviour allows better coordination, collision avoidance, and performance monitoring of individual drones in the swarm. The research presented in this paper proposes a deep learning-based approach for reliable detection and tracking of individual drones within a swarm using stereo-vision cameras in real time. The motivation behind this research is in the need to gain a deeper understanding of swarm dynamics, enabling improved coordination, collision avoidance, and performance monitoring of individual drones within a swarm. The proposed solution provides a precise tracking system and considers the highly dense and dynamic behaviour of drones. The approach is evaluated in both sparse and dense networks in a variety of configurations. The accuracy and efficiency of the proposed solution have been analysed by implementing a series of comparative experiments that demonstrate reasonable accuracy in detecting and tracking drones within a swarm.},
  archive      = {J_JIRS},
  author       = {Kumari, Nisha and Lee, Kevin and Barca, Jan Carlo and Ranaweera, Chathurika},
  doi          = {10.1007/s10846-024-02115-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-31},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Towards reliable identification and tracking of drones within a swarm},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Humanoid robot motion planning approaches: A survey.
<em>JIRS</em>, <em>110</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s10846-024-02117-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanoid robots are complex, dynamic systems. Any humanoid robotic application starts with determining a sequence of optimal paths to perform a given task in a known or unknown environment. This paper critically reviews and rates available literature on the three key areas of multi-level motion and task planning for humanoid robots. First is efficiency while navigating and manipulating objects in environments designed for humans. Here, the research has broadly been summarized as behavior cloning approaches. Second is robustness to perturbations and collisions caused by operation in dynamic and unpredictable environments. Here, the modeling approaches integrated into motion planning algorithms have been the focus of many researchers studying humanoid motion’s balance and dynamic stability aspects. Last is real-time performance, wherein the robot must adjust its motion based on the most recent sensory data to achieve the required degree of interaction and responsiveness. Here, the focus has been on the kinematic constraints imposed by the robot’s mechanical structure and joint movements. The iterative nature of solving constrained optimization problems, the computational complexity of forward and inverse kinematics, and the requirement to adjust to a rapidly changing environment all pose challenges to real-time performance. The study has identified current trends and, more importantly, research gaps while pointing to areas needing further investigation.},
  archive      = {J_JIRS},
  author       = {de Lima, Carolina Rutili and Khan, Said G. and Tufail, Muhammad and Shah, Syed H. and Maximo, Marcos R. O. A.},
  doi          = {10.1007/s10846-024-02117-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Humanoid robot motion planning approaches: A survey},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MMFG: Multimodal-based mutual feature gating 3D object
detection. <em>JIRS</em>, <em>110</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02119-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problem that image and point cloud features are fused in a coarse fusion way and cannot achieve deep fusion, this paper proposes a multimodal 3D object detection architecture based on a mutual feature gating mechanism. First, since the feature aggregation approach based on the set abstraction layer cannot obtain fine-grained features, a point-based self-attention mechanism module is designed. This module is added to the extraction branch of point cloud features to achieve fine-grained feature aggregation while maintaining accurate location information. Second, a new gating mechanism is designed for the deep fusion of image and point cloud. Deep fusion is achieved by mutual feature weighting between the image and the point cloud. The newly fused features are then fed into a feature refinement network to extract classification confidence and 3D target bounding boxes. Finally, a multi-scale detection architecture is proposed to obtain a more complete object shape. The location-based encoding feature algorithm is also designed to focus the interest points in the region of interest adaptively. The whole architecture shows outstanding performance on the KITTI3D and nuSenece datasets, especially at the difficult level. It shows that the framework solves the problem of low detection rates in LiDAR mode due to the low number of surface points obtained from distant objects.},
  archive      = {J_JIRS},
  author       = {Xu, Wanpeng and Fu, Zhipeng},
  doi          = {10.1007/s10846-024-02119-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {MMFG: Multimodal-based mutual feature gating 3D object detection},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024c). JIRS editorial, second quarter 2024. <em>JIRS</em>,
<em>110</em>(2), 1. (<a
href="https://doi.org/10.1007/s10846-024-02120-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIRS},
  author       = {Valavanis, Kimon P.},
  doi          = {10.1007/s10846-024-02120-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {JIRS editorial, second quarter 2024},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic modelling and optimal sliding mode control of the
wearable rehabilitative bipedal cable robot with 7 degrees of freedom.
<em>JIRS</em>, <em>110</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02122-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although robot-assisted physiotherapy has gained increasing attention in recent years, the use of wearable rehabilitation robots for lower limbs has shown reduced efficiency due to additional equipment and motors located at the center of the joint, increasing complexity and load on disabled patients. This paper proposes a novel rehabilitation approach by eliminating motors and equipment from the center of joints and placing them on a fixed platform using cable-based power transmission. A proposed model of a 14 cable-driven bipedal robot with 7 degrees of freedom has been used to model a lower limb rehabilitation robot corresponding to it. The dynamic equations of the robot are derived using the Euler-Lagrange method. The sliding mode control technique is utilized to offer accurate control for tracking desired trajectories, ensuring smoothness despite disturbances, and reducing tracking errors. This approach is employed to help prevent patients from falling and support them in maintaining balance during rehabilitative exercises. To ensure that cables exert positive tension, the sliding mode controller was combined with quadratic programming optimization, minimizing path error while constraining the controller input torque to be non-negative. The performance of the proposed controller was assessed by considering several control gains resulting in K = 10 identified as the most effective one. The feasibility of this approach to rehabilitation is demonstrated by the numerical results in MATLAB simulation, which show that the RMSE amount of the right and left hip and thigh angles are 0.29, 0.37, 0.31, and 0.44, respectively which verified an improved rehabilitation process. Also, the correlation coefficient between the Adams and MATLAB simulation results for motor torque was found to be 0.98, indicating a high degree of correlation between the two simulation results.},
  archive      = {J_JIRS},
  author       = {Sajedifar, A. and Korayem, M. H. and Allahverdi, F.},
  doi          = {10.1007/s10846-024-02122-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Dynamic modelling and optimal sliding mode control of the wearable rehabilitative bipedal cable robot with 7 degrees of freedom},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Context adaptive fault tolerant multi-sensor fusion: Towards
a fail-safe multi operational objective vehicle localization.
<em>JIRS</em>, <em>110</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10846-023-01906-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many transport applications, one of the safety critical function is the localization. This is all the more true for land transport applications such as autonomous vehicles. While the democratization of satellite positioning systems, such as GPS, Galileo, Beidou or Glonass, has made it possible to consider a global solution applicable anywhere in the world, the principle of positioning by receiving signals from satellites more than twenty thousand kilometers away shows limits when they are confronted with disturbances related to the environment close to the receiver. However, for these safety-critical applications, the requirements are strong and sometimes even conflicting. The developed function must meet a defined level of precision, availability, continuity of service, integrity, operational safety and finally robustness to environment changes. Taken separately, these requirements can be achieved by actions recommended by the literature. For more precision and availability, coupling between absolute GNSS data and relative INS and odometer data, is recommended. To increase safety and integrity, a fault detection layer is essential, but this will negatively impact availability. One therefore needs a fault management layer. A harmonious policy, thought at the function design, makes it possible to achieve all the objectives. In this study, we propose a framework based on a tripartite approach: the tight fusion of GNSS and IMU data, the development of a diagnostic layer based on information theory and using the very promising alpha Rényi divergence, as well as a fault isolation layer. The diagnostic layer is designed to be robust and adaptive to changing environment through a deep neural network. The proposed framework is tested on data acquired in the field. Encouraging results allow to consider the generalization of the concept.},
  archive      = {J_JIRS},
  author       = {Harbaoui, Nesrine and Makkawi, Khoder and Ait-Tmazirte, Nourdine and El Najjar, Maan El Badaoui},
  doi          = {10.1007/s10846-023-01906-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Context adaptive fault tolerant multi-sensor fusion: Towards a fail-safe multi operational objective vehicle localization},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A switched control strategy for avoiding flip ambiguities in
3D formations. <em>JIRS</em>, <em>110</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10846-023-01967-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flip ambiguities are a notorious issue with distance-based formation control due to the presence of unwanted equilibrium points in the formation dynamics. We propose a switched control system for preventing these ambiguities in 3D formations composed of tetrahedra. The approach contains a switching strategy that steers the formation of mobile robots towards the desired configuration for all initial positions, excluding certain collocated, collinear, or coplanar cases, by applying the standard distance-based controller and/or rigid-body maneuvers to subformations. Simulations demonstrate that the proposed formation control system can lead to faster formation acquisition and less control effort than an existing method.},
  archive      = {J_JIRS},
  author       = {Sahebsara , Farid and Queiroz, Marcio de},
  doi          = {10.1007/s10846-023-01967-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A switched control strategy for avoiding flip ambiguities in 3D formations},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Position and attitude tracking controllers using lyapunov
transformations for quadrotors. <em>JIRS</em>, <em>110</em>(1), 1–17.
(<a href="https://doi.org/10.1007/s10846-023-02016-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel feedback control strategy for quadrotor trajectory tracking is designed and experimentally tested with proof of exponential stability, using the Lyapunov transformations theory. The controller is derived from an inner-outer loop control structure, namely by considering the position system coupled through an interconnection term with the attitude system. For the design of the position controller, the considered dynamics are worked on the body frame, which is uncommon in the literature, and its synthesis derives from theories such as Pontryagin’s maximum principle, Lyapunov theory, and Linear Quadratic Regulator (LQR), which ensure Input-to-state stability, steady-state optimality, and global exponential stability. The attitude system is based on an error quaternion parameterization via a nonlinear coordinate transformation matrix followed by a state input feedback, rendering the system linear and time-invariant. Under a correct transformation, LQR theory ensures almost exponential stability and steady-state optimality for the overall interconnected closed-loop systems. Experimental and simulation results illustrate the performance of the tracking system onboard a quadrotor.},
  archive      = {J_JIRS},
  author       = {Madeiras, João and Cardeira, Carlos and Oliveira, Paulo},
  doi          = {10.1007/s10846-023-02016-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Position and attitude tracking controllers using lyapunov transformations for quadrotors},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Visual detection algorithm for enhanced environmental
perception of unmanned surface vehicles in complex marine environments.
<em>JIRS</em>, <em>110</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10846-023-02020-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned surface vehicles (USVs) are distinguished by their intelligence, compactness, and absence of human casualties, making them a vital component of the maritime industry. The implementation of vision-based algorithms for sea surface target detection can enhance the autonomous perceptual abilities of USVs. In the present study, a sea surface target detection algorithm was proposed that fulfils the requirements of USVs marine environment sensing and sea area monitoring. Sea surface target detection faces unique challenges, such as highly variable target sizes and a complex and changing marine environments. The current state-of-the-art You Only Look Once (YOLO) model was selected as the baseline target detection model. Firstly, to improve the network’s ability to extract features of different sizes, a Cross Stage Partial Lightweight Spatial Pyramid Pooling-Fast (CSPLSPPF) structure was proposed. Additionally, for achieving the advantages of multiple feature maps to complement each other and output more judgmental feature maps, Path Aggregation Network Powerful (PANP) was proposed to more rationally fuse features of feature maps with different resolutions. Finally, lightweight convolution with fused attention(LCFA) was proposed to enable the network to selectively focus on crucial spatial and channel information while simultaneously reducing the model’s parameter count. Experiments were conducted on a self-made Ocean Buoys dataset and the open-source Seaships dataset. The results showed that the proposed method could efficiently and accurately detect objects such as ships and buoys in marine environments, which was of significant value for USVs to achieve intelligent environment perception.},
  archive      = {J_JIRS},
  author       = {Dong, Kaiyuan and Liu, Tao and Zheng, Yan and Shi, Zhen and Du, Hongwang and Wang, Xianfeng},
  doi          = {10.1007/s10846-023-02020-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-24},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Visual detection algorithm for enhanced environmental perception of unmanned surface vehicles in complex marine environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Configuration and force-field aware variable impedance
control with faster re-learning. <em>JIRS</em>, <em>110</em>(1), 1–16.
(<a href="https://doi.org/10.1007/s10846-023-02022-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable impedance control (VIC) is rapidly becoming an important ingredient for robotic manipulation in unstructured and uncertain environments. In such situations, it is often necessary to rapidly adapt to different impedance levels as per the task requirements, and to return to a low baseline impedance for safety requirements. Such a capability is crucial to stabilize interactions in divergent force fields, which commonly arise in a variety of contact and force production tasks and occasionally in non-contact tasks. Conventional methods, such as iterative learning control, often underperform in terms of stabilization and efficacy. While VIC algorithms perform better, typical challenges in such methods include unnecessarily high impedance adaptation in divergent fields, difficulty in distinguishing between error-independent and error-based divergent forces, and reliance on the Jacobian inverse which diminishes performance near singularities. In this paper, we introduce an innovative VIC algorithm that addresses typical VIC challenges. The proposed method employs a Cartesian-space field adaptation avoiding the need for inverting the Jacobian during adaptation, while at the same time providing a theoretical stabilization guarantee. Utilizing the Lyapunov function, the algorithm is shown to drive tracking errors to zero, even in the presence of divergent position and velocity-error fields and error-independent forces. Notably, the system exhibits human-like relearning at a faster pace when exposed to previously learned fields or perturbations, improving learning speeds by up to 47.97%. Performance validation was conducted through simulations on a two-link serial chain manipulator that mimics the human arm, as well as tests on a seven degrees-of-freedom KUKA robot, underscoring the algorithm’s advantages in handling VIC challenges and uncertain conditions.},
  archive      = {J_JIRS},
  author       = {Jadav, Shail and Palanthandalam-Madapusi, Harish J.},
  doi          = {10.1007/s10846-023-02022-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Configuration and force-field aware variable impedance control with faster re-learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Monocular visual navigation algorithm for nursing robots via
deep learning oriented to dynamic object goal. <em>JIRS</em>,
<em>110</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10846-023-02024-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robot navigation systems suffer from relatively localizing the robots and object goals in the three-dimensional(3D) dynamic environment. Especially, most object detection algorithms adopt in navigation suffer from large resource consumption and a low calculation rate. Hence, this paper proposes a lightweight PyTorch-based monocular vision 3D aware object goal navigation system for nursing robot, which relies on a novel pose-adaptive algorithm for inverse perspective mapping (IPM) to recover 3D information of an indoor scene from a monocular image. First, it detects objects and combines their location with the bird-eye view (BEV) information from the improved IPM to estimate the objects’ orientation, distance, and dynamic collision risk. Additionally, the 3D aware object goal navigation network utilizes an improved spatial pyramid pooling strategy, which introduces an average-pooling branch and a max-pooling branch, better integrating local and global features and thus improving detection accuracy. Finally, a novel pose-adaptive algorithm for IPM is proposed, which introduces a novel voting mechanism to adaptively compensate for the monocular camera’s pose variations to enhance further the depth information accuracy, called the adaptive IPM algorithm. Several experiments demonstrate that the proposed navigation algorithm has a lower memory consumption, is computationally efficient, and improves ranging accuracy, thus meeting the requirements for autonomous collision-free navigation.},
  archive      = {J_JIRS},
  author       = {Fu, Guoqiang and Wang, Yina and Yang, Junyou and Wang, Shuoyu and Yang, Guang},
  doi          = {10.1007/s10846-023-02024-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Monocular visual navigation algorithm for nursing robots via deep learning oriented to dynamic object goal},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MonoSAID: Monocular 3D object detection based on scene-level
adaptive instance depth estimation. <em>JIRS</em>, <em>110</em>(1),
1–17. (<a href="https://doi.org/10.1007/s10846-023-02027-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocular 3D object detection (Mono3OD) is a challenging yet cost-effective vision task in the fields of autonomous driving and mobile robotics. The lack of reliable depth information makes obtaining accurate 3D positional information extremely difficult. In recent years, center-guided monocular 3D object detectors have directly regressed the absolute depth of the object center based on 2D detection. However, this approach heavily relies on local semantic information, ignoring contextual spatial cues and global-to-local visual correlations. Moreover, visual variations in the scene can lead to inevitable depth prediction errors for objects at different scales. To address these limitations, we propose a Mono3OD framework based on scene-level adaptive instance depth estimation (MonoSAID). Firstly, the continuous depth is discretized into multiple bins, and the width distribution of depth bins is adaptively generated based on scene-level contextual semantic information. Then, by establishing the correlation between global contextual semantic feature information and local semantic features of instances, and using the probability distribution representation of local instance features and the linear combination of bin centers distributions to solve the depth problem. In addition, a multi-scale spatial perception attention module is designed to extract attention maps of various scales through pyramid pooling operations. This design enhances the model’s receptive field and multi-scale spatial perception capabilities, thereby improving its ability to model target objects. We conducted extensive experiments on the KITTI dataset and the Waymo dataset. The results show that MonoSAID can effectively improve the 3D detection accuracy and robustness, and our method achieves state-of-the-art performance.},
  archive      = {J_JIRS},
  author       = {Xia, Chenxing and Zhao, Wenjun and Han, Huidan and Tao, Zhanpeng and Ge, Bin and Gao, Xiuju and Li, Kuan-Ching and Zhang, Yan},
  doi          = {10.1007/s10846-023-02027-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {MonoSAID: Monocular 3D object detection based on scene-level adaptive instance depth estimation},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cooperative grasp detection using convolutional neural
network. <em>JIRS</em>, <em>110</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10846-023-02028-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a complete robotic system to enable the robot to fulfill object-independent cooperative grasp tasks. The human subject initiates a task by either holding the object in hand or placing the object on the table. The human intention is inferred through body motions, after which the robot selects the corresponding grasp strategy. A novel real-time grasp detection model is proposed to choose the best picking locations according to the object’s shape. This module enables the robot to grasp any object placed on the table. Moreover, if handover grasp task is triggered, the hand pixels are detected and filtered out from candidate grasp poses for safety purpose. The proposed grasp detection model is evaluated on two public grasping datasets and a set of casual objects. The best model variant can achieve accuracy of 97.8% and 96.6% on image-wise splitting and object-wise splitting tests on Cornell Grasp Dataset respectively. The Jacquard Dataset accuracy is 93.9%. The overall system is also evaluated on real cooperative grasp tasks. The experimental results show effectiveness of the proposed robot grasp detection and implementation system.},
  archive      = {J_JIRS},
  author       = {Gu, Ye and Wei, Dujia and Du, Yawei and Cao, Jianmin},
  doi          = {10.1007/s10846-023-02028-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Cooperative grasp detection using convolutional neural network},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel method for selecting inverse kinematic solutions
based on configuration space partition for 6R noncuspidal manipulators.
<em>JIRS</em>, <em>110</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s10846-023-02029-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of an optimal solution from multiple inverse kinematics solutions (IKSs) is a fundamental task in manipulator motion. However, the conventional minimum joint motion criterion (MJM) method suffers from drawbacks such as high computational time and the inability to ensure configuration invariance. With the prevalence of noncuspidal structures in commercial manipulators, a novel IKS selection methodology is exigent. This paper analyzes the limitations of the MJM method by geometric representations of the IKS formal and proposes a novel IKS selection method based on configuration space decomposition. The configuration space of noncuspidal manipulators is partitioned into independent subdomains called uniqueness domains (UD). Subsequently, a bijection between configuration, UD, and IKS is established for selecting IKS, and three important related theorems are proven. The proposed method offers low computational cost, and allows configuration invariance in continuous trajectory tracking or point-to-point planning. Finally, the physical experiment results demonstrate the effectiveness of the proposed method.},
  archive      = {J_JIRS},
  author       = {Zhang, Xiaofeng and Li, Gongfa and Xu, Manman and Jiang, Du and Yun, Juntong},
  doi          = {10.1007/s10846-023-02029-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A novel method for selecting inverse kinematic solutions based on configuration space partition for 6R noncuspidal manipulators},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning with inverse jacobian based
model-free path planning for deburring in complex industrial
environment. <em>JIRS</em>, <em>110</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10846-023-02030-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present an innovative approach to robotic deburring path planning by combining deep reinforcement learning (DRL) with an inverse Jacobian strategy. Existing model-based path planning methods, including sampling-based approaches, often suffer from computational complexity and challenges in capturing the dynamics of deburring systems. To overcome these limitations, our novel DRL-based framework for path planning leverages experiential learning to identify optimal deburring trajectories without relying on predefined models. This model-free approach is particularly suited for complex deburring scenarios with unknown system dynamics. Additionally, we employ an inverse Jacobian technique with a time-varying gain module (η(t) = e^2t) during training, which yields remarkable benefits in terms of exploration–exploitation balance and collision avoidance, enhancing the overall performance of the DRL agent. Through a series of experiments conducted in a simulated environment, we evaluate the efficacy of our proposed algorithm for deburring path planning. Our modified DRL-based approach, utilizing inverse kinematics with a time-varying gain module, demonstrates superior performance in terms of convergence speed, optimality, and robustness when compared to conventional path planning methods. Notably, in comparison to algorithms like sampling-based strategies, our model-free DRL-based approach outperforms these methods, achieving an exceptional average success rate of 97%. The integration of the inverse Jacobian technique further enhances the effectiveness of our algorithm by effectively reducing the state space dimensionality, leading to improved learning efficiency and the generation of optimal deburring trajectories.},
  archive      = {J_JIRS},
  author       = {Rahul, M. R. and Chiddarwar, Shital S.},
  doi          = {10.1007/s10846-023-02030-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Deep reinforcement learning with inverse jacobian based model-free path planning for deburring in complex industrial environment},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multimodal interaction strategies for walker-assisted gait:
A case study for rehabilitation in post-stroke patients. <em>JIRS</em>,
<em>110</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-023-02031-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke has been considered the main cause of neuromuscular damages worldwide and one of the most common causes of walking disabilities, with approximately 60% of the individuals suffering from persistent problems in walking. These patients generally use technical aids for walking to achieve independent gait, however, when cognitive impairments are also present, conventional assistive devices such as walkers could be difficult to handle. By leveraging multimodal interfaces, smart walkers can offer natural and intuitive human-robot interaction. In this work, we present two multimodal interaction strategies for smart walkers focusing on guiding post-stroke patients through their environment. These strategies leverage different communication channels and provide distinct levels of guidance: one strategy uses haptic feedback and a visual interface to indicate the desired path to the user, while the other strategy uses haptic feedback and a virtual torque to maintain the user on path. We also present two case studies with post-stroke patients to preliminarily validate these interaction strategies with their target population and to collect valuable insight as to how multimodal strategies for smart walkers can be enhanced to deal with the characteristic asymmetries of post-stroke patients. Our results show that both strategies can guide the volunteers, however, the first one demands more effort from the volunteer and is more suited for patients with increased levels of independence. The second interaction strategy allows for higher linear velocity (Volunteer 1, $$\varvec{0.18}$$ $$\varvec{\pm 0.026}$$ $$\varvec{m/s}$$ ; Volunteer 2, $$\varvec{0.22}$$ $$\varvec{\pm 0.0283}$$ $$\varvec{m/s}$$ ) than the first one (Volunteer 1, $$\varvec{0.10}$$ $$\varvec{\pm 0.031}$$ $$\varvec{m/s}$$ ; Volunteer 2, $$\varvec{0.20}$$ $$\varvec{\pm 0.012}$$ $$\varvec{m/s}$$ ), suggesting improved guidance.},
  archive      = {J_JIRS},
  author       = {Jimenez, Mario F. and Mello, Ricardo C. and Loterio, Flavia and Frizera-Neto, Anselmo},
  doi          = {10.1007/s10846-023-02031-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Multimodal interaction strategies for walker-assisted gait: A case study for rehabilitation in post-stroke patients},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). GRVINS: Tightly coupled GNSS-range-visual-inertial system.
<em>JIRS</em>, <em>110</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-023-02033-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bridge inspection is currently a labor intensive task. Utilizing unmanned aerial vehicles (UAVs) to assist in inspection tasks is a promising direction. However, enabling UAVs for autonomous inspection involves the UAV state estimation problems. Since parts of UAV sensors could be unavailable, how to estimate states via sensor fusion is the key. In this paper, we propose a tightly-coupled nonlinear optimization-based system that integrates four kinds of sensors: camera, IMU, Ultra-wideband (UWB) range measurements, and global navigation satellite system (GNSS). Due to the tightly-coupled multi-sensor fusion method and system design, the system takes the advantage of the four sensors, and can seamlessly respond to indoor and outdoor GNSS and UWB loss or reacquisition. It can effectively reduce the long-term trajectory drift and provide smooth and continuous state estimation. The experimental results show that the proposed method outperforms the state-of-the-art approaches.},
  archive      = {J_JIRS},
  author       = {Lu, Bing-Xian and Tsai, Yu-Chung and Tseng, Kuo-Shih},
  doi          = {10.1007/s10846-023-02033-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {GRVINS: Tightly coupled GNSS-range-visual-inertial system},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A geometric approach to task-specific cartesian stiffness
shaping. <em>JIRS</em>, <em>110</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s10846-023-02035-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the exact Cartesian stiffness values of a robot end-effector (EE) is troublesome because of difficulties associated with estimating the stiffness and controllability of a full Cartesian stiffness matrix. However, most practical applications require only quantitative (high/low) stiffness values in the EE motion direction (or perpendicular direction). Full control of the stiffness matrix requiring too many control inputs which is hardly possible in practical applications. To ensure the efficiency of execution for a range of redundant robots, we present an algorithm for shaping a robot’s Cartesian stiffness ellipsoid, a more intuitive and visual stiffness representation, using a nonlinear sequential least square programming optimization. The algorithm is designed to optimize the joint stiffness values and the trajectory of the robot’s joints, using null-space exploration, for a given task. Using eigenvalue decomposition of the stiffness matrix, the algorithm minimizes the orientation difference between the major axis of the current and the desired stiffness ellipsoid and specify a scaling factor between the major and the minor axis. The presented approach allows the user to better understand and control of a robot, regardless of the user’s knowledge of the achievable stiffness range and the interdependencies of the Cartesian stiffness matrix elements.},
  archive      = {J_JIRS},
  author       = {Knežević, Nikola and Lukić, Branko and Petrič, Tadej and Jovanovič, Kosta},
  doi          = {10.1007/s10846-023-02035-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-11},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A geometric approach to task-specific cartesian stiffness shaping},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards automatic code generation for robotic soccer
behavior simulation. <em>JIRS</em>, <em>110</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10846-023-02036-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Systems (MAS) are an Artificial Intelligence (AI) branch where agents handle distributed nature tasks in a cooperative system. MAS is widely used in robotic systems in scenarios where multiple robots must cooperate. In this direction, the robot soccer domain has been used as a test bed to stimulate research in this area, as it reproduces some important features of these systems, such as coordination. Each soccer team member is an agent whose behavior must be coordinated with the other team members cooperating to win the game. Simulation tools are frequently used in this context to create rehearsed plays, called setplays, during team training. However, these tools generally have a limited set of behaviors, e.g., kicking, available to use in setplays, and new behaviors must be manually implemented. This implementation requires knowledge of specific source codes and a significant programming effort, in addition to leaving the behavior coupled and dependent on the tool. This work proposes the Robot Soccer Behavior Generator (RoboSocBG), a solution to develop new behaviors in the context of simulated soccer robots. It uses Model-Driven Development (MDD), an approach that enables the specification of behavior platform-independent models and code generation in specific tools. The solution was tested in our laboratory and validated in a case study. The results evidenced its feasibility to generate code in different platforms.},
  archive      = {J_JIRS},
  author       = {Sales, Raoni and Fontes Magalhães Mascarenhas, Ana Patrícia and Simões, Marco A. C. and Rodrigues de Souza, Josemar},
  doi          = {10.1007/s10846-023-02036-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Towards automatic code generation for robotic soccer behavior simulation},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fusion of time-of-flight based sensors with monocular
cameras for a robotic person follower. <em>JIRS</em>, <em>110</em>(1),
1–14. (<a href="https://doi.org/10.1007/s10846-023-02037-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot collaboration (HRC) is becoming increasingly important in advanced production systems, such as those used in industries and agriculture. This type of collaboration can contribute to productivity increase by reducing physical strain on humans, which can lead to reduced injuries and improved morale. One crucial aspect of HRC is the ability of the robot to follow a specific human operator safely. To address this challenge, a novel methodology is proposed that employs monocular vision and ultra-wideband (UWB) transceivers to determine the relative position of a human target with respect to the robot. UWB transceivers are capable of tracking humans with UWB transceivers but exhibit a significant angular error. To reduce this error, monocular cameras with Deep Learning object detection are used to detect humans. The reduction in angular error is achieved through sensor fusion, combining the outputs of both sensors using a histogram-based filter. This filter projects and intersects the measurements from both sources onto a 2D grid. By combining UWB and monocular vision, a remarkable 66.67% reduction in angular error compared to UWB localization alone is achieved. This approach demonstrates an average processing time of 0.0183s and an average localization error of 0.14 meters when tracking a person walking at an average speed of 0.21 m/s. This novel algorithm holds promise for enabling efficient and safe human-robot collaboration, providing a valuable contribution to the field of robotics.},
  archive      = {J_JIRS},
  author       = {Sarmento, José and Neves dos Santos, Filipe and Silva Aguiar, André and Filipe, Vítor and Valente, António},
  doi          = {10.1007/s10846-023-02037-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Fusion of time-of-flight based sensors with monocular cameras for a robotic person follower},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel positioning accuracy improvement method for
polishing robot based on levenberg–marquardt and opposition-based
learning squirrel search algorithm. <em>JIRS</em>, <em>110</em>(1),
1–18. (<a href="https://doi.org/10.1007/s10846-023-02038-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving high-precision manufacturing of optical components requires improving the absolute positioning accuracy of the robot to the highest possible level. Identifying the robot&#39;s kinematic parameters and compensating for kinematic errors are effective methods for improving the robot&#39;s positioning accuracy. This paper proposes a hybrid algorithm that combines the Levenberg–Marquardt algorithm and an opposition-based learning squirrel search algorithm to identify the kinematic parameters of a polishing robot. Firstly, the Levenberg–Marquardt algorithm is utilized to solve the suboptimal values of kinematic parameter deviations. Secondly, an opposition-based learning strategy is integrated into the standard squirrel search algorithm to increase the diversity of the population and prevent the population from getting stuck in local optima. The suboptimal values obtained by the Levenberg–Marquardt algorithm are subsequently used as the central values to generate the initial population for the opposition-based learning squirrel search algorithm, which helps identify more accurate kinematic parameter deviations. Ultimately, the kinematic parameters of the robot are effectively calibration. The calibration experimental results showed that the proposed method achieved a high level of calibration accuracy, resulting in a 62.61% improvement in absolute positioning error compared to before calibration. Offline machining experiments have validated the effectiveness of LM-OBLSSA in reducing deviations in the dwell points of optical components during the machining process.},
  archive      = {J_JIRS},
  author       = {Deng, Yonghong and Hou, Xi and Li, Bincheng and Wang, Jia and Zhang, Yun},
  doi          = {10.1007/s10846-023-02038-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A novel positioning accuracy improvement method for polishing robot based on Levenberg–Marquardt and opposition-based learning squirrel search algorithm},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robotics meets AI and vision in south america (topical
collection). <em>JIRS</em>, <em>110</em>(1), 1–5. (<a
href="https://doi.org/10.1007/s10846-023-02039-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of robotics research with Artificial Intelligence (AI) and Computer Vision (CV) has enabled the solution of practical tasks previously challenging with traditional techniques. This interdisciplinary approach focuses on developing intelligent computational systems for decision-making, planning, and object recognition, minimizing human intervention in various domains like e-commerce, healthcare, industry, and more. South American researchers contribute significantly, with emphasis on emerging AI technologies such as Deep Learning, statistical methods, and computer vision applied to robotics. The works within this collection highlight the increasing prominence of robotics in education, with it becoming a part of basic education, and discuss a topical collection showcasing research presented at Latin American robotics events in 2021. The papers cover diverse topics, including altitude control for hybrid aerial-underwater vehicles, robust localization in challenging environments, cross-domain localization for underwater robots, image-based navigation for agricultural rovers, continuous training of educators in Educational Robotics, and the role of robotic simulators in education. The collection aims to disseminate cutting-edge robotics research and foster collaboration in the field.},
  archive      = {J_JIRS},
  author       = {Silva, Bruno M. F. and Todt, Eduardo and Nascimento, Tiago P. and Curvelo, Carla da C. F. and Gonçalves, Luiz M. G.},
  doi          = {10.1007/s10846-023-02039-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-5},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Robotics meets AI and vision in south america (Topical collection)},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Correction to the euler lagrange multirotor model with euler
angles generalized coordinates. <em>JIRS</em>, <em>110</em>(1), 1–9. (<a
href="https://doi.org/10.1007/s10846-023-02040-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This technical note proves analytically how the exact equivalence of the Newton-Euler and Euler-Lagrange modeling formulations as applied to multirotor UAVs is achieved. This is done by deriving a correct Euler-Lagrange multirotor attitude dynamics model. A review of the published literature reveals that the commonly adopted Euler-Lagrange multirotor dynamics model is equivalent to the Newton-Euler model only when it comes to the position dynamics, but not in the attitude dynamics. Step-by-step derivations and calculations are provided to show how modeling equivalence to the Newton-Euler formulation is proven. The modeling equivalence is then verified by obtaining identical results in numerical simulation studies. Simulation results also illustrate that when using the correct model for feedback linearization, controller stability at high gains is improved.},
  archive      = {J_JIRS},
  author       = {Martini, Simone and Valavanis, Kimon P. and Stefanovic, Margareta and Rutherford, Matthew J. and Rizzo, Alessandro},
  doi          = {10.1007/s10846-023-02040-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-9},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Correction to the euler lagrange multirotor model with euler angles generalized coordinates},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards autonomous firefighting UAVs: Online planners for
obstacle avoidance and payload delivery. <em>JIRS</em>, <em>110</em>(1),
1–14. (<a href="https://doi.org/10.1007/s10846-023-02042-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone technology is advancing rapidly and represents significant benefits during firefighting operations. This paper presents a novel approach for autonomous firefighting missions for Unmanned Aerial Vehicles (UAVs). The proposed UAV framework consists of a local planner module that finds an obstacle-free path to guide the vehicle toward a target zone. After detecting the target point, the UAV plans an optimal trajectory to perform a precision ballistic launch of an extinguishing ball, exploiting its kinematics. The generated trajectory minimises the overall traversal time and the final state error while respecting UAV dynamic limits. The performance of the proposed system is evaluated both in simulations and real tests with randomly positioned obstacles and target locations. The proposed framework has been employed in the 2022 UAV Competition of the International Conference on Unmanned Aircraft Systems (ICUAS), where it successfully completed the mission in several runs of increasing difficulty, both in simulation and in real scenarios, achieving third place overall. A video attachment to this paper is available on the website https://www.youtube.com/watch?v=_hdxX2xXkVQ .},
  archive      = {J_JIRS},
  author       = {Mugnai, Michael and Teppati Losè, Massimo and Satler, Massimo and Avizzano, Carlo Alberto},
  doi          = {10.1007/s10846-023-02042-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Towards autonomous firefighting UAVs: Online planners for obstacle avoidance and payload delivery},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-UAV collaborative system for the identification of
surface cyanobacterial blooms and aquatic macrophytes. <em>JIRS</em>,
<em>110</em>(1), 1–27. (<a
href="https://doi.org/10.1007/s10846-023-02043-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aquatic macrophyte is a generic denomination for macro-algae with active photosynthetic parts that remain totally or partially submerged in fresh or salty water, in rivers and lakes. Currently, algae monitoring is carried out manually by collecting samples to send for laboratory analysis. In most cases, harmful algal blooms are already widespread when the results are disclosed. This paper proposes the application of a team of heterogeneous Unmanned Aerial Vehicles (UAVs) that cooperate to increase the system’s overall observation range and reduce the reaction time. Leader UAV, featured with a deep-learning-based vision system, covers a pre-determined region and determines high-interest inspection areas in real-time. Through a multi-robot Informative Path Planning (MIPP) approach, the leader UAV coordinates a team of customized quadcopter (named ART2) to reach points of interest, managing their route dynamically. ART2s are able to land on water, and collect and test samples in situ by applying phosphorescence sensors. While path planning, task assignment, and route management are centralized operations, each UAV is conducted by a decentralized trajectory tracking control. Simulations performed in a realistic environment implemented on the Unity platform and experimental proof of concepts demonstrated the reliability of the proposed approach. The presented multi-UAV framework with heterogeneous agents also enables the reconfiguration and expansion of specific objectives, in addition to minimizing the task completion time by executing different processes in parallel. This preventive monitoring enables a plague control action in advance, solving it faster, cheaper, and more effectively.},
  archive      = {J_JIRS},
  author       = {Vivaldini, Kelen C. T. and Pazelli, Tatiana F. P. A. T. and Rocha, Lidia G. S. and Santos, Igor A. D. and Caldas, Kenny A. Q. and Soler, Diego P. and Benevides, João R. S. and Simplício, Paulo V. G. and Hernandes, André C. and Andrade, Kleber O. and Kim, Pedro H. C. and Alvarez, Isaac G. and Nascimento, Eduardo V. and Santos, Marcela A. A. and Almeida, Aline G. and Cavalcanti, Lucas H. G. and Inoue, Roberto S. and Terra, Marco H. and Becker, Marcelo},
  doi          = {10.1007/s10846-023-02043-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-27},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Multi-UAV collaborative system for the identification of surface cyanobacterial blooms and aquatic macrophytes},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Surface tracking controls of an unmanned underwater vehicle
with fixed sonar ray measurements in tunnel-like environments.
<em>JIRS</em>, <em>110</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s10846-023-02044-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces 3-D surface tracking control of an Unmanned Underwater Vehicle (UUV) in tunnel-like environments. Consider the case where a sonar transducer in the UUV does not rotate, and it only emits fixed sonar ray reporting a simple distance measurement. This reduces the power consumption of the UUV, while reducing the UUV’s size and price. The UUV is controlled to proceed in tunnel-like environments, while maintaining a predefined distance from the tunnel boundaries. For maintaining a predefined distance from tunnel boundaries, the UUV uses fixed sonar rays surrounding it. As far as we know, our article is novel in developing 3-D surface tracking controls of tunnel-like environments utilizing an UUV with fixed sonar rays surrounding it. MATLAB simulations are used for demonstrating the performance of the proposed tracking controls.},
  archive      = {J_JIRS},
  author       = {Kim, Jonghoek},
  doi          = {10.1007/s10846-023-02044-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-10},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Surface tracking controls of an unmanned underwater vehicle with fixed sonar ray measurements in tunnel-like environments},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Communication-aware control of large data transmissions via
centralized cognition and 5G networks for multi-robot map merging.
<em>JIRS</em>, <em>110</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s10846-023-02045-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple modern robotic applications benefit from centralized cognition and processing schemes. However, modern equipped robotic platforms can output a large amount of data, which may exceed the capabilities of modern wireless communication systems if all data is transmitted without further consideration. This research presents a multi-agent, centralized, and real-time 3D point cloud map merging scheme for ceaselessly connected robotic agents. Centralized architectures enable mission awareness to all agents at all times, making tasks such as search and rescue more effective. The centralized component is placed on an edge server, ensuring low communication latency, while all agents access the server utilizing a fifth-generation (5G) network. In addition, the proposed solution introduces a communication-aware control function that regulates the transmissions of map instances to prevent the creation of significant data congestion and communication latencies as well as address conditions where the robotic agents traverse in limited to no coverage areas. The presented framework is agnostic of the used localization and mapping procedure, while it utilizes the full power of an edge server. Finally, the efficiency of the novel established framework is being experimentally validated based on multiple scenarios.},
  archive      = {J_JIRS},
  author       = {Damigos, Gerasimos and Stathoulopoulos, Nikolaos and Koval, Anton and Lindgren, Tore and Nikolakopoulos, George},
  doi          = {10.1007/s10846-023-02045-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-22},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Communication-aware control of large data transmissions via centralized cognition and 5G networks for multi-robot map merging},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RGB-d based visual SLAM algorithm for indoor crowd
environment. <em>JIRS</em>, <em>110</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10846-023-02046-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current research on dynamic visual Simultaneous Localization and Mapping (SLAM) systems focuses on scenes where static objects occupy most of the environment. However, in densely populated indoor environments, the movement of the crowd can lead to the loss of feature information, thereby diminishing the system’s robustness and accuracy. This paper proposes a visual SLAM algorithm for dense crowd environments based on a combination of the ORB-SLAM2 framework and RGB-D cameras. Firstly, we introduced a dedicated target detection network thread and improved the performance of the target detection network, enhancing its detection coverage in crowded environments, resulting in a 41.5% increase in average accuracy. Additionally, we found that some feature points other than humans in the detection box were mistakenly deleted. Therefore, we proposed an algorithm based on standard deviation fitting to effectively filter out the features. Finally, our system is evaluated on the TUM and Bonn RGB-D dynamic datasets and compared with ORB-SLAM2 and other state-of-the-art visual dynamic SLAM methods. The results indicate that our system’s pose estimation error is reduced by at least 93.60% and 97.11% compared to ORB-SLAM2 in high dynamic environments and the Bonn RGB-D dynamic dataset, respectively. Our method demonstrates comparable performance compared to other recent visual dynamic SLAM methods.},
  archive      = {J_JIRS},
  author       = {Li, Jianfeng and Dai, Juan and Su, Zhong and Zhu, Cui},
  doi          = {10.1007/s10846-023-02046-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {RGB-D based visual SLAM algorithm for indoor crowd environment},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CPG-fuzzy heading control for a hexapod robot with
arc-shaped blade legs. <em>JIRS</em>, <em>110</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10846-023-02047-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the central pattern generator (CPG) and fuzzy controller, this paper proposes a heading control method for the directional motion for a new type of blade legged hexapod robot (BLHR). First, the modified Hopf oscillator is used to construct the CPG model of BLHR based on the limit cycle. Second, the fuzzy controller is applied to adjust the support angles of legs to change the heading of BLHR, thereby correcting the error between the actual and desired heading angle in real-time. Finally, the feasibility and effectiveness of the proposed CPG-Fuzzy control method is verified in Gazebo simulations and real-world experiments. This is the first attempt to combine CPG and fuzzy control in the context of hexapod robot. In comparison to existing control methods, the proposed CPG-Fuzzy controller can implement heading control of BLHR with better performance and value of further investigation.},
  archive      = {J_JIRS},
  author       = {Zhang, Yani and Cui, Rongxin and Li, Haoquan and Guo, Xinxin},
  doi          = {10.1007/s10846-023-02047-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {CPG-fuzzy heading control for a hexapod robot with arc-shaped blade legs},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Connectivity maintenance through unlabeled spanning tree
matching. <em>JIRS</em>, <em>110</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02048-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key function of mobile networks is the ability to dynamically reshape itself to any desired geometry. Lacking absolute position awareness, agents often rely on distance-limited inter-agent spatial measurements to maintain state awareness. Methods of formation control must therefore ensure a minimal level of persistent pairwise measurement feedback throughout transition, giving rise to the classic connectivity maintenance problem. To address this problem, we propose a method of structure-preserving assignment, matching agents to desired positions such that persistent global connectivity is naturally and automatically satisfied under smooth transition. Compared to other approaches, this complementary technique reduces reliance on aggressive or costly mid-flight formation control protocols. The technique is shown to scale and even improve with network size.},
  archive      = {J_JIRS},
  author       = {Hamaoui, Moshe},
  doi          = {10.1007/s10846-024-02048-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Connectivity maintenance through unlabeled spanning tree matching},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State-dependent maximum entropy reinforcement learning for
robot long-horizon task learning. <em>JIRS</em>, <em>110</em>(1), 1–14.
(<a href="https://doi.org/10.1007/s10846-024-02049-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task-oriented robot learning has shown significant potential with the development of Reinforcement Learning (RL) algorithms. However, the learning of long-horizon tasks for robots remains a formidable challenge due to the inherent complexity of tasks, typically comprising multiple diverse stages. Universal RL algorithms commonly encounter issues such as slow convergence or even failure to converge altogether when applied to such tasks. The reasons behind these challenges lie in the local optima trap or redundant exploration during the new stages or the junction of two continuous stages. To address these challenges, we propose a novel state-dependent maximum entropy (SDME) reinforcement learning algorithm. This algorithm effectively balances the trade-off between exploration and exploitation around three kinds of critical states arising from the unique nature of long-horizon tasks. We conducted experiments within an open-source simulation environment, focusing on two representative long-horizon tasks. The proposed SDME algorithm exhibits faster and more stable learning capabilities, requiring merely one-third of the number of learning samples necessary for baseline approaches. Furthermore, we assess the generalization ability of our method under randomly initialized conditions, and the results show that the success rate of the SDME algorithm is nearly twice that of the baselines. Our code will be available at https://github.com/Peter-zds/SDME .},
  archive      = {J_JIRS},
  author       = {Zheng, Deshuai and Yan, Jin and Xue, Tao and Liu, Yong},
  doi          = {10.1007/s10846-024-02049-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {State-dependent maximum entropy reinforcement learning for robot long-horizon task learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online capability based task allocation of cooperative
manipulators. <em>JIRS</em>, <em>110</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02050-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cooperative manipulator group can accomplish complex and heavy payload tasks of object manipulation and transportation compared to a single manipulator. Effective coordination is crucial for cooperative task accomplishments. Multi-manipulator task distribution is highly complex because of the varying dynamic capabilities of the manipulators. We have introduced a novel fastest technique to quantify the dynamic task capability of the cooperative manipulator by scalar quantity and allocate the task accordingly. The scalar quantity determines the capability of applying an external wrench by end effector (EE) in line with the required wrench at the center of mass of the manipulating object. This quantity helps to diminish tracking errors in object manipulations or transportation and actuator saturation avoidance. The task distribution among the members is in proportion to their computed dynamic capability to ensure equal priority to the individual manipulators. The proposed task distribution formulation ensures the minimum magnitude of wrench interaction at the grasp point and the minimum internal wrench build-up in the object. Several physical simulation results assure trajectory tracking performance with the proposed task capability metric. The same metric aids in identifying the least capable manipulator, rearranging members for better performance, and deciding the required number of manipulators in the manipulator group.},
  archive      = {J_JIRS},
  author       = {Patra, Keshab and Sinha, Arpita and Guha, Anirban},
  doi          = {10.1007/s10846-024-02050-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Online capability based task allocation of cooperative manipulators},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic via-points and improved spatial generalization for
online trajectory generation with dynamic movement primitives.
<em>JIRS</em>, <em>110</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02051-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Movement Primitives (DMP) have found remarkable applicability and success in various robotic tasks, which can be mainly attributed to their generalization, modulation and robustness properties. However, the spatial generalization of DMP can be problematic in some cases, leading to excessive overscaling and in turn large velocities and accelerations. While other DMP variants have been proposed in the literature to tackle this issue, they can also exhibit excessive overscaling as we show in this work. Moreover, incorporating intermediate points (via-points) for adjusting the DMP trajectory to account for the geometry of objects related to the task, or to avoid or push aside objects that obstruct a specific task, is not addressed by the current DMP literature. In this work we tackle these unresolved so far issues by proposing an improved online spatial generalization, that remedies the shortcomings of the classical DMP generalization, and moreover allows the incorporation of dynamic via-points. This is achieved by designing an online adaptation scheme for the DMP weights which is proved to minimize the distance from the demonstrated acceleration profile to retain the shape of the demonstration, subject to dynamic via-point and initial/final state constraints. Extensive comparative simulations with the classical and other DMP variants are conducted, while experimental results validate the practical usefulness and efficiency of the proposed method.},
  archive      = {J_JIRS},
  author       = {Sidiropoulos, Antonis and Doulgeri, Zoe},
  doi          = {10.1007/s10846-024-02051-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Dynamic via-points and improved spatial generalization for online trajectory generation with dynamic movement primitives},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Motion transition under urgent change of target step-stone
during three-dimensional biped walking. <em>JIRS</em>, <em>110</em>(1),
1–15. (<a href="https://doi.org/10.1007/s10846-024-02053-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling a biped robot to walk through rough terrains is crucial to the robot’s field application. For a human in the workplace, the ability to flexibly transfer motion while walking in some urgent circumstances is necessary. Explicitly, the according scenario can be dodging an approaching object or instantly modifying the target place to step on. The function is also important for humanoid robot workers. Therefore, we proposed a walking control framework that achieves three-dimensional (3-D) walking and transfers the whole body motion when the target stepping location is urgently changed. The proposed framework contains a motion planner which outputs the desired center of mass (CoM) and center of pressure (CoP) trajectories in 3-D space and a hierarchical whole body controller (WBC) that outputs corresponding whole body joints’ trajectories. In the motion planner, the CoM jerk for each loop is calculated by the Linear-Quadratic-Tracker (LQT), a variation of the Linear-Quadratic-Regulator (LQR). The LQT coefficients adapt to the adjusted step length, making the desired CoM and CoP trajectories respond flexibly to the change of target step-stone. In WBC, three levels of tasks are defined, which meet dynamic, kinematic, and viable contact constraints, respectively. The optimal joints’ angular accelerations are obtained by exploiting the nullspace of the first two levels tasks and by quadratic programming (QP) for the third-level task. In the simulations, our method is demonstrated to be effective for the robot to transfer the motion under urgent change of the target step-stone.},
  archive      = {J_JIRS},
  author       = {Zhang, Runming and Yu, Zhangguo and Chen, Xuechao and Huang, Qiang},
  doi          = {10.1007/s10846-024-02053-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Motion transition under urgent change of target step-stone during three-dimensional biped walking},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modelling, analysis, and control of OmniMorph: An
omnidirectional morphing multi-rotor UAV. <em>JIRS</em>,
<em>110</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02054-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces for the first time the design, modelling, and control of a novel morphing multi-rotor Unmanned Aerial Vehicle (UAV) that we call the OmniMorph. The morphing ability allows the selection of the configuration that optimizes energy consumption while ensuring the needed maneuverability for the required task. The most energy-efficient uni-directional thrust (UDT) configuration can be used, e.g., during standard point-to-point displacements. Fully-actuated (FA) and omnidirectional (OD) configurations can be instead used for full pose tracking, such as, e.g., constant attitude horizontal motions and full rotations on the spot, and for full wrench 6D interaction control and 6D disturbance rejection. Morphing is obtained using a single servomotor, allowing possible minimization of weight, costs, and maintenance complexity. The actuation properties are studied, and an optimal controller that compromises between performance and control effort is proposed and validated in realistic simulations. Preliminary tests on the prototype are presented to assess the propellers’ mutual aerodynamic interference.},
  archive      = {J_JIRS},
  author       = {Aboudorra, Youssef and Gabellieri, Chiara and Brantjes, Ralph and Sablé, Quentin and Franchi, Antonio},
  doi          = {10.1007/s10846-024-02054-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Modelling, analysis, and control of OmniMorph: An omnidirectional morphing multi-rotor UAV},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On real-time cooperative trajectory planning of
aerial-ground systems. <em>JIRS</em>, <em>110</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02055-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative trajectory planning of aerial-ground systems is a fundamental and challenging problem, which aims to leverage the aerial information to assist the ground tasks. Existing methods often suffer from suboptimal trajectories or computation burden. In this paper, we address cooperative trajectory planning of aerial-ground systems in which an unmanned ground vehicle (UGV) plans its local trajectory in real-time with the assistance of an unmanned aerial vehicle (UAV). Firstly, the UAV generates guidance trajectory using nonlinear model predictive control (NMPC), which considers the obstacle distribution density as a factor reflecting the coupling effect of multiple obstacles on the UGV, thereby avoiding local minima problem and improving the feasibility of the planned trajectory. Secondly, a null-space-based behavioral control (NSBC) framework is employed to merge the guidance trajectory into the UGV’s own planned one as a task. Finally, an event triggering task supervisor is developed for the UGV to decide the priorities of all tasks, which reduces the switching frequency of task priorities brought by traditional rule-based task supervisors. Both simulation and experiment results show that the proposed approach has superior trajectory planning performance in terms of trajectory error, on-line computation time and the success rate of task execution.},
  archive      = {J_JIRS},
  author       = {Huang, Jie and Chen, Jianfei and Zhang, Zhenyi and Chen, Yutao and Lin, Dingci},
  doi          = {10.1007/s10846-024-02055-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {On real-time cooperative trajectory planning of aerial-ground systems},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Passenger air taxi services: An assessment of the current
european union rules on consumer protection for passengers.
<em>JIRS</em>, <em>110</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02057-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Paris Olympics and Paralympics are scheduled to take place between 26 July and 8 September 2024, whereby electric vertical take-off and landing aircraft are anticipated to take to the skies to offer a new mobility solution to spectators of the Games. This will allow paying members of the public to move between different points within the Paris region akin to an on-demand taxi service, but through the air; passenger air taxi services (PATS). These passengers, as consumers, will have certain rights and duties under European Union law. To determine the level of protection afforded to these air passengers, a full assessment of Regulation (EC) No 261/2004 is required. As the revision of the Regulation is currently on the European Commission’s agenda, it is also important to consider its revision in light of PATS, whereby new technology, emerging business practices, changing customer behaviour and societal expectations for the level of legal protection of PATS users must be considered. This article will, therefore, assess the current version of the Regulation, in light of the interpretation from the European Court, to see whether it applies to PATS and, if so, whether it is suitable or if specific amendments need to be added to the planned revised Regulation.},
  archive      = {J_JIRS},
  author       = {Scott, Benjamyn I.},
  doi          = {10.1007/s10846-024-02057-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Passenger air taxi services: An assessment of the current european union rules on consumer protection for passengers},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable task allocation with communications connectivity
for flying ad-hoc networks. <em>JIRS</em>, <em>110</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s10846-024-02059-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task allocation enables heterogeneous agents to execute heterogeneous tasks in the domain of unmanned aerial vehicles, while responding to dynamic changes in the environment and available resources to complete complex, multi-objective missions, leading to swarm intelligence. We propose a bio-inspired approach using digital pheromones to perform scalable task allocation when the number of agents, tasks, and the diameter of the communications graph increase. The resulting emergent behaviour also enables idle agents in the swarm to provide periodic or continuous connectivity between disconnected parts of the swarm. We validate our results through simulation and demonstrate the feasibility of our approach by applying it to the 3D coverage and patrol problem.},
  archive      = {J_JIRS},
  author       = {Leong, Wai Lun and Cao, Jiawei and Teo, Rodney},
  doi          = {10.1007/s10846-024-02059-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-33},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Scalable task allocation with communications connectivity for flying ad-hoc networks},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal transport and model predictive control-based
simultaneous task assignment and trajectory planning for unmanned system
swarm. <em>JIRS</em>, <em>110</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s10846-024-02060-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a simultaneous task assignment and trajectory planning method for unmanned system swarm by using optimal transport and model predictive control (OT-MPC). Unlike the conventional hierarchical assignment and planning, the proposed approach addresses both the task assignment and trajectory planning subproblems concurrently. To be specific, a unified cost function is designed to solve task assignment and trajectory planning problem. Moreover, the multi-tasks are assigned by using optimal transport, which establishes an optimal mapping between tasks and unmanned system vehicles based on transportation cost. The trajectory planning is achieved by using model predictive control, which generates high-quality navigation trajectories considering obstacle avoidance. Finally, the proposed method is applied to the unmanned surface vehicles swarm. Numerical simulations and experiments were conducted to validate the effectiveness of the proposed method.},
  archive      = {J_JIRS},
  author       = {Wu, Xiwei and Xiao, Bing and Cao, Lu and Huang, Haibin},
  doi          = {10.1007/s10846-024-02060-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Optimal transport and model predictive control-based simultaneous task assignment and trajectory planning for unmanned system swarm},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Calibration of static errors and compensation of dynamic
errors for cable-driven parallel 3D printer. <em>JIRS</em>,
<em>110</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02062-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As rigid robots suffer from the higher inertia of their rigid links, cable-driven parallel robots (CDPRs) are more suitable for large-scale three-dimensional (3D) printing tasks due to their outstanding reconfigurability, high load-to-weight ratio, and extensive workspace. In this paper, a parallel 3D printing robot is proposed, comprising three pairs of driving cables to control the platform motion and three pairs of redundant cables to adjust the cable tension. To improve the motion accuracy of the moving platform, the static kinematic error model is established, and the error sensitivity coefficient is determined to reduce the dimensionality of the optimization function. Subsequently, the self-calibration positions are determined based on the maximum cable length error in the reachable workspace. A self-calibration method is proposed based on the genetic algorithm to solve the kinematic parameter deviations. Additionally, the dynamic errors are effectively reduced by compensating for the elastic deformation errors of the cable lengths. Furthermore, an experimental prototype is developed. The results of dynamic error compensation after the self-calibration indicate a 67.4% reduction in terms of the maximum error along the Z-axis direction. Finally, the developed prototype and proposed calibration and compensation methods are validated through the printing experiment.},
  archive      = {J_JIRS},
  author       = {Qian, Sen and Jiang, Xiao and Qian, Pengfei and Zi, Bin and Zhu, Weidong},
  doi          = {10.1007/s10846-024-02062-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Calibration of static errors and compensation of dynamic errors for cable-driven parallel 3D printer},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Event-based guidance and incremental control with
application to fixed-wing unmanned aerial vehicle perched landing
maneuvers. <em>JIRS</em>, <em>110</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02063-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the nonlinearity and unknown dynamics of fixed-wing unmanned aerial vehicles in perched landing maneuvers, an event-based online guidance and incremental control scheme is proposed. The guidance trajectory for perched landing must be dynamically feasible therefore an event-based trapezoidal collocation point optimization method is proposed. Introduction of the triggering mechanism for the rational use of computing resources to improve PL accuracy. Furthermore, a filter-based incremental nonlinear dynamic inverse (F-INDI) control with state transformation is proposed to achieve robust trajectory tracking under high angle of attack (AOA). The F-INDI uses low-pass filters to obtain incremental dynamics of the system, which simplifies the design process. The state transformation strategy is to convert the flight-path angle, AOA and velocity into two composite dynamics, which avoids the sign reversal problem of control gain under high AOA. The stability analysis shows that the original states can be controlled only by controlling the composite state. Simulation results show that the proposed scheme achieves high perched landing accuracy and a reliable trajectory tracking control.},
  archive      = {J_JIRS},
  author       = {Song, Yansui and Sun, Shaoshan and Tao, Chenggang and He, Zhen and Xu, Bin},
  doi          = {10.1007/s10846-024-02063-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Event-based guidance and incremental control with application to fixed-wing unmanned aerial vehicle perched landing maneuvers},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A procedural constructive learning mechanism with deep
reinforcement learning for cognitive agents. <em>JIRS</em>,
<em>110</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10846-024-02064-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in AI and deep learning have created a growing demand for artificial agents capable of performing tasks within increasingly complex environments. To address the challenges associated with continuous learning constraints and knowledge capacity in this context, cognitive architectures inspired by human cognition have gained significance. This study contributes to existing research by introducing a cognitive-attentional system employing a constructive neural network-based learning approach for continuous acquisition of procedural knowledge. We replace an incremental tabular Reinforcement Learning algorithm with a constructive neural network deep reinforcement learning mechanism for continuous sensorimotor knowledge acquisition, thereby enhancing the overall learning capacity. The primary emphasis of this modification centers on optimizing memory utilization and reducing training time. Our study presents a learning strategy that amalgamates deep reinforcement learning with procedural learning, mirroring the incremental learning process observed in human sensorimotor development. This approach is embedded within the CONAIM cognitive-attentional architecture, leveraging the cognitive tools of CST. The proposed learning mechanism allows the model to dynamically create and modify elements in its procedural memory, facilitating the reuse of previously acquired functions and procedures. Additionally, it equips the model with the capability to combine learned elements to effectively adapt to complex scenarios. A constructive neural network was employed, initiating with an initial hidden layer comprising one neuron. However, it possesses the capacity to adapt its internal architecture in response to its performance in procedural and sensorimotor learning tasks, inserting new hidden layers or neurons. Experimentation conducted through simulations involving a humanoid robot demonstrates the successful resolution of tasks that were previously unsolved through incremental knowledge acquisition. Throughout the training phase, the constructive agent achieved a minimum of 40% greater rewards and executed 8% more actions when compared to other agents. In the subsequent testing phase, the constructive agent exhibited a 15% increase in the number of actions performed in contrast to its counterparts.},
  archive      = {J_JIRS},
  author       = {de Lellis Rossi, Leonardo and Rohmer, Eric and Dornhofer Paro Costa, Paula and Colombini, Esther Luna and da Silva Simões, Alexandre and Gudwin, Ricardo Ribeiro},
  doi          = {10.1007/s10846-024-02064-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-25},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A procedural constructive learning mechanism with deep reinforcement learning for cognitive agents},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diving into clarity: Restoring underwater images using deep
learning. <em>JIRS</em>, <em>110</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02065-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a learning-based restoration approach to learn the optimal parameters for enhancing the quality of different types of underwater images and apply a set of intensity transformation techniques to process raw underwater images. The methodology comprises two steps. Firstly, a Convolutional Neural Network (CNN) Regression model is employed to learn enhancing parameters for each underwater image type. Trained on a diverse dataset, the CNN captures complex relationships, enabling generalization to various underwater conditions. Secondly, we apply intensity transformation techniques to raw underwater images. These transformations collectively compensate for visual information loss due to underwater degradation, enhancing overall image quality. In order to evaluate the performance of our proposed approach, we conducted qualitative and quantitative experiments using well-known underwater image datasets (U45 and UIEB), and using the proposed challenging dataset composed by 276 underwater images from the Amazon region (AUID). The results demonstrate that our approach achieves an impressive accuracy rate in different underwater image datasets. For U45 and UIEB datasets, regarding PSNR and SSIM quality metrics, we achieved 26.967, 0.847, 27.299 and 0.793, respectively. Meanwhile, the best comparison techniques achieved 26.879, 0.831, 27.157 and 0.788, respectively.},
  archive      = {J_JIRS},
  author       = {Martinho, Laura A. and Calvalcanti, João M. B. and Pio, José L. S. and Oliveira, Felipe G.},
  doi          = {10.1007/s10846-024-02065-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Diving into clarity: Restoring underwater images using deep learning},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Control of the PVTOL with strong input coupling.
<em>JIRS</em>, <em>110</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s10846-024-02066-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the modeling and control of a Planar Vertical Take-Off and Landing (PVTOL) with steerable thruster. A longitudinal model is obtained using Newton’s second law for the PVTOL which evolves in 3 degrees of freedom and has two control inputs. The aerial vehicle is driven by steerable propulsion controlling its evolution in the vertical plane through the thrust and torque control inputs, which drive the vehicle body and generate a rotation. The obtained model is nonlinear and is significantly different with respect to the well-known PVTOL. For this reason, different control algorithms are presented, and the closed-loop behavior is studied for each of them. The proposed control strategies perform a stationary flight at a desired altitude and control the position of the aerial vehicle. The performance of the proposed control algorithms is tested in numerical simulations.},
  archive      = {J_JIRS},
  author       = {Lozano, Rogelio and Eulopa-Hernandez, Jhonatan F and Salazar-Cruz, Sergio},
  doi          = {10.1007/s10846-024-02066-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-10},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Control of the PVTOL with strong input coupling},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aviation safety for urban air mobility: Pilot licensing and
fatigue management. <em>JIRS</em>, <em>110</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s10846-024-02070-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban Air Mobility (UAM) is an emerging air traffic system designed for passengers and cargo in and around urban environments. Both the Federal Aviation Administration of the United States and the European Union Aviation Safety Agency endorse a phased development approach for UAM, commencing with manned aviation and subsequently transitioning to remotely piloted and autonomous operations. This article focuses on legal considerations related to aviation safety, with a specific focus on pilot licensing and crew fatigue management. An analysis of existing aviation law provisions suggests that the International Civil Aviation Organization can work with local authorities to create regulations governing both on-board and remote pilots involved in UAM operations. Safety standards in air law can apply mutatis mutandis to on-board pilots until specific regulations are developed. In the longer term, there shall be domestic laws on both on-board and remote UAM pilots.},
  archive      = {J_JIRS},
  author       = {Shi, Yuran},
  doi          = {10.1007/s10846-024-02070-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-10},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Aviation safety for urban air mobility: Pilot licensing and fatigue management},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Terrain-shape-adaptive coverage path planning with
traversability analysis. <em>JIRS</em>, <em>110</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10846-024-02073-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coverage path planning (CPP) is in great demand with applications in agriculture, mining, manufacturing, etc. Most research in this area focused on 2D CPP problems solving the coverage problem with irregular 2D maps. Comparatively, CPP on uneven terrains is not fully solved. When there are many slopy areas in the working field, it is necessary to adjust the path shape and make it adapt to the 3D terrain surface to save energy consumption. This article proposes a terrain-shape-adaptive CPP method with three significant features. First, the paths grow by themselves according to the local terrain surface shapes. Second, the growth rule utilizes the 3D terrain traversability analysis, which makes them automatically avoid entering hazardous zones. Third, the irregularly distributed paths are connected under an optimal sequence with an improved genetic algorithm. As a result, the method can provide an autonomously growing terrain-adaptive coverage path with high energy efficiency and coverage rate compared to previous research works. It is demonstrated on various maps and is proven to be robust to terrain conditions.},
  archive      = {J_JIRS},
  author       = {Qiu, Wenwei and Zhou, Dacheng and Hui, Wenbo and Kwabena, Afimbo Reuben and Xing, Yubo and Qian, Yi and Li, Quan and Pu, Huayan and Xie, Yangmin},
  doi          = {10.1007/s10846-024-02073-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Terrain-shape-adaptive coverage path planning with traversability analysis},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel communication time-delay cooperative control method
with switching event-triggered strategy. <em>JIRS</em>, <em>110</em>(1),
1–15. (<a href="https://doi.org/10.1007/s10846-024-02076-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel communication time-delay classification-based method is designed for nonlinear multiagent systems with the finite-time prescribed performance function. The time-delay phenomenon for communication channels between agents is discussed. Then, an improved time-delay classification method is proposed to broaden the standard of classification mechanism by considering the degree of deviation and relative variation of neighbor agents, rather than classifying the delay time into large time-delay and small time-delay. Based on this, the unified Lyapunov-Krasovskii functional and the finite-time performance function are used to solve the large time-delay phenomenon and ensure that the error is within the preset boundary, respectively. Furthermore, a modified switching event-triggered strategy is put forward to reduce the transmission burden, which considers the impact of tracking error to adjust the threshold condition in real-time. Additionally, all signals of the closed-loop systems are bounded. Eventually, two simulation examples verify the validity of the control strategy.},
  archive      = {J_JIRS},
  author       = {Li, Dongni and Cao, Liang and Pan, Yingnan and Xiao, Wenbin and Xue, Hong},
  doi          = {10.1007/s10846-024-02076-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A novel communication time-delay cooperative control method with switching event-triggered strategy},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How challenging is a challenge? CEMS: A challenge evaluation
module for SLAM visual perception. <em>JIRS</em>, <em>110</em>(1), 1–19.
(<a href="https://doi.org/10.1007/s10846-024-02077-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite promising SLAM research in both vision and robotics communities, which fundamentally sustains the autonomy of intelligent unmanned systems, visual challenges still threaten its robust operation severely. Existing SLAM methods usually focus on specific challenges and solve the problem with sophisticated enhancement or multi-modal fusion. However, they are basically limited to particular scenes with a non-quantitative understanding and awareness of challenges, resulting in a significant performance decline with poor generalization and(or) redundant computation with inflexible mechanisms. To push the frontier of visual SLAM, we propose a fully computational reliable evaluation module called CEMS (Challenge Evaluation Module for SLAM) for general visual perception based on a clear definition and systematic analysis. It decomposes various challenges into several common aspects and evaluates degradation with corresponding indicators. Extensive experiments demonstrate our feasibility and outperformance. The proposed module has a high consistency of 88.298% compared with annotation ground truth, and a strong correlation of 0.879 compared with SLAM tracking performance. Moreover, we show the prototype SLAM based on CEMS with better performance and the first comprehensive CET (Challenge Evaluation Table) for common SLAM datasets (EuRoC, KITTI, etc.) with objective and fair evaluations of various challenges. We make it available online to benefit the community on our website.},
  archive      = {J_JIRS},
  author       = {Zhao, Xuhui and Gao, Zhi and Li, Hao and Ji, Hong and Yang, Hong and Li, Chenyang and Fang, Hao and M. Chen, Ben},
  doi          = {10.1007/s10846-024-02077-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {How challenging is a challenge? CEMS: A challenge evaluation module for SLAM visual perception},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). JIRS editorial, first quarter 2024. <em>JIRS</em>,
<em>110</em>(1), 1. (<a
href="https://doi.org/10.1007/s10846-024-02083-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIRS},
  author       = {Valavanis, Kimon P.},
  doi          = {10.1007/s10846-024-02083-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {JIRS editorial, first quarter 2024},
  volume       = {110},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
