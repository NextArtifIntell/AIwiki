<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Alg_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="alg---123">Alg - 123</h2>
<ul>
<li><details>
<summary>
(2024). Energy constrained depth first search. <em>Alg</em>,
<em>86</em>(12), 3759–3782. (<a
href="https://doi.org/10.1007/s00453-024-01275-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth first search is a natural algorithmic technique for constructing a closed route that visits all vertices of a graph. The length of such a route equals, in an edge-weighted tree, twice the total weight of all edges of the tree and this is asymptotically optimal over all exploration strategies. This paper considers a variant of such search strategies where the length of each route is bounded by a positive integer B (e.g. due to limited energy resources of the searcher). The objective is to cover all the edges of a tree T using the minimum number of routes, each starting and ending at the root and each being of length at most B. To this end, we analyze the following natural greedy tree traversal process that is based on decomposing a depth first search traversal into a sequence of limited length routes. Given any arbitrary depth first search traversal R of the tree T, we cover R with routes $$R_1,\ldots ,R_l$$ , each of length at most B such that: $$R_i$$ starts at the root, reaches directly the farthest point of R visited by $$R_{i-1}$$ , then $$R_i$$ continues along the path R as far as possible, and finally $$R_i$$ returns to the root. We call the above algorithm piecemeal-DFS and we prove that it achieves the asymptotically minimal number of routes l, regardless of the choice of R. Our analysis also shows that the total length of the traversal (and thus the traversal time) of piecemeal-DFS is asymptotically minimum over all energy-constrained exploration strategies. The fact that R can be chosen arbitrarily means that the exploration strategy can be constructed in an online fashion when the input tree T is not known in advance. Each route $$R_i$$ can be constructed without any knowledge of the yet unvisited part of T. Surprisingly, our results show that depth first search is efficient for energy constrained exploration of trees, even though it is known that the same does not hold for energy constrained exploration of arbitrary graphs.},
  archive      = {J_Alg},
  author       = {Das, Shantanu and Dereniowski, Dariusz and Uznański, Przemysław},
  doi          = {10.1007/s00453-024-01275-8},
  journal      = {Algorithmica},
  month        = {12},
  number       = {12},
  pages        = {3759-3782},
  shortjournal = {Algorithmica},
  title        = {Energy constrained depth first search},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recovering the original simplicity: Succinct and exact
quantum algorithm for the welded tree problem. <em>Alg</em>,
<em>86</em>(12), 3719–3758. (<a
href="https://doi.org/10.1007/s00453-024-01273-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work revisits quantum algorithms for the well-known welded tree problem, proposing a succinct quantum algorithm based on the simple coined quantum walks. It iterates the naturally defined coined quantum walk operator for a classically precomputed number of iterations, and measures. The number of iterations is linear in the depth of the tree. The success probability of this procedure is inversely linear in the depth of the tree. Moreover, it is the same for all instances of the problem of a fixed size, therefore, we can use the exact quantum amplitude amplification subroutine to answer with probability 1. This gives an exponential speedup over any classical algorithm for the same problem. The significance of the results may be seen as follows. (i) Our algorithm is rather simple compared with the one in (Jeffery and Zur, STOC’2023), which not only breaks the stereotype that coined quantum walks can only achieve quadratic speedups over classical algorithms, but also demonstrates the power of the simplest quantum walk model. (ii) Our algorithm achieves certainty of success for the first time. Thus, it becomes one of the few examples that exhibit exponential separation between exact quantum and randomized query complexities.},
  archive      = {J_Alg},
  author       = {Li, Guanzhong and Li, Lvzhou and Luo, Jingquan},
  doi          = {10.1007/s00453-024-01273-w},
  journal      = {Algorithmica},
  month        = {12},
  number       = {12},
  pages        = {3719-3758},
  shortjournal = {Algorithmica},
  title        = {Recovering the original simplicity: Succinct and exact quantum algorithm for the welded tree problem},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Permutation-constrained common string partitions with
applications. <em>Alg</em>, <em>86</em>(12), 3684–3718. (<a
href="https://doi.org/10.1007/s00453-024-01276-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a new combinatorial problem based on the famous Minimum Common String Partition problem, which we call Permutation-constrained Common String Partition (PCSP for short). In PCSP, we are given two sequences/genomes s and t with the same length and a permutation $$\pi $$ on $$[\ell ]$$ , the question is to decide whether it is possible to decompose s and t into $$\ell $$ blocks that can be matched according to some specified requirements, and that conform with the permutation $$\pi $$ . Our main result is that PCSP is FPT in parameter $$\ell + d$$ , where d is the maximum number of occurrences that any symbol may have in s or t. We also study a variant where the input specifies whether each matched pair of block needs to be preserved as is, or reversed. With this result on PCSP, we show that a series of genome rearrangement problems are FPT $$k + d$$ , where k is the rearrangement distance between two genomes of interest.},
  archive      = {J_Alg},
  author       = {Lafond, Manuel and Zhu, Binhai},
  doi          = {10.1007/s00453-024-01276-7},
  journal      = {Algorithmica},
  month        = {12},
  number       = {12},
  pages        = {3684-3718},
  shortjournal = {Algorithmica},
  title        = {Permutation-constrained common string partitions with applications},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reachability of fair allocations via sequential exchanges.
<em>Alg</em>, <em>86</em>(12), 3653–3683. (<a
href="https://doi.org/10.1007/s00453-024-01271-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the allocation of indivisible goods, a prominent fairness notion is envy-freeness up to one good (EF1). We initiate the study of reachability problems in fair division by investigating the problem of whether one EF1 allocation can be reached from another EF1 allocation via a sequence of exchanges such that every intermediate allocation is also EF1. We show that two EF1 allocations may not be reachable from each other even in the case of two agents, and deciding their reachability is PSPACE-complete in general. On the other hand, we prove that reachability is guaranteed for two agents with identical or binary utilities as well as for any number of agents with identical binary utilities. We also examine the complexity of deciding whether there is an EF1 exchange sequence that is optimal in the number of exchanges required.},
  archive      = {J_Alg},
  author       = {Igarashi, Ayumi and Kamiyama, Naoyuki and Suksompong, Warut and Yuen, Sheung Man},
  doi          = {10.1007/s00453-024-01271-y},
  journal      = {Algorithmica},
  month        = {12},
  number       = {12},
  pages        = {3653-3683},
  shortjournal = {Algorithmica},
  title        = {Reachability of fair allocations via sequential exchanges},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On flipping the fréchet distance. <em>Alg</em>,
<em>86</em>(12), 3629–3652. (<a
href="https://doi.org/10.1007/s00453-024-01267-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical and extensively-studied Fréchet distance between two curves is defined as an inf max, where the infimum is over all traversals of the curves, and the maximum is over all concurrent positions of the two agents. In this article we investigate a “flipped” Fréchet measure defined by a sup min – the supremum is over all traversals of the curves, and the minimum is over all concurrent positions of the two agents. This measure produces a notion of “social distance” between two curves (or general domains), where agents traverse curves while trying to stay as far apart as possible. We first study the flipped Fréchet measure between two polygonal curves in one and two dimensions, providing conditional lower bounds and matching algorithms. We then consider this measure on polygons, where it denotes the minimum distance that two agents can maintain while restricted to travel in or on the boundary of the same polygon. We investigate several variants of the problem in this setting, for some of which we provide linear-time algorithms. We draw connections between our proposed flipped Fréchet measure and existing related work in computational geometry, hoping that our new measure may spawn investigations akin to those performed for the Fréchet distance, and into further interesting problems that arise.},
  archive      = {J_Alg},
  author       = {Filtser, Omrit and Goswami, Mayank and Mitchell, Joseph S. B. and Polishchuk, Valentin},
  doi          = {10.1007/s00453-024-01267-8},
  journal      = {Algorithmica},
  month        = {12},
  number       = {12},
  pages        = {3629-3652},
  shortjournal = {Algorithmica},
  title        = {On flipping the fréchet distance},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-streaming algorithms for submodular function
maximization under b-matching, matroid, and matchoid constraints.
<em>Alg</em>, <em>86</em>(11), 3598–3628. (<a
href="https://doi.org/10.1007/s00453-024-01272-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of maximizing a non-negative submodular function under the b-matching constraint, in the semi-streaming model. When the function is linear, monotone, and non-monotone, we obtain the approximation ratios of $$2+\varepsilon $$ , $$3 + 2 \sqrt{2} \approx 5.828$$ , and $$4 + 2 \sqrt{3} \approx 7.464$$ , respectively. We also consider a generalized problem, where a k-uniform hypergraph is given, along with an extra matroid or a $$k&#39;$$ -matchoid constraint imposed on the edges, with the same goal of finding a b-matching that maximizes a submodular function. When the extra constraint is a matroid, we obtain the approximation ratios of $$k + 1 + \varepsilon $$ , $$k + 2\sqrt{k+1} + 2$$ , and $$k + 2\sqrt{k + 2} + 3$$ for linear, monotone and non-monotone submodular functions, respectively. When the extra constraint is a $$k&#39;$$ -matchoid, we attain the approximation ratio $$\frac{8}{3}k+ \frac{64}{9}k&#39; + O(1)$$ for general submodular functions.},
  archive      = {J_Alg},
  author       = {Huang, Chien-Chung and Sellier, François},
  doi          = {10.1007/s00453-024-01272-x},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3598-3628},
  shortjournal = {Algorithmica},
  title        = {Semi-streaming algorithms for submodular function maximization under b-matching, matroid, and matchoid constraints},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the parameterized complexity of compact set packing.
<em>Alg</em>, <em>86</em>(11), 3579–3597. (<a
href="https://doi.org/10.1007/s00453-024-01269-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Set Packing problem is, given a collection of sets $$\mathcal {S}$$ over a ground set U, to find a maximum collection of sets that are pairwise disjoint. The problem is among the most fundamental NP-hard optimization problems that have been studied extensively in various computational regimes. The focus of this work is on parameterized complexity, Parameterized Set Packing (PSP): Given parameter $$r \in {\mathbb N}$$ , is there a collection $$ \mathcal {S}&#39; \subseteq \mathcal {S}: |\mathcal {S}&#39;| = r$$ such that the sets in $$\mathcal {S}&#39;$$ are pairwise disjoint? Unfortunately, the problem is not fixed parameter tractable unless $$\textsf {W[1]} = \textsf {FPT} $$ , and, in fact, an “enumerative” running time of $$|\mathcal {S}|^{\Omega (r)}$$ is required unless the exponential time hypothesis (ETH) fails. This paper is a quest for tractable instances of Set Packing from parameterized complexity perspectives. We say that the input $$({U},\mathcal {S})$$ is “compact” if $$|{U}| = f(r)\cdot \textsf {poly} ( \log |\mathcal {S}|)$$ , for some $$f(r) \ge r$$ . In the Compact PSP problem, we are given a compact instance of PSP. In this direction, we present a “dichotomy” result of PSP: When $$|{U}| = f(r)\cdot o(\log |\mathcal {S}|)$$ , PSP is in FPT, while for $$|{U}| = r\cdot \Theta (\log (|\mathcal {S}|))$$ , the problem is W[1]-hard; moreover, assuming ETH, Compact PSP does not admit $$|\mathcal {S}|^{o(r/\log r)}$$ time algorithm even when $$|{U}| = r\cdot \Theta (\log (|\mathcal {S}|))$$ . Although certain results in the literature imply hardness of compact versions of related problems such as Set $$r$$ -Covering and Exact $$r$$ -Covering, these constructions fail to extend to Compact PSP. A novel contribution of our work is the identification and construction of a gadget, which we call Compatible Intersecting Set System pair, that is crucial in obtaining the hardness result for Compact PSP. Finally, our framework can be extended to obtain improved running time lower bounds for Compact $$r$$ -VectorSum.},
  archive      = {J_Alg},
  author       = {Gadekar, Ameet},
  doi          = {10.1007/s00453-024-01269-6},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3579-3597},
  shortjournal = {Algorithmica},
  title        = {On the parameterized complexity of compact set packing},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ultimate greedy approximation of independent sets in
subcubic graphs. <em>Alg</em>, <em>86</em>(11), 3518–3578. (<a
href="https://doi.org/10.1007/s00453-024-01268-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the approximability of the maximum size independent set (MIS) problem in bounded degree graphs. This is one of the most classic and widely studied NP-hard optimization problems. It is known for its inherent hardness of approximation. We focus on the well known minimum-degree greedy algorithm for this problem. This algorithm iteratively chooses a minimum degree vertex in the graph, adds it to the solution and removes its neighbors, until the remaining graph is empty. The approximation ratios of this algorithm have been widely studied, where it is augmented with an advice that tells the greedy algorithm which minimum degree vertex to choose if it is not unique. Our main contribution is a new mathematical theory for the design of such greedy algorithms for MIS with efficiently computable advice and for the analysis of their approximation ratios. Using this theory we obtain the ultimate approximation ratio of 5/4 for greedy algorithms on graphs with maximum degree 3, which completely solves an open problem from the paper by Halldórsson and Yoshihara (in: Staples, Eades, Katoh, Moffat (eds) Algorithms and computations—ISAAC ’95, in 2026 LNCS, Springer, Berlin, Heidelberg, 1995) . Our algorithm is the fastest currently known algorithm for MIS with this approximation ratio on such graphs. We also obtain a simple and short proof of the $$(\Delta +2)/3$$ -approximation ratio of any greedy algorithms on graphs with maximum degree $$\Delta $$ , the result proved previously by Halldórsson and Radhakrishnan (Nord J Comput 1:475–492, 1994) . We almost match this ratio by showing a lower bound of $$(\Delta +1)/3$$ on the ratio of a greedy algorithm that can use an advice. We apply our new algorithm to the minimum vertex cover problem on graphs with maximum degree 3 to obtain a substantially faster 6/5-approximation algorithm than the one currently known. We complement our algorithmic, upper bound results with lower bound results, which show that the problem of designing good advice for greedy algorithms for MIS is computationally hard and even hard to approximate on various classes of graphs. These results significantly improve on the previously known hardness results. Moreover, these results suggest that obtaining the upper bound results on the design and analysis of the greedy advice is non-trivial.},
  archive      = {J_Alg},
  author       = {Krysta, Piotr and Mari, Mathieu and Zhi, Nan},
  doi          = {10.1007/s00453-024-01268-7},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3518-3578},
  shortjournal = {Algorithmica},
  title        = {Ultimate greedy approximation of independent sets in subcubic graphs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Testing connectedness of images. <em>Alg</em>,
<em>86</em>(11), 3496–3517. (<a
href="https://doi.org/10.1007/s00453-024-01248-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate algorithms for testing whether an image is connected. Given a proximity parameter $${\epsilon }\in (0,1)$$ and query access to a black-and-white image represented by an $$n\times n$$ matrix of Boolean pixel values, a (1-sided error) connectedness tester accepts if the image is connected and rejects with probability at least 2/3 if the image is $${\epsilon }$$ -far from connected. We show that connectedness can be tested nonadaptively with $$O\Big (\frac{1}{{\epsilon }^2}\Big )$$ queries and adaptively with $$O\Big (\frac{1}{{\epsilon }^{3/2}} \sqrt{\log \frac{1}{{\epsilon }}}\Big )$$ queries. The best connectedness tester to date, by Berman, Raskhodnikova, and Yaroslavtsev (STOC 2014) had query complexity $$O\Big (\frac{1}{{\epsilon }^2}\log \frac{1}{{\epsilon }}\Big )$$ and was adaptive. We also prove that every nonadaptive, 1-sided error tester for connectedness must make $$\Omega \Big (\frac{1}{{\epsilon }}\log \frac{1}{{\epsilon }}\Big )$$ queries.},
  archive      = {J_Alg},
  author       = {Berman, Piotr and Murzabulatov, Meiram and Raskhodnikova, Sofya and Ristache, Dragos-Florian},
  doi          = {10.1007/s00453-024-01248-x},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3496-3517},
  shortjournal = {Algorithmica},
  title        = {Testing connectedness of images},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Romeo and juliet meeting in forest like regions.
<em>Alg</em>, <em>86</em>(11), 3465–3495. (<a
href="https://doi.org/10.1007/s00453-024-01264-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The game of rendezvous with adversaries is a game on a graph played by two players: Facilitator and Divider. Facilitator has two agents and Divider has a team of $$k \ge 1$$ agents. While the initial positions of Facilitator’s agents are fixed, Divider gets to select the initial positions of his agents. Then, they take turns to move their agents to adjacent vertices (or stay put) with Facilitator’s goal to bring both her agents at same vertex and Divider’s goal to prevent it. The computational question of interest is to determine if Facilitator has a winning strategy against Divider with k agents. Fomin, Golovach, and Thilikos [WG, 2021] introduced this game and proved that it is PSPACE-hard and co-W[2]-hard parameterized by the number of agents. This hardness naturally motivates the structural parameterization of the problem. The authors proved that it admits an FPT algorithm when parameterized by the modular width and the number of allowed rounds. However, they left open the complexity of the problem from the perspective of other structural parameters. In particular, they explicitly asked whether the problem admits an FPT or XP-algorithm with respect to the treewidth of the input graph. We answer this question in the negative and show that Rendezvous is co-NP-hard even for graphs of constant treewidth. Further, we show that the problem is co-W[1]-hard when parameterized by the feedback vertex set number and the number of agents, and is unlikely to admit a polynomial kernel when parameterized by the vertex cover number and the number of agents. Complementing these hardness results, we show that the Rendezvous is FPT when parameterized by both the vertex cover number and the solution size. Finally, for graphs of treewidth at most two and girds, we show that the problem can be solved in polynomial time.},
  archive      = {J_Alg},
  author       = {Misra, Neeldhara and Mulpuri, Manas and Tale, Prafullkumar and Viramgami, Gaurav},
  doi          = {10.1007/s00453-024-01264-x},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3465-3495},
  shortjournal = {Algorithmica},
  title        = {Romeo and juliet meeting in forest like regions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Connected k-center and k-diameter clustering. <em>Alg</em>,
<em>86</em>(11), 3425–3464. (<a
href="https://doi.org/10.1007/s00453-024-01266-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by an application from geodesy, we study the connected k-center problem and the connected k-diameter problem. The former problem has been introduced by Ge et al. (ACM Trans Knowl Discov Data 2(2):1–35, 2008. https://doi.org/10.1145/1376815.1376816 ) to model clustering of data sets with both attribute and relationship data. These problems arise from the classical k-center and k-diameter problems by adding a side constraint. For the side constraint, we are given an undirected connectivity graph G on the input points, and a clustering is now only feasible if every cluster induces a connected subgraph in G. Usually in clustering problems one assumes that the clusters are pairwise disjoint. We study this case but additionally also the case that clusters are allowed to be non-disjoint. This can help to satisfy the connectivity constraints. Our main result is an $$O(\log ^2k)$$ -approximation algorithm for the disjoint connected k-center and k-diameter problem. For Euclidean spaces of constant dimension and for metrics with constant doubling dimension, the approximation factor improves to O(1). Our algorithm works by computing a non-disjoint connected clustering first and transforming it into a disjoint connected clustering. We complement these upper bounds by several upper and lower bounds for variations and special cases of the model.},
  archive      = {J_Alg},
  author       = {Drexler, Lukas and Eube, Jan and Luo, Kelin and Reineccius, Dorian and Röglin, Heiko and Schmidt, Melanie and Wargalla, Julian},
  doi          = {10.1007/s00453-024-01266-9},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3425-3464},
  shortjournal = {Algorithmica},
  title        = {Connected k-center and k-diameter clustering},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Algorithmic meta-theorems for combinatorial reconfiguration
revisited. <em>Alg</em>, <em>86</em>(11), 3395–3424. (<a
href="https://doi.org/10.1007/s00453-024-01261-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph and two vertex sets satisfying a certain feasibility condition, a reconfiguration problem asks whether we can reach one vertex set from the other by repeating prescribed modification steps while maintaining feasibility. In this setting, as reported by Mouawad et al. (IPEC, Springer, Berlin, 2014) presented an algorithmic meta-theorem for reconfiguration problems that says if the feasibility can be expressed in monadic second-order logic (MSO), then the problem is fixed-parameter tractable parameterized by $$\text {treewidth} + \ell $$ , where $$\ell $$ is the number of steps allowed to reach the target set. On the other hand, it is shown by Wrochna (J Comput Syst Sci 93:1–10, 2018). https://doi.org/10.1016/j.jcss.2017.11.003 ) that if $$\ell $$ is not part of the parameter, then the problem is PSPACE-complete even on graphs of constant bandwidth. In this paper, we present the first algorithmic meta-theorems for the case where $$\ell $$ is not part of the parameter, using some structural graph parameters incomparable with bandwidth. We show that if the feasibility is defined in MSO, then the reconfiguration problem under the so-called token jumping rule is fixed-parameter tractable parameterized by neighborhood diversity. We also show that the problem is fixed-parameter tractable parameterized by $$\text {treedepth} + k$$ , where k is the size of sets being transformed. We finally complement the positive result for treedepth by showing that the problem is PSPACE-complete on forests of depth 3.},
  archive      = {J_Alg},
  author       = {Gima, Tatsuya and Ito, Takehiro and Kobayashi, Yasuaki and Otachi, Yota},
  doi          = {10.1007/s00453-024-01261-0},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3395-3424},
  shortjournal = {Algorithmica},
  title        = {Algorithmic meta-theorems for combinatorial reconfiguration revisited},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for adversarial streaming via differential
privacy and difference estimators. <em>Alg</em>, <em>86</em>(11),
3339–3394. (<a
href="https://doi.org/10.1007/s00453-024-01259-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical streaming algorithms operate under the (not always reasonable) assumption that the input stream is fixed in advance. Recently, there is a growing interest in designing robust streaming algorithms that provide provable guarantees even when the input stream is chosen adaptively as the execution progresses. We propose a new framework for robust streaming that combines techniques from two recently suggested frameworks by Hassidim et al. (NeurIPS 2020) and by Woodruff and Zhou (FOCS 2021). These recently suggested frameworks rely on very different ideas, each with its own strengths and weaknesses. We combine these two frameworks into a single hybrid framework that obtains the “best of both worlds”, thereby solving a question left open by Woodruff and Zhou.},
  archive      = {J_Alg},
  author       = {Attias, Idan and Cohen, Edith and Shechner, Moshe and Stemmer, Uri},
  doi          = {10.1007/s00453-024-01259-8},
  journal      = {Algorithmica},
  month        = {11},
  number       = {11},
  pages        = {3339-3394},
  shortjournal = {Algorithmica},
  title        = {A framework for adversarial streaming via differential privacy and difference estimators},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reconfiguring shortest paths in graphs. <em>Alg</em>,
<em>86</em>(10), 3309–3338. (<a
href="https://doi.org/10.1007/s00453-024-01263-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfiguring two shortest paths in a graph means modifying one shortest path to the other by changing one vertex at a time so that all the intermediate paths are also shortest paths. This problem has several natural applications, namely: (a) repaving road networks, (b) rerouting data packets in a synchronous multiprocessing setting, (c) the shipping container stowage problem, and (d) the train marshalling problem. When modelled as graph problems, (a) is the most general case while (b), (c), (d) are restrictions to different graph classes. We show that (a) does not admit polynomial-time algorithms (assuming $${{\,\mathrm{\texttt {P}}\,}}\ne {{\,\mathrm{\texttt {NP}}\,}}$$ ), even for relaxed variants of the problem (assuming $${{\,\mathrm{\texttt {P}}\,}}\ne {{\,\mathrm{\texttt {PSPACE}}\,}}$$ ). For (b), (c), (d), we present polynomial-time algorithms to solve the respective problems. We also generalize the problem to when at most k (for a fixed integer $$k\ge 2$$ ) contiguous vertices on a shortest path can be changed at a time.},
  archive      = {J_Alg},
  author       = {Gajjar, Kshitij and Jha, Agastya Vibhuti and Kumar, Manish and Lahiri, Abhiruk},
  doi          = {10.1007/s00453-024-01263-y},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3309-3338},
  shortjournal = {Algorithmica},
  title        = {Reconfiguring shortest paths in graphs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterized complexity of reconfiguration of atoms.
<em>Alg</em>, <em>86</em>(10), 3284–3308. (<a
href="https://doi.org/10.1007/s00453-024-01262-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our work is motivated by the challenges presented in preparing arrays of atoms for use in quantum simulation. The recently-developed process of loading atoms into traps results in approximately half of the traps being filled. To consolidate the atoms so that they form a dense and regular arrangement, such as all locations in a grid, atoms are rearranged using moving optical tweezers. Time is of the essence, as the longer that the process takes and the more that atoms are moved, the higher the chance that atoms will be lost in the process. Viewed as a problem on graphs, we wish to solve the problem of reconfiguring one arrangement of tokens (representing atoms) to another using as few moves as possible. Because the problem is NP-complete on general graphs as well as on grids, we focus on the parameterized complexity for various parameters, considering both undirected and directed graphs, and tokens with and without labels. For unlabelled tokens, the problem is fixed-parameter tractable when parameterized by the number of tokens, the number of moves, or the number of moves plus the number of vertices without tokens in either the source or target configuration, but intractable when parameterized by the difference between the number of moves and the number of differences in the placement of tokens in the source and target configurations. When labels are added to tokens, however, most of the tractability results are replaced by hardness results.},
  archive      = {J_Alg},
  author       = {Cooper, Alexandre and Maaz, Stephanie and Mouawad, Amer E. and Nishimura, Naomi},
  doi          = {10.1007/s00453-024-01262-z},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3284-3308},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of reconfiguration of atoms},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Runtime analysis of quality diversity algorithms.
<em>Alg</em>, <em>86</em>(10), 3252–3283. (<a
href="https://doi.org/10.1007/s00453-024-01254-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality diversity (QD) is a branch of evolutionary computation that gained increasing interest in recent years. The Map-Elites QD approach defines a feature space, i.e., a partition of the search space, and stores the best solution for each cell of this space. We study a simple QD algorithm in the context of pseudo-Boolean optimisation on the “number of ones” feature space, where the ith cell stores the best solution amongst those with a number of ones in $$[(i-1)k, ik-1]$$ . Here k is a granularity parameter $$1 \le k \le n+1$$ . We give a tight bound on the expected time until all cells are covered for arbitrary fitness functions and for all k and analyse the expected optimisation time of QD on OneMax and other problems whose structure aligns favourably with the feature space. On combinatorial problems we show that QD finds a $${(1-1/e)}$$ -approximation when maximising any monotone sub-modular function with a single uniform cardinality constraint efficiently. Defining the feature space as the number of connected components of an edge-weighted graph, we show that QD finds a minimum spanning forest in expected polynomial time. We further consider QD’s performance on classes of transformed functions in which the feature space is not well aligned with the problem. The asymptotic performance is unaffected by transformations on easy functions like OneMax. Applying a worst-case transformation to a deceptive problem increases the expected optimisation time from $$O(n^2 \log n)$$ to an exponential time. However, QD is still faster than a (1+1) EA by an exponential factor.},
  archive      = {J_Alg},
  author       = {Bossek, Jakob and Sudholt, Dirk},
  doi          = {10.1007/s00453-024-01254-z},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3252-3283},
  shortjournal = {Algorithmica},
  title        = {Runtime analysis of quality diversity algorithms},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the parameterized complexity of bend-minimum orthogonal
planarity. <em>Alg</em>, <em>86</em>(10), 3231–3251. (<a
href="https://doi.org/10.1007/s00453-024-01260-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing planar orthogonal drawings with the minimum number of bends is one of the most studied topics in Graph Drawing. The problem is known to be NP-hard, even when we want to test the existence of a rectilinear planar drawing, i.e., an orthogonal drawing without bends (Garg and Tamassia in SIAM J Comput 31(2):601–625, 2001). From the parameterized complexity perspective, the problem is fixed-parameter tractable when parameterized by the sum of three parameters: the number b of bends, the number k of vertices of degree at most two, and the treewidth $$\textsf{tw}$$ of the input graph (Di Giacomo et al. in J Comput Syst Sci 125:129–148, 2022). We improve this last result by showing that the problem remains fixed-parameter tractable when parameterized only by $$b+k$$ . As a consequence, rectilinear planarity testing lies in FPT parameterized by the number of vertices of degree at most two. We also prove that our choice of parameters is minimal, as deciding if an orthogonal drawing with at most b bends exists is already NP-hard when k is zero (i.e., the problem is para-NP-hard parameterized in k); hence, there is neither an FPT nor an XP algorithm parameterized only by the parameter k (unless P = NP). In addition, we prove that the problem is W[1]-hard parameterized by $$k+\textsf{tw}$$ , complementing a recent result (Jansen et al. in Upward and orthogonal planarity are W[1]-hard parameterized by treewidth. CoRR, abs/2309.01264, 2023; in: Bekos MA, Chimani M (eds) Graph Drawing and Network Visualization, vol 14466, Springer, Cham, pp 203–217, 2023) that shows W[1]-hardness for the parameterization $$b+\textsf{tw}$$ . As a consequence, we are able to trace a clear parameterized tractability landscape for the bend-minimum orthogonal planarity problem with respect to the three parameters b, k, and $$\textsf{tw}$$ .},
  archive      = {J_Alg},
  author       = {Di Giacomo, Emilio and Didimo, Walter and Liotta, Giuseppe and Montecchiani, Fabrizio and Ortali, Giacomo},
  doi          = {10.1007/s00453-024-01260-1},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3231-3251},
  shortjournal = {Algorithmica},
  title        = {On the parameterized complexity of bend-minimum orthogonal planarity},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The complexity of finding and enumerating optimal subgraphs
to represent spatial correlation. <em>Alg</em>, <em>86</em>(10),
3186–3230. (<a
href="https://doi.org/10.1007/s00453-024-01256-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding spatial correlation is vital in many fields including epidemiology and social science. Lee et al. (Stat Comput 31(4):51, 2021. https://doi.org/10.1007/s11222-021-10025-7 ) recently demonstrated that improved inference for areal unit count data can be achieved by carrying out modifications to a graph representing spatial correlations; specifically, they delete edges of the planar graph derived from border-sharing between geographic regions in order to maximise a specific objective function. In this paper, we address the computational complexity of the associated graph optimisation problem. We demonstrate that this optimisation problem is NP-hard; we further show intractability for two simpler variants of the problem. We follow these results with two parameterised algorithms that exactly solve the problem. The first is parameterised by both treewidth and maximum degree, while the second is parameterised by the maximum number of edges that can be removed and is also restricted to settings where the input graph has maximum degree three. Both of these algorithms solve not only the decision problem, but also enumerate all solutions with polynomial time precalculation, delay, and postcalculation time in respective restricted settings. For this problem, efficient enumeration allows the uncertainty in the spatial correlation to be utilised in the modelling. The first enumeration algorithm utilises dynamic programming on a tree decomposition of the input graph, and has polynomial time precalculation and linear delay if both the treewidth and maximum degree are bounded. The second algorithm is restricted to problem instances with maximum degree three, as may arise from triangulations of planar surfaces, but can output all solutions with FPT precalculation time and linear delay when the maximum number of edges that can be removed is taken as the parameter.},
  archive      = {J_Alg},
  author       = {Enright, Jessica and Lee, Duncan and Meeks, Kitty and Pettersson, William and Sylvester, John},
  doi          = {10.1007/s00453-024-01256-x},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3186-3230},
  shortjournal = {Algorithmica},
  title        = {The complexity of finding and enumerating optimal subgraphs to represent spatial correlation},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Limitations of the impagliazzo–nisan–wigderson pseudorandom
generator against permutation branching programs. <em>Alg</em>,
<em>86</em>(10), 3153–3185. (<a
href="https://doi.org/10.1007/s00453-024-01251-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classic Impagliazzo–Nisan–Wigderson (INW) pseudorandom generator (PRG) (STOC ‘94) for space-bounded computation uses a seed of length $$O(\log n \cdot \log (nw/\varepsilon )+\log d)$$ to fool ordered branching programs of length n, width w, and alphabet size d to within error $$\varepsilon $$ . A series of works have shown that the analysis of the INW generator can be improved for the class of permutation branching programs or the more general regular branching programs, improving the $$O(\log ^2 n)$$ dependence on the length n to $$O(\log n)$$ or $${\tilde{O}}(\log n)$$ . However, when also considering the dependence on the other parameters, these analyses still fall short of the optimal PRG seed length $$O(\log (nwd/\varepsilon ))$$ . In this paper, we prove that any “spectral analysis” of the INW generator requires seed length $$\begin{aligned} \Omega \left( \log n\cdot \log \log \left( \min \{n,d\}\right) +\log n\cdot \log \left( w/\varepsilon \right) +\log d\right) \end{aligned}$$ to fool ordered permutation branching programs of length n, width w, and alphabet size d to within error $$\varepsilon $$ . By “spectral analysis” we mean an analysis of the INW generator that relies only on the spectral expansion of the graphs used to construct the generator; this encompasses all prior analyses of the INW generator. Our lower bound matches the upper bound of Braverman–Rao–Raz–Yehudayoff (FOCS 2010, SICOMP 2014) for regular branching programs of alphabet size $$d=2$$ except for a gap between their $$O\left( \log n \cdot \log \log n\right) $$ term and our $$\Omega \left( \log n \cdot \log \log \min \{n,d\}\right) $$ term. It also matches the upper bounds of Koucký–Nimbhorkar–Pudlák (STOC 2011), De (CCC 2011), and Steinke (ECCC 2012) for constant-width ( $$w=O(1)$$ ) permutation branching programs of alphabet size $$d=2$$ to within a constant factor. To fool permutation branching programs in the measure of spectral norm, we prove that any spectral analysis of the INW generator requires a seed of length $$\Omega \left( \log n\cdot \log \log n+\log n\cdot \log (1/\varepsilon )\right) $$ when the width is at least polynomial in n ( $$w=n^{\Omega (1)}$$ ), matching the recent upper bound of Hoza–Pyne–Vadhan (ITCS 2021) to within a constant factor.},
  archive      = {J_Alg},
  author       = {Hoza, William M. and Pyne, Edward and Vadhan, Salil},
  doi          = {10.1007/s00453-024-01251-2},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3153-3185},
  shortjournal = {Algorithmica},
  title        = {Limitations of the Impagliazzo–Nisan–Wigderson pseudorandom generator against permutation branching programs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tight runtime bounds for static unary unbiased evolutionary
algorithms on linear functions. <em>Alg</em>, <em>86</em>(10),
3115–3152. (<a
href="https://doi.org/10.1007/s00453-024-01258-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a seminal paper in 2013, Witt showed that the (1+1) Evolutionary Algorithm with standard bit mutation needs time $$(1+o(1))n \ln n/p_1$$ to find the optimum of any linear function, as long as the probability $$p_1$$ to flip exactly one bit is $$\Theta (1)$$ . In this paper we investigate how this result generalizes if standard bit mutation is replaced by an arbitrary unbiased mutation operator. This situation is notably different, since the stochastic domination argument used for the lower bound by Witt no longer holds. In particular, starting closer to the optimum is not necessarily an advantage, and OneMax is no longer the easiest function for arbitrary starting positions. Nevertheless, we show that Witt’s result carries over if $$p_1$$ is not too small, with different constraints for upper and lower bounds, and if the number of flipped bits has bounded expectation $$\chi $$ . Notably, this includes some of the heavy-tail mutation operators used in fast genetic algorithms, but not all of them. We also give examples showing that algorithms with unbounded $$\chi $$ have qualitatively different trajectories close to the optimum.},
  archive      = {J_Alg},
  author       = {Doerr, Carola and Janett, Duri Andrea and Lengler, Johannes},
  doi          = {10.1007/s00453-024-01258-9},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3115-3152},
  shortjournal = {Algorithmica},
  title        = {Tight runtime bounds for static unary unbiased evolutionary algorithms on linear functions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing energy consumption for real-time tasks on
heterogeneous platforms under deadline and reliability constraints.
<em>Alg</em>, <em>86</em>(10), 3079–3114. (<a
href="https://doi.org/10.1007/s00453-024-01253-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As real-time systems are safety critical, guaranteeing a high reliability threshold is as important as meeting all deadlines. Periodic tasks are replicated to mitigate the negative impact of transient faults, which leads to redundancy and high energy consumption. On the other hand, energy saving is widely identified as increasingly relevant issues in real-time systems. In this paper, we formalize this challenging tri-criteria optimization problem, i.e., minimizing the expected energy consumption while enforcing the reliability threshold and meeting all task deadlines, and propose several mapping and scheduling heuristics to solve it. Specifically, a novel approach is designed to (i) map an arbitrary number of replicas onto processors, (ii) schedule each replica of each task instance on its assigned processor with less temporal overlap. The platform is composed of processing units with different characteristics, including speed profile, energy cost and fault rate. The heterogeneity of the computing platform makes the problem more complicated, because different mappings achieve different levels of reliability and consume different amounts of energy. Moreover, scheduling plays an important role in energy saving, as the expected energy consumption is the average over all failure scenarios. Once a task replica is successful, the other replicas of that task instance can be canceled, which calls for minimizing the overlap between any replica pair. Finally, to quantitatively analyze our methods, we derive a theoretical lower-bound for the expected energy consumption. Comprehensive experiments are conducted on a large set of execution scenarios and parameters. The comparison results reveal that our strategies perform better than the random baseline under almost all settings, with an average gain in energy consumption of more than 40%, and our best heuristic achieves an excellent performance: its energy saving is only 2% less than the lower-bound on average.},
  archive      = {J_Alg},
  author       = {Gao, Yiqin and Han, Li and Liu, Jing and Robert, Yves and Vivien, Frédéric},
  doi          = {10.1007/s00453-024-01253-0},
  journal      = {Algorithmica},
  month        = {10},
  number       = {10},
  pages        = {3079-3114},
  shortjournal = {Algorithmica},
  title        = {Minimizing energy consumption for real-time tasks on heterogeneous platforms under deadline and reliability constraints},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On a traveling salesman problem for points in the unit cube.
<em>Alg</em>, <em>86</em>(9), 3054–3078. (<a
href="https://doi.org/10.1007/s00453-024-01257-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let X be an n-element point set in the k-dimensional unit cube $$[0,1]^k$$ where $$k \ge 2$$ . According to an old result of Bollobás and Meir (Oper Res Lett 11:19–21, 1992) , there exists a cycle (tour) $$x_1, x_2, \ldots , x_n$$ through the n points, such that $$\left( \sum _{i=1}^n |x_i - x_{i+1}|^k \right) ^{1/k} \le c_k$$ , where $$|x-y|$$ is the Euclidean distance between x and y, and $$c_k$$ is an absolute constant that depends only on k, where $$x_{n+1} \equiv x_1$$ . From the other direction, for every $$k \ge 2$$ and $$n \ge 2$$ , there exist n points in $$[0,1]^k$$ , such that their shortest tour satisfies $$\left( \sum _{i=1}^n |x_i - x_{i+1}|^k \right) ^{1/k} = 2^{1/k} \cdot \sqrt{k}$$ . For the plane, the best constant is $$c_2=2$$ and this is the only exact value known. Bollobás and Meir showed that one can take $$c_k = 9 \left( \frac{2}{3} \right) ^{1/k} \cdot \sqrt{k}$$ for every $$k \ge 3$$ and conjectured that the best constant is $$c_k = 2^{1/k} \cdot \sqrt{k}$$ , for every $$k \ge 2$$ . Here we significantly improve the upper bound and show that one can take $$c_k = 3 \sqrt{5} \left( \frac{2}{3} \right) ^{1/k} \cdot \sqrt{k}$$ or $$c_k = 2.91 \sqrt{k} \ (1+o_k(1))$$ . Our bounds are constructive. We also show that $$c_3 \ge 2^{7/6}$$ , which disproves the conjecture for $$k=3$$ . Connections to matching problems, power assignment problems, related problems, including algorithms, are discussed in this context. A slightly revised version of the Bollobás–Meir conjecture is proposed.},
  archive      = {J_Alg},
  author       = {Balogh, József and Clemen, Felix Christian and Dumitrescu, Adrian},
  doi          = {10.1007/s00453-024-01257-w},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {3054-3078},
  shortjournal = {Algorithmica},
  title        = {On a traveling salesman problem for points in the unit cube},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-crossing hamiltonian paths and cycles in
output-polynomial time. <em>Alg</em>, <em>86</em>(9), 3027–3053. (<a
href="https://doi.org/10.1007/s00453-024-01255-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that, for planar point sets, the number of non-crossing Hamiltonian paths is polynomially bounded in the number of non-crossing paths, and the number of non-crossing Hamiltonian cycles (polygonalizations) is polynomially bounded in the number of surrounding cycles. As a consequence, we can list the non-crossing Hamiltonian paths or the polygonalizations, in time polynomial in the output size, by filtering the output of simple backtracking algorithms for non-crossing paths or surrounding cycles respectively. We do not assume that the points are in general position. To prove these results we relate the numbers of non-crossing structures to two easily-computed parameters of the point set: the minimum number of points whose removal results in a collinear set, and the number of points interior to the convex hull. These relations also lead to polynomial-time approximation algorithms for the numbers of structures of all four types, accurate to within a constant factor of the logarithm of these numbers.},
  archive      = {J_Alg},
  author       = {Eppstein, David},
  doi          = {10.1007/s00453-024-01255-y},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {3027-3053},
  shortjournal = {Algorithmica},
  title        = {Non-crossing hamiltonian paths and cycles in output-polynomial time},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New partitioning techniques and faster algorithms for
approximate interval scheduling. <em>Alg</em>, <em>86</em>(9),
2997–3026. (<a
href="https://doi.org/10.1007/s00453-024-01252-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval scheduling is a basic algorithmic problem and a classical task in combinatorial optimization. We develop techniques for partitioning and grouping jobs based on their starting/ending times, enabling us to view an instance of interval scheduling on many jobs as a union of multiple interval scheduling instances, each containing only a few jobs. Instantiating these techniques in a dynamic setting produces several new results. For $$(1+\varepsilon )$$ -approximation of job scheduling of n jobs on a single machine, we develop a fully dynamic algorithm with $$O(\nicefrac {\log {n}}{\varepsilon })$$ update and $$O(\log {n})$$ query worst-case time. Our techniques are also applicable in a setting where jobs have weights. We design a fully dynamic deterministic algorithm whose worst-case update and query times are $$\text {poly} (\log n,\frac{1}{\varepsilon })$$ . This is the first algorithm that maintains a $$(1+\varepsilon )$$ -approximation of the maximum independent set of a collection of weighted intervals in $$\text {poly} (\log n,\frac{1}{\varepsilon })$$ time updates/queries. This is an exponential improvement in $$1/\varepsilon $$ over the running time of an algorithm of Henzinger, Neumann, and Wiese  [SoCG, 2020]. Our approach also removes all dependence on the values of the jobs’ starting/ending times and weights.},
  archive      = {J_Alg},
  author       = {Compton, Spencer and Mitrović, Slobodan and Rubinfeld, Ronitt},
  doi          = {10.1007/s00453-024-01252-1},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2997-3026},
  shortjournal = {Algorithmica},
  title        = {New partitioning techniques and faster algorithms for approximate interval scheduling},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sublinear algorithms in t-interval dynamic networks.
<em>Alg</em>, <em>86</em>(9), 2959–2996. (<a
href="https://doi.org/10.1007/s00453-024-01250-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider standard T-interval dynamic networks, under the synchronous timing model and the broadcast CONGEST model. In a T-interval dynamic network, the set of nodes is always fixed and there are no node failures. The edges in the network are always undirected, but the set of edges in the topology may change arbitrarily from round to round, as determined by some adversary and subject to the following constraint: For every T consecutive rounds, the topologies in those rounds must contain a common connected spanning subgraph. Let $$H_r$$ to be the maximum (in terms of number of edges) such subgraph for round r through $$r+T-1$$ . We define the backbone diameter d of a T-interval dynamic network to be the maximum diameter of all such $$H_r$$ ’s, for $$r\ge 1$$ . We use n to denote the number of nodes in the network. Within such a context, we consider a range of fundamental distributed computing problems including Count/Max/Median/Sum/LeaderElect/Consensus/ConfirmedFlood. Existing algorithms for these problems all have time complexity of $$\Omega (n)$$ rounds, even for $$T=\infty $$ and even when d is as small as O(1). This paper presents a novel approach/framework, based on the idea of massively parallel aggregation. Following this approach, we develop a novel deterministic Count algorithm with $$O(d^3 \log ^2 n)$$ complexity, for T-interval dynamic networks with $$T \ge c\cdot d^2 \log ^2n$$ . Here c is a (sufficiently large) constant independent of d, n, and T. To our knowledge, our algorithm is the very first such algorithm whose complexity does not contain a $$\Theta (n)$$ term. This paper further develops novel algorithms for solving Max/Median/Sum/LeaderElect/Consensus/ConfirmedFlood, while incurring $$O(d^3 \text{ polylog }(n))$$ complexity. Again, for all these problems, our algorithms are the first ones whose time complexity does not contain a $$\Theta (n)$$ term.},
  archive      = {J_Alg},
  author       = {Jahja, Irvan and Yu, Haifeng},
  doi          = {10.1007/s00453-024-01250-3},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2959-2996},
  shortjournal = {Algorithmica},
  title        = {Sublinear algorithms in T-interval dynamic networks},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stagnation detection in highly multimodal fitness
landscapes. <em>Alg</em>, <em>86</em>(9), 2929–2958. (<a
href="https://doi.org/10.1007/s00453-024-01249-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stagnation detection has been proposed as a mechanism for randomized search heuristics to escape from local optima by automatically increasing the size of the neighborhood to find the so-called gap size, i. e., the distance to the next improvement. Its usefulness has mostly been considered in simple multimodal landscapes with few local optima that could be crossed one after another. In multimodal landscapes with a more complex location of optima of similar gap size, stagnation detection suffers from the fact that the neighborhood size is frequently reset to  1 without using gap sizes that were promising in the past. In this paper, we investigate a new mechanism called radius memory which can be added to stagnation detection to control the search radius more carefully by giving preference to values that were successful in the past. We implement this idea in an algorithm called SD-RLS $$^{\text {m}}$$ and show compared to previous variants of stagnation detection that it yields speed-ups for linear functions under uniform constraints and the minimum spanning tree problem. Moreover, its running time does not significantly deteriorate on unimodal functions and a generalization of the Jump benchmark. Finally, we present experimental results carried out to study SD-RLS $$^{\text {m}}$$ and compare it with other algorithms.},
  archive      = {J_Alg},
  author       = {Rajabi, Amirhossein and Witt, Carsten},
  doi          = {10.1007/s00453-024-01249-w},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2929-2958},
  shortjournal = {Algorithmica},
  title        = {Stagnation detection in highly multimodal fitness landscapes},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterized complexity of streaming diameter and
connectivity problems. <em>Alg</em>, <em>86</em>(9), 2885–2928. (<a
href="https://doi.org/10.1007/s00453-024-01246-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the investigation of the parameterized complexity of Diameter and Connectivity in the streaming paradigm. On the positive end, we show that knowing a vertex cover of size k allows for algorithms in the Adjacency List (AL) streaming model whose number of passes is constant and memory is $$\mathcal {O}(\log n)$$ for any fixed k. Underlying these algorithms is a method to execute a breadth-first search in $$\mathcal {O}(k)$$ passes and $$\mathcal {O}(k \log n)$$ bits of memory. On the negative end, we show that many other parameters lead to lower bounds in the AL model, where $$\Omega (n/p)$$ bits of memory is needed for any p-pass algorithm even for constant parameter values. In particular, this holds for graphs with a known modulator (deletion set) of constant size to a graph that has no induced subgraph isomorphic to a fixed graph H, for most H. For some cases, we can also show one-pass, $$\Omega (n \log n)$$ bits of memory lower bounds. We also prove a much stronger $$\Omega (n^2/p)$$ lower bound for Diameter on bipartite graphs. Finally, using the insights we developed into streaming parameterized graph exploration algorithms, we show a new streaming kernelization algorithm for computing a vertex cover of size k. This yields a kernel of 2k vertices (with $$\mathcal {O}(k^2)$$ edges) produced as a stream in $$\text {poly}(k)$$ passes and only $$\mathcal {O}(k \log n)$$ bits of memory.},
  archive      = {J_Alg},
  author       = {Oostveen, Jelle J. and van Leeuwen, Erik Jan},
  doi          = {10.1007/s00453-024-01246-z},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2885-2928},
  shortjournal = {Algorithmica},
  title        = {Parameterized complexity of streaming diameter and connectivity problems},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation algorithms for the two-watchman route in a
simple polygon. <em>Alg</em>, <em>86</em>(9), 2845–2884. (<a
href="https://doi.org/10.1007/s00453-024-01245-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-watchman route problem is that of computing a pair of closed tours in an environment so that the two tours together see the whole environment and some length measure on the two tours is minimized. Two standard measures are: the minmax measure, where we want the tours where the longest of them has smallest length, and the minsum measure, where we want the tours for which the sum of their lengths is the smallest. It is known that computing a minmax two-watchman route is NP-hard for simple rectilinear polygons and thus also for simple polygons. Also, any c-approximation algorithm for the minmax two-watchman route is automatically a 2c-approximation algorithm for the minsum two-watchman route. We exhibit two constant factor approximation algorithms for computing minmax two-watchman routes in simple polygons with approximation factors 5.969 and 11.939, having running times $$O(n^8)$$ and $$O(n^4)$$ respectively, where n is the number of vertices of the polygon. We also use the same techniques to obtain a 6.922-approximation for the fixed two-watchman route problem running in $$O(n^2)$$ time, i.e., when two starting points of the two tours are given as input.},
  archive      = {J_Alg},
  author       = {Nilsson, Bengt J. and Packer, Eli},
  doi          = {10.1007/s00453-024-01245-0},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2845-2884},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithms for the two-watchman route in a simple polygon},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Algorithms for matrix multiplication via sampling and
opportunistic matrix multiplication. <em>Alg</em>, <em>86</em>(9),
2822–2844. (<a
href="https://doi.org/10.1007/s00453-024-01247-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As proposed by Karppa and Kaski (in: Proceedings 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), 2019) a novel “broken&quot; or &quot;opportunistic&quot; matrix multiplication algorithm, based on a variant of Strassen’s algorithm, and used this to develop new algorithms for Boolean matrix multiplication, among other tasks. Their algorithm can compute Boolean matrix multiplication in $$O(n^{2.778})$$ time. While asymptotically faster matrix multiplication algorithms exist, most such algorithms are infeasible for practical problems. We describe an alternative way to use the broken multiplication algorithm to approximately compute matrix multiplication, either for real-valued or Boolean matrices. In brief, instead of running multiple iterations of the broken algorithm on the original input matrix, we form a new larger matrix by sampling and run a single iteration of the broken algorithm on it. Asymptotically, our algorithm has runtime $$O(n^{2.763})$$ , a slight improvement over the Karppa–Kaski algorithm. Since the goal is to obtain new practical matrix-multiplication algorithms, we also estimate the concrete runtime for our algorithm for some large-scale sample problems. It appears that for these parameters, further optimizations are still needed to make our algorithm competitive.},
  archive      = {J_Alg},
  author       = {Harris, David G.},
  doi          = {10.1007/s00453-024-01247-y},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2822-2844},
  shortjournal = {Algorithmica},
  title        = {Algorithms for matrix multiplication via sampling and opportunistic matrix multiplication},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online unit profit knapsack with predictions. <em>Alg</em>,
<em>86</em>(9), 2786–2821. (<a
href="https://doi.org/10.1007/s00453-024-01239-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variant of the online knapsack problem is considered in the setting of predictions. In Unit Profit Knapsack, the items have unit profit, i.e., the goal is to pack as many items as possible. For Online Unit Profit Knapsack, the competitive ratio is unbounded. In contrast, it is easy to find an optimal solution offline: Pack as many of the smallest items as possible into the knapsack. The prediction available to the online algorithm is the average size of those smallest items that fit in the knapsack. For the prediction error in this hard online problem, we use the ratio $$r=\frac{a}{\hat{a}}$$ where a is the actual value for this average size and $$\hat{a}$$ is the prediction. We give an algorithm which is $$\frac{e-1}{e}$$ -competitive, if $$r=1$$ , and this is best possible among online algorithms knowing a and nothing else. More generally, the algorithm has a competitive ratio of $$\frac{e-1}{e}r$$ , if $$r \le 1$$ , and $$\frac{e-r}{e}r$$ , if $$1 \le r &lt; e$$ . Any algorithm with a better competitive ratio for some $$r&lt;1$$ will have a worse competitive ratio for some $$r&gt;1$$ . To obtain a positive competitive ratio for all r, we adjust the algorithm, resulting in a competitive ratio of $$\frac{1}{2r}$$ for $$r\ge 1$$ and $$\frac{r}{2}$$ for $$r\le 1$$ . We show that improving the result for any $$r&lt; 1$$ leads to a worse result for some $$r&gt;1$$ .},
  archive      = {J_Alg},
  author       = {Boyar, Joan and Favrholdt, Lene M. and Larsen, Kim S.},
  doi          = {10.1007/s00453-024-01239-y},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2786-2821},
  shortjournal = {Algorithmica},
  title        = {Online unit profit knapsack with predictions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate and randomized algorithms for computing a second
hamiltonian cycle. <em>Alg</em>, <em>86</em>(9), 2766–2785. (<a
href="https://doi.org/10.1007/s00453-024-01238-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the following problem: Given a Hamiltonian graph G, and a Hamiltonian cycle C of G, can we compute a second Hamiltonian cycle $$C^{\prime } \ne C$$ of G, and if yes, how quickly? If the input graph G satisfies certain conditions (e.g. if every vertex of G is odd, or if the minimum degree is large enough), it is known that such a second Hamiltonian cycle always exists. Despite substantial efforts, no subexponential-time algorithm is known for this problem. In this paper we relax the problem of computing a second Hamiltonian cycle in two ways. First, we consider approximating the length of a second longest cycle on n-vertex graphs with minimum degree $$\delta $$ and maximum degree $$\Delta $$ . We provide a linear-time algorithm for computing a cycle $$C^{\prime } \ne C$$ of length at least $$n-4\alpha (\sqrt{n}+2\alpha )+8$$ , where $$\alpha = \frac{\Delta -2}{\delta -2}$$ . This results provides a constructive proof of a recent result by Girão, Kittipassorn, and Narayanan in the regime of $$\frac{\Delta }{\delta } = o(\sqrt{n})$$ . Our second relaxation of the problem is probabilistic. We propose a randomized algorithm which computes a second Hamiltonian cycle with high probability, given that the input graph G has a large enough minimum degree. More specifically, we prove that for every $$0&lt;p\le 0.02$$ , if the minimum degree of G is at least $$\frac{8}{p} \log \sqrt{8}n + 4$$ , then a second Hamiltonian cycle can be computed with probability at least $$1 - \frac{1}{n}\left( \frac{50}{p^4} + 1 \right) $$ in $$poly(n) \cdot 2^{4pn}$$ time. This result implies that, when the minimum degree $$\delta $$ is sufficiently large, we can compute with high probability a second Hamiltonian cycle faster than any known deterministic algorithm. In particular, when $$\delta = \omega (\log n)$$ , our probabilistic algorithm works in $$2^{o(n)}$$ time.},
  archive      = {J_Alg},
  author       = {Deligkas, Argyrios and Mertzios, George B. and Spirakis, Paul G. and Zamaraev, Viktor},
  doi          = {10.1007/s00453-024-01238-z},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2766-2785},
  shortjournal = {Algorithmica},
  title        = {Approximate and randomized algorithms for computing a second hamiltonian cycle},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online geometric covering and piercing. <em>Alg</em>,
<em>86</em>(9), 2739–2765. (<a
href="https://doi.org/10.1007/s00453-024-01244-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the online version of the piercing set problem, where geometric objects arrive one by one, and the online algorithm must maintain a valid piercing set for the already arrived objects by making irrevocable decisions. It is easy to observe that any deterministic algorithm solving this problem for intervals in $$\mathbb {R}$$ has a competitive ratio of at least $$\Omega (n)$$ . This paper considers the piercing set problem for similarly sized objects. We propose a deterministic online algorithm for similarly sized fat objects in $$\mathbb {R}^d$$ . For homothetic hypercubes in $$\mathbb {R}^d$$ with side length in the range [1, k], we propose a deterministic algorithm having a competitive ratio of at most $$3^d\lceil \log _2 k\rceil +2^d$$ . In the end, we show deterministic lower bounds of the competitive ratio for similarly sized $$\alpha $$ -fat objects in $$\mathbb {R}^2$$ and homothetic hypercubes in $$\mathbb {R}^d$$ . Note that piercing translated copies of a convex object is equivalent to the unit covering problem, which is well-studied in the online setup. Surprisingly, no upper bound of the competitive ratio was known for the unit covering problem when the corresponding object is anything other than a ball or a hypercube. Our result yields an upper bound of the competitive ratio for the unit covering problem when the corresponding object is any convex object in $$\mathbb {R}^d$$ .},
  archive      = {J_Alg},
  author       = {De, Minati and Jain, Saksham and Kallepalli, Sarat Varma and Singh, Satyam},
  doi          = {10.1007/s00453-024-01244-1},
  journal      = {Algorithmica},
  month        = {9},
  number       = {9},
  pages        = {2739-2765},
  shortjournal = {Algorithmica},
  title        = {Online geometric covering and piercing},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Slim tree-cut width. <em>Alg</em>, <em>86</em>(8),
2714–2738. (<a
href="https://doi.org/10.1007/s00453-024-01241-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree-cut width is a parameter that has been introduced as an attempt to obtain an analogue of treewidth for edge cuts. Unfortunately, in spite of its desirable structural properties, it turned out that tree-cut width falls short as an edge-cut based alternative to treewidth in algorithmic aspects. This has led to the very recent introduction of a simple edge-based parameter called edge-cut width [WG 2022], which has precisely the algorithmic applications one would expect from an analogue of treewidth for edge cuts, but does not have the desired structural properties. In this paper, we study a variant of tree-cut width obtained by changing the threshold for so-called thin nodes in tree-cut decompositions from 2 to 1. We show that this “slim tree-cut width” satisfies all the requirements of an edge-cut based analogue of treewidth, both structural and algorithmic, while being less restrictive than edge-cut width. Our results also include an alternative characterization of slim tree-cut width via an easy-to-use spanning-tree decomposition akin to the one used for edge-cut width, a characterization of slim tree-cut width in terms of forbidden immersions as well as approximation algorithm for computing the parameter.},
  archive      = {J_Alg},
  author       = {Ganian, Robert and Korchemna, Viktoriia},
  doi          = {10.1007/s00453-024-01241-4},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2714-2738},
  shortjournal = {Algorithmica},
  title        = {Slim tree-cut width},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximating long cycle above dirac’s guarantee.
<em>Alg</em>, <em>86</em>(8), 2676–2713. (<a
href="https://doi.org/10.1007/s00453-024-01240-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterization above (or below) a guarantee is a successful concept in parameterized algorithms. The idea is that many computational problems admit “natural” guarantees bringing to algorithmic questions whether a better solution (above the guarantee) could be obtained efficiently. For example, for every boolean CNF formula on m clauses, there is an assignment that satisfies at least m/2 clauses. How difficult is it to decide whether there is an assignment satisfying more than $$m/2 +k$$ clauses? Or, if an n-vertex graph has a perfect matching, then its vertex cover is at least n/2. Is there a vertex cover of size at least $$n/2 +k$$ for some $$k\ge 1$$ and how difficult is it to find such a vertex cover? The above guarantee paradigm has led to several exciting discoveries in the areas of parameterized algorithms and kernelization. We argue that this paradigm could bring forth fresh perspectives on well-studied problems in approximation algorithms. Our example is the longest cycle problem. One of the oldest results in extremal combinatorics is the celebrated Dirac’s theorem from 1952. Dirac’s theorem provides the following guarantee on the length of the longest cycle: for every 2-connected n-vertex graph G with minimum degree $$\delta (G)\le n/2$$ , the length of a longest cycle L is at least $$2\delta (G)$$ . Thus the “essential” part in finding the longest cycle is in approximating the “offset” $$k = L - 2 \delta (G)$$ . The main result of this paper is the above-guarantee approximation theorem for k. Informally, the theorem says that approximating the offset k is not harder than approximating the total length L of a cycle. In other words, for any (reasonably well-behaved) function f, a polynomial time algorithm constructing a cycle of length f(L) in an undirected graph with a cycle of length L, yields a polynomial time algorithm constructing a cycle of length $$2\delta (G)+\Omega (f(k))$$ .},
  archive      = {J_Alg},
  author       = {Fomin, Fedor V. and Golovach, Petr A. and Sagunov, Danil and Simonov, Kirill},
  doi          = {10.1007/s00453-024-01240-5},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2676-2713},
  shortjournal = {Algorithmica},
  title        = {Approximating long cycle above dirac’s guarantee},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New algorithms for steiner tree reoptimization.
<em>Alg</em>, <em>86</em>(8), 2652–2675. (<a
href="https://doi.org/10.1007/s00453-024-01243-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reoptimization is a setting in which we are given a good approximate solution of an optimization problem instance and a local modification that slightly changes the instance. The main goal is that of finding a good approximate solution of the modified instance. We investigate one of the most studied scenarios in reoptimization known as Steiner tree reoptimization. Steiner tree reoptimization is a collection of strongly $$\textsf {NP}$$ -hard optimization problems that are defined on top of the classical Steiner tree problem and for which several constant-factor approximation algorithms have been designed in the last decades. In this paper we improve upon all these results by developing a novel technique that allows us to design polynomial-time approximation schemes. Remarkably, prior to this paper, no approximation algorithm better than recomputing a solution from scratch was known for the elusive scenario in which the cost of a single edge decreases. Our results are best possible since none of the problems addressed in this paper admits a fully polynomial-time approximation scheme, unless $$\textsf {P}=\textsf {NP}$$},
  archive      = {J_Alg},
  author       = {Bilò, Davide},
  doi          = {10.1007/s00453-024-01243-2},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2652-2675},
  shortjournal = {Algorithmica},
  title        = {New algorithms for steiner tree reoptimization},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation algorithms for covering vertices by long
paths. <em>Alg</em>, <em>86</em>(8), 2625–2651. (<a
href="https://doi.org/10.1007/s00453-024-01242-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph, the general problem to cover the maximum number of vertices by a collection of vertex-disjoint long paths seems to escape from the literature. A path containing at least k vertices is considered long. When $$k \le 3$$ , the problem is polynomial time solvable; when k is the total number of vertices, the problem reduces to the Hamiltonian path problem, which is NP-complete. For a fixed $$k \ge 4$$ , the problem is NP-hard and the best known approximation algorithm for the weighted set packing problem implies a k-approximation algorithm. To the best of our knowledge, there is no approximation algorithm directly designed for the general problem; when $$k = 4$$ , the problem admits a 4-approximation algorithm which was presented recently. We propose the first $$(0.4394 k + O(1))$$ -approximation algorithm for the general problem and an improved 2-approximation algorithm when $$k = 4$$ . Both algorithms are based on local improvement, and their theoretical performance analyses are done via amortization and their practical performance is examined through simulation studies.},
  archive      = {J_Alg},
  author       = {Gong, Mingyang and Edgar, Brett and Fan, Jing and Lin, Guohui and Miyano, Eiji},
  doi          = {10.1007/s00453-024-01242-3},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2625-2651},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithms for covering vertices by long paths},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parity permutation pattern matching. <em>Alg</em>,
<em>86</em>(8), 2605–2624. (<a
href="https://doi.org/10.1007/s00453-024-01237-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given two permutations, a pattern $$\sigma $$ and a text $$\pi $$ , Parity Permutation Pattern Matching asks whether there exists a parity and order preserving embedding of $$\sigma $$ into $$\pi $$ . While it is known that Permutation Pattern Matching is in $$\textsc {FPT}$$ , we show that adding the parity constraint to the problem makes it $$\textsc {W}[1]$$ -hard, even for alternating permutations or for 4321-avoiding patterns. However, the problem remains in $$\textsc {FPT}$$ if $$\pi $$ avoids a fixed permutation, thanks to a recent meta-theorem on twin-width. On the other hand, as for the classical version, Parity Permutation Pattern Matching remains polynomial-time solvable when the pattern is separable, or if both permutations are 321-avoiding, but NP-hard if $$\sigma $$ is 321-avoiding and $$\pi $$ is 4321-avoiding.},
  archive      = {J_Alg},
  author       = {Martínez, Virginia Ardévol and Sikora, Florian and Vialette, Stéphane},
  doi          = {10.1007/s00453-024-01237-0},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2605-2624},
  shortjournal = {Algorithmica},
  title        = {Parity permutation pattern matching},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved approximation algorithms by generalizing the
primal-dual method beyond uncrossable functions. <em>Alg</em>,
<em>86</em>(8), 2575–2604. (<a
href="https://doi.org/10.1007/s00453-024-01235-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address long-standing open questions raised by Williamson, Goemans, Vazirani and Mihail pertaining to the design of approximation algorithms for problems in network design via the primal-dual method (Williamson et al. in Combinatorica 15(3):435–454, 1995. https://doi.org/10.1007/BF01299747 ). Williamson et al. prove an approximation ratio of two for connectivity augmentation problems where the connectivity requirements can be specified by uncrossable functions. They state: “Extending our algorithm to handle non-uncrossable functions remains a challenging open problem. The key feature of uncrossable functions is that there exists an optimal dual solution which is laminar ... A larger open issue is to explore further the power of the primal-dual approach for obtaining approximation algorithms for other combinatorial optimization problems.” Our main result proves that the primal-dual algorithm of Williamson et al. achieves an approximation ratio of $$16$$ for a class of functions that generalizes the notion of an uncrossable function. There exist instances that can be handled by our methods where none of the optimal dual solutions has a laminar support. We present three applications of our main result to problems in the area of network design. (1)  A $$16$$ -approximation algorithm for augmenting a family of small cuts of a graph G. The previous best approximation ratio was $$O(\log {|V(G)|})$$ . (2)  A $$16\cdot {\lceil k/u_{min} \rceil }$$ -approximation algorithm for the Cap-k-ECSS problem which is as follows: Given an undirected graph $$G = (V,E)$$ with edge costs $$c \in {\mathbb {Q}}_{\ge 0}^E$$ and edge capacities $$u \in {\mathbb {Z}}_{\ge 0}^E$$ , find a minimum-cost subset of the edges $$F\subseteq E$$ such that the capacity of any cut in (V, F) is at least k; $$u_{min}$$ (respectively, $$u_{max}$$ ) denotes the minimum (respectively, maximum) capacity of an edge in E, and w.l.o.g. $$u_{max} \le k$$ . The previous best approximation ratio was $$\min (O(\log {|V|}), k, 2u_{max})$$ . (3)  A $$20$$ -approximation algorithm for the model of (p, 2)-Flexible Graph Connectivity. The previous best approximation ratio was $$O(\log {|V(G)|})$$ , where G denotes the input graph.},
  archive      = {J_Alg},
  author       = {Bansal, Ishan and Cheriyan, Joseph and Grout, Logan and Ibrahimpur, Sharat},
  doi          = {10.1007/s00453-024-01235-2},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2575-2604},
  shortjournal = {Algorithmica},
  title        = {Improved approximation algorithms by generalizing the primal-dual method beyond uncrossable functions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterized approximation algorithms and lower bounds for
k-center clustering and variants. <em>Alg</em>, <em>86</em>(8),
2557–2574. (<a
href="https://doi.org/10.1007/s00453-024-01236-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {k-center is one of the most popular clustering models. While it admits a simple 2-approximation in polynomial time in general metrics, the Euclidean version is NP-hard to approximate within a factor of 1.82, even in the plane, if one insists the dependence on k in the running time be polynomial. Without this restriction, a classic algorithm by Agarwal and Procopiuc [Algorithmica 2002] yields an $$O(n\log k)+(1/\epsilon )^{O(2^dk^{1-1/d}\log k)}$$ -time $$(1+\epsilon )$$ -approximation for Euclidean k-center, where d is the dimension. We show for a closely related problem, k-supplier, the double-exponential dependence on dimension is unavoidable if one hopes to have a sub-linear dependence on k in the exponent. We also derive similar algorithmic results to the ones by Agarwal and Procopiuc for both k-center and k-supplier. We use a relatively new tool, called Voronoi separator, which makes our algorithms and analyses substantially simpler. Furthermore we consider a well-studied generalization of k-center, called Non-uniform k-center (NUkC), where we allow different radii clusters. NUkC is NP-hard to approximate within any factor, even in the Euclidean case. We design a $$2^{O(k\log k)}n^2$$ time 3-approximation for NUkC in general metrics, and a $$2^{O((k\log k)/\epsilon )}dn$$ time $$(1+\epsilon )$$ -approximation for Euclidean NUkC. The latter time bound matches the bound for k-center.},
  archive      = {J_Alg},
  author       = {Bandyapadhyay, Sayan and Friggstad, Zachary and Mousavi, Ramin},
  doi          = {10.1007/s00453-024-01236-1},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2557-2574},
  shortjournal = {Algorithmica},
  title        = {Parameterized approximation algorithms and lower bounds for k-center clustering and variants},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample-based distance-approximation for
subsequence-freeness. <em>Alg</em>, <em>86</em>(8), 2519–2556. (<a
href="https://doi.org/10.1007/s00453-024-01233-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the problem of approximating the distance to subsequence-freeness in the sample-based distribution-free model. For a given subsequence (word) $$w = w_1 \ldots w_k$$ , a sequence (text) $$T = t_1 \ldots t_n$$ is said to contain w if there exist indices $$1 \le i_1&lt; \cdots &lt; i_k \le n$$ such that $$t_{i_{j}} = w_j$$ for every $$1 \le j \le k$$ . Otherwise, T is w-free. Ron and Rosin (ACM Trans Comput Theory 14(4):1–31, 2022) showed that the number of samples both necessary and sufficient for one-sided error testing of subsequence-freeness in the sample-based distribution-free model is $$\Theta (k/\epsilon )$$ . Denoting by $$\Delta (T,w,p)$$ the distance of T to w-freeness under a distribution $$p:[n]\rightarrow [0,1]$$ , we are interested in obtaining an estimate $$\widehat{\Delta }$$ , such that $$|\widehat{\Delta }- \Delta (T,w,p)| \le \delta $$ with probability at least 2/3, for a given error parameter $$\delta $$ . Our main result is a sample-based distribution-free algorithm whose sample complexity is $$\tilde{O}(k^2/\delta ^2)$$ . We first present an algorithm that works when the underlying distribution p is uniform, and then show how it can be modified to work for any (unknown) distribution p. We also show that a quadratic dependence on $$1/\delta $$ is necessary.},
  archive      = {J_Alg},
  author       = {Cohen Sidon, Omer and Ron, Dana},
  doi          = {10.1007/s00453-024-01233-4},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2519-2556},
  shortjournal = {Algorithmica},
  title        = {Sample-based distance-approximation for subsequence-freeness},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fourier analysis meets runtime analysis: Precise runtimes on
plateaus. <em>Alg</em>, <em>86</em>(8), 2479–2518. (<a
href="https://doi.org/10.1007/s00453-024-01232-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method based on discrete Fourier analysis to analyze the time evolutionary algorithms spend on plateaus. This immediately gives a concise proof of the classic estimate of the expected runtime of the $$(1+1)$$ evolutionary algorithm on the Needle problem due to Garnier et al. (Evol Comput 7:173–203, 1999). We also use this method to analyze the runtime of the $$(1+1)$$ evolutionary algorithm on a benchmark consisting of $$n/\ell $$ plateaus of effective size $$2^\ell -1$$ which have to be optimized sequentially in a LeadingOnes fashion. Using our new method, we determine the precise expected runtime both for static and fitness-dependent mutation rates. We also determine the asymptotically optimal static and fitness-dependent mutation rates. For $$\ell = o(n)$$ , the optimal static mutation rate is approximately 1.59/n. The optimal fitness dependent mutation rate, when the first k fitness-relevant bits have been found, is asymptotically $$1/(k+1)$$ . These results, so far only proven for the single-instance problem LeadingOnes, thus hold for a much broader class of problems. We expect similar extensions to be true for other important results on LeadingOnes. We are also optimistic that the Fourier analysis approach can be applied to other plateau problems as well.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin and Kelley, Andrew James},
  doi          = {10.1007/s00453-024-01232-5},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2479-2518},
  shortjournal = {Algorithmica},
  title        = {Fourier analysis meets runtime analysis: Precise runtimes on plateaus},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nearly time-optimal kernelization algorithms for the
line-cover problem with big data. <em>Alg</em>, <em>86</em>(8),
2448–2478. (<a
href="https://doi.org/10.1007/s00453-024-01231-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on well-known complexity theory conjectures, any polynomial-time kernelization algorithm for the NP-hard Line-Cover problem produces a kernel of size $$\Omega (k^2)$$ , where k is the size of the sought line cover. Motivated by the current research in massive data processing, we study the existence of kernelization algorithms with limited space and time complexity for Line-Cover. We prove that every kernelization algorithm for Line-Cover takes time $$\Omega (n \log k + k^2 \log k)$$ , and present a randomized kernelization algorithm for Line-Cover that produces a kernel of size bounded by $$k^2$$ , and runs in time $${\mathcal {O}}(n \log k + k^2 (\log k \log \log k)^2)$$ and space $${\mathcal {O}}(k^2\log ^{2} k)$$ . Our techniques are also useful for developing deterministic kernelization algorithms for Line-Cover with limited space and improved running time, and for developing streaming kernelization algorithms for Line-Cover with near-optimal update-time.},
  archive      = {J_Alg},
  author       = {Chen, Jianer and Huang, Qin and Kanj, Iyad and Xia, Ge},
  doi          = {10.1007/s00453-024-01231-6},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2448-2478},
  shortjournal = {Algorithmica},
  title        = {Nearly time-optimal kernelization algorithms for the line-cover problem with big data},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Planar drawings with few slopes of halin graphs and nested
pseudotrees. <em>Alg</em>, <em>86</em>(8), 2413–2447. (<a
href="https://doi.org/10.1007/s00453-024-01230-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The planar slope number $${{\,\textrm{psn}\,}}(G)$$ of a planar graph G is the minimum number of edge slopes in a planar straight-line drawing of G. It is known that $${{\,\textrm{psn}\,}}(G) \in O(c^{\Delta })$$ for every planar graph G of maximum degree $$\Delta $$ . This upper bound has been improved to $$O(\Delta ^5)$$ if G has treewidth three, and to $$O(\Delta )$$ if G has treewidth two. In this paper we prove $${{\,\textrm{psn}\,}}(G) \le \max \{4,\Delta \}$$ when G is a Halin graph, and thus has treewidth three. Furthermore, we present the first polynomial upper bound on the planar slope number for a family of graphs having treewidth four. Namely we show that $$O(\Delta ^2)$$ slopes suffice for nested pseudotrees.},
  archive      = {J_Alg},
  author       = {Chaplick, Steven and Da Lozzo, Giordano and Di Giacomo, Emilio and Liotta, Giuseppe and Montecchiani, Fabrizio},
  doi          = {10.1007/s00453-024-01230-7},
  journal      = {Algorithmica},
  month        = {8},
  number       = {8},
  pages        = {2413-2447},
  shortjournal = {Algorithmica},
  title        = {Planar drawings with few slopes of halin graphs and nested pseudotrees},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online multiset submodular cover. <em>Alg</em>,
<em>86</em>(7), 2393–2411. (<a
href="https://doi.org/10.1007/s00453-024-01234-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Online Multiset Submodular Cover problem (OMSC), where we are given a universe U of elements and a collection of subsets $$\mathcal {S}\subseteq 2^U$$ . Each element $$u_j \in U$$ is associated with a nonnegative, nondecreasing, submodular polynomially computable set function $$f_j$$ . Initially, the elements are uncovered, and therefore we pay a penalty per each unit of uncovered element. Subsets with various coverage and cost arrive online. Upon arrival of a new subset, the online algorithm must decide how many copies of the arriving subset to add to the solution. This decision is irrevocable, in the sense that the algorithm will not be able to add more copies of this subset in the future. On the other hand, the algorithm can drop copies of a subset, but such copies cannot be retrieved later. The goal is to minimize the total cost of subsets taken plus penalties for uncovered elements. We present an $$O(\sqrt{\rho _{\max }})$$ -competitive algorithm for OMSC that does not dismiss subset copies that were taken into the solution, but relies on prior knowledge of the value of $$\rho _{\max }$$ , where $$\rho _{\max }$$ is the maximum ratio, over all subsets, between the penalties covered by a subset and its cost. We provide an $$O\left( \log (\rho _{\max }) \sqrt{\rho _{\max }} \right) $$ -competitive algorithm for OMSC that does not rely on advance knowledge of $$\rho _{\max }$$ but uses dismissals of previously taken subsets. Finally, for the capacitated versions of the Online Multiset Multicover problem, we obtain an $$O(\sqrt{\rho _{\max }&#39;})$$ -competitive algorithm when $$\rho _{\max }&#39;$$ is known and an $$O\left( \log (\rho _{\max }&#39;) \sqrt{\rho _{\max }&#39;} \right) $$ -competitive algorithm when $$\rho _{\max }&#39;$$ is unknown, where $$\rho _{\max }&#39;$$ is the maximum ratio over all subset incarnations between the penalties covered by this incarnation and its cost.},
  archive      = {J_Alg},
  author       = {Halldórsson, Magnús M. and Rawitz, Dror},
  doi          = {10.1007/s00453-024-01234-3},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2393-2411},
  shortjournal = {Algorithmica},
  title        = {Online multiset submodular cover},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Runtime analysis of competitive co-evolutionary algorithms
for maximin optimisation of a bilinear function. <em>Alg</em>,
<em>86</em>(7), 2352–2392. (<a
href="https://doi.org/10.1007/s00453-024-01218-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-evolutionary algorithms have a wide range of applications, such as in hardware design, evolution of strategies for board games, and patching software bugs. However, these algorithms are poorly understood and applications are often limited by pathological behaviour, such as loss of gradient, relative over-generalisation, and mediocre objective stasis. It is an open challenge to develop a theory that can predict when co-evolutionary algorithms find solutions efficiently and reliable. This paper provides a first step in developing runtime analysis for population-based competitive co-evolutionary algorithms. We provide a mathematical framework for describing and reasoning about the performance of co-evolutionary processes. To illustrate the framework, we introduce a population-based co-evolutionary algorithm called PDCoEA, and prove that it obtains a solution to a bilinear maximin optimisation problem in expected polynomial time. Finally, we describe settings where PDCoEA needs exponential time with overwhelmingly high probability to obtain a solution.},
  archive      = {J_Alg},
  author       = {Lehre, Per Kristian},
  doi          = {10.1007/s00453-024-01218-3},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2352-2392},
  shortjournal = {Algorithmica},
  title        = {Runtime analysis of competitive co-evolutionary algorithms for maximin optimisation of a bilinear function},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Min orderings and list homomorphism dichotomies for graphs
and signed graphs. <em>Alg</em>, <em>86</em>(7), 2289–2316. (<a
href="https://doi.org/10.1007/s00453-024-01228-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the CSP dichotomy conjecture has been established, a number of other dichotomy questions have attracted interest, including one for list homomorphism problems of signed graphs. Signed graphs arise naturally in many contexts, including for instance nowhere-zero flows for graphs embedded in non-orientable surfaces. The dichotomy classification is known for homomorphisms without list restrictions, so it is surprising that it is not known, or even conjectured, if lists are present since this usually makes the classifications easier to obtain. There is however a conjectured classification, due to Kim and Siggers, in the special case of “semi-balanced” signed graphs. These authors confirmed their conjecture for the class of reflexive signed graphs. As our main result we verify the conjecture for irreflexive signed graphs. For this purpose, we prove an extension result for two-directional ray graphs which is of independent interest and which leads to an analogous extension result for interval graphs. Moreover, we offer an alternative proof for the class of reflexive signed graphs, and a direct polynomial-time algorithm in the polynomial cases where the previous algorithms used algebraic methods of general CSP dichotomy theorems. For both reflexive and irreflexive cases the dichotomy classification depends on a result linking the absence of certain structures to the existence of a special ordering. The structures are used to prove the NP-completeness and the ordering is used to design polynomial algorithms.},
  archive      = {J_Alg},
  author       = {Bok, Jan and Brewster, Richard C. and Hell, Pavol and Jedličková, Nikola and Rafiey, Arash},
  doi          = {10.1007/s00453-024-01228-1},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2289-2316},
  shortjournal = {Algorithmica},
  title        = {Min orderings and list homomorphism dichotomies for graphs and signed graphs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conflict-free coloring: Graphs of bounded clique-width and
intersection graphs. <em>Alg</em>, <em>86</em>(7), 2250–2288. (<a
href="https://doi.org/10.1007/s00453-024-01227-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A conflict-free coloring of a graph G is a (partial) coloring of its vertices such that every vertex u has a neighbor whose assigned color is unique in the neighborhood of u. There are two variants of this coloring, one defined using the open neighborhood and one using the closed neighborhood. For both variants, we study the problem of deciding whether the conflict-free coloring of a given graph G is at most a given number k. In this work, we investigate the relation of clique-width and minimum number of colors needed (for both variants) and show that these parameters do not bound one another. Moreover, we consider specific graph classes, particularly graphs of bounded clique-width and types of intersection graphs, such as distance hereditary graphs, interval graphs and unit square and disk graphs. We also consider Kneser graphs and split graphs. We give (often tight) upper and lower bounds and determine the complexity of the decision problem on these graph classes, which improve some of the results from the literature. Particularly, we settle the number of colors needed for an interval graph to be conflict-free colored under the open neighborhood model, which was posed as an open problem.},
  archive      = {J_Alg},
  author       = {Bhyravarapu, Sriram and Hartmann, Tim A. and Hoang, Hung P. and Kalyanasundaram, Subrahmanyam and Vinod Reddy, I.},
  doi          = {10.1007/s00453-024-01227-2},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2250-2288},
  shortjournal = {Algorithmica},
  title        = {Conflict-free coloring: Graphs of bounded clique-width and intersection graphs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impacts of dimensionality, diffusion, and directedness
on intrinsic cross-model simulation in tile-based self-assembly.
<em>Alg</em>, <em>86</em>(7), 2211–2249. (<a
href="https://doi.org/10.1007/s00453-024-01219-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by applications in DNA-nanotechnology, theoretical investigations in algorithmic tile-assembly have blossomed into a mature theory. In addition to computational universality, the abstract Tile Assembly Model (aTAM) was shown to be intrinsically universal (FOCS 2012), a strong notion of completeness where a single tile set is capable of simulating the full dynamics of all systems within the model; however, this construction fundamentally required non-deterministic tile attachments. This was confirmed necessary when it was shown that the class of directed aTAM systems, those where all possible sequences of tile attachments result in the same terminal assembly, is not intrinsically universal (FOCS 2016). Furthermore, it was shown that the non-cooperative aTAM, where tiles only need to match on 1 side to bind rather than 2 or more, is not intrinsically universal (SODA 2014) nor computationally universal (STOC 2017). Building on these results to further investigate the other dynamics, Hader et al. examined several tile-assembly models which varied across (1) the numbers of dimensions used, (2) how tiles diffused through space, and (3) whether each system is directed, and determined which models exhibited intrinsic universality (SODA 2020). In this paper we extend those results to provide direct comparisons of the various models against each other by considering intrinsic simulations between models. Our results show that in some cases, one model is strictly more powerful than another, and in others, pairs of models have mutually exclusive capabilities. This paper is a greatly expanded version of that which appeared in ICALP 2023.},
  archive      = {J_Alg},
  author       = {Hader, Daniel and Patitz, Matthew J.},
  doi          = {10.1007/s00453-024-01219-2},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2211-2249},
  shortjournal = {Algorithmica},
  title        = {The impacts of dimensionality, diffusion, and directedness on intrinsic cross-model simulation in tile-based self-assembly},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized coloring of permutations. <em>Alg</em>,
<em>86</em>(7), 2174–2210. (<a
href="https://doi.org/10.1007/s00453-024-01220-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A permutation $$\pi $$ is a merge of a permutation $$\sigma $$ and a permutation $$\tau $$ , if we can color the elements of $$\pi $$ red and blue so that the red elements have the same relative order as $$\sigma $$ and the blue ones as $$\tau $$ . We consider, for fixed hereditary permutation classes $$\mathcal {C}$$ and $$\mathcal {D}$$ , the complexity of determining whether a given permutation $$\pi $$ is a merge of an element of $$\mathcal {C}$$ with an element of $$\mathcal {D}$$ . We develop general algorithmic approaches for identifying polynomially tractable cases of merge recognition. Our tools include a version of streaming recognizability of permutations via polynomially constructible nondeterministic automata, as well as a concept of bounded width decomposition, inspired by the work of Ahal and Rabinovich. As a consequence of the general results, we can provide nontrivial examples of tractable permutation merges involving commonly studied permutation classes, such as the class of layered permutations, the class of separable permutations, or the class of permutations avoiding a decreasing sequence of a given length. On the negative side, we obtain a general hardness result which implies, for example, that it is NP-complete to recognize the permutations that can be merged from two subpermutations avoiding the pattern 2413.},
  archive      = {J_Alg},
  author       = {Jelínek, Vít and Opler, Michal and Valtr, Pavel},
  doi          = {10.1007/s00453-024-01220-9},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2174-2210},
  shortjournal = {Algorithmica},
  title        = {Generalized coloring of permutations},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extending partial representations of circle graphs in
near-linear time. <em>Alg</em>, <em>86</em>(7), 2152–2173. (<a
href="https://doi.org/10.1007/s00453-024-01216-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The partial representation extension problem generalizes the recognition problem for geometric intersection graphs. The input consists of a graph G, a subgraph $$H \subseteq G$$ and a representation $$\mathcal R&#39;$$ of H. The question is whether G admits a representation $$\mathcal R$$ whose restriction to H is $$\mathcal R&#39;$$ . We study this question for circle graphs, which are intersection graphs of chords of a circle. Their representations are called chord diagrams. We show that for a graph with n vertices and m edges the partial representation extension problem can be solved in $$O((n + m) \alpha (n + m))$$ time, thereby improving over an $$O(n^3)$$ -time algorithm by Chaplick et al. (J Graph Theory 91(4), 365–394, 2019). The main technical contributions are a canonical way of orienting chord diagrams and a novel compact representation of the set of all canonically oriented chord diagrams that represent a given circle graph G, which is of independent interest.},
  archive      = {J_Alg},
  author       = {Brückner, Guido and Rutter, Ignaz and Stumpf, Peter},
  doi          = {10.1007/s00453-024-01216-5},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2152-2173},
  shortjournal = {Algorithmica},
  title        = {Extending partial representations of circle graphs in near-linear time},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the closures of monotone algebraic classes and variants
of the determinant. <em>Alg</em>, <em>86</em>(7), 2130–2151. (<a
href="https://doi.org/10.1007/s00453-024-01221-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we prove the following two results.},
  archive      = {J_Alg},
  author       = {Chaugule, Prasad and Limaye, Nutan},
  doi          = {10.1007/s00453-024-01221-8},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2130-2151},
  shortjournal = {Algorithmica},
  title        = {On the closures of monotone algebraic classes and variants of the determinant},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). <span
class="math display"><em>α</em><sub><em>i</em></sub></span> -metric
graphs: Radius, diameter and all eccentricities. <em>Alg</em>,
<em>86</em>(7), 2092–2129. (<a
href="https://doi.org/10.1007/s00453-024-01223-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend known results on chordal graphs and distance-hereditary graphs to much larger graph classes by using only a common metric property of these graphs. Specifically, a graph is called $$\alpha _i$$ -metric ( $$i\in {\mathcal {N}}$$ ) if it satisfies the following $$\alpha _i$$ -metric property for every vertices u, w, v and x: if a shortest path between u and w and a shortest path between x and v share a terminal edge vw, then $$d(u,x)\ge d(u,v) + d(v,x)-i$$ . Roughly, gluing together any two shortest paths along a common terminal edge may not necessarily result in a shortest path but yields a “near-shortest” path with defect at most i. It is known that $$\alpha _0$$ -metric graphs are exactly ptolemaic graphs, and that chordal graphs and distance-hereditary graphs are $$\alpha _i$$ -metric for $$i=1$$ and $$i=2$$ , respectively. We show that an additive O(i)-approximation of the radius, of the diameter, and in fact of all vertex eccentricities of an $$\alpha _i$$ -metric graph can be computed in total linear time. Our strongest results are obtained for $$\alpha _1$$ -metric graphs, for which we prove that a central vertex can be computed in subquadratic time, and even better in linear time for so-called $$(\alpha _1,\varDelta )$$ -metric graphs (a superclass of chordal graphs and of plane triangulations with inner vertices of degree at least 7). The latter answers a question raised in Dragan (Inf Probl Lett 154:105873, 2020), 2020). Our algorithms follow from new results on centers and metric intervals of $$\alpha _i$$ -metric graphs. In particular, we prove that the diameter of the center is at most $$3i+2$$ (at most 3, if $$i=1$$ ). The latter partly answers a question raised in Yushmanov and Chepoi (Math Probl Cybernet 3:217–232, 1991).},
  archive      = {J_Alg},
  author       = {Dragan, Feodor F. and Ducoffe, Guillaume},
  doi          = {10.1007/s00453-024-01223-6},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2092-2129},
  shortjournal = {Algorithmica},
  title        = {$$\alpha _i$$ -metric graphs: Radius, diameter and all eccentricities},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embedding arbitrary boolean circuits into fungal automata.
<em>Alg</em>, <em>86</em>(7), 2069–2091. (<a
href="https://doi.org/10.1007/s00453-024-01222-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fungal automata are a variation of the two-dimensional sandpile automaton of Bak et al. (Phys Rev Lett 59(4):381–384, 1987. https://doi.org/10.1103/PhysRevLett.59.381 ). In each step toppling cells emit grains only to some of their neighbors chosen according to a specific update sequence. We show how to embed any Boolean circuit into the initial configuration of a fungal automaton with update sequence HV. In particular we give a constructor that, given the description B of a circuit, computes the states of all cells in the finite support of the embedding configuration in $$O(\log \left| {B}\right| )$$ space. As a consequence the prediction problem for fungal automata with update sequence HV is $$\textsf {P}$$ -complete. This solves an open problem of Goles et al. (Phys Lett A 384(22):126541, 2020. https://doi.org/10.1016/j.physleta.2020.126541 ).},
  archive      = {J_Alg},
  author       = {Modanese, Augusto and Worsch, Thomas},
  doi          = {10.1007/s00453-024-01222-7},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {2069-2091},
  shortjournal = {Algorithmica},
  title        = {Embedding arbitrary boolean circuits into fungal automata},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysing equilibrium states for population diversity.
<em>Alg</em>, <em>86</em>(7), 1–35. (<a
href="https://doi.org/10.1007/s00453-024-01226-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population diversity is crucial in evolutionary algorithms as it helps with global exploration and facilitates the use of crossover. Despite many runtime analyses showing advantages of population diversity, we have no clear picture of how diversity evolves over time. We study how the population diversity of $$(\mu +1)$$ algorithms, measured by the sum of pairwise Hamming distances, evolves in a fitness-neutral environment. We give an exact formula for the drift of population diversity and show that it is driven towards an equilibrium state. Moreover, we bound the expected time for getting close to the equilibrium state. We find that these dynamics, including the location of the equilibrium, are unaffected by surprisingly many algorithmic choices. All unbiased mutation operators with the same expected number of bit flips have the same effect on the expected diversity. Many crossover operators have no effect at all, including all binary unbiased, respectful operators. We review crossover operators from the literature and identify crossovers that are neutral towards the evolution of diversity and crossovers that are not.},
  archive      = {J_Alg},
  author       = {Lengler, Johannes and Opris, Andre and Sudholt, Dirk},
  doi          = {10.1007/s00453-024-01226-3},
  journal      = {Algorithmica},
  month        = {7},
  number       = {7},
  pages        = {1-35},
  shortjournal = {Algorithmica},
  title        = {Analysing equilibrium states for population diversity},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Editor’s note: Special issue with GECCO 2021. <em>Alg</em>,
<em>86</em>(6), 2067. (<a
href="https://doi.org/10.1007/s00453-024-01217-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  doi          = {10.1007/s00453-024-01217-4},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {2067},
  shortjournal = {Algorithmica},
  title        = {Editor’s note: Special issue with GECCO 2021},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The near exact bin covering problem. <em>Alg</em>,
<em>86</em>(6), 2041–2066. (<a
href="https://doi.org/10.1007/s00453-024-01224-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new generalization of the bin covering problem that is known to be a strongly NP-hard problem. In our generalization there is a positive constant $$\varDelta $$ , and we are given a set of items each of which has a positive size. We would like to find a partition of the items into bins. We say that a bin is near exact covered if the total size of items packed into the bin is between 1 and $$1+\varDelta $$ . Our goal is to maximize the number of near exact covered bins. If $$\varDelta =0$$ or $$\varDelta &gt;0$$ is given as part of the input, our problem is shown here to have no approximation algorithm with a bounded asymptotic approximation ratio (assuming that $$P\ne NP$$ ). However, for the case where $$\varDelta &gt;0$$ is seen as a constant, we present an asymptotic fully polynomial time approximation scheme (AFPTAS) that is our main contribution.},
  archive      = {J_Alg},
  author       = {Levin, Asaf},
  doi          = {10.1007/s00453-024-01224-5},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {2041-2066},
  shortjournal = {Algorithmica},
  title        = {The near exact bin covering problem},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Diverse pairs of matchings. <em>Alg</em>, <em>86</em>(6),
2026–2040. (<a
href="https://doi.org/10.1007/s00453-024-01214-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the study of the Diverse Pair of (Maximum/ Perfect) Matchings problems which given a graph G and an integer k, ask whether G has two (maximum/perfect) matchings whose symmetric difference is at least k. Diverse Pair of Matchings (asking for two not necessarily maximum or perfect matchings) is $$\textsf{NP}$$ -complete on general graphs if k is part of the input, and we consider two restricted variants. First, we show that on bipartite graphs, the problem is polynomial-time solvable, and second we show that Diverse Pair of Maximum Matchings is $$\textsf{FPT}$$ parameterized by k. We round off the work by showing that Diverse Pair of Matchings has a kernel on $${\mathcal {O}}(k^2)$$ vertices.},
  archive      = {J_Alg},
  author       = {Fomin, Fedor V. and Golovach, Petr A. and Jaffke, Lars and Philip, Geevarghese and Sagunov, Danil},
  doi          = {10.1007/s00453-024-01214-7},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {2026-2040},
  shortjournal = {Algorithmica},
  title        = {Diverse pairs of matchings},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear space data structures for finite groups with constant
query-time. <em>Alg</em>, <em>86</em>(6), 1979–2025. (<a
href="https://doi.org/10.1007/s00453-024-01212-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A finite group of order n can be represented by its Cayley table. In the word-RAM model the Cayley table of a group of order n can be stored using $$O(n^2)$$ words and can be used to answer a multiplication query in constant time. It is interesting to ask if we can design a data structure to store a group of order n that uses $$o(n^2)$$ space but can still answer a multiplication query in constant time. Das et al. (J Comput Syst Sci 114:137–146, 2020) showed that for any finite group G of order n and for any $$\delta \in [1/\log {n}, 1]$$ , a data structure can be constructed for G that uses $$O(n^{1+\delta }/\delta )$$ space and answers a multiplication query in time $$O(1/\delta )$$ . Farzan and Munro (ISSAC, 2006) gave an information theoretic lower bound of $$\Omega (n)$$ on the number of words to store a group of order n. We design a constant query-time data structure that can store any finite group using O(n) words where n is the order of the group. Since our data structure achieves the information theoretic lower bound and answers queries in constant time, it is optimal in both space usage and query-time. A crucial step in the process is essentially to design linear space and constant query-time data structures for nonabelian simple groups. The data structures for nonabelian simple groups are designed using a lemma that we prove using the Classification Theorem for Finite Simple Groups.},
  archive      = {J_Alg},
  author       = {Das, Bireswar and Kumar, Anant and Sharma, Shivdutt and Thakkar, Dhara},
  doi          = {10.1007/s00453-024-01212-9},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1979-2025},
  shortjournal = {Algorithmica},
  title        = {Linear space data structures for finite groups with constant query-time},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pattern masking for dictionary matching: Theory and
practice. <em>Alg</em>, <em>86</em>(6), 1948–1978. (<a
href="https://doi.org/10.1007/s00453-024-01213-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data masking is a common technique for sanitizing sensitive data maintained in database systems which is becoming increasingly important in various application areas, such as in record linkage of personal data. This work formalizes the Pattern Masking for Dictionary Matching (PMDM) problem: given a dictionary $$\mathscr {D}$$ of d strings, each of length $$\ell $$ , a query string q of length $$\ell $$ , and a positive integer z, we are asked to compute a smallest set $$K\subseteq \{1,\ldots ,\ell \}$$ , so that if q[i] is replaced by a wildcard for all $$i\in K$$ , then q matches at least z strings from $$\mathscr {D}$$ . Solving PMDM allows providing data utility guarantees as opposed to existing approaches. We first show, through a reduction from the well-known k-Clique problem, that a decision version of the PMDM problem is NP-complete, even for binary strings. We thus approach the problem from a more practical perspective. We show a combinatorial $$\mathscr {O}((d\ell )^{|K|/3}+d\ell )$$ -time and $$\mathscr {O}(d\ell )$$ -space algorithm for PMDM for $$|K|=\mathscr {O}(1)$$ . In fact, we show that we cannot hope for a faster combinatorial algorithm, unless the combinatorial k-Clique hypothesis fails (Abboud et al. in SIAM J Comput 47:2527–2555, 2018; Lincoln et al., in: 29th ACM-SIAM Symposium on Discrete Algorithms (SODA), 2018). Our combinatorial algorithm, executed with small |K|, is the backbone of a greedy heuristic that we propose. Our experiments on real-world and synthetic datasets show that our heuristic finds nearly-optimal solutions in practice and is also very efficient. We also generalize this algorithm for the problem of masking multiple query strings simultaneously so that every string has at least z matches in $$\mathscr {D}$$ . PMDM can be viewed as a generalization of the decision version of the dictionary matching with mismatches problem: by querying a PMDM data structure with string q and $$z=1$$ , one obtains the minimal number of mismatches of q with any string from $$\mathscr {D}$$ . The query time or space of all known data structures for the more restricted problem of dictionary matching with at most k mismatches incurs some exponential factor with respect to k. A simple exact algorithm for PMDM runs in time $$\mathscr {O}(2^\ell d)$$ . We present a data structure for PMDM that answers queries over $$\mathscr {D}$$ in time $$\mathscr {O}(2^{\ell /2}(2^{\ell /2}+\tau )\ell )$$ and requires space $$\mathscr {O}(2^{\ell }d^2/\tau ^2+2^{\ell /2}d)$$ , for any parameter $$\tau \in [1,d]$$ . We complement our results by showing a two-way polynomial-time reduction between PMDM and the Minimum Union problem [Chlamtáč et al., ACM-SIAM Symposium on Discrete Algorithms (SODA) 2017]. This gives a polynomial-time $$\mathscr {O}(d^{1/4+\epsilon })$$ -approximation algorithm for PMDM, which is tight under a plausible complexity conjecture. This is an extended version of a paper that was presented at International Symposium on Algorithms and Computation (ISAAC) 2021.},
  archive      = {J_Alg},
  author       = {Charalampopoulos, Panagiotis and Chen, Huiping and Christen, Peter and Loukides, Grigorios and Pisanti, Nadia and Pissis, Solon P. and Radoszewski, Jakub},
  doi          = {10.1007/s00453-024-01213-8},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1948-1978},
  shortjournal = {Algorithmica},
  title        = {Pattern masking for dictionary matching: Theory and practice},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding optimal solutions with neighborly help.
<em>Alg</em>, <em>86</em>(6), 1921–1947. (<a
href="https://doi.org/10.1007/s00453-023-01204-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can we efficiently compute optimal solutions to instances of a hard problem from optimal solutions to neighbor instances, that is, instances with one local modification? For example, can we efficiently compute an optimal coloring for a graph from optimal colorings for all one-edge-deleted subgraphs? Studying such questions not only gives detailed insight into the structure of the problem itself, but also into the complexity of related problems, most notably, graph theory’s core notion of critical graphs (e.g., graphs whose chromatic number decreases under deletion of an arbitrary edge) and the complexity-theoretic notion of minimality problems (also called criticality problems, e.g., recognizing graphs that become 3-colorable when an arbitrary edge is deleted). We focus on two prototypical graph problems, colorability and vertex cover. For example, we show that it is $$\text {NP}$$ -hard to compute an optimal coloring for a graph from optimal colorings for all its one-vertex-deleted subgraphs, and that this remains true even when optimal solutions for all one-edge-deleted subgraphs are given. In contrast, computing an optimal coloring from all (or even just two) one-edge-added supergraphs is in $$\text {P}$$ . We observe that vertex cover exhibits a remarkably different behavior, demonstrating the power of our model to delineate problems from each other more precisely on a structural level. Moreover, we provide a number of new complexity results for minimality and criticality problems. For example, we prove that Minimal-3-UnColorability is complete for $$\text {DP}$$ (differences of $$\text {NP}$$ sets), which was previously known only for the more amenable case of deleting vertices rather than edges. For vertex cover, we show that recognizing $$\beta $$ -vertex-critical graphs is complete for $$\Theta _2^\text {p}$$ (parallel access to $$\text {NP}$$ ), obtaining the first completeness result for a criticality problem for this class.},
  archive      = {J_Alg},
  author       = {Burjons, Elisabet and Frei, Fabian and Hemaspaandra, Edith and Komm, Dennis and Wehner, David},
  doi          = {10.1007/s00453-023-01204-1},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1921-1947},
  shortjournal = {Algorithmica},
  title        = {Finding optimal solutions with neighborly help},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable matchings, one-sided ties, and approximate
popularity. <em>Alg</em>, <em>86</em>(6), 1888–1920. (<a
href="https://doi.org/10.1007/s00453-024-01215-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a matching problem in a bipartite graph $$G = (A \cup B, E)$$ where vertices in A rank their neighbors in a strict order of preference while vertices in B are allowed to have weak rankings, i.e., ties are allowed in their rankings. Stable matchings always exist in G and are easy to find, however popular matchings need not exist in G and it is NP-complete to decide if one exists. This motivates the “approximately popular” matching problem. A well-known measure of approximate popularity is low unpopularity factor. We show that when each tie in G has length at most k, there always exists a stable matching whose unpopularity factor is at most k and such a matching can be computed in polynomial time. Thus when ties have bounded length, there always exists a near-popular stable matching. This can be considered to be a generalization of Gärdenfors’ result (1975) which showed that when rankings are strict, every stable matching is popular. We then extend our result to the hospitals/residents setting, i.e., vertices in B have capacities. There are several applications where the size of the matching is its most important attribute. When ties are one-sided and of length at most k, we show a polynomial time algorithm to find a maximum matching whose unpopularity factor within the set of maximum matchings is at most 2k.},
  archive      = {J_Alg},
  author       = {Kavitha, Telikepalli},
  doi          = {10.1007/s00453-024-01215-6},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1888-1920},
  shortjournal = {Algorithmica},
  title        = {Stable matchings, one-sided ties, and approximate popularity},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimal roman dominating functions: Extensions and
enumeration. <em>Alg</em>, <em>86</em>(6), 1862–1887. (<a
href="https://doi.org/10.1007/s00453-024-01211-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roman domination is one of the many variants of domination that keeps most of the complexity features of the classical domination problem. We prove that Roman domination behaves differently in two aspects: enumeration and extension. We develop non-trivial enumeration algorithms for minimal Roman dominating functions with polynomial delay and polynomial space. Recall that the existence of a similar enumeration result for minimal dominating sets is open for decades. Our result is based on a polynomial-time algorithm for Extension Roman Domination: Given a graph $$G=(V,E)$$ and a function $$f:V\rightarrow \{0,1,2\}$$ , is there a minimal Roman dominating function $$\tilde{f}$$ with $$f\le \tilde{f}$$ ? Here, $$\le $$ lifts $$0&lt; 1&lt; 2$$ pointwise; minimality is understood in this order. Our enumeration algorithm is also analyzed from an input-sensitive viewpoint, leading to a run-time estimate of $$\mathcal {O}(1.9332^n)$$ for graphs of order n; this is complemented by a lower bound example of $$\Omega (1.7441^n)$$ .},
  archive      = {J_Alg},
  author       = {Abu-Khzam, Faisal N. and Fernau, Henning and Mann, Kevin},
  doi          = {10.1007/s00453-024-01211-w},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1862-1887},
  shortjournal = {Algorithmica},
  title        = {Minimal roman dominating functions: Extensions and enumeration},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The time complexity of consensus under oblivious message
adversaries. <em>Alg</em>, <em>86</em>(6), 1830–1861. (<a
href="https://doi.org/10.1007/s00453-024-01209-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of solving consensus in synchronous directed dynamic networks, in which communication is controlled by an oblivious message adversary that picks the communication graph to be used in a round from a fixed set of graphs $$\textbf{D}$$ arbitrarily. In this fundamental model, determining consensus solvability and designing efficient consensus algorithms is surprisingly difficult. Enabled by a decision procedure that is derived from a well-established previous consensus solvability characterization for a given set $$\textbf{D}$$ , we study, for the first time, the time complexity of solving consensus in this model: We provide both upper and lower bounds for this time complexity, and also relate it to the number of iterations required by the decision procedure. Among other results, we find that reaching consensus under an oblivious message adversary can take exponentially longer than both deciding consensus solvability and broadcasting the input value of some unknown process to all other processes.},
  archive      = {J_Alg},
  author       = {Winkler, Kyrill and Paz, Ami and Galeana, Hugo Rincon and Schmid, Stefan and Schmid, Ulrich},
  doi          = {10.1007/s00453-024-01209-4},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1830-1861},
  shortjournal = {Algorithmica},
  title        = {The time complexity of consensus under oblivious message adversaries},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sublinear time eigenvalue approximation via random sampling.
<em>Alg</em>, <em>86</em>(6), 1764–1829. (<a
href="https://doi.org/10.1007/s00453-024-01208-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of approximating the eigenspectrum of a symmetric matrix $$\textbf{A} \in \mathbb {R}^{n \times n}$$ with bounded entries (i.e., $$\Vert \textbf{A}\Vert _{\infty } \le 1$$ ). We present a simple sublinear time algorithm that approximates all eigenvalues of $$\textbf{A}$$ up to additive error $$\pm \epsilon n$$ using those of a randomly sampled $${\tilde{O}}\left( \frac{\log ^3 n}{\epsilon ^3}\right) \times {{\tilde{O}}}\left( \frac{\log ^3 n}{\epsilon ^3}\right) $$ principal submatrix. Our result can be viewed as a concentration bound on the complete eigenspectrum of a random submatrix, significantly extending known bounds on just the singular values (the magnitudes of the eigenvalues). We give improved error bounds of $$\pm \epsilon \sqrt{\text {nnz}(\textbf{A})}$$ and $$\pm \epsilon \Vert \textbf{A}\Vert _F$$ when the rows of $$\textbf{A}$$ can be sampled with probabilities proportional to their sparsities or their squared $$\ell _2$$ norms respectively. Here $$\text {nnz}(\textbf{A})$$ is the number of non-zero entries in $$\textbf{A}$$ and $$\Vert \textbf{A}\Vert _F$$ is its Frobenius norm. Even for the strictly easier problems of approximating the singular values or testing the existence of large negative eigenvalues (Bakshi, Chepurko, and Jayaram, FOCS ’20), our results are the first that take advantage of non-uniform sampling to give improved error bounds. From a technical perspective, our results require several new eigenvalue concentration and perturbation bounds for matrices with bounded entries. Our non-uniform sampling bounds require a new algorithmic approach, which judiciously zeroes out entries of a randomly sampled submatrix to reduce variance, before computing the eigenvalues of that submatrix as estimates for those of $$\textbf{A}$$ . We complement our theoretical results with numerical simulations, which demonstrate the effectiveness of our algorithms in practice.},
  archive      = {J_Alg},
  author       = {Bhattacharjee, Rajarshi and Dexter, Gregory and Drineas, Petros and Musco, Cameron and Ray, Archan},
  doi          = {10.1007/s00453-024-01208-5},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1764-1829},
  shortjournal = {Algorithmica},
  title        = {Sublinear time eigenvalue approximation via random sampling},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the parameterized intractability of determinant
maximization. <em>Alg</em>, <em>86</em>(6), 1731–1763. (<a
href="https://doi.org/10.1007/s00453-023-01205-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Determinant Maximization problem, given an $$n \times n$$ positive semi-definite matrix $${\textbf {A}} $$ in $$\mathbb {Q}^{n \times n}$$ and an integer k, we are required to find a $$k \times k$$ principal submatrix of $${\textbf {A}} $$ having the maximum determinant. This problem is known to be NP-hard and further proven to be W[1]-hard with respect to k by Koutis (Inf Process Lett 100:8–13, 2006); i.e., a $$f(k)n^{{{\,\mathrm{\mathcal {O}}\,}}(1)}$$ -time algorithm is unlikely to exist for any computable function f. However, there is still room to explore its parameterized complexity in the restricted case, in the hope of overcoming the general-case parameterized intractability. In this study, we rule out the fixed-parameter tractability of Determinant Maximization even if an input matrix is extremely sparse or low rank, or an approximate solution is acceptable. We first prove that Determinant Maximization is NP-hard and W[1]-hard even if an input matrix is an arrowhead matrix; i.e., the underlying graph formed by nonzero entries is a star, implying that the structural sparsity is not helpful. By contrast, Determinant Maximization is known to be solvable in polynomial time on tridiagonal matrices (Al-Thani and Lee, in: LAGOS, 2021). Thereafter, we demonstrate the W[1]-hardness with respect to the rank r of an input matrix. Our result is stronger than Koutis’ result in the sense that any $$k \times k$$ principal submatrix is singular whenever $$k &gt; r$$ . We finally give evidence that it is W[1]-hard to approximate Determinant Maximization parameterized by k within a factor of $$2^{-c\sqrt{k}}$$ for some universal constant $$c &gt; 0$$ . Our hardness result is conditional on the Parameterized Inapproximability Hypothesis posed by Lokshtanov et al. (in: SODA, 2020), which asserts that a gap version of Binary Constraint Satisfaction Problem is W[1]-hard. To complement this result, we develop an $$\varepsilon $$ -additive approximation algorithm that runs in $$\varepsilon ^{-r^2} \cdot r^{{{\,\mathrm{\mathcal {O}}\,}}(r^3)} \cdot n^{{{\,\mathrm{\mathcal {O}}\,}}(1)}$$ time for the rank r of an input matrix, provided that the diagonal entries are bounded.},
  archive      = {J_Alg},
  author       = {Ohsaka, Naoto},
  doi          = {10.1007/s00453-023-01205-0},
  journal      = {Algorithmica},
  month        = {6},
  number       = {6},
  pages        = {1731-1763},
  shortjournal = {Algorithmica},
  title        = {On the parameterized intractability of determinant maximization},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploration of high-dimensional grids by finite state
machines. <em>Alg</em>, <em>86</em>(5), 1700–1729. (<a
href="https://doi.org/10.1007/s00453-024-01207-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of finding a “treasure” at an unknown point of an n-dimensional infinite grid, $$n\ge 3$$ , by initially collocated finite automaton (FA) agents. Recently, the problem has been well characterized for 2 dimensions for deterministic as well as randomized FA agents, both in synchronous and semi-synchronous models (Brandt et al. in Proceedings of 32nd International Symposium on Distributed Computing (DISC) LIPCS 121:13:1–13:17, 2018; Emek et al. in Theor Comput Sci 608:255–267, 2015). It has been conjectured that $$n+1$$ randomized FA agents are necessary to solve this problem in the n-dimensional grid (Cohen et al. in Proceedings of the 28th SODA, SODA ’17, pp 207–224, 2017). In this paper we disprove the conjecture in a strong sense: we show that three randomized synchronous FA agents suffice to explore an n-dimensional grid for any n. Our algorithm is optimal in terms of the number of the agents. Our key insight is that a constant number of FA agents can, by their positions and movements, implement a stack, which can store the path being explored. We also show how to implement our algorithm using: four randomized semi-synchronous FA agents; four deterministic synchronous FA agents; or five deterministic semi-synchronous FA agents. We give a different, no-stack algorithm that uses 4 deterministic semi-synchronous FA agents for the 3-dimensional grid. This is provably optimal in the number of agents and the exploration cost, and surprisingly, matches the result for 2 dimensions. For $$n\ge 4$$ , the time complexity of the stack-based algorithms mentioned above is exponential in distance D of the treasure from the starting point of the agents. We show that in the deterministic case, one additional finite automaton agent brings the time down to a polynomial. We also show that any algorithm using 3 synchronous deterministic FA agents in 3 dimensions must travel beyond $$\Omega (D^{3/2})$$ from the origin. Finally, we show that all the above algorithms can be generalized to unoriented grids. More specifically, six deterministic semi-synchronous FA agents are sufficient to locate the treasure in an unoriented n-dimensional grid.},
  archive      = {J_Alg},
  author       = {Dobrev, Stefan and Narayanan, Lata and Opatrny, Jaroslav and Pankratov, Denis},
  doi          = {10.1007/s00453-024-01207-6},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1700-1729},
  shortjournal = {Algorithmica},
  title        = {Exploration of high-dimensional grids by finite state machines},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved FPT algorithms for deletion to forest-like
structures. <em>Alg</em>, <em>86</em>(5), 1657–1699. (<a
href="https://doi.org/10.1007/s00453-023-01206-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Feedback Vertex Set problem is undoubtedly one of the most well-studied problems in Parameterized Complexity. In this problem, given an undirected graph G and a non-negative integer k, the objective is to test whether there exists a subset $$S\subseteq V(G)$$ of size at most k such that $$G-S$$ is a forest. After a long line of improvement, recently, Li and Nederlof [TALG, 2022] designed a randomized algorithm for the problem running in time $${\mathcal {O}}^{\star }(2.7^k)^{*}$$ . In the Parameterized Complexity literature, several problems around Feedback Vertex Set have been studied. Some of these include Independent Feedback Vertex Set (where the set S should be an independent set in G), Almost Forest Deletion and Pseudoforest Deletion. In Pseudoforest Deletion, each connected component in $$G-S$$ has at most one cycle in it. However, in Almost Forest Deletion, the input is a graph G and non-negative integers $$k,\ell \in {{\mathbb {N}}}$$ , and the objective is to test whether there exists a vertex subset S of size at most k, such that $$G-S$$ is $$\ell $$ edges away from a forest. In this paper, using the methodology of Li and Nederlof [TALG, 2022], we obtain the current fastest algorithms for all these problems. In particular we obtain the following randomized algorithms.},
  archive      = {J_Alg},
  author       = {Gowda, Kishen N. and Lonkar, Aditya and Panolan, Fahad and Patel, Vraj and Saurabh, Saket},
  doi          = {10.1007/s00453-023-01206-z},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1657-1699},
  shortjournal = {Algorithmica},
  title        = {Improved FPT algorithms for deletion to forest-like structures},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient algorithm for all-pairs bounded edge
connectivity. <em>Alg</em>, <em>86</em>(5), 1623–1656. (<a
href="https://doi.org/10.1007/s00453-023-01203-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our work concerns algorithms for a variant of Maximum Flow in unweighted graphs. In the All-Pairs Connectivity (APC) problem, we are given a graph G on n vertices and m edges, and are tasked with computing the maximum number of edge-disjoint paths from s to t (equivalently, the size of a minimum (s, t)-cut) in G, for all pairs of vertices (s, t). Significant algorithmic breakthroughs have recently shown that over undirected graphs, APC can be solved in $$n^{2+o(1)}$$ time, which is essentially optimal. In contrast, the true time complexity of APC over directed graphs remains open: this problem can be solved in $${\tilde{O}}(m^\omega )$$ time, where $$\omega \in [2, 2.373)$$ is the exponent of matrix multiplication, but no matching conditional lower bound is known. Following [Abboud et al. In: 46th International colloquium on automata, languages, and programming, ICALP 2019, July 9-12, 2019, Patras, Greece, Schloss Dagstuhl-Leibniz-Zentrum für Informatik, 2019], we study a bounded version of $${{\textsf {APC}}}$$ called the k-Bounded All Pairs Connectivity (k-APC) problem. In this variant of APC, we are given an integer k in addition to the graph G, and are now tasked with reporting the size of a minimum (s, t)-cut only for pairs (s, t) of vertices with min-cut value less than k (if the minimum (s, t)-cut has size at least k, we can just report it is “large” instead of computing the exact value). Our main result is an $${\tilde{O}}((kn)^\omega )$$ time algorithm solving k-APC in directed graphs. This is the first algorithm which solves k-APC faster than simply solving the more general APC problem exactly, for all $$k\ge 3$$ . This runtime is $${{\tilde{O}}}(n^\omega )$$ for all $$k\le {{\,\textrm{poly}\,}}(\log n)$$ , which essentially matches the optimal runtime for the $$k=1$$ case of k-APC, under popular conjectures from fine-grained complexity. Previously, this runtime was only achieved for $$k\le 2$$ in general directed graphs [Georgiadis et al. In: 44th international colloquium on automata, languages, and programming (ICALP 2017), volume 80 of Leibniz International Proceedings in Informatics (LIPIcs), Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2017], and for $$k\le o(\sqrt{\log n})$$ in the special case of directed acyclic graphs [Abboud et al. In: 46th international colloquium on automata, languages, and programming, ICALP 2019, July 9–12, 2019, Patras, Greece, Schloss Dagstuhl-Leibniz-Zentrum für Informatik, 2019]. Our result employs the same algebraic framework used in previous work, introduced by [Cheung et al. In: FOCS, 2011]. A direct implementation of this framework involves inverting a large random matrix. Our new algorithm is based off the insight that for solving k-APC, it suffices to invert a low-rank random matrix instead of a generic random matrix. We also obtain a new algorithm for a variant of k-APC, the k-Bounded All-Pairs Vertex Connectivity (k-APVC) problem, where we are now tasked with reporting, for every pair of vertices (s, t), the maximum number of internally vertex-disjoint (rather than edge-disjoint) paths from s to t if this number is less than k, and otherwise reporting that there are at least k internally vertex-disjoint paths from s to t. Our second result is an $${\tilde{O}}(k^2n^\omega )$$ time algorithm solving k-APVC in directed graphs. Previous work showed how to solve an easier version of the k-APVC problem (where answers only need to be returned for pairs of vertices (s, t) which are not edges in the graph) in $${{\tilde{O}}}((kn)^\omega )$$ time [Abboud et al. In: 46th International colloquium on automata, languages, and programming, ICALP 2019, July 9–12, 2019, Patras, Greece, Schloss Dagstuhl-Leibniz-Zentrum für Informatik, 2019]. In comparison, our algorithm solves the full k-APVC problem, and is faster if $$\omega &gt; 2$$ .},
  archive      = {J_Alg},
  author       = {Akmal, Shyan and Jin, Ce},
  doi          = {10.1007/s00453-023-01203-2},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1623-1656},
  shortjournal = {Algorithmica},
  title        = {An efficient algorithm for all-pairs bounded edge connectivity},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Truthful matching with online items and offline agents.
<em>Alg</em>, <em>86</em>(5), 1600–1622. (<a
href="https://doi.org/10.1007/s00453-023-01202-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study truthful mechanisms for welfare maximization in online bipartite matching. In our (multi-parameter) setting, every buyer is associated with a (possibly private) desired set of items, and has a private value for being assigned an item in her desired set. Unlike most online matching settings, where agents arrive online, in our setting the items arrive one by one in an adversarial order while the buyers are present for the entire duration of the process. This poses a significant challenge to the design of truthful mechanisms, due to the ability of buyers to strategize over future rounds. We provide an almost full picture of the competitive ratios in different scenarios, including myopic vs. non-myopic agents, tardy vs. prompt payments, and private vs. public desired sets. Among other results, we identify the frontier up to which the celebrated $$e/(e-1)$$ competitive ratio for the vertex-weighted online matching of Karp, Vazirani and Vazirani extends to truthful agents and online items.},
  archive      = {J_Alg},
  author       = {Feldman, Michal and Fusco, Federico and Leonardi, Stefano and Mauras, Simon and Reiffenhäuser, Rebecca},
  doi          = {10.1007/s00453-023-01202-3},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1600-1622},
  shortjournal = {Algorithmica},
  title        = {Truthful matching with online items and offline agents},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predecessor on the ultra-wide word RAM. <em>Alg</em>,
<em>86</em>(5), 1578–1599. (<a
href="https://doi.org/10.1007/s00453-023-01193-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the predecessor problem on the ultra-wide word RAM model of computation, which extends the word RAM model with ultrawords consisting of $$w^2$$ bits (TAMC, 2015). The model supports arithmetic and boolean operations on ultrawords, in addition to scattered memory operations that access or modify w (potentially non-contiguous) memory addresses simultaneously. The ultra-wide word RAM model captures (and idealizes) modern vector processor architectures. Our main result is a simple, linear space data structure that supports predecessor in constant time and updates in amortized, expected constant time. This improves the space of the previous constant time solution that uses space in the order of the size of the universe. Our result holds even in a weaker model where ultrawords consist of $$w^{1+\epsilon }$$ bits for any $$\epsilon &gt; 0 $$ . It is based on a new implementation of the classic x-fast trie data structure of Willard (Inform Process Lett 17(2):81–84, https://doi.org/10.1016/0020-0190(83)90075-3 , 1983) combined with a new dictionary data structure that supports fast parallel lookups.},
  archive      = {J_Alg},
  author       = {Bille, Philip and Gørtz, Inge Li and Stordalen, Tord},
  doi          = {10.1007/s00453-023-01193-1},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1578-1599},
  shortjournal = {Algorithmica},
  title        = {Predecessor on the ultra-wide word RAM},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximations for throughput maximization. <em>Alg</em>,
<em>86</em>(5), 1545–1577. (<a
href="https://doi.org/10.1007/s00453-023-01201-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the classical problem of throughput maximization. In this problem we have a collection J of n jobs, each having a release time $$r_j$$ , deadline $$d_j$$ , and processing time $$p_j$$ . They have to be scheduled non-preemptively on m identical parallel machines. The goal is to find a schedule which maximizes the number of jobs scheduled entirely in their $$[r_j,d_j]$$ window. This problem has been studied extensively (even for the case of $$m=1$$ ). Several special cases of the problem remain open. Bar-Noy et al. (Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, May 1–4, 1999, Atlanta, Georgia, USA, pp. 622–631. ACM, 1999, https://doi.org/10.1145/301250.301420 ) presented an algorithm with ratio $$1-1/(1+1/m)^m$$ for m machines, which approaches $$1-1/e$$ as m increases. For $$m=1$$ , Chuzhoy et al. (42nd Annual Symposium on Foundations of Computer Science (FOCS) 2001, 14–17 October 2001, Las Vegas, Nevada, USA, pp. 348–356. IEEE Computer Society, 2001) presented an algorithm with approximation with ratio $$1-\frac{1}{e}-\varepsilon $$ (for any $$\varepsilon &gt;0$$ ). Recently Im et al. (SIAM J Discrete Math 34(3):1649–1669, 2020) presented an algorithm with ratio $$1-1/e+\varepsilon _0$$ for some absolute constant $$\varepsilon _0&gt;0$$ for any fixed m. They also presented an algorithm with ratio $$1-O(\sqrt{\log m/m})-\varepsilon $$ for general m which approaches 1 as m grows. The approximability of the problem for $$m=O(1)$$ remains a major open question. Even for the case of $$m=1$$ and $$c=O(1)$$ distinct processing times the problem is open (Sgall in: Algorithms - ESA 2012 - 20th Annual European Symposium, Ljubljana, Slovenia, September 10–12, 2012. Proceedings, pp 2–11, 2012). In this paper we study the case of $$m=O(1)$$ and show that if there are c distinct processing times, i.e. $$p_j$$ ’s come from a set of size c, then there is a randomized $$(1-{\varepsilon })$$ -approximation that runs in time $$O(n^{mc^7{\varepsilon }^{-6}}\log T)$$ , where T is the largest deadline. Therefore, for constant m and constant c this yields a PTAS. Our algorithm is based on proving structural properties for a near optimum solution that allows one to use a dynamic programming with pruning.},
  archive      = {J_Alg},
  author       = {Hyatt-Denesik, Dylan and Rahgoshay, Mirmahdi and Salavatipour, Mohammad R.},
  doi          = {10.1007/s00453-023-01201-4},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1545-1577},
  shortjournal = {Algorithmica},
  title        = {Approximations for throughput maximization},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Connectivity with uncertainty regions given as line
segments. <em>Alg</em>, <em>86</em>(5), 1512–1544. (<a
href="https://doi.org/10.1007/s00453-023-01200-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a set $${\mathcal {Q}}$$ of points in the plane and a real number $$\delta \ge 0$$ , let $${\mathbb {G}}_\delta ({\mathcal {Q}})$$ be the graph defined on $${\mathcal {Q}}$$ by connecting each pair of points at distance at most $$\delta $$ .We consider the connectivity of $${\mathbb {G}}_\delta ({\mathcal {Q}})$$ in the best scenario when the location of a few of the points is uncertain, but we know for each uncertain point a line segment that contains it. More precisely, we consider the following optimization problem: given a set $${\mathcal {P}}$$ of $$n-k$$ points in the plane and a set $${\mathcal {S}}$$ of k line segments in the plane, find the minimum $$\delta \ge 0$$ with the property that we can select one point $$p_s\in s$$ for each segment $$s\in {\mathcal {S}}$$ and the corresponding graph $${\mathbb {G}}_\delta ( {\mathcal {P}}\cup \{ p_s\mid s\in {\mathcal {S}}\})$$ is connected. It is known that the problem is NP-hard. We provide an algorithm to exactly compute an optimal solution in $${{\,\mathrm{{\mathcal {O}}}\,}}(f(k) n \log n)$$ time, for a computable function $$f(\cdot )$$ . This implies that the problem is FPT when parameterized by k. The best previous algorithm uses $${{\,\mathrm{{\mathcal {O}}}\,}}((k!)^k k^{k+1}\cdot n^{2k})$$ time and computes the solution up to fixed precision.},
  archive      = {J_Alg},
  author       = {Cabello, Sergio and Gajser, David},
  doi          = {10.1007/s00453-023-01200-5},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1512-1544},
  shortjournal = {Algorithmica},
  title        = {Connectivity with uncertainty regions given as line segments},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On structural parameterizations of the harmless set problem.
<em>Alg</em>, <em>86</em>(5), 1475–1511. (<a
href="https://doi.org/10.1007/s00453-023-01199-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the Harmless Set problem from a parameterized complexity perspective. Given a graph $$G = (V,E)$$ , a threshold function $$~t~:~ V \rightarrow {\mathbb {N}}$$ and an integer k, we study Harmless Set, where the goal is to find a subset of vertices $$S \subseteq V$$ of size at least k such that every vertex $$v\in V$$ has fewer than t(v) neighbours in S. On the positive side, we obtain fixed-parameter algorithms for the problem when parameterized by the neighbourhood diversity, the twin-cover number and the vertex integrity of the input graph. We complement two of these results from the negative side. On dense graphs, we show that the problem is W[1]-hard parameterized by cluster vertex deletion number—a natural generalization of the twin-cover number. We show that the problem is W[1]-hard parameterized by a wide range of fairly restrictive structural parameters such as the feedback vertex set number, pathwidth, and treedepth—a natural generalization of the vertex integrity. We thereby resolve one open question stated by Bazgan and Chopin (Discrete Optim 14(C):170–182, 2014) concerning the complexity of Harmless Set parameterized by the treewidth of the input graph. We also show that Harmless Set for a special case where each vertex has the threshold set to half of its degree (the so-called Majority Harmless Set problem) is W[1]-hard when parameterized by the treewidth of the input graph. Given a graph G and an irredundant c-expression of G, we prove that Harmless Set can be solved in XP-time when parameterized by clique-width.},
  archive      = {J_Alg},
  author       = {Gaikwad, Ajinkya and Maity, Soumen},
  doi          = {10.1007/s00453-023-01199-9},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1475-1511},
  shortjournal = {Algorithmica},
  title        = {On structural parameterizations of the harmless set problem},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domination and cut problems on chordal graphs with bounded
leafage. <em>Alg</em>, <em>86</em>(5), 1428–1474. (<a
href="https://doi.org/10.1007/s00453-023-01196-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The leafage of a chordal graph G is the minimum integer $$\ell $$ such that G can be realized as an intersection graph of subtrees of a tree with $$\ell $$ leaves. We consider structural parameterization by the leafage of classical domination and cut problems on chordal graphs. Fomin, Golovach, and Raymond [ESA 2018, Algorithmica 2020] proved, among other things, that Dominating Set on chordal graphs admits an algorithm running in time $$2^{\mathcal {O}(\ell ^2)} \cdot n^{\mathcal {O}(1)}$$ . We present a conceptually much simpler algorithm that runs in time $$2^{\mathcal {O}(\ell )} \cdot n^{\mathcal {O}(1)}$$ . We extend our approach to obtain similar results for Connected Dominating Set and Steiner Tree. We then consider the two classical cut problems MultiCut with Undeletable Terminals and Multiway Cut with Undeletable Terminals. We prove that the former is W[1]-hard when parameterized by the leafage and complement this result by presenting a simple $$n^{\mathcal {O}(\ell )}$$ -time algorithm. To our surprise, we find that Multiway Cut with Undeletable Terminals on chordal graphs can be solved, in contrast, in $$n^{{{\mathcal {O}}}(1)}$$ -time.},
  archive      = {J_Alg},
  author       = {Galby, Esther and Marx, Dániel and Schepper, Philipp and Sharma, Roohani and Tale, Prafullkumar},
  doi          = {10.1007/s00453-023-01196-y},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1428-1474},
  shortjournal = {Algorithmica},
  title        = {Domination and cut problems on chordal graphs with bounded leafage},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation algorithms for multiprocessor scheduling with
testing to minimize the total job completion time. <em>Alg</em>,
<em>86</em>(5), 1400–1427. (<a
href="https://doi.org/10.1007/s00453-023-01198-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In offline scheduling models, jobs are given with their exact processing times. In their online counterparts, jobs arrive in sequence together with their processing times and the scheduler makes irrevocable decisions on how to execute each of them upon its arrival. We consider a semi-online variant which has equally rich application background, called scheduling with testing, where the exact processing time of a job is revealed only after a required testing operation is finished, or otherwise the job has to be executed for a given possibly over-estimated length of time. For multiprocessor scheduling with testing to minimize the total job completion time, we present several first approximation algorithms with constant competitive ratios for various settings, including a $$2 \varphi $$ -competitive algorithm for the non-preemptive general testing case and a $$(0.0382 + 2.7925 (1 - \frac{1}{2\,m}))$$ -competitive randomized algorithm, when the number of machines $$m \ge 37$$ or otherwise 2.7925-competitive, where $$\varphi = (1 + \sqrt{5}) / 2 &lt; 1.6181$$ is the golden ratio and m is the number of machines, a $$(3.5 - \frac{3}{2\,m})$$ -competitive algorithm allowing job preemption when $$m \ge 3$$ or otherwise 3-competitive, and a $$(\varphi + \frac{\varphi + 1}{2} (1 - \frac{1}{\,}m))$$ -competitive algorithm for the non-preemptive uniform testing case when $$m \ge 5$$ or otherwise $$(\varphi + 1)$$ -competitive. Our results improve three previous best approximation algorithms for the single machine scheduling with testing problems, respectively.},
  archive      = {J_Alg},
  author       = {Gong, Mingyang and Chen, Zhi-Zhong and Hayashi, Kuniteru},
  doi          = {10.1007/s00453-023-01198-w},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1400-1427},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithms for multiprocessor scheduling with testing to minimize the total job completion time},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Theoretical analysis of git bisect. <em>Alg</em>,
<em>86</em>(5), 1365–1399. (<a
href="https://doi.org/10.1007/s00453-023-01194-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of finding a regression in a version control system (VCS), such as git. The set of versions is modelled by a directed acyclic graph (DAG) where vertices represent versions of the software, and arcs are the changes between different versions. We assume that somewhere in the DAG, a bug was introduced, which persists in all of its subsequent versions. It is possible to query a vertex to check whether the corresponding version carries the bug. Given a DAG and a bugged vertex, the Regression Search Problem consists in finding the first vertex containing the bug in a minimum number of queries in the worst-case scenario. This problem is known to be NP-complete. We study the algorithm used in git to address this problem, known as git bisect. We prove that in a general setting, git bisect can use an exponentially larger number of queries than an optimal algorithm. We also consider the restriction where all vertices have indegree at most 2 (i.e. where merges are made between at most two branches at a time in the VCS), and prove that in this case, git bisect is a $$\frac{1}{\log _2(3/2)}$$ -approximation algorithm, and that this bound is tight. We also provide a better approximation algorithm for this case. Finally, we give an alternative proof of the NP-completeness of the Regression Search Problem, via a variation with bounded indegree.},
  archive      = {J_Alg},
  author       = {Courtiel, Julien and Dorbec, Paul and Lecoq, Romain},
  doi          = {10.1007/s00453-023-01194-0},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1365-1399},
  shortjournal = {Algorithmica},
  title        = {Theoretical analysis of git bisect},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic variance reduction for DR-submodular
maximization. <em>Alg</em>, <em>86</em>(5), 1335–1364. (<a
href="https://doi.org/10.1007/s00453-023-01195-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimization has experienced significant growth in recent decades, with the increasing prevalence of variance reduction techniques in stochastic optimization algorithms to enhance computational efficiency. In this paper, we introduce two projection-free stochastic approximation algorithms for maximizing diminishing return (DR) submodular functions over convex constraints, building upon the Stochastic Path Integrated Differential EstimatoR (SPIDER) and its variants. Firstly, we present a SPIDER Continuous Greedy (SPIDER-CG) algorithm for the monotone case that guarantees a $$(1-e^{-1})\text {OPT}-\varepsilon $$ approximation after $$\mathcal {O}(\varepsilon ^{-1})$$ iterations and $$\mathcal {O}(\varepsilon ^{-2})$$ stochastic gradient computations under the mean-squared smoothness assumption. For the non-monotone case, we develop a SPIDER Frank–Wolfe (SPIDER-FW) algorithm that guarantees a $$\frac{1}{4}(1-\min _{x\in \mathcal {C}}{\Vert x\Vert _{\infty }})\text {OPT}-\varepsilon $$ approximation with $$\mathcal {O}(\varepsilon ^{-1})$$ iterations and $$\mathcal {O}(\varepsilon ^{-2})$$ stochastic gradient estimates. To address the practical challenge associated with a large number of samples per iteration, we introduce a modified gradient estimator based on SPIDER, leading to a Hybrid SPIDER-FW (Hybrid SPIDER-CG) algorithm, which achieves the same approximation guarantee as SPIDER-FW (SPIDER-CG) algorithm with only $$\mathcal {O}(1)$$ samples per iteration. Numerical experiments on both simulated and real data demonstrate the efficiency of the proposed methods.},
  archive      = {J_Alg},
  author       = {Lian, Yuefang and Du, Donglei and Wang, Xiao and Xu, Dachuan and Zhou, Yang},
  doi          = {10.1007/s00453-023-01195-z},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1335-1364},
  shortjournal = {Algorithmica},
  title        = {Stochastic variance reduction for DR-submodular maximization},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum weighted independent set: Effective reductions and
fast algorithms on sparse graphs. <em>Alg</em>, <em>86</em>(5),
1293–1334. (<a
href="https://doi.org/10.1007/s00453-023-01197-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum independent set problem is one of the most important problems in graph algorithms and has been extensively studied in the line of research on the worst-case analysis of exact algorithms for NP-hard problems. In the weighted version, each vertex in the graph is associated with a weight and we are going to find an independent set of maximum total vertex weight. Many reduction rules for the unweighted version have been developed that can be used to effectively reduce the input instance without loss the optimality. However, it seems that reduction rules for the weighted version have not been systemically studied. In this paper, we design a series of reduction rules for the maximum weighted independent set problem and also design a fast exact algorithm based on the reduction rules. By using the measure-and-conquer technique to analyze the algorithm, we show that the algorithm runs in $$O^*(1.1443^{(0.624x-0.872)n&#39;})$$ time and polynomial space, where $$n&#39;$$ is the number of vertices of degree at least 2 and x is the average degree of these vertices in the graph. When the average degree is small, our running-time bound beats previous results. For example, on graphs with the minimum degree at least 2 and average degree at most 3.68, our running time bound is better than that of previous polynomial-space algorithms for graphs with maximum degree at most 4.},
  archive      = {J_Alg},
  author       = {Xiao, Mingyu and Huang, Sen and Chen, Xiaoyu},
  doi          = {10.1007/s00453-023-01197-x},
  journal      = {Algorithmica},
  month        = {5},
  number       = {5},
  pages        = {1293-1334},
  shortjournal = {Algorithmica},
  title        = {Maximum weighted independent set: Effective reductions and fast algorithms on sparse graphs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Partial and simultaneous transitive orientations via modular
decompositions. <em>Alg</em>, <em>86</em>(4), 1263–1292. (<a
href="https://doi.org/10.1007/s00453-023-01188-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A natural generalization of the recognition problem for a geometric graph class is the problem of extending a representation of a subgraph to a representation of the whole graph. A related problem is to find representations for multiple input graphs that coincide on subgraphs shared by the input graphs. A common restriction is the sunflower case where the shared graph is the same for each pair of input graphs. These problems translate to the setting of comparability graphs where the representations correspond to transitive orientations of their edges. We use modular decompositions to improve the runtime for the orientation extension problem and the sunflower orientation problem to linear time. We apply these results to improve the runtime for the partial representation problem and the sunflower case of the simultaneous representation problem for permutation graphs to linear time. We also give the first efficient algorithms for these problems on circular permutation graphs.},
  archive      = {J_Alg},
  author       = {Münch, Miriam and Rutter, Ignaz and Stumpf, Peter},
  doi          = {10.1007/s00453-023-01188-y},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1263-1292},
  shortjournal = {Algorithmica},
  title        = {Partial and simultaneous transitive orientations via modular decompositions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combinatorial reallocation mechanisms. <em>Alg</em>,
<em>86</em>(4), 1246–1262. (<a
href="https://doi.org/10.1007/s00453-023-01191-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider reallocation problems in settings where the initial endowment of each agent consists of a subset of the resources. The private information of the players is their value for every possible subset of the resources. The goal is to redistribute resources among agents to maximize efficiency. Monetary transfers are allowed, but participation is voluntary. We develop incentive-compatible, individually-rational and budget-balanced mechanisms for two settings in which agents have complex multi-parameter valuations, both settings include double auctions as a special case. The first setting is combinatorial exchanges, where we provide a mechanism that achieves a logarithmic approximation to the optimal efficiency when valuations are subadditive. The second setting is Arrow–Debreu markets for a single divisible good, where we present a constant approximation mechanism. The first result is given for a Bayesian setting, where the latter result is for prior-free environments.},
  archive      = {J_Alg},
  author       = {Blumrosen, Liad and Dobzinski, Shahar},
  doi          = {10.1007/s00453-023-01191-3},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1246-1262},
  shortjournal = {Algorithmica},
  title        = {Combinatorial reallocation mechanisms},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Server cloud scheduling. <em>Alg</em>, <em>86</em>(4),
1210–1245. (<a
href="https://doi.org/10.1007/s00453-023-01189-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a set of jobs connected to a directed acyclic task graph with a fixed source and sink. The edges of this graph model precedence constraints and the jobs have to be scheduled with respect to those. We introduce the server cloud scheduling problem, in which the jobs have to be processed either on a single local machine or on one of infinitely many cloud machines. For each job, processing times both on the server and in the cloud are given. Furthermore, for each edge in the task graph, a communication delay is included in the input and has to be taken into account if one of the two jobs is scheduled on the server and the other in the cloud. The server processes jobs sequentially, whereas the cloud can serve as many as needed in parallel, but induces costs. We consider both makespan and cost minimization. The main results are an FPTAS for the makespan objective for graphs with a constant source and sink dividing cut and strong hardness for the case with unit processing times and delays.},
  archive      = {J_Alg},
  author       = {Maack, Marten and Meyer auf der Heide, Friedhelm and Pukrop, Simon},
  doi          = {10.1007/s00453-023-01189-x},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1210-1245},
  shortjournal = {Algorithmica},
  title        = {Server cloud scheduling},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum matching sans maximal matching: A new approach for
finding maximum matchings in the data stream model. <em>Alg</em>,
<em>86</em>(4), 1173–1209. (<a
href="https://doi.org/10.1007/s00453-023-01190-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of finding a maximum size matching in a graph (known as the maximum matching problem) is one of the most classical problems in computer science. Despite a significant body of work dedicated to the study of this problem in the data stream model, the state-of-the-art single-pass semi-streaming algorithm for it is still a simple greedy algorithm that computes a maximal matching, and this way obtains $${1}/{2}$$ -approximation. Some previous works described two/three-pass algorithms that improve over this approximation ratio by using their second and third passes to improve the above mentioned maximal matching. One contribution of this paper continues this line of work by presenting new three-pass semi-streaming algorithms that work along these lines and obtain improved approximation ratios of 0.6111 and 0.5694 for triangle-free and general graphs, respectively. Unfortunately, a recent work Konrad and Naidu (Approximation, randomization, and combinatorial optimization. Algorithms and techniques, APPROX/RANDOM 2021, August 16–18, 2021. LIPIcs, vol 207, pp 19:1–19:18, 2021. https://doi.org/10.4230/LIPIcs.APPROX/RANDOM.2021.19 ) shows that the strategy of constructing a maximal matching in the first pass and then improving it in further passes has limitations. Additionally, this technique is unlikely to get us closer to single-pass semi-streaming algorithms obtaining a better than $${1}/{2}$$ -approximation. Therefore, it is interesting to come up with algorithms that do something else with their first pass (we term such algorithms non-maximal-matching-first algorithms). No such algorithms were previously known, and the main contribution of this paper is describing such algorithms that obtain approximation ratios of 0.5384 and 0.5555 in two and three passes, respectively, for general graphs. The main significance of our results is not in the numerical improvements, but in demonstrating the potential of non-maximal-matching-first algorithms.},
  archive      = {J_Alg},
  author       = {Feldman, Moran and Szarf, Ariel},
  doi          = {10.1007/s00453-023-01190-4},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1173-1209},
  shortjournal = {Algorithmica},
  title        = {Maximum matching sans maximal matching: A new approach for finding maximum matchings in the data stream model},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Complexity issues on of secondary domination number.
<em>Alg</em>, <em>86</em>(4), 1163–1172. (<a
href="https://doi.org/10.1007/s00453-023-01192-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the computational complexity issues of the problem of secondary domination (known also as (1, 2)-domination) in several graph classes. We also study the computational complexity of the problem of determining whether the domination and secondary domination numbers are equal. In particular, we study the influence of triangles and vertices of degree 1 on these numbers. Also, an optimal algorithm for finding a minimum secondary dominating set in trees is presented.},
  archive      = {J_Alg},
  author       = {Raczek, Joanna},
  doi          = {10.1007/s00453-023-01192-2},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1163-1172},
  shortjournal = {Algorithmica},
  title        = {Complexity issues on of secondary domination number},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation algorithms for the min–max mixed rural postmen
cover problem and its variants. <em>Alg</em>, <em>86</em>(4), 1135–1162.
(<a href="https://doi.org/10.1007/s00453-023-01187-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a multi-vehicle (or multi-postman) extension of the classical Mixed Rural Postman Problem, which we call the Min–Max Mixed Rural Postmen Cover Problem (MRPCP). The MRPCP is defined on a mixed graph $$G=(V,E,A)$$ , where V is the vertex set, E denotes the (undirected) edge set and A represents the (directed) arc set. Let $$F\subseteq E$$ ( $$H\subseteq A$$ ) be the set of required edges (required arcs). There is a nonnegative weight associated with each edge and arc. The objective is to determine no more than k closed walks to cover all the required edges in F and all the required arcs in H such that the weight of the maximum weight closed walk is minimized. By replacing closed walks with (open) walks in the MRPCP, we obtain the Min–Max Mixed Rural Postmen Walk Cover Problem (MRPWCP). The Min–Max Mixed Chinese Postmen Cover Problem (MCPCP) is a special case of the MRPCP where $$F=E$$ and $$H=A$$ . The Min–Max Stacker Crane Cover Problem (SCCP) is another special case of the MRPCP where $$F=\emptyset $$ and $$H=A$$ For the MRPCP with the input graph satisfying the weakly symmetric condition, i.e., for each arc there exists a parallel edge whose weight is not greater than this arc, we devise a $$\frac{27}{4}$$ -approximation algorithm. This algorithm achieves an approximation ratio of $$\frac{33}{5}$$ for the SCCP with the weakly symmetric condition. Moreover, we obtain the first 5-approximation algorithm (4-approximation algorithm) for the MRPWCP (MCPCP) with the weakly symmetric condition.},
  archive      = {J_Alg},
  author       = {Huang, Liting and Yu, Wei and Liu, Zhaohui},
  doi          = {10.1007/s00453-023-01187-z},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1135-1162},
  shortjournal = {Algorithmica},
  title        = {Approximation algorithms for the Min–Max mixed rural postmen cover problem and its variants},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On maximizing sums of non-monotone submodular and linear
functions. <em>Alg</em>, <em>86</em>(4), 1080–1134. (<a
href="https://doi.org/10.1007/s00453-023-01183-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of Regularized Unconstrained Submodular Maximization (RegularizedUSM) as defined by Bodek and Feldman (Maximizing sums of non-monotone submodular and linear functions: understanding the unconstrained case, arXiv:2204.03412 , 2022): given query access to a non-negative submodular function $$f:2^{{\mathcal {N}}}\rightarrow {\mathbb {R}}_{\ge 0}$$ and a linear function $$\ell :2^{{\mathcal {N}}}\rightarrow {\mathbb {R}}$$ over the same ground set $${\mathcal {N}}$$ , output a set $$T\subseteq {\mathcal {N}}$$ approximately maximizing the sum $$f(T)+\ell (T)$$ . An algorithm is said to provide an $$(\alpha ,\beta )$$ -approximation for RegularizedUSM if it outputs a set T such that $${\mathbb {E}}[f(T)+\ell (T)]\ge \max _{S\subseteq {\mathcal {N}}}[\alpha \cdot f(S)+\beta \cdot \ell (S)]$$ . We also consider the setting where S and T are constrained to be independent in a given matroid, which we refer to as Regularized Constrained Submodular Maximization (RegularizedCSM). The special case of RegularizedCSM with monotone f has been extensively studied (Sviridenko et al. in Math Oper Res 42(4):1197–1218, 2017; Feldman in Algorithmica 83(3):853–878, 2021; Harshaw et al., in: International conference on machine learning, PMLR, 2634–2643, 2019), whereas we are aware of only one prior work that studies RegularizedCSM with non-monotone f (Lu et al. in Optimization 1–27, 2023), and that work constrains $$\ell $$ to be non-positive. In this work, we provide improved $$(\alpha ,\beta )$$ -approximation algorithms for both RegularizedUSM and RegularizedCSM with non-monotone f. Specifically, we are the first to provide nontrivial $$(\alpha ,\beta )$$ -approximations for RegularizedCSM where the sign of $$\ell $$ is unconstrained, and the $$\alpha $$ we obtain for RegularizedUSM improves over (Bodek and Feldman in Maximizing sums of non-monotone submodular and linear functions: understanding the unconstrained case, arXiv:2204.03412 , 2022) for all $$\beta \in (0,1)$$ . We also prove new inapproximability results for RegularizedUSM and RegularizedCSM, as well as 0.478-inapproximability for maximizing a submodular function where S and T are subject to a cardinality constraint, improving a 0.491-inapproximability result due to Oveis Gharan and Vondrak (in: Proceedings of the twenty-second annual ACM-SIAM symposium on discrete algorithms, SIAM, pp 1098–1116, 2011).},
  archive      = {J_Alg},
  author       = {Qi, Benjamin},
  doi          = {10.1007/s00453-023-01183-3},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1080-1134},
  shortjournal = {Algorithmica},
  title        = {On maximizing sums of non-monotone submodular and linear functions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A deterministic parallel reduction from weighted matroid
intersection search to decision. <em>Alg</em>, <em>86</em>(4),
1057–1079. (<a
href="https://doi.org/10.1007/s00453-023-01184-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given two matroids on the same ground set, the matroid intersection problem asks for a common base, i.e., a subset of the ground set that is a base in both the matroids. The weighted version of the problem asks for a common base with maximum weight. In the case of linearly representable matroids, the weighted version is known to have a randomized parallel (RNC) algorithm based on the isolation lemma, when the given weights are polynomially bounded (Narayanan et al. in SIAM J Comput 23(2): 387–397, 1994). Finding a deterministic parallel (NC) algorithm, even for the unweighted decision question, has been a long-standing open question. The above RNC algorithm can be viewed as a randomized reduction from weighted search to weighted decision, which works for arbitrary matroids. We derandomize this reduction, i.e., we give an NC algorithm for weighted matroid intersection search using oracle access to its decision version.},
  archive      = {J_Alg},
  author       = {Ghosh, Sumanta and Gurjar, Rohit and Raj, Roshan},
  doi          = {10.1007/s00453-023-01184-2},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1057-1079},
  shortjournal = {Algorithmica},
  title        = {A deterministic parallel reduction from weighted matroid intersection search to decision},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Near-optimal search time in <span
class="math display"><em>δ</em></span> -optimal space, and vice versa.
<em>Alg</em>, <em>86</em>(4), 1031–1056. (<a
href="https://doi.org/10.1007/s00453-023-01186-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two recent lower bounds on the compressibility of repetitive sequences, $$\delta \le \gamma $$ , have received much attention. It has been shown that a length-n string S over an alphabet of size $$\sigma $$ can be represented within the optimal $$O(\delta \log \tfrac{n\log \sigma }{\delta \log n})$$ space, and further, that within that space one can find all the occ occurrences in S of any length-m pattern in time $$O(m\log n + occ \log ^\epsilon n)$$ for any constant $$\epsilon &gt;0$$ . Instead, the near-optimal search time $$O(m+({occ+1})\log ^\epsilon n)$$ has been achieved only within $$O(\gamma \log \frac{n}{\gamma })$$ space. Both results are based on considerably different locally consistent parsing techniques. The question of whether the better search time could be supported within the $$\delta $$ -optimal space remained open. In this paper, we prove that both techniques can indeed be combined to obtain the best of both worlds: $$O(m+({occ+1})\log ^\epsilon n)$$ search time within $$O(\delta \log \tfrac{n\log \sigma }{\delta \log n})$$ space. Moreover, the number of occurrences can be computed in $$O(m+\log ^{2+\epsilon }n)$$ time within $$O(\delta \log \tfrac{n\log \sigma }{\delta \log n})$$ space. We also show that an extra sublogarithmic factor on top of this space enables optimal $$O(m+occ)$$ search time, whereas an extra logarithmic factor enables optimal O(m) counting time.},
  archive      = {J_Alg},
  author       = {Kociumaka, Tomasz and Navarro, Gonzalo and Olivares, Francisco},
  doi          = {10.1007/s00453-023-01186-0},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1031-1056},
  shortjournal = {Algorithmica},
  title        = {Near-optimal search time in $$\delta $$ -optimal space, and vice versa},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On finding constrained independent sets in cycles.
<em>Alg</em>, <em>86</em>(4), 1006–1030. (<a
href="https://doi.org/10.1007/s00453-023-01179-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subset of $$[n] = \{1,2,\ldots ,n\}$$ is called stable if it forms an independent set in the cycle on the vertex set [n]. In 1978, Schrijver proved via a topological argument that for all integers n and k with $$n \ge 2k$$ , the family of stable k-subsets of [n] cannot be covered by $$n-2k+1$$ intersecting families. We study two total search problems whose totality relies on this result. In the first problem, denoted by $$\textsc {Schrijver}(n,k,m)$$ , we are given an access to a coloring of the stable k-subsets of [n] with $$m = m(n,k)$$ colors, where $$m \le n-2k+1$$ , and the goal is to find a pair of disjoint subsets that are assigned the same color. While for $$m = n-2k+1$$ the problem is known to be $$\textsf{PPA}$$ -complete, we prove that for $$m &lt; d \cdot \lfloor \frac{n}{2k+d-2} \rfloor $$ , with d being any fixed constant, the problem admits an efficient algorithm. For $$m = \lfloor n/2 \rfloor -2k+1$$ , we prove that the problem is efficiently reducible to the $$\textsc {Kneser}$$ problem. Motivated by the relation between the problems, we investigate the family of unstable k-subsets of [n], which might be of independent interest. In the second problem, called Unfair Independent Set in Cycle, we are given $$\ell $$ subsets $$V_1, \ldots , V_\ell $$ of [n], where $$\ell \le n-2k+1$$ and $$|V_i| \ge 2$$ for all $$i \in [\ell ]$$ , and the goal is to find a stable k-subset S of [n] satisfying the constraints $$|S \cap V_i| \le |V_i|/2$$ for $$i \in [\ell ]$$ . We prove that the problem is $$\textsf{PPA}$$ -complete and that its restriction to instances with $$n=3k$$ is at least as hard as the Cycle plus Triangles problem, for which no efficient algorithm is known. On the contrary, we prove that there exists a constant c for which the restriction of the problem to instances with $$n \ge c \cdot k$$ can be solved in polynomial time.},
  archive      = {J_Alg},
  author       = {Haviv, Ishay},
  doi          = {10.1007/s00453-023-01179-z},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {1006-1030},
  shortjournal = {Algorithmica},
  title        = {On finding constrained independent sets in cycles},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parameterised and fine-grained subgraph counting, modulo 2.
<em>Alg</em>, <em>86</em>(4), 944–1005. (<a
href="https://doi.org/10.1007/s00453-023-01178-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a class of graphs $${\mathcal {H}}$$ , the problem $$\oplus \text {{Sub}}({\mathcal {H}})$$ is defined as follows. The input is a graph $$H\in {\mathcal {H}}$$ together with an arbitrary graph G. The problem is to compute, modulo 2, the number of subgraphs of G that are isomorphic to H. The goal of this research is to determine for which classes $${\mathcal {H}}$$ the problem $$\oplus \text {{Sub}}({\mathcal {H}})$$ is fixed-parameter tractable (FPT), i.e., solvable in time $$f(|H|)\cdot |G|^{O(1)}$$ . Curticapean, Dell, and Husfeldt (ESA 2021) conjectured that $$\oplus \text {{Sub}}({\mathcal {H}})$$ is FPT if and only if the class of allowed patterns $${\mathcal {H}}$$ is matching splittable, which means that for some fixed B, every $$H \in {\mathcal {H}}$$ can be turned into a matching (a graph in which every vertex has degree at most 1) by removing at most B vertices. Assuming the randomised Exponential Time Hypothesis, we prove their conjecture for (I) all hereditary pattern classes $${\mathcal {H}}$$ , and (II) all tree pattern classes, i.e., all classes $${\mathcal {H}}$$ such that every $$H\in {\mathcal {H}}$$ is a tree. We also establish almost tight fine-grained upper and lower bounds for the case of hereditary patterns (I).},
  archive      = {J_Alg},
  author       = {Goldberg, Leslie Ann and Roth, Marc},
  doi          = {10.1007/s00453-023-01178-0},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {944-1005},
  shortjournal = {Algorithmica},
  title        = {Parameterised and fine-grained subgraph counting, modulo 2},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing the maximum flow time in the online food delivery
problem. <em>Alg</em>, <em>86</em>(4), 907–943. (<a
href="https://doi.org/10.1007/s00453-023-01177-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a common delivery problem encountered in nowadays online food-ordering platforms: Customers order dishes online, and the restaurant delivers the food after receiving the order. Specifically, we study a problem where k vehicles of capacity c are serving a set of requests ordering food from one restaurant. After a request arrives, it can be served by a vehicle moving from the restaurant to its delivery location. We are interested in serving all requests while minimizing the maximum flow-time, i.e., the maximum time length a customer waits to receive his/her food after submitting the order. The problem also has a close connection with the broadcast scheduling problem with maximum flow time objective. We show that the problem is hard in both offline and online settings even when $$k = 1$$ and $$c = \infty $$ : There is a hardness of approximation of $$\Omega (n)$$ for the offline problem, and a lower bound of $$\Omega (n)$$ on the competitive ratio of any online algorithm, where n is number of points in the metric. We circumvent the strong negative results in two directions. Our main result is an O(1)-competitive online algorithm for the uncapaciated (i.e, $$c = \infty $$ ) food delivery problem on tree metrics; we also have a negative result showing that the condition $$c = \infty $$ is needed. Then we consider the speed-augmentation model, in which our online algorithm is allowed to use $$\alpha $$ -speed vehicles, where $$\alpha \ge 1$$ is called the speeding factor. We develop an exponential time $$(1+\epsilon )$$ -speeding $$O(1/\epsilon )$$ -competitive algorithm for any $$\epsilon &gt; 0$$ . A polynomial time algorithm can be obtained with a speeding factor of $$\alpha _{\textsf{TSP}}+ \epsilon $$ or $$\alpha _{\textsf{CVRP}}+ \epsilon $$ , depending on whether the problem is uncapacitated. Here $$\alpha _{\textsf{TSP}}$$ and $$\alpha _{\textsf{CVRP}}$$ are the best approximation factors for the traveling salesman (TSP) and capacitated vehicle routing (CVRP) problems respectively. We complement the results with some negative ones.},
  archive      = {J_Alg},
  author       = {Guo, Xiangyu and Li, Shi and Luo, Kelin and Zhang, Yuhao},
  doi          = {10.1007/s00453-023-01177-1},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {907-943},
  shortjournal = {Algorithmica},
  title        = {Minimizing the maximum flow time in the online food delivery problem},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing a minimum subset feedback vertex set on chordal
graphs parameterized by leafage. <em>Alg</em>, <em>86</em>(3), 874–906.
(<a href="https://doi.org/10.1007/s00453-023-01149-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chordal graphs are characterized as the intersection graphs of subtrees in a tree and such a representation is known as the tree model. Restricting the characterization results in well-known subclasses of chordal graphs such as interval graphs or split graphs. A typical example of a problem that does not behave computationally the same in all subclasses of chordal graphs is the Subset Feedback Vertex Set (SFVS) problem: given a vertex-weighted graph $$G=(V,E)$$ and a set $$S\subseteq V$$ , we seek for a vertex set of minimum weight that intersects all cycles containing a vertex of S. SFVS is known to be polynomial-time solvable on interval graphs, whereas SFVS remains np-complete on split graphs and, consequently, on chordal graphs. Towards a better understanding of the complexity of SFVS on subclasses of chordal graphs, we exploit structural properties of a tree model in order to cope with the hardness of SFVS. Here we consider the leafage, which measures the minimum number of leaves in a tree model. We show that SFVS can be solved in polynomial time for every chordal graph with bounded leafage. In particular, given a chordal graph on n vertices with leafage $$\ell $$ , we provide an algorithm for solving SFVS with running time $$n^{O(\ell )}$$ , thus improving upon $$n^{O(\ell ^2)}$$ , which is the running time of an approach that utilizes the previously known algorithm for graphs with bounded mim-width. We complement our result by showing that SFVS is w[1]-hard parameterized by $$\ell $$ . Pushing further our positive result, it is natural to also consider the vertex leafage, which measures the minimum upper bound on the number of leaves of every subtree in a tree model. However, we show that it is unlikely to obtain a similar result, as we prove that SFVS remains np-complete on undirected path graphs, i.e., chordal graphs having vertex leafage at most two. Lastly, we provide a polynomial-time algorithm for solving SFVS on rooted path graphs, a proper subclass of undirected path graphs and graphs with mim-width one, which is faster than the approach of constructing a graph decomposition of mim-width one and applying the previously known algorithm for graphs with bounded mim-width.},
  archive      = {J_Alg},
  author       = {Papadopoulos, Charis and Tzimas, Spyridon},
  doi          = {10.1007/s00453-023-01149-5},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {874-906},
  shortjournal = {Algorithmica},
  title        = {Computing a minimum subset feedback vertex set on chordal graphs parameterized by leafage},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data structures for computing unique palindromes in static
and non-static strings. <em>Alg</em>, <em>86</em>(3), 852–873. (<a
href="https://doi.org/10.1007/s00453-023-01170-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A palindromic substring T[i..j] of a string T is said to be a shortest unique palindromic substring (SUPS) in T for an interval [p, q] if T[i..j] is a shortest palindromic substring such that T[i..j] occurs only once in T, and [i, j] contains [p, q]. The SUPS problem is, given a string T of length n, to construct a data structure that can compute all the SUPSs for any given query interval. It is known that any SUPS query can be answered in $$O(\alpha )$$ time after O(n)-time preprocessing, where $$\alpha $$ is the number of SUPSs to output (Inoue in J Discrete Algorithms 52-53:122–132, 2018). In this paper, we first show that $$\alpha $$ is at most 4, and the upper bound is tight. We also show that the total sum of lengths of minimal unique palindromic substrings of string T, which is strongly related to SUPSs, is O(n). Then, we present the first O(n)-bits data structures that can answer any SUPS query in constant time. Also, we present an algorithm to solve the SUPS problem for a sliding window that can answer any query in $$O(\log \log W)$$ time and update data structures in amortized $$O(\log \sigma + \log \log W)$$ time, where W is the size of the window, and $$\sigma $$ is the alphabet size. Furthermore, we consider the SUPS problem in the after-edit model and present an efficient algorithm. Namely, we present an algorithm that uses O(n) time for preprocessing and answers any k SUPS queries in $$O(\log n\log \log n + k\log \log n)$$ time after single character substitution. Finally, as a by-product, we propose a fully-dynamic data structure for range minimum queries (RmQs) with a constraint where the width of each query range is limited to poly-logarithmic. The constrained RmQ data structure can answer such a query in constant time and support a single-element edit operation in amortized constant time.},
  archive      = {J_Alg},
  author       = {Mieno, Takuya and Funakoshi, Mitsuru},
  doi          = {10.1007/s00453-023-01170-8},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {852-873},
  shortjournal = {Algorithmica},
  title        = {Data structures for computing unique palindromes in static and non-static strings},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reducing graph parameters by contractions and deletions.
<em>Alg</em>, <em>86</em>(3), 825–851. (<a
href="https://doi.org/10.1007/s00453-023-01141-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the following problem: for a given graph G and two integers k and d, can we apply a fixed graph operation at most k times in order to reduce a given graph parameter $$\pi $$ by at least d? We show that this problem is NP-hard when the parameter is the independence number and the graph operation is vertex deletion or edge contraction, even for fixed $$d=1$$ and when restricted to chordal graphs. We give a polynomial time algorithm for bipartite graphs when the operation is edge contraction, the parameter is the independence number and d is fixed. Further, we complete the complexity dichotomy for H-free graphs when the parameter is the clique number and the operation is edge contraction by showing that this problem is NP-hard in $$(C_3+P_1)$$ -free graphs even for fixed $$d=1$$ . When the operation is edge deletion and the parameter is the chromatic number, we determine the computational complexity of the associated problem for cographs and complete multipartite graphs. Our results answer several open questions stated in Diner et al. (Theor Comput Sci 746:49–72, 2012, https://doi.org/10.1016/j.tcs.2018.06.023 ).},
  archive      = {J_Alg},
  author       = {Lucke, Felicia and Mann, Felix},
  doi          = {10.1007/s00453-023-01141-z},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {825-851},
  shortjournal = {Algorithmica},
  title        = {Reducing graph parameters by contractions and deletions},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Winner determination algorithms for graph games with
matching structures. <em>Alg</em>, <em>86</em>(3), 808–824. (<a
href="https://doi.org/10.1007/s00453-023-01136-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cram, Domineering, and Arc Kayles are well-studied combinatorial games. They are interpreted as edge-selecting-type games on graphs, and the selected edges during a game form a matching. In this paper, we define a generalized game called Colored Arc Kayles, which includes these games. Colored Arc Kayles is played on a graph whose edges are colored in black, white, or gray, and black (resp., white) edges can be selected only by the black (resp., white) player, while gray edges can be selected by both black and white players. We first observe that the winner determination for Colored Arc Kayles can be done in $$O^*(2^n)$$ time by a simple algorithm, where n is the order of the input graph. We then focus on the vertex cover number, which is linearly related to the number of turns, and show that Colored Arc Kayles, BW-Arc Kayles, and Arc Kayles are solved in time $$O^*(1.4143^{{\tau }^2+3.17{\tau }})$$ , $$O^*(1.3161^{{\tau }^2+4{{\tau }}})$$ , and $$O^*(1.1893^{{\tau }^2+6.34{{\tau }}})$$ , respectively, where $${\tau }$$ is the vertex cover number. Furthermore, we present an $$O^*((n/{\nu }+1)^{{\nu }})$$ -time algorithm for Arc Kayles, where $${\nu }$$ is neighborhood diversity. We finally show that Arc Kayles on trees can be solved in $$O^* (2^{n/2})(=O(1.4143^n))$$ time, which improves $$O^*(3^{n/3})(=O(1.4423^n))$$ by a direct adjustment of the analysis of Bodlaender et al.’s $$O^*(3^{n/3})$$ -time algorithm for Node Kayles.},
  archive      = {J_Alg},
  author       = {Hanaka, Tesshu and Kiya, Hironori and Ono, Hirotaka and Yoshiwatari, Kanae},
  doi          = {10.1007/s00453-023-01136-w},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {808-824},
  shortjournal = {Algorithmica},
  title        = {Winner determination algorithms for graph games with matching structures},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). List covering of regular multigraphs with semi-edges.
<em>Alg</em>, <em>86</em>(3), 782–807. (<a
href="https://doi.org/10.1007/s00453-023-01163-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In line with the recent development in topological graph theory, we are considering undirected graphs that are allowed to contain multiple edges, loops, and semi-edges. A graph is called simple if it contains no semi-edges, no loops, and no multiple edges. A graph covering projection, also known as a locally bijective homomorphism, is a mapping between vertices and edges of two graphs which preserves incidences and which is a local bijection on the edge-neighborhood of every vertex. This notion stems from topological graph theory, but has also found applications in combinatorics and theoretical computer science. It has been known that for every fixed simple regular graph H of valency greater than 2, deciding if an input graph covers H is NP-complete. Graphs with semi-edges have been considered in this context only recently and only partial results on the complexity of covering such graphs are known so far. In this paper we consider the list version of the problem, called List-H-Cover, where the vertices and edges of the input graph come with lists of admissible targets. Our main result reads that the List-H-Cover problem is NP-complete for every regular graph H of valency greater than 2 which contains at least one semi-simple vertex (i.e., a vertex which is incident with no loops, with no multiple edges and with at most one semi-edge). Using this result we show the NP-co/polytime dichotomy for the computational complexity of List-H-Cover for cubic graphs.},
  archive      = {J_Alg},
  author       = {Bok, Jan and Fiala, Jiří and Jedličková, Nikola and Kratochvíl, Jan and Rzążewski, Paweł},
  doi          = {10.1007/s00453-023-01163-7},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {782-807},
  shortjournal = {Algorithmica},
  title        = {List covering of regular multigraphs with semi-edges},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). 1-extendability of independent sets. <em>Alg</em>,
<em>86</em>(3), 757–781. (<a
href="https://doi.org/10.1007/s00453-023-01138-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the 70 s, Berge introduced 1-extendable graphs (also called B-graphs), which are graphs where every vertex belongs to a maximum independent set. Motivated by an application in the design of wireless networks, we study the computational complexity of 1-extendability, the problem of deciding whether a graph is 1-extendable. We show that, in general, 1-extendability cannot be solved in $$2^{o(n)}$$ time assuming the Exponential Time Hypothesis, where n is the number of vertices of the input graph, and that it remains NP-hard in subcubic planar graphs and in unit disk graphs (which is a natural model for wireless networks). Although 1-extendability seems to be very close to the problem of finding an independent set of maximum size (a.k.a. Maximum Independent Set), we show that, interestingly, there exist 1-extendable graphs for which Maximum Independent Set is NP-hard. Finally, we investigate a parameterized version of 1-extendability.},
  archive      = {J_Alg},
  author       = {Bergé, Pierre and Busson, Anthony and Feghali, Carl and Watrigant, Rémi},
  doi          = {10.1007/s00453-023-01138-8},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {757-781},
  shortjournal = {Algorithmica},
  title        = {1-extendability of independent sets},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing longest lyndon subsequences and longest common
lyndon subsequences. <em>Alg</em>, <em>86</em>(3), 735–756. (<a
href="https://doi.org/10.1007/s00453-023-01125-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a string T of length n whose characters are drawn from an ordered alphabet of size $$\sigma $$ , its longest Lyndon subsequence is a maximum-length subsequence of T that is a Lyndon word. We propose algorithms for finding such a subsequence in $$\mathop {}\mathopen {}\mathcal {O}\mathopen {}(n^3)$$ time with $$\mathop {}\mathopen {}\mathcal {O}\mathopen {}(n)$$ space, or online in $$\mathop {}\mathopen {}\mathcal {O}\mathopen {}(n^3)$$ space and time. Our first result can be extended to find the longest common Lyndon subsequence of two strings of length at most n in $$\mathop {}\mathopen {}\mathcal {O}\mathopen {}(n^4 \sigma )$$ time using $$\mathop {}\mathopen {}\mathcal {O}\mathopen {}(n^2)$$ space.},
  archive      = {J_Alg},
  author       = {Bannai, Hideo and I., Tomohiro and Kociumaka, Tomasz and Köppl, Dominik and Puglisi, Simon J.},
  doi          = {10.1007/s00453-023-01125-z},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {735-756},
  shortjournal = {Algorithmica},
  title        = {Computing longest lyndon subsequences and longest common lyndon subsequences},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster algorithm for finding maximum 1-restricted simple
2-matchings. <em>Alg</em>, <em>86</em>(3), 717–734. (<a
href="https://doi.org/10.1007/s00453-023-01148-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the problem of finding a 1-restricted simple 2-matching of maximum cardinality. Recall that, given an undirected graph $${\varvec{G = (V, E)}}$$ , a simple 2-matching is a subset $${\varvec{M}} \subseteq {\varvec{E}}$$ of edges such that each node in $${\varvec{V}}$$ is incident to at most two edges in $${\varvec{M}}$$ . Clearly, each such $${\varvec{M}}$$ decomposes into a node-disjoint collection of paths and circuits. $${\varvec{M}}$$ is called 1-restricted if it contains no isolated edges (i.e. paths of length one). A combinatorial polynomial algorithm for finding such $${\varvec{M}}$$ of maximum cardinality and also a min-max relation were devised by Hartvigsen. It was shown that finding such $${\varvec{M}}$$ amounts to computing a (not necessarily 1-restricted) simple 2-matching $${\varvec{M}}_{\varvec{0}}$$ of maximum cardinality and subsequently altering it into $${\varvec{M}}$$ of the same cardinality so as to minimize the number of isolated edges. While the first phase (which computes $${\varvec{M}}_{\varvec{0}}$$ ) runs in $${\varvec{O}}\left( {\varvec{E}} \sqrt{V}\right) $$ time, the second one (which turns $${\varvec{M}}_{\varvec{0}}$$ into $${\varvec{M}}$$ ) requires $${\varvec{O(VE)}}$$ time. In this paper we apply the general blocking augmentation approach (initially introduced, e.g., for bipartite matchings by Hopcroft and Karp, and also by Dinic) and present a novel algorithm that reduces the time needed for the second phase to $${\varvec{O}}\left( \textbf{E} \sqrt{V}\right) $$ thus completely closing the gap between 1-restricted and unrestricted cases.},
  archive      = {J_Alg},
  author       = {Artamonov, Stepan and Babenko, Maxim},
  doi          = {10.1007/s00453-023-01148-6},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {717-734},
  shortjournal = {Algorithmica},
  title        = {Faster algorithm for finding maximum 1-restricted simple 2-matchings},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perfect matchings with crossings. <em>Alg</em>,
<em>86</em>(3), 697–716. (<a
href="https://doi.org/10.1007/s00453-023-01147-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For sets of n points, n even, in general position in the plane, we consider straight-line drawings of perfect matchings on them. It is well known that such sets admit at least $$C_{n/2}$$ different plane perfect matchings, where $$C_{n/2}$$ is the n/2-th Catalan number. Generalizing this result we are interested in the number of drawings of perfect matchings which have k crossings. We show the following results. (1) For every $$k\le \frac{1}{64}n^2-\frac{35}{32}n\sqrt{n}+\frac{1225}{64}n$$ , any set with n points, n sufficiently large, admits a perfect matching with exactly k crossings. (2) There exist sets of n points where every perfect matching has at most $$\frac{5}{72}n^2-\frac{n}{4}$$ crossings. (3) The number of perfect matchings with at most k crossings is superexponential in n if k is superlinear in n. (4) Point sets in convex position minimize the number of perfect matchings with at most k crossings for $$k=0,1,2$$ , and maximize the number of perfect matchings with $$\left( {\begin{array}{c}n/2\\ 2\end{array}}\right) $$ crossings and with $${\left( {\begin{array}{c}n/2\\ 2\end{array}}\right) }\!-\!1$$ crossings.},
  archive      = {J_Alg},
  author       = {Aichholzer, Oswin and Fabila-Monroy, Ruy and Kindermann, Philipp and Parada, Irene and Paul, Rosna and Perz, Daniel and Schnider, Patrick and Vogtenhuber, Birgit},
  doi          = {10.1007/s00453-023-01147-7},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {697-716},
  shortjournal = {Algorithmica},
  title        = {Perfect matchings with crossings},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preface of the special issue dedicated to selected papers
from IWOCA 2022. <em>Alg</em>, <em>86</em>(3), 695–696. (<a
href="https://doi.org/10.1007/s00453-024-01225-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_Alg},
  author       = {Bazgan, Cristina and Fernau, Henning},
  doi          = {10.1007/s00453-024-01225-4},
  journal      = {Algorithmica},
  month        = {3},
  number       = {3},
  pages        = {695-696},
  shortjournal = {Algorithmica},
  title        = {Preface of the special issue dedicated to selected papers from IWOCA 2022},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counting cycles on planar graphs in subexponential time.
<em>Alg</em>, <em>86</em>(2), 656–693. (<a
href="https://doi.org/10.1007/s00453-023-01182-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of counting all cycles or self- avoiding walks (SAWs) on triangulated planar graphs. We present a subexponential $$2^{O(\sqrt{n})}$$ time algorithm for this counting problem. Among the technical ingredients used in this algorithm are the planar separator theorem and a delicate analysis using pairs of Motzkin paths and Motzkin numbers. We can then adapt this algorithm to uniformly sample SAWs, in subexponential time. Our work is motivated by the problem of gerrymandered districting maps.},
  archive      = {J_Alg},
  author       = {Cai, Jin-Yi and Maran, Ashwin},
  doi          = {10.1007/s00453-023-01182-4},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {656-693},
  shortjournal = {Algorithmica},
  title        = {Counting cycles on planar graphs in subexponential time},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Token sliding on graphs of girth five. <em>Alg</em>,
<em>86</em>(2), 638–655. (<a
href="https://doi.org/10.1007/s00453-023-01181-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Token Sliding problem we are given a graph G and two independent sets $$I_s$$ and $$I_t$$ in G of size $$k \ge 1$$ . The goal is to decide whether there exists a sequence $$\langle I_1, I_2, \ldots , I_\ell \rangle $$ of independent sets such that for all $$j \in \{1,\ldots , \ell - 1\}$$ the set $$I_j$$ is an independent set of size k, $$I_1 = I_s$$ , $$I_\ell = I_t$$ and $$I_j \triangle I_{j + 1} = \{u, v\} \in E(G)$$ . Intuitively, we view each independent set as a collection of tokens placed on the vertices of the graph. Then, the problem asks whether there exists a sequence of independent sets that transforms $$I_s$$ into $$I_t$$ where at each step we are allowed to slide one token from a vertex to a neighboring vertex. In this paper, we focus on the parameterized complexity of Token Sliding parameterized by k. As shown by Bartier et al. (Algorithmica 83(9):2914–2951, 2021. https://doi.org/10.1007/s00453-021-00848-1 ), the problem is W[1]-hard on graphs of girth four or less, and the authors posed the question of whether there exists a constant $$p \ge 5$$ such that the problem becomes fixed-parameter tractable on graphs of girth at least p. We answer their question positively and prove that the problem is indeed fixed-parameter tractable on graphs of girth five or more, which establishes a full classification of the tractability of Token Sliding parameterized by the number of tokens based on the girth of the input graph.},
  archive      = {J_Alg},
  author       = {Bartier, Valentin and Bousquet, Nicolas and Hanna, Jihad and Mouawad, Amer E. and Siebertz, Sebastian},
  doi          = {10.1007/s00453-023-01181-5},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {638-655},
  shortjournal = {Algorithmica},
  title        = {Token sliding on graphs of girth five},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Recognizing map graphs of bounded treewidth. <em>Alg</em>,
<em>86</em>(2), 613–637. (<a
href="https://doi.org/10.1007/s00453-023-01180-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A map is a partition of the sphere into interior-disjoint regions homeomorphic to closed disks. Some regions are labeled as nations, while the remaining ones are labeled as holes. A map in which at most k nations touch at the same point is a k-map, while it is hole-free if it contains no holes. A graph is a map graph if there is a bijection between its vertices and the nations of a map, such that two nations touch if and only the corresponding vertices are connected by an edge. We present a fixed-parameter tractable algorithm for recognizing map graphs parameterized by treewidth. Its time complexity is linear in the size of the graph. It reports a certificate in the form of a so-called witness, if the input is a yes-instance. Our algorithmic framework is general enough to test, for any k, if the input graph admits a k-map or a hole-free k-map.},
  archive      = {J_Alg},
  author       = {Angelini, Patrizio and Bekos, Michael A. and Da Lozzo, Giordano and Gronemann, Martin and Montecchiani, Fabrizio and Tappini, Alessandra},
  doi          = {10.1007/s00453-023-01180-6},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {613-637},
  shortjournal = {Algorithmica},
  title        = {Recognizing map graphs of bounded treewidth},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meta-theorem for distributed certification. <em>Alg</em>,
<em>86</em>(2), 585–612. (<a
href="https://doi.org/10.1007/s00453-023-01185-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed certification, whether it be proof-labeling schemes, locally checkable proofs, etc., deals with the issue of certifying the legality of a distributed system with respect to a given boolean predicate. A certificate is assigned to each process in the system by a non-trustable oracle, and the processes are in charge of verifying these certificates, so that two properties are satisfied: completeness, i.e., for every legal instance, there is a certificate assignment leading all processes to accept, and soundness, i.e., for every illegal instance, and for every certificate assignment, at least one process rejects. The verification of the certificates must be fast, and the certificates themselves must be small. A large quantity of results have been produced in this framework, each aiming at designing a distributed certification mechanism for specific boolean predicates. This paper presents a “meta-theorem”, applying to many boolean predicates at once. Specifically, we prove that, for every boolean predicate on graphs definable in the monadic second-order (MSO) logic of graphs, there exists a distributed certification mechanism using certificates on $$O(\log ^2n)$$ bits in n-node graphs of bounded treewidth, with a verification protocol involving a single round of communication between neighbors.},
  archive      = {J_Alg},
  author       = {Fraigniaud, Pierre and Montealegre, Pedro and Rapaport, Ivan and Todinca, Ioan},
  doi          = {10.1007/s00453-023-01185-1},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {585-612},
  shortjournal = {Algorithmica},
  title        = {A meta-theorem for distributed certification},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Randomized strategies for robust combinatorial optimization
with approximate separation. <em>Alg</em>, <em>86</em>(2), 566–584. (<a
href="https://doi.org/10.1007/s00453-023-01175-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the following robust optimization problem. Given a set family representing feasibility and candidate objective functions, we choose a feasible set, and then an adversary chooses one objective function, knowing our choice. The goal is to find a randomized strategy (i.e., a probability distribution over the feasible sets) that maximizes the expected objective value in the worst case. This problem is fundamental in wide areas such as artificial intelligence, machine learning, game theory, and optimization. To solve the problem, we provide a general framework based on the dual linear programming problem. In the framework, we utilize the ellipsoid algorithm with the approximate separation algorithm. We prove that there exists an $$\alpha $$ -approximation algorithm for our robust optimization problem if there exists an $$\alpha $$ -approximation algorithm for finding a (deterministic) feasible set that maximizes a nonnegative linear combination of the candidate objective functions. Using our result, we provide approximation algorithms for the max–min fair randomized allocation problem and the maximum cardinality robustness problem with a knapsack constraint.},
  archive      = {J_Alg},
  author       = {Kawase, Yasushi and Sumita, Hanna},
  doi          = {10.1007/s00453-023-01175-3},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {566-584},
  shortjournal = {Algorithmica},
  title        = {Randomized strategies for robust combinatorial optimization with approximate separation},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-adjusting population sizes for non-elitist evolutionary
algorithms: Why success rates matter. <em>Alg</em>, <em>86</em>(2),
526–565. (<a href="https://doi.org/10.1007/s00453-023-01153-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are general-purpose optimisers that come with several parameters like the sizes of parent and offspring populations or the mutation rate. It is well known that the performance of EAs may depend drastically on these parameters. Recent theoretical studies have shown that self-adjusting parameter control mechanisms that tune parameters during the algorithm run can provably outperform the best static parameters in EAs on discrete problems. However, the majority of these studies concerned elitist EAs and we do not have a clear answer on whether the same mechanisms can be applied for non-elitist EAs. We study one of the best-known parameter control mechanisms, the one-fifth success rule, to control the offspring population size $$\lambda $$ in the non-elitist $${(1,\lambda )}$$ EA. It is known that the $${(1,\lambda )}$$ EA has a sharp threshold with respect to the choice of $$\lambda $$ where the expected runtime on the benchmark function OneMax changes from polynomial to exponential time. Hence, it is not clear whether parameter control mechanisms are able to find and maintain suitable values of $$\lambda $$ . For OneMax we show that the answer crucially depends on the success rate s (i. e. a one- $$(s+1)$$ -th success rule). We prove that, if the success rate is appropriately small, the self-adjusting $${(1,\lambda )}$$ EA optimises OneMax in O(n) expected generations and $$O(n \log n)$$ expected evaluations, the best possible runtime for any unary unbiased black-box algorithm. A small success rate is crucial: we also show that if the success rate is too large, the algorithm has an exponential runtime on OneMax and other functions with similar characteristics.},
  archive      = {J_Alg},
  author       = {Hevia Fajardo, Mario Alejandro and Sudholt, Dirk},
  doi          = {10.1007/s00453-023-01153-9},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {526-565},
  shortjournal = {Algorithmica},
  title        = {Self-adjusting population sizes for non-elitist evolutionary algorithms: Why success rates matter},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the d-claw vertex deletion problem. <em>Alg</em>,
<em>86</em>(2), 505–525. (<a
href="https://doi.org/10.1007/s00453-023-01144-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let d-claw (or d-star) stand for $$K_{1,d}$$ , the complete bipartite graph with 1 and $$d\ge 1$$ vertices on each part. The d-claw vertex deletion problem, $$d$$ -claw-vd, asks for a given graph G and an integer k if one can delete at most k vertices from G such that the resulting graph has no d-claw as an induced subgraph. Thus, $$1$$ -claw-vd and $$2$$ -claw-vd are just the famous vertex cover problem and the cluster vertex deletion problem, respectively. In this paper, we strengthen a hardness result recently proved in Jena and Subramani (in: Du, Du, Wu, and Zhu (eds) Theory and applications of models of computation - 17th annual conference, TAMC 2022, Tianjin, China, September 16–18, 2022, Proceedings, 2022), by showing that cluster vertex deletion remains $$\textsf{NP}$$ -complete even when restricted to planar bipartite graphs of maximum degree 3 and arbitrary large girth. Moreover, for every $$d\ge 3$$ , we show that $$d$$ -claw-vd is $$\textsf{NP}$$ -complete even when restricted to planar bipartite graphs of maximum degree d. These hardness results are optimal with respect to degree constraint. By extending the hardness result in Bonomo-Braberman et al (in: Computing and combinatorics - 26th international conference, COCOON 2020, Proceedings, Lecture Notes in Computer Science, vol 12273, Springer, 2020, pp 14–26, 2020), we show that, for every $$d\ge 3$$ , $$d$$ -claw-vd is $$\textsf{NP}$$ -complete even when restricted to split graphs without $$(d+1)$$ -claws, and split graphs of diameter 2. On the positive side, we prove that $$d$$ -claw-vd is polynomially solvable on what we call d-block graphs, a class properly contains all block graphs. This result extends the polynomial-time algorithm in Cao et al (Theor Comput Sci, 2018) for $$2$$ -claw-vd on block graphs to $$d$$ -claw-vd for all $$d\ge 2$$ and improves the polynomial-time algorithm proposed by Bonomo-Brabeman et al. for (unweighted) $$3$$ -claw-vd on block graphs to 3-block graphs.},
  archive      = {J_Alg},
  author       = {Hsieh, Sun-Yuan and Le, Hoang-Oanh and Le, Van Bang and Peng, Sheng-Lung},
  doi          = {10.1007/s00453-023-01144-w},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {505-525},
  shortjournal = {Algorithmica},
  title        = {On the d-claw vertex deletion problem},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polynomial-time combinatorial algorithm for general max–min
fair allocation. <em>Alg</em>, <em>86</em>(2), 485–504. (<a
href="https://doi.org/10.1007/s00453-023-01105-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the general max–min fair allocation problem, there are m players and n indivisible resources, each player has his/her own utilities for the resources, and the goal is to find an assignment that maximizes the minimum total utility of resources assigned to a player. The problem finds many natural applications such as bandwidth distribution in telecom networks, processor allocation in computational grids, and even public-sector decision making. We introduce an over-estimation strategy to design approximation algorithms for this problem. When all utilities are positive, we obtain an approximation ratio of $$\frac{c}{1-\epsilon }$$ , where c is the maximum ratio of the largest utility to the smallest utility of any resource. When some utilities are zero, we obtain an approximation ratio of $$\bigl (1+3{\hat{c}}+O(\delta {\hat{c}}^2)\bigr )$$ , where $${\hat{c}}$$ is the maximum ratio of the largest utility to the smallest positive utility of any resource.},
  archive      = {J_Alg},
  author       = {Ko, Sheng-Yen and Chen, Ho-Lin and Cheng, Siu-Wing and Hon, Wing-Kai and Liao, Chung-Shou},
  doi          = {10.1007/s00453-023-01105-3},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {485-504},
  shortjournal = {Algorithmica},
  title        = {Polynomial-time combinatorial algorithm for general Max–Min fair allocation},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lazy parameter tuning and control: Choosing all parameters
randomly from a power-law distribution. <em>Alg</em>, <em>86</em>(2),
442–484. (<a href="https://doi.org/10.1007/s00453-023-01098-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most evolutionary algorithms have multiple parameters and their values drastically affect the performance. Due to the often complicated interplay of the parameters, setting these values right for a particular problem (parameter tuning) is a challenging task. This task becomes even more complicated when the optimal parameter values change significantly during the run of the algorithm since then a dynamic parameter choice (parameter control) is necessary. In this work, we propose a lazy but effective solution, namely choosing all parameter values (where this makes sense) in each iteration randomly from a suitably scaled power-law distribution. To demonstrate the effectiveness of this approach, we perform runtime analyses of the $$(1+(\lambda ,\lambda ))$$ genetic algorithm with all three parameters chosen in this manner. We show that this algorithm on the one hand can imitate simple hill-climbers like the $$(1+1)$$ EA, giving the same asymptotic runtime on problems like OneMax, LeadingOnes, or Minimum Spanning Tree. On the other hand, this algorithm is also very efficient on jump functions, where the best static parameters are very different from those necessary to optimize simple problems. We prove a performance guarantee that is comparable to the best performance known for static parameters. For the most interesting case that the jump size k is constant, we prove that our performance is asymptotically better than what can be obtained with any static parameter choice. We complement our theoretical results with a rigorous empirical study confirming what the asymptotic runtime results suggest.},
  archive      = {J_Alg},
  author       = {Antipov, Denis and Buzdalov, Maxim and Doerr, Benjamin},
  doi          = {10.1007/s00453-023-01098-z},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {442-484},
  shortjournal = {Algorithmica},
  title        = {Lazy parameter tuning and control: Choosing all parameters randomly from a power-law distribution},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). More precise runtime analyses of non-elitist evolutionary
algorithms in uncertain environments. <em>Alg</em>, <em>86</em>(2),
396–441. (<a href="https://doi.org/10.1007/s00453-022-01044-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world applications often involve “uncertain” objectives, i.e., where optimisation algorithms observe objective values as a random variables with positive variance. In the past decade, several rigorous analysis results for evolutionary algorithms (EAs) on discrete problems show that EAs can cope with low-level uncertainties, i.e. when the variance of the uncertain objective value is small, and sometimes even benefit from uncertainty. Previous work showed that a large population combined with a non-elitist selection mechanism is a promising approach to handle high levels of uncertainty. However, the population size and the mutation rate can dramatically impact the performance of non-elitist EAs, and the optimal choices of these parameters depend on the level of uncertainty in the objective function. The performance and the required parameter settings for non-elitist EAs in some common objective-uncertainty scenarios are still unknown. We analyse the runtime of non-elitist EAs on two classical benchmark problems OneMax and LeadingOnes in in the one-bit, the bitwise, the Gaussian, and the symmetric noise models, and the dynamic binary value problem (DynBV). Our analyses are more extensive and precise than previous analyses of non-elitist EAs. In several settings, we prove that the non-elitist EAs outperform the current state-of-the-art results. Furthermore, we provide more precise guidance on how to choose the mutation rate, the selective pressure, and the population size as a function of the level of uncertainty.},
  archive      = {J_Alg},
  author       = {Lehre, Per Kristian and Qin, Xiaoyu},
  doi          = {10.1007/s00453-022-01044-5},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {396-441},
  shortjournal = {Algorithmica},
  title        = {More precise runtime analyses of non-elitist evolutionary algorithms in uncertain environments},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lower bounds from fitness levels made easy. <em>Alg</em>,
<em>86</em>(2), 367–395. (<a
href="https://doi.org/10.1007/s00453-022-00952-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the first and easy to use techniques for proving run time bounds for evolutionary algorithms is the so-called method of fitness levels by Wegener. It uses a partition of the search space into a sequence of levels which are traversed by the algorithm in increasing order, possibly skipping levels. An easy, but often strong upper bound for the run time can then be derived by adding the reciprocals of the probabilities to leave the levels (or upper bounds for these). Unfortunately, a similarly effective method for proving lower bounds has not yet been established. The strongest such method, proposed by Sudholt (2013), requires a careful choice of the viscosity parameters $$\gamma _{i,j}$$ , $$0 \le i &lt; j \le n$$ . In this paper we present two new variants of the method, one for upper and one for lower bounds. Besides the level leaving probabilities, they only rely on the probabilities that levels are visited at all. We show that these can be computed or estimated without greater difficulties and apply our method to reprove the following known results in an easy and natural way. (i) The precise run time of the (1+1) EA on LeadingOnes. (ii) A lower bound for the run time of the (1+1) EA on OneMax, tight apart from an O(n) term. (iii) A lower bound for the run time of the (1+1) EA on long k-paths (which differs slightly from the previous result due to a small error in the latter). We also prove a tighter lower bound for the run time of the (1+1) EA on jump functions by showing that, regardless of the jump size, only with probability $$O(2^{-n})$$ the algorithm can avoid to jump over the valley of low fitness.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin and Kötzing, Timo},
  doi          = {10.1007/s00453-022-00952-w},
  journal      = {Algorithmica},
  month        = {2},
  number       = {2},
  pages        = {367-395},
  shortjournal = {Algorithmica},
  title        = {Lower bounds from fitness levels made easy},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing generalized convolutions faster than brute force.
<em>Alg</em>, <em>86</em>(1), 334–366. (<a
href="https://doi.org/10.1007/s00453-023-01176-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a general notion of convolution. Let $$D$$ be a finite domain and let $$D^n$$ be the set of n-length vectors (tuples) of $$D$$ . Let $$f :D\times D\rightarrow D$$ be a function and let $$\oplus _f$$ be a coordinate-wise application of f. The $$f$$ -Convolution of two functions $$g,h :D^n \rightarrow \{-M,\ldots ,M\}$$ is $$\begin{aligned} (g \mathbin {\circledast _{f}}h)(\textbf{v}) {:}{=}\sum _{\begin{array}{c} \textbf{v}_g,\textbf{v}_h \in D^n\\ \text {s.t. } \textbf{v}= \textbf{v}_g \oplus _f \textbf{v}_h \end{array}} g(\textbf{v}_g) \cdot h(\textbf{v}_h) \end{aligned}$$ for every $$\textbf{v}\in D^n$$ . This problem generalizes many fundamental convolutions such as Subset Convolution, XOR Product, Covering Product or Packing Product, etc. For arbitrary function f and domain $$D$$ we can compute $$f$$ -Convolution via brute-force enumeration in $$\widetilde{{\mathcal {O}}}(|D|^{2n} \cdot \textrm{polylog}(M))$$ time. Our main result is an improvement over this naive algorithm. We show that $$f$$ -Convolution can be computed exactly in $$\widetilde{{\mathcal {O}}}( (c \cdot |D|^2)^{n} \cdot \textrm{polylog}(M))$$ for constant $$c {:}{=}3/4$$ when $$D$$ has even cardinality. Our main observation is that a cyclic partition of a function $$f :D\times D\rightarrow D$$ can be used to speed up the computation of $$f$$ -Convolution, and we show that an appropriate cyclic partition exists for every f. Furthermore, we demonstrate that a single entry of the $$f$$ -Convolution can be computed more efficiently. In this variant, we are given two functions $$g,h :D^n \rightarrow \{-M,\ldots ,M\}$$ alongside with a vector $$\textbf{v}\in D^n$$ and the task of the $$f$$ -Query problem is to compute integer $$(g \mathbin {\circledast _{f}}h)(\textbf{v})$$ . This is a generalization of the well-known Orthogonal Vectors problem. We show that $$f$$ -Query can be computed in $$\widetilde{{\mathcal {O}}}(|D|^{\frac{\omega }{2} n} \cdot \textrm{polylog}(M))$$ time, where $$\omega \in [2,2.372)$$ is the exponent of currently fastest matrix multiplication algorithm.},
  archive      = {J_Alg},
  author       = {Esmer, Barış Can and Kulik, Ariel and Marx, Dániel and Schepper, Philipp and Węgrzycki, Karol},
  doi          = {10.1007/s00453-023-01176-2},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {334-366},
  shortjournal = {Algorithmica},
  title        = {Computing generalized convolutions faster than brute force},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On parameterized complexity of binary networked public goods
game. <em>Alg</em>, <em>86</em>(1), 307–333. (<a
href="https://doi.org/10.1007/s00453-023-01174-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the binary networked public goods (BNPG for short) game, every player needs to decide if she participates in a public project whose utility is shared equally by the community. We study the problem of deciding if there exists a pure strategy Nash equilibrium (PSNE) in such games. The problem is already known to be $$\textsf{NP}$$ -complete. This casts doubt on predictive power of PSNE in BNPG games. We provide fine-grained analysis of this problem under the lens of parameterized complexity theory. We consider various natural graph parameters and show $$\mathsf {W[1]}$$ -hardness, XP, and $$\textsf{FPT}$$ results. Hence, our work significantly improves our understanding of BNPG games where PSNE serves as a reliable solution concept. We finally prove that some graph classes, for example path, cycle, bi-clique, and complete graph, always have a PSNE if the utility function of the players are same.},
  archive      = {J_Alg},
  author       = {Maiti, Arnab and Dey, Palash},
  doi          = {10.1007/s00453-023-01174-4},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {307-333},
  shortjournal = {Algorithmica},
  title        = {On parameterized complexity of binary networked public goods game},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing and listing avoidable vertices and paths.
<em>Alg</em>, <em>86</em>(1), 281–306. (<a
href="https://doi.org/10.1007/s00453-023-01168-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A simplicial vertex of a graph is a vertex whose neighborhood is a clique. It is known that listing all simplicial vertices can be done in O(nm) time or $$O(n^{\omega })$$ time, where $$O(n^{\omega })$$ is the time needed to perform a fast matrix multiplication. The notion of avoidable vertices generalizes the concept of simplicial vertices in the following way: a vertex u is avoidable if every induced path on three vertices with middle vertex u is contained in an induced cycle. We present algorithms for listing all avoidable vertices of a graph through the notion of minimal triangulations and common neighborhood detection. In particular we give algorithms with running times $$O(n^{2}m)$$ and $$O(n^{1+\omega })$$ , respectively. Additionally, based on a simplified graph traversal we propose a fast algorithm that runs in time $$O(n^2 + m^2)$$ and matches the corresponding running time of listing all simplicial vertices on sparse graphs with $$m=O(n)$$ . Moreover, we show that our algorithms cannot be improved significantly, as we prove that under plausible complexity assumptions there is no truly subquadratic algorithm for recognizing an avoidable vertex. To complement our results, we consider their natural generalizations of avoidable edges and avoidable paths. We propose an O(nm)-time algorithm that recognizes whether a given induced path is avoidable.},
  archive      = {J_Alg},
  author       = {Papadopoulos, Charis and Zisis, Athanasios E.},
  doi          = {10.1007/s00453-023-01168-2},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {281-306},
  shortjournal = {Algorithmica},
  title        = {Computing and listing avoidable vertices and paths},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The need for seed (in the abstract tile assembly model).
<em>Alg</em>, <em>86</em>(1), 218–280. (<a
href="https://doi.org/10.1007/s00453-023-01160-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the abstract Tile Assembly Model (aTAM) square tiles self-assemble, autonomously binding via glues on their edges, to form structures. Algorithmic aTAM systems can be designed in which the patterns of tile attachments are forced to follow the execution of targeted algorithms. Such systems have been proven to be computationally universal as well as intrinsically universal (IU), a notion borrowed and adapted from cellular automata showing that a single tile set exists which is capable of simulating all aTAM systems (FOCS 2012). The input to an algorithmic aTAM system can be provided in a variety of ways, with a common method being via the “seed” assembly, which is a pre-formed assembly from which all growth propagates. Arbitrary amounts of information can be encoded into seed assemblies by both (1) the types and patterns of glues exposed on their exteriors, and (2) their shapes. Since a common metric by which aTAM systems are measured is their tile complexity (i.e. the number of unique types of tiles they utilize), in order to provide a fair basis for comparison, systems are often designed with seed assemblies consisting of only a single seed tile, a.k.a. single-tile seeds. (For instance, in STOC 2000 and 2001 information theoretically optimal tile complexity was shown possible for the self-assembly of squares.) This requires the transferring of any information that may be encoded in a multi-tile seed assembly into tile complexity. In this paper, we explore this process to show when and how such transformations are possible while ensuring that a derived system with a single-tile seed faithfully replicates the behaviors of the original system. We first show that a trivial transformation, in which the locations of a multi-tile seed are tiled by “hard-coded” tiles that can grow to represent that seed from a single tile, can succeed only if (1) there are not tile locations in the seed such that there exist growth sequences where those locations could block future growth, or (2) an ordering of growth can be enforced for the growth of the seed from a single tile to ensure that such blocking locations are tiled before collisions are possible. However, we show that knowing if this is the case is uncomputable. Therefore, we examine what is possible if the scale factor of the original system is increased and show that all systems with multi-tile seeds can be transformed into systems with single-tile seeds at scale factor 3 (i.e. each tile of the original system is replaced by a $$3 \times 3$$ square of tiles), such that the transformed systems faithfully replicate the dynamics of the original systems. We also prove that this scale factor is optimal, and that in fact there exist systems with multi-tile seeds for which no systems at scale factors 1 or 2 (or scale factor 3 when a more restrictive form of simulation is required) with single-tile seeds exist that can even produce the same sets of terminal output shapes. Since the scale 3 transformation results in a tile complexity which is proportional to the size of the original tile set plus the size of the multi-tile seed multiplied by the scale factor, we then also provide a transformation that yields an asymptotically optimal tile complexity proportional to the Kolmogorov complexity of the original system and which is based on the IU construction from FOCS 2012. Additionally, we are able to make simple modifications to that construction to provide a single aTAM system which simultaneously and in parallel simulates all aTAM systems, and provide a connection between that system and the existence of systems within models other than the aTAM which are IU for the aTAM. This set of results provides a full characterization of the tradeoffs between systems with multi-tile seeds and those with single-tile seeds, which is fundamental to the measure of complexity of aTAM systems.},
  archive      = {J_Alg},
  author       = {Alseth, Andrew and Patitz, Matthew J.},
  doi          = {10.1007/s00453-023-01160-w},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {218-280},
  shortjournal = {Algorithmica},
  title        = {The need for seed (in the abstract tile assembly model)},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Refined bounds on the number of eulerian tours in undirected
graphs. <em>Alg</em>, <em>86</em>(1), 194–217. (<a
href="https://doi.org/10.1007/s00453-023-01162-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected multigraph $$G=(V,E)$$ with no self-loops, and one of its nodes $$s\in V$$ , we consider the #P-complete problem of counting the number $$ET^{(e)}_s(G)$$ of its Eulerian tours starting and ending at node s. We provide lower and upper bounds on the size of $$ET^{(e)}_s(G)$$ . Namely, let d(v) denote the degree of a node $$v\in V$$ ; we show that $$ \max \{L_1^{(e)}, L_2^{(e)}\} \le |ET^{(e)}_{s}(G)| \le d(s)\, \prod _{v \in V} (d(v) - 1)!! $$ where $$L_1^{(e)} = (d(s)-1)!!\prod _{v \in V {\setminus } s}{(d(v)-2)!!}$$ and $$L_2^{(e)} = 2^{1-|V|+|E|}$$ . We also consider the notion of node-distinct Eulerian tours. Indeed, the classical Eulerian tours are edge-distinct sequences. Node-distinct Eulerian tours, denoted $$ET^{(n)}_s(G)$$ , should instead be different as node sequences. Let $$\Delta (u)$$ be the number of distinct neighbors of a node u, $$D \subseteq E$$ be the set of distinct edges in the multigraph G, and m(e) for an edge $$e\in E$$ be its multiplicity (i.e. $$|E|=\sum _{e \in D} m(e)$$ ). We prove that $$ \max \{L_1^{(n)}, L_2^{(n)}, L_3^{(n)}\} \le |ET^{(n)}_{s}(G)| \le d(s)\, \prod _{v \in V} (d(v) - 1)!! \cdot \textstyle \prod _{e\in D} m(e)!^{-1}, $$ where $$L_1^{(n)} = L_1^{(e)}/(\prod _{e \in D}m(e)!)$$ , $$L_2^{(n)} = (\Delta (s)-1)!!\prod _{v \in V {\setminus } s}{(\Delta (v)-2)!!}$$ , and $$L_3^{(n)} = 2^{1-|V|+|D|}$$ . We also extend all of our results to graphs having self-loops.},
  archive      = {J_Alg},
  author       = {Punzi, Giulia and Conte, Alessio and Grossi, Roberto and Rizzi, Romeo},
  doi          = {10.1007/s00453-023-01162-8},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {194-217},
  shortjournal = {Algorithmica},
  title        = {Refined bounds on the number of eulerian tours in undirected graphs},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fully dynamic k-center clustering with outliers.
<em>Alg</em>, <em>86</em>(1), 171–193. (<a
href="https://doi.org/10.1007/s00453-023-01159-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the robust version of the classic k-center clustering problem, where we wish to remove up to z points (outliers), so as to be able to cluster the remaining points in k clusters with minimum maximum radius. We study such a problem under the fully dynamic adversarial model, where points can be inserted or deleted arbitrarily. In this setting, the main goal is to design algorithms that maintain a high quality solution at any point in time, while requiring a “small” amortized cost, i.e. a “small” number of operations per insertion or deletion, on average. In our work, we provide the first constant bi-criteria approximation algorithm for such a problem with its amortized cost being independent of both z and the size of the current input. We also complement our positive result with a lower bound showing that any constant (non bi-criteria) approximation algorithm has amortized cost at least linear in z. Finally, we conduct an in-depth experimental analysis of our algorithm on Twitter, Flickr, and Air-Quality datasets showing the effectiveness of our approach.},
  archive      = {J_Alg},
  author       = {Chan, T.-H. Hubert and Lattanzi, Silvio and Sozio, Mauro and Wang, Bo},
  doi          = {10.1007/s00453-023-01159-3},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {171-193},
  shortjournal = {Algorithmica},
  title        = {Fully dynamic k-center clustering with outliers},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extended MSO model checking via small vertex integrity.
<em>Alg</em>, <em>86</em>(1), 147–170. (<a
href="https://doi.org/10.1007/s00453-023-01161-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the model checking problem of an extended $$\textsf{MSO}$$ with local and global cardinality constraints, called $$\textsf{MSO}^{\textsf{GL}}_{\textsf{Lin}}$$ , introduced recently by Knop et al. (Log Methods Comput Sci, 15(4), 2019. https://doi.org/10.23638/LMCS-15(4:12)2019 ). We show that the problem is fixed-parameter tractable parameterized by vertex integrity, where vertex integrity is a graph parameter standing between vertex cover number and treedepth. Our result thus narrows the gap between the fixed-parameter tractability parameterized by vertex cover number and the W[1]-hardness parameterized by treedepth.},
  archive      = {J_Alg},
  author       = {Gima, Tatsuya and Otachi, Yota},
  doi          = {10.1007/s00453-023-01161-9},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {147-170},
  shortjournal = {Algorithmica},
  title        = {Extended MSO model checking via small vertex integrity},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi brute-force search approach for (balanced)
clustering. <em>Alg</em>, <em>86</em>(1), 130–146. (<a
href="https://doi.org/10.1007/s00453-023-01158-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is one of the most long-standing fundamental problems in the fields of computational geometry and algorithm design. In this paper, we focus on the variance-based clustering problems, included in which is the widely known k-means clustering. As the main contribution, a so-called semi brute-force search approach is proposed and analyzed from both theoretical and experimental aspects. The proposed approach samples a small percentage from the input dataset and search in a brute-force way for a k sized seed whose resulting Voronoi Diagram gives a good clustering of the original dataset. With high probability, the clustering is provably good to estimate the optimum under certain assumptions. Extensive experiments on both synthetic datasets and real-world datasets show that to obtain competitive results compared with k-means method (Llyod in IEEE Trans Inf Theory 28(2):129–137, 1982) and k-means++ method (Arthur and Vassilvitskii, (in: 18th ACM-SIAM symposium on discrete algorithms (SODA), 2007)), we only need a subset of 7% size comparing with the input dataset. If we are allowed to sample 15% from the dataset, our algorithm outperforms both the k-means method and k-means++ method in at least 80% of the clustering tasks. Also, an extended algorithm based on the same idea guarantees a balanced k-clustering result.},
  archive      = {J_Alg},
  author       = {Xu, Yicheng and Chau, Vincent and Wu, Chenchen and Zhang, Yong and Zissimopoulos, Vassilis and Zou, Yifei},
  doi          = {10.1007/s00453-023-01158-4},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {130-146},
  shortjournal = {Algorithmica},
  title        = {A semi brute-force search approach for (Balanced) clustering},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Runtime analysis for permutation-based evolutionary
algorithms. <em>Alg</em>, <em>86</em>(1), 90–129. (<a
href="https://doi.org/10.1007/s00453-023-01146-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the theoretical analysis of evolutionary algorithms (EAs) has made significant progress for pseudo-Boolean optimization problems in the last 25 years, only sporadic theoretical results exist on how EAs solve permutation-based problems. To overcome the lack of permutation-based benchmark problems, we propose a general way to transfer the classic pseudo-Boolean benchmarks into benchmarks defined on sets of permutations. We then conduct a rigorous runtime analysis of the permutation-based $$(1+1)$$ EA proposed by Scharnow et al. (J Math Model Algorithm 3:349–366, 2004) on the analogues of the LeadingOnes and Jump benchmarks. The latter shows that, different from bit-strings, it is not only the Hamming distance that determines how difficult it is to mutate a permutation $$\sigma $$ into another one $$\tau $$ , but also the precise cycle structure of $$\sigma \tau ^{-1}$$ . For this reason, we also regard the more symmetric scramble mutation operator. We observe that it not only leads to simpler proofs, but also reduces the runtime on jump functions with odd jump size by a factor of $$\Theta (n)$$ . Finally, we show that a heavy-tailed version of the scramble operator, as in the bit-string case, leads to a speed-up of order $$m^{\Theta (m)}$$ on jump functions with jump size m. A short empirical analysis confirms these findings, but also reveals that small implementation details like the rate of void mutations can make an important difference.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin and Ghannane, Yassine and Ibn Brahim, Marouane},
  doi          = {10.1007/s00453-023-01146-8},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {90-129},
  shortjournal = {Algorithmica},
  title        = {Runtime analysis for permutation-based evolutionary algorithms},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulated annealing is a polynomial-time approximation
scheme for the minimum spanning tree problem. <em>Alg</em>,
<em>86</em>(1), 64–89. (<a
href="https://doi.org/10.1007/s00453-023-01135-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that Simulated Annealing with an appropriate cooling schedule computes arbitrarily tight constant-factor approximations to the minimum spanning tree problem in polynomial time. This result was conjectured by Wegener (Automata, Languages and Programming, ICALP, Berlin, 2005). More precisely, denoting by $$n, m, w_{\max }$$ , and $$w_{\min }$$ the number of vertices and edges as well as the maximum and minimum edge weight of the MST instance, we prove that simulated annealing with initial temperature $$T_0 \ge w_{\max }$$ and multiplicative cooling schedule with factor $$1-1/\ell $$ , where $$\ell = \omega (mn\ln (m))$$ , with probability at least $$1-1/m$$ computes in time $$O(\ell (\ln \ln (\ell ) + \ln (T_0/w_{\min }) ))$$ a spanning tree with weight at most $$1+\kappa $$ times the optimum weight, where $$1+\kappa = \frac{(1+o(1))\ln (\ell m)}{\ln (\ell ) -\ln (mn\ln (m))}$$ . Consequently, for any $$\epsilon &gt;0$$ , we can choose $$\ell $$ in such a way that a $$(1+\epsilon )$$ -approximation is found in time $$O((mn\ln (n))^{1+1/\epsilon +o(1)}(\ln \ln n + \ln (T_0/w_{\min })))$$ with probability at least $$1-1/m$$ . In the special case of so-called $$(1+\epsilon )$$ -separated weights, this algorithm computes an optimal solution (again in time $$O( (mn\ln (n))^{1+1/\epsilon +o(1)}(\ln \ln n + \ln (T_0/w_{\min })))$$ ), which is a significant speed-up over Wegener’s runtime guarantee of $$O(m^{8 + 8/\epsilon })$$ . Our tighter upper bound also admits the result that in some situations a hybridization of simulated annealing and the $${(1 + 1)}$$ EA can lead to stronger runtime guarantees than either algorithm alone.},
  archive      = {J_Alg},
  author       = {Doerr, Benjamin and Rajabi, Amirhossein and Witt, Carsten},
  doi          = {10.1007/s00453-023-01135-x},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {64-89},
  shortjournal = {Algorithmica},
  title        = {Simulated annealing is a polynomial-time approximation scheme for the minimum spanning tree problem},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of surrogate-assisted information-geometric
optimization algorithms. <em>Alg</em>, <em>86</em>(1), 33–63. (<a
href="https://doi.org/10.1007/s00453-022-01087-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate functions are often employed to reduce the number of objective function evaluations in a continuous optimization. However, their effects have seldom been investigated theoretically. This paper analyzes the effect of a surrogate function in the information-geometric optimization (IGO) framework, which includes as an algorithm instance a variant of the covariance matrix adaptation evolution strategy—a widely used solver for black-box continuous optimization. We derive a sufficient condition on the surrogate function for the parameter update in the IGO algorithms to point to a descent direction of the objective function expected over the search distribution. The condition is expressed in terms of three measures of correlation between the objective function and the surrogate function. Our result constitutes a partial justification for the use of a surrogate function in IGO algorithms.},
  archive      = {J_Alg},
  author       = {Akimoto, Youhei},
  doi          = {10.1007/s00453-022-01087-8},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {33-63},
  shortjournal = {Algorithmica},
  title        = {Analysis of surrogate-assisted information-geometric optimization algorithms},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extended jump functions benchmark for the analysis of
randomized search heuristics. <em>Alg</em>, <em>86</em>(1), 1–32. (<a
href="https://doi.org/10.1007/s00453-022-00977-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Jump functions are the most-studied non-unimodal benchmark in the theory of randomized search heuristics, in particular, evolutionary algorithms (EAs). They have significantly improved our understanding of how EAs escape from local optima. However, their particular structure—to leave the local optimum one can only jump directly to the global optimum—raises the question of how representative such results are. For this reason, we propose an extended class $$\textsc {Jump}_{k,\delta }$$ of jump functions that contain a valley of low fitness of width $$\delta $$ starting at distance k from the global optimum. We prove that several previous results extend to this more general class: for all $$k \le \frac{n^{1/3}}{\ln {n}}$$ and $$\delta &lt; k$$ , the optimal mutation rate for the $$(1+1)$$ EA is $$\frac{\delta }{n}$$ , and the fast $$(1+1)$$ EA runs faster than the classical $$(1+1)$$ EA by a factor super-exponential in $$\delta $$ . However, we also observe that some known results do not generalize: the randomized local search algorithm with stagnation detection, which is faster than the fast $$(1+1)$$ EA by a factor polynomial in k on $$\textsc {Jump}_k$$ , is slower by a factor polynomial in n on some $$\textsc {Jump}_{k,\delta }$$ instances. Computationally, the new class allows experiments with wider fitness valleys, especially when they lie further away from the global optimum.},
  archive      = {J_Alg},
  author       = {Bambury, Henry and Bultel, Antoine and Doerr, Benjamin},
  doi          = {10.1007/s00453-022-00977-1},
  journal      = {Algorithmica},
  month        = {1},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Algorithmica},
  title        = {An extended jump functions benchmark for the analysis of randomized search heuristics},
  volume       = {86},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
