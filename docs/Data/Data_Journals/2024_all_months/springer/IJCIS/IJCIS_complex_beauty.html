<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcis---116">IJCIS - 116</h2>
<ul>
<li><details>
<summary>
(2024). Architecture optimization for hybrid deep residual networks
in liver tumor segmentation using a GA. <em>IJCIS</em>, <em>17</em>(1),
1–22. (<a href="https://doi.org/10.1007/s44196-024-00542-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, liver tumor segmentation has been widely applied for vital medical objectives such as illness diagnosis, treatment, and evaluation of liver function. In this work, we aim to improve the performance of hybrid convolution neural network (CNN) models for liver tumor segmentation. A new automatic design method is introduced to build a hybrid CNN model with an optimal architecture using a combination of the original U_Net and the Res-UNet. In the proposed design method, the Res-UNet model is divided into different blocks, and then many different candidate architectures for the hybrid CNN model can be created using gradually these blocks to replace their corresponding blocks of the original U-Net. The replacement is executed if the candidate architecture using a residual block gives better performance than the corresponding one that uses the original U-Net block. We use a genetic algorithm (GA) to get the optimal architecture among the candidate architectures that gives the best performance for the hybrid CNN model. During the optimization process, in addition to the optimal architecture, other crucial configurations such as the learning algorithm, learning rate, and batch size are also determined. We refer to the hybrid CNN model that has the best architecture as GA_Res_UNet. Comparison has been made with other CNN models that are commonly used in image segmentation of liver tumors. We use the 3D-IRCADb01 liver tumor dataset that contains 2800 magnetic resonance (MR) images of 20 patients. Each image has a liver tumor with its corresponding mask. All MR images are resized to 256 × 256 in DICOM format. The findings indicate that GA_Res_UNet outperformed the other compared models over the considered dataset. It achieves 98.5% of dice coefficient and 99.8% of accuracy. Moreover, two other liver tumor segmentation datasets (LiTS17 and CHAOS) are utilized in another comparison to show the superior performance of our proposed model. The reported results show that the proposed model outperformed the other compared state-of-the-art models.},
  archive      = {J_IJCIS},
  author       = {Reyad, Mohamed and Sarhan, Amany M. and Arafa, M.},
  doi          = {10.1007/s44196-024-00542-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Architecture optimization for hybrid deep residual networks in liver tumor segmentation using a GA},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AraTSum: Arabic twitter trend summarization using topic
analysis and extractive algorithms. <em>IJCIS</em>, <em>17</em>(1),
1–18. (<a href="https://doi.org/10.1007/s44196-024-00546-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Twitter’s trending topics enable users to view the topics currently being discussed on the platform. Users can stay up to date with news, events, and conversations. However, the platform’s method of sorting tweets by time can make it hard to gather semantic information. To fully comprehend the various dimensions of trends and the diverse opinions surrounding them, users need to sift through a substantial number of results. Traditional techniques for content summarization, such as multi-document summarization, can facilitate information aggregation, categorization, and visualization of events, but there are two challenges. First, they fail to consider the topic’s polarity, which is essential to covering all aspects of the subject and incorporating less popular opinions. Second, some techniques only provide summaries at the topic level, potentially leaving out crucial dimensions that require representation in this summary. This research developed a novel summarization approach on Twitter which is known as ARAbic Trending SUMmarization (AraTSum). The proposed system generates the summary based on the extracted topics and aspects from the trend. The approach involves a topic sentiment-based technique that combines generative statistical Latent Dirichlet Allocation with a pre-trained model to automatically reflect the sentiments (negative or positive) of tweets in each topic; followed by extractive summarization algorithms in each cluster. The AraTSum was evaluated through several experiments on five different X datasets. The obtained results showed that AraTSum outperformed existing approaches on the ROUGE evaluation metric compared to state-of-the-art Twitter event summarizing algorithms. To ensure a comprehensive and accurate evaluation, three human experts were tasked with manually summarizing the utilized five datasets. The results demonstrated that the proposed AraTSum method is dependent on sentiment topical aspect analysis, and it enhances the summarization&#39;s performance.},
  archive      = {J_IJCIS},
  author       = {Monir, Enas and Salah, Ahmad},
  doi          = {10.1007/s44196-024-00546-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {AraTSum: Arabic twitter trend summarization using topic analysis and extractive algorithms},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New modification of ranked set sampling for estimating
population mean: Neutrosophic median ranked set sampling with an
application to demographic data. <em>IJCIS</em>, <em>17</em>(1), 1–15.
(<a href="https://doi.org/10.1007/s44196-024-00548-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study addressed the limitations of classical statistical methods when dealing with ambiguous data, emphasizing the importance of adopting neutrosophic statistics as a more effective alternative. Classical methods falter in managing uncertainty inherent in such data, necessitating a shift towards methodologies like neutrosophic statistics. To address this gap, the research introduced a novel sampling approach called “neutrosophic median ranked set sampling” and incorporated neutrosophic estimators tailored for estimating the population mean in the presence of ambiguity. This modification aims to address the inherent challenges associated with estimating the population mean when dealing with neutrosophic data. The methods employed involved modifying traditional ranked set sampling techniques to accommodate neutrosophic data characteristics. Additionally, neutrosophic estimators were developed to leverage auxiliary information within the framework of median-ranked set sampling, enhancing the accuracy of population mean estimation under uncertain conditions. The methods employed involved modifying traditional ranked set sampling techniques to accommodate neutrosophic data characteristics. Bias and mean squared error equations for the suggested estimators were provided, offering insights into their theoretical underpinnings. To illustrate the effectiveness and practical applications of the proposed methodology and estimators, a numerical demonstration and simulation study have been conducted using the R programming language. The key results highlighted the superior performance of the proposed estimators compared to existing alternatives, as demonstrated through comprehensive evaluations based on mean squared error and percentage relative efficiency criteria. The conclusions drawn underscored the effectiveness of the neutrosophic median ranked set sampling approach and suggested estimators in estimating the population mean under conditions of uncertainty, particularly when utilizing neutrosophic auxiliary information and validated real-life applicability. The methodology and estimators presented in the study were shown to yield interval-based results, providing a more realistic representation of uncertainty associated with population parameters. This interval estimation, coupled with minimum mean squared error considerations, enhanced the efficacy of the estimators in determining population mean values. The novelty of the work lies in its introduction of a tailored sampling approach and estimators designed specifically for neutrosophic data, filling a significant gap in the literature. By extending classical statistics to accommodate ambiguity, the study offers a substantial advancement in statistical methodology, particularly in domains where precise data is scarce and uncertainty is prevalent. Furthermore, the empirical validation through numerical demonstrations and simulation studies using the R programming language adds robustness to the proposed methodology and contributes to its practical applicability.},
  archive      = {J_IJCIS},
  author       = {Kumari, Anamika and Singh, Rajesh and Smarandache, Florentin},
  doi          = {10.1007/s44196-024-00548-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {New modification of ranked set sampling for estimating population mean: Neutrosophic median ranked set sampling with an application to demographic data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing intercultural business english communication
factors evaluation system using the termite life cycle optimization
algorithm and dynamically stabilized recurrent neural network.
<em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00564-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s globalized business environment, effective intercultural communication in English is paramount for successful collaboration among professionals from diverse backgrounds. To enhance the accuracy of the evaluation system, enhancing intercultural business English communication factors evaluation system using the termite life cycle optimization algorithm and dynamically stabilized recurrent neural network (IBEC–DSRNN–TLCOA) is proposed in this manuscript. The input image is captured from mobile camera. Then the input images are preprocessed using intelligent weight decreasing firefly–particle filtering (IWDFPF) to remove noise and enhance the input images. Afterwards, the preprocessed image is fed to the entropy-founded spatial fuzzy C-means clustering approach for segmenting the image. Then the contrast, correlation, energy and homogeneousness features are extracted by using force-invariant improved feature extraction technique. The extracted features are given to dynamically stabilized recurrent neural network (DSRNN) to image target detection and English description generation. Termite life cycle optimization algorithm (TLCOA) is employed to enhance the weight parameters of DSRNN. The proposed IBEC–DSRNN–TLCOA method is implemented. The proposed IBEC–DSRNN–TLCOA method provides 32.53%, 31.86%, and 35.72% higher accuracy; 35.58%, 32.16%, and 37.72% higher F-measure when compared with the existing methods, such as exploration of intelligent translation with evaluation systems for business English (IBEC–RCNN), E-learning engagement with convolution neural networks on business education (IBEC–CNN), and deep neural network-based research on scoring business English oral training (IBEC–DNN), respectively.},
  archive      = {J_IJCIS},
  author       = {Zhang, Yandong},
  doi          = {10.1007/s44196-024-00564-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing intercultural business english communication factors evaluation system using the termite life cycle optimization algorithm and dynamically stabilized recurrent neural network},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized ATOVIC system based on triangular fuzzy numbers
for pattern classification. <em>IJCIS</em>, <em>17</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-024-00586-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diseases such as diabete and cancer must be detected and treated precociouse. They are generally detected using recognition and classification systems. The latter must be choosen according their accuracies and other measures. In addition, some difficulties and ambiguities can exist related with features representing data sets such as their variant types (eg., integer, nominal, etc.) or overlapping between them. Also, data can be imprecise or incomplete and can influence negatively classification results. Fuzzy sets and their generalizations, resolve problems of data uncertainty by modeling them with linguistic variables. The latter are presented with membership functions having different shapes. Triangular fuzzy numbers which represent tringular functions are very rarely used in classification systems. The cause can be that triangular shape does not preserve in case of some calculations. This research proposes to generalize the classification system &quot;‘Amended Fused TOPSIS-VIKOR for classification&quot;’ (ATOVIC) with triangular fuzzy numbers and to apply it to some UCI date sets. The objective is to unveil the impact of triangular fuzzy numbers in classification. The results of generalized fuzzy ATOVIC are compared to those of its crisp version and those of some existing classification systems using fuzzy sets. Results of ATOVIC generalized with tringular fuzzy numbers are promising. Especially its results on breast cancer Wisconsin and IRIS data sets are higher than Mamdani and Segano fuzzy inference systems using triangular fuzzy numbers from literature.},
  archive      = {J_IJCIS},
  author       = {Baccour, Leila},
  doi          = {10.1007/s44196-024-00586-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Generalized ATOVIC system based on triangular fuzzy numbers for pattern classification},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An effective tag estimation method based upon artificial
neural networks and signal strength for anticollision in radio frequency
identification systems. <em>IJCIS</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00587-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio frequency identification (RFID) technology has been widely used in applications such as access control, inventory management, spatial positioning, and object identification. Accurate tag estimation is one of the major challenges in RFID reader systems particularly in areas where large tag populations are to be identified such as shopping carts, warehouse inventory monitoring, and small ruminant farms. This paper proposes a new tag estimation technique employing artificial neural networks (ANNs) and signal strength to read large tag populations. The technique estimates the number of tags through the signal strength of the backscatter channel for efficient implementation of dynamic framed slotted Aloha (DFSA) protocol by analyzing the RN16 and the received signal strength indicator (RSSI). The ANN model is trained using the signal strength of various tag populations and can identify the number of tags with minimal errors. The proposed technique does not require any modification in the tags and is implemented as a minimal software script to be added to the tag estimation module of the reader. The proposed signal strength-ANN model is able to estimate the accurate number of tags thereby improving the performance of the employed DFSA model.},
  archive      = {J_IJCIS},
  author       = {Alhuthali, Shakir A. H. and Murad, Mohsin and Tasadduq, Imran A. and Awedh, Mohammad Hamza and Rushdi, Ali M. and Alotaibi, Sultan},
  doi          = {10.1007/s44196-024-00587-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An effective tag estimation method based upon artificial neural networks and signal strength for anticollision in radio frequency identification systems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning method for real-time fire detection system for
urban fire monitoring and control. <em>IJCIS</em>, <em>17</em>(1), 1–14.
(<a href="https://doi.org/10.1007/s44196-024-00592-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During urban fire incidents, real-time videos and images are vital for emergency responders and decision-makers, facilitating efficient decision-making and resource allocation in smart city fire monitoring systems. However, real-time videos and images require simple and embeddable models in small computer systems with highly accurate fire detection ratios. YOLOv5s has a relatively small model size and fast processing time with limited accuracy. The aim of this study is to propose a method that employs a YOLOv5s network with a squeeze-and-excitation module for image filtering and classification to meet the urgent need for rapid and accurate real-time screening of irrelevant data. In this study, over 3000 internet images were used for crawling and annotating to construct a dataset. Furthermore, the YOLOv5, YOLOv5x and YOLOv5s models were developed to train and test the dataset. Comparative analysis revealed that the proposed YOLOv5s model achieved 98.2% accuracy, 92.5% recall, and 95.4% average accuracy, with a remarkable processing speed of 0.009 s per image and 0.19 s for a 35 frames-per-second video. This surpasses the performance of other models, demonstrating the efficacy of the proposed YOLOv5s for real-time screening and classification in smart city fire monitoring systems.},
  archive      = {J_IJCIS},
  author       = {Yang, Wenyang and Wu, Yesen and Chow, Steven Kwok Keung},
  doi          = {10.1007/s44196-024-00592-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Deep learning method for real-time fire detection system for urban fire monitoring and control},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fairness group recommendation algorithm based on user
activity. <em>IJCIS</em>, <em>17</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-024-00602-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of group recommendation, due to the different preferences of group members, the recommendation results cannot meet the needs of all users. How to maximize the fairness of group recommendation is still a challenge. Therefore, this paper proposes a group recommendation algorithm based on user activity. Firstly, a group discovery algorithm based on item cluster preference was used to mine potential groups. Secondly, considering the dynamic change of activity, a sliding time window is designed to investigate the recent activity of each member in the group at the time of subgroup division, and the group is divided into active subgroup and inactive subgroup. Finally, the group recommendation list was generated by aggregating the subgroup preferences by average consensus. Experimental results on the public dataset show that compared with the AGREE algorithm, the recommendation accuracy and coverage of the proposed algorithm are improved by 2.1% and 2.9%, respectively. By focusing on the preference needs of inactive users, the proposed algorithm effectively improves the recommendation satisfaction and group fairness.},
  archive      = {J_IJCIS},
  author       = {Jia, Junjie and Wang, Fen and Wang, Huijuan and Liu, Shilong},
  doi          = {10.1007/s44196-024-00602-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A fairness group recommendation algorithm based on user activity},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Auto-correlation and channel attention enhanced deep graph
convolution networks for gait phase prediction based on multi-IMU
system. <em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00603-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait phase prediction is important in controlling assistive robotic devices such as exoskeletons, where the control unit must differentiate between gait phases to provide the necessary assistance when the user is wearing the exoskeleton. To achieve the objective of precisely identifying the gait phase of users for the accurate control of the exoskeleton, this study proposes Auto-Correlation and Channel Attention enhanced Deep Graph Convolutional Networks (ACCA-DGCN) for gait phase prediction, and a gait phase prediction model based on multiple inertial measurement units (IMUs) and skeleton graph was established, in order to fully utilize the dependency among joints, and enhance accuracy and reliability of gait phase prediction. First, a human lower limb gait data acquisition equipment was developed, and the gait data of human walking were collected. The skeleton graph of the human lower limb was constructed through the natural connection relationship of joints in the human skeleton. After that, the ACCA-DGCN-based gait phase prediction model was constructed by using the gait data of human walking. Auto-Correlation (AC) and Efficient Channel Attention (ECA) were introduced to effectively capture periodic features of gait data and focus on the channels with high contributions to gait phase prediction. Finally, the effect of the window size on the performance of the ACCA-DGCN model was explored, and the proposed algorithm was compared with the other five deep learning algorithms: CNN, RNN, TCN, LSTM, and DGCN. The experimental results show that the average accuracy of gait phase prediction model based on ACCA-DGCN reaches up to 92.26% and 97.21% in user-independent and user-dependent experiments, respectively, which is superior to the other five algorithms. This study provides a new method for gait phase prediction, which is useful for improving the control of exoskeleton robots.},
  archive      = {J_IJCIS},
  author       = {Yan, Jianjun and Xu, Yingjia and Yang, Zhihao and Jin, Li and Jiang, Jinlin and Lin, Yue and Xiong, Weixiang},
  doi          = {10.1007/s44196-024-00603-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Auto-correlation and channel attention enhanced deep graph convolution networks for gait phase prediction based on multi-IMU system},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective approach for dynamic economic emission
dispatch problem considering power system reliability and transmission
loss prediction using cascaded forward neural network. <em>IJCIS</em>,
<em>17</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s44196-024-00604-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the significant problem of Dynamic Economic Emission Dispatch (DEED), a critical consideration in power systems from both economic and environmental protection viewpoints. Reliability stands as another vital facet, impacting maintenance and operation perspectives. The integration of Artificial Neural Network (ANN)-based transmission loss prediction into the DEED model is also essential to address specific limitations and enhance the overall performance of the dispatch process. Traditionally, the DEED model relies on a single B-loss coefficient to estimate transmission losses. While this approach simplifies calculations, it fails to account for the significant variations in demand that occur throughout the dispatch period and it leads to inaccuracies in loss prediction, especially in dynamic environments. Using a single coefficient, the model cannot adequately capture the complex, non-linear relationships between power generation, load, and transmission losses under different operating conditions. To overcome this limitation, this study introduces an ANN-based loss prediction method integrated into the DEED model and uses trained ANN to replace the process of finding B-loss coefficients during each dispatch period. This paper also introduces a strategy leveraging the multi-objective northern goshawk optimizer algorithm, characterized by a non-dominated sorting and crowding distance mechanism, to enhance DEED considerations incorporating reliability (DEEDR). This novel algorithm improves the solution space effectively, maintains high population diversity and enables an even distribution of individuals sharing the same rank in the objective space. The fundamental objective of this study is to balance fuel cost, emission, and system reliability in power system operations. Compared with a few existing multi-objective optimization algorithms, this study demonstrates superior performance in generating a series of non-dominated solutions. The experimental results highlight its competitive and potential as an efficient tool in the DEED and DEEDR problems, promising a synergistic coordination of economy, environmental protection, and system reliability benefits in power system management.},
  archive      = {J_IJCIS},
  author       = {Nagulsamy, Nalini and Chandrasekaran, Kumar and Manoharan, Premkumar and Derebew, Bizuwork},
  doi          = {10.1007/s44196-024-00604-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-objective approach for dynamic economic emission dispatch problem considering power system reliability and transmission loss prediction using cascaded forward neural network},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dynamic scheduling method for logistics supply chain based
on adaptive ant colony algorithm. <em>IJCIS</em>, <em>17</em>(1), 1–15.
(<a href="https://doi.org/10.1007/s44196-024-00606-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the dynamic scheduling cost of logistics supply chain and improve customer satisfaction, this paper proposes a dynamic scheduling method for logistics supply chain based on adaptive ant colony algorithm. First, determine the goal of dynamic scheduling in the logistics supply chain. Second, considering supplier satisfaction, transportation costs, and maximum delivery distance constraints, a dynamic scheduling model for logistics supply chain is constructed. Then by smoothing the pheromones and designing a transition function, adjusting factors are introduced to update the pheromone rules. Finally, based on the adaptive ant colony algorithm, the solution of the dynamic scheduling function of the logistics supply chain is solved to achieve the dynamic scheduling of the current logistics supply chain. The experimental results show that after 19 iterations, the method can search for the optimal route A1 group with a length of 33.85 km, with fewer iterations and shorter paths. The total cost is 114,290 yuan, and the degree of cargo loss is low, with a maximum of only 0.14%. The task completion time is short, customer satisfaction is above 0.85, and the scheduling accuracy is 99.9%. It can effectively control costs, improve customer satisfaction, and accurately arrange logistics supply chains.},
  archive      = {J_IJCIS},
  author       = {Zhang, Yinxia and Wang, Liang},
  doi          = {10.1007/s44196-024-00606-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A dynamic scheduling method for logistics supply chain based on adaptive ant colony algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MLAWSMOTE: Oversampling in imbalanced multi-label
classification with missing labels by learning label correlation matrix.
<em>IJCIS</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00607-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing labels in multi-label datasets are a common problem, especially for minority classes, which are more likely to occur. This limitation hinders the performance of classifiers in identifying and extracting information from minority classes. Oversampling is an effective method for addressing imbalanced multi-label problems by generating synthetic instances to create a class-balanced dataset. However, the existing oversampling algorithms mainly focus on the location of the generated data, and there is a lack of design on how to complete the labels of the synthetic data. To address this issue, we propose MLAWSMOTE, a synthetic data generation algorithm based on matrix factorization weights. We introduce a weak supervised learning method in the oversampling method, optimize the weights of features and labels by using label correlation, and iteratively learn the ideal label weights. The mapping relationship between features and labels is learned from the dataset and the label correlation matrix. The oversampling ratio is defined based on the discrepancy between observed labels and the ideal label of synthetic instances. It mitigates the impact of missing minority labels on the model’s predictions. The labeling of synthetic instances is performed based on label prediction, and the potential labeling distribution is complemented. Experimental results on multiple multi-label datasets under different label missing ratios demonstrate the effectiveness of the proposed method in terms of ACC, Hamming loss, MacroF1 and MicroF1. In the validation of the four classifiers, MacroF1 decreased by 24.78%, 17.81%, 3.8% and 19.56%, respectively, with the increase of label loss rate. After applying MLAWSMOTE only decreased by 15.79%, 13.63%, 3.78% and 15.21%.},
  archive      = {J_IJCIS},
  author       = {Mao, Jian and Huang, Kai and Liu, Jinming},
  doi          = {10.1007/s44196-024-00607-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MLAWSMOTE: Oversampling in imbalanced multi-label classification with missing labels by learning label correlation matrix},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Construction of risk prediction models for enterprise
finance sharing operations using k-means and c4.5 algorithms.
<em>IJCIS</em>, <em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00608-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of financial sharing centres in enterprises typically relies on outdated financial data, lacks comprehensive assessment, and presents risks such as employee misconduct. To address these challenges, we propose a risk prediction model for enterprise financial sharing operations based on the K-means clustering algorithm for performance evaluation and the C4.5 algorithm for managing employee risks. Our approach enhances the accuracy and objectivity of performance evaluation while improving the efficiency of personnel risk management. Results indicate that the K-means algorithm classifies employee performance into five levels, facilitating comprehensive performance evaluation. Furthermore, through risk management optimisation, accuracy and recall rates increase to 0.905 and 0.890, respectively. The proposed risk prediction model achieves high accuracy rates of 90.5% and 92.4% in the training and test sets, respectively. Practical application of our methodology and model in A Group&#39;s financial sharing centre demonstrates their effectiveness and potential for enhancing the operation and management of enterprise financial sharing centres.},
  archive      = {J_IJCIS},
  author       = {Pan, Chun},
  doi          = {10.1007/s44196-024-00608-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Construction of risk prediction models for enterprise finance sharing operations using K-means and c4.5 algorithms},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). COVID-19 detection systems based on speech and image data
using deep learning algorithms. <em>IJCIS</em>, <em>17</em>(1), 1–16.
(<a href="https://doi.org/10.1007/s44196-024-00609-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 is a worldwide epidemic that seriously affected the lives of people. Since its inception, physicians have tried their best to trace the virus and reduce its spread. Several diagnostic approaches have been reported to detect the coronavirus in research, clinical, and public health laboratories. Although the existing systems aid medical experts in the diagnosis, they still lack precise detection and may fail to detect COVID-19 in a timely manner. Therefore, in this study, we recommend two approaches i.e., the first approach is based on the VGGish network that focuses on vocal signals, such as breathing and coughing, and the second approach is based on ResNet50, which takes chest X-rays as input. With the help of VGGish, the patient’s cough, voice, and respiration audios have been classified as patient and non-patient achieving an accuracy of more than 98%. We also assessed the performance of several methods for X-ray classification, such as ResNet50, VGG16, VGG19, Densnet201, Inceptionv3, Darknet, GoogleNet, squeezeNet, and Alex-Net. TheResNet50 outpaced all supplementary CNN models with a precision of 94%. However, when we took both types of inputs simultaneously, the accuracy for detection was increased to 99.7%. After extensive experimentation, we believe that our proposed hybrid method is robust enough to take X-rays and audio as mel-spectrograms and identify COVID-19 at early stages, attaining an accuracy of 99.7%.},
  archive      = {J_IJCIS},
  author       = {Akhtar, Farooq and Mahum, Rabbia and Ragab, Adham E. and Butt, Faisal Shafique and El-Meligy, Mohammed A. and Hassan, Haseeb},
  doi          = {10.1007/s44196-024-00609-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {COVID-19 detection systems based on speech and image data using deep learning algorithms},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inter-satellite link prediction with supervised learning
based on kepler and SGP4 orbits. <em>IJCIS</em>, <em>17</em>(1), 1–9.
(<a href="https://doi.org/10.1007/s44196-024-00610-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed Space Systems (DSS) are gaining prominence in the space industry due to their ability to increase mission performance by allowing cooperation and resource sharing between multiple satellites. In DSS where communication between heterogeneous satellites is necessary, achieving autonomous cooperation while minimizing energy consumption is a critical requirement, particularly in sparse constellations with nano-satellites. In order to minimize the functioning time and energy consumed by the Inter-Satellite Links established for satellite-to-satellite communication, their temporal encounters must be anticipated. This work proposes an autonomous solution based on Supervised Learning that allows heterogeneous satellites in circular polar Low-Earth Orbits to predict their close-approach encounters given the Orbital Elements. The model performance is evaluated and compared in two different scenarios: (1) a simplified scenario assuming Kepler orbits and (2) a realistic scenario assuming Simplified General Perturbations 4 orbital model. The obtained results demonstrate a Balanced Accuracy exceeding 95% when compared to realistic data from an available database. This work represents a promising initial stage in developing an alternative approach within the field of DSS.},
  archive      = {J_IJCIS},
  author       = {Ferrer, Estel and Ruiz-De-Azua, Joan A. and Betorz, Francesc and Escrig, Josep},
  doi          = {10.1007/s44196-024-00610-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-9},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Inter-satellite link prediction with supervised learning based on kepler and SGP4 orbits},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Online portfolio selection of fuzzy mean regression strategy
considering investor sentiment based on text data. <em>IJCIS</em>,
<em>17</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-024-00611-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investors are often affected by emotion, cognition, and other psychological factors in stock trading when making decisions. At present, people can use machine learning and other technologies to obtain a massive amount of text data from the Internet to mine information related to investor behavior and sentiment. Building intelligent online portfolio trading strategies that consider investor sentiment has become an important topic and key challenge in the financial field. Therefore, this paper explores how to use text data to depict investor sentiment, fuzzifies historical stock price data, designs a new weight transfer equation, and finally obtains a novel fuzzy mean regression strategy that considers investor sentiment based on text data. We conduct empirical tests on this strategy by using the stock price data selected from CSI300 constituent stocks, as well as the text data of investors’ opinions on the internet. The results show that the strategy proposed in this study has a higher Calmar ratio than other mean regression strategies previously studied.},
  archive      = {J_IJCIS},
  author       = {Zeng, Zhiming and Xu, Weijun and Peng, Zijin and Zhong, Yannan},
  doi          = {10.1007/s44196-024-00611-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Online portfolio selection of fuzzy mean regression strategy considering investor sentiment based on text data},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving multi-pixel visual quality of invariant visual
cryptography scheme. <em>IJCIS</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s44196-024-00613-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A visual cryptography scheme (VCS) splits the secret image into several shares. Stacking a certain number of shares will reveal the secret image. The principle algorithm (deterministic algorithm) retains the size of shares, and the revealed image is at least double the size of the secret image with good visual quality. In contrast, the probabilistic algorithm has the size of the revealed image equal to that of the secret image with the noisily revealed image. Multi-pixel algorithm cast solutions for the trade off problems between the good visual quality and the non-expansion size of the revealed image. In this paper, we introduce new algorithms for multi-pixel to improve the quality of preceding algorithms, generalize the multi-pixel algorithm, provide evidence of the best form of multi-pixel, and contribute to the thin line problem.},
  archive      = {J_IJCIS},
  author       = {Wafy, Maged},
  doi          = {10.1007/s44196-024-00613-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improving multi-pixel visual quality of invariant visual cryptography scheme},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized technique for college students job searching
strategies using fuzzy logic control with cuckoo search algorithm.
<em>IJCIS</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00614-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {College students face uncertainties during job searches due to a lack of career planning, unclear objectives, and ineffective search strategies, leading to poor employment outcomes. Fuzzy Control (FC) based Job Search Strategies (JS2) are proposed in this research as an optimized technique named FC-JS2-TSC. This technique combines Takagi-Sugeno (TS) fuzzy inference with Cuckoo (C) search optimization. The primary goals are improving individualized advice and creating an integrated system to deal with job search concerns. The FC uses fuzzy logic and sets to model uncertainties such as vague job desires and ever-changing market circumstances. Individual student profiles and preferences are used to fine-tune methods by cuckoo search. Through experimental validation, we can see that FC-JS2-TSC outperforms previous methods in terms of both job strategy selection and results. As a measure of system efficacy, the results demonstrate a high Cronbach&#39;s alpha reliability of 0.96, a low RMSEA of 0.04 and 96.6% regarding job offers. By adjusting tactics in response to uncertainty, the innovative FC-JS2-TSC algorithm facilitates data-driven, personalized decision-making, ultimately leading to more efficient job searches. It has an integrated design that combines optimization with fuzzy logic&#39;s uncertainty handling to ensure students have the best possible chance of success in their job searches.},
  archive      = {J_IJCIS},
  author       = {Xiao, Youping and Liu, Fei},
  doi          = {10.1007/s44196-024-00614-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimized technique for college students job searching strategies using fuzzy logic control with cuckoo search algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knee osteoporosis diagnosis based on deep learning.
<em>IJCIS</em>, <em>17</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s44196-024-00615-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporosis, a silent yet debilitating disease, presents a significant challenge due to its asymptomatic nature until fractures occur. Rapid bone loss outpaces regeneration, leading to pain, disability, and loss of independence. Early detection is pivotal for effective management and fracture risk reduction, yet current diagnostic methods are time-consuming. Despite its importance, research addressing early diagnosis remains limited. Deep learning, particularly convolutional neural networks (CNNs), has emerged as a potent tool in image analysis. This paper presents a novel approach utilizing transfer learning with CNNs for osteoporosis detection from X-ray images. The proposed approach not only achieves a high accuracy of osteoporosis diagnosis but also offers a revealed feature map that can guide medical professionals for osteoporosis diagnosis. The innovation lies in a dual strategy: (i) a model integrating transfer learning from CNN architectures such as AlexNet, VGG-16, ResNet-50, VGG-19, InceptionNet, XceptionNet, and a custom CNN, and (ii) a dataset collection augmentation mechanism to enhance learning accuracy. The study includes binary and multiclass classification of knee joint X-ray images into normal, osteopenia, and osteoporosis groups, utilizing a dataset of 1947 knee X-rays for training and testing. Performance comparisons against state-of-the-art models reveal the proposed VGG-19 model achieves the highest accuracy at 92.0% for multiclass and 97.5% for binary. These findings underscore the potential of deep learning with transfer learning in aiding early osteoporosis detection, thereby mitigating fracture risks.},
  archive      = {J_IJCIS},
  author       = {Sarhan, Amany M. and Gobara, Mohamed and Yasser, Shady and Elsayed, Zainab and Sherif, Ghada and Moataz, Nada and Yasir, Yasmen and Moustafa, Esraa and Ibrahim, Sara and Ali, Hesham A.},
  doi          = {10.1007/s44196-024-00615-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Knee osteoporosis diagnosis based on deep learning},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective optimization-based algorithm for selecting
the optimal path of rural multi-temperature zone cold chain dynamic
logistics intermodal transportation. <em>IJCIS</em>, <em>17</em>(1),
1–14. (<a href="https://doi.org/10.1007/s44196-024-00616-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The road network in rural areas is complex and the infrastructure is relatively backward. The multi-temperature zone cold chain logistics involves agricultural products with different temperature requirements, which requires considering the transportation cost, carbon emission cost, refrigeration cost, and time cost of different temperature zones during path planning, thereby increasing the difficulty of path planning. Therefore, a multi-objective optimization-based algorithm for selecting the optimal path of rural multi-temperature zone cold chain dynamic logistics intermodal transportation is proposed. Based on the analysis of the multi-temperature cold chain collection and distribution model based on multimodal transportation, a multi-objective optimization model is constructed. This model aims to minimize transportation costs, carbon emission costs, refrigeration costs, time costs, and maximize logistics quality, while satisfying constraints such as transfer schedule times, the number of transport mode conversions, transport mode selection, and time continuity. To solve this model, an improved NSGA-II algorithm is adopted, which combines an improved mutation operator, congestion distance calculation, and the C-W saving algorithm to achieve the optimal transport path solution. Additionally, ArcGIS software is used to implement the shortest path planning based on real road networks. The experimental results show that by selecting the road-rail combined transport mode and adopting the D1–D6–D10 transport path, it is possible to transport fresh agricultural products from location A to the distribution center at location B, with the lowest Pareto fitness value. Furthermore, the algorithm&#39;s effectiveness is further verified by completing the end-of-life fresh agricultural product distribution task with four multi-temperature refrigerated vehicles. The study also finds that extending or shortening the latest service time window for customers, although it leads to a decrease or increase in the optimal value of the algorithm&#39;s objective function, has little impact on the average distribution time and transport vehicles. These findings provide new theoretical and practical guidance for the path selection of multimodal transportation in multi-temperature cold chain logistics, with significant theoretical and application value.},
  archive      = {J_IJCIS},
  author       = {Qi, Chunwei},
  doi          = {10.1007/s44196-024-00616-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-objective optimization-based algorithm for selecting the optimal path of rural multi-temperature zone cold chain dynamic logistics intermodal transportation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the transferability of adversarial patch via
alternating minimization. <em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00617-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial patches, a type of adversarial example, pose serious security threats to deep neural networks (DNNs) by inducing erroneous outputs. Existing gradient stabilization methods aim to stabilize the optimization direction of adversarial examples through accumulating gradient momentum to enhance attack transferability on black-box models. However, they are not fully effective for adversarial patches. The accumulated momentum during optimization often misaligns with the optimization direction, reducing their efficacy in black-box scenarios. We introduce an optimization method called Alternating Minimization for Adversarial Patch (AMAP). This method decomposes the original AP into multiple sub-patches and utilizes their update direction to stabilize the optimization of the original AP. Additionally, we propose an adaptive step size optimization method that accelerates convergence and boosts the attack performance. In face recognition tasks, AMAP outperforms baseline methods by a remarkable 5.21% and exceeds the second-best method by 1.4%. Furthermore, AMAP demonstrates practical feasibility in the physical domain, highlighting its potential for robust computer security testing applications.},
  archive      = {J_IJCIS},
  author       = {Wang, Yang and Chen, Lei and Yang, Zhen and Cao, Tieyong},
  doi          = {10.1007/s44196-024-00617-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing the transferability of adversarial patch via alternating minimization},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EFection: Effectiveness detection technique for clustering
cloud workload traces. <em>IJCIS</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00618-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is widely used in cloud computing studies to extract vital information. These studies have ignored investigating the potential improvements in clustering quality from better selection of its dimensions and methods. Consequently, developing an automated technique to perform such a selection was not addressed thoroughly. Most of the recent attempts either relied on feature reduction or general non-automated techniques, which were deemed unreliable for sufficient selection. Therefore, we first conducted a comprehensive investigation to study the impact of selecting better clustering dimensions and methods. Our results indicate achieving significant improvement by 15–70% points through better selection. Then, we developed a novel technique (EFection) to detect the best selection in advance using a combination of internal validation metrics (Davies–Bouldin) and the Pearson correlation coefficient. We evaluate our technique’s accuracy by comparing the clustering quality of its suggestions with that of the optimal selection. We then compare EFection’s performance with recent attempts to measure its superiority. Finally, we validate its applicability when adopted in cloud clustering-based studies. The results show that EFection offers high accuracy, around 83%, and surpasses prior art by 11%.},
  archive      = {J_IJCIS},
  author       = {Ali, Shallaw Mohammed and Kecskemeti, Gabor},
  doi          = {10.1007/s44196-024-00618-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {EFection: Effectiveness detection technique for clustering cloud workload traces},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Super-resolution virtual scene rendering technology based on
generalized huber-MRF image modeling. <em>IJCIS</em>, <em>17</em>(1),
1–16. (<a href="https://doi.org/10.1007/s44196-024-00619-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional rendering technology creates virtual scenes with insufficient fidelity, which are quite different from real scenes. To address this issue, a super-resolution virtual scene rendering technology based on generalized Huber-MRF image modeling has been studied. This study preprocesses the original image through three steps: graying, filtering, and enhancement. The generalized Huber-MRF is employed for super-resolution image restoration to enhance image clarity. Corner features are extracted from the super-resolution image, and the Delaunay triangular grid method is used to construct the image&#39;s 3D model. Texture and lighting conditions of the virtual scene are then set through texture mapping, shadow rendering, and other technologies to achieve realistic scene effects. The results indicate that, when applied, the research technology yields a relatively small chamfer distance in virtual scene modeling, suggesting that the design method preserves the details and shape information of the original image, reducing the difference between the virtual scene and the real scene and increasing the fidelity of the virtual scene. Furthermore, this method achieves maximum PSNR and SSIM values of 17.54 and 0.978, respectively, with an image preprocessing time of only 1.21 s and a CPU utilization rate of only 35.5%. This method demonstrates excellent performance across multiple aspects.},
  archive      = {J_IJCIS},
  author       = {Mao, Dong and Rao, Hanyu and Chen, Zuge and Wang, Jiaqi and Zhao, Shuai and Wang, Yidan},
  doi          = {10.1007/s44196-024-00619-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Super-resolution virtual scene rendering technology based on generalized huber-MRF image modeling},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). HM–GDM: Hybrid measures and graph-dependent modeling for
environmental sound classification. <em>IJCIS</em>, <em>17</em>(1),
1–24. (<a href="https://doi.org/10.1007/s44196-024-00622-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the upcoming areas of research is the automated environmental sound classification, as its application is highly utilized in criminal investigations scenarios, surveillance systems, biomedical fields, radio navigation systems, etc. The procedure of environmental sound classification deals with standardized techniques such as feature extraction and feature selection, followed by classification with machine learning or deep learning techniques. In this work, five feature extraction techniques are used initially such as the discrete wavelet transform (DWT)-based empirical mode decomposition (EMD) technique, phase space reconstruction (PSR), kernel principal component analysis (KPCA), variational mode decomposition (VMD) and tunable Q-wavelet transform (TQWT). The extracted features are then selected through seven feature selection techniques, out of which two have been proposed newly and five have already existed. The proposed feature selection techniques are stratified clustered collective technique (SCCT) and fuzzy-based template shape clustering (FTSC). The other feature selection techniques used are the generalized discriminant analysis (GDA), ReliefF, Fisher discriminant criterion (FDC), Kruskal–Wallis test and coati optimization algorithm (COA). The selected features are then classified through the proposed swarm intelligence-based hybrid Adaboost – random forest termed as SIHAR classifier and the selected features are classified with the less explored sparse representation classifier (SRC) along with eight other traditionally used machine learning classifiers. The work also proposes graph-dependent modeling for the environmental sounds where the rhythms are extracted for the similarity assessment and later the decision-making is done using hypothesis testing. The work is tested on Firat ESC-50 dataset and the best results are produced in terms of a high classification accuracy of 87.48% which is obtained for the TQWT + SCCT + SIHAR combination.},
  archive      = {J_IJCIS},
  author       = {Prabhakar, Sunil Kumar and Ju, Young-Gi and Won, Dong-Ok},
  doi          = {10.1007/s44196-024-00622-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {HM–GDM: Hybrid measures and graph-dependent modeling for environmental sound classification},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The application of big data and fuzzy decision support
systems in the innovation of personalized music teaching in
universities. <em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00623-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized music teaching in universities improves students’ learning and efficiency through adaptive guidance. This adaptability requires large study data and intelligent decisions based on the learner’s ability. This article introduces a Definitive Teaching Support System (DTSS) exclusive to music learning to augment this concept. This system is designed to increase the adaptability of music learning based on student interest and ability. The system is powered by a fuzzy decision system for identifying maximum teaching adaptability to personalized processes. Low-to-high-sorted personalization provides new endorsements for further music sessions in the fuzzy derivative process. Maximum adaptability is the target for new personalized sessions in the universities. This differs for various students from which a common adaptability level for monotonous recommendations is identified. The identified adaptability is set as a global maximum solution towards music learning personalization. The defuzzification reduces the chances of low adaptability by expelling the stationary adaptability outcomes.},
  archive      = {J_IJCIS},
  author       = {Chen, Shuangshuang},
  doi          = {10.1007/s44196-024-00623-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {The application of big data and fuzzy decision support systems in the innovation of personalized music teaching in universities},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel multi-modal sentiment analysis based on multiple
kernel learning with margin-dimension constraint. <em>IJCIS</em>,
<em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00624-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the sentiment analysis studies focus on the sentimental classification of pictures in the video, ignoring the spatio-temporal information of the sequence of picture frames as well as text and audio information. The multiple kernel learning is a new hotspot in the field of nuclear machine learning, capable of handling multiple modalities. For multiple kernel learning, it is easy to ignore the basic features that are not discriminative, and cannot make full use of the base features of different modes. This paper puts forward a novel multi-modal fusion model for sentiment analysis, in which a multiple kernel learning algorithm based on convolution margin-dimension constraint is proposed for feature fusion. Moreover, the 3D convolutional neural network is used to extract the features of visual information, and the multiple kernel learning algorithm based on margin-dimension constraint is used to fuse visual, text and audio sentiment features. Experiments conducted on the MOUD and IEMOCAP sentiment databases show that the proposed model outperforms existing models in the field of multi-modal sentiment analysis research.},
  archive      = {J_IJCIS},
  author       = {Liu, Jun and Wang, Zhihao and Wan, Guangrong and Liu, Jianbo},
  doi          = {10.1007/s44196-024-00624-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel multi-modal sentiment analysis based on multiple kernel learning with margin-dimension constraint},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KMPR-AEP: Knowledge-enhanced multi-task parallelized
recommendation algorithm incorporating attention-embedded propagation.
<em>IJCIS</em>, <em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-024-00625-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing knowledge graph-based recommendation algorithms either use Knowledge Graphs (KGs) as auxiliary information or use KG prediction tasks as regular terms to constrain recommendation with multi-task learning. However, the first method, which introduces multi-hop neighbors to enhance item representations, also weakens the relationship information within individual triples to some extent. The second method ignores neighboring information and thus fails to capture the long-range connectivity between items, which leads to a lack of utilization of the structural information in the KG. In response to the limitations of existing recommendation algorithms that do not fully leverage the relational and structural information within KGs, we propose a novel method named Knowledge-Enhanced Multi-Task Parallelized Recommendation Algorithm Incorporating Attention-Embedded Propagation (KMPR-AEP). It employs a parallel approach to simultaneously incorporate KG as auxiliary information and a regular term. We take into account the multi-hop neighbor information of users and items as well as enhance the relations among individual triples, which considers both the structural and relational information of KG. Extensive experiments conducted on three real-world datasets for CTR prediction and Top-K recommendation scenarios demonstrate the superiority of our proposed method over the state-of-the-art. On average, our KMPR-AEP shows improvements of 2.44% in AUC, 3.49% in ACC, and 2.64% in F1.},
  archive      = {J_IJCIS},
  author       = {Zhang, Yang and Cai, Juanjuan and Li, Chuanzhen and Li, Tong and Wang, Hui},
  doi          = {10.1007/s44196-024-00625-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {KMPR-AEP: Knowledge-enhanced multi-task parallelized recommendation algorithm incorporating attention-embedded propagation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy outerplanar graphs and its applications.
<em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00626-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of a crisp graph is essential in the study of outerplanar graphs because outerplanar graphs are a unique type of planar graphs containing special characteristics. One of the core concepts of crisp graphs, the notion of a subgraph, is utilized primarily to solve difficult data problems. In this paper, researching outerplanar graphs in fuzzy graphs is the main aim of the work. By allowing edges connecting vertices to have varying levels of membership or fuzziness, a fuzzy graph is a mathematical framework that develops on the concept of crisp graphs. Because of their capacity to describe unclear or imprecise relationships between items, fuzzy outerplanar graphs might have potential applications. The subgraphs of fuzzy outerplanar graphs are revealed by eliminating specific vertices or edges from the fuzzy graphs. Furthermore, maximum, and maximal fuzzy outerplanar subgraphs defined for both vertex and edge deletion are examined using examples. Some of the connections between the concepts discussed are represented as theorems and conclusions. An application for the layout of a bypass road is discussed using the proposed concepts.},
  archive      = {J_IJCIS},
  author       = {Jaisankar, Deivanai and Ramalingam, Sujatha and Deivanayagampillai, Nagarajan and Walelign, Tadesse},
  doi          = {10.1007/s44196-024-00626-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fuzzy outerplanar graphs and its applications},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Many-objective grasshopper optimization algorithm (MaOGOA):
A new many-objective optimization technique for solving engineering
design problems. <em>IJCIS</em>, <em>17</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s44196-024-00627-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In metaheuristic multi-objective optimization, the term effectiveness is used to describe the performance of a metaheuristic algorithm in achieving two main goals—converging its solutions towards the Pareto front and ensuring these solutions are well-spread across the front. Achieving these objectives is particularly challenging in optimization problems with more than three objectives, known as many-objective optimization problems. Multi-objective algorithms often fall short in exerting adequate selection pressure towards the Pareto front in these scenarios and difficult to keep solutions evenly distributed, especially in cases with irregular Pareto fronts. In this study, the focus is on overcoming these challenges by developing an innovative and efficient a novel Many-Objective Grasshopper Optimisation Algorithm (MaOGOA). MaOGOA incorporates reference point, niche preserve and information feedback mechanism (IFM) for superior convergence and diversity. A comprehensive array of quality metrics is utilized to characterize the preferred attributes of Pareto Front approximations, focusing on convergence, uniformity and expansiveness diversity in terms of IGD, HV and RT metrics. It acknowledged that MaOGOA algorithm is efficient for many-objective optimization challenges. These findings confirm the approach effectiveness and competitive performance. The MaOGOA efficiency is thoroughly examined on WFG1-WFG9 benchmark problem with 5, 7 and 9 objectives and five real-world (RWMaOP1- RWMaOP5) problem, contrasting it with MaOSCA, MaOPSO, MOEA/DD, NSGA-III, KnEA, RvEA and GrEA algorithms. The findings demonstrate MaOGOA superior performance against these algorithms.},
  archive      = {J_IJCIS},
  author       = {Kalita, Kanak and Jangir, Pradeep and Čep, Robert and Pandya, Sundaram B. and Abualigah, Laith},
  doi          = {10.1007/s44196-024-00627-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Many-objective grasshopper optimization algorithm (MaOGOA): A new many-objective optimization technique for solving engineering design problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing drone-based IoT base stations in 6G networks
using the quasi-opposition-based lemurs optimization algorithm.
<em>IJCIS</em>, <em>17</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s44196-024-00628-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution and integration of next-generation Internet-of-things (NG-IoT) applications present new complexities for sixth-generation (6G) mobile communication networks, including the need for extensive connectivity, increased network capacity, and ultralow-latency communications. While ultradense networking, characterized by deploying numerous base stations, offers a potential solution, practical and financial constraints limit its feasibility. Drone-based stations (DBSs) emerge as a flexible alternative, but their optimal positioning remains a critical challenge due to finite energy sources and potential signal degradation. This study introduces a new quasi-opposition-based lemurs optimizer (QOBLO) to address the optimal placement of DBSs in NG-IoT networks. QOBLO combines lemur foraging behaviour with quasi-opposition-based learning to enhance exploration and exploitation in the optimization process. The performance of QOBLO was evaluated across three scenarios and compared with other swarm intelligence algorithms using metrics such as Friedman’s ranking test (FRT) and the Wilcoxon signed-rank test (WSRT). Rigorous simulations emulated real-world conditions and varying network demands, testing QOBLO&#39;s adaptability and robustness. Results indicate that QOBLO significantly outperforms other algorithms, achieving a top FRT value of 1.234 and demonstrating superior p values in the WSRT. These findings highlight QOBLO&#39;s capability to enhance connectivity, coverage, and energy efficiency in 6G environments. The primary contribution of this research is the development of QOBLO, a scalable and efficient method for optimizing DBS deployment. This new approach improves network performance in complex NG-IoT applications, offering a robust solution to the challenges of 6G networks and ensuring enhanced reliability and sustainability of future communication infrastructures.},
  archive      = {J_IJCIS},
  author       = {Loganathan, Vigneash and Veerappan, Saminathan and Manoharan, Premkumar and Derebew, Bizuwork},
  doi          = {10.1007/s44196-024-00628-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimizing drone-based IoT base stations in 6G networks using the quasi-opposition-based lemurs optimization algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Beyond words: Analyzing emotions and linguistic
characteristics to detect hoax-related tweets during spanish regional
elections. <em>IJCIS</em>, <em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00629-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting misinformation on social media, especially Twitter/X, is crucial during electoral periods. This study presents a comprehensive methodology using a Random Forest model to identify hoax-related tweets in the Spanish political landscape by analyzing their syntactic, semantic, lexical and emotional characteristics. The results reveal consistent emotional patterns where, the emotions most closely related to misinformation tend to be anger, disgust, fear and negativity. As a tangible outcome, we propose a tool designed to enhance the efficiency of fact-checkers in the detection of hoaxes. Also considered are the limitations of generic and multilingual approaches, supporting the use of context-specific strategies. The study demonstrates the effectiveness and generalizability, of the screening tool proposed as a means of combating misinformation in tweets during Spanish electoral periods.},
  archive      = {J_IJCIS},
  author       = {Álvarez-García, Elena and García-Costa, Daniel and Paniagua, Sandra and Vicens, Julian and Vila-Francés, Joan and Grimaldo, Francisco},
  doi          = {10.1007/s44196-024-00629-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Beyond words: Analyzing emotions and linguistic characteristics to detect hoax-related tweets during spanish regional elections},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized tiny machine learning and explainable AI for
trustable and energy-efficient fog-enabled healthcare decision support
system. <em>IJCIS</em>, <em>17</em>(1), 1–28. (<a
href="https://doi.org/10.1007/s44196-024-00631-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of things (IoT)-based healthcare decision support system plays a crucial role in modern medicine, especially with the rise in chronic illnesses and an aging population necessitating continuous remote health monitoring. Current healthcare decision support systems struggle to deliver timely and accurate decisions with minimal latency due to limited real-time healthcare data and inefficient computational resources. There is a critical need for an optimized, energy-efficient machine learning model that reliably supports remote health monitoring within IoT and fog computing environments. Our study proposes an Optimized Tiny Machine Learning (TinyML) and Explainable AI (XAI) binary classification model for a trustable and energy-efficient healthcare decision support system, leveraging fog computing to optimize performance. The fog-based approach improves response times and enhances bandwidth usage, addressing critical needs such as reduced latency, higher bandwidth utilization, and decreased packet loss. To further improve efficiency, we incorporate the innovative mLZW data compression technique, significantly enhancing data communication efficiency and reducing response time to critical health alerts. However, limited real-time healthcare data records challenge machine learning classification performance. By implementing a TinyML algorithm, our system demonstrates superior performance to other machine learning models. The proposed optimized TinyML model achieves an impressive F1 score of 0.93 for health abnormalities detection, emphasizing its robustness and effectiveness. This paper highlights the potential of TinyML and XAI in delivering robust, trustworthy, and energy-aware healthcare solutions, making significant contributions toward effective remote health monitoring and decision support in fog-enabled IoT networks.},
  archive      = {J_IJCIS},
  author       = {Arthi, R. and Krishnaveni, S.},
  doi          = {10.1007/s44196-024-00631-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimized tiny machine learning and explainable AI for trustable and energy-efficient fog-enabled healthcare decision support system},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Small object detection in UAV images based on YOLOv8n.
<em>IJCIS</em>, <em>17</em>(1), 1–9. (<a
href="https://doi.org/10.1007/s44196-024-00632-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of unmanned aerial vehicle (UAV) technology, there is an urgent need for high-performance aerial object detection algorithms that are tailored for deployment on drones with limited computing capabilities. This paper proposes a series of improvements to the state-of-the-art YOLOv8 object detector to enhance its detection accuracy and speed for small, partially occluded objects in complex environments. Specifically, we introduce multi-scale feature fusion through additional detection layers, employ conditionally parameterized convolutions to increase representational capacity, and import a dynamic non-monotonic loss function named Wise-IoU to enable more effective regression of bounding boxes. Experiments conducted on the large-scale UAV benchmark dataset VisDrone demonstrate that the improved model achieves state-of-the-art accuracy of 37.6% mAP with 3 M parameters, outperforming other lightweight YOLO detectors and two-stage detectors like Faster R-CNN. The improved model also reaches 40 FPS on an embedded edge device, validating its efficiency and suitability for real-time UAV applications. Through comprehensive quantitative experiments and visual results, this work provides valuable insights and techniques to tailor object detection algorithms for robust and efficient deployment on UAVs with limited onboard computing power.},
  archive      = {J_IJCIS},
  author       = {Xu, LongYan and Zhao, YiFan and Zhai, YaHong and Huang, LiMing and Ruan, ChongWei},
  doi          = {10.1007/s44196-024-00632-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-9},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Small object detection in UAV images based on YOLOv8n},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive value of machine learning models in mortality of
coronavirus disease 2019 (COVID-19) pneumonia. <em>IJCIS</em>,
<em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00633-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coronavirus disease 2019 (COVID-19) became the most spread and lethal disease in the last 3 years. Early predictions could optimize the decision-making process, healthcare outcomes, and effective usage of healthcare resources during peaks. This study set out to predict the mortality risk of COVID-19 patients by investigating 14 machine learning (ML) models using extensive clinical, laboratory, and image-based features. Additionally, feature importances in each model and the influences of features in the mortality prediction of ML models have been evaluated in this study. Data from 252 patients during the 5th peak of the COVID-19 pandemic (July 2021-September 2021) with 42 features were used for the training of ML models. Fourteen ML models were created using the fivefold cross-validation method. Each model was trained using a training-validation dataset with its own optimized parameters. The performance of models has been evaluated by metric parameters of accuracy, precision, sensitivity, specificity, AUC, and F1 score. The highest values of accuracy (87.30%), precision (100%), sensitivity (77.27%), specificity (100%), AUC (91.90%), and F1 score (77.99%) were observed for the linear discriminant analysis (LDA), K-Nearest Neighbors (KNN), Gaussian Naive Bayes (GNB), KNN, Passive Aggressive Classifier (PAC), and LDA models, respectively, when training was performed with all 42 features. By using feature selection techniques, the support vector classifier (SVC) model with 10 features showed the most AUC of 93.40%. The features of mechanical ventilation, consolidation, fatigue, malignancy, dry cough, level of consciousness (LOC), gender, diarrhea, O2 therapy, and SpO2 are potential predictors of mortality rates in COVID-19 patients.},
  archive      = {J_IJCIS},
  author       = {Rostami, Atefeh and Mousavi, Faezeh and Javadinia, Seyed Alireza and Robatjazi, Mostafa and Mehrpouyan, Mohammad},
  doi          = {10.1007/s44196-024-00633-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Predictive value of machine learning models in mortality of coronavirus disease 2019 (COVID-19) pneumonia},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved adaptive neuro-fuzzy inference framework for
lung cancer detection and prediction on internet of medical things
platform. <em>IJCIS</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00635-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has become increasingly difficult for medical practitioners to recognize illness in recent years due to the emergence of new diseases from their myriad causes on a daily basis. Due in large part to inadequate diagnostic and monitoring infrastructure, a substantial amount of illness and death are associated with lung cancer (LC). The aim of the paper is to find lung cancer early and help patients receive curative treatment. Quitting smoking or never starting is the best way to mitigate the potential for disease-related death. As a result, cutting-edge detection and monitoring technologies must be developed to enable rapid, accurate, and timely diagnosis. Fuzzy logic (FL) is one of the best approaches to modeling complex and uncertain systems; therefore, it helps us deal with these challenges. Fuzzy expert system for lung cancer [FES-LC] detection and prediction on Internet of medical things (IoMT) is employed to overcome the challenges. Hence, an enhanced adaptive neuro-fuzzy inference framework [ANF-IF] is proposed in the current research. The cloud-based application of an adaptive neuro-fuzzy inference system yields four risk categories: not at risk, slightly at risk, moderately at risk, and severely at risk. New methods and theoretical frameworks have made it possible to diagnose LC in its earliest stages with the help of magnetic nanoparticles (MNPs), which allow researchers to overcome the limitations of conventionally slow diagnostic efficiency. The proposed system exhibits a precision of 93.4%, accuracy of 95.1%, specificity of 90.6%, sensitivity of 92.8%, false positive rate of 0.22%, false negative ratio of 0.18%, and classification accuracy of 98.2%. The proposed method outperforms all methods and provides better lung cancer detection accuracy than others.},
  archive      = {J_IJCIS},
  author       = {Shabu, S. L. Jany and Refonaa, J. and Mallik, Saurav and Dhamodaran, D. and Grace, L. K. Joshila and Ksibi, Amel and Ayadi, Manel and Alshalali, Tagrid Abdullah N.},
  doi          = {10.1007/s44196-024-00635-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An improved adaptive neuro-fuzzy inference framework for lung cancer detection and prediction on internet of medical things platform},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Power quality enhancement in high-voltage transmission
systems using STATCOM by type 1 and type 2 fuzzy logic controllers.
<em>IJCIS</em>, <em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00636-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuing growth of load demand leads to increased power system complexity and interconnections. During faults and abnormal operating conditions, conventional power systems change the load flow in transmission lines, which may cause voltage drops or swells, and other power quality issues. Voltage regulation is connected to reactive power compensation in system busbars, and fixed capacitor banks are usually used for this purpose, but they are not flexible and dynamic enough to meet the power quality requirements. With power electronics development, flexible alternative current transmission systems (FACTS) became a popular solution for power quality improvement and power transmission capability increment in power systems, and FACTS can be categorized into series and shunt systems. In this study, STATCOM was used to improve the voltage profile in part of Iraq’s high-voltage transmission system during abnormal operating conditions, such as sudden load addition and removal, which causes voltage dip and voltage swell. Type 1 fuzzy logic controller and type 2 fuzzy logic controller were used as the outer controller in the STATCOM; both controllers were able to regulate the voltage magnitude by reducing the voltage dip from 1.32 to 0.4%, voltage swell from 1.02 to 0.5%, and voltage THD at the connecting point did not exceed 3%, indicating that SATACOM with FLC improves the voltage profile under different operating conditions.},
  archive      = {J_IJCIS},
  author       = {Chremk, Faissl G. and Medhaffar, Hanene},
  doi          = {10.1007/s44196-024-00636-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Power quality enhancement in high-voltage transmission systems using STATCOM by type 1 and type 2 fuzzy logic controllers},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy logic-based quantitative development model for job
satisfaction in college graduates. <em>IJCIS</em>, <em>17</em>(1), 1–13.
(<a href="https://doi.org/10.1007/s44196-024-00637-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {College graduates’ job satisfaction is validated via their feedback, experiences and personal developments during their career progression. Validation is accomplished to ensure the students’ job satisfaction and retain them for a prolonged time. The traditional validation models have difficulties in analyzing the individual satisfaction level. The research issue is addressed by introducing the Quantitative Assessment Method (QAM) using Fuzzy Logic to validate the job satisfaction level of different newly placed students. The QAM approach assesses the student experience and personal development across various quarters. The fuzzy optimization uses two factors differentially using partial derivatives. The partial derivatives are extracted using the min–max functions of the fuzzification process such that the derivatives are halted after the maximum factors. The proposed method optimizes the validation using individual satisfaction levels and cumulative experience shared by the students. The available derivatives identify the best-afford job satisfaction level for different progression levels. This best-fit feature is handled using multiple min and max derivatives to extract optimal outputs. This proposed method is valid for improving satisfaction levels and experience analysis.},
  archive      = {J_IJCIS},
  author       = {Cheng, Yuqi},
  doi          = {10.1007/s44196-024-00637-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fuzzy logic-based quantitative development model for job satisfaction in college graduates},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Towards integrating automatic emotion recognition in
education: A deep learning model based on 5 EEG channels.
<em>IJCIS</em>, <em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-024-00638-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a technologically advanced world, artificial intelligence has impacted all fields of activity. The augmentation of online learning by means of emotion recognition systems raises new challenges in terms of obtaining high-performance systems and in interpreting the results. The paper aims to investigate the usage of automated emotion recognition in learning and to develop a deep learning model based on physiological data to recognize emotions often encountered in classrooms. So, an 1D-CNN model based on physiological data is used to recognize seven emotions: boredom, confusion, frustration, curiosity, excitement, concentration, and anxiety. These emotions are described according to the PAD model and the 5 EEG signals, FP1, AF3, F7, T7, FP2, are taken from the DEAP dataset to train and to test the convolutional neural network model. The high accuracy we obtained (i.e. boredom—99.64%, confusion—99.70%, frustration—99.66%, curiosity—99.80%, excitement—99.91%, concentration—99.70%, anxiety—99.21%) proves that the use of signals obtained via only five channels is sufficient to recognize the presence of emotions. Furthermore, an improved method of analysis based on LIME is proposed and used to obtain reliable explanations for the predictions of our model.},
  archive      = {J_IJCIS},
  author       = {Moise, Gabriela and Dragomir, Elia Georgiana and Șchiopu, Daniela and Iancu, Lidia Angelica},
  doi          = {10.1007/s44196-024-00638-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Towards integrating automatic emotion recognition in education: A deep learning model based on 5 EEG channels},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prediction of remaining useful life of aero-engines based on
CNN-LSTM-attention. <em>IJCIS</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s44196-024-00639-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the remaining useful life (RUL) of aircraft engines is crucial for maintaining financial stability and aviation safety. To further enhance the prediction accuracy of aircraft engine RUL, a deep learning-based RUL prediction method is proposed. This method possesses the potential to strengthen the recognition of data features, thereby improving the prediction accuracy of the model. First, the input features are normalized and the CMAPSS (Commercial Modular Aero-Propulsion System Simulation) dataset is utilized to calculate the RUL for aircraft engines. After extracting attributes from the input data using a convolutional neural network (CNN), the extracted data are input into a long short-term memory (LSTM) network model, with the addition of attention mechanisms to predict the RUL of aircraft engines. Finally, the proposed aircraft engine model is evaluated and compared through ablation studies and comparative model experiments. The results indicate that the CNN-LSTM-Attention model exhibits superior prediction performance for datasets FD001, FD002, FD003, and FD004, with RMSEs of 15.977, 14.452, 13.907, and 16.637, respectively. Compared with CNN, LSTM, and CNN-LSTM models, the CNN-LSTM model demonstrates better prediction performance across datasets. In comparison with other models, this model achieves the highest prediction accuracy on the CMAPSS dataset, showcasing strong reliability and accuracy.},
  archive      = {J_IJCIS},
  author       = {Deng, Sizhe and Zhou, Jian},
  doi          = {10.1007/s44196-024-00639-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Prediction of remaining useful life of aero-engines based on CNN-LSTM-attention},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing multi-step brent oil price forecasting with
ensemble multi-scenario bi-GRU networks. <em>IJCIS</em>, <em>17</em>(1),
1–12. (<a href="https://doi.org/10.1007/s44196-024-00640-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate crude oil price forecasting is crucial for economic stability, investment planning, and strategic decision-making across various industries. Despite numerous research efforts in applying deep learning to time-series forecasting, achieving high accuracy in multi-step predictions for volatile time-series like crude oil prices remains a significant challenge. Moreover, most existing approaches primarily focus on one-step forecasting, and the performance often varies depending on the dataset and specific case study. This paper introduces ensemble-based deep-learning models to capture Brent oil price volatility and enhance the multi-step price prediction. Our methodology employs a two-pronged approach. First, we present an empirical comparison of deep-learning models and architectures, including RNNs, CNNs, and transformers, for forecasting Brent oil prices. We also examine the impact of various external factors on forecasting accuracy. Then, we introduce a novel approach that employs ensemble GRU-based models to enhance prediction accuracy across multiple forecasting scenarios. Extensive experiments were conducted using a dataset of historical Brent prices encompassing the COVID-19 pandemic, which significantly impacted energy markets. The results demonstrate that the proposed model outperforms benchmark and established models, achieving a 9.3% reduction in MSE compared to the closest benchmark model for a 3-day forecasting horizon.},
  archive      = {J_IJCIS},
  author       = {Alruqimi, Mohammed and Di Persio, Luca},
  doi          = {10.1007/s44196-024-00640-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing multi-step brent oil price forecasting with ensemble multi-scenario bi-GRU networks},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Creating personalized higher education teaching system using
fuzzy association rule mining. <em>IJCIS</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00641-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Universities and colleges aim to provide students with a solid academic foundation. Quality instruction is one strategy for achieving the highest possible standard in the higher education system. Personalized teaching caters to each student by adapting the learning pace and method to their specific requirements. However, the present state of customized education in higher education resources prevents proper resources from being extracted due to a lack of multi-dimensional association analysis between students, circumstances, and materials. A hybrid personalized teaching system utilizing fuzzy association rules mining is the goal of this research to improve learning in higher education. Effective multi-dimensional association analysis among students, settings, and instructional materials is facilitated by the fuzzy association rules mining-based hybrid personalized teaching system (FARM-HPT). The proposed study conforms to AI standards, is based on fuzzy logic theories, and guarantees precise university-level resource discovery. The study builds on earlier work in data mining by presenting a new, learner-specific recommendation model for personalized teaching that uses FARM to ensure accurate resource recognition and efficient mining of instructional assets at the higher education level. This new approach generates fewer set comparisons and does them faster than the current standard. Focusing on experimental validation, the study shows that the FARM-HPT system can generate individualized lessons while overcoming the constraints of traditional information mining methods. These findings align with AI standards, which shows how important it is to validate new AI approaches using robust empirical evidence. The system ensures effective accuracy on various datasets: LFW (89.76%), JAOLAD (94.43%), OECD (95.43%) and OULAD (97.45%).},
  archive      = {J_IJCIS},
  author       = {Li, Dezhi},
  doi          = {10.1007/s44196-024-00641-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Creating personalized higher education teaching system using fuzzy association rule mining},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of artificial intelligence and fuzzy control
algorithm in green and low-carbon highway construction. <em>IJCIS</em>,
<em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00642-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart highways endorse green and low-carbon handling construction infrastructures for promoting pollution-free environments and driving spaces. With the incorporation of artificial intelligence and smart computing features, sophisticated decision systems improve the aim of such smart highway constructions. For promoting green and low-carbon highway construction infrastructure, this research article introduces a pollution control-facilitated recommendation system (PCFRS). The system aims to satisfy eco-friendly driving demands and low-carbon emission requirements. In this system, eco-friendly driving demands and low-carbon emissions are the prime requirements for designing such highways. The research employs fuzzy control algorithms to analyze the relationship between green demands and demand satisfaction factors across different infrastructures based on policies from environmental departments and governing agencies. The green demands as formulated by the environmental department/ governing agencies are used for verifying the demand and relationship factors across various infrastructures. The fuzzy algorithm provides recommendations for optimal highway infrastructure design by identifying the maximum possible combinations of satisfaction factors, enabling cost-effective construction while meeting green environment and low-carbon emission goals. This process is aided by a fuzzy control algorithm with the relationship and demand factor as crisp inputs. The decisions on the maximum possible combinations of the satisfaction factor are used for infrastructure recommendations. The need for optimal design and promoting green environments are optimal across various highway lanes.},
  archive      = {J_IJCIS},
  author       = {Zhang, Jingyuan and Cai, Xiurong and Wang, Shuang and Zhang, Haiying},
  doi          = {10.1007/s44196-024-00642-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Application of artificial intelligence and fuzzy control algorithm in green and low-carbon highway construction},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constructing a novel network structure weighting technique
into the ANP decision support system for optimal alternative evaluation:
A case study on crowdfunding tokenization for startup financing.
<em>IJCIS</em>, <em>17</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-024-00643-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study constructed a novel decision-making framework for startup companies to evaluate token financing options. A Network structure weighting (NSW) technique was developed and integrated with the analytic network process (ANP) to create a comprehensive assessment model. This innovative approach addressed the limitations of traditional multi-criteria decision-making methods by effectively capturing the complex interdependencies between factors influencing token financing decisions. The proposed model comprises three main steps: (1) utilizing a modified Delphi method to identify key factors affecting token financing, (2) developing the NSW technique to determine the network structure of these factors, and (3) integrating the NSW results into the ANP model to evaluate and rank the critical factors and alternatives. This study applied this framework to assess three token financing alternatives: Initial Coin Offerings (ICO), Initial Exchange Offerings (IEO), and Security Token Offerings (STO). The results indicate that STO is the optimal financing alternative for the analyzed startup scenario in token financing, followed by Initial Exchange Offerings and Initial Coin Offerings. The model identified platform fees, issuance costs, and financing success rate as the three most critical factors influencing the decision. This study contributes to both methodology and practice in FinTech decision-making. The NSW-ANP framework offers a more robust approach to modeling complex financial decisions, while the application to token financing provides valuable insights for startup companies navigating this emerging funding landscape. The proposed framework lays the groundwork for more informed and structured decision-making in the rapidly evolving field of cryptocurrency-based financing.},
  archive      = {J_IJCIS},
  author       = {Lin, Chun-Yueh},
  doi          = {10.1007/s44196-024-00643-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Constructing a novel network structure weighting technique into the ANP decision support system for optimal alternative evaluation: A case study on crowdfunding tokenization for startup financing},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing critical infrastructure security: Unsupervised
learning approaches for anomaly detection. <em>IJCIS</em>,
<em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00644-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional security detection methods face challenges in identifying zero-day attacks in critical infrastructures (CIs) integrated with the industrial internet of things (IIoT). These attacks exploit unknown vulnerabilities and are difficult to detect due to their connection to physical systems. The integration of legacy ICS networks with modern computing and networking technologies has significantly expanded the attack surface, making these systems more susceptible to cyber-attacks. Despite existing security measures, attackers continually find ways to breach these operating networks. Anomaly detection systems are critical in protecting these CIs from current cyber threats. This study investigates the effectiveness of unsupervised anomaly detection models in detecting operational anomalies that could lead to cyber-attacks, thereby disrupting and negatively impacting quality of life. We preprocess the data with a focus on cybersecurity and chose the SWAT dataset because it accurately represents the types of attack vectors that critical infrastructures commonly encounter. We evaluated the performance of isolation forest (IF), local outlier factor (LOF), one-class SVM (OCSVM), and Autoencoder algorithms—trained exclusively on normal data—in enhancing cybersecurity within IIoT environments. Our comprehensive analysis includes an assessment of each model’s detection capabilities. The findings highlight the VAE-LSTM model’s potential to identify cyber-attacks within seconds in a high-frequency dataset, suggesting near real-time detection capability. The final model combines the reconstruction ability of the variational autoencoder (VAE) with regularization using the Kullback–Leibler divergence, reflecting the non-Gaussian nature of industrial system data. Our model successfully detected 23 out of 26 attack scenarios in the SWAT dataset, demonstrating its effectiveness in improving the security of IIoT-based CIs.},
  archive      = {J_IJCIS},
  author       = {Pinto, Andrea and Herrera, Luis-Carlos and Donoso, Yezid and Gutierrez, Jairo A.},
  doi          = {10.1007/s44196-024-00644-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing critical infrastructure security: Unsupervised learning approaches for anomaly detection},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the construction of congruences over generalized fuzzy
g-acts. <em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00645-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group action is defined to support Cayley’s claim that every group is isomorphic to a suitable subgroup of a symmetric group. Group actions have a wide range of applications, including the analysis of symmetries of geometric objects and algorithms and cryptographic systems. In 1965, Zadeh introduced the concept of fuzzy sets and provided a mathematical formulation for various concepts in this area. Since then, the concept of fuzziness has been integrated into several branches of mathematics to address the uncertainties of real-life scenarios. This article introduces the concept of group action in a fuzzy environment, termed fuzzy $$\mathcal {G}$$ -subacts. The study provide the concept of fuzzy $$\mathcal {G}$$ -orbits and fuzzy $$\mathcal {G}$$ -stabilizers and clearly outlines fuzzy permutation representations of $$\mathcal {G}$$ and fuzzy $$\mathcal {G}$$ -morphisms. The research findings significantly contributes to the understanding of fuzzy $$\mathcal {G}$$ -congruences and fuzzy quotient $$\mathcal {G}$$ -subacts with the help of fuzzy $$\mathcal {G}$$ -partitions. This approach not only refines the underlying theories but also opens up new possibilities for practical implementation. Thus, the study demonstrates how the more complex fuzzy theory can expand and enrich the mathematical structures of abstract algebra, making them highly applicable.},
  archive      = {J_IJCIS},
  author       = {Kousar, Sajida and Shaheen, Sumaira and Kausar, Nasreen and Pamucar, Dragan and Simic, Vladimir and Salman, Mohammed Abdullah},
  doi          = {10.1007/s44196-024-00645-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {On the construction of congruences over generalized fuzzy G-acts},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MBJELEL: An end-to-end knowledge graph entity linking method
applied to civil aviation emergencies. <em>IJCIS</em>, <em>17</em>(1),
1–15. (<a href="https://doi.org/10.1007/s44196-024-00647-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aviation emergency management is playing a more and more important role in the aviation field. How to make effective use of massive heterogeneous and multi-source aviation accident knowledge has become a great challenge for aviation emergency management. Aiming at the problems such as too long physical length, mixed and composite entities, similar character of domain entity names, information difference between entities, separation of codes between entities, coding errors during transmission, etc., the construction method of knowledge map of civil aviation emergencies is studied. In previous research methods, entity link is always divided into two parts, that is, first detection and then disambiguation, which makes the mentioned entity and the candidate entity are encoded separately, and there is error transmission between the two parts, modules cannot communicate with each other, and the close association between entities cannot be well learned. In this paper, we proposed an end-to-end entity linking method based on two-layer BiLSTM model joint coding vectorize each word of civil aviation text information, and then concatenate feature vectors into two-layer BiLSTM model to obtain high-level context representation. Because the joint encoding of boundary information can reduce the error transmission, information is exchanged between candidate entities during the initial encoding to enhance the closeness between candidate entities and candidate entities. The experimental results show that compared with other sota models, the F1 value of the proposed model reaches 88.97%.},
  archive      = {J_IJCIS},
  author       = {Qu, Jiayi and Wang, Jintao and Zhao, Zuyi and Chen, Xingguo},
  doi          = {10.1007/s44196-024-00647-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MBJELEL: An end-to-end knowledge graph entity linking method applied to civil aviation emergencies},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint optimization-based QoS and PAPR reduction technique
for energy-efficient massive MIMO system. <em>IJCIS</em>,
<em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00648-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive multiple input multiple output (MIMO) is an innovative wireless communication technology that significantly enhances the capacity and efficiency of data transmission in modern networks. Massive multiple input multiple output, despite benefits, faces difficulties in managing numerous antennas affecting signal quality, peak-to-average power ratio (PAPR), and energy efficiency due to its scale and complexity. However, overcoming these complexities is vital for unlocking massive multiple input multiple output’s potential in high-quality, energy-efficient wireless communication. A proposed joint optimization-based technique aims to address these issues in massive MIMO systems. In phase 1, joint optimization with quality of service maximizes capacity via power distribution, employing the hybrid spider wasp Fick’s law algorithm. In phase 2, zero-forcing with symbol-level linear precoding, especially the stacked convolutional sparse bidirectional long short-term memory autoencoder (SCS–BiLSTMAE) network, efficiently reduces peak-to-average power ratio, collaborating for reduced bit rate error and peak-to-average power ratio through adaptive mapping. Refining the model involves precise hyperparameter tuning using the enhanced influencer buddy optimization algorithm. The proposed framework not only demonstrates exceptional performance, but the metrics also underscore the model&#39;s effectiveness in addressing diverse challenges, establishing it as a robust solution for quality enhancement, peak-to-average power ratio reduction, and energy efficiency. Additionally, the proposed model attains 28.14% greater system capacity than existing methods.},
  archive      = {J_IJCIS},
  author       = {Bolla, Sandhya and Singh, Manwinder},
  doi          = {10.1007/s44196-024-00648-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Joint optimization-based QoS and PAPR reduction technique for energy-efficient massive MIMO system},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A shark inspired ensemble deep learning stacks for ensuring
the security in internet of things (IoT)-based smart city
infrastructure. <em>IJCIS</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00649-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in the Internet of Things (IoT) have paved the way for intelligent and sustainable solutions in smart city environments. However, despite these advantages, IoT-connected devices present significant privacy and security risks, as network attacks increasingly exploit user-centric information. To protect the network against the rapidly growing number of cyber-attacks, it is essential to employ a cognitive intrusion detection system (CIDS) capable of handling complex and voluminous network data. This research presents a novel ensemble deep learning framework designed to enhance cybersecurity in IoT-based smart city ecosystems. The proposed architecture integrates Self-Attention Convolutional Neural Networks, Bidirectional Gated Recurrent Units, and Shark Smell Optimized Feed Forward Networks to create a robust, adaptive system for detecting and mitigating cyber threats. By leveraging fog computing, the model significantly reduces latency and computational overhead, making it highly suitable for large-scale IoT deployments. Extensive experimentation using the ToN-IoT dataset demonstrates the framework&#39;s exceptional performance, achieving a 99.78% detection rate across various attack types and an AUC of 0.989. The proposed model outperforms existing state-of-the-art approaches, achieving a mean fitness function value of 0.85640 and a standard deviation of 0.037630 in binary classification outcomes. In multi-class classification, the model maintains a mean fitness function value of 0.8230 and a variance of 2.28930 × 104, significantly outperforming other meta-heuristic algorithms such as Particle Swarm Optimization (PSO) and Genetic Algorithm (GA). The model exhibits superior accuracy and efficiency compared to existing state-of-the-art approaches, particularly in identifying complex and emerging threats. This research makes significant contributions by introducing innovative feature extraction techniques, optimizing model performance for resource-constrained environments, and providing a scalable solution for securing smart city infrastructure. The findings highlight the potential of ensemble deep learning approaches to fortify IoT networks against cyberattacks, paving the way for more resilient and secure smart cities.},
  archive      = {J_IJCIS},
  author       = {Kumar, P. Jagadish and Neduncheliyan, S.},
  doi          = {10.1007/s44196-024-00649-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A shark inspired ensemble deep learning stacks for ensuring the security in internet of things (IoT)-based smart city infrastructure},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cross-efficiency evaluation method with performance level as
a management objective in consideration of bounded rationality.
<em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00650-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to management by objectives (MBO) theory, the significance of management objectives must be considered as a reference point in a performance evaluation. Cross efficiency evaluation has always been considered to be one of the important performance evaluation methods. However, few studies to date have considered the impact of management objectives on cross efficiency. According to prospect theory, the choice of reference point will cause irrational psychology in decision makers. A management objective is a natural reference point, which will cause a ‘gain and loss’ psychology in enterprises and may create irrational psychology. Performance level is an important index by which to evaluate resource allocation, which in turn can be regarded as an important enterprise management objective. This paper proposes a cross efficiency evaluation method based on performance level. Cross efficiency evaluation models are constructed, based on the irrational psychology that occurs under organization objectives, personal objectives and composite objectives. This method not only considers the bounded rational behavior of enterprises, but is also more flexible. A numerical example is given to illustrate the application of the bounded rational cross efficiency evaluation method in data envelopment analysis (DEA) ranking.},
  archive      = {J_IJCIS},
  author       = {Shi, Hai-Liu and Wang, Ying-Ming and Zhang, Xiao-Ming},
  doi          = {10.1007/s44196-024-00650-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Cross-efficiency evaluation method with performance level as a management objective in consideration of bounded rationality},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Insulator defect detection based on the CDDCR–YOLOv8
algorithm. <em>IJCIS</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00654-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insulator defect detection is a critical aspect of grid inspection in reality, yet it faces intricate environmental challenges, such as slow detection speed and low accuracy. To address this issue, we propose a YOLOv8-based insulator defect detection algorithm named CDDCR–YOLOv8. This algorithm divides the input insulator images into multiple grid cells, with each grid cell responsible for predicting the presence and positional information of one or more targets. First, we introduce the Coordinate Attention (CA) mechanism module into the backbone network and replace the original C2f module with the enhanced C2f_DCN module. Second, improvements are made to the original upsampling and downsampling layers in the neck network, along with the introduction of the lightweight module RepGhost. Finally, we employ Wise-IoU (WIoU) to replace the original CIoU as the loss function for network regression. Experimental results demonstrate that the improved algorithm achieves an average precision mean (mAP @ 0.5) of 97.5% and 90.6% on the CPLID and IPLID data sets, respectively, with a frame per second (FPS) of 84, achieving comprehensive synchronous improvement. Compared to traditional algorithms, our algorithm exhibits significant performance enhancement.},
  archive      = {J_IJCIS},
  author       = {Jiang, Tingyao and Hou, Xuan and Wang, Min},
  doi          = {10.1007/s44196-024-00654-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Insulator defect detection based on the CDDCR–YOLOv8 algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Author correction: Power quality enhancement in
high-voltage transmission systems using STATCOM by type 1 and type 2
fuzzy logic controllers. <em>IJCIS</em>, <em>17</em>(1), 1. (<a
href="https://doi.org/10.1007/s44196-024-00659-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Chremk, Faissl G. and Medhaffar, Hanene},
  doi          = {10.1007/s44196-024-00659-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Author correction: Power quality enhancement in high-voltage transmission systems using STATCOM by type 1 and type 2 fuzzy logic controllers},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning for optimizing macro-ergonomics in
pharmaceutical supply chain. <em>IJCIS</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00513-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study endeavors to enhance the macro-ergonomics of pharmaceutical supply chains by introducing an innovative hybrid AI methodology, incorporating fuzzy data envelopment analysis (FDEA). A comprehensive case study is conducted to evaluate the efficiency of the pharmaceutical supply chain, focusing on macro-ergonomic work system assessment. This evaluation aims to identify design flaws contributing to communication delays between physicians and patients. The proposed integrated approach utilizes a hybrid AI framework, specifically FDEA, to accurately measure macro-ergonomic influences on the healthcare supply chain under uncertain conditions. The case study involves a prominent urban outpatient medical facility with 20 clinics, selecting 20 Decision-Making Units for a holistic perspective. Results uncover factors causing delays, emphasizing weak or absent feedback structures as critical elements affecting the healthcare supply chain’s effectiveness. In conclusion, the study recommends modifications to optimize the pharmaceutical supply chain, enhancing overall healthcare efficiency. The findings provide valuable insights for healthcare management, underscoring the crucial role of advanced AI methodologies in addressing complex challenges within healthcare supply chains.},
  archive      = {J_IJCIS},
  author       = {Jamali, Najmeh and Gharib, Mohammad Reza and Moayyedian, Mehdi and Hedayati-Dezfooli, Mohsen},
  doi          = {10.1007/s44196-024-00513-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Machine learning for optimizing macro-ergonomics in pharmaceutical supply chain},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian optimization with additive kernels for a stepwise
calibration of simulation models for cost-effectiveness analysis.
<em>IJCIS</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s44196-024-00646-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A critical aspect of simulation models used in cost-effectiveness analysis lies in accurately representing the natural history of diseases, requiring parameters such as probabilities and disease burden rates. While most of these parameters can be sourced from scientific literature, they often require calibration to align with the model’s expected outcomes. Traditional optimization methods can be time-consuming and computationally expensive, as they often rely on simplistic heuristics that may not ensure feasible solutions. In this study, we explore using Bayesian optimization to enhance the calibration process by leveraging domain-specific knowledge and exploiting structural properties within the solution space. Specifically, we investigate the impact of additive kernel decomposition and a stepwise approach, which capitalizes on the sequential block structure inherent in simulation models. This approach breaks down large optimization problems into smaller ones without compromising solution quality. In some instances, parameters obtained using this methodology may exhibit less error than those derived from naive calibration techniques. We compare this approach with two state-of-the-art high-dimensional Bayesian Optimization techniques: SAASBO and BAxUS. Our findings demonstrate that Bayesian optimization significantly enhances the calibration process, resulting in faster convergence and improved solutions, particularly for larger simulation models. This improvement is most pronounced when combined with a stepwise calibration methodology.},
  archive      = {J_IJCIS},
  author       = {Gómez-Guillén, David and Díaz, Mireia and Arcos, Josep Lluís and Cerquides, Jesus},
  doi          = {10.1007/s44196-024-00646-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Bayesian optimization with additive kernels for a stepwise calibration of simulation models for cost-effectiveness analysis},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Screening of key transcripts from expression data using
applied artificial intelligence for cancer prediction. <em>IJCIS</em>,
<em>17</em>(1), 1–8. (<a
href="https://doi.org/10.1007/s44196-024-00657-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on the effects of artificial intelligence (AI)-driven solutions in the field of oncology is still being conducted all around the world. Applications of AI to identify the transcripts that cause cancer are being investigated, particularly when employing ensemble learning techniques. Ensemble feature fusion is the process of distributing the feature selection process and combining the local features that were chosen to create a smaller global feature set. This article addresses the use of ensemble feature fusion in the field of differential transcript expression analysis to screen for important transcripts linked to a disease. Owing to the necessity and significance of research in cancer diagnosis, an ensemble feature fusion approach experimental case study has been carried out using 109 liver cancer samples obtained from Mitranscriptome dataset. It was found that the expression data were used to filter the most pertinent transcripts, which allowed for the best possible differentiation between sample type. Accordingly, a set of 26 significant liver cancer causing transcripts has been screened using unanimous voting-scheme, giving an accuracy of percentage of 96. During generalization testing, cancer prediction classifiers constructed with this essential transcript collection shown excellent discriminating power and performed well in differentiating between normal and malignant cells. By resolving the “high dimension-low sample (High p Low n)” issue that is typically present in the expression data, this improves the predicting ability of cancer diagnostic systems. In the field of oncology, artificial intelligence-powered solutions will facilitate the development of applications that prioritize Sustainable Development Goal 3: Good Health and Well-Being.},
  archive      = {J_IJCIS},
  author       = {Pratap, Anju and Hamada, Michiaki},
  doi          = {10.1007/s44196-024-00657-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-8},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Screening of key transcripts from expression data using applied artificial intelligence for cancer prediction},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear monotonic inter-electrode associations as
quantitative EEG for alcoholism diagnosis. <em>IJCIS</em>,
<em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00660-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alcohol use disorders (AUDs) are associated with alterations in EEG patterns that reflect underlying neural dysfunctions, such as impaired cognitive processing, reduced neural connectivity, and disrupted brain rhythms. These EEG alterations can be indicative of several brain disorders, including cognitive deficits, mood disorders, and neurodegenerative diseases, which are often exacerbated by chronic alcohol abuse. Cognitive impairment in alcoholic subjects is caused due to altered functional connectivity between brain regions that can be quantified using statistical measures such as correlation. This paper proposes novel Quantitative EEG (QEEG) features comprising the band-wise absolute value of inter-electrode correlations as a measure of brain functional connectivity to classify alcoholic and non-alcoholic EEG. The EEG signal is first decomposed into five frequency sub-bands. In each sub-band, the absolute value of the linear Pearson product-moment correlation coefficient is computed between time-series EEG recorded by electrode pairs placed over different brain regions. To reduce the dimensionality of the feature vector, an ensemble feature selection approach is adopted, utilizing ANOVA and Chi-square, in conjunction with greedy forward feature selection wrapper algorithm. Four classifiers, namely SVM, KNN, ANN and RF are utilized for the classification. Among them, the SVM classifier achieves the best classification accuracies of 100% on validation with test data and 99.58% on cross-validation with train data, respectively.},
  archive      = {J_IJCIS},
  author       = {Holker, Ruchi and Susan, Seba},
  doi          = {10.1007/s44196-024-00660-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Linear monotonic inter-electrode associations as quantitative EEG for alcoholism diagnosis},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid framework for improved weighted quantum particle
swarm optimization and fast mask recurrent CNN to enhance phishing-URL
prediction performance. <em>IJCIS</em>, <em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-024-00663-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phishing websites are cybercrimes that aim to collect confidential data, including bank card numbers, bank accounts, and credentials. To detect phishing sites, specialists must extract the elements of the websites and utilize third-party resources. One of the drawbacks of these methods is that identifying phishing characteristics takes a lot of effort and knowledge. Second, the recognition of phishing websites is delayed when third-party services are used. A novel detecting system Improved Weighted Quantum Particle Swarm Optimisation (IWQPSO) and Fast Mask Recurrent Convolutional Neural Network (FMRCNN) proposed to strengthen and empower the technique of identifying phishing URLs. The proposed model does not require the retrieval of target website content or the use of any third-party services. Phishing attacks continue to pose significant cyber-security threats, particularly through deceptive URLs. This study proposes a novel approach to enhance phishing-URL prediction using a hybrid methodology. The method integrates an IWQPSO-FMRCNN. The IWQPSO algorithm is leveraged to optimize the weights and parameters of the FMRCNN model, enhancing its performance in distinguishing between legitimate and phishing URLs. By combining the strengths of evolutionary optimization and deep learning, the proposed approach aims to achieve higher accuracy 99.3%, precision 94.6%, F1-Score 96.7%, Recall 98.2% and AUC score 97.9% in detecting phishing URLs compared to existing methods. Experimental results demonstrate the effectiveness of the proposed hybrid method in improving phishing-URL prediction performance, providing a promising avenue for enhancing cyber-security measures against online threats.},
  archive      = {J_IJCIS},
  author       = {Kumar, S. Senthil and Muthusamy, Prakash and Jerald, M. Paul Arokiadass},
  doi          = {10.1007/s44196-024-00663-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A hybrid framework for improved weighted quantum particle swarm optimization and fast mask recurrent CNN to enhance phishing-URL prediction performance},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blockchain-assisted keyword search scheme for SWIM service
based on improved CSC-cuckoo filter. <em>IJCIS</em>, <em>17</em>(1),
1–17. (<a href="https://doi.org/10.1007/s44196-024-00665-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the civil aviation industry, the demand for secure sharing of civil aviation data is increasing. As a global platform for secure sharing of civil aviation data, the security of the System Wide Information Management (SWIM) system is of great concern. SWIM adopts a service-oriented architecture and realizes the interaction of civil aviation data through a publish-subscribe model. To protect the service privacy while enabling subscribers to subscribe to the service quickly and securely, this paper proposes an efficient Circular Shift and Coalesce-Cuckoo Filter (CSC-CF)-based service Keyword Search (CCKS) scheme assisted by blockchain. This scheme uses the Symmetric-key Hidden Vector Encryption (SHVE) algorithm to encrypt and match service indexes and trapdoors to protect service privacy; the CSC-CF structure is applied to keyword search, which can effectively improve the efficiency of SWIM user subscription service. To improve search accuracy and space utilization, we propose the improved CCKS (ICCKS) scheme by optimizing the query algorithm of CSC-CF and setting a threshold for the number of keyword query failures. ICCKS improves search accuracy by 5–20% compared to CCKS when the filter’s space utilization is between 60 and 90%. Additionally, the scheme stores service topic indexes and registry on the blockchain and implements a smart contract to match indexes and subscription trapdoors, ensuring the integrity and trustworthiness of service topics and registry. Security analysis and experimental simulations demonstrate that the scheme is effective and secure in the SWIM system.},
  archive      = {J_IJCIS},
  author       = {Zhang, Lizhe and Luo, Wei and Li, Jiahao and Wu, Zhijun and Li, Ruiqi},
  doi          = {10.1007/s44196-024-00665-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Blockchain-assisted keyword search scheme for SWIM service based on improved CSC-cuckoo filter},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel approach for temperature forecasting in climate
change using ensemble decomposition of time series. <em>IJCIS</em>,
<em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00667-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents FORSEER (Forecasting by Selective Ensemble Estimation and Reconstruction), a novel methodology designed to address temperature forecasting under the challenges inherent to climate change. FORSEER integrates decomposition, forecasting, and ensemble methods within a modular framework. This methodology decomposes the time series into trend, seasonal, and residual components. Subsequently, multiple optimized forecast models are applied to each component. These component models are then carefully weighted and combined through an ensemble process to generate a final robust forecast. Experimental results demonstrate that FORSEER is an efficient computational forecasting methodology for complex climate time series. Furthermore, we show that FORSEER has an equivalent forecasting performance to the M4 competition champion SMYL method for temperature series. Besides, the proposed methodology has less computational complexity than SMYL, making it a more accessible and scalable option. FORSEER&#39;s modular architecture also allows flexibility when substituting techniques depending on the context of the problem, facilitating the parallel execution of independent tasks and resulting in a strategy adaptable to multiple contexts.},
  archive      = {J_IJCIS},
  author       = {Estrada-Patiño, Erick and Castilla-Valdez, Guadalupe and Frausto-Solis, Juan and González-Barbosa, Javier and Sánchez-Hernández, Juan Paulo},
  doi          = {10.1007/s44196-024-00667-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel approach for temperature forecasting in climate change using ensemble decomposition of time series},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Biometric CNN model for verification based on blockchain and
hyperparameter optimization. <em>IJCIS</em>, <em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00653-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, fingerprints as biometrics are among the most popular means of identity verification for various applications. However, they are susceptible to theft, tampering, or alteration by attackers after storage. Hence, it is critical to guarantee the privacy of these fingerprint templates because standard privacy techniques are not secure enough. Additionally, fingerprint templates are verified using a deep learning model to distinguish between authentic and fake fingerprints, making them more protected and secure by storing them inside a blockchain, which has become the most common secure technique in recent years. This paper implements the proposed efficient and secure biometric system for verification based on blockchain technology and hyperparameter optimization. First, for the storing phase, each user’s authentic fingerprint template, private, and public keys are saved in the block and linked to the previous block in the chain by a hash function. If a hacker attempts to assault a fingerprint, all prior blocks must be changed. Second, for the authentication phase, the user logs in with his fingerprint and looks up the required template in the chain. If the required fingerprint exists, it creates a new block with the login details, and the number 1 is returned, which means that the authentication is valid; if it does not exist, it is verified to see if it is authentic or fake using the proposed biometric convolutional neural network (CNN). The proposed CNN uses the Grid Search (GS) algorithm to tune hyperparameters to distinguish between authentic and fake fingerprints. The SOCOFing dataset is used for evaluating our experiment. According to the experimental results, the proposed CNN model achieved the highest accuracy of 99.52%. As a result of the blockchain, our system can return authentication information after looking up the chain in 300 ms.},
  archive      = {J_IJCIS},
  author       = {Asem, Esraa and Abouelmagd, Lobna M. and Tolba, Ahmed Elsaid and Elmougy, Samir},
  doi          = {10.1007/s44196-024-00653-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Biometric CNN model for verification based on blockchain and hyperparameter optimization},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A novel method for identifying landslide surface
deformation via the integrated YOLOX and mask r-CNN model.
<em>IJCIS</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00655-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of landslide areas and surface characteristics is the prerequisite and basis of landslide hazard risk assessment. The traditional method relies mainly on manual field identification, and discrimination is based on the lack of unified quantitative standards. Thus, the use of neural networks for the quantitative identification and prediction of landslide surface deformation is explored. By constructing an integrated model based on YOLO X-CNN and Mask R-CNN, a deep learning-based feature detection method for landslide surface images is proposed. First, the method superimposes Unmanned Aerial Vehicle (UAV) oblique photography data (UOPD) and Internet heterosource image data (IHID) to construct a landslide surface image dataset and landslide surface deformation database. Second, an integrated model suitable for small- and medium-scale target detection and large-scale target edge extraction is constructed to automatically identify and extract landslide surface features and to achieve rapid detection of landslide surface features and accurate segmentation and deformation recognition of landslide areas. The results show that the detection accuracy for small rock targets is greater than 80% and that the speed is 57.04 FPS. The classification and mask segmentation accuracies of large slope targets are approximately 90%. A speed of 7.89 FPS can meet the needs of disaster emergency response; this provides a reference method for the accurate identification of landslide surface features.},
  archive      = {J_IJCIS},
  author       = {Wan, Chenhui and Gan, Jianjun and Chen, Anbang and Acharya, Prabin and Li, Fenghui and Yu, Wenjie and Liu, Fangzhou},
  doi          = {10.1007/s44196-024-00655-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel method for identifying landslide surface deformation via the integrated YOLOX and mask R-CNN model},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Image-based fitness yoga pose recognition: Using ensemble
learning and multi-head attention. <em>IJCIS</em>, <em>17</em>(1), 1–17.
(<a href="https://doi.org/10.1007/s44196-024-00662-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing awareness of fitness, more and more people are choosing to participate in fitness activities. Yoga, as a form of exercise that improves both physical and mental health, is becoming increasingly popular worldwide. In order to assist yoga practitioners in more effective training through automated or semi automated systems, improve training effectiveness, assist professional athletes in training through intelligent recognition systems, correct movements, and improve athletic performance. This paper proposes a method that addresses the low accuracy issue of current yoga pose recognition algorithms by integrating multi-head attention mechanism and ensemble learning. Firstly, the Mixup algorithm is used to enhance yoga movement images. Subsequently, convolutional features are extracted from the images using the ResNet101 and VGGNet19 transfer learning models. Finally, the extracted convolutional features are combined and stacked using a multi-head attention mechanism. Model training, validation, and testing are performed using the Soft target cross-entropy loss function. Experimental results demonstrate that the proposed method achieves a training accuracy of 100%, a validation accuracy of 89.94%, a testing accuracy of 93.79%, and a detection speed of 297 frames per second. Overall, this method demonstrates high stability and robustness, providing a technological foundation for intelligent recognition of yoga poses.},
  archive      = {J_IJCIS},
  author       = {Kou, Yue and Li, Hai},
  doi          = {10.1007/s44196-024-00662-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Image-based fitness yoga pose recognition: Using ensemble learning and multi-head attention},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An energy-efficient bio-inspired mobility-aware cluster
p-WOA algorithm for intelligent whale optimization and fuzzy-logic-based
zonal clustering algorithm in FANET. <em>IJCIS</em>, <em>17</em>(1),
1–15. (<a href="https://doi.org/10.1007/s44196-024-00651-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The newest research topic is flight ad hoc network (FANET). The primary obstacles faced by unmanned aerial vehicles (UAVs) are their limited flight duration and inefficient routes resulting from their great mobility and low battery power. Compared to MANETs or VANETs, FANETS routing is thought to be more difficult because of these topological restrictions. Artificial intelligence (AI)-based clustering techniques can be applied to resolve intricate routing issues in situations when both static and dynamic routing are ineffective. To overcome these path difficulties, clustering techniques based on evolutionary algorithms, including intelligent, probabilistic, bio-inspired whale optimization algorithms (p-WOAs), we suggest fuzzy-logic-based zonal clustering-based routing algorithms in this study to be used in FANET to build clusters. In addition to requiring fewer cluster heads (CHs) for routing, p-WOA offers good coverage and low energy consumption. The stochastic whale optimization technique, which draws inspiration from nature, is utilized in this paper to build networks and deploy nodes. The next step is to choose cluster heads using a region clustering technique based on fuzzy logic. By selecting the right cluster head, you can decrease routing traffic and increase cluster longevity. Routing overhead is also decreased. The data are then sent to the best path using a reference point group mobility model. The proposed p-WOA was used to test fuzzy integral and fuzzy logic ant optimization, fuzzy integral and neural network interference system, fuzzy integral and whale optimization algorithm (ANFIS-WOA), and fuzzy integral and FL-ALO. An array of indicators, such as cluster count, longevity, cluster configuration time, cluster head consistency, and energy usage, are employed to assess the effectiveness of the suggested methodology. The suggested algorithm works better than the most advanced techniques available today, as demonstrated by the experimental findings presented in this paper.},
  archive      = {J_IJCIS},
  author       = {Karpagalakshmi, R. C. and Rani, D. Leela and Magendiran, N. and Manikandan, A.},
  doi          = {10.1007/s44196-024-00651-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An energy-efficient bio-inspired mobility-aware cluster p-WOA algorithm for intelligent whale optimization and fuzzy-logic-based zonal clustering algorithm in FANET},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AI-FEED: Prototyping an AI-powered platform for the food
charity ecosystem. <em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00656-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the development and functionalities of the AI-FEED web-based platform (ai-feed.ai), designed to address food and nutrition insecurity challenges within the food charity ecosystem. AI-FEED leverages advancements in artificial intelligence (AI) and blockchain technology to facilitate improved access to nutritious food and efficient resource allocation, aiming to reduce food waste and bolster community health. The initial phase involved comprehensive interviews with various stakeholders to gather insights into the ecosystem’s unique challenges and requirements. This informed the design of four distinct modules in the AI-FEED platform, each targeting the needs of one of four stakeholder groups (food charities, donors, clients, and community leaders). Prototyping and iterative feedback processes were integral to refining these modules. The food charity module assists charities in generating educational content and predicting client needs through AI-driven tools. Based on blockchain technology, the food donor module streamlines donation processes, enhances donor engagement, and provides donor recognition. The client module provides real-time information on food charity services and offers a centralized repository for nutritional information. The platform includes a comprehensive mapping and proposal system for community leaders to strategically address local food insecurity issues. AI-FEED’s integrated platform approach allows data sharing across modules, enhancing overall functionality and impact. The paper also discusses ethical considerations, potential biases in AI systems, and the transformation of AI-FEED from a research project to a sustainable entity. The AI-FEED platform exemplifies the potential of interdisciplinary collaboration and technological innovation in addressing societal challenges, particularly in improving food security and community health.},
  archive      = {J_IJCIS},
  author       = {Sammer, Marcus and Seong, Kijin and Olvera, Norma and Gronseth, Susie L. and Anderson-Fletcher, Elizabeth and Jiao, Junfeng and Reese, Alison and Kakadiaris, Ioannis A.},
  doi          = {10.1007/s44196-024-00656-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {AI-FEED: Prototyping an AI-powered platform for the food charity ecosystem},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on parallel task scheduling algorithm of SaaS
platform based on dynamic adaptive particle swarm optimization in cloud
service environment. <em>IJCIS</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00666-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To efficiently realize the parallel task scheduling of SaaS platform in large-scale cloud service environment, this paper studies the parallel task scheduling algorithm of SaaS platform based on dynamic adaptive particle swarm optimization in cloud service environment. Users access the cloud through the user access interface module, and issue task scheduling instructions or send task scheduling requests. After the service management module provides diversified application service support according to the scheduling requirements, the core service module determines the SaaS platform parallel scheduling objective function, and uses dynamic adaptive particle swarm optimization to solve the objective function to obtain the SaaS platform parallel task scheduling results. The test results show that the algorithm has better multi-objective solving ability and can obtain higher quality objective solutions, and the test results of the total execution time of parallel scheduling tasks and the total transmission time of task data on SaaS platform are all within 30 s. The results of virtual machine resource load balancing degree are all below 15%; the utilization rate of virtual machine resources is above 92.2%.},
  archive      = {J_IJCIS},
  author       = {Zhu, Jian and Li, Qian and Ying, Shi and Zheng, Zhihua},
  doi          = {10.1007/s44196-024-00666-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Research on parallel task scheduling algorithm of SaaS platform based on dynamic adaptive particle swarm optimization in cloud service environment},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Predictive modelling for sensitive social media contents
using entropy-FlowSort and artificial neural networks initialized by
large language models. <em>IJCIS</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00668-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work offers an integrated methodological framework that integrates the capabilities of large language models (LLMs), rules-based reasoning, multi-criteria sorting, and artificial neural networks (ANN) in developing a predictive model for classifying the intensity of sensitive social media contents. The current literature lacks a holistic consideration of multiple attributes in evaluating social media contents, and the proposed framework intends to bridge such a gap. Three actions constitute the development of the framework. First, LLMs (i.e., GPT4) evaluate the social media contents under a predefined set of attributes, leveraging the power of LLMs in content analytics. Second, rules-based reasoning and multi-criteria sorting (i.e., entropy-FlowSort) determine the categories of social media contents. Lastly, the two previous actions produced a complete dataset that can be used to train a predictive model using ANN to classify sensitive social media contents. With 1100 randomly extracted social media contents and the predefined categories of violations against community standards set by Facebook, the proposed integrated methodology produces an ANN-based classification model with 86.36% prediction accuracy. Comparative analysis using Decision Trees, k-nearest neighbors, Linear Discriminant Analysis, Random Forest, and Naive Bayes classification yields the highest performance of ANN. The predictive model can be used as a decision-support tool to design moderation actions on social media contents.},
  archive      = {J_IJCIS},
  author       = {Galamiton, Narcisan and Bacus, Suzette and Fuentes, Noreen and Ugang, Janeth and Villarosa, Rica and Wenceslao, Charldy and Ocampo, Lanndon},
  doi          = {10.1007/s44196-024-00668-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Predictive modelling for sensitive social media contents using entropy-FlowSort and artificial neural networks initialized by large language models},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved YOLOv9 and its applications for detecting
flexible circuit boards connectors. <em>IJCIS</em>, <em>17</em>(1),
1–12. (<a href="https://doi.org/10.1007/s44196-024-00669-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible circuit boards are a cornerstone of the modern electronics industry. In automatic defect detection, FPC connectors present challenges such as minimal differences between oxidation defects and the background, easy degradation of Intersection over Union (IoU) scores, and significant variations in the shapes of black defect boundaries. Consequently, existing algorithms perform poorly in this task. We improve model YOLOv9 by introducing Multi-scale Dilated Attention (MSDA) on the output side to enhance the ability to capture features, and Deformable Large Kernel Attention (DLKA) on the other side of the output header to improve the ability to adapt to complex defect boundaries. Our use of IoU loss completely eliminates the risk of IoU degradation or gradient vanishing. Furthermore, we reduce computational overhead with the implementation of Faster Block. Following these improvements, the mean Average Precision (mAP) at 75% IoU (mAP75) for oxidized defects increased by 7.5% relative to the base model. Similarly, the mAP at 50% IoU (mAP50) for black defects increased by 5.7%, validating the relevance and efficacy of our proposed improvements. Overall, the average mAP50, mAP75, and mAP50:95 for all defects improved by 3.8%, 2.0%, and 2.3%, respectively. The performance gain achieved by our enhanced model significantly exceeds the improvement of YOLOv9 relative to YOLOv8.},
  archive      = {J_IJCIS},
  author       = {Huang, Gengjie and Huang, Yinbing and Li, Haoyang and Guan, Ziwen and Li, Xuecong and Zhang, Guidong and Li, Wendong and Zheng, Xiran},
  doi          = {10.1007/s44196-024-00669-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An improved YOLOv9 and its applications for detecting flexible circuit boards connectors},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Research on safety separation distance in paired approach
based on monte carlo simulation. <em>IJCIS</em>, <em>17</em>(1), 1–14.
(<a href="https://doi.org/10.1007/s44196-024-00673-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with the increasing number of flights, efficient and orderly operations have become a critical issue for busy airports. The closely spaced parallel runway paired approach technology has been proven to be an effective solution for increasing runway capacity and operational efficiency. This research focuses on determining the safety separation between paired aircraft, particularly the collision safety limit. This study refines the kinematic modeling process by constructing a three-dimensional kinematic model and advancing the starting point of paired approach, making the simulation process more aligned with reality. Subsequently, the Monte Carlo simulation method is applied, integrating the kinematic model and considering collision risks to simulate the entire paired approach process. Multiple scenarios are created, and simulation experiments are conducted to determine the safety separation between the two paired aircraft. Finally, by adjusting parameter settings and taking the example of the two closely spaced parallel runways at Chongqing Jiangbei International Airport, the correlation between various influencing factors and the safety separation is analyzed. Different scenarios are simulated 100,000 times each, and the results show that the speed difference between the two paired aircraft has the most significant impact on the safety separation, followed by the paired approach mode and runway centerline spacing. The wake turbulence category matching has a minimal effect on the safety separation. The results provide a theoretical basis for airports with closely spaced parallel runways to further reduce the separation between paired aircraft, thereby enhancing airport capacity and runway operational efficiency.},
  archive      = {J_IJCIS},
  author       = {Chen, Yaqing and Yang, Hong and He, Xin and Gao, Haoran and Zhao, Rui and Sun, Wenxia},
  doi          = {10.1007/s44196-024-00673-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Research on safety separation distance in paired approach based on monte carlo simulation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TransImg: A translation algorithm of visible-to-infrared
image based on generative adversarial network. <em>IJCIS</em>,
<em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00674-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared images of sensitive targets are difficult to obtain and cannot meet the design and training needs of target detection and tracking algorithms for mobile platforms such as aircraft. This paper proposes an image translation algorithm TransImg, which can achieve visible light image translation to the infrared domain to enrich the dataset. First, the algorithm designed a generator structure consisting of a deep residual connected encoder and a region perception feature fusion module to enhance feature learning, thereby avoiding issues such as generating infrared images with insufficient details in the transfer task. Afterward, a multi-scale discriminator and a composite loss function were designed to further improve the transfer effect. Finally, an automatic mixed-precision training strategy was designed for the overall migration algorithm architecture to accelerate the training and generation of infrared images. Experiments have shown that the image translation algorithm TransImg has good algorithm accuracy, and the infrared image generated by visible light image translation has richer texture details, faster generation speed, and lower video memory consumption, and the performance exceeds the mainstream traditional algorithm, and the generated images can meet the requirements of target detection and tracking algorithms design and training for mobile platforms such as aircraft.},
  archive      = {J_IJCIS},
  author       = {Han, Shuo and Mo, Bo and Xu, Junwei and Sun, Shizun and Zhao, Jie},
  doi          = {10.1007/s44196-024-00674-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {TransImg: A translation algorithm of visible-to-infrared image based on generative adversarial network},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: A novel method for identifying landslide
surface deformation via the integrated YOLOX and mask r-CNN model.
<em>IJCIS</em>, <em>17</em>(1), 1. (<a
href="https://doi.org/10.1007/s44196-024-00682-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Wan, Chenghui and Gan, Jianjun and Chen, Anbang and Acharya, Prabin and Li, Fenghui and Yu, Wenjie and Liu, Fangzhou},
  doi          = {10.1007/s44196-024-00682-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: A novel method for identifying landslide surface deformation via the integrated YOLOX and mask R-CNN model},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fuzzy association rule mining for personalized chinese
language and literature teaching from higher education. <em>IJCIS</em>,
<em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00676-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to rapid information technology growth, teaching Chinese in higher education has changed, and Chinese literary majors have vigorously evolved. The key teaching difficulties are scalability, individualized teaching, and a lack of resources and methodologies. Research shows individualized education improves topic comprehension, cultural engagement, and learner interest. Fuzzy association rule mining uses fuzzy linguistic values and membership functions to provide more realistic results. Hence, an algorithm, EF-PCL2T, has been proposed to improve personalized Chinese language and literature teaching (PCL2T) using enhanced fuzzy (EF) Apriori association rule mining integrated with the genetic algorithm. Fuzzy Apriori association rule mining identified frequent itemsets with relevant learning patterns and produced applicable association rules from datasets with fuzzy or unclear information, capturing fluctuating itemset importance and providing a flexible representation of relationships to determine student preferences. From fuzzy-related data, a genetic algorithm optimizes skill sets and creates individualized lesson plans considering each student’s competency and preferences for adjusting to personalized teaching tactics. Testing shows that fuzzy enhancement association rule mining for the PCL2T model improves student retention, PET (personalized teaching efficiency), minimal support and confidence update with fuzzy rules, and student involvement compared to other state-of-the-art methods. Students agree that tailored Chinese language and literary instruction is possible. The improvement results show fuzzy rules with minimum confidence levels of 50% to 100%, highly correlated in this model, student retention ratio of 96%, improved assessment grade of various language skills by 40 marks, PTE analysis of 93%, and student involvement ratio of 97%.},
  archive      = {J_IJCIS},
  author       = {Teng, Fei},
  doi          = {10.1007/s44196-024-00676-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fuzzy association rule mining for personalized chinese language and literature teaching from higher education},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning enhanced MLP–LSTM modeling in an
integrated deep learning pipeline for stock market prediction.
<em>IJCIS</em>, <em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00680-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the research presents the Federated Learning Enhanced Multi-Layer Perceptron (Fed-MLP) Long Short-Term Memory that is suggested by the research. The research intends to use the LSTM networks extensively that are proficient in spatial dependence capturing and integrate them with the collaborative learning framework of Federated Learning in an endeavor to augment the predictive competency. In the first step, we gather stock market indices from various financial organizations, using CAC40 stocks as the index for the French stock market. To guarantee data consistency and quality, pre-processing methods including linear interpolation and Z-score normalization are used. There are two types of models for each of the three basic elements within the Fed-MLP–LSTM, namely, MLP for feature extraction and LSTM for sequence modeling. Institutionally, each refining institution trains a local MLP–LSTM on the corpus specific to their institution, with only the model parameters being transferred to a central server through Federated Learning. A global model is created and updated through repeated training and totaling of parameters while preserving privacy of the data going to each node. In the performance evaluation, quantitative measures like Root-Mean-Square Error (RMSE), and accuracy are seven used. Hypothesis testing shows that we have good evidence to support that the proposed Fed-MLP–LSTM outperforms the other methods with the lowest RMSE of 0. 0108 and 98.3% of accuracy with reference to their respective cocaine molecule target. The proposed method is implemented in python. This suggests that using Federated Learning along with MLP and LSTM as the components of this vector enhanced the function increasing its capacity and reliability in predicting the trends of stocks. In conclusion, the present study suggests a sound solution for effective and secure stock market forecasting in collaboration environments that can find its use in the financial domains and securities businesses.},
  archive      = {J_IJCIS},
  author       = {Kumarappan, Jayaraman and Rajasekar, Elakkiya and Vairavasundaram, Subramaniyaswamy and Kotecha, Ketan and Kulkarni, Ambarish},
  doi          = {10.1007/s44196-024-00680-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Federated learning enhanced MLP–LSTM modeling in an integrated deep learning pipeline for stock market prediction},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning-based ECG signal classification for
enhanced early detection of doxorubicin-induced cardiotoxicity in rats.
<em>IJCIS</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00621-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiotoxicity, which leads to irreversible myocardial damage, is a major adverse effect associated with chemotherapy. Electrocardiogram (ECG) is an inexpensive, rapid, and simple tool that may provide valuable diagnostic information pertinent to cardiotoxicity. An automatic interpretation and classification of the ECG signals by machine learning algorithms is considered superior to human interpretation of the ECG which may not be able to early detect subtle alterations in the ECG and vary according to the experience of the specialist. The present work aimed at using different machine learning algorithms to classify ECG signals recorded from doxorubicin-injected rats. Rats were divided into four groups and each group was intraperitoneally injected with different cumulative doses of doxorubicin (0, 6, 12, and 18 mg/kg). ECG signal classification depended on multiple features that were extracted from the recorded signals under different conditions. K nearest-neighbors’ algorithm achieved higher classification accuracy (99.83%) than random forest (99.56%), decision tree (99.54%), artificial neural network (99.50%), and support vector machine (99.38%). Furthermore, the dose-dependent cardiotoxicity was validated via a histopathological examination of the left ventricle that indicated significant pathological alterations in the cardiac tissue. The present findings emphasized the potential of the machine learning-based enhanced detection of cardiotoxicity and validated the dose-dependent toxicity of doxorubicin in the cardiac left ventricle. This approach might be applicable clinically to avoid cardiotoxicity in chemotherapy-treated patients.},
  archive      = {J_IJCIS},
  author       = {Mohammed, Haitham S. and Hanafy, A. H. and Abdo, Abdelrahman and Alazoul, Abdelaziz H. and Rashid, Mohamed E. and El-Naggar, Rabab},
  doi          = {10.1007/s44196-024-00621-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Machine learning-based ECG signal classification for enhanced early detection of doxorubicin-induced cardiotoxicity in rats},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ExAq-MSPP: An energy-efficient mobile sink path planning
using extended aquila optimization algorithm. <em>IJCIS</em>,
<em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-024-00670-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks play a crucial role in gathering data from remote or hard-to-reach locations, enabling real-time monitoring and decision-making in a wide range of industries and applications. The mobile sink path planning (MSPP) enables mobile sinks (e.g., drones or rovers) to navigate through the environment, collecting data from different sensor nodes, ensuring comprehensive coverage, and adaptively addressing changing conditions. Still, the energy-efficient routing with minimal delay is the challenging aspect. This research focuses on improving data gathering in wireless sensor networks by introducing an efficient routing protocol. In this proposed protocol, sensor nodes are initially deployed using Voronoi diagrams to ensure uniform network coverage. The network is then divided into clusters using the low-energy adaptive clustering hierarchy (LEACH) algorithm for energy-efficient routing. To optimize the path planning of a mobile sink for data collection, we introduce the extended Aquila (ExAq) optimization algorithm, which uses a multi-objective fitness function considering factors such as delay, residual energy, link quality, priority, and distance. Simulation results demonstrate the effectiveness of the proposed ExAq-MSPP protocol in terms of reduced delay, improved network lifetime, higher packet delivery ratio, enhanced residual energy, and increased throughput compared to existing protocols with the values of 1.169, 99.857, 99.920, 0.997, and 255.306, respectively. Thus, the energy-efficient routing and optimizing path planning for mobile sinks, the proposed ExAq-MSPP protocol can extend network lifetime, increase data accuracy, and provide more robust performance under changing environmental conditions.},
  archive      = {J_IJCIS},
  author       = {Sangeetha, S. and Victoire, T. Aruldoss Albert and Premkumar, Manoharan and Sowmya, Ravichandran},
  doi          = {10.1007/s44196-024-00670-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {ExAq-MSPP: An energy-efficient mobile sink path planning using extended aquila optimization algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing expert decision-making for wastewater treatment
plants with seidel laplacian energy and cosine similarity measure in
intuitionistic fuzzy graphs. <em>IJCIS</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00672-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment facilities’ main goal is to protect the public and environment from the hazardous and poisonous materials found in wastewater. Water treatment facilities were developed to speed up the natural process of cleansing water. A novel cosine similarity measure across intuitionistic fuzzy graphs has been proven to be more effective than certain present ones in group decision-making issues using example verification. This paper provides a unique approach for calculating expert-certified, well-known scores by finding the ambiguous information of intuitionistic fuzzy preference relations as well as the regular cosine similarity grades from one separable intuitionistic fuzzy preference relation to another. The new technique considers both &quot;objective&quot; and &quot;subjective&quot; information provided by experts. Using intuitionistic fuzzy preference relations, we provide workable techniques for judging experts’ eligible reputational ratings. This can be used to raise or decrease the relevance of the stated criteria in an evaluation that takes into account several competing elements. We give a solution to a decisional problem by using two effective methods: the newly constructed cosine similarity measure and the Seidel Laplacian energy (SLe+) of an intuitionistic fuzzy graph. Finally, two working procedures and circumstances are offered to show the effectiveness and superiority of the proposed techniques.},
  archive      = {J_IJCIS},
  author       = {Atheeque, A. Mohamed and Basha, S. Sharief},
  doi          = {10.1007/s44196-024-00672-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing expert decision-making for wastewater treatment plants with seidel laplacian energy and cosine similarity measure in intuitionistic fuzzy graphs},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application and empirical analysis of fuzzy neural networks
in mining social media users’ behavioral characteristics and formulating
accurate online marketing strategies. <em>IJCIS</em>, <em>17</em>(1),
1–15. (<a href="https://doi.org/10.1007/s44196-024-00675-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current digital social environment, social media platforms have become an important position for user behavior insights and precision marketing. User behavioral data on social media contain rich information, but they are often fuzzy, uncertain and highly complex. Fuzzy neural network (FNN), as an advanced model combining fuzzy logic and neural network theory, provides a powerful tool for processing and analyzing social media user behavioral features. This study is dedicated to exploring the application of fuzzy neural networks in social media user behavior analysis and their key role in the design of accurate online marketing strategies. We construct and optimize a fuzzy neural network model by meticulously classifying and quantifying user behavioral features, including behavioral frequency features, content topic features, social interaction features, and time series features, as well as applying fuzzy set theory to deal with fuzzy features such as emotional states. Through empirical analysis, we will show how fuzzy neural networks can reveal the intrinsic laws behind user behaviors, and how these insights can be used to design and implement precise online marketing strategies to improve advertising effectiveness, user engagement, and brand loyalty.},
  archive      = {J_IJCIS},
  author       = {Luo, Beibei and Luo, Rongfei},
  doi          = {10.1007/s44196-024-00675-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Application and empirical analysis of fuzzy neural networks in mining social media users’ behavioral characteristics and formulating accurate online marketing strategies},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pricing and financing strategies in a dual-channel
low-carbon supply chain for bilateral capital-constrained retailers.
<em>IJCIS</em>, <em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00677-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of low-carbon economy, financial constraints are prevalent among both upstream and downstream enterprises, exacerbated by the trend of online retailers extending into offline physical stores. This study first proposes and evaluates three financing combination models: “bank lending + advance payment,” (in short, AF), “bank lending + delayed payment,” (in short, DF), and “bilateral bank lending.” (in short, TF). It then examines the retailer’s dual-channel supply chain pricing and financing decision-making models under unified pricing strategy and independent self-pricing strategy respectively. The evaluation results indicate that among various financing models, the independent self-pricing strategy has the potential to enhance the retailer&#39;s profitability, outperforming the unified pricing strategy. In addition, when channel preference is significant, the retailer should prioritize the independent self-pricing strategy. A comparison of the optimal decisions across the three financing combination models indicates that both the cost coefficient of carbon emission reduction and the loan interest rate exert a limiting influence on the decision-making and income of all supply chain parties. Furthermore, the DF model emerges as a financing equilibrium strategy within the supply chain, with a shift to the AF model being considered only when the manufacturer’s loan interest rate is relatively high.},
  archive      = {J_IJCIS},
  author       = {Du, Limin and Zhang, Yuhao and Lu, Keping},
  doi          = {10.1007/s44196-024-00677-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Pricing and financing strategies in a dual-channel low-carbon supply chain for bilateral capital-constrained retailers},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Random oversampling-based diabetes classification via
machine learning algorithms. <em>IJCIS</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00678-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes mellitus is considered one of the main causes of death worldwide. If diabetes fails to be treated and diagnosed earlier, it can cause several other health problems, such as kidney disease, nerve disease, vision problems, and brain issues. Early detection of diabetes reduces healthcare costs and minimizes the chance of serious complications. In this work, we propose an e-diagnostic model for diabetes classification via a machine learning algorithm that can be executed on the Internet of Medical Things (IoMT). The study uses and analyses two benchmarking datasets, the PIMA Indian Diabetes Dataset (PIDD) and the Behavioral Risk Factor Surveillance System (BRFSS) diabetes dataset, to classify diabetes. The proposed model consists of the random oversampling method to balance the range of classes, the interquartile range technique-based outlier detection to eliminate outlier data, and the Boruta algorithm for selecting the optimal features from the datasets. The proposed approach considers ML algorithms such as random forest, gradient boosting models, light gradient boosting classifiers, and decision trees, as they are widely used classification algorithms for diabetes prediction. We evaluated all four ML algorithms via performance indicators such as accuracy, F1 score, recall, precision, and AUC-ROC. Comparative analysis of this model suggests that the random forest algorithm outperforms all the remaining classifiers, with the greatest accuracy of 92% on the BRFSS diabetes dataset and 94% accuracy on the PIDD dataset, which is greater than the 3% accuracy reported in existing research. This research is helpful for assisting diabetologists in developing accurate treatment regimens for patients who are diabetic.},
  archive      = {J_IJCIS},
  author       = {Ashisha, G. R. and Mary, X. Anitha and Kanaga, E. Grace Mary and Andrew, J. and Eunice, R. Jennifer},
  doi          = {10.1007/s44196-024-00678-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Random oversampling-based diabetes classification via machine learning algorithms},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk evaluation for human factors of flight dispatcher based
on the hesitant fuzzy TOPSIS-DEMATEL-ISM approach: A case study in
sichuan airlines. <em>IJCIS</em>, <em>17</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-024-00683-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively mitigate unsafe events and accident symptoms stemming from flight dispatchers’ human factors, this paper proposes a novel risk evaluation model to accurately identify and evaluate potential human risks associated with flight dispatchers. First, the HFACS (Human Factors Analysis and Classification System, HFACS) model is employed to construct a human risk assessment indicator system for flight dispatchers. Second, the hesitant fuzzy set is introduced to represent the uncertainty during experts’ evaluation, and the improved TOPSIS (Technique for Order Preference by Similarity to Ideal Solution, TOPSIS) method is applied within a hesitant fuzzy environment to obtain rankings of human factors. Third, the hesitant fuzzy DEMATEL (Decision-Making Trial and Evaluation Laboratory, DEMATEL)-ISM (Interpretive Structural Modeling, ISM) approach is constructed to analyze the correlation among human factors, leading to the establishment of a multi-level hierarchical structure model. Finally, a case study of risk assessment for human factors of flight dispatchers in Sichuan Airlines is conducted to demonstrate the effectiveness of the proposed method. The results revealed the flight dispatchers’ human factors associated with higher risks and identified the key factors with a larger impact on other factors in Sichuan Airlines. Subsequently, a multi-level hierarchical structure model comprising five layers is developed to investigate the internal correlations among human factors, facilitating the formulation of targeted improvement suggestions for the higher risk indicators and key influencing factors.},
  archive      = {J_IJCIS},
  author       = {Zeng, Jing-Han and Huang, Jing-Yang and Zhong, Qing-Wei and Zhu, Dai-Wu and Dai, Yi},
  doi          = {10.1007/s44196-024-00683-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Risk evaluation for human factors of flight dispatcher based on the hesitant fuzzy TOPSIS-DEMATEL-ISM approach: A case study in sichuan airlines},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Artificial intelligence in aviation safety: Systematic
review and biometric analysis. <em>IJCIS</em>, <em>17</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s44196-024-00671-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to offer aviation safety researchers, practitioners, and decision-makers a comprehensive exploration of integrating advanced technologies, such as artificial intelligence and machine learning, to inform and fortify future safety strategies. Focusing on systematic and bibliometric perspectives, the paper reviewed 224 articles in the Scopus database from 2004 to 2024 (January). Key findings highlight China’s notable contributions to aviation safety research, underscoring its leadership in international collaboration. The techniques employed encompass machine learning, time series models, deep learning, AI, neurophysiological modeling, and optimization algorithms. The analysis discerns prominent research trends, including aviation accident analysis, pilot behavior, aviation safety measures, and endeavors to enhance safety standards. The aviation industry’s steadfast commitment to safety, efficiency, and technological innovation is evident. By uncovering the main structures, foci, and trends in aviation safety research, this study equips researchers and practitioners with crucial insights into ongoing endeavors and potential future developments, fostering a more profound understanding of aviation safety.},
  archive      = {J_IJCIS},
  author       = {Demir, Gülay and Moslem, Sarbast and Duleba, Szabolcs},
  doi          = {10.1007/s44196-024-00671-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Artificial intelligence in aviation safety: Systematic review and biometric analysis},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computational and human intelligence methods for
constructing practical risk prediction models: An application to
cardio-renal outcomes in non-diabetic CKD patients. <em>IJCIS</em>,
<em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00685-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current investigation aimed to develop a novel approach for risk prediction modeling of clinical outcomes in common diseases based on computational and human intelligence techniques with no a priori input on risk factors using real-world individual patient-level data from administrative claims. Bootstrapping multivariable Cox regression and ant colony optimization were employed to develop time-to-first-event risk prediction models of cardio-renal outcomes in patients with non-diabetic chronic kidney disease (CKD) as a demonstration case. A cohort of 504,924 non-diabetic CKD stage 3 or 4 patients enrolled from 2008 to 2018 were identified in the US administrative de-identified claims database, Optum Clinformatics® Data Mart. Initial set of potential risk factors was derived from patient-level data at baseline and included more than 540,000 variables. Risk prediction models of hospitalization for heart failure, worsening of CKD stage from baseline and a renal composite outcome of end-stage kidney disease, kidney failure or need for dialysis in non-diabetic CKD stage 3 or 4 were built. Final model optimization was conducted using human intelligence to combine clinically similar features and build equivalence classes to ensure that risk factors included in the final model were routinely collected and easily interpretable by healthcare providers. Demonstrated validity of our approach in non-diabetic CKD offers opportunities for application in other therapeutic areas, with the potential to improve overall prognosis and decrease the clinical and economic burden of common diseases. The approach enables developing practical prediction models for risk estimation in routine clinical practice.},
  archive      = {J_IJCIS},
  author       = {Bauer, Chris and Schuchhardt, Johannes and Vaitsiakhovich, Tatsiana and Kleinjung, Frank},
  doi          = {10.1007/s44196-024-00685-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Computational and human intelligence methods for constructing practical risk prediction models: An application to cardio-renal outcomes in non-diabetic CKD patients},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel product ranking approach considering sentiment
intensity distribution of online reviews. <em>IJCIS</em>,
<em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-024-00688-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews of products have a significant impact on consumers&#39; purchasing decisions, making it important for both platform retailers and consumers to rank products, and eventually purchase products. With respect to the problem of product ranking that consists of the information contained in online reviews; by considering the sentiment intensity distribution of online reviews, we establish a fine-grained sentiment intensity analysis and then exploit grey incidence analysis and TOPSIS to establish a multi-attribute approach for product ranking. Finally, a case study of laptop purchases verifies the applicability and effectiveness of the proposed approach.},
  archive      = {J_IJCIS},
  author       = {Gu, Sheng-qiang and Liu, Shi-tong and Liu, Yong and Ding, Jia-ming},
  doi          = {10.1007/s44196-024-00688-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel product ranking approach considering sentiment intensity distribution of online reviews},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel CNN-BiLSTM-GRU hybrid deep learning model for human
activity recognition. <em>IJCIS</em>, <em>17</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s44196-024-00689-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) is critical in a variety of disciplines, including healthcare and robotics. This paper presents a new Convolutional Neural Network with Bidirectional Long Short-Term Memory and along with Gated Recurrent Unit (CNN-BiLSTM-GRU)hybrid deep learning model designed for Human Activity Recognition (HAR) that makes use of data from wearable sensors and mobile devices. Surprisingly, the model achieves an amazing accuracy rate of 99.7% on the difficult Wireless Sensor Data Mining (WISDM) dataset, demonstrating its ability to properly identify human behaviors. This study emphasizes parameter optimization, with a focus on batch size 0.3 as a significant component in improving the model’s robustness. Furthermore, the findings of this study have far-reaching implications for bipedal robotics, where precise HAR (Human Activity Recognition) is critical to improving human–robot interaction quality and overall work efficiency. These discoveries not only strengthen Human Activity Recognition (HAR) techniques, but also provide practical benefits in real-world applications, particularly in the robotics and healthcare areas. This study thus makes a significant contribution to the continuous development of Human Activity Recognition methods and their actual applications, emphasizing their important role in stimulating innovation and efficiency across a wide range of industries.},
  archive      = {J_IJCIS},
  author       = {Lalwani, Pooja and Ganeshan, R.},
  doi          = {10.1007/s44196-024-00689-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel CNN-BiLSTM-GRU hybrid deep learning model for human activity recognition},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved bald eagle search optimization algorithm for
feature selection in classification. <em>IJCIS</em>, <em>17</em>(1),
1–28. (<a href="https://doi.org/10.1007/s44196-024-00691-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection serves as an effective way for decreasing the quantity of features within a dataset, which helps enhance the performance of classification in machine learning (ML). In this paper, we formulate a joint feature selection problem to reduce the number of selected features while improving the classification accuracy. We propose an improved bald eagle search (IBES) algorithm to solve the optimization problem. Specifically, the BES algorithm is enhanced by introducing the lévy flight mechanism in the selection phase to improve the global search capability of the algorithm. In addition, we adopt an adaptive weighting factor to balance the global and local search capabilities. Finally, a novel mutation mechanism incorporating Gaussian and differential mutation is proposed, which contributes to maintain the diversity of the population. Comparative experiments are conducted with six benchmark algorithms on eighteen typical datasets. The results analysis indicates that the proposed IBES algorithm can achieve higher classification accuracy with a small number of features.},
  archive      = {J_IJCIS},
  author       = {Feng, Jinghui and Zhang, Xukun and Zhang, Lihua},
  doi          = {10.1007/s44196-024-00691-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Improved bald eagle search optimization algorithm for feature selection in classification},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient prediction of judicial case decisions based on
state space modeling. <em>IJCIS</em>, <em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00695-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of information technology and artificial intelligence, the digitization of legal texts has caused a swift increase in the volume of legal materials. Judges now face increased professional demands, larger information loads, and more complex case structures, which heightens their workload and demands. To enhance the quality and efficiency of judicial work and drive the modernization of the judicial system, the application of intelligent prediction models has become essential. This paper presents the MambaEffNet model, which integrates multiple modules such as Convolutional Neural Networks (CNN) and Multilayer Perceptrons (MLP). The core convolutional structure is improved using a state space model, and a multi-directional feature fusion structure is designed to enhance the performance of sequence feature extraction. Generative Adversarial Networks (GAN) are employed for data augmentation, to address the issue of missing features in judicial case predictions. The EfficientNetV2 architecture is used to optimize the kernel size and the expansion ratio of input and output channels. Experimental results demonstrate that the MambaEffNet model achieves a prediction accuracy of 92.05% on the Nigerian Supreme Court judgment dataset and performs excellently on other judicial datasets, significantly improving prediction accuracy and efficiency. Specifically, the MambaEffNet model increases the prediction accuracy for criminal and civil case judgments by 9.53% and 11.57%, respectively. Additionally, the model excels in handling long sequence data, effectively capturing key features and providing comprehensive decision support.},
  archive      = {J_IJCIS},
  author       = {Liu, Yuntao},
  doi          = {10.1007/s44196-024-00695-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Efficient prediction of judicial case decisions based on state space modeling},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Channel2DTransformer: A multi-level features self-attention
fusion module for semantic segmentation. <em>IJCIS</em>, <em>17</em>(1),
1–11. (<a href="https://doi.org/10.1007/s44196-024-00630-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a crucial technology for intelligent vehicles, enabling scene understanding in complex driving environments. However, complex real-world scenarios often contain diverse multi-scale objects, which bring challenges to the accurate semantic segmentation. To address this challenge, we propose a multi-level features self-attention fusion module called Channel2DTransformer. The module utilizes self-attention mechanisms to dynamically fuse multi-level features by computing self-attention weights between their channels, resulting in a consistent and comprehensive representation of scene features. We perform the module on the Cityscapes and NYUDepthV2 datasets, which contain a large number of multi-scale objects. The experimental results validate the positive contributions of the module in enhancing the semantic segmentation accuracy of multi-scale objects and improving the performance of semantic segmentation in complex scenes.},
  archive      = {J_IJCIS},
  author       = {Liu, Weitao and Wu, Junjun},
  doi          = {10.1007/s44196-024-00630-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Channel2DTransformer: A multi-level features self-attention fusion module for semantic segmentation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Progressive conditional generative adversarial network
optimized with archimedes optimization algorithm fostered inheritance
and innovation of huizhou carving culture. <em>IJCIS</em>,
<em>17</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-024-00681-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past dynasties literature has very few records as the literature of the earlier ones is a novelty and the hereditary secret historical and cultural assets are now at risk. In this study, the inheritance and innovation of the Huizhou carving culture using a progressive conditional generative adversarial network enhanced using the Archimedes Optimization algorithm (HCC-PCGAN-AO) is proposed. Initially, the data are gathered using the onsite Huizhou culture website with three-dimensional data scanning technique. The progressive conditional generative adversarial network (PCGAN) is used to design the Huizhou carving. Then, the Archimedes Optimization algorithm (AOA) is proposed to optimize the Progressive PCGAN classifier, which precisely eliminates errors in the design. It demonstrates the 3D digital carving into architectural cultural property is required and achieves a essential role in preserving the advancing architectural cultural heritage. The proposed HCC-PCGAN-AO method attains 22.13%, 19.46% and 30.65% lower RMSE compared with the existing methods such as Inheritance and Protection of Temple Architectural Cultural Heritage utilizing in the Case of Three-Mountain Kings Ancestral Temple of Jiexi Lintian with Digital Media Technology (IPTA-CH-DMT), Research on Innovative design of tourism cultural and creative products from the perception of Huizhou intangible cultural heritage culture (RID-TCC-HICHC) and Research on the Inheritance along Development of Huizhou Culture in the Construction of New Countryside in Anhui Province (RID-HCC-NCAP) respectively.},
  archive      = {J_IJCIS},
  author       = {Geng, Dianmei},
  doi          = {10.1007/s44196-024-00681-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Progressive conditional generative adversarial network optimized with archimedes optimization algorithm fostered inheritance and innovation of huizhou carving culture},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A metaheuristic approach for a two-dimensional fuzzy version
of the variable size and cost bin packing problem. <em>IJCIS</em>,
<em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00693-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Variable Size and Cost Bin Packing Problem (VSCBPP) focuses on minimizing the overall cost of containers used to pack a specified set of items. This problem has significant applications across various fields, including energy, cargo transport, and informatics, among others. Most research conducted on this problem has concentrated on enhancing solution methodologies. Recently, some studies have investigated the use of fuzzy approaches to VSCBPP, which allow for the relaxation of certain constraints. In this paper, we introduce a metaheuristic method for solving the fuzzy version of VSCBPP, facilitating the simultaneous relaxation of two constraints: the overloading of containers and the exclusion of specific items from the packing process. Consequently, this two-dimensional fuzzy relaxation of the VSCBPP enables us to derive a range of solutions that present varying trade-offs between cost and the satisfaction levels of the original constraints. We employ mechanisms from the multi-objective metaheuristic approach to maximize the degrees of relaxation while minimizing the original cost function. To demonstrate the efficacy of our proposed solution, we utilized two well-known multi-objective evolutionary P-metaheuristics (Multi-Objective Genetic Algorithm and NSGA-II) and two S-metaheuristics (Multi-Objective Local Search and Ulungu Multi-Objective Simulated Annealing) specifically tailored for the fuzzy version of the VSCBPP. Computational experiments were conducted on 39 instances to validate the effectiveness of this approach.},
  archive      = {J_IJCIS},
  author       = {Franklin, Jorge Herrera and Rosete, Alejandro and Sosa-Gómez, Guillermo and Rojas, Omar},
  doi          = {10.1007/s44196-024-00693-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A metaheuristic approach for a two-dimensional fuzzy version of the variable size and cost bin packing problem},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing fair tourism opportunities in emerging
destinations by means of multi-criteria recommender systems: The case of
restaurants in riohacha, colombia. <em>IJCIS</em>, <em>17</em>(1), 1–25.
(<a href="https://doi.org/10.1007/s44196-024-00700-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the problem of recommending restaurants in emerging tourist destinations, taking into account factors vital in these locations, such as location, safety, price and services. The novel recommendation model is based on the well-known logical scoring of preferences (LSP) methodology. The system considers individual preferences across a hierarchy of criteria. The user can customize the recommender by providing suitability scores and aggregation operators for each criterion. The first contribution is the identification of relevant criteria for the selection of restaurants in emerging destinations and the definition of a new scoring system to manage user preferences regarding types of food. The second contribution of this study is the selection of appropriate conjunctive/disjunctive aggregation operators. The recommender system has been tested in a use case in Riohacha (Colombia), obtaining promising results in a wide range of user profiles.},
  archive      = {J_IJCIS},
  author       = {Solano-Barliza, Andres and Valls, Aida and Acosta-Coll, Melisa and Moreno, Antonio and Escorcia-Gutierrez, José and De-La-Hoz-Franco, Emiro and Arregoces-Julio, Isabel},
  doi          = {10.1007/s44196-024-00700-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing fair tourism opportunities in emerging destinations by means of multi-criteria recommender systems: The case of restaurants in riohacha, colombia},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Federated learning-assisted coati deep learning-based model
for intrusion detection in MANET. <em>IJCIS</em>, <em>17</em>(1), 1–15.
(<a href="https://doi.org/10.1007/s44196-024-00590-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MANET is a set of self-arranged, wirelessly connected nodes. Each mobile ad hoc network node acts as a router to send the packet from the source node to the destination node. MANET nodes’ random movements and decentralized architecture pose security challenges, making them vulnerable to various attacks like node selfishness, network partition, black hole, and DoS due to limited hardware resources. In this paper, a novel Hybrid Intrusion DEtection for MANet (HIDE-MAN) technique has been proposed to detect intrusion like DDoS and MitM attacks in MANET. The proposed HIDE-MAN framework initiates by preprocessing malicious data packets through data cleaning and data transformation resulting in the creation of high-dimensional vectors. The intrusion detection system then makes use of the CO-BiLSTM model, which is based on the actions of Coati and BiLSTM. It categorizes outputs into DDoS attacks, MitM attacks, or the absence of any attacks. Federated learning with GAN networks allows for the aggregation of updates from multiple local models distributed across MANET. Assessment metrics such as accuracy, precision, F1 score, detection rate, recall, and security rate have been utilized to assess the efficacy of the proposed HIDE-MAN method. The comparative analysis shows that the detection rate of the proposed HIDE-MAN is greater by 18.9%, 18.07%, and 4.03% than that of the current KBIDS, WOA-DNN, and MSA-GCNN techniques, respectively.},
  archive      = {J_IJCIS},
  author       = {Hussain, S. Faizal Mukthar and Fathima, S. M. H. Sithi Shameem},
  doi          = {10.1007/s44196-024-00590-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Federated learning-assisted coati deep learning-based model for intrusion detection in MANET},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Application of hybrid algorithm based on ant colony
optimization and sparrow search in UAV path planning. <em>IJCIS</em>,
<em>17</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s44196-024-00652-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Traveling Salesman Problem (TSP) is a classic problem in combinatorial optimization, aiming to find the shortest path that traverses all cities and eventually returns to the starting point. The ant colony optimization algorithm has achieved significant results, but when the number of cities increases, the ant colony algorithm is prone to fall into local optimal solutions, making it difficult to obtain the global optimal path. To overcome this limitation, this paper proposes an innovative hybrid ant colony algorithm. Our main motivation is to introduce other optimization strategies to improve the global search ability and convergence speed of the ant colony algorithm in solving TSP problems. We first incorporate the iterative solution of the sparrow search algorithm (SSA) into the ant colony algorithm to provide a better initial pheromone distribution. Second, we improve the pheromone update method to enhance the algorithm’s diversity during the search process and reduce the risk of falling into local optima. Finally, we define a dynamic pheromone evaporation factor to adjust the pheromone evaporation rate according to real-time changes in the search process. Through simulation tests on large-scale TSP problems and practical applications, we find that the hybrid ant colony algorithm outperforms the ant colony algorithm in both accuracy and running time. In Eg.2, the average accuracy of ISSA-ACO is improved by 12%, and the average running time is reduced by 45.6%. This study not only provides a new and effective method for solving large-scale TSP problems but also provides valuable references and insights for the application of ant colony algorithms in solving other complex optimization problems. At the same time, our research further verifies the effectiveness of improving heuristic algorithms by fusing different optimization strategies, providing new ideas and directions for future algorithm design and optimization.},
  archive      = {J_IJCIS},
  author       = {Tian, Yangyang and Zhang, Jiaxiang and Wang, Qi and Liu, Shanfeng and Guo, Zhimin and Zhang, Huanlong},
  doi          = {10.1007/s44196-024-00652-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Application of hybrid algorithm based on ant colony optimization and sparrow search in UAV path planning},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A model for estimating resiliency of AI-based classifiers
defending against cyber attacks. <em>IJCIS</em>, <em>17</em>(1), 1–32.
(<a href="https://doi.org/10.1007/s44196-024-00686-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI techniques for cybersecurity are advancing, but AI-based classifiers are suspectable of adversarial attacks. It is challenging to quantify the efforts required of an adversary to manipulate a system and quantify this resilience such that different systems can be compared using standard metrics. The study intends to quantify the actions required when an attacker abuses an AI-based system and propose a model to assess the attacker’s cybersecurity resilience. The study proposes an Egyptian Vulture Optimized Adaptive Elman Recurrent Neural Networks (EVO-AERNN) model to assess cybersecurity resilience and compare it with machine learning and deep learning-based classifiers. It illustrates the potential of using adversary-aware feature sampling to build more robust classifiers and use an optimized algorithm to maintain inherent resilience. The proposed model is achieved with an accuracy of 0.995, an F1 score of 0.9932, a precision of 0.9921, a recall (before an attack) of 0.987, a recall (after an attack) of 0.632, and a severity score of 0.363. The proposed model is further validated with a secondary dataset. This study paves the way for a more comprehensive knowledge of adversarial attack scenarios on network systems and offers valuable insights, inspiring further research on advancing cybersecurity studies.},
  archive      = {J_IJCIS},
  author       = {Barik, Kousik and Misra, Sanjay and Sanz, Luis Fernandez},
  doi          = {10.1007/s44196-024-00686-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A model for estimating resiliency of AI-based classifiers defending against cyber attacks},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing warehouse selection through topological index
based energy of q-rung orthopair fuzzy graphs. <em>IJCIS</em>,
<em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00687-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the study of q-rung orthopair fuzzy graphs (or q-ROFGs) has gained significant attention due to their ability to model complex and uncertain relationships. One crucial aspect in analyzing such graphs is the computation of their energy, which provides insights into their structural properties and dynamics. q-rung orthopair fuzzy sets were introduced, as a method for adjusting the range of indication of decision information by modifying a parameter q. This article presents a comprehensive approach for computing the energy of q-ROFGs. The new concepts of Zagreb energy of q-ROFGs are proposed and some bounds are determined. To demonstrate the applicability of the developed approach and show its viability, a numerical model related to the selection of the most suitable warehouse location is provided. Lastly, a comparative analysis is done, and the proposed approach is found to be compatible with existing models.},
  archive      = {J_IJCIS},
  author       = {Guan, Hao and Hameed, Saira and Akhter, Sadia and Yousaf, Zulqarnain and Shafi, Jana and Khan, Aysha},
  doi          = {10.1007/s44196-024-00687-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimizing warehouse selection through topological index based energy of q-rung orthopair fuzzy graphs},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Machine learning and metaheuristic algorithms for
voice-based authentication: A mobile banking case study. <em>IJCIS</em>,
<em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-024-00690-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {These days, every bank requires secure identification before granting access to personal accounts. Voice authentication is increasingly popular for important mobile processes. The hybrid authentication technique is used in this work to address concerns about forgery attacks in the voice authentication system. Here, we accomplish this goal by using a user authentication approach that decodes passwords from acoustic signals. This method involves the user speaking into the phone to enter their private password. Then, to crack the code, an artificial neural network is employed along with retrieved statistics and speech parameters such as energy and Mel frequency cepstral coefficient. The password numbers are read and saved. The planned application divides the read integers by using the pauses in between the digits. On the other hand, by employing the frequency and phase properties to compare the target&#39;s voice to the discovered password key, this method will prevent speech forgeries. This speech and password matching verification system uses our fuzzy nonlinear support vector machine network classification system, which was trained using the Ali Baba and the forty thieves algorithm. Our method is evaluated on a dataset of 30 individuals and three smartphones, achieving an accuracy rate of more than 98.29%. Our system is resistant against a wide range of challenges, including variations in authentication angle, authentication distance, passphrase length, ambient noise, and more, in addition to being device independent.},
  archive      = {J_IJCIS},
  author       = {Nosrati, Leili and Bidgoli, Amir Massoud and Javadi, Hamid Haj Seyyed},
  doi          = {10.1007/s44196-024-00690-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Machine learning and metaheuristic algorithms for voice-based authentication: A mobile banking case study},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Studying the impact of changing consumer behavior during
crisis periods through store classification. <em>IJCIS</em>,
<em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00694-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since customer behavior changes unpredictably during crisis periods such as pandemics, many sectors have been affected differently. The retail sector in particular has been one of the most affected sectors. Retail companies that could not determine the right strategies against customer behavior change were in a difficult situation, and some even had to close down. The inability of consumers to do physical shopping for reasons such as socializing, experiencing products and interacting during the pandemic process required an understanding of changing consumer needs. In this study, to determine the changes in customer purchasing behaviors during the pandemic period, using the sales data of a company operating in the women’s clothing sector and whose sales loss approached 50% during the pandemic period, separate stores were divided into clusters using machine learning methods for the pre-pandemic and pandemic period. The clusters formed were examined and the stores in different clusters were determined depending on customer purchasing behavior. The aim of the study is to ensure that the company segments its stores correctly to gain competitive advantage. Firms will be able to determine the right strategies against changing consumer behavior through a correct store segmentation. First, stores that do not belong to any classification group are clustered using unsupervised machine learning methods. No significant change was observed in the clusters formed before and during the pandemic. This indicated that the pandemic had a similar effect on all stores. Then, pre-pandemic, pandemic period and both periods data were analyzed using 7 different machine learning classification algorithms. The results obtained were compared. For all three analyses, the random forest algorithm gave the highest accuracy rate. The random forest algorithm with the highest accuracy was hybridized with 3 different classification algorithms. The hybrid model consisting of random forest and support vector machine gave the highest accuracy rate (90%) for the period including all data for store classification. Thanks to the hybrid model created with random forest and support vector machines, companies can be advantageous against other companies in the competitive environment by creating separate strategies for each store class.},
  archive      = {J_IJCIS},
  author       = {Tabak Kızgın, Kiymet and Alp, Selçuk},
  doi          = {10.1007/s44196-024-00694-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Studying the impact of changing consumer behavior during crisis periods through store classification},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of motorcycle brands using multi-attribute
decision-making method under single-valued neutrosophic cubic hypersoft
set environment. <em>IJCIS</em>, <em>17</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s44196-024-00696-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of motorcycles evaluation is intricate and influenced by several factors that are uncertain, indeterminate and vague. It is difficult to estimate to what extent the choice will satisfy all requirements and change with the times. The theoretical frameworks such as hypersoft sets, interval and single-valued neutrosophic sets are useful in managing such vagueness and uncertainty. This study introduces a novel theoretical framework; the single-valued neutrosophic cubic hypersoft set (svNCHSS), to mitigate the loss of useful data. In comparison to the frameworks mentioned above, the svNCHSS is more adaptable in handling ambiguous and unpredictable circumstances because it incorporates all of their limitations as a single model. The set-theoretic operations like P-union $$(\sqcup _{P})$$ , P-intersection $$( \sqcap _{P})$$ , R-union $$( \sqcup _{R})$$ , R-intersection $$(\sqcap _{R})$$ , AND- and OR-operations are investigated for svNCHSS environment. Two potent algorithms are proposed in the context of a decision-assisted mechanism that employs AND- and OR-operations for the evaluation of motorbikes taking into account multi-argument-based factors. To evaluate the suggested algorithms’ effectiveness, a prototype case study is used for validation. The computed results are then compared. The structural comparison reveals the flexibility of svNCHSS, making its aggregation operations a useful tool for a variety of industrial applications, including risk assessment, process improvement, and decision-making.},
  archive      = {J_IJCIS},
  author       = {Sajid, Muhammad and Khan, Khuram Ali and Rahman, Atiqe Ur},
  doi          = {10.1007/s44196-024-00696-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Evaluation of motorcycle brands using multi-attribute decision-making method under single-valued neutrosophic cubic hypersoft set environment},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fine-grained meetup events extraction through context-aware
event argument positioning and recognition. <em>IJCIS</em>,
<em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00697-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting meetup events from social network posts or webpage announcements is the core technology to build event search services on the Web. While event extraction in English achieves good performance in sentence-level evaluation [1], the quality of auto-labeled training data via distant supervision is not good enough for word-level event extraction due to long event titles [2]. Additionally, meetup event titles are more complex and diverse than trigger-word-based event extraction. Therefore, the performance of event title extraction is usually worse than that of traditional named entity recognition (NER). In this paper, we propose a context-aware meetup event extraction (CAMEE) framework that incorporates a sentence-level event argument positioning model to locate event fields (i.e., title, venue, dates, etc.) within a message and then perform word-level event title, venue, and date extraction. Experimental results show that adding sentence-level event argument positioning as a filtering step improves the word-level event field extraction performance from 0.726 to 0.743 macro-F1, outperforming large language models like GPT-4-turbo (with 0.549 F1) and SOTA NER model SoftLexicon (with 0.733 F1). Furthermore, when evaluating the main event extraction task, the proposed model achieves 0.784 macro-F1.},
  archive      = {J_IJCIS},
  author       = {Lin, Yuan-Hao and Chang, Chia-Hui and Chuang, Hsiu-Min},
  doi          = {10.1007/s44196-024-00697-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Fine-grained meetup events extraction through context-aware event argument positioning and recognition},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing streamflow prediction accuracy: A comprehensive
analysis of hybrid neural network models with runge–kutta with aquila
optimizer. <em>IJCIS</em>, <em>17</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s44196-024-00699-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the efficacy of hybrid artificial neural network (ANN) methods, incorporating metaheuristic algorithms such as particle swarm optimization (PSO), genetic algorithm (GA), gray wolf optimizer (GWO), Aquila optimizer (AO), Runge–Kutta (RUN), and the novel ANN-based Runge–Kutta with Aquila optimizer (LSTM-RUNAO). The key novelty of this research lies in the developing and applying the LSTM-RUNAO model, which combines Runge–Kutta and Aquila optimizer to enhance streamflow prediction accuracy. The models’ performance is compared against the conventional ANN method, analyzing monthly streamflow prediction across three data split scenarios (50–50%, 60–40%, and 75–25%). Results show that the LSTM-RUNAO model outperformed conventional ANN methods, achieving a 28.7% reduction in root mean square error (RMSE) and a 20.3% reduction in mean absolute error (MAE) compared to standard ANN models. In addition, the model yielded a Nash–Sutcliffe Efficiency (NSE) improvement of 12.4% and an R-squared value increase of 7.8%. The study advocates for the 75–25% train-test data splitting scenario for optimal performance in data-driven methodologies. Furthermore, it elucidates the nuanced influence of input variables on prediction accuracy, emphasizing the importance of thoughtful consideration during model development. In summary, this research contributes valuable insights and introduces an innovative hybrid model to enhance the reliability of streamflow prediction models for practical applications.},
  archive      = {J_IJCIS},
  author       = {Adnan, Rana Muhammad and Mo, Wang and Ewees, Ahmed A. and Heddam, Salim and Kisi, Ozgur and Zounemat-Kermani, Mohammad},
  doi          = {10.1007/s44196-024-00699-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing streamflow prediction accuracy: A comprehensive analysis of hybrid neural network models with Runge–Kutta with aquila optimizer},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A talent cultivation and performance evaluation model based
on a fuzzy control algorithm. <em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00701-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet era has raised the demand for skilled workers in businesses and for economic expansion. Businesses find it difficult to expand when trained personnel are shortages. Evaluating and managing exceptionally gifted persons have become more difficult due to technological developments, which have slowed down technological progress and business expansion. The study suggests a technique to quantify how firms develop and employ talent to address this issue. An algorithm called the fuzzy optimized talent cultivation engine (FOTCE) is introduced to evaluate the effectiveness of talent development. The algorithm combines an adaptive neuro-Fuzzy Inference System with Adaptive Hybrid Particle Swarm Optimization. By considering factors including work-life balance, training, involvement, job performance, and satisfaction, the suggested FOTCE algorithm hopes to improve talent strategies and boost organizational competitiveness. The FOTCE algorithm assesses talent development on three levels: overall efficacy, major categories (such as job satisfaction and involvement), and individual indicators within each category. Fuzzy logic handles subjective viewpoints and unclear data in the study, allowing for a more comprehensive assessment. The technique uses fuzzy math to show different levels of employee retention by giving different factors different weights. The results show that the FOTCE technique helps evaluate and upgrade talent development programs and provides valuable insights for better people management when tested with accurate HR data from a company. The findings demonstrate that the suggested FOTCE algorithm outperformed state-of-the-art models like IAA-NRM (83% retention rate) and FAHP (87% retention rate) by a wide margin. Comparatively, FAHP had an EEI of 83% and DEA had 86%. The EEI for this organization achieved 95%. In addition, the FOTCE model showed a higher Talent Development Efficiency Score (TCDES) of 93%, proving that it boosts organizational competitiveness and employee happiness.},
  archive      = {J_IJCIS},
  author       = {Jiang, Shanshan},
  doi          = {10.1007/s44196-024-00701-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A talent cultivation and performance evaluation model based on a fuzzy control algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). LCAT-net: Lightweight context-aware deep learning approach
for teeth segmentation in panoramic x-rays. <em>IJCIS</em>,
<em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00703-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teeth segmentation is a crucial and fundamental player for doctors in diagnosis and treatment planning in dentistry. Due to the blurred interdental boundaries, variations in noise, and the complexities arising from the orientation and overlapping of dental structures within oral images, the segmentation process becomes extremely challenging and time-consuming. Nowadays, computational tools have been introduced as promising strategies for automating teeth segmentation. As one of them, this paper presents a novel architecture called LCAT-Net, designed to address these challenges and improve teeth segmentation in panoramic X-rays. The proposed architecture incorporates several components to address the above challenges. Firstly, it leverages the main components of the Half-UNet for lightweight feature extraction, starting from ghost modules, unified channel numbers, and full-scale feature fusion. Secondly, to give our model the ability to focus on critical regions for improved differentiation in complex dental structures, a convolutional block attention module (CBAM) is integrated into the network. Thirdly, the architecture incorporates a novel multi-scale context fusion (MCF) module, our proposed MCF module extracts multi-scale spatial information through a spatial context fusion (SCF) block, followed by a CBAM block that learns to balance channel-wise features. The network uses a Dense skip connection module (DSM) to reduce the semantic gap. Experiments on three dental panoramic X-ray image datasets of Children, Adults, and Combined (Children and Adults) consisting of 193, 1776, and 1969 X-rays show that our model outperformed the SOTA models in teeth segmentation, with a high mean Dice-scores of 0.9235, 0.9444, 0.9405, respectively. While requiring significantly fewer parameters and floating-point operations (FLOPs) than existing methods.},
  archive      = {J_IJCIS},
  author       = {Khaldi, Anouar and Khaldi, Belal and Aiadi, Oussama},
  doi          = {10.1007/s44196-024-00703-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {LCAT-net: Lightweight context-aware deep learning approach for teeth segmentation in panoramic X-rays},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Toward safer flight training: The data-driven modeling of
accident risk network using text mining based on deep learning.
<em>IJCIS</em>, <em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-024-00705-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flight training, a critical component of the general aviation industry, exhibits a relatively high severity of risk due to its complexity and the uncertainty inherent in risk interactions. To mine the risk factors and dynamic evolution characteristics affecting flight safety, a data-driven network modeling methodology that integrates text mining with domain knowledge in accident analysis is proposed for the analysis of accident risks specific to flight training. First, flight training accident reports are labeled using domain knowledge gained from accident causation theory to provide basic data for subsequent study. Second, the adversarial training algorithm is introduced to enhance the generalization capability of BERT model in processing imbalanced accident textual data. The fine-tuned BERT, Bidirectional Long Short-Term Memory (Bi-LSTM) Conditional Random Field (CRF) algorithm is fused to construct an ensemble algorithm for risk identification, which accomplishes the joint entity-relationship extraction of accident reports. Third, based on the risk identification results, data-driven modeling of the Flight Training Risk Network (FTRN) is performed to quantify the accident evolution characteristics. Then the aforementioned tasks are meticulously optimized and integrated, subsequently applied to a case study focusing on Loss of Control In-Flight(LOCI) accidents. The findings suggest that the identification algorithm effectively and efficiently extracts risk information and inter-relationships. In addition, the network analysis results reveal the key insights into flight training accidents, facilitating the development of holistic risk control strategies. This study provides a powerful and innovative analytical tool for safety management departments, enhancing safety and reliability in flight training operations.},
  archive      = {J_IJCIS},
  author       = {Zhuang, Zibo and Hou, Yongkang and Yang, Lei and Gong, Jingwei and Wang, Lei},
  doi          = {10.1007/s44196-024-00705-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Toward safer flight training: The data-driven modeling of accident risk network using text mining based on deep learning},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On study of multiset dimension in fuzzy zero divisor graphs
associated with commutative rings. <em>IJCIS</em>, <em>17</em>(1), 1–10.
(<a href="https://doi.org/10.1007/s44196-024-00706-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the concept of fuzzy zero divisor graph (FZDG) for a commutative ring $$R$$ denoted by $${\Gamma }_{f}\left(\text{R}\right)$$ . We explore the multiset dimension (Mdim), a new variant of the metric dimension (MD), specifically in the context of FZDGs. To illustrate our findings, we analyze the FZDG for the ring $${\mathbb{Z}}_{n}$$ of integers modulo $$n$$ of integers modulo $$n$$ , denoted by $${\Gamma }_{f}\left({\mathbb{Z}}_{n}\right).$$ We compute the multiset dimension for all possible values of $$n$$ for the FZDG $${\Gamma }_{f}\left({\mathbb{Z}}_{n}\right)$$ , providing significant theoretical insights into its structure. Our results not only advance the understanding of FZDGs and their multiset dimensions but also have practical implications across various fields, including cryptography, coding theory, and network analysis. This study lays the groundwork for future research on the application of fuzzy concepts in graph theory and algebraic structures.},
  archive      = {J_IJCIS},
  author       = {Ali, Nasir and Siddiqui, Hafiz Muhammad Afzal and Qureshi, Muhammad Imran and Abdalla, Manal Elzain Mohamed and EL-Gawaad, N. S. Abd and Tolasa, Fikadu Tesgera},
  doi          = {10.1007/s44196-024-00706-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {On study of multiset dimension in fuzzy zero divisor graphs associated with commutative rings},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Correction: Artificial intelligence in aviation safety:
Systematic review and biometric analysis. <em>IJCIS</em>,
<em>17</em>(1), 1. (<a
href="https://doi.org/10.1007/s44196-024-00707-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Demir, Gülay and Moslem, Sarbast and Duleba, Szabolcs},
  doi          = {10.1007/s44196-024-00707-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: artificial intelligence in aviation safety: systematic review and biometric analysis},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep learning algorithm for optimized sensor data fusion in
fault diagnosis and tolerance. <em>IJCIS</em>, <em>17</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-024-00692-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental perception is one of the key technologies to realize autonomous vehicles. The fault diagnosis process involves identifying the fault that occurred or the cause of the out-of-control condition. Here, the major objective is to locate problems in detection by analysing previous data or sequential patterns of data that cause failure. This study evaluates the use of deep learning for improved sensor data fusion in fault identification and tolerance using the KITTI dataset. The input video from the dataset has been transformed to frames through median filtering. Next, feature extraction is applied to a preprocessed image, resulting in the fusion of sensor data. Data fusion is then carried out utilizing an enhanced RPN (region proposal network). The enhanced RPN also has a loss function (object detection loss, bounding box loss and target classification loss), an estimate of ROI and feature extraction network (FEN). Through the use of the COOT connected blue monkey optimization (CCBMO) model, the weight of the optimally enhanced RPN is established. Next, using global non-maximum suppression with both global and local confidence, fault identification and tolerance are carried out. From the analysis, it clearly shows that proposed method accomplished better results in terms of accuracy, precision and specificity of 97.78%, 93.76% and 93.43%, respectively, when compared with various conventional models with respect to diverse performance measures.},
  archive      = {J_IJCIS},
  author       = {Elhoseny, M. and Rao, Deepak Dasaratha and Veerasamy, Bala Dhandayuthapani and Alduaiji, Noha and Shreyas, J. and Shukla, Piyush Kumar},
  doi          = {10.1007/s44196-024-00692-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Deep learning algorithm for optimized sensor data fusion in fault diagnosis and tolerance},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing personalized and context-aware recommendations in
pervasive computing environments. <em>IJCIS</em>, <em>17</em>(1), 1–13.
(<a href="https://doi.org/10.1007/s44196-024-00658-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The researchers in the current era provided many new recommendation methodologies. Though various recommendation techniques exist, there is a need to develop a unique technique for capturing latent factors and patterns from sparse and high-dimensional data in pervasive environments, specifically for optimizing dynamic recommendations. This study proposes a hybrid approach for optimizing dynamic recommendations in pervasive environments by combining Non-Negative Matrix Factorization (NMF) with deep learning and reinforcement learning techniques. The goal is to overcome the challenge of capturing latent factors and patterns from sparse and high-dimensional data. By leveraging NMF, meaningful latent factors are extracted, while deep learning, specifically Faster recurrent neural networks (FRNNs), learns complex feature representations. Reinforcement learning algorithms optimize the recommendation policy based on user feedback. This Hybrid Context-Aware Optimized Recommendation (HCOR) approach improves recommendation accuracy and relevance in pervasive environments, adapts to changing contexts, and enhances user experiences. The performance benefits are achieved by effectively capturing latent factors and patterns, resulting in improved accuracy and the ability to provide personalized and context-aware recommendations. The performance indicators to validate the research work include the recommendations&#39; accuracy, relevance, and adaptability in pervasive environments. Additionally, metrics, such as precision, recall, and F1-score, are used to evaluate the effectiveness of the hybrid approach in capturing latent factors and patterns. User feedback and satisfaction are also measured to assess the impact on user experiences. The HCOR approach shows substantial performance gains, measuring a precision of 0.932, a recall of 0.922, and an F1-score of 0.943, which indicates the excellent ability of the approach to deliver accurate and personalized recommendations in a pervasive environment.},
  archive      = {J_IJCIS},
  author       = {Kaladevi, A. C. and Kumar, V. Vinoth and Mahesh, T. R. and Guluwadi, Suresh},
  doi          = {10.1007/s44196-024-00658-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimizing personalized and context-aware recommendations in pervasive computing environments},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neuro-fuzzy logic for automatic animation scene generation
in movie arts in digital media technology. <em>IJCIS</em>,
<em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00709-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animation scene generation (ASG) is the best digital media tool for lifelike scenes, particularly for movies. Traditional animation methods are laborious, computationally intensive, and scalable. Thus, this work addresses animation production issues using NFL-ASG. Combining fuzzy logic with a convolution neural network may create more realistic animated situations with less human interaction and better learning. Convolutional model training uses animation scenarios’ complicated motion patterns, character interactions, and ambient factors. Deep learning and fuzzy logic might change animation by boosting production techniques and releasing digital media technological creativity. After testing the system on the Moana Island scene dataset, it achieved a perception analysis success rate of 0.981% and a minimal processing complexity of (n logn).},
  archive      = {J_IJCIS},
  author       = {Peng, Liu},
  doi          = {10.1007/s44196-024-00709-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Neuro-fuzzy logic for automatic animation scene generation in movie arts in digital media technology},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperplane-assisted multi-objective particle swarm
optimization with twofold proportional assignment strategy.
<em>IJCIS</em>, <em>17</em>(1), 1–27. (<a
href="https://doi.org/10.1007/s44196-024-00702-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the simultaneous optimization of multiple objectives, how to balance convergence promotion and diversity preservation in the evolutionary process is a key and challenging problem. In this research, a hyperplane-assisted multi-objective particle swarm optimization with a twofold proportional assignment strategy (tpahaMOPSO) is suggested to ameliorate the optimization performance of MOPSO. First, the external archive is maintained in combination with hyperplane-based convergence evaluation and shift-based density estimation to retain high-quality candidate solutions. Second, a twofold proportional assignment scheme is designed to search the surrounding region of candidate solutions with better potential to emphasize convergence and diversity, respectively. Third, the domination relationship and convergence difference are combined to select a more reasonable individual historical best and reduce the risk of particle aggregation. Finally, the proposed tpahaMOPSO was compared with ten representative and advanced multi-objective optimization algorithms on 22 widely used test functions with different characteristics. The simulation results present that the developed tpahaMOPSO got the best result in 11 benchmark functions for both IGD and HV criteria. Concurrently, the Friedman test was applied for ranking analysis and the proposed algorithm also obtained excellent statistical analysis results. The promising performance and strong competitiveness of the proposed tpahaMOPSO have been verified by different experimental studies.},
  archive      = {J_IJCIS},
  author       = {Song, Qian and Liu, Yanmin and Zhang, Xiaoyan and Zhang, Yansong},
  doi          = {10.1007/s44196-024-00702-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hyperplane-assisted multi-objective particle swarm optimization with twofold proportional assignment strategy},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Route optimization and optimal cluster head selection for
cluster-oriented wireless sensor network utilizing circle-inspired
optimization algorithm. <em>IJCIS</em>, <em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00708-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wireless sensor network (WSN)&#39;s lifespan and optimal orientation are greatly increased by clustering. Clustering selects non-cluster heads (NCHs) and cluster heads (CHs) and integrates sensor nodes via clusters. The purpose of this research is to find the best route and select the best cluster head for the WSN with the help of optimization methodology. The adaptive multi-path routing protocol (AMPRP), which is best chosen utilizing the circle-inspired optimization algorithm (CIOA) algorithm, is proposed in this study as a method for choosing NCHs and CHs. The optimal CHs have been chosen after the probabilities have been calculated, and the findings have been utilized to identify the optimal shortest path employing the same CIOA. To find the best route, the CIOA algorithm employs a fitness function made out of a network. The superiority of the proposed model is demonstrated by validating it with various state-of-the-art methods in terms of distinct analysis. The proposed AMPRP-CIOA for the optimal route and CH selection model in terms of energy consumption is 85.71%, 86.67%, 88.89%, and 77.78% better than EAHPW-TOPSIS, DA-EECHS, GEEC, and EADCR, respectively.},
  archive      = {J_IJCIS},
  author       = {Divya, P. and Sudhakar, B.},
  doi          = {10.1007/s44196-024-00708-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Route optimization and optimal cluster head selection for cluster-oriented wireless sensor network utilizing circle-inspired optimization algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overlapping channel allocation method for wireless
communication network based on discrete particle swarm optimization
algorithm. <em>IJCIS</em>, <em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-024-00711-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of interference between network channels and low-frequency resource utilization efficiency, and to improve the overall performance and resource allocation fairness of the network, this study proposes a wireless communication network overlapping channel allocation strategy based on a discrete particle swarm optimization algorithm. First, the overlapping channel allocation problem in wireless networks is abstracted as a linear programming model with specific constraints, with the core objective of minimizing weighted interference between links. To solve this model, a discrete particle swarm optimization algorithm is introduced. In this algorithm, each particle’s position corresponds to a feasible overlapping channel allocation scheme, which is the potential solution to the optimization problem; The velocity of particles reflects the process of transitioning from the current channel configuration to the target channel configuration. Subsequently, based on the characteristics of discrete variables, corresponding operation rules and particle motion equations were defined. In addition, when particle swarm aggregation occurs, an optimal asymptotic mutation operator is introduced, which not only enhances the local search ability of the algorithm but also strengthens its global search ability. During algorithm execution, this mutation operator is applied based on a certain probability of mutation. The experimental results show that when using this strategy for overlapping channel allocation in wireless communication networks, even with an increase in the number of traffic flows, the average network throughput can remain stable, demonstrating a high network carrying capacity. Meanwhile, wireless networks exhibit a higher fairness factor, indicating a more balanced allocation of network resources among different users. In the process of optimal channel allocation, the packet loss rate reaches the lowest level, ensuring the reliability of data transmission.},
  archive      = {J_IJCIS},
  author       = {Qin, Yue and Zhu, Lei and Zhang, Jingsong and Liu, Chao},
  doi          = {10.1007/s44196-024-00711-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Overlapping channel allocation method for wireless communication network based on discrete particle swarm optimization algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Correction: LCAT-net: Lightweight context-aware deep
learning approach for teeth segmentation in panoramic x-rays.
<em>IJCIS</em>, <em>17</em>(1), 1. (<a
href="https://doi.org/10.1007/s44196-024-00717-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Khaldi, Anouar and Khaldi, Belal and Aiadi, Oussama},
  doi          = {10.1007/s44196-024-00717-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: LCAT-net: lightweight context-aware deep learning approach for teeth segmentation in panoramic X-rays},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A systematic review of artificial intelligence in
orthopaedic disease detection: A taxonomy for analysis and
trustworthiness evaluation. <em>IJCIS</em>, <em>17</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s44196-024-00718-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthopaedic diseases, which affect millions of people globally, present significant diagnostic challenges, often leading to long-term disability and chronic pain. There is an ongoing debate across the literature regarding the trustworthiness of artificial intelligence (AI) in detecting orthopaedic diseases. This systematic review aims to provide a comprehensive taxonomy of AI applications in orthopaedic disease detection. A thorough literature search was conducted across five major databases (Science Direct, Scopus, IEEE Xplore, PubMed, and Web of Science) covering publications from January 2019 to 2024. Following rigorous screening on the basis of predefined inclusion criteria, 85 relevant studies were identified and critically evaluated. For the first time, this review classifies AI contributions into six key categories of orthopaedic conditions on the basis of medical perspective: arthritis, tumours, deformities, fractures, osteoporosis, and general bone abnormalities. In addition to analyzing motivations, challenges, and recommendations for future research, this review highlights the various AI techniques employed, including deep learning (DL), machine learning (ML), explainable AI (XAI), fuzzy logic, and multicriteria decision-making (MCDM), as well as the datasets utilized. Furthermore, the trustworthiness of AI models is evaluated on the basis of seven AI trustworthiness components, aligned with European Union guidelines, within each category. These findings underscore the need for high-quality research to ensure that AI computational systems in orthopaedic disease detection are reliable, safe, and ethical. Future research should focus on optimizing AI algorithms, improving dataset diversity, and addressing ethical and regulatory challenges to ensure successful integration into clinical practice.},
  archive      = {J_IJCIS},
  author       = {Mohammed, Thura J. and Xinying, Chew and Alnoor, Alhamzah and Khaw, Khai Wah and Albahri, A. S. and Teoh, Wei Lin and Chong, Zhi Lin and Saha, Sajal},
  doi          = {10.1007/s44196-024-00718-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A systematic review of artificial intelligence in orthopaedic disease detection: A taxonomy for analysis and trustworthiness evaluation},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph contrastive pre-training for anti-money laundering.
<em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00720-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anti-money laundering (AML) is vital to maintaining financial markets, social stability, and political authority. At present, many studies model the AML task as the graph and leverage graph neural network (GNN) for node/edge classification. Although these studies have achieved some achievements, they struggle with the issue of label scarcity in real-world scenarios. In this paper, we propose a graph contrastive pre-training framework for anti-money laundering (GCPAL), which mines supervised signals from the label-free transaction network to significantly reduce the dependence on annotations. Specifically, we construct three augmented views (i.e., two stochastic perturbed views and a KNN view). Perturbed views are beneficial to the model learning invariant information and improve the robustness against noise. KNN view provides implicit interactions to mitigate the link sparsity in the transaction network. Moreover, we extend the positive sample set using connected neighbors and node pairs with similar features to further enhance the expressiveness of the model. We evaluate the GCPAL on two datasets, and the extensive experimental results demonstrate that the GCPAL is consistently superior to other SOTA baselines, especially with scarce labels.},
  archive      = {J_IJCIS},
  author       = {Lu, Hanbin and Wang, Haosen},
  doi          = {10.1007/s44196-024-00720-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Graph contrastive pre-training for anti-money laundering},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective stemmers using trie data structure for enhanced
processing of gujarati text. <em>IJCIS</em>, <em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-024-00679-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stemming plays a crucial role in natural language processing and information retrieval. It is challenging for the Gujarati language due to the complex morphology of several stemming algorithms for the Gujarati language that have been developed using rule-based, dictionary-based, or hybrid approaches. However, they are computationally expensive, produce more over-stemming errors and have limited accuracy. This paper introduces three novel optimized Gujarati stemmers using a trie data structure to overcome the above-mentioned limitations. The significant contributions to this paper are as follows. First, three optimized Gujarati stemmers, namely Optimized Gujarati Stemmer using Suffix Stripping Approach (OGS_SSA), Optimized Gujarati Stemmer using Rule-Based Approach (OGS_RBA), and Optimized Gujarati Stemmer using Re-parsing Based Approach (OGS_RPA), are proposed. Second, a novel algorithm to create a Gujarati dictionary using the trie data structure is proposed. Third, the proposed stemmers are rigorously assessed using three standard datasets, namely entertainment, health, and agriculture. The performance of the proposed stemmers is measured using evaluation parameters such as precision, recall, F1 score, accuracy, number of stemming errors and processing time. The results show that OGS_RPA consistently exceeds the OGS_SSA and OGS_RBA for precision, recall, F1 score, and accuracy. In addition, it exhibits a lower number of stemming errors. Moreover, the performance of the proposed stemmer is compared with the existing Gujarati hybrid stemmer. The results show a 14–16% improvement in accuracy and less processing time compared to the Gujarati hybrid stemmer. OGS_SSA demonstrated enhanced processing time, making it a feasible option for applications that prioritize prompt response time. Furthermore, it demonstrates 10–11% enhancement in accuracy and a reduction in processing time than the Gujarati hybrid stemmer. OGS_RBA exhibits moderate performance due to its rule-based methodology compared to OGS_RPA and OGS_SSA. However, it shows 10–13% improvement in accuracy than the Gujarati hybrid stemmer.},
  archive      = {J_IJCIS},
  author       = {Dave, Nakul R. and Mehta, Mayuri A. and Kotecha, Ketan},
  doi          = {10.1007/s44196-024-00679-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Effective stemmers using trie data structure for enhanced processing of gujarati text},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel slime mould multiverse algorithm for global
optimization and mechanical engineering design problems. <em>IJCIS</em>,
<em>17</em>(1), 1–56. (<a
href="https://doi.org/10.1007/s44196-024-00704-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The slime mould optimization algorithm (SMA) is one of the well-established optimization algorithms with a superior performance in a variety of real-life optimization problems. The SMA has certain limitations that reduce the diversity and accuracy of solutions, raising the risk of premature convergence with an inadequate balance between its exploitation and exploration phases. In this study, a novel hybrid slime mould multi-verse algorithm (SMMVA) is proposed to improve the performance of SMA algorithm. The SMA and multi-verse optimization (MVO) algorithm hybrid is introduced while updating variation parameter through novel nonlinear convergence factor. The proposed algorithm balances the ability of the SMA algorithm to explore and exploit, boosts the global exploration capability and improves the accuracy, stability, and convergence speed. The performance of SMMVA algorithm is compared with 16 well-established and recently-published metaheuristic algorithms on 23 standard benchmark functions, CEC2017, CEC2022 test functions, five engineering design problems, and five UCI repository datasets. The statistical tests such as Friedman’s test, box plot comparison and Wilcoxon rank sum test are employed to verify the SMMVA’s stability and statistical superiority. The algorithm was tested on total 64 benchmark functions, achieving an overall success rate of 68.75% across 30 runs compared to the other counterparts. The results for the feature selection problem show that the proposed algorithm with k-nearest neighbour (KNN) classifier obtained more informative features with higher accuracy values. Thus, the proposed SMMVA algorithm is proven to perform excellent performance in solving optimization problems with better solution accuracy and promising prospect.},
  archive      = {J_IJCIS},
  author       = {Thakur, Gauri and Pal, Ashok},
  doi          = {10.1007/s44196-024-00704-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-56},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel slime mould multiverse algorithm for global optimization and mechanical engineering design problems},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Attention-based convolutional aggregation: An efficient
model for off-gas profile forecasting and dynamic pre-control of BOF
steelmaking. <em>IJCIS</em>, <em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00713-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proved that the curves of carbon monoxide (CO), carbon dioxide (CO2), and CO + CO2 in the off-gas profile were forecastable, and realized a 32-s-ahead forecasting for them. It established a technical foundation for addressing the delay in off-gas profile display and for enabling pre-control in BOF steelmaking based on the forecasted curves’ features. First, a data pre-processing method was proposed based on the characteristics of the off-gas curves, where there are many samples, but each sample contains limited time-steps. It is termed the mixed-batch approach. The importance of the time series’ channels and time-steps were also analyzed by models with attention mechanism. Then, a deep-learning model is proposed to forecast the dynamic off-gas profile, named attention-based convolutional aggregation (ABCA). It incorporates artificial intelligence (AI) techniques, such as aggregation structures, causal dilation convolution, attention mechanisms, residual connections, etc. Its forecasting coefficient of determination (R2) values for the curves of CO, CO2, and CO + CO2 reached 0.9386, 0.8566, and 0.9428, respectively, while the mean squared errors (MSEs) values were 47.3884, 11.9314, and 54.3583, respectively. These results outperform the benchmark state-of-the-art (SOTA) models. Additionally, ABCA was implemented in a forecasting tool for external validation. The results of external validation showed that ABCA has good forecasting accuracy and robustness. What is more, approaches in four aspects of pre-control of BOF steelmaking process with forecasted off-gas profile were also provided as pre-control examples.},
  archive      = {J_IJCIS},
  author       = {Xie, Tian-yi and Zhang, Jun-guo and Li, Lan-jie and Zhang, Fei and Liu, Shuai and Guo, Han-jie},
  doi          = {10.1007/s44196-024-00713-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Attention-based convolutional aggregation: An efficient model for off-gas profile forecasting and dynamic pre-control of BOF steelmaking},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-objective community detection algorithm with a
learning-based strategy. <em>IJCIS</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00715-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a fundamental task in network analysis in that it can express the characteristics of individual behaviors and the relationships between individuals in complex networks, thus revealing the functional and structural properties of various networks. However, as networks become larger and larger, how to quickly and accurately detect the community structure of large-scale networks has become a huge challenge nowadays. In this paper, an efficient algorithm, called Local Search for Community Detection (LSCD), is proposed to solve the multi-objective community detection problem. In the algorithm, an iterated local search is performed to search for non-dominated solutions in the solution space. To search for higher quality non-dominated solutions, this paper employs a learning-based strategy to select nodes in each round of the search. The strategy learns from the historical movement of the nodes and changes their selection probability according to their importance. Moreover, to search the entire solution space, this paper proposes a local search strategy that restricts one objective with a bound for a certain round, as well as an adaptive bound update mechanism. Experimental results on synthetic and real-world networks show that the proposed algorithm outperforms several state-of-the-art algorithms in terms of multi-objective optimization performance and accuracy in detecting the community structure of complex networks, since it performs best on 44 instances out of 46 in terms of Modularity (Q) and 29 out of 39 in terms of Normalized Mutual Information (NMI). In addition, the results show that the proposed algorithm has a good ability to handle large-scale networks.},
  archive      = {J_IJCIS},
  author       = {Liu, Bo and Wang, Dan and Gao, Jian},
  doi          = {10.1007/s44196-024-00715-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A multi-objective community detection algorithm with a learning-based strategy},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Study of an adaptive financial recommendation algorithm
using big data analysis and user interest pattern with fuzzy k-means
algorithm. <em>IJCIS</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s44196-024-00719-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an ever-changing financial market, big data is set to revolutionize user interest management by sparking innovation and reshaping recommendations for the future. Conventional financial services face significant challenges like accessibility, personalization, limited reachability, and incomplete information about user interest patterns. Thus, it results in suboptimal financial recommendations that do not fully capture the individual user interests and adapt to changing market conditions. Hence, the research developed an adaptive algorithm that uses fuzzy logic, neural networks, and big data to deliver accurate financial recommendations based on user patterns using the Fuzzy Neural Financial Recommendation (FNFinRec) Algorithm. Implemented on a Hadoop platform with a MapReduce framework, the FNFinRec ensures efficient processing of large datasets. Fuzzy K-means clustering is applied, in which fuzzy logic helps to handle uncertainties in financial data and clusters users with similar patterns. An adaptive user profile is developed based on real-time user data input. The Neutral Collaborative Filtering (NCF) recommendation approach aims to predict user interests in financial products/services by learning from user interaction data. The neural networks provide personalized financial recommendations, adapting to changes in user patterns over time for improved accuracy. The metrics such as silhouette coefficient, Davies–Bouldin Index, mean square error (MSE), Precision@k, and Recall@k are used to assess the algorithm’s performance with existing algorithms. The results show that the proposed FNFinRec algorithm outperforms existing methods regarding clustering quality and recommendation accuracy. The competitive processing times that FNFinRec achieves are also crucial for making real-time financial decisions.},
  archive      = {J_IJCIS},
  author       = {Yang, Jinyong},
  doi          = {10.1007/s44196-024-00719-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Study of an adaptive financial recommendation algorithm using big data analysis and user interest pattern with fuzzy K-means algorithm},
  volume       = {17},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
