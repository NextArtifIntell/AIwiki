<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JIIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jiis---78">JIIS - 78</h2>
<ul>
<li><details>
<summary>
(2024). Enhancing e-learning effectiveness: A process mining
approach for short-term tutorials. <em>JIIS</em>, <em>62</em>(6),
1773–1794. (<a
href="https://doi.org/10.1007/s10844-024-00874-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of e-learning systems has revolutionized education, enabling the collection of valuable students’ activity data for continuous improvement. While existing studies have predominantly focused on prolonged learning paths, short-term tutorials offer a flexible and efficient alternative that is recently gaining increasing popularity. This article presents a methodology for investigating e-learning systems for short-term tutorials leveraging user behavior tracking and process mining techniques. A case study involving a web-based tutorial with approximately one hour of learning explores the learning processes of 250 students in Italy. The study analyzes learning outcomes and investigates the impact of different learning paths on student progress. The research questions concern i) the extraction of activity flows in short-term tutorials; ii) the prediction of outcomes in the early stages of short-term learning process. The proposed approach provides descriptive insights into the learning process which can also be used to offer prescriptive guidance.},
  archive      = {J_JIIS},
  author       = {Nai, Roberto and Sulis, Emilio and Genga, Laura},
  doi          = {10.1007/s10844-024-00874-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1773-1794},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing E-learning effectiveness: A process mining approach for short-term tutorials},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved machine learning technique for feature reduction
and its application in spam email detection. <em>JIIS</em>,
<em>62</em>(6), 1749–1771. (<a
href="https://doi.org/10.1007/s10844-024-00870-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces MPAG, a new feature selection method aimed at overcoming the limitations of the conventional Marine Predators Algorithm (MPA). The MPA may experience stagnation and become trapped in local optima during optimization. To address this challenge, we propose a refined version of the MPA, termed MPAG, which incorporates the Local Escape Operator (LEO) from the gradient-based optimizer (GBO). By leveraging the LEO operator, MPAG enhances the exploration ability of the MPA, particularly during the initial one-third of iterations. This enhancement injects more diversity into populations, thereby improving the process of search space discovery and mitigating the risk of premature convergence. The performance of MPAG is evaluated on 14 feature selection benchmark datasets, employing seven performance measures including fitness value, classification accuracy, and selected features. Our findings indicate that MPAG outperforms other algorithms in 86% of the datasets, underscoring its capability to select the most relevant features across various datasets while maintaining stability. Additionally, MPAG is evaluated using two cybersecurity applications, specifically spam detection datasets, where it demonstrates superior performance across most performance measures compared to other methods.},
  archive      = {J_JIIS},
  author       = {Ewees, Ahmed A. and Gaheen, Marwa A. and Alshahrani, Mohammed M. and Anter, Ahmed M. and Ismail, Fatma H.},
  doi          = {10.1007/s10844-024-00870-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1749-1771},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Improved machine learning technique for feature reduction and its application in spam email detection},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). SESAME - self-supervised framework for extractive question
answering over document collections. <em>JIIS</em>, <em>62</em>(6),
1725–1747. (<a
href="https://doi.org/10.1007/s10844-024-00869-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question Answering is one of the most relevant areas in the field of Natural Language Processing, rapidly evolving with promising results due to the increasing availability of suitable datasets and the advent of new technologies, such as Generative Models. This article introduces SESAME, a Self-supervised framework for Extractive queStion Answering over docuMent collEctions. SESAME aims to enhance open-domain question answering systems (ODQA) by leveraging domain adaptation with synthetic datasets, enabling efficient question answering over private document collections with low resource usage. The framework incorporates recent advances with large language models, and an efficient hybrid method for context retrieval. We conducted several sets of experiments with the Machine Reading for Question Answering (MRQA) 2019 Shared Task datasets, FAQuAD - a Brazilian Portuguese reading comprehension dataset, Wikipedia, and Retrieval-Augmented Generation Benchmark, to demonstrate SESAME’s effectiveness. The results indicate that SESAME’s domain adaptation using synthetic data significantly improves QA performance, generalizes across different domains and languages, and competes with or surpasses state-of-the-art systems in ODQA. Finally, SESAME is an open-source tool, and all code, datasets and experimental data are available for public use in our repository.},
  archive      = {J_JIIS},
  author       = {Batista, Vitor A. and Gomes, Diogo S. M. and Evsukoff, Alexandre},
  doi          = {10.1007/s10844-024-00869-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1725-1747},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {SESAME - self-supervised framework for extractive question answering over document collections},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving graph collaborative filtering with view explorer
for social recommendation. <em>JIIS</em>, <em>62</em>(6), 1703–1724. (<a
href="https://doi.org/10.1007/s10844-024-00865-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommender systems (SRS) have garnered adequate attention due to the supplementary information provided by social network, which aids in making recommendations. However, social network information contains noise, which can be detrimental to recommendation performance. Current social recommendation models are deficient in feature validation and extraction of social data. To fill that gap, we propose a novel model called Social View Explorer Collaborative Filtering (SVE-CF) which aims to extract significant consistent signals from the noisy social network. First, SVE-CF correlates users’ social and interaction behaviors, creating follow, joint, and interaction views to represent all interaction patterns. Second, it samples unlabeled examples from users to assess consistency across the three views, assigning pseudo-labels as evidence of social homophily. Third, it selects top-k pseudo-labels to amplify significant consistent signals and minimize noise through tri-view joint learning. Extensive experiments are conducted to demonstrate the effectiveness of the proposed model over the commonly used state-of-the-art (SOTA) methods.},
  archive      = {J_JIIS},
  author       = {Duan, Yongrui and Tu, Yijun and Lu, Yusheng and Wang, Xiaofeng},
  doi          = {10.1007/s10844-024-00865-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1703-1724},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Improving graph collaborative filtering with view explorer for social recommendation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generative adversarial meta-learning knowledge graph
completion for large-scale complex knowledge graphs. <em>JIIS</em>,
<em>62</em>(6), 1685–1701. (<a
href="https://doi.org/10.1007/s10844-024-00860-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study of large-scale complex knowledge graphs, due to the incompleteness of knowledge and the existence of low-frequency knowledge samples, existing knowledge graph complementation methods are often limited by the amount of data and ignore the complex semantic information. To solve this problem, this paper proposes a knowledge graph completion method CGAML based on the combination of Conditional Generative Adversarial Network and Meta-Learning, which utilizes the hierarchical background knowledge as the basis and introduces conditional variables in the Generative Adversarial Network to represent the required semantic information to constrain the semantic attributes of the generated knowledge. In addition, we design a meta-learning multi-task framework to embed Conditional Generative Adversarial Networks into the meta-learning process and propose local constraints and global gradient optimization strategies to quickly adapt to new tasks and improve computational efficiency. Empirically, our method demonstrates superior performance in realizing few-shot link prediction when compared to existing representative methods.},
  archive      = {J_JIIS},
  author       = {Tong, Weiming and Chu, Xu and Li, Zhongwei and Tan, Liguo and Zhao, Jinxiao and Pan, Feng},
  doi          = {10.1007/s10844-024-00860-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1685-1701},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Generative adversarial meta-learning knowledge graph completion for large-scale complex knowledge graphs},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aspect sentiment triplet extraction based on data
augmentation and task feedback. <em>JIIS</em>, <em>62</em>(6),
1659–1683. (<a
href="https://doi.org/10.1007/s10844-024-00855-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect sentiment triplet extraction (ASTE), which focuses on mining the triplets (aspect, opinion, sentiment), is a complex and integrated subtask in aspect-based sentiment analysis. It is widely used in market research, product design and promotion, online comment analysis, and so on. Although significant progress has been achieved in existing methods, several challenges remain, such as data scarcity and the separation of span extraction and sentiment classification. Therefore, this paper adds data augmentation and task feedback based on the bidirectional machine reading comprehension model. Before training the model, the data augmentation module applies mask prediction and mark replacement to enrich the data. Span extraction and sentiment classification are two tasks during ASTE. We adopt the direct span extraction method with one classifier to avoid the error accumulation caused by multiple classifiers and to improve the adaptive ability between different datasets. In addition, we fuse the text features derived from the above two tasks for sentiment classification. Based on the feature fusion, the task feedback module is established to alleviate the task separation. Extensive experiments verify the effectiveness of our method. The code is available at https://github.com/zhenzhen313/BMRC-with-DA-and-TF .},
  archive      = {J_JIIS},
  author       = {Liu, Shu and Lu, Tingting and Li, Kaiwen and Liu, Weihua},
  doi          = {10.1007/s10844-024-00855-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1659-1683},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Aspect sentiment triplet extraction based on data augmentation and task feedback},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the clarity of questions in community question
answering networks. <em>JIIS</em>, <em>62</em>(6), 1631–1658. (<a
href="https://doi.org/10.1007/s10844-024-00847-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every day, thousands of questions are asked on the Community Question Answering network, making these questions and answers extremely valuable for information seekers around the world. However, a significant proportion of these questions do not elicit proper answers. There are several reasons for this, with the lack of clarity in questions being one of the most crucial factors. In this study, our primary focus is on enhancing the clarity of unclear questions in Community Question Answering networks. In the first step, DistilBERT, which uses Siamese and triplet network structures for meaningful sentence embeddings, is combined with HDBSCAN, effective in diverse noise datasets and less sensitive to density variations, to extract unique features from each question. Questions were then categorized as clear or unclear using an Extremely Randomized Trees ensemble model, known for its robust resistance to class imbalance, with more than 90% accuracy. Next, efforts were made to extract information that could enhance the clarity of unclear questions by comparing them with similar, clearer questions using Dynamic Time Warping, a versatile technique suitable for time series analyses in information systems and applicable across various domains. Finally, the extracted information was incorporated into the feature vector of unclear questions based on histogram-coverage methods to enhance their clarity. When a question is made clearer, the missing information and its importance are shown to the questioner. This enables the questioner to be aware of the missing information and facilitates them in clarifying the question.},
  archive      = {J_JIIS},
  author       = {Khabbazan, Alireza and Abin, Ahmad Ali and Vu, Viet-Vu},
  doi          = {10.1007/s10844-024-00847-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1631-1658},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Improving the clarity of questions in community question answering networks},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conversing with business process-aware large language
models: The BPLLM framework. <em>JIIS</em>, <em>62</em>(6), 1607–1629.
(<a href="https://doi.org/10.1007/s10844-024-00898-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, process-aware Decision Support Systems (DSSs) have been enhanced with AI functionalities to facilitate quick and informed decision-making. In this context, AI-Augmented Business Process Management Systems have emerged as innovative human-centric information systems, blending flexibility, autonomy, and conversational capability. Large Language Models (LLMs) have significantly boosted such systems, showcasing remarkable natural language processing capabilities across various tasks. Despite the potential of LLMs to support human decisions in business contexts, empirical validations of their effectiveness for process-aware decision support are scarce in the literature. In this paper, we propose the Business Process Large Language Model (BPLLM) framework, a novel approach for enacting actionable conversations with human workers. BPLLM couples Retrieval-Augmented Generation with fine-tuning, to enrich process-specific knowledge. Additionally, a process-aware chunking approach is incorporated to enhance the BPLLM pipeline. We evaluated the approach in various experimental scenarios to assess its ability to generate accurate and contextually relevant answers to users’ questions. The empirical study shows the promising performance of the framework in identifying the presence of particular activities and sequence flows within the considered process model, offering insights into its potential for enhancing process-aware DSSs.},
  archive      = {J_JIIS},
  author       = {Bernardi, Mario Luca and Casciani, Angelo and Cimitile, Marta and Marrella, Andrea},
  doi          = {10.1007/s10844-024-00898-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1607-1629},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Conversing with business process-aware large language models: The BPLLM framework},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-view subspace text clustering. <em>JIIS</em>,
<em>62</em>(6), 1583–1606. (<a
href="https://doi.org/10.1007/s10844-024-00897-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text clustering has become an important challenge in artificial intelligence since several applications require to automatically organize documents into homogeneous topics. Given the availability of several text representation models, text documents can be organized through a multi-view text clustering approach. In this context, we propose a new subspace multi-view text clustering method (MVSTC). The proposed method offers a rich representation of text by integrating several models to detect different aspects of text such as syntactic, topic, and semantic features. MVSTC is capable of discovering latent correlations between documents by projecting the data onto a topological map. MVSTC seeks a subspace representation based on a low-rank and sparse representation to capture the global and local structure of multi-view textual data. Extensive experiments on real text data sets demonstrate that our method outperforms the existing multi-view clustering methods in terms of several evaluation metrics.},
  archive      = {J_JIIS},
  author       = {Fraj, Maha and HajKacem, Mohamed Aymen Ben and Essoussi, Nadia},
  doi          = {10.1007/s10844-024-00897-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1583-1606},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Multi-view subspace text clustering},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CONCORD: Enhancing COVID-19 research with weak-supervision
based numerical claim extraction. <em>JIIS</em>, <em>62</em>(6),
1559–1581. (<a
href="https://doi.org/10.1007/s10844-024-00885-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 Numerical Claims Open Research Dataset (CONCORD) is a comprehensive, open-source dataset that extracts numerical claims from academic papers on COVID-19 research. A weak-supervision model is employed for this extraction, taking advantage of its white-box, explainable nature and reduced computational and annotation costs compared to transformer-based models. This model uses labelling functions such as pattern matching, external knowledge bases, phrase matching, and third-party models to generate labels, with an aggregator function handling contradictory labels. Evaluated against established baselines, the model achieved a weighted F1-score of 0.932 and a micro F1-score of 0.930. While transformer-based models achieve comparable results, the explainability of weak-supervision offers distinct advantages. Additionally, generative LLMs were tested to understand their effectiveness in extracting numerical claims, highlighting the impact of prompt engineering on performance. CONCORD contains approximately 200,000 numerical claims from over 57,000 COVID-19 research articles, serving as a valuable resource for tracking developments in COVID-19 research. This dataset, coupled with the weak-supervision approach, provides researchers with a significant tool for advancing COVID-19 research and showcases the potential of these methodologies in the broader biomedical field.},
  archive      = {J_JIIS},
  author       = {Shah, Dhwanil and Shah, Krish and Jagani, Manan and Shah, Agam and Chaudhury, Bhaskar},
  doi          = {10.1007/s10844-024-00885-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1559-1581},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {CONCORD: Enhancing COVID-19 research with weak-supervision based numerical claim extraction},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). DIAMANTE: A data-centric semantic segmentation approach to
map tree dieback induced by bark beetle infestations via satellite
images. <em>JIIS</em>, <em>62</em>(6), 1531–1558. (<a
href="https://doi.org/10.1007/s10844-024-00877-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forest tree dieback inventory has a crucial role in improving forest management strategies. This inventory is traditionally performed by forests through laborious and time-consuming human assessment of individual trees. On the other hand, the large amount of Earth satellite data that are publicly available with the Copernicus program and can be processed through advanced deep learning techniques has recently been established as an alternative to field surveys for forest tree dieback tasks. However, to realize its full potential, deep learning requires a deep understanding of satellite data since the data collection and preparation steps are essential as the model development step. In this study, we explore the performance of a data-centric semantic segmentation approach to detect forest tree dieback events due to bark beetle infestation in satellite images. The proposed approach prepares a multisensor data set collected using both the SAR Sentinel-1 sensor and the optical Sentinel-2 sensor and uses this dataset to train a multisensor semantic segmentation model. The evaluation shows the effectiveness of the proposed approach in a real inventory case study that regards non-overlapping forest scenes from the Northeast of France acquired in October 2018. The selected scenes host bark beetle infestation hotspots of different sizes, which originate from the mass reproduction of the bark beetle in the 2018 infestation.},
  archive      = {J_JIIS},
  author       = {Andresini, Giuseppina and Appice, Annalisa and Ienco, Dino and Recchia, Vito},
  doi          = {10.1007/s10844-024-00877-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1531-1558},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {DIAMANTE: A data-centric semantic segmentation approach to map tree dieback induced by bark beetle infestations via satellite images},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing data preparation: Insights from a time series case
study. <em>JIIS</em>, <em>62</em>(6), 1503–1530. (<a
href="https://doi.org/10.1007/s10844-024-00867-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data play a key role in AI systems that support decision-making processes. Data-centric AI highlights the importance of having high-quality input data to obtain reliable results. However, well-preparing data for machine learning is becoming difficult due to the variety of data quality issues and available data preparation tasks. For this reason, approaches that help users in performing this demanding phase are needed. This work proposes DIANA, a framework for data-centric AI to support data exploration and preparation, suggesting suitable cleaning tasks to obtain valuable analysis results. We design an adaptive self-service environment that can handle the analysis and preparation of different types of sources, i.e., tabular, and streaming data. The central component of our framework is a knowledge base that collects evidence related to the effectiveness of the data preparation actions along with the type of input data and the considered machine learning model. In this paper, we first describe the framework, the knowledge base model, and its enrichment process. Then, we show the experiments conducted to enrich the knowledge base in a particular case study: time series data streams.},
  archive      = {J_JIIS},
  author       = {Sancricca, Camilla and Siracusa, Giovanni and Cappiello, Cinzia},
  doi          = {10.1007/s10844-024-00867-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1503-1530},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing data preparation: Insights from a time series case study},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-centric AI. <em>JIIS</em>, <em>62</em>(6), 1493–1502.
(<a href="https://doi.org/10.1007/s10844-024-00901-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of Artificial Intelligence (AI) has been driven by two core components: data and algorithms. Historically, AI research has predominantly followed the Model-Centric paradigm, which focuses on developing and refining models, while often treating data as static. This approach has led to the creation of increasingly sophisticated algorithms, which demand vast amounts of manually labeled and meticulously curated data. However, as data becomes central to AI development, it is also emerging as a significant bottleneck. The Data-Centric AI (DCAI) paradigm shifts the focus towards improving data quality, enabling the achievement of accuracy levels that are unattainable with Model-Centric approaches alone. This special issue presents recent advancements in DCAI, offering insights into the paradigm and exploring future research directions, aiming to contextualize the contributions included in this issue.},
  archive      = {J_JIIS},
  author       = {Malerba, Donato and Pasquadibisceglie, Vincenzo},
  doi          = {10.1007/s10844-024-00901-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1493-1502},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Data-centric AI},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heuristic approaches for non-exhaustive pattern-based change
detection in dynamic networks. <em>JIIS</em>, <em>62</em>(5), 1455–1492.
(<a href="https://doi.org/10.1007/s10844-024-00866-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic networks are ubiquitous in many domains for modelling evolving graph-structured data and detecting changes allows us to understand the dynamic of the domain represented. A category of computational solutions is represented by the pattern-based change detectors (PBCDs), which are non-parametric unsupervised change detection methods based on observed changes in sets of frequent patterns over time. Patterns have the ability to depict the structural information of the sub-graphs, becoming a useful tool in the interpretation of the changes. Existing PBCDs often rely on exhaustive mining, which corresponds to the worst-case exponential time complexity, making this category of algorithms inefficient in practice. In fact, in such a case, the pattern mining process is even more time-consuming and inefficient due to the combinatorial explosion of the sub-graph pattern space caused by the inherent complexity of the graph structure. Non-exhaustive search strategies can represent a possible approach to this problem, also because not all the possible frequent patterns contribute to changes in the time-evolving data. In this paper, we investigate the viability of different heuristic approaches which prevent the complete exploration of the search space, by returning a concise set of sub-graph patterns (compared to the exhaustive case). The heuristics differ on the criterion used to select representative patterns. The results obtained on real-world and synthetic dynamic networks show that these solutions are effective, when mining patterns, and even more accurate when detecting changes.},
  archive      = {J_JIIS},
  author       = {Loglisci, Corrado and Impedovo, Angelo and Calders, Toon and Ceci, Michelangelo},
  doi          = {10.1007/s10844-024-00866-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1455-1492},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Heuristic approaches for non-exhaustive pattern-based change detection in dynamic networks},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving search and rescue planning and resource allocation
through case-based and concept-based retrieval. <em>JIIS</em>,
<em>62</em>(5), 1431–1453. (<a
href="https://doi.org/10.1007/s10844-024-00861-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for effective and efficient search and rescue operations is more important than ever as the frequency and severity of disasters increase due to the escalating effects of climate change. Recognizing the value of personal knowledge and past experiences of experts, in this paper, we present findings of an investigation of how past knowledge and experts’ experiences can be effectively integrated with current search and rescue practices to improve rescue planning and resource allocation. A special focus is on investigating and demonstrating the potential associated with integrating knowledge graphs and case-based reasoning as a viable approach for search and rescue decision support. As part of our investigation, we have implemented a demonstrator system using a Norwegian search and rescue dataset and case-based and concept-based similarity retrieval. The main contribution of the paper is insight into how case-based and concept-based retrieval services can be designed to improve the effectiveness of search and rescue planning. To evaluate the validity of ranked cases in terms of how they align with the existing knowledge and insights of search and rescue experts, we use evaluation measures such as precision and recall. In our evaluation, we observed that attributes, such as the rescue operation type, have high precision, while the precision associated with the objects involved is relatively low. Central findings from our evaluation process are that knowledge-based creation, as well as case- and concept-based similarity retrieval services, can be beneficial in optimizing search and rescue planning time and allocating appropriate resources according to search and rescue incident descriptions.},
  archive      = {J_JIIS},
  author       = {Nasar, Wajeeha and Torres, Ricardo da Silva and Gundersen, Odd Erik and Karlsen, Anniken Susanne Thoresen},
  doi          = {10.1007/s10844-024-00861-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1431-1453},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Improving search and rescue planning and resource allocation through case-based and concept-based retrieval},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An interpretable model for sepsis prediction using
multi-objective rule extraction. <em>JIIS</em>, <em>62</em>(5),
1403–1429. (<a
href="https://doi.org/10.1007/s10844-024-00859-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a leading cause of death among intensive care unit patients. Early sepsis prediction, which primarily relies on advanced artificial intelligence technology, is an important phase in sepsis management. In previous sepsis prediction research, tremendous time and effort are spent in building high accurate tree ensemble models. However, due to the “black box” nature of tree ensemble models, clinicians typically reluctant to use them in clinical practice. To fill the gap, a novel multi-objective rule extraction method is proposed to trade off the predictive performance and the interpretability of tree ensemble model for sepsis prediction. The proposed method encompasses two phases: rule extraction utilizing a novel multi-objective binary differential evolution algorithm (MOBDE), and rule simplification employing a greedy heuristic method. In addition, rule extraction incorporates a Tchebycheff-based competitive learning strategy and a binary mutation operation aimed at enhancing the search ability of MOBDE. Rule simplification leveraging the proposed greedy heuristic method, streamlines the extracted rules from the previous phase by eliminating redundant constraints. The 2019 PhysioNet/CinC Challenge dataset, a well-known dataset in sepsis prediction, is used to evaluate the effectiveness of the proposed method. The experimental results show that the proposed method is more interpretable and has higher accuracy than some of commonly used rule-based models for sepsis prediction. The proposed method can be popularized to practical sepsis treatment, and assist doctors in sepsis diagnosis with the comprehensible decision-making support.},
  archive      = {J_JIIS},
  author       = {Chen, Mingzhou and Huo, Jiazhen and Duan, Yongrui},
  doi          = {10.1007/s10844-024-00859-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1403-1429},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {An interpretable model for sepsis prediction using multi-objective rule extraction},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relation representation based on private and shared features
for adaptive few-shot link prediction. <em>JIIS</em>, <em>62</em>(5),
1375–1401. (<a
href="https://doi.org/10.1007/s10844-024-00856-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Knowledge Graphs (KGs) provide great value in many applications, they are often incomplete with many missing facts. KG Completion (KGC) is a popular technique for knowledge supplement. However, there are two fundamental challenges for KGC. One challenge is that few entity pairs are often available for most relations, and the other is that there exists complex relations, including one-to-many (1-N), many-to-one (N-1), and many-to-many (N-N). In this paper, we propose a new model to accomplish Few-shot KG Completion (FKGC) under complex relations, which is called Relation representation based on Private and Shared features for Adaptive few-shot link prediction (RPSA). In this model, we utilize the hierarchical attention mechanism for extracting the essential and crucial hidden information regarding the entity’s neighborhood so as to improve its representation. To enhance the representation of few-shot relations, we extract the private features (i.e., unique feature of each entity pair that represents the few-shot relation) and shared features (i.e., one or more commonalities among a few entity pairs that represent the few-shot relation). Specifically, a private feature extractor is used to extract the private semantic feature of the few-shot relation in the entity pair. After that, we design a shared feature extractor to extract the shared semantic features among a few reference entity pairs in the few-shot relation. Moreover, an adaptive aggregator aggregates several representations of the few-shot relation about the query. We conduct experiments on three datasets, including NELL-One, CoDEx-S-One and CoDEx-M-One datasets. According to the experimental results, the RPSA’s performance is better than that of the existing FKGC models. In addition, the RPSA model can also handle complex relations well, even in the few-shot scenario.},
  archive      = {J_JIIS},
  author       = {Zhang, Weiwen and Yang, Canqun},
  doi          = {10.1007/s10844-024-00856-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1375-1401},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Relation representation based on private and shared features for adaptive few-shot link prediction},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ERABQS: Entity resolution based on active machine learning
and balancing query strategy. <em>JIIS</em>, <em>62</em>(5), 1347–1373.
(<a href="https://doi.org/10.1007/s10844-024-00853-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity Resolution (ER) is a crucial process in the field of data management and integration. The primary goal of ER is to identify different profiles (or records) that refer to the same real-world entity across databases. The challenging problem is that labeling a large sample of profiles can be very expensive and time-consuming. Active Machine Learning (ActiveML) addresses this issue by selecting the most representative or informative profiles pairs to be labeled. The informativeness is determined by the capacity to diminish the uncertainty of the model. Conversely, representativeness evaluates whether a selected instance effectively reflects the overall input patterns of unlabeled data. Traditional ActiveML techniques typically rely on one strategy, Which may severely restrict the performance of the ActiveML process and lead to slow convergence. Especially in ER problems with a lack of initial training data. In this paper, we overcame this issue by inventing an approach for balancing the two above strategies. The implemented solution named EBEES (Epsilon-based Balancing Exploration and Exploitation Strategy), Which contains two variations: Adaptive- $$\epsilon $$ and $$\epsilon $$ -decreasing. We evaluated the EBEES on twelve datasets. Comparing the EBEES strategy against the state-of-the-art methods, without an initial training data, showed an enhanced performance in terms of F1-score, model stability, and rapid convergence.},
  archive      = {J_JIIS},
  author       = {Mourad, Jabrane and Hiba, Tabbaa and Yassir, Rochd and Imad, Hafidi},
  doi          = {10.1007/s10844-024-00853-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1347-1373},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {ERABQS: Entity resolution based on active machine learning and balancing query strategy},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring and mitigating gender bias in book recommender
systems with explicit feedback. <em>JIIS</em>, <em>62</em>(5),
1325–1346. (<a
href="https://doi.org/10.1007/s10844-023-00827-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are indispensable because they influence our day-to-day behavior and decisions by giving us personalized suggestions. Services like Kindle, YouTube, and Netflix depend heavily on the performance of their recommender systems to ensure that their users have a good experience and to increase revenues. Despite their popularity, it has been shown that recommender systems reproduce and amplify the bias present in the real world. The resulting feedback creates a self-perpetuating loop that deteriorates the user experience and results in homogenizing recommendations over time. Further, biased recommendations can also reinforce stereotypes based on gender or ethnicity, thus reinforcing the filter bubbles that we live in. In this paper, we address the problem of gender bias in recommender systems with explicit feedback. We propose a model to quantify the gender bias present in book rating datasets and in the recommendations produced by the recommender systems. Our main contribution is to provide a principled approach to mitigate the bias being produced in the recommendations. We theoretically show that the proposed approach provides unbiased recommendations despite biased data. Through empirical evaluation of publicly available book rating datasets, we further show that the proposed model can significantly reduce bias without significant impact on accuracy and outperforms the existing model in terms of bias. Our method is model-agnostic and can be applied to any recommender system. To demonstrate the performance of our model, we present the results on four recommender algorithms, two from the K-nearest neighbors family, UserKNN and ItemKNN, and the other two from the matrix factorization family, Alternating Least Square and Singular Value Decomposition. The extensive simulations of various recommender algorithms show the generality of the proposed approach.},
  archive      = {J_JIIS},
  author       = {Saxena, Shrikant and Jain, Shweta},
  doi          = {10.1007/s10844-023-00827-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1325-1346},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Exploring and mitigating gender bias in book recommender systems with explicit feedback},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-aware adaptive graph network for commonsense
question answering. <em>JIIS</em>, <em>62</em>(5), 1305–1324. (<a
href="https://doi.org/10.1007/s10844-024-00854-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense Question Answering (CQA) aims to select the correct answers to common knowledge questions. Most existing approaches focus on integrating external knowledge graph (KG) representations with question context representations to facilitate reasoning. However, the approaches cannot effectively select the correct answer due to (i) the incomplete reasoning chains when using knowledge graphs as external knowledge, and (ii) the insufficient understanding of semantic information of the question during the reasoning process. Here we propose a novel model, KA-AGN. First, we utilize a joint representation of dependency parse trees and language models to describe QA pairs. Next, we introduce question semantic information as nodes into a knowledge subgraph and compute the correlations between nodes using adaptive graph networks. Finally, bidirectional attention and graph pruning are employed to update the question representation and the knowledge subgraph representation. To evaluate the performance of our method, we conducted experiments on two widely used benchmark datasets: CommonsenseQA and OpenBookQA. The ablation experiment results demonstrate the effectiveness of the adaptive graph network in enhancing reasoning chains, while showing the ability of the joint representation of dependency parse trees and language models to correctly understand question semantics. Our code is publicly available at https://github.com/agfsghfdhg/KAAGN-main .},
  archive      = {J_JIIS},
  author       = {Kang, Long and Li, Xiaoge and An, Xiaochun},
  doi          = {10.1007/s10844-024-00854-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1305-1324},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Knowledge-aware adaptive graph network for commonsense question answering},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A motif-based probabilistic approach for community detection
in complex networks. <em>JIIS</em>, <em>62</em>(5), 1285–1303. (<a
href="https://doi.org/10.1007/s10844-024-00850-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in complex networks is an important task for discovering hidden information in network analysis. Neighborhood density between nodes is one of the fundamental indicators of community presence in the network. A community with a high edge density will have correlations between nodes that extend beyond their immediate neighbors, denoted by motifs. Motifs are repetitive patterns of edges observed with high frequency in the network. We proposed the PCDMS method (Probabilistic Community Detection with Motif Structure) that detects communities by estimating the triangular motif in the network. This study employs structural density between nodes, a key concept in graph analysis. The proposed model has the advantage of using a probabilistic generative model that calculates the latent parameters of the probabilistic model and determines the community based on the likelihood of triangular motifs. The relationship between observing two pairs of nodes in multiple communities leads to an increasing likelihood estimation of the existence of a motif structure between them. The output of the proposed model is the intensity of each node in the communities. The efficiency and validity of the proposed method are evaluated through experimental work on both synthetic and real-world networks; the findings will show that the community identified by the proposed method is more accurate and dense than other algorithms with modularity, NMI, and F1score evaluation metrics.},
  archive      = {J_JIIS},
  author       = {Hajibabaei, Hossein and Seydi, Vahid and Koochari, Abbas},
  doi          = {10.1007/s10844-024-00850-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1285-1303},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A motif-based probabilistic approach for community detection in complex networks},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Early detection of fake news on emerging topics through weak
supervision. <em>JIIS</em>, <em>62</em>(5), 1263–1284. (<a
href="https://doi.org/10.1007/s10844-024-00852-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a methodology for the early detection of fake news on emerging topics through the innovative application of weak supervision. Traditional techniques for fake news detection often rely on fact-checkers or supervised learning with labeled data, which is not readily available for emerging topics. To address this, we introduce the Weakly Supervised Text Classification framework (WeSTeC), an end-to-end solution designed to programmatically label large-scale text datasets within specific domains and train supervised text classifiers using the assigned labels. The proposed framework automatically generates labeling functions through multiple weak labeling strategies and eliminates underperforming ones. Labels assigned through the generated labeling functions are then used to fine-tune a pre-trained RoBERTa classifier for fake news detection. By using a weakly labeled dataset, which contains fake news related to the emerging topic, the trained fake news detection model becomes specialized for the topic under consideration. We explore both semi-supervision and domain adaptation setups, utilizing small amounts of labeled data and labeled data from other domains, respectively. The fake news classification model generated by the proposed framework excels when compared with all baselines in both setups. In addition, when compared to its fully supervised counterpart, our fake news detection model trained through weak labels achieves accuracy within 1%, emphasizing the robustness of the proposed framework’s weak labeling capabilities.},
  archive      = {J_JIIS},
  author       = {Akdag, Serhat Hakki and Cicekli, Nihan Kesim},
  doi          = {10.1007/s10844-024-00852-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1263-1284},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Early detection of fake news on emerging topics through weak supervision},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid recognition framework of crucial seed spreaders in
complex networks with neighborhood overlap. <em>JIIS</em>,
<em>62</em>(5), 1239–1262. (<a
href="https://doi.org/10.1007/s10844-024-00849-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing crucial seed spreaders of complex networks is an open issue that studies the dynamic spreading process and analyzes the performance of networks. However, most of the findings design the hierarchical model based on nodes’ degree such as Kshell decomposition for obtaining global information, and identifying effects brought by the weight value of each layer is coarse. In addition, local structural information fails to be effectively captured when neighborhood nodes are sometimes unconnected in the hierarchical structure. To solve these issues, in this paper, we design a novel hierarchical structure based on the shortest path distance by using the interpretative structure model and determine influence weights of each layer. Furthermore, we also design the local neighborhood overlap coefficient and the local index based on the overlap (LIO) by considering two conditions of connected and unconnected neighborhood nodes in the hierarchical structure. For reaching a comprehensive recognition and finding crucial seed spreaders precisely, we introduce influence weights vector, local evaluation index matrix after normalization and the weight vector of local indexes into a new hybrid recognition framework. The proposed method adopts a series of indicators, including the monotonicity relation, Susceptible-Infected-Susceptible model, complementary cumulative distribution function, Kendall’s coefficient, spreading scale ratio and average shortest path length, to execute corresponding experiments and evaluate the diffusion ability in different datasets. Results demonstrate that, our method outperforms involved algorithms in the recognition effects and spreading capability.},
  archive      = {J_JIIS},
  author       = {Tong, Tianchi and Wang, Min and Yuan, Wenying and Dong, Qian and Sun, Jinsheng and Jiang, Yuan},
  doi          = {10.1007/s10844-024-00849-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1239-1262},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A hybrid recognition framework of crucial seed spreaders in complex networks with neighborhood overlap},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing sentiment and emotion translation of review text
through MLM knowledge integration in NMT. <em>JIIS</em>, <em>62</em>(5),
1213–1237. (<a
href="https://doi.org/10.1007/s10844-024-00843-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Producing a high-quality review translation is a multifaceted process. It goes beyond successful semantic transfer and requires conveying the original message’s tone and style in a way that resonates with the target audience, whether they are human readers or Natural Language Processing (NLP) applications. Capturing these subtle nuances of the review text demands a deeper understanding and better encoding of the source message. In order to achieve this goal, we explore the use of self-supervised masked language modeling (MLM) and a variant called polarity masked language modeling (p-MLM) as auxiliary tasks in a multi-learning setup. MLM is widely recognized for its ability to capture rich linguistic representations of the input and has been shown to achieve state-of-the-art accuracy in various language understanding tasks. Motivated by its effectiveness, in this paper we adopt joint learning, combining the neural machine translation (NMT) task with source polarity-masked language modeling within a shared embedding space to induce a deeper understanding of the emotional nuances of the text. We analyze the results and observe that our multi-task model indeed exhibits a better understanding of linguistic concepts like sentiment and emotion. Intriguingly, this is achieved even without explicit training on sentiment-annotated or domain-specific sentiment corpora. Our multi-task NMT model consistently improves the translation quality of affect sentences from diverse domains in three language pairs.},
  archive      = {J_JIIS},
  author       = {Kumari, Divya and Ekbal, Asif},
  doi          = {10.1007/s10844-024-00843-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1213-1237},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing sentiment and emotion translation of review text through MLM knowledge integration in NMT},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). CMC-MMR: Multi-modal recommendation model with cross-modal
correction. <em>JIIS</em>, <em>62</em>(5), 1187–1211. (<a
href="https://doi.org/10.1007/s10844-024-00848-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal recommendation using multi-modal features (e.g., image and text features) has received significant attention and has been shown to have more effective recommendation. However, there are currently the following problems with multi-modal recommendation: (1) Multi-modal recommendation often handle individual modes’ raw data directly, leading to noise affecting the model’s effectiveness and the failure to explore interconnections between modes; (2) Different users have different preferences. It’s impractical to treat all modalities equally, as this could interfere with the model’s ability to make recommendation. To address the above problems, this paper proposes a Multi-modal recommendation model with cross-modal correction (CMC-MMR). Firstly, in order to reduce the effect of noise in the raw data and to take full advantage of the relationships between modes, we designed a cross-modal correction module to denoise and correct the modes using a cross-modal correction mechanism; Secondly, the similarity between the same modalities of each item is used as a benchmark to build item-item graphs for each modality, and user-item graphs with degree-sensitive pruning strategies are also built to mine higher-order information; Finally, we designed a self-supervised task to adaptively mine user preferences for modality. We conducted comparative experiments with eleven baseline models on four real-world datasets. The experimental results show that CMC-MMR improves 6.202%, 4.975% , 6.054% and 11.368% on average on the four datasets, respectively, demonstrates the effectiveness of CMC-MMR.},
  archive      = {J_JIIS},
  author       = {Wang, YuBin and Xia, HongBin and Liu, Yuan},
  doi          = {10.1007/s10844-024-00848-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1187-1211},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {CMC-MMR: Multi-modal recommendation model with cross-modal correction},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Querying knowledge graphs through positive and negative
examples and feedback. <em>JIIS</em>, <em>62</em>(5), 1165–1186. (<a
href="https://doi.org/10.1007/s10844-024-00846-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The formulation of structured queries over Knowledge Graphs is not an easy task. To alleviate this problem, we propose a novel interactive method for SPARQL query formulation, for enabling users (plain and advanced) to formulate gradually queries by providing examples and various kinds of positive and negative feedback, in a manner that does not pre-suppose knowledge of the query language or the contents of the Knowledge Graph. In comparison to other example-based query approaches, distinctive features of our approach is the support of negative examples, and the positive/negative feedback on the generated constraints. We detail the algorithmic aspect and we present an interactive user interface that implements the approach. The application of the model on real datasets from DBpedia (Movies, Actors) and other datasets (scientific papers), showcases the feasibility and the effectiveness of the approach. A task-based evaluation that included users that are not familiar with SPARQL, provided positive evidence that the interaction is easy-to-grasp and enabled most users to formulate the desired queries.},
  archive      = {J_JIIS},
  author       = {Akritidis, Akritas and Tzitzikas, Yannis},
  doi          = {10.1007/s10844-024-00846-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1165-1186},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Querying knowledge graphs through positive and negative examples and feedback},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sports recommender systems: Overview and research
directions. <em>JIIS</em>, <em>62</em>(4), 1125–1164. (<a
href="https://doi.org/10.1007/s10844-024-00857-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports recommender systems receive an increasing attention due to their potential of fostering healthy living, improving personal well-being, and increasing performances in sports. These systems support people in sports, for example, by the recommendation of healthy and performance-boosting food items, the recommendation of training practices, talent and team recommendation, and the recommendation of specific tactics in competitions. With applications in the virtual world, for example, the recommendation of maps or opponents in e-sports, these systems already transcend conventional sports scenarios where physical presence is needed. On the basis of different examples, we present an overview of sports recommender systems applications and techniques. Overall, we analyze the related state-of-the-art and discuss future research directions.},
  archive      = {J_JIIS},
  author       = {Felfernig, Alexander and Wundara, Manfred and Tran, Thi Ngoc Trang and Le, Viet-Man and Lubos, Sebastian and Polat-Erdeniz, Seda},
  doi          = {10.1007/s10844-024-00857-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1125-1164},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Sports recommender systems: Overview and research directions},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using an explainable machine learning approach to prioritize
factors contributing to healthcare professionals’ burnout.
<em>JIIS</em>, <em>62</em>(4), 1113–1124. (<a
href="https://doi.org/10.1007/s10844-024-00862-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burnout in healthcare professionals (HCPs) is a global concern. Few studies use theoretical and conceptual models to assess work system stressors contributing to HCP burnout. A survey consisting of demographic characteristics and work system stressors based on the National Academy of Medicine’s theoretical model was administered to 589 HCPs (participation rate: 64%). We compare four classifiers with four feature selection methods to predict HCP burnout. We use SHapley Additive exPlanations (SHAP) to prioritize key work system stressors contributing to HCP burnout and explain the predictions from the best model, random forest using recursive feature elimination (AUC: 0.75). Time pressure, work-life integration, inadequate technology, administrative burden, values and expectations, professional relationships, lack of recognition for QI activities, moral distress, and patient factors are the work system stressors that have the highest impact on predicting HCP burnout. Identifying and prioritizing key factors to mitigate HCP burnout is important for the healthcare system to allocate resources and improve patient safety and quality of care.},
  archive      = {J_JIIS},
  author       = {Pillai, Malvika and Liu, Chao Chin and Kwong, Elizabeth and Kratzke, Ian and Charguia, Nadia and Mazur, Lukasz and Adapa, Karthik},
  doi          = {10.1007/s10844-024-00862-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1113-1124},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Using an explainable machine learning approach to prioritize factors contributing to healthcare professionals’ burnout},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensemble of temporal transformers for financial time series.
<em>JIIS</em>, <em>62</em>(4), 1087–1111. (<a
href="https://doi.org/10.1007/s10844-024-00851-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of price forecasts is important for financial market trading strategies and portfolio management. Compared to traditional models such as ARIMA and other state-of-the-art deep learning techniques, temporal Transformers with similarity embedding perform better for multi-horizon forecasts in financial time series, as they account for the conditional heteroscedasticity inherent in financial data. Despite this, the methods employed in generating these forecasts must be optimized to achieve the highest possible level of precision. One approach that has been shown to improve the accuracy of machine learning models is ensemble techniques. To this end, we present an ensemble approach that efficiently utilizes the available data over an extended timeframe. Our ensemble combines multiple temporal Transformer models learned within sliding windows, thereby making optimal use of the data. As combination methods, along with an averaging approach, we also introduced a stacking meta-learner that leverages a quantile estimator to determine the optimal weights for combining the base models of smaller windows. By decomposing the constituent time series of an extended timeframe, we optimize the utilization of the series for financial deep learning. This simplifies the training process of a temporal Transformer model over an extended time series while achieving better performance, particularly when accounting for the non-constant variance of financial time series. Our experiments, conducted across volatile and non-volatile extrapolation periods, using 20 companies from the Dow Jones Industrial Average show more than 40% and 60% improvement in predictive performance compared to the baseline temporal Transformer.},
  archive      = {J_JIIS},
  author       = {Olorunnimbe, Kenniy and Viktor, Herna},
  doi          = {10.1007/s10844-024-00851-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1087-1111},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Ensemble of temporal transformers for financial time series},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Audio super-resolution via vision transformer.
<em>JIIS</em>, <em>62</em>(4), 1071–1085. (<a
href="https://doi.org/10.1007/s10844-023-00833-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio super-resolution refers to techniques that improve the audio signals quality, usually by exploiting bandwidth extension methods, whereby audio enhancement is obtained by expanding the phase and the spectrogram of the input audio traces. These techniques are therefore much significant for all those cases where audio traces miss relevant parts of the audible spectrum. In several cases, the given input signal contains the low-band frequencies (the easiest to capture with low-quality recording instruments) whereas the high-band must be generated. In this paper, we illustrate techniques implemented into a system for bandwidth extension that works on musical tracks and generates the high-band frequencies starting from the low-band ones. The system, called ViT Super-resolution ( $$\textit{ViT-SR}$$ ), features an architecture based on a Generative Adversarial Network and Vision Transformer model. In particular, two versions of the architecture will be presented in this paper, that work on different input frequency ranges. Experiments, which are accounted for in the paper, prove the effectiveness of our approach. In particular, the objective has been attained to demonstrate that it is possible to faithfully reconstruct the high-band signal of an audio file having only its low-band spectrum available as the input, therewith including the usually difficult to synthetically generate harmonics occurring in the audio tracks, which significantly contribute to the final perceived sound quality.},
  archive      = {J_JIIS},
  author       = {Nisticò, Simona and Palopoli, Luigi and Romano, Adele Pia},
  doi          = {10.1007/s10844-023-00833-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1071-1085},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Audio super-resolution via vision transformer},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging distant supervision and deep learning for twitter
sentiment and emotion classification. <em>JIIS</em>, <em>62</em>(4),
1045–1070. (<a
href="https://doi.org/10.1007/s10844-024-00845-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, various applications across industries, healthcare, and security have begun adopting automatic sentiment analysis and emotion detection in short texts, such as posts from social media. Twitter stands out as one of the most popular online social media platforms due to its easy, unique, and advanced accessibility using the API. On the other hand, supervised learning is the most widely used paradigm for tasks involving sentiment polarity and fine-grained emotion detection in short and informal texts, such as Twitter posts. However, supervised learning models are data-hungry and heavily reliant on abundant labeled data, which remains a challenge. This study aims to address this challenge by creating a large-scale real-world dataset of 17.5 million tweets. A distant supervision approach relying on emojis available in tweets is applied to label tweets corresponding to Ekman’s six basic emotions. Additionally, we conducted a series of experiments using various conventional machine learning models and deep learning, including transformer-based models, on our dataset to establish baseline results. The experimental results and an extensive ablation analysis on the dataset showed that BiLSTM with FastText and an attention mechanism outperforms other models in both classification tasks, achieving an F1-score of 70.92% for sentiment classification and 54.85% for emotion detection.},
  archive      = {J_JIIS},
  author       = {Kastrati, Muhamet and Kastrati, Zenun and Shariq Imran, Ali and Biba, Marenglen},
  doi          = {10.1007/s10844-024-00845-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1045-1070},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Leveraging distant supervision and deep learning for twitter sentiment and emotion classification},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Movie tag prediction: An extreme multi-label multi-modal
transformer-based solution with explanation. <em>JIIS</em>,
<em>62</em>(4), 1021–1043. (<a
href="https://doi.org/10.1007/s10844-023-00836-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing rich and accurate metadata for indexing media content is a crucial problem for all the companies offering streaming entertainment services. These metadata are commonly employed to enhance search engine results and feed recommendation algorithms to improve the matching with user interests. However, the problem of labeling multimedia content with informative tags is challenging as the labeling procedure, manually performed by domain experts, is time-consuming and prone to error. Recently, the adoption of AI-based methods has been demonstrated to be an effective approach for automating this complex process. However, developing an effective solution requires coping with different challenging issues, such as data noise and the scarcity of labeled examples during the training phase. In this work, we address these challenges by introducing a Transformer-based framework for multi-modal multi-label classification enriched with model prediction explanation capabilities. These explanations can help the domain expert to understand the system’s predictions. Experimentation conducted on two real test cases demonstrates its effectiveness.},
  archive      = {J_JIIS},
  author       = {Guarascio, Massimo and Minici, Marco and Pisani, Francesco Sergio and De Francesco, Erika and Lambardi, Pasquale},
  doi          = {10.1007/s10844-023-00836-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1021-1043},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Movie tag prediction: An extreme multi-label multi-modal transformer-based solution with explanation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data- &amp; compute-efficient deviance mining via active
learning and fast ensembles. <em>JIIS</em>, <em>62</em>(4), 995–1019.
(<a href="https://doi.org/10.1007/s10844-024-00841-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting deviant traces in business process logs is crucial for modern organizations, given the harmful impact of deviant behaviours (e.g., attacks or faults). However, training a Deviance Prediction Model (DPM) by solely using supervised learning methods is impractical in scenarios where only few examples are labelled. To address this challenge, we propose an Active-Learning-based approach that leverages multiple DPMs and a temporal ensembling method that can train and merge them in a few training epochs. Our method needs expert supervision only for a few unlabelled traces exhibiting high prediction uncertainty. Tests on real data (of either complete or ongoing process instances) confirm the effectiveness of the proposed approach.},
  archive      = {J_JIIS},
  author       = {Folino, Francesco and Folino, Gianluigi and Guarascio, Massimo and Pontieri, Luigi},
  doi          = {10.1007/s10844-024-00841-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {995-1019},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Data- &amp; compute-efficient deviance mining via active learning and fast ensembles},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). How can text mining improve the explainability of food
security situations? <em>JIIS</em>, <em>62</em>(4), 971–994. (<a
href="https://doi.org/10.1007/s10844-023-00832-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food Security (FS) is a major concern in West Africa, particularly in Burkina Faso, which has been the epicenter of a humanitarian crisis since the beginning of this century. Early warning systems for FS and famines rely mainly on numerical data for their analyses, whereas textual data, which are more complex to process, are rarely used. However, this data is easy to access and represents a source of relevant information that is complementary to commonly used data sources. This study explores methods for obtaining the explanatory context associated with FS from textual data. Based on a corpus of local newspaper articles, we analyze FS over the last ten years in Burkina Faso. We propose an original and dedicated pipeline that combines different textual analysis approaches to obtain an explanatory model evaluated on real-world and large-scale data. The results of our analyses have proven how our approach provides significant results that offer distinct and complementary qualitative information on food security and its spatial and temporal characteristics.},
  archive      = {J_JIIS},
  author       = {Deléglise, Hugo and Bégué, Agnès and Interdonato, Roberto and Maître d’Hôtel, Elodie and Roche, Mathieu and Teisseire, Maguelonne},
  doi          = {10.1007/s10844-023-00832-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {971-994},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {How can text mining improve the explainability of food security situations?},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bayesian-neural-networks framework for scaling posterior
distributions over different-curation datasets. <em>JIIS</em>,
<em>62</em>(4), 951–969. (<a
href="https://doi.org/10.1007/s10844-023-00837-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose and experimentally assess an innovative framework for scaling posterior distributions over different-curation datasets, based on Bayesian-Neural-Networks (BNN). Another innovation of our proposed study consists in enhancing the accuracy of the Bayesian classifier via intelligent sampling algorithms. The proposed methodology is relevant in emerging applicative settings, such as provenance detection and analysis and cybercrime. Our contributions are complemented by a comprehensive experimental evaluation and analysis over both static and dynamic image datasets. Derived results confirm the successful application of our proposed methodology to emerging big data analytics settings.},
  archive      = {J_JIIS},
  author       = {Cuzzocrea, Alfredo and Baldo, Alessandro and Fadda, Edoardo},
  doi          = {10.1007/s10844-023-00837-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {951-969},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A bayesian-neural-networks framework for scaling posterior distributions over different-curation datasets},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning autoencoder ensembles for detecting malware hidden
communications in IoT ecosystems. <em>JIIS</em>, <em>62</em>(4),
925–949. (<a href="https://doi.org/10.1007/s10844-023-00819-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern IoT ecosystems are the preferred target of threat actors wanting to incorporate resource-constrained devices within a botnet or leak sensitive information. A major research effort is then devoted to create countermeasures for mitigating attacks, for instance, hardware-level verification mechanisms or effective network intrusion detection frameworks. Unfortunately, advanced malware is often endowed with the ability of cloaking communications within network traffic, e.g., to orchestrate compromised IoT nodes or exfiltrate data without being noticed. Therefore, this paper showcases how different autoencoder-based architectures can spot the presence of malicious communications hidden in conversations, especially in the TTL of IPv4 traffic. To conduct tests, this work considers IoT traffic traces gathered in a real setting and the presence of an attacker deploying two hiding schemes (i.e., naive and “elusive” approaches). Collected results showcase the effectiveness of our method as well as the feasibility of deploying autoencoders in production-quality IoT settings.},
  archive      = {J_JIIS},
  author       = {Cassavia, Nunziato and Caviglione, Luca and Guarascio, Massimo and Liguori, Angelica and Zuppelli, Marco},
  doi          = {10.1007/s10844-023-00819-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {925-949},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Learning autoencoder ensembles for detecting malware hidden communications in IoT ecosystems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing anomaly detectors with LatentOut. <em>JIIS</em>,
<em>62</em>(4), 905–923. (<a
href="https://doi.org/10.1007/s10844-023-00829-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {$${{\textbf{Latent}}\varvec{Out}}$$ is a recently introduced algorithm for unsupervised anomaly detection which enhances latent space-based neural methods, namely (Variational) Autoencoders, GANomaly and ANOGan architectures. The main idea behind it is to exploit both the latent space and the baseline score of these architectures in order to provide a refined anomaly score performing density estimation in the augmented latent-space/baseline-score feature space. In this paper we investigate the performance of $${{\textbf{Latent}}\varvec{Out}}$$ acting as a one-class classifier and we experiment the combination of $${{\textbf{Latent}}\varvec{Out}}$$ with GAAL architectures, a novel type of Generative Adversarial Networks for unsupervised anomaly detection. Moreover, we show that the feature space induced by $${{\textbf{Latent}}\varvec{Out}}$$ has the characteristic to enhance the separation between normal and anomalous data. Indeed, we prove that standard data mining outlier detection methods perform better when applied on this novel augmented latent space rather than on the original data space.},
  archive      = {J_JIIS},
  author       = {Angiulli, Fabrizio and Fassetti, Fabio and Ferragina, Luca},
  doi          = {10.1007/s10844-023-00829-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {905-923},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing anomaly detectors with LatentOut},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A transformer-based framework for predicting geomagnetic
indices with uncertainty quantification. <em>JIIS</em>, <em>62</em>(4),
887–903. (<a href="https://doi.org/10.1007/s10844-023-00828-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geomagnetic activities have a crucial impact on Earth, which can affect spacecraft and electrical power grids. Geospace scientists use a geomagnetic index, called the Kp index, to describe the overall level of geomagnetic activity. This index is an important indicator of disturbances in the Earth’s magnetic field and is used by the U.S. Space Weather Prediction Center as an alert and warning service for users who may be affected by the disturbances. Another commonly used index, called the ap index, is converted from the Kp index. Early and accurate prediction of the Kp and ap indices is essential for preparedness and disaster risk management. In this paper, we present a deep learning framework, named GNet, to perform short-term forecasting of the Kp and ap indices. Specifically, GNet takes as input time series of solar wind parameters’ values, provided by NASA’s Space Science Data Coordinated Archive, and predicts as output the Kp and ap indices respectively at time point $$\varvec{t + w}$$ hours for a given time point $$\varvec{t}$$ where $$\varvec{w}$$ ranges from 1 to 9. GNet combines transformer encoder blocks with Bayesian inference, which is capable of quantifying both aleatoric uncertainty (data uncertainty) and epistemic uncertainty (model uncertainty) in making predictions. Experimental results show that GNet outperforms closely related machine learning methods in terms of the root mean square error and R-squared score. Furthermore, GNet can provide both data and model uncertainty quantification results, which the existing methods cannot offer. To our knowledge, this is the first time that Bayesian transformers have been used for geomagnetic activity prediction.},
  archive      = {J_JIIS},
  author       = {Abduallah, Yasser and Wang, Jason T. L. and Wang, Haimin and Jing, Ju},
  doi          = {10.1007/s10844-023-00828-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {887-903},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A transformer-based framework for predicting geomagnetic indices with uncertainty quantification},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special issue on intelligent systems. <em>JIIS</em>,
<em>62</em>(4), 883–886. (<a
href="https://doi.org/10.1007/s10844-024-00868-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIIS},
  author       = {Ceci, Michelangelo and Flesca, Sergio and Manco, Giuseppe and Masciari, Elio},
  doi          = {10.1007/s10844-024-00868-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {883-886},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Special issue on intelligent systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semantic-enhanced reasoning question answering over temporal
knowledge graphs. <em>JIIS</em>, <em>62</em>(3), 859–881. (<a
href="https://doi.org/10.1007/s10844-024-00840-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question Answering Over Temporal Knowledge Graphs (TKGQA) is an important topic in question answering. TKGQA focuses on accurately understanding questions involving temporal constraints and retrieving accurate answers from knowledge graphs. In previous research, the hierarchical structure of question contexts and the constraints imposed by temporal information on different sentence components have been overlooked. In this paper, we propose a framework called “Semantic-Enhanced Reasoning Question Answering” (SERQA) to tackle this problem. First, we adopt a pretrained language model (LM) to obtain the question relation representation vector. Then, we leverage syntactic information from the constituent tree and dependency tree, in combination with Masked Self-Attention (MSA), to enhance temporal constraint features. Finally, we integrate the temporal constraint features into the question relation representation using an information fusion function for answer prediction. Experimental results demonstrate that SERQA achieves better performance on the CRONQUESTIONS and ImConstrainedQuestions datasets. In comparison with existing temporal KGQA methods, our model exhibits outstanding performance in comprehending temporal constraint questions. The ablation experiments verified the effectiveness of combining the constituent tree and the dependency tree with MSA in question answering.},
  archive      = {J_JIIS},
  author       = {Du, Chenyang and Li, Xiaoge and Li, Zhongyang},
  doi          = {10.1007/s10844-024-00840-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {859-881},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Semantic-enhanced reasoning question answering over temporal knowledge graphs},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). KIMedQA: Towards building knowledge-enhanced medical QA
models. <em>JIIS</em>, <em>62</em>(3), 833–858. (<a
href="https://doi.org/10.1007/s10844-024-00844-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical question-answering systems require the ability to extract accurate, concise, and comprehensive answers. They will better comprehend the complex text and produce helpful answers if they can reason on the explicit constraints described in the question’s textual context and the implicit, pertinent knowledge of the medical world. Integrating Knowledge Graphs (KG) with Language Models (LMs) is a common approach to incorporating structured information sources. However, effectively combining and reasoning over KG representations and language context remains an open question. To address this, we propose the Knowledge Infused Medical Question Answering system (KIMedQA), which employs two techniques viz. relevant knowledge graph selection and pruning of the large-scale graph to handle Vector Space Inconsistent (VSI) and Excessive Knowledge Information (EKI). The representation of the query and context are then combined with the pruned knowledge network using a pre-trained language model to generate an informed answer. Finally, we demonstrate through in-depth empirical evaluation that our suggested strategy provides cutting-edge outcomes on two benchmark datasets, namely MASH-QA and COVID-QA. We also compared our results to ChatGPT, a robust and very powerful generative model, and discovered that our model outperforms ChatGPT according to the F1 Score and human evaluation metrics such as adequacy.},
  archive      = {J_JIIS},
  author       = {Zafar, Aizan and Sahoo, Sovan Kumar and Varshney, Deeksha and Das, Amitava and Ekbal, Asif},
  doi          = {10.1007/s10844-024-00844-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {833-858},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {KIMedQA: Towards building knowledge-enhanced medical QA models},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel technique using graph neural networks and relevance
scoring to improve the performance of knowledge graph-based question
answering systems. <em>JIIS</em>, <em>62</em>(3), 809–832. (<a
href="https://doi.org/10.1007/s10844-023-00839-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Knowledge Graph-based Question Answering (KGQA) system attempts to answer a given natural language question using a knowledge graph (KG) rather than from text data. The current KGQA methods attempt to determine whether there is an explicit relationship between the entities in the question and a well-structured relationship between them in the KG. However, such strategies are difficult to build and train, limiting their consistency and versatility. The use of language models such as BERT has aided in the advancement of natural language question answering. In this paper, we present a novel Graph Neural Network(GNN) based approach with relevance scoring for improving KGQA. GNNs use the weight of nodes and edges to influence the information propagation while updating the node features in the network. The suggested method comprises subgraph construction, weighing of nodes and edges, and pruning processes to obtain meaningful answers. BERT-based GNN is used to build subgraph node embeddings. We tested the influence of weighting for both nodes and edges and observed that the system performs better for weighted graphs than unweighted graphs. Additionally, we experimented with several GNN convolutional layers and obtainined improved results by combining GENeralised Graph Convolution (GENConv) with node weights for simple questions. Extensive testing on benchmark datasets confirmed the effectiveness of the proposed model in comparison to state-of-the-art KGQA systems.},
  archive      = {J_JIIS},
  author       = {Thambi, Sincy V. and Reghu Raj, P. C.},
  doi          = {10.1007/s10844-023-00839-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {809-832},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A novel technique using graph neural networks and relevance scoring to improve the performance of knowledge graph-based question answering systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A qualitative analysis of knowledge graphs in recommendation
scenarios through semantics-aware autoencoders. <em>JIIS</em>,
<em>62</em>(3), 787–807. (<a
href="https://doi.org/10.1007/s10844-023-00830-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) have already proven their strength as a source of high-quality information for different tasks such as data integration, search, text summarization, and personalization. Another prominent research field that has been benefiting from the adoption of KGs is that of Recommender Systems (RSs). Feeding a RS with data coming from a KG improves recommendation accuracy, diversity, and novelty, and paves the way to the creation of interpretable models that can be used for explanations. This possibility of combining a KG with a RS raises the question whether such an addition can be performed in a plug-and-play fashion – also with respect to the recommendation domain – or whether each combination needs a careful evaluation. To investigate such a question, we consider all possible combinations of (i) three recommendation tasks (books, music, movies); (ii) three recommendation models fed with data from a KG (and in particular, a semantics-aware deep learning model, that we discuss in detail), compared with three baseline models without KG addition; (iii) two main encyclopedic KGs freely available on the Web: DBpedia and Wikidata. Supported by an extensive experimental evaluation, we show the final results in terms of accuracy and diversity of the various combinations, highlighting that the injection of knowledge does not always pay off. Moreover, we show how the choice of the KG, and the form of data in it, affect the results, depending on the recommendation domain and the learning model.},
  archive      = {J_JIIS},
  author       = {Bellini, Vito and Di Sciascio, Eugenio and Donini, Francesco Maria and Pomo, Claudio and Ragone, Azzurra and Schiavone, Angelo},
  doi          = {10.1007/s10844-023-00830-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {787-807},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A qualitative analysis of knowledge graphs in recommendation scenarios through semantics-aware autoencoders},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sentiment analysis of twitter data to detect and predict
political leniency using natural language processing. <em>JIIS</em>,
<em>62</em>(3), 765–785. (<a
href="https://doi.org/10.1007/s10844-024-00842-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyses Twitter data to detect the political lean of a profile by extracting and classifying sentiments expressed through tweets. The work utilizes natural language processing, augmented with sentiment analysis algorithms and machine learning techniques, to classify specific keywords. The proposed methodology initially performs data pre-processing, followed by multi-aspect sentiment analysis for computing the sentiment score of the extracted keywords, for precisely classifying users into various clusters based on similarity score with respect to a sample user in each cluster. The proposed technique also predicts the sentiment of a profile towards unknown keywords and gauges the bias of an unidentified user towards political events or social issues. The proposed technique was tested on Twitter dataset with 1.72 million tweets taken from over 10,000 profiles and was able to successfully identify the political leniency of the user profiles with 99% confidence level, and also on a synthetic dataset with 2500 tweets, where the predicted accuracy and F1 score were 0.99 and 0.985 respectively, and 0.97 and 0.975 when neutral users were also considered for classification. The paper could also identify the impact of political decisions on various clusters, by analyzing the shift in the number of users belonging to the different clusters.},
  archive      = {J_JIIS},
  author       = {Kowsik, V. V. Sai and Yashwanth, L. and Harish, Srivatsan and Kishore, A. and S, Renji and Jose, Arun Cyril and V, Dhanyamol M},
  doi          = {10.1007/s10844-024-00842-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {765-785},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Sentiment analysis of twitter data to detect and predict political leniency using natural language processing},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing the fairness of offensive memes detection models
by mitigating unintended political bias. <em>JIIS</em>, <em>62</em>(3),
735–763. (<a href="https://doi.org/10.1007/s10844-023-00834-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the critical challenge of detecting and mitigating unintended political bias in offensive meme detection. Political memes are a powerful tool that can be used to influence public opinion and disrupt voters’ mindsets. However, current visual-linguistic models for offensive meme detection exhibit unintended bias and struggle to accurately classify non-offensive and offensive memes. This can harm the fairness of the democratic process either by targeting minority groups or promoting harmful political ideologies. With Hindi being the fifth most spoken language globally and having a significant number of native speakers, it is essential to detect and remove Hindi-based offensive memes to foster a fair and equitable democratic process. To address these concerns, we propose three debiasing techniques to mitigate the overrepresentation of majority group perspectives while addressing the suppression of minority opinions in political discourse. To support our approach, we curate a comprehensive dataset called Pol_Off_Meme, designed especially for the Hindi language. Empirical analysis of this dataset demonstrates the efficacy of our proposed debiasing techniques in reducing political bias in internet memes, promoting a fair and equitable democratic environment. Our debiased model, named $$DRTIM^{Adv}_{Att}$$ , exhibited superior performance compared to the CLIP-based baseline model. It achieved a significant improvement of +9.72% in the F1-score while reducing the False Positive Rate Difference (FPRD) by -16% and the False Negative Rate Difference (FNRD) by -14.01%. Our efforts strive to cultivate a more informed and inclusive political discourse, ensuring that all opinions, irrespective of their majority or minority status, receive adequate attention and representation.},
  archive      = {J_JIIS},
  author       = {Kumari, Gitanjali and Sinha, Anubhav and Ekbal, Asif and Chatterjee, Arindam and N, Vinutha B},
  doi          = {10.1007/s10844-023-00834-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {735-763},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing the fairness of offensive memes detection models by mitigating unintended political bias},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TSUNAMI - an explainable PPM approach for customer churn
prediction in evolving retail data environments. <em>JIIS</em>,
<em>62</em>(3), 705–733. (<a
href="https://doi.org/10.1007/s10844-023-00838-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retail companies are greatly interested in performing continuous monitoring of purchase traces of customers, to identify weak customers and take the necessary actions to improve customer satisfaction and ensure their revenues remain unaffected. In this paper, we formulate the customer churn prediction problem as a Predictive Process Monitoring (PPM) problem to be addressed under possible dynamic conditions of evolving retail data environments. To this aim, we propose TSUNAMI as a PPM approach to monitor the customer loyalty in the retail sector. It processes online the sale receipt stream produced by customers of a retail business company and learns a deep neural model to early detect possible purchase customer traces that will outcome in future churners. In addition, the proposed approach integrates a mechanism to detect concept drifts in customer purchase traces and adapts the deep neural model to concept drifts. Finally, to make decisions of customer purchase monitoring explainable to potential stakeholders, we analyse Shapley values of decisions, to explain which characteristics of the customer purchase traces are the most relevant for disentangling churners from non-churners and how these characteristics have possibly changed over time. Experiments with two benchmark retail data sets explore the effectiveness of the proposed approach.},
  archive      = {J_JIIS},
  author       = {Pasquadibisceglie, Vincenzo and Appice, Annalisa and Ieva, Giuseppe and Malerba, Donato},
  doi          = {10.1007/s10844-023-00838-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {705-733},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {TSUNAMI - an explainable PPM approach for customer churn prediction in evolving retail data environments},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parallel computing framework for real-time moving object
detection on high resolution videos. <em>JIIS</em>, <em>62</em>(3),
683–704. (<a href="https://doi.org/10.1007/s10844-022-00737-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphic Processing Units (GPUs) are becoming very important in the present day. Their high computational capabilities with high speed and accuracy are making them a very strong force in communication engineering. In recent times, their need has increased tremendously due to the increasing range of applications. Video surveillance is an important field where very heavy computations are needed to be done on videos to perfectly detect the motion of an object in suspicious situations. The various analyses on video can be used to extract information and process data to generate actionable intelligent conclusions. However, CPUs fail to deliver real time results when it comes to high-resolution videos from a large number of cameras simultaneously. Thankfully, there is a lot of graphic hardware available nowadays, which comprises powerful hardware processors often intended to process data in parallel and so greatly accelerates the processes being done on them. An accelerated algorithm is required for processing petabytes of data from security cameras and video surveillance satellites and that in real time. In this paper, we propose a method of using GPUs in detecting the motion of an object at different junctions in video surveillance. The results show a great gain in performance when the proposed method runs on GPUs and CPUs in terms of speed as well as accuracy. The new parallel processing approaches are developed on each phase of the algorithm to enhance the efficiency of the system. Proposed algorithm achieved an average speed up of 50.094x for lower resolution video frames (320 × 240,720 × 480,1024 × 768) and 38.012x for higher resolution video frames (1360 × 768,1920 × 1080) on GPU, which is superior to CPU processing.},
  archive      = {J_JIIS},
  author       = {Hashmi, Mohammad Farukh and Ayele, Eskinder and Naik, Banoth Thulasya and Keskar, Avinash G.},
  doi          = {10.1007/s10844-022-00737-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {683-704},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A parallel computing framework for real-time moving object detection on high resolution videos},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable computer interactive education system based on
large-scale multimedia data analysis. <em>JIIS</em>, <em>62</em>(3),
665–682. (<a href="https://doi.org/10.1007/s10844-022-00719-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive teaching resources will cause serious teaching efficiency problems for online teaching, and traditional online teaching models are even inferior to traditional classroom teaching in terms of teaching effects. Based on this, this paper analyzes massive educational resources and builds a scalable computer interactive education system based on large-scale multimedia data analysis. Moreover, this paper sets the role of the system according to the actual teaching situation, and constructs the functional module of the system structure. In addition, this paper uses computer simulation technology to analyze interactive technology and make technical improvements to make interactive technology the core technology of the computer interactive education system, and get an extensible interactive education system based on the characteristics of network teaching. Then helps to monitor and access the performance of an interactive educational system. Furthermore, this paper designs an experiment to evaluate the performance of the computer interactive education system, which is mainly carried out from two aspects: interactive evaluation and teaching evaluation. From the experimental research results, we can see that this system can effectively improve the quality of teaching.},
  archive      = {J_JIIS},
  author       = {Zhao, Jie and Liu, Taotang and Li, Shuping},
  doi          = {10.1007/s10844-022-00719-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {665-682},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Scalable computer interactive education system based on large-scale multimedia data analysis},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Design of fully homomorphic multikey encryption scheme for
secured cloud access and storage environment. <em>JIIS</em>,
<em>62</em>(3), 641–663. (<a
href="https://doi.org/10.1007/s10844-022-00715-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud hosting is a kind of storage that enables users to access, save, and manage their data in a secure and private cloud environment. As a result of this choice, users are no longer need to maintain and build their storage infrastructure on their computers or servers. Many businesses are hesitant to embrace cloud storage because of the complexities of data privacy and security issues. An easy-to-use and secure method for cloud storage sharing and data access is proposed in this study, which may be implemented quickly and easily. This solution requires users to have a secure password and biometric data in order to function properly. Their capacity to deceive consumers into disclosing critical information to their service providers is the primary reason for this problem. Cloud storage systems must have a secure framework in place in order for users to connect to and interact with one another. Many benefits of cloud storage exist, including enabling users to store and manage their data in a safe environment. Users can regulate and manage their data security while using cloud storage services. While implementing a safe and authenticated data storage model, this article addresses the different elements that must be taken into consideration. Several procedures have been established to deal with this problem. Unfortunately, they are not sufficiently secure to prevent a wide variety of security intrusions from taking place on them. When encrypting stored cloud data, the Fully Homomorphic multikey Encryption (FHE) algorithm is utilized. They also have a vulnerability in their protocol that makes it susceptible to both user and serverside attacks. When it comes to remote access, cloud data and data sharing between geographically dispersed devices is a reliable protocol to use.},
  archive      = {J_JIIS},
  author       = {Salvakkam, Dilli Babu and Pamula, Rajendra},
  doi          = {10.1007/s10844-022-00715-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {641-663},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Design of fully homomorphic multikey encryption scheme for secured cloud access and storage environment},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classroom teaching of tourism management using multimedia
big data analysis. <em>JIIS</em>, <em>62</em>(3), 625–640. (<a
href="https://doi.org/10.1007/s10844-022-00696-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the effectiveness of tourism management classroom teaching, this article intelligentizes the teaching process of tourism management, and combines multimedia technology and big data technology to improve the teaching process. The crisis early warning system based on the image monitoring index system monitors and observes the components of the tourist destination from the perspective of tourists, and calculate the indexes based on the monitored results, so as to discover the possibility of image crisis events in time and better serve tourists. In addition, this article builds a tourism management classroom teaching system based on multimedia and big data technology on this basis, and tests the system. Through research, it can be seen that the crisis early warning system based on the image monitoring index system and the tourism management classroom teaching system based on multimedia and big data technology proposed in this paper have good practical effects.},
  archive      = {J_JIIS},
  author       = {Li, Yan and Zhang, Jieli},
  doi          = {10.1007/s10844-022-00696-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {625-640},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Classroom teaching of tourism management using multimedia big data analysis},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Frequency roughness analysis in image processing and game
design. <em>JIIS</em>, <em>62</em>(3), 605–624. (<a
href="https://doi.org/10.1007/s10844-021-00669-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous progress of science and technology, image processing techniques have been used increasingly in recent years. Image processing plays an indispensable role in the fields of computer vision, artificial intelligence, pattern recognition, and related fields. Improvements in basic algorithms and the development of new algorithms have resulted in considerable innovation and progress. This paper is devoted to finding new game applications in a branch of image processing. It introduces an analysis model proposed by the author and discusses the relationship between roughness in the frequency domain and visual image interpretation. By using the concept of roughness, we separated the image features into meaningful information and residual information and analysed the image in the frequency domain. The results were compared with those of traditional image processing methods. The starting point is the visual identification of a feature based on human interpretation. The image information was separated into meaningful features and the residual component to reduce the redundancy of the model. This allowed for a sparse representation of the feature information in the image. By analysing the meaningful features and residual components of an image separately, we established a relationship between the results and the original images. Parameters such as texture, morphology, and the degree of blurring were considered and we developed a parameter called “frequency roughness”. The algorithm incorporates the concepts of frequency and roughness and the roughness is determined in the frequency domain. The frequency roughness algorithm successfully separated the rough features in the frequency domain and calculated the residual value in an image. This model provided more accurate image processing results than comparable methods. This paper includes an analysis and game applications of the proposed model for de-blurring, image enhancement, recognition, and other image processing tasks. Some game applications were successful, whereas others require further investigation.},
  archive      = {J_JIIS},
  author       = {Li, Jiaqi},
  doi          = {10.1007/s10844-021-00669-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {605-624},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Frequency roughness analysis in image processing and game design},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable computing for large-scale multimedia data
analytics. <em>JIIS</em>, <em>62</em>(3), 601–603. (<a
href="https://doi.org/10.1007/s10844-024-00863-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIIS},
  author       = {Karuppiah, Marimuthu and Chaudhry, Shehzad Ashraf and Alsharif, Mohammed H.},
  doi          = {10.1007/s10844-024-00863-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {601-603},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Scalable computing for large-scale multimedia data analytics},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tell me what you like: Introducing natural language
preference elicitation strategies in a virtual assistant for the movie
domain. <em>JIIS</em>, <em>62</em>(2), 575–599. (<a
href="https://doi.org/10.1007/s10844-023-00835-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference elicitation is a crucial step for every recommendation algorithm. In this paper, we present a strategy that allows users to express their preferences and needs through natural language statements. In particular, our natural language preference elicitation pipeline allows users to express preferences on objective movie features (e.g., actors, directors, etc.) as well as on subjective features that are collected by mining user-written movie reviews. To validate our claims, we carried out a user study in the movie domain ( $$N=114$$ ). The main finding of our experiment is that users tend to express their preferences by using objective features, whose usage largely overcomes that of subjective features, which are more complicated to be expressed. However, when the users are able to express their preferences also in terms of subjective features, they obtain better recommendations in a lower number of conversation turns. We have also identified the main challenges that arise when users talk to the virtual assistant by using subjective features, and this paves the way for future developments of our methodology.},
  archive      = {J_JIIS},
  author       = {Musto, Cataldo and Martina, Alessandro Francesco Maria and Iovine, Andrea and Narducci, Fedelucio and de Gemmis, Marco and Semeraro, Giovanni},
  doi          = {10.1007/s10844-023-00835-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {575-599},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Tell me what you like: Introducing natural language preference elicitation strategies in a virtual assistant for the movie domain},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mutually enhanced multi-scale relation-aware graph
convolutional network for argument pair extraction. <em>JIIS</em>,
<em>62</em>(2), 555–574. (<a
href="https://doi.org/10.1007/s10844-023-00826-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Argument pair extraction (APE) is a fine-grained task of argument mining which aims to identify arguments offered by different participants in some discourse and detect interaction relationships between arguments from different participants. In recent years, many research efforts have been devoted to dealing with APE in a multi-task learning framework. Although these approaches have achieved encouraging results, they still face several challenging issues. First, different types of sentence relationships as well as different levels of information exchange among sentences are largely ignored. Second, they solely model interactions between argument pairs either in an explicit or implicit strategy, while neglecting the complementary effect of the two strategies. In this paper, we propose a novel Mutually Enhanced Multi-Scale Relation-Aware Graph Convolutional Network (MMR-GCN) for APE. Specifically, we first design a multi-scale relation-aware graph aggregation module to explicitly model the complex relationships between review and rebuttal passage sentences. In addition, we propose a mutually enhancement transformer module to implicitly and interactively enhance representations of review and rebuttal passage sentences. We experimentally validate MMR-GCN by comparing with the state-of-the-art APE methods. Experimental results show that it considerably outperforms all baseline methods, and the relative performance improvement of MMR-GCN over the best performing baseline MRC-APE in terms of F1 score reaches to 3.48% and 4.43% on the two benchmark datasets, respectively.},
  archive      = {J_JIIS},
  author       = {Zhu, Xiaofei and Liu, Yidan and Chen, Zhuo and Chen, Xu and Guo, Jiafeng and Dietze, Stefan},
  doi          = {10.1007/s10844-023-00826-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {555-574},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A mutually enhanced multi-scale relation-aware graph convolutional network for argument pair extraction},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). T-shaped expert mining: A novel approach based on skill
translation and focal loss. <em>JIIS</em>, <em>62</em>(2), 535–554. (<a
href="https://doi.org/10.1007/s10844-023-00831-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hiring knowledgeable and cost-effective individuals, who use their knowledge and expertise to boost the organization, is extremely important for organizations as they are the most valuable assets. T-shaped experts are the best option based on agile methodology. The T-shaped professional has a deep understanding of one topic and broad knowledge of several others. Compared to other types of professionals, T-shaped professionals are better communicators and cheaper to hire. Finding T-shaped experts in a given skill area requires determining each candidate’s depth of knowledge and shape of expertise. To estimate each candidate’s depth of knowledge in a given skill area, we propose a translation-based method that utilizes two attention-based skill translation models to overcome the vocabulary mismatch between skills and user documents. We also propose two new approaches based on binary cross-entropy and focal loss to determine whether each user is T-shaped. Our experiments on three collections of the StackOverflow dataset demonstrate the efficiency of our proposed method compared to the state-of-the-art approaches.},
  archive      = {J_JIIS},
  author       = {Fallahnejad, Zohreh and Karimian, Mahmood and Lashkari, Fatemeh and Beigy, Hamid},
  doi          = {10.1007/s10844-023-00831-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {535-554},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {T-shaped expert mining: A novel approach based on skill translation and focal loss},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EqBal-RS: Mitigating popularity bias in recommender systems.
<em>JIIS</em>, <em>62</em>(2), 509–534. (<a
href="https://doi.org/10.1007/s10844-023-00817-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are deployed heavily by many online platforms for better user engagement and providing recommendations. Despite being so popular, several works have shown the existence of popularity bias due to the non-random nature of missing data. Popularity bias leads to the recommendation of only a few popular items causing starvation of many non-popular items. This paper considers an easy-to-understand metric to evaluate the popularity bias as the difference between mean squared error on popular and non-popular items. Then, we propose EqBal-RS, a novel re-weighting technique that updates the weights of popular and non-popular items. Re-weighting ensures that both item sets are equally balanced during training using a trade-off function between overall loss and popularity bias. Our experiments on real-world datasets show that EqBal-RS outperforms the existing state-of-art algorithms in terms of accuracy, quality, and fairness. EqBal-RS works well on the proposed and existing popularity bias metrics and has significantly reduced runtime. The code is publicly available at https://github.com/eqbalrs/EqBalRS},
  archive      = {J_JIIS},
  author       = {Gupta, Shivam and Kaur, Kirandeep and Jain, Shweta},
  doi          = {10.1007/s10844-023-00817-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {509-534},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {EqBal-RS: Mitigating popularity bias in recommender systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BMDF-SR: Bidirectional multi-sequence decoupling fusion
method for sequential recommendation. <em>JIIS</em>, <em>62</em>(2),
485–507. (<a href="https://doi.org/10.1007/s10844-023-00825-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of sequence recommendation, contextual information has been shown to effectively improve the accuracy of predicting the user’s next interaction. However, existing studies do not consider the dependencies between contextual information and item sequences, but the contextual information is directly fusing with the item sequences, which brings the problems described below: (1) Direct fusion fuses contextual information (e.g., time and categories) with item sequences which increases the dimensionality of the embedding matrix, thus increasing the complexity of the attention computation. (2) The attention computation of heterogeneous context information in the same embedding matrix makes it difficult for the recommendation model to distinguish this heterogeneous information. Therefore, we propose a bidirectional multi-sequence decoupling fusion method for sequence recommendation (BMDF-SR) to address the above issues. To establish the dependencies between temporal context sequences and item sequences, we first treat temporal contextual information as independent sequences and build bidirectional dependencies between contextual information sequences and item sequences via a three-layer seq2seq structure. Then, we perform attention computation independently for context sequences such as categories, and the complexity of attention computation can be effectively reduced by this decoupled attention computation. Moreover, since the attention computation is performed separately for each sequence, the interference between heterogeneous information during sequence fusion is reduced, allowing the model to effectively discriminate between different types of information. Extensive experiments on four real-world datasets show that the BMDF-SR method outperforms popular models.},
  archive      = {J_JIIS},
  author       = {Gao, Aohua and Qin, Jiwei and Ma, Chao and Wang, Tao},
  doi          = {10.1007/s10844-023-00825-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {485-507},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {BMDF-SR: Bidirectional multi-sequence decoupling fusion method for sequential recommendation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding a needle in a haystack: Insights on feature
selection for classification tasks. <em>JIIS</em>, <em>62</em>(2),
459–483. (<a href="https://doi.org/10.1007/s10844-023-00823-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of Big Data has resulted in an overwhelming increase in the volume of data available, including the number of features. Feature selection, the process of selecting relevant features and discarding irrelevant ones, has been successfully used to reduce the dimensionality of datasets. However, with numerous feature selection approaches in the literature, determining the best strategy for a specific problem is not straightforward. In this study, we compare the performance of various feature selection approaches to a random selection to identify the most effective strategy for a given type of problem. We use a large number of datasets to cover a broad range of real-world challenges. We evaluate the performance of seven popular feature selection approaches and five classifiers. Our findings show that feature selection is a valuable tool in machine learning and that correlation-based feature selection is the most effective strategy regardless of the scenario. Additionally, we found that using improper thresholds with ranker approaches produces results as poor as randomly selecting a subset of features.},
  archive      = {J_JIIS},
  author       = {Morán-Fernández, Laura and Bolón-Canedo, Verónica},
  doi          = {10.1007/s10844-023-00823-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {459-483},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Finding a needle in a haystack: Insights on feature selection for classification tasks},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A novel algorithm for mining couples of enhanced association
rules based on the number of output couples and its application.
<em>JIIS</em>, <em>62</em>(2), 431–458. (<a
href="https://doi.org/10.1007/s10844-023-00820-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Besides the need for more advanced predictive methods, there is increasing demand for easily interpretable results. Couples of enhanced association rules (a generalization of association rules/apriori/frequent itemsets) are excellent candidates for this task. They can be interpreted in various ways, subgroup discovery being an example. A typical result in rule mining is that there are too low or too many rules in the resulting ruleset. Analysts must usually iterate 5–15 times to get a reasonable number of rules. Inspired by research in a similar area of frequent itemsets to simplify input and parameter-free frequent itemsets, we have proposed a novel algorithm that finds rules based not on parameters like support and confidence but the best rules by a given range of required rule count in output. We propose this algorithm for couples of rules – SD4ft-Miner procedure and benefits from a brand new implementation of methods of mechanizing hypothesis formation in Python called Cleverminer that allows easy implementation of this algorithm. We have verified the algorithm by several applications on eight public data sets. Our original case was a case study, and it was also the reason why we developed the algorithm. However, implementation is in Python, and the algorithm itself can be used on a broader class of methods in any language. The algorithm iterates quickly, in all experiments we needed a maximum of 10 iterations. Possible enhancements to this algorithm are also outlined.},
  archive      = {J_JIIS},
  author       = {Máša, Petr and Rauch, Jan},
  doi          = {10.1007/s10844-023-00820-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {431-458},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A novel algorithm for mining couples of enhanced association rules based on the number of output couples and its application},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Session-aware recommender system using double deep
reinforcement learning. <em>JIIS</em>, <em>62</em>(2), 403–429. (<a
href="https://doi.org/10.1007/s10844-023-00824-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-aware recommender systems capture user-specific preferences that emerge within multiple user sessions by leveraging the sequential nature of user interactions. Existing session-aware recommendation methods face challenges in finding the right balance between exploration and exploitation leading to less diverse recommendations and also suffering from overestimation bias. This bias problem refers to the tendency for value estimates to be higher than their true values resulting in slower convergence, suboptimal, and less diverse recommendations. This paper proposes a Double Deep Q-network based session-aware recommender system, DDQN-SaRS, which takes care of the overestimation bias and generates diverse recommendations capturing the user’s dynamic interests. The proposed system works in two phases. The first phase generates embedding for users, items, and sessions using a Graph Convolutional Network (GCN). The obtained embedding vectors are then given to Double Deep Q-Network (DDQN), a Double Deep Reinforcement Learning (DDRL) technique for suggesting items of interest to the user(s) in the second phase. DDQN decouples the task of action selection and action evaluation by utilizing two networks viz. main and target networks and resolves the overestimation bias problem while maintaining diversity in recommendations. The proposed system learns recommendation policies and corresponding rewards from a pure offline setting. It is validated on two real-world datasets: Diginetica from the CIKM Cup Challenge 2016 and Retailrocket from the Kaggle competition. Experimental results show that our proposed system, DDQN-SaRS outperformed various baseline algorithms viz. S-POP, Item-KNN, GRU4Rec, STAMP, HRNN, NSAR,IDSR, and GNN-GNF.},
  archive      = {J_JIIS},
  author       = {Khurana, Purnima and Gupta, Bhavna and Sharma, Ravish and Bedi, Punam},
  doi          = {10.1007/s10844-023-00824-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {403-429},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Session-aware recommender system using double deep reinforcement learning},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging neighborhood and path information for influential
spreaders recognition in complex networks. <em>JIIS</em>,
<em>62</em>(2), 377–401. (<a
href="https://doi.org/10.1007/s10844-023-00822-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of influential spreaders has become a growing area of interest within network sciences due to its critical implications in understanding the robustness and vulnerability of complex networks. There is a significant degree of focus on the factors that dictate the decision-making process for identifying these influential spreaders in highly complex networks, given their crucial role in network performance and security. Previous research methodologies have offered a deep understanding of the importance of spreaders, also referred to as nodes. These methods, however, have primarily depended on either neighborhood or path information to identify these spreaders. They have often studied local network data, or adopted a more broad-based, global view of the network. Such an approach may not provide a comprehensive understanding of the overall network structure and the relationships between nodes. Addressing this limitation, our research introduces Neighborhood and Path Information-based Centrality (NPIC) algorithm. This innovative centrality algorithm combines both neighborhood and path information to identify influential spreaders in a complex network. By incorporating these two significant aspects, NPIC provides a more holistic analysis of network centrality, enabling a more accurate identification of influential spreaders. We have subjected NPIC to rigorous testing using numerous simulations on both real and artificially-created datasets. These simulations applied an epidemic model to calculate the spreading efficiency of each node within its given environment. Our simulations, conducted across a wide range of synthetic and real-world datasets, demonstrated that NPIC outperforms existing methodologies in identifying influential spreaders in corresponding networks.},
  archive      = {J_JIIS},
  author       = {Ullah, Aman and Sheng, JinFang and Wang, Bin and Din, Salah Ud and Khan, Nasrullah},
  doi          = {10.1007/s10844-023-00822-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {377-401},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Leveraging neighborhood and path information for influential spreaders recognition in complex networks},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). I-s <span class="math display"><sup>2</sup></span> FND: A
novel interpretable self-ensembled semi-supervised model based on
transformers for fake news detection. <em>JIIS</em>, <em>62</em>(2),
355–375. (<a href="https://doi.org/10.1007/s10844-023-00821-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the serious consequences of social media usage is fake information dissemination that locomotes society towards negativity. Existing solutions focus on supervised fake news detection models, which requires extensive labelled data. In this paper, we deal with two different problems of fake news detection such as (1) Detecting fake news with limited annotated data and (2) Interpretability of the proposed model on fake news detection. We address these issues by designing an Interpretable Self Ensembled Semi-Supervised Fake News Detection Model (I-S $$^2$$ FND). In I-S $$^2$$ FND, the model learns the enhanced representations of labelled and unlabelled fake news by incorporating an adaptive pseudo-labelling mechanism on unlabelled data. Moreover, interpretation of the model on text using the gradients improves the identification of essential words in the content of fake news. Based on the experimental findings, it is evident that the proposed model outperforms existing state-of-the-art models by approximately 5% in terms of accuracy when trained with only a limited amount of labeled data across different datasets.},
  archive      = {J_JIIS},
  author       = {U, Shivani Sri Varshini and R, Praneetha Sree and M, Srinivas and R.B.V., Subramanyam},
  doi          = {10.1007/s10844-023-00821-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {355-375},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {I-S $$^2$$ FND: A novel interpretable self-ensembled semi-supervised model based on transformers for fake news detection},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Developing and validating an electronic health record-based
frailty index in pre-operative settings using machine learning.
<em>JIIS</em>, <em>62</em>(2), 339–354. (<a
href="https://doi.org/10.1007/s10844-023-00818-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frailty is associated with poor post-operative outcomes. However, frailty assessments in clinical practice are challenging due to the need for more resources and pragmatic complexities. We aimed to create a pre-operative frailty ascertainment using machine learning (ML) from electronic health record (EHR) data that is built on the Fried frailty phenotype. We leveraged a research database of 8,999 individuals aged 65 years and above who underwent a surgery. Healthcare providers administered a pre-operative frailty assessment using the Fried frailty phenotype. We built ML models to predict pre-operative frailty as a whole and by surgical service. We used the SHapley Additive exPlanations (SHAP) to interpret the results. Comparisons with the accumulated deficit approach were made using Pearson’s correlation coefficients and McNemar’s test. The ML model achieved an AUC of 0.74 in predicting pre-operative frailty phenotype. The ML models’ predictive power varied by surgical services, with AUC ranging from 0.63 to 0.81. SHAP showed that advanced age, anemia, chronic pulmonary disease, and literacy deficit were the most important features of pre-operative frailty. The ML model had similar performance to the accumulated deficit approach, with positive correlation (r: 0.36-0.58, P&gt; 0.001) between frailty risk scores predicted by ML and frailty indices obtained from the accumulated deficit approach. Our approach provided new insights into the importance of specific EHR features in pre-operative frailty assessment. ML may offer an alternative method to predict frailty in pre-operative settings. Further validation on external data sources is required to generalize our ML models.},
  archive      = {J_JIIS},
  author       = {Bai, Chen and Al-Ani, Mohammad and Amini, Shawna and Tighe, Patrick and Price, Catherine and Manini, Todd and Mardini, Mamoun},
  doi          = {10.1007/s10844-023-00818-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {339-354},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Developing and validating an electronic health record-based frailty index in pre-operative settings using machine learning},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). C-GDN: Core features activated graph dual-attention network
for personalized recommendation. <em>JIIS</em>, <em>62</em>(2), 317–338.
(<a href="https://doi.org/10.1007/s10844-023-00816-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular graph learning technique, graph neural networks (GNN) show great advantages in the field of personalized recommendation. Existing GNN-based recommendation methods organized user-item interactions (e.g., click, purchase, review, etc.) as the bipartite graph and captured the higher-order collaborative signal with the aid of the GNN to achieve personalized recommendation. However, there exists two limitations in existing studies. First, core features activating user-item interactions were not be identified, which causes that user-item interactions fail to be accurately exploited at the feature level. Second, existing GNNs ignored the mutual association among neighbors in information propagation, which results in structural signal in the bipartite graph not being sufficiently captured. Towards this end, we developed the core features activated graph dual-attention network, namely C-GDN, for personalized recommendation. Specifically, C-GDN firstly identifies core user and item features activating user-item interactions and employs these core features to initialize the bipartite graph, which effectively optimizes the utilizing of user-item interactions at the feature level. Furthermore, C-GDN designs a novel graph dual-attention network to conduct information propagation, which captures more sufficient structural signal in the bipartite graph by considering information from neighbors as well as their mutual association. Extensive experiments on three benchmark datasets shows that C-GDN outperforms state-of-the-art baselines.},
  archive      = {J_JIIS},
  author       = {Zhang, Xiongtao and Gan, Mingxin},
  doi          = {10.1007/s10844-023-00816-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {317-338},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {C-GDN: Core features activated graph dual-attention network for personalized recommendation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolvable transformation of knowledge graphs into
human-oriented formats. <em>JIIS</em>, <em>62</em>(2), 295–316. (<a
href="https://doi.org/10.1007/s10844-023-00809-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the ongoing digitalization of society, we witness a strong movement to make scientific data FAIR, machine-actionable, and available in the form of knowledge graphs. On the other hand, converting machine-actionable data from knowledge graphs back into human-oriented formats, including documents, graphical, or voice user interfaces, poses significant challenges. The solutions often build on various templates tailored to specific platforms on top of the shared underlying data. These templates suffer from limited reusability, making their adaptations difficult. Moreover, the continuous evolution of data or technological advancements requires substantial efforts to maintain these templates over time. In general, these challenges increase software development costs and are error-prone. In this paper, we propose a solution based on Normalized Systems Theory to address this challenge with the aim of achieving evolvability and sustainability in the transformation process of knowledge graphs into human-oriented formats with broad applicability across domains and technologies. We explain the theoretical foundation and design theorems used in our solution and outline the approach and implementation details. We theoretically evaluate our solution by comparing it to the traditional approach, where the systems are crafted manually. The evaluation shows that our solution is more efficient and effective on a large scale, reducing the human labor required to maintain various templates and supported target platforms. Next, we demonstrate the technical feasibility of our solution on a proof-of-concept implementation in a domain of data management planning that may also serve as a basis for future development.},
  archive      = {J_JIIS},
  author       = {Slifka, Jan and Knaisl, Vojtěch and Pergl, Robert},
  doi          = {10.1007/s10844-023-00809-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {295-316},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Evolvable transformation of knowledge graphs into human-oriented formats},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). OIE4PA: Open information extraction for the public
administration. <em>JIIS</em>, <em>62</em>(1), 273–294. (<a
href="https://doi.org/10.1007/s10844-023-00814-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tenders are powerful means of investment of public funds and represent a strategic development resource. Despite the efforts made so far by governments at national and international levels to digitalise documents related to the Public Administration sector, most of the information is still available in an unstructured format only. With the aim of bridging this gap, we present OIE4PA, our latest study on extracting and classifying relations from tenders of the Public Administration. Our work focuses on the Italian language, where the availability of linguistic resources to perform Natural Language Processing tasks is considerably limited. Nevertheless, OIE4PA adopts a multilingual approach so it can be applied to several languages by providing appropriate training data. Rather than purely training a classifier on a portion of the extracted relations, the backbone idea of our learning strategy is to put a supervised method based on self-training to the proof and to assess whether or not it improves the performance of the classifier. For evaluation purposes, we built a dataset composed of 2,000 triples which have been manually annotated by two human experts. The in-vitro evaluation shows that OIE4PA achieves a MacroF $$_1$$ equal to 0.89 and a 91 $$\%$$ accuracy. In addition, OIE4PA was used as the pillar of a prototype search engine, which has been evaluated through an in-vivo experiment with positive feedback from 32 final users, obtaining a SUS score equal to 83.98.},
  archive      = {J_JIIS},
  author       = {Siciliani, Lucia and Ghizzota, Eleonora and Basile, Pierpaolo and Lops, Pasquale},
  doi          = {10.1007/s10844-023-00814-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {273-294},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {OIE4PA: Open information extraction for the public administration},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global-mirror graph network for session-based
recommendation. <em>JIIS</em>, <em>62</em>(1), 255–272. (<a
href="https://doi.org/10.1007/s10844-023-00813-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation(SBR) is a hot research direction, and how to solve the problem of sparse data in sessions is a challenging task. Although the existing model mirror graph enhanced neural model for session-based recommendation(MGS) solves the problem of data sparsity by introducing additional information from items, this model is still unable to model the general interest of the session well due to the limitations of data attribute information and the interference of noise, resulting in a certain amount of room for improvement in recommendation accuracy. To address this issue, this paper proposes a Global-Mirror Graph Model for Session-based Recommendation (GMGS), based on the research work related to MGS models, combining global graph modeling and reverse position awareness. Specifically, the GMGS model first builds a global graph based on all item transformations, and uses this to capture contextual information between sessions, thereby completing the modeling of general session interests. Then, a gating mechanism is used to combine reverse position information and the last click to obtain a session representation for final prediction. Finally, we conducted a large number of comparative experiments on three real datasets, and the GMGS model proposed in this paper achieved better results than the current representative recommendation models. Compared with the MGS model, the MRR@20 indicator has increased by 2.6 $$\%$$ , 0.6 $$\%$$ , and 6.5 $$\%$$ on the three datasets, respectively. In addition, we also conducted ablation experiments on three datasets to verify the effectiveness of each component improvement.},
  archive      = {J_JIIS},
  author       = {Li, Yuqiang and Long, Jianxiang and Liu, Chun},
  doi          = {10.1007/s10844-023-00813-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {255-272},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Global-mirror graph network for session-based recommendation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformer based multilingual joint learning framework for
code-mixed and english sentiment analysis. <em>JIIS</em>,
<em>62</em>(1), 231–253. (<a
href="https://doi.org/10.1007/s10844-023-00808-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, there has been tremendous growth in the number of multi-lingual users on social media platforms. Consequently, the code-mixing phenomenon, i.e., mixing of more than one language, has become ubiquitous in Internet content. In this paper, we present a shared-private, multi-lingual, multi-task model coupled with a transformer-based pre-trained encoder for sentiment analysis of code-mixed and English languages. Our model is tailored for multitasking that transfers the knowledge between code-mixed and English sentiment tasks. We consider code-mixed sentiment analysis as the primary task and enhance its performance by English sentiment analysis (auxiliary task) by sharing knowledge between them. We fine-tune the Bidirectional Encoder Representation using Transformer (BERT) encoder in a shared-private fashion to obtain the shared and task-specific features using the multi-task objective function. We evaluate our proposed framework using three benchmark datasets for the Hindi-English (Hinglish), Punjabi-English (Punglish) code-mixed and English sentiment tasks. Experiment results justify that our proposed multi-task framework improves the performance of our primary task in comparison to the state-of-art single-task systems.},
  archive      = {J_JIIS},
  author       = {Mamta and Ekbal, Asif},
  doi          = {10.1007/s10844-023-00808-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {231-253},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Transformer based multilingual joint learning framework for code-mixed and english sentiment analysis},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving information retrieval through correspondence
analysis instead of latent semantic analysis. <em>JIIS</em>,
<em>62</em>(1), 209–230. (<a
href="https://doi.org/10.1007/s10844-023-00815-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The initial dimensions extracted by latent semantic analysis (LSA) of a document-term matrix have been shown to mainly display marginal effects, which are irrelevant for information retrieval. To improve the performance of LSA, usually the elements of the raw document-term matrix are weighted and the weighting exponent of singular values can be adjusted. An alternative information retrieval technique that ignores the marginal effects is correspondence analysis (CA). In this paper, the information retrieval performance of LSA and CA is empirically compared. Moreover, it is explored whether the two weightings also improve the performance of CA. The results for four empirical datasets show that CA always performs better than LSA. Weighting the elements of the raw data matrix can improve CA; however, it is data dependent and the improvement is small. Adjusting the singular value weighting exponent often improves the performance of CA; however, the extent of the improvement depends on the dataset and the number of dimensions.},
  archive      = {J_JIIS},
  author       = {Qi, Qianqian and Hessen, David J. and van der Heijden, Peter G. M.},
  doi          = {10.1007/s10844-023-00815-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {209-230},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Improving information retrieval through correspondence analysis instead of latent semantic analysis},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-supervised opinion summarization with multi-modal
knowledge graph. <em>JIIS</em>, <em>62</em>(1), 191–208. (<a
href="https://doi.org/10.1007/s10844-023-00812-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal opinion summarization aims at automatically generating summaries of products or businesses from multi-modal reviews containing text, image and table to present clear references for other customers. To create faithful summaries, multi-modal structural knowledge should be well utilized, which is neglected by most existing work on multi-modal opinion summarization. Thus, we propose an opinion summarization framework based on multi-modal knowledge graphs (MKGOpinSum) to utilize structural knowledge in multi-modal data for opinion summarization. To construct a multi-modal knowledge graph, we first build a textual knowledge graph from review text and then enrich it by linking detected image objects to its corresponding entities. Our method obtains each modality representation from their own encoders, and generates the summary from the text decoder. To address the issue of heterogeneity of multi-modal data, we adopt a multi-modal training pipeline. In the pipeline we first pretrain text encoder and decoder with only text modality data. Then we respectively pretrain table and MKG modality by taking text decoder as a pivot. Finally, we train the entire encoder-decoder architecture and fuse representations of all modalities to generate the summary text. Experiments on Amazon and Yelp dataset show the framework has satisfactory performances when compared to ten baselines.},
  archive      = {J_JIIS},
  author       = {Jin, Lingyun and Chen, Jingqiang},
  doi          = {10.1007/s10844-023-00812-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {191-208},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Self-supervised opinion summarization with multi-modal knowledge graph},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing aspect-based sentiment analysis with
dependency-attention GCN and mutual assistance mechanism. <em>JIIS</em>,
<em>62</em>(1), 163–189. (<a
href="https://doi.org/10.1007/s10844-023-00811-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) has been extensively studied in recent years. It involves several subtasks for extracting one or more sentiment elements, including the aspect category, aspect term, opinion term, and sentiment polarity. In this paper, we propose two novel approaches to addressing different ABSA subtasks. Firstly, we introduce a Dependency-Attention GCN-based Aspect Opinion Extractor (DAG-AOE) for the Aspect-Opinion Pair Extraction (AOPE) task. DAG-AOE employs an improved graph convolutional network to extract syntactic structure information from text sequences, thereby effectively identifying aspect-opinion pairs in sentences. Secondly, we propose a Mutual Assistance Mechanism-based Category Sentiment Classifier (MAM-CSC) that utilizes the results of DAG-AOE to address the Aspect Sentiment Quad Prediction (ASQP) task. MAM-CSC leverages the semantic relationships between words in a sentence and addresses the two independent classification tasks through a mutual assistance approach. We conduct extensive experiments on benchmark datasets, and the experimental results demonstrate that our models have demonstrated a significant improvement over all baseline methods. Specifically, our models achieved the highest improvement of 1.4% F1 score over the baseline on the AOPE task and 1.5% F1 score on the ASQP task.},
  archive      = {J_JIIS},
  author       = {Feng, Jialin and Li, Hong and Yu, Zhiyi},
  doi          = {10.1007/s10844-023-00811-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {163-189},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing aspect-based sentiment analysis with dependency-attention GCN and mutual assistance mechanism},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving graph collaborative filtering with
multimodal-side-information-enriched contrastive learning.
<em>JIIS</em>, <em>62</em>(1), 143–161. (<a
href="https://doi.org/10.1007/s10844-023-00807-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multimodal side information such as images and text have been commonly used as supplements to improve graph collaborative filtering recommendations. However, there is often a semantic gap between multimodal information and collaborative filtering information. Previous works often directly fuse or align these information, which results in semantic distortion or degradation. Additionally, multimodal information also introduces additional noises, and previous methods lack explicit supervision to identify these noises. To tackle the issues, we propose a novel contrastive learning approach to improve graph collaborative filtering, named Multimodal-Side-Information-enriched Contrastive Learning (MSICL), which does not fuse multimodal information directly, but still explicitly captures users’ potential preferences for similar images or text by contrasting ID embeddings, and filters noises in multimodal side information. Specifically, we first search for samples with similar images or text as positive contrastive pairs. Secondly, some searched sample pairs may be irrelevant, so we distinguish the noise by filtering out sample pairs that have no interaction relationship. Thirdly, we contrast the ID embeddings of the true positive sample pairs to excavate the potential similarity relationship in multimodal side information. Extensive experiments on three datasets demonstrate the superiority of our method in multimodal recommendation. Moreover, our approach significantly reduces computation and memory cost compared to previous work.},
  archive      = {J_JIIS},
  author       = {Lei, Shan and Huanhuan, Yuan and Pengpeng, Zhao and Jianfeng, Qu and Junhua, Fang and Guanfeng, Liu and Victor S., Sheng},
  doi          = {10.1007/s10844-023-00807-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {143-161},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Improving graph collaborative filtering with multimodal-side-information-enriched contrastive learning},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Personality trait analysis during the COVID-19 pandemic: A
comparative study on social media. <em>JIIS</em>, <em>62</em>(1),
117–142. (<a href="https://doi.org/10.1007/s10844-023-00810-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic, a global contagion of coronavirus infection caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2), has triggered severe social and economic disruption around the world and provoked changes in people’s behavior. Given the extreme societal impact of COVID-19, it becomes crucial to understand the emotional response of the people and the impact of COVID-19 on personality traits and psychological dimensions. In this study, we contribute to this goal by thoroughly analyzing the evolution of personality and psychological aspects in a large-scale collection of tweets extracted during the COVID-19 pandemic. The objectives of this research are: i) to provide evidence that helps to understand the estimated impact of the pandemic on people’s temperament, ii) to find associations and trends between specific events (e.g., stages of harsh confinement) and people’s reactions, and iii) to study the evolution of multiple personality aspects, such as the degree of introversion or the level of neuroticism. We also examine the development of emotions, as a natural complement to the automatic analysis of the personality dimensions. To achieve our goals, we have created two large collections of tweets (geotagged in the United States and Spain, respectively), collected during the pandemic. Our work reveals interesting trends in personality dimensions, emotions, and events. For example, during the pandemic period, we found increasing traces of introversion and neuroticism. Another interesting insight from our study is that the most frequent signs of personality disorders are those related to depression, schizophrenia, and narcissism. We also found some peaks of negative/positive emotions related to specific events.},
  archive      = {J_JIIS},
  author       = {Fernández-Pichel, Marcos and Aragón, Mario Ezra and Saborido-Patiño, Julián and Losada, David E.},
  doi          = {10.1007/s10844-023-00810-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {117-142},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Personality trait analysis during the COVID-19 pandemic: A comparative study on social media},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Prompted and integrated textual information enhancing
aspect-based sentiment analysis. <em>JIIS</em>, <em>62</em>(1), 91–115.
(<a href="https://doi.org/10.1007/s10844-023-00805-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based Sentiment Analysis (ABSA) aims to automatically predict the sentiment polarity of the written text based on the analysis of specific aspects. By applying various pre-trained language encoders, recent studies have achieved great success in modeling aspect and context features and measuring the word-level correlations. However, the pre-trained language models (PLM) were usually employed as the feature representations generator without any task-oriented guidance. And the syntax dependency tree is also not fully utilized. Besides, simply concatenating usually fails to exploit deep semantic features from multi-source spaces and weakens the representation of context features. In this study, we propose a novel model, namely PRoGCN (Prompted RoBERTa &amp; Graph Convolution Network), which directly tells RoBERTa the goal of the present task by inserting the task-oriented specific prompting word to the raw text. Moreover, the prompted feature representation is also utilized to help generate textual knowledge graph, and strongly enhances the syntactic feature representation. In addition, we first introduce cross attention into our study to integrate semantic representation and syntactic representation, which has been proven to be successful in implementing and fusing multi-source information. Experimental results on five publicly available ABSA datasets validate the effectiveness of our method, and the proposed method achieves state-of-the-art performance on mentioned ABSA benchmarks.},
  archive      = {J_JIIS},
  author       = {Shi, Xuefeng and Hu, Min and Ren, Fuji and Shi, Piao and Deng, Jiawen and Tang, Yiming},
  doi          = {10.1007/s10844-023-00805-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {91-115},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Prompted and integrated textual information enhancing aspect-based sentiment analysis},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Semi-supervised and ensemble learning to predict
work-related stress. <em>JIIS</em>, <em>62</em>(1), 77–90. (<a
href="https://doi.org/10.1007/s10844-023-00806-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress is a common feeling in people’s day-to-day life, especially at work, being the cause of several health problems and absenteeism. Despite the difficulty in identifying it properly, several studies have established a correlation between stress and perceivable human features. The problem of detecting stress has attracted significant attention in the last decade. It has been mainly addressed through the analysis of physiological signals in the execution of specific tasks in controlled environments. Taking advantage of technological advances that allow to collect stress-related data in a non-invasive way, the goal of this work is to provide an alternative approach to detect stress in the workplace without requiring specific controlled conditions. To this end, a video-based plethysmography application that analyses the person’s face and retrieves several physiological signals in a non-invasive way was used. Moreover, in an initial phase, additional information that complements and labels the physiological data was obtained through a brief questionnaire answered by the participants. The data collection pilot took place over a period of two months, having involved 28 volunteers. Several stress detection models were developed; the best trained model achieved an accuracy of 86.8% and a F1 score of 87% on a binary stress/non-stress prediction.},
  archive      = {J_JIIS},
  author       = {Rodrigues, Fátima and Correia, Hugo},
  doi          = {10.1007/s10844-023-00806-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {77-90},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Semi-supervised and ensemble learning to predict work-related stress},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep latent representation enhancement method for social
recommendation. <em>JIIS</em>, <em>62</em>(1), 57–75. (<a
href="https://doi.org/10.1007/s10844-023-00802-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendation can effectively improve recommendation performance by leveraging social relationships to alleviate the sparsity of user-item interaction data. Because these connections in social recommendation can be easily represented as graph-structured data, social recommendation based on graph neural networks has received significant attention. However, existing works focus on modeling the long-term preferences of users and rarely consider the effect of temporal factors on preferences, resulting in a failure to accurately learn the representation of present preferences. Moreover, existing works mainly utilize similarity to connect different items. But items in the same category often have more connections and correlations with each other, which can be employed to enhance the learning of item representations. Therefore, this work proposes DLREM (Deep Latent Representation Enhancement Method for Social Recommendation) to address the above limitations. Specifically, DLREM exploits dual graph attention networks to learn long-term representations of users and items separately and exploits recurrent neural networks to capture the dynamic preferences of users. In addition, attention mechanisms are used to model user social relationships and item correlations, enhancing the learning of user and item representations. Combining the enhanced deep latent representations of users and items can improve the accuracy of social recommendation. Experimental results on two public datasets show that our model achieves competitive performance compared with state-of-the-art models.},
  archive      = {J_JIIS},
  author       = {Hou, Xiaoyu and Zou, Guobing and Zhang, Bofeng and Niu, Sen},
  doi          = {10.1007/s10844-023-00802-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {57-75},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Deep latent representation enhancement method for social recommendation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stock market prediction with time series data and news
headlines: A stacking ensemble approach. <em>JIIS</em>, <em>62</em>(1),
27–56. (<a href="https://doi.org/10.1007/s10844-023-00804-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting models are gaining traction in many real-world domains as valuable decision support tools. Stock market analysis is a challenging domain, characterized by a complex multi-variate and time-evolving nature, with high volatility, and multiple correlations with exogenous factors. Autoregressive, machine learning, and deep learning models for temporal data have been adopted thus far to solve this task. However, they are usually limited to the analysis of a single data source or modality, and do not collectively deal with all the inherent challenges and complexities presented by stock market data. In this paper, inspired by the promising learning capabilities of hybrid ensemble methods, we propose a novel stacking ensemble approach for stock market prediction that jointly considers news headlines, multi-variate time series data, and multiple base models as predictors. By taking multiple factors into consideration, our model is able to learn historical patterns leveraging multiple data sources and models. Our experiments showcase the ability of our model to outperform popular baselines on next-day stock market trend prediction. A portfolio analysis reveals that our method is also able to yield potential gains or capital preservation capabilities when its predictions are exploited for trading decisions.},
  archive      = {J_JIIS},
  author       = {Corizzo, Roberto and Rosen, Jacob},
  doi          = {10.1007/s10844-023-00804-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {27-56},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Stock market prediction with time series data and news headlines: A stacking ensemble approach},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Top-n music recommendation framework for precision and
novelty under diversity group size and similarity. <em>JIIS</em>,
<em>62</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10844-023-00784-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of music streaming market is expected to be boosted by the rising use of smart devices and the streaming platforms in the forecast period. Music recommendation systems for groups have been intensively studied as the application scenario becomes more dynamic, where different kinds of group formulations lead to different levels of similarity in music tastes. This paper proposes a music recommendation framework to generate a Top-N list in high-similar, high-dissimilar, and regular groups. Additionally, we investigate the performance of the recommendation system in a wide range of aspects, including precision, ranking quality, and novelty. Based on the listening frequency of each user and for each track, implicit feedback is also derived from the track popularity. To prevent popularity bias, we combine track popularity and group popularity into latent factor models to improve the performance of the recommendation algorithm. As a result of our evaluation, we found that the proposed methods provided excellent recommendations regarding accuracy, diversity, and novelty.},
  archive      = {J_JIIS},
  author       = {Chen, Shih-Han and Sou, Sok-Ian and Hsieh, Hsun-Ping},
  doi          = {10.1007/s10844-023-00784-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-26},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Top-N music recommendation framework for precision and novelty under diversity group size and similarity},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
