<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIJ_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij---112">AIJ - 112</h2>
<ul>
<li><details>
<summary>
(2024). Knowing how to plan about planning: Higher-order and
meta-level epistemic planning. <em>AIJ</em>, <em>337</em>, 104233. (<a
href="https://doi.org/10.1016/j.artint.2024.104233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated planning in AI and the logics of knowing how have close connections. In the recent literature, various planning-based know-how logics have been proposed and studied, making use of several notions of planning in AI. In this paper, we explore the reverse direction by using a multi-agent logic of knowing how to do know-how-based planning via model checking and theorem proving/satisfiability checking. Based on our logical framework, we propose two new classes of related planning problems: higher-order epistemic planning and meta-level epistemic planning , which generalize the current genre of epistemic planning in the literature. The former is for planning about planning, i.e., planning with higher-order goals that are again about epistemic planning, e.g., finding a plan for an agent to make sure p such that the adversary does not know how to make p false in the future. The latter is about planning at the meta-level by abstract reasoning combining knowledge-how from different agents, e.g., given that i knows how to prove a lemma and i knows j knows how to prove the theorem once the lemma is proved, we should derive that i knows how to let j knows how to prove the theorem. To make these possible, our framework features not only the operators of know-that and know-how but also a temporal operator □, which can help in capturing both the local and global knowledge-how. We axiomatize this powerful logic over finite models with perfect recall and show its decidability. We also give a PTIME algorithm for the model checking problem over finite models.},
  archive      = {J_AIJ},
  author       = {Yanjun Li and Yanjing Wang},
  doi          = {10.1016/j.artint.2024.104233},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104233},
  shortjournal = {Artif. Intell.},
  title        = {Knowing how to plan about planning: Higher-order and meta-level epistemic planning},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automatically designing counterfactual regret minimization
algorithms for solving imperfect-information games. <em>AIJ</em>,
<em>337</em>, 104232. (<a
href="https://doi.org/10.1016/j.artint.2024.104232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic decision-making in imperfect-information games is an important problem in artificial intelligence. Counterfactual regret minimization (CFR), a family of iterative algorithms, has been the workhorse for solving these types of games since its inception. In recent years, a series of novel CFR variants have been proposed, significantly improving the convergence rate of vanilla CFR. However, most of these new variants are hand-designed by researchers through trial and error, often based on different motivations, which generally requires a tremendous amount of effort and insight. This work proposes AutoCFR, a systematic framework that meta-learns novel CFR algorithms through evolution, easing the burden of manual algorithm design. We first design a search language that is rich enough to represent various CFR variants. We then exploit a scalable regularized evolution algorithm with a set of acceleration techniques to efficiently search over the combinatorial space of algorithms defined by this language. The learned novel CFR algorithm can generalize to new imperfect-information games not seen during training and performs on par with or better than existing state-of-the-art CFR variants. In addition to superior empirical performance, we also theoretically show that the learned algorithm converges to an approximate Nash equilibrium. Extensive experiments across diverse imperfect-information games highlight the scalability, extensibility, and generalizability of AutoCFR, establishing it as a general-purpose framework for solving imperfect-information games.},
  archive      = {J_AIJ},
  author       = {Kai Li and Hang Xu and Haobo Fu and Qiang Fu and Junliang Xing},
  doi          = {10.1016/j.artint.2024.104232},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104232},
  shortjournal = {Artif. Intell.},
  title        = {Automatically designing counterfactual regret minimization algorithms for solving imperfect-information games},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An α-regret analysis of adversarial bilateral trade.
<em>AIJ</em>, <em>337</em>, 104231. (<a
href="https://doi.org/10.1016/j.artint.2024.104231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study sequential bilateral trade where sellers and buyers valuations are completely arbitrary ( i.e. , determined by an adversary). Sellers and buyers are strategic agents with private valuations for the good and the goal is to design a mechanism that maximizes efficiency (or gain from trade) while being incentive compatible, individually rational and budget balanced. In this paper we consider gain from trade, which is harder to approximate than social welfare. We consider a variety of feedback scenarios and distinguish the cases where the mechanism posts one price and when it can post different prices for buyer and seller. We show several surprising results about the separation between the different scenarios. In particular we show that (a) it is impossible to achieve sublinear α -regret for any α &lt; 2 α&amp;lt;2 , (b) but with full feedback sublinear 2-regret is achievable; (c) with a single price and partial feedback one cannot get sublinear α regret for any constant α (d) nevertheless, posting two prices even with one-bit feedback achieves sublinear 2-regret, and (e) there is a provable separation in the 2-regret bounds between full and partial feedback.},
  archive      = {J_AIJ},
  author       = {Yossi Azar and Amos Fiat and Federico Fusco},
  doi          = {10.1016/j.artint.2024.104231},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104231},
  shortjournal = {Artif. Intell.},
  title        = {An α-regret analysis of adversarial bilateral trade},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive large-neighbourhood search for optimisation in
answer-set programming. <em>AIJ</em>, <em>337</em>, 104230. (<a
href="https://doi.org/10.1016/j.artint.2024.104230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer-set programming (ASP) is a prominent approach to declarative problem solving that is increasingly used to tackle challenging optimisation problems. We present an approach to leverage ASP optimisation by using large-neighbourhood search (LNS), which is a meta-heuristic where parts of a solution are iteratively destroyed and reconstructed in an attempt to improve an overall objective. In our LNS framework, neighbourhoods can be specified either declaratively as part of the ASP encoding or automatically generated by code. Furthermore, our framework is self-adaptive, i.e., it also incorporates portfolios for the LNS operators along with selection strategies to adjust search parameters on the fly. The implementation of our framework, the system ALASPO, currently supports the ASP solver clingo, as well as its extensions clingo-dl and clingcon that allow for difference and full integer constraints, respectively. It utilises multi-shot solving to efficiently realise the LNS loop and in this way avoids program regrounding. We describe our LNS framework for ASP as well as its implementation, discuss methodological aspects, and demonstrate the effectiveness of the adaptive LNS approach for ASP on different optimisation benchmarks, some of which are notoriously difficult, as well as real-world applications for shift planning, configuration of railway-safety systems, parallel machine scheduling, and test laboratory scheduling.},
  archive      = {J_AIJ},
  author       = {Thomas Eiter and Tobias Geibinger and Nelson Higuera Ruiz and Nysret Musliu and Johannes Oetsch and Dave Pfliegler and Daria Stepanova},
  doi          = {10.1016/j.artint.2024.104230},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104230},
  shortjournal = {Artif. Intell.},
  title        = {Adaptive large-neighbourhood search for optimisation in answer-set programming},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On trivalent logics, probabilistic weak deduction theorems,
and a general import-export principle. <em>AIJ</em>, <em>337</em>,
104229. (<a href="https://doi.org/10.1016/j.artint.2024.104229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we first recall some results for conditional events, compound conditionals, conditional random quantities, p-consistency, and p-entailment. We discuss the equivalence between conditional bets and bets on conditionals, and review de Finetti&#39;s trivalent analysis of conditionals. But we go beyond de Finetti&#39;s early trivalent logical analysis and his later ideas, aiming to take his proposals to a higher level. We examine two recent articles that explore trivalent logics for conditionals and their definitions of logical validity and compare them with the approach to compound conditionals introduced by Gilio and Sanfilippo within the framework of conditional random quantities. As we use the notion of p-entailment, the full deduction theorem does not hold. We prove a Probabilistic Weak Deduction Theorem for conditional events. After that we study some variants of it, with further results, and we present several examples. Moreover, we illustrate how to derive new inference rules related to selected Aristotelian syllogisms. We focus on iterated conditionals and the invalidity of the Import-Export principle in the light of our Probabilistic Weak Deduction Theorem. We use the inference from a disjunction, A or B , to the conditional, if not-A then B , as an example to show the invalidity of this principle. We introduce a General Import-Export principle by examining examples and counterexamples. In particular, when considering the inference rules of System P, we find that a General Import-Export principle is satisfied, even if the assumptions of the Probabilistic Weak Deduction Theorem do not hold. We also deepen further aspects related to p-entailment and p-consistency. Finally, we briefly discuss some related work relevant to AI.},
  archive      = {J_AIJ},
  author       = {Angelo Gilio and David E. Over and Niki Pfeifer and Giuseppe Sanfilippo},
  doi          = {10.1016/j.artint.2024.104229},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104229},
  shortjournal = {Artif. Intell.},
  title        = {On trivalent logics, probabilistic weak deduction theorems, and a general import-export principle},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integration of memory systems supporting non-symbolic
representations in an architecture for lifelong development of
artificial agents. <em>AIJ</em>, <em>337</em>, 104228. (<a
href="https://doi.org/10.1016/j.artint.2024.104228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIJ},
  author       = {François Suro and Fabien Michel and Tiberiu Stratulat},
  doi          = {10.1016/j.artint.2024.104228},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104228},
  shortjournal = {Artif. Intell.},
  title        = {Integration of memory systems supporting non-symbolic representations in an architecture for lifelong development of artificial agents},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Declarative probabilistic logic programming in
discrete-continuous domains. <em>AIJ</em>, <em>337</em>, 104227. (<a
href="https://doi.org/10.1016/j.artint.2024.104227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past three decades, the logic programming paradigm has been successfully expanded to support probabilistic modeling, inference and learning. The resulting paradigm of probabilistic logic programming (PLP) and its programming languages owes much of its success to a declarative semantics, the so-called distribution semantics. However, the distribution semantics is limited to discrete random variables only. While PLP has been extended in various ways for supporting hybrid, that is, mixed discrete and continuous random variables, we are still lacking a declarative semantics for hybrid PLP that not only generalizes the distribution semantics and the modeling language but also the standard inference algorithm that is based on knowledge compilation. We contribute the measure semantics together with the hybrid PLP language DC-ProbLog (where DC stands for distributional clauses) and its inference engine infinitesimal algebraic likelihood weighting (IALW). These have the original distribution semantics, standard PLP languages such as ProbLog, and standard inference engines for PLP based on knowledge compilation as special cases. Thus, we generalize the state of the art of PLP towards hybrid PLP in three different aspects: semantics, language and inference. Furthermore, IALW is the first inference algorithm for hybrid probabilistic programming based on knowledge compilation.},
  archive      = {J_AIJ},
  author       = {Pedro Zuidberg Dos Martires and Luc De Raedt and Angelika Kimmig},
  doi          = {10.1016/j.artint.2024.104227},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104227},
  shortjournal = {Artif. Intell.},
  title        = {Declarative probabilistic logic programming in discrete-continuous domains},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PathLAD+: Towards effective exact methods for subgraph
isomorphism problem. <em>AIJ</em>, <em>337</em>, 104219. (<a
href="https://doi.org/10.1016/j.artint.2024.104219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subgraph isomorphism problem (SIP) is a challenging problem with wide practical applications. In the last decade, despite being a theoretical hard problem, researchers designed various algorithms for solving SIP. In this work, we propose five main strategies and develop an improved exact algorithm for SIP. First, we design a probing search procedure to try whether the search procedure can successfully obtain a solution at first sight. Second, we design a novel matching ordering strategy as a value-ordering heuristic, which uses some useful information obtained from the probing search procedure to preferentially select some promising target vertices. Third, we discuss the characteristics of different propagation methods in the context of SIP and present an adaptive propagation method to make a good balance between these methods. Moreover, to further improve the performance of solving large graphs, we propose an enhanced implementation of the edge constraint method and a domain limitation strategy, which aims to accelerate the search process. Experimental results on a broad range of classic and graph-database benchmarks show that our proposed algorithm performs better than several state-of-the-art algorithms for the SIP.},
  archive      = {J_AIJ},
  author       = {Yiyuan Wang and Chenghou Jin and Shaowei Cai},
  doi          = {10.1016/j.artint.2024.104219},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104219},
  shortjournal = {Artif. Intell.},
  title        = {PathLAD+: Towards effective exact methods for subgraph isomorphism problem},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polynomial calculus for optimization. <em>AIJ</em>,
<em>337</em>, 104208. (<a
href="https://doi.org/10.1016/j.artint.2024.104208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MaxSAT is the problem of finding an assignment satisfying the maximum number of clauses in a CNF formula. We consider a natural generalization of this problem to generic sets of polynomials and propose a weighted version of Polynomial Calculus to address this problem. Weighted Polynomial Calculus is a natural generalization of the systems MaxSAT-Resolution and weighted Resolution. Unlike such systems, weighted Polynomial Calculus manipulates polynomials with coefficients in a finite field and either weights in N N or Z Z . We show the soundness and completeness of weighted Polynomial Calculus via an algorithmic procedure. Weighted Polynomial Calculus, with weights in N N and coefficients in F 2 F2 , is able to prove efficiently that Tseitin formulas on a connected graph are minimally unsatisfiable. Using weights in Z Z , it also proves efficiently that the Pigeonhole Principle is minimally unsatisfiable.},
  archive      = {J_AIJ},
  author       = {Ilario Bonacina and Maria Luisa Bonet and Jordi Levy},
  doi          = {10.1016/j.artint.2024.104208},
  journal      = {Artificial Intelligence},
  month        = {12},
  pages        = {104208},
  shortjournal = {Artif. Intell.},
  title        = {Polynomial calculus for optimization},
  volume       = {337},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interval abstractions for robust counterfactual
explanations. <em>AIJ</em>, <em>336</em>, 104218. (<a
href="https://doi.org/10.1016/j.artint.2024.104218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual Explanations (CEs) have emerged as a major paradigm in explainable AI research, providing recourse recommendations for users affected by the decisions of machine learning models. However, CEs found by existing methods often become invalid when slight changes occur in the parameters of the model they were generated for. The literature lacks a way to provide exhaustive robustness guarantees for CEs under model changes, in that existing methods to improve CEs&#39; robustness are mostly heuristic, and the robustness performances are evaluated empirically using only a limited number of retrained models. To bridge this gap, we propose a novel interval abstraction technique for parametric machine learning models, which allows us to obtain provable robustness guarantees for CEs under a possibly infinite set of plausible model changes Δ. Based on this idea, we formalise a robustness notion for CEs, which we call Δ-robustness, in both binary and multi-class classification settings. We present procedures to verify Δ-robustness based on Mixed Integer Linear Programming, using which we further propose algorithms to generate CEs that are Δ-robust. In an extensive empirical study involving neural networks and logistic regression models, we demonstrate the practical applicability of our approach. We discuss two strategies for determining the appropriate hyperparameters in our method, and we quantitatively benchmark CEs generated by eleven methods, highlighting the effectiveness of our algorithms in finding robust CEs.},
  archive      = {J_AIJ},
  author       = {Junqi Jiang and Francesco Leofante and Antonio Rago and Francesca Toni},
  doi          = {10.1016/j.artint.2024.104218},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104218},
  shortjournal = {Artif. Intell.},
  title        = {Interval abstractions for robust counterfactual explanations},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximating problems in abstract argumentation with graph
convolutional networks. <em>AIJ</em>, <em>336</em>, 104209. (<a
href="https://doi.org/10.1016/j.artint.2024.104209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a novel approximation approach for abstract argumentation using a customized Graph Convolutional Network (GCN) architecture and a tailored training method. Our approach demonstrates promising results in approximating abstract argumentation tasks across various semantics, setting a new state of the art for performance on certain tasks. We provide a detailed analysis of approximation and runtime performance and propose a new scheme for evaluation. By advancing the state of the art for approximating the acceptability status of abstract arguments, we make theoretical and empirical advances in understanding the limits and opportunities for approximation in this field. Our approach shows potential for creating both general purpose and task-specific approximators and offers insights into the performance differences across benchmarks and semantics.},
  archive      = {J_AIJ},
  author       = {Lars Malmqvist and Tangming Yuan and Peter Nightingale},
  doi          = {10.1016/j.artint.2024.104209},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104209},
  shortjournal = {Artif. Intell.},
  title        = {Approximating problems in abstract argumentation with graph convolutional networks},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Characterising harmful data sources when constructing
multi-fidelity surrogate models. <em>AIJ</em>, <em>336</em>, 104207. (<a
href="https://doi.org/10.1016/j.artint.2024.104207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate modelling techniques have seen growing attention in recent years when applied to both modelling and optimisation of industrial design problems. These techniques are highly relevant when assessing the performance of a particular design carries a high cost, as the overall cost can be mitigated via the construction of a model to be queried in lieu of the available high-cost source. The construction of these models can sometimes employ other sources of information which are both cheaper and less accurate. The existence of these sources however poses the question of which sources should be used when constructing a model. Recent studies have attempted to characterise harmful data sources to guide practitioners in choosing when to ignore a certain source. These studies have done so in a synthetic setting, characterising sources using a large amount of data that is not available in practice. Some of these studies have also been shown to potentially suffer from bias in the benchmarks used in the analysis. In this study, we approach the characterisation of harmful low-fidelity sources as an algorithm selection problem. We employ recently developed benchmark filtering techniques to conduct a bias-free assessment, providing objectively varied benchmark suites of different sizes for future research. Analysing one of these benchmark suites with the technique known as Instance Space Analysis, we provide an intuitive visualisation of when a low-fidelity source should be used. By performing this analysis using only the limited data available to train a surrogate model, we are able to provide guidelines that can be directly used in an applied industrial setting.},
  archive      = {J_AIJ},
  author       = {Nicolau Andrés-Thió and Mario Andrés Muñoz and Kate Smith-Miles},
  doi          = {10.1016/j.artint.2024.104207},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104207},
  shortjournal = {Artif. Intell.},
  title        = {Characterising harmful data sources when constructing multi-fidelity surrogate models},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Is it possible to find the single nearest neighbor of a
query in high dimensions? <em>AIJ</em>, <em>336</em>, 104206. (<a
href="https://doi.org/10.1016/j.artint.2024.104206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate an open question in the study of the curse of dimensionality: Is it possible to find the single nearest neighbor of a query in high dimensions? Using the notion of (in)distinguishability to examine whether the feature map of a kernel is able to distinguish two distinct points in high dimensions, we analyze this ability of a metric-based Lipschitz continuous kernel as well as that of the recently introduced Isolation Kernel. Between the two kernels, we show that only Isolation Kernel has distinguishability and it performs consistently well in four tasks: indexed search for exact nearest neighbor search, anomaly detection using kernel density estimation, t-SNE visualization and SVM classification in both low and high dimensions, compared with distance, Gaussian and three other existing kernels.},
  archive      = {J_AIJ},
  author       = {Kai Ming Ting and Takashi Washio and Ye Zhu and Yang Xu and Kaifeng Zhang},
  doi          = {10.1016/j.artint.2024.104206},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104206},
  shortjournal = {Artif. Intell.},
  title        = {Is it possible to find the single nearest neighbor of a query in high dimensions?},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Abstract argumentation frameworks with strong and weak
constraints. <em>AIJ</em>, <em>336</em>, 104205. (<a
href="https://doi.org/10.1016/j.artint.2024.104205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dealing with controversial information is an important issue in several application contexts. Formal argumentation enables reasoning on arguments for and against a claim to decide on an outcome. Dung&#39;s abstract Argumentation Framework (AF) has emerged as a central formalism in argument-based reasoning. Key aspects of the success and popularity of Dung&#39;s framework include its simplicity and expressiveness. Integrity constraints help to express domain knowledge in a compact and natural way, thus keeping easy the modeling task even for problems that otherwise would be hard to encode within an AF. In this paper, we first explore two intuitive semantics based on Kleene and Lukasiewicz logics, respectively, for AF augmented with (strong) constraints—the resulting argumentation framework is called Constrained AF (CAF). Then, we propose a new argumentation framework called Weak constrained AF (WAF) that enhances CAF with weak constraints. Intuitively, these constraints can be used to find “optimal” solutions to problems defined through CAF. We provide a detailed complexity analysis of CAF and WAF, showing that strong constraints do not increase the expressive power of AF in most cases, while weak constraints systematically increase the expressive power of CAF (and AF) under several well-known argumentation semantics.},
  archive      = {J_AIJ},
  author       = {Gianvincenzo Alfano and Sergio Greco and Domenico Mandaglio and Francesco Parisi and Irina Trubitsyna},
  doi          = {10.1016/j.artint.2024.104205},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104205},
  shortjournal = {Artif. Intell.},
  title        = {Abstract argumentation frameworks with strong and weak constraints},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Addressing maximization bias in reinforcement learning with
two-sample testing. <em>AIJ</em>, <em>336</em>, 104204. (<a
href="https://doi.org/10.1016/j.artint.2024.104204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Value-based reinforcement-learning algorithms have shown strong results in games, robotics, and other real-world applications. Overestimation bias is a known threat to those algorithms and can sometimes lead to dramatic performance decreases or even complete algorithmic failure. We frame the bias problem statistically and consider it an instance of estimating the maximum expected value (MEV) of a set of random variables. We propose the T -Estimator (TE) based on two-sample testing for the mean, that flexibly interpolates between over- and underestimation by adjusting the significance level of the underlying hypothesis tests. We also introduce a generalization, termed K -Estimator (KE), that obeys the same bias and variance bounds as the TE and relies on a nearly arbitrary kernel function. We introduce modifications of Q -Learning and the Bootstrapped Deep Q -Network (BDQN) using the TE and the KE, and prove convergence in the tabular setting. Furthermore, we propose an adaptive variant of the TE-based BDQN that dynamically adjusts the significance level to minimize the absolute estimation bias. All proposed estimators and algorithms are thoroughly tested and validated on diverse tasks and environments, illustrating the bias control and performance potential of the TE and KE.},
  archive      = {J_AIJ},
  author       = {Martin Waltz and Ostap Okhrin},
  doi          = {10.1016/j.artint.2024.104204},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104204},
  shortjournal = {Artif. Intell.},
  title        = {Addressing maximization bias in reinforcement learning with two-sample testing},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bisimulation between base argumentation and
premise-conclusion argumentation. <em>AIJ</em>, <em>336</em>, 104203.
(<a href="https://doi.org/10.1016/j.artint.2024.104203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structured argumentation system that represents arguments by premise-conclusion pairs is called premise-conclusion argumentation (PA) and the one that represents arguments by their premises is called base argumentation (BA). To assess whether BA and PA have the same ability in argument evaluation by extensional semantics, this paper defines the notion of extensional equivalence between BA and PA. It also defines the notion of bisimulation between BA and PA and shows that bisimulation implies extensional equivalence. To illustrate how base argumentation, bisimulation and extensional equivalence can contribute to the study of PA, we prove some new results about PA by investigating the extensional properties of a base argumentation framework and exporting them to two premise-conclusion argumentation frameworks via bisimulation and extensional equivalence. We show that there are essentially three kinds of extensions in these frameworks and that the extensions in the two premise-conclusion argumentation frameworks are identical.},
  archive      = {J_AIJ},
  author       = {Jinsheng Chen and Beishui Liao and Leendert van der Torre},
  doi          = {10.1016/j.artint.2024.104203},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104203},
  shortjournal = {Artif. Intell.},
  title        = {Bisimulation between base argumentation and premise-conclusion argumentation},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On generalized notions of consistency and reinstatement and
their preservation in formal argumentation. <em>AIJ</em>, <em>336</em>,
104202. (<a href="https://doi.org/10.1016/j.artint.2024.104202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a conceptualization providing an original domain-independent perspective on two crucial properties in reasoning: consistency and reinstatement. They emerge as a pair of dual characteristics, representing complementary requirements on the outcomes of reasoning processes. Central to our formalization are two underlying parametric relations: incompatibility and reinstatement violation. Different instances of these relations give rise to a spectrum of consistency and reinstatement scenarios. As a demonstration of versatility and expressive power of our approach we provide a characterization of various abstract argumentation semantics which are expressed as combinations of distinct consistency and reinstatement constraints. Moreover, we conduct an investigation into preserving these essential properties across different reasoning stages. Specifically, we delve into scenarios where a labelling is derived from other labellings through a synthesis function, using the synthesis of argument justification as an illustrative instance. We achieve a general characterization of consistency preservation synthesis functions, while we unveil an impossibility result concerning reinstatement preservation, leading us to explore an alternative notion to ensure feasibility. Our exploration reveals a weakness in the traditional definition of argument justification, for which we propose a refined version overcoming this limitation.},
  archive      = {J_AIJ},
  author       = {Pietro Baroni and Federico Cerutti and Massimiliano Giacomin},
  doi          = {10.1016/j.artint.2024.104202},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104202},
  shortjournal = {Artif. Intell.},
  title        = {On generalized notions of consistency and reinstatement and their preservation in formal argumentation},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modular control architecture for safe marine navigation:
Reinforcement learning with predictive safety filters. <em>AIJ</em>,
<em>336</em>, 104201. (<a
href="https://doi.org/10.1016/j.artint.2024.104201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many autonomous systems are safety-critical, making it essential to have a closed-loop control system that satisfies constraints arising from underlying physical limitations and safety aspects in a robust manner. However, this is often challenging to achieve for real-world systems. For example, autonomous ships at sea have nonlinear and uncertain dynamics and are subject to numerous time-varying environmental disturbances such as waves, currents, and wind. There is increasing interest in using machine learning-based approaches to adapt these systems to more complex scenarios, but there are few standard frameworks that guarantee the safety and stability of such systems. Recently, predictive safety filters (PSF) have emerged as a promising method to ensure constraint satisfaction in learning-based control, bypassing the need for explicit constraint handling in the learning algorithms themselves. The safety filter approach leads to a modular separation of the problem, allowing the use of arbitrary control policies in a task-agnostic way. The filter takes in a potentially unsafe control action from the main controller and solves an optimization problem to compute a minimal perturbation of the proposed action that adheres to both physical and safety constraints. In this work, we combine reinforcement learning (RL) with predictive safety filtering in the context of marine navigation and control. The RL agent is trained on path-following and safety adherence across a wide range of randomly generated environments, while the predictive safety filter continuously monitors the agents&#39; proposed control actions and modifies them if necessary. The combined PSF/RL scheme is implemented on a simulated model of Cybership II, a miniature replica of a typical supply ship. Safety performance and learning rate are evaluated and compared with those of a standard, non-PSF, RL agent. It is demonstrated that the predictive safety filter is able to keep the vessel safe, while not prohibiting the learning rate and performance of the RL agent.},
  archive      = {J_AIJ},
  author       = {Aksel Vaaler and Svein Jostein Husa and Daniel Menges and Thomas Nakken Larsen and Adil Rasheed},
  doi          = {10.1016/j.artint.2024.104201},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104201},
  shortjournal = {Artif. Intell.},
  title        = {Modular control architecture for safe marine navigation: Reinforcement learning with predictive safety filters},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Representing states in iterated belief revision.
<em>AIJ</em>, <em>336</em>, 104200. (<a
href="https://doi.org/10.1016/j.artint.2024.104200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iterated belief revision requires information about the current beliefs. This information is represented by mathematical structures called doxastic states. Most literature concentrates on how to revise a doxastic state and neglects that it may exponentially grow. This problem is studied for the most common ways of storing a doxastic state. All four of them are able to store every doxastic state, but some do it in less space than others. In particular, the explicit representation (an enumeration of the current beliefs) is the more wasteful on space. The level representation (a sequence of propositional formulae) and the natural representation (a history of natural revisions) are more succinct than it. The lexicographic representation (a history of lexicographic revision) is even more succinct than them.},
  archive      = {J_AIJ},
  author       = {Paolo Liberatore},
  doi          = {10.1016/j.artint.2024.104200},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104200},
  shortjournal = {Artif. Intell.},
  title        = {Representing states in iterated belief revision},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). NovPhy: A physical reasoning benchmark for open-world AI
systems. <em>AIJ</em>, <em>336</em>, 104198. (<a
href="https://doi.org/10.1016/j.artint.2024.104198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the emergence of AI systems that interact with the physical environment, there is an increased interest in incorporating physical reasoning capabilities into those AI systems. But is it enough to only have physical reasoning capabilities to operate in a real physical environment? In the real world, we constantly face novel situations we have not encountered before. As humans, we are competent at successfully adapting to those situations. Similarly, an agent needs to have the ability to function under the impact of novelties in order to properly operate in an open-world physical environment. To facilitate the development of such AI systems, we propose a new benchmark, NovPhy, that requires an agent to reason about physical scenarios in the presence of novelties and take actions accordingly. The benchmark consists of tasks that require agents to detect and adapt to novelties in physical scenarios. To create tasks in the benchmark, we develop eight novelties representing a diverse novelty space and apply them to five commonly encountered scenarios in a physical environment, related to applying forces and motions such as rolling, falling, and sliding of objects. According to our benchmark design, we evaluate two capabilities of an agent: the performance on a novelty when it is applied to different physical scenarios and the performance on a physical scenario when different novelties are applied to it. We conduct a thorough evaluation with human players, learning agents, and heuristic agents. Our evaluation shows that humans&#39; performance is far beyond the agents&#39; performance. Some agents, even with good normal task performance, perform significantly worse when there is a novelty, and the agents that can adapt to novelties typically adapt slower than humans. We promote the development of intelligent agents capable of performing at the human level or above when operating in open-world physical environments. Benchmark website: https://github.com/phy-q/novphy .},
  archive      = {J_AIJ},
  author       = {Vimukthini Pinto and Chathura Gamage and Cheng Xue and Peng Zhang and Ekaterina Nikonova and Matthew Stephenson and Jochen Renz},
  doi          = {10.1016/j.artint.2024.104198},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104198},
  shortjournal = {Artif. Intell.},
  title        = {NovPhy: A physical reasoning benchmark for open-world AI systems},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manipulation and peer mechanisms: A survey. <em>AIJ</em>,
<em>336</em>, 104196. (<a
href="https://doi.org/10.1016/j.artint.2024.104196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In peer mechanisms, the competitors for a prize also determine who wins. Each competitor may be asked to rank, grade, or nominate peers for the prize. Since the prize can be valuable, such as financial aid, course grades, or an award at a conference, competitors may be tempted to manipulate the mechanism. We survey approaches to prevent or discourage the manipulation of peer mechanisms. We conclude our survey by identifying several important research challenges.},
  archive      = {J_AIJ},
  author       = {Matthew Olckers and Toby Walsh},
  doi          = {10.1016/j.artint.2024.104196},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104196},
  shortjournal = {Artif. Intell.},
  title        = {Manipulation and peer mechanisms: A survey},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sample-based bounds for coherent risk measures: Applications
to policy synthesis and verification. <em>AIJ</em>, <em>336</em>,
104195. (<a href="https://doi.org/10.1016/j.artint.2024.104195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous systems are increasingly used in highly variable and uncertain environments giving rise to the pressing need to consider risk in both the synthesis and verification of policies for these systems. This paper first develops a sample-based method to upper bound the risk measure evaluation of a random variable whose distribution is unknown. These bounds permit us to generate high-confidence verification statements for a large class of robotic systems in a sample-efficient manner. Second, we develop a sample-based method to determine solutions to non-convex optimization problems that outperform a large fraction of the decision space of possible solutions. Both sample-based approaches then permit us to rapidly synthesize risk-aware policies that are guaranteed to achieve a minimum level of system performance. To showcase our approach in simulation, we verify a cooperative multi-agent system and develop a risk-aware controller that outperforms the system&#39;s baseline controller. Our approach can be extended to account for any g -entropic risk measure.},
  archive      = {J_AIJ},
  author       = {Prithvi Akella and Anushri Dixit and Mohamadreza Ahmadi and Joel W. Burdick and Aaron D. Ames},
  doi          = {10.1016/j.artint.2024.104195},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104195},
  shortjournal = {Artif. Intell.},
  title        = {Sample-based bounds for coherent risk measures: Applications to policy synthesis and verification},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). QCDCL with cube learning or pure literal elimination – what
is best? <em>AIJ</em>, <em>336</em>, 104194. (<a
href="https://doi.org/10.1016/j.artint.2024.104194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantified conflict-driven clause learning (QCDCL) is one of the main approaches for solving quantified Boolean formulas (QBF). We formalise and investigate several versions of QCDCL that include cube learning and/or pure-literal elimination, and formally compare the resulting solving variants via proof complexity techniques. Our results show that almost all of the QCDCL variants are exponentially incomparable with respect to proof size (and hence solver running time), pointing towards different orthogonal ways how to practically implement QCDCL.},
  archive      = {J_AIJ},
  author       = {Benjamin Böhm and Tomáš Peitl and Olaf Beyersdorff},
  doi          = {10.1016/j.artint.2024.104194},
  journal      = {Artificial Intelligence},
  month        = {11},
  pages        = {104194},
  shortjournal = {Artif. Intell.},
  title        = {QCDCL with cube learning or pure literal elimination – what is best?},
  volume       = {336},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Identifying roles of formulas in inconsistency under
priest’s minimally inconsistent logic of paradox. <em>AIJ</em>,
<em>335</em>, 104199. (<a
href="https://doi.org/10.1016/j.artint.2024.104199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been increasingly recognized that identifying roles of formulas of a knowledge base in the inconsistency of that base can help us better look inside the inconsistency. However, there are few approaches to identifying such roles of formulas from a perspective of models in some paraconsistent logic, one of typical tools used to characterize inconsistency in semantics. In this paper, we characterize the role of each formula in the inconsistency arising in a knowledge base from informational as well as causal aspects in the framework of Priest&#39;s minimally inconsistent logic of paradox. At first, we identify the causal responsibility of a formula for the inconsistency based on the counterfactual dependence of the inconsistency on the formula under some contingency in semantics. Then we incorporate the change on semantic information in the framework of causal responsibility to develop the informational responsibility of a formula for the inconsistency to capture the contribution made by the formula for the inconsistent information. This incorporation makes the informational responsibility interpretable from the point of view of causality, and capable of catching the role of a formula in inconsistent information concisely. In addition, we propose notions of naive and quasi naive responsibilities as two auxiliaries to describe special relations between inconsistency and formulas in semantic sense. Some intuitive and interesting properties of the two kinds of responsibilities are also discussed.},
  archive      = {J_AIJ},
  author       = {Kedian Mu},
  doi          = {10.1016/j.artint.2024.104199},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104199},
  shortjournal = {Artif. Intell.},
  title        = {Identifying roles of formulas in inconsistency under priest&#39;s minimally inconsistent logic of paradox},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On measuring inconsistency in graph databases with regular
path constraints. <em>AIJ</em>, <em>335</em>, 104197. (<a
href="https://doi.org/10.1016/j.artint.2024.104197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data are often inconsistent. Although a substantial amount of research has been done on measuring inconsistency, this research concentrated on knowledge bases formalized in propositional logic. Recently, inconsistency measures have been introduced for relational databases. However, nowadays, real-world information is always more frequently represented by graph-based structures which offer a more intuitive conceptualization than relational ones. In this paper, we explore inconsistency measures for graph databases with regular path constraints, a class of integrity constraints based on a well-known navigational language for graph data. In this context, we define several inconsistency measures dealing with specific elements contributing to inconsistency in graph databases. We also define some rationality postulates that are desirable properties for an inconsistency measure for graph databases. We analyze the compliance of each measure with each postulate and find various degrees of satisfaction; in fact, one of the measures satisfies all the postulates. Finally, we investigate the data and combined complexity of the calculation of all the measures as well as the complexity of deciding whether a measure is lower than, equal to, or greater than a given threshold. It turns out that for a majority of the measures these problems are tractable, while for the other different levels of intractability are exhibited.},
  archive      = {J_AIJ},
  author       = {John Grant and Francesco Parisi},
  doi          = {10.1016/j.artint.2024.104197},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104197},
  shortjournal = {Artif. Intell.},
  title        = {On measuring inconsistency in graph databases with regular path constraints},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An abstract and structured account of dialectical argument
strength. <em>AIJ</em>, <em>335</em>, 104193. (<a
href="https://doi.org/10.1016/j.artint.2024.104193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a formal model of dialectical argument strength in terms of the number of ways in which an argument can be successfully attacked in expansions of an abstract argumentation framework. First a model is proposed that is abstract but designed to avoid overly limiting assumptions on instantiations or dialogue contexts. It is then shown that most principles for argument strength proposed in the literature fail to hold for the proposed notions of dialectical strength, which clarifies the rational foundations of these principles and highlights the importance of distinguishing between kinds of argument strength, in particular logical, dialectical and rhetorical argument strength. The abstract model is then instantiated with ASPIC + to test the claim that it does not make overly limiting assumptions on the structure of arguments and the nature of their relations.},
  archive      = {J_AIJ},
  author       = {Henry Prakken},
  doi          = {10.1016/j.artint.2024.104193},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104193},
  shortjournal = {Artif. Intell.},
  title        = {An abstract and structured account of dialectical argument strength},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A crossword solving system based on monte carlo tree search.
<em>AIJ</em>, <em>335</em>, 104192. (<a
href="https://doi.org/10.1016/j.artint.2024.104192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the development of AI in games is remarkable, intelligent machines still lag behind humans in games that require the ability of language understanding. In this paper, we focus on the crossword puzzle resolution task. Solving crossword puzzles is a challenging task since it requires the ability to answer natural language questions with knowledge and the ability to execute a search over possible answers to find an optimal set of solutions for the grid. Previous solutions are devoted to exploiting heuristic strategies in search to find solutions while having limited ability to explore the search space. We build a comprehensive system for crossword puzzle resolution based on Monte Carlo Tree Search (MCTS). As far as we know, we are the first to model the crossword puzzle resolution problem as a Markov Decision Process and apply the MCTS to solve it. We construct a dataset for crossword puzzle resolution based on daily puzzles from The New York Times with detailed specifications of both the puzzle and clue database selection. Our method achieves state-of-the-art performance on the dataset. The code of the system and experiments in this paper is publicly available: https://www.github.com/lhlclhl/CP .},
  archive      = {J_AIJ},
  author       = {Jingping Liu and Lihan Chen and Sihang Jiang and Chao Wang and Sheng Zhang and Jiaqing Liang and Yanghua Xiao and Rui Song},
  doi          = {10.1016/j.artint.2024.104192},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104192},
  shortjournal = {Artif. Intell.},
  title        = {A crossword solving system based on monte carlo tree search},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective meta-learning. <em>AIJ</em>, <em>335</em>,
104184. (<a href="https://doi.org/10.1016/j.artint.2024.104184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning has arisen as a powerful tool for many machine learning problems. With multiple factors to be considered when designing learning models for real-world applications, meta-learning with multiple objectives has attracted much attention recently. However, existing works either linearly combine multiple objectives into one objective or adopt evolutionary algorithms to handle it, where the former approach needs to pay high computational cost to tune the combination coefficients while the latter approach is computationally heavy and incapable to be integrated into gradient-based optimization. To alleviate those limitations, in this paper, we aim to propose a generic gradient-based Multi-Objective Meta-Learning (MOML) framework with applications in many machine learning problems. Specifically, the MOML framework formulates the objective function of meta-learning with multiple objectives as a Multi-Objective Bi-Level optimization Problem (MOBLP) where the upper-level subproblem is to solve several possibly conflicting objectives for the meta-learner. Different from those existing works, in this paper, we propose a gradient-based algorithm to solve the MOBLP. Specifically, we devise the first gradient-based optimization algorithm by alternately solving the lower-level and upper-level subproblems via the gradient descent method and the gradient-based multi-objective optimization method, respectively. Theoretically, we prove the convergence property and provide a non-asymptotic analysis of the proposed gradient-based optimization algorithm. Empirically, extensive experiments justify our theoretical results and demonstrate the superiority of the proposed MOML framework for different learning problems, including few-shot learning, domain adaptation, multi-task learning, neural architecture search, and reinforcement learning. The source code of MOML is available at https://github.com/Baijiong-Lin/MOML .},
  archive      = {J_AIJ},
  author       = {Feiyang Ye and Baijiong Lin and Zhixiong Yue and Yu Zhang and Ivor W. Tsang},
  doi          = {10.1016/j.artint.2024.104184},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104184},
  shortjournal = {Artif. Intell.},
  title        = {Multi-objective meta-learning},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). ASQ-IT: Interactive explanations for reinforcement-learning
agents. <em>AIJ</em>, <em>335</em>, 104182. (<a
href="https://doi.org/10.1016/j.artint.2024.104182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As reinforcement learning methods increasingly amass accomplishments, the need for comprehending their solutions becomes more crucial. Most explainable reinforcement learning (XRL) methods generate a static explanation depicting their developers&#39; intuition of what should be explained and how. In contrast, literature from the social sciences proposes that meaningful explanations are structured as a dialog between the explainer and the explainee, suggesting a more active role for the user and her communication with the agent. In this paper, we present ASQ-IT – an interactive explanation system that presents video clips of the agent acting in its environment based on queries given by the user that describe temporal properties of behaviors of interest. Our approach is based on formal methods: queries in ASQ-IT&#39;s user interface map to a fragment of Linear Temporal Logic over finite traces (LTLf), which we developed, and our algorithm for query processing is based on automata theory. User studies show that end-users can understand and formulate queries in ASQ-IT and that using ASQ-IT assists users in identifying faulty agent behaviors.},
  archive      = {J_AIJ},
  author       = {Yotam Amitai and Ofra Amir and Guy Avni},
  doi          = {10.1016/j.artint.2024.104182},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104182},
  shortjournal = {Artif. Intell.},
  title        = {ASQ-IT: Interactive explanations for reinforcement-learning agents},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Planning with mental models – balancing explanations and
explicability. <em>AIJ</em>, <em>335</em>, 104181. (<a
href="https://doi.org/10.1016/j.artint.2024.104181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-aware planning involves generating plans that are explicable, i.e. conform to user expectations, as well as providing explanations when such plans cannot be found. In this paper, we bring these two concepts together and show how an agent can achieve a trade-off between these two competing characteristics of a plan. To achieve this, we conceive a first-of-its-kind planner MEGA that can reason about the possibility of explaining a plan in the plan generation process itself . We will also explore how solutions to such problems can be expressed as “self-explaining plans” – and show how this representation allows us to leverage classical planning compilations of epistemic planning to reason about this trade-off at plan generation time without having to incur the computational burden of having to search in the space of differences between the agent model and the mental model of the human in the loop in order to come up with the optimal trade-off. We will illustrate these concepts in two well-known planning domains, as well as with a robot in a typical search and reconnaissance task. Human factor studies in the latter highlight the usefulness of the proposed approach.},
  archive      = {J_AIJ},
  author       = {Sarath Sreedharan and Tathagata Chakraborti and Christian Muise and Subbarao Kambhampati},
  doi          = {10.1016/j.artint.2024.104181},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104181},
  shortjournal = {Artif. Intell.},
  title        = {Planning with mental models – balancing explanations and explicability},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A note on incorrect inferences in non-binary qualitative
probabilistic networks. <em>AIJ</em>, <em>335</em>, 104180. (<a
href="https://doi.org/10.1016/j.artint.2024.104180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qualitative probabilistic networks (QPNs) combine the conditional independence assumptions of Bayesian networks with the qualitative properties of positive and negative dependence. They formalise various intuitive properties of positive dependence to allow inferences over a large network of variables. However, we will demonstrate in this paper that, due to an incorrect symmetry property, many inferences obtained in non-binary QPNs are not mathematically true. We will provide examples of such incorrect inferences and briefly discuss possible resolutions.},
  archive      = {J_AIJ},
  author       = {Jack Storror Carter},
  doi          = {10.1016/j.artint.2024.104180},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104180},
  shortjournal = {Artif. Intell.},
  title        = {A note on incorrect inferences in non-binary qualitative probabilistic networks},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assessing fidelity in XAI post-hoc techniques: A comparative
study with ground truth explanations datasets. <em>AIJ</em>,
<em>335</em>, 104179. (<a
href="https://doi.org/10.1016/j.artint.2024.104179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evaluation of the fidelity of eXplainable Artificial Intelligence (XAI) methods to their underlying models is a challenging task, primarily due to the absence of a ground truth for explanations. However, assessing fidelity is a necessary step for ensuring a correct XAI methodology. In this study, we conduct a fair and objective comparison of the current state-of-the-art XAI methods by introducing three novel image datasets with reliable ground truth for explanations. The primary objective of this comparison is to identify methods with low fidelity and eliminate them from further research, thereby promoting the development of more trustworthy and effective XAI techniques. Our results demonstrate that XAI methods based on the direct gradient calculation and the backpropagation of output information to input yield higher accuracy and reliability compared to methods relying on perturbation based or Class Activation Maps (CAM). However, these methods tend to generate more noisy saliency maps. These findings have significant implications for the advancement of XAI methods, enabling the elimination of erroneous explanations and fostering the development of more robust and reliable XAI.},
  archive      = {J_AIJ},
  author       = {Miquel Miró-Nicolau and Antoni Jaume-i-Capó and Gabriel Moyà-Alcover},
  doi          = {10.1016/j.artint.2024.104179},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104179},
  shortjournal = {Artif. Intell.},
  title        = {Assessing fidelity in XAI post-hoc techniques: A comparative study with ground truth explanations datasets},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Truthful aggregation of budget proposals with
proportionality guarantees. <em>AIJ</em>, <em>335</em>, 104178. (<a
href="https://doi.org/10.1016/j.artint.2024.104178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a participatory budgeting problem, where a set of strategic agents wish to split a divisible budget among different projects, by aggregating their proposals on a single division. Unfortunately, the straightforward rule that divides the budget proportionally is susceptible to manipulation. Recently, a class of truthful mechanisms has been proposed, namely the moving phantom mechanisms. One such mechanism satisfies the proportionality property, in the sense that in the extreme case where all agents prefer a single project to receive the whole amount, the budget is assigned proportionally. While proportionality is a naturally desired property, it is defined over a limited type of preference profiles. To address this, we expand the notion of proportionality, by proposing a quantitative framework that evaluates a budget aggregation mechanism according to its worst-case distance from the proportional allocation. Crucially, this is defined for every preference profile. We study this measure on the class of moving phantom mechanisms, and we provide approximation guarantees. For two projects, we show that the Uniform Phantom mechanism is optimal among all truthful mechanisms. For three projects, we propose a new, proportional mechanism that is virtually optimal among all moving phantom mechanisms. Finally, we provide impossibility results regarding the approximability of moving phantom mechanisms.},
  archive      = {J_AIJ},
  author       = {Ioannis Caragiannis and George Christodoulou and Nicos Protopapas},
  doi          = {10.1016/j.artint.2024.104178},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104178},
  shortjournal = {Artif. Intell.},
  title        = {Truthful aggregation of budget proposals with proportionality guarantees},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Class fairness in online matching. <em>AIJ</em>,
<em>335</em>, 104177. (<a
href="https://doi.org/10.1016/j.artint.2024.104177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the study of fairness among classes of agents in online bipartite matching where there is a given set of offline vertices (aka agents) and another set of vertices (aka items) that arrive online and must be matched irrevocably upon arrival. In this setting, agents are partitioned into classes and the matching is required to be fair with respect to the classes. We adapt popular fairness notions (e.g. envy-freeness, proportionality, and maximin share) and their relaxations to this setting and study deterministic algorithms for matching indivisible items (leading to integral matchings) and for matching divisible items (leading to fractional matchings). For matching indivisible items, we propose an adaptive-priority-based algorithm, Match-and-Shift , prove that it achieves 1 2 12 -approximation of both class envy-freeness up to one item and class maximin share fairness, and show that each guarantee is tight. For matching divisible items, we design a water-filling-based algorithm, Equal-Filling , that achieves ( 1 − 1 e ) (1−1e) -approximation of class envy-freeness and class proportionality; we prove 1 − 1 e 1−1e to be tight for class proportionality and establish a 3 4 34 upper bound on class envy-freeness. Finally, we discuss several challenges in designing randomized algorithms that achieve reasonable fairness approximation ratios. Nonetheless, we build upon Equal-Filling to design a randomized algorithm for matching indivisible items, Equal-Filling-OCS , which achieves 0.593-approximation of class proportionality.},
  archive      = {J_AIJ},
  author       = {Hadi Hosseini and Zhiyi Huang and Ayumi Igarashi and Nisarg Shah},
  doi          = {10.1016/j.artint.2024.104177},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104177},
  shortjournal = {Artif. Intell.},
  title        = {Class fairness in online matching},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adversarial analysis of similarity-based sign prediction.
<em>AIJ</em>, <em>335</em>, 104173. (<a
href="https://doi.org/10.1016/j.artint.2024.104173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial social network analysis explores how social links can be altered or otherwise manipulated to hinder unwanted information collection. To date, however, problems of this kind have not been studied in the context of signed networks in which links have positive and negative labels. Such formalism is often used to model social networks with positive links indicating friendship or support and negative links indicating antagonism or opposition. In this work, we present a computational analysis of the problem of attacking sign prediction in signed networks, whereby the aim of the attacker (a network member) is to hide from the defender (an analyst) the signs of a target set of links by removing the signs of some other, non-target, links. While the problem turns out to be NP-hard if either local or global similarity measures are used for sign prediction, we provide a number of positive computational results, including an FPT-algorithm for eliminating common signed neighborhood and heuristic algorithms for evading local similarity-based link prediction in signed networks.},
  archive      = {J_AIJ},
  author       = {Michał T. Godziszewski and Marcin Waniek and Yulin Zhu and Kai Zhou and Talal Rahwan and Tomasz P. Michalak},
  doi          = {10.1016/j.artint.2024.104173},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104173},
  shortjournal = {Artif. Intell.},
  title        = {Adversarial analysis of similarity-based sign prediction},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning spatio-temporal dynamics on mobility networks for
adaptation to open-world events. <em>AIJ</em>, <em>335</em>, 104120. (<a
href="https://doi.org/10.1016/j.artint.2024.104120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a decisive part in the success of Mobility-as-a-Service (MaaS), spatio-temporal dynamics modeling on mobility networks is a challenging task particularly considering scenarios where open-world events drive mobility behavior deviated from the routines. While tremendous progress has been made to model high-level spatio-temporal regularities with deep learning, most, if not all of the existing methods are neither aware of the dynamic interactions among multiple transport modes on mobility networks, nor adaptive to unprecedented volatility brought by potential open-world events. In this paper, we are therefore motivated to improve the canonical spatio-temporal network (ST-Net) from two perspectives: (1) design a heterogeneous mobility information network (HMIN) to explicitly represent intermodality in multimodal mobility; (2) propose a memory-augmented dynamic filter generator (MDFG) to generate sequence-specific parameters in an on-the-fly fashion for various scenarios. The enhanced e vent- a ware s patio- t emporal net work, namely EAST-Net , is evaluated on several real-world datasets with a wide variety and coverage of open-world events. Both quantitative and qualitative experimental results verify the superiority of our approach compared with the state-of-the-art baselines. What is more, experiments show generalization ability of EAST-Net to perform zero-shot inference over different open-world events that have not been seen.},
  archive      = {J_AIJ},
  author       = {Zhaonan Wang and Renhe Jiang and Hao Xue and Flora D. Salim and Xuan Song and Ryosuke Shibasaki and Wei Hu and Shaowen Wang},
  doi          = {10.1016/j.artint.2024.104120},
  journal      = {Artificial Intelligence},
  month        = {10},
  pages        = {104120},
  shortjournal = {Artif. Intell.},
  title        = {Learning spatio-temporal dynamics on mobility networks for adaptation to open-world events},
  volume       = {335},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlled query evaluation in description logics through
consistent query answering. <em>AIJ</em>, <em>334</em>, 104176. (<a
href="https://doi.org/10.1016/j.artint.2024.104176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlled Query Evaluation (CQE) is a framework for the protection of confidential data, where a policy given in terms of logic formulae indicates which information must be kept private. Functions called censors filter query answering so that no answers are returned that may lead a user to infer data protected by the policy. The preferred censors, called optimal censors, are the ones that conceal only what is necessary, thus maximizing the returned answers. Typically, given a policy over a data or knowledge base, several optimal censors exist. Our research on CQE is based on the following intuition: confidential data are those that violate the logical assertions specifying the policy, and thus censoring them in query answering is similar to processing queries in the presence of inconsistent data as studied in Consistent Query Answering (CQA). In this paper, we investigate the relationship between CQE and CQA in the context of Description Logic ontologies. We borrow the idea from CQA that query answering is a form of skeptical reasoning that takes into account all possible optimal censors. This approach leads to a revised notion of CQE, which allows us to avoid making an arbitrary choice on the censor to be selected, as done by previous research on the topic. We then study the data complexity of query answering in our CQE framework, for conjunctive queries issued over ontologies specified in the popular Description Logics DL-Lite R DL-LiteR and EL ⊥ EL⊥ . In our analysis, we consider some variants of the censor language, which is the language used by the censor to enforce the policy. Whereas the problem is in general intractable for simple censor languages, we show that for DL-Lite R DL-LiteR ontologies it is first-order rewritable, and thus in AC 0 in data complexity, for the most expressive censor language we propose.},
  archive      = {J_AIJ},
  author       = {Gianluca Cima and Domenico Lembo and Riccardo Rosati and Domenico Fabio Savo},
  doi          = {10.1016/j.artint.2024.104176},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104176},
  shortjournal = {Artif. Intell.},
  title        = {Controlled query evaluation in description logics through consistent query answering},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Incremental measurement of structural entropy for dynamic
graphs. <em>AIJ</em>, <em>334</em>, 104175. (<a
href="https://doi.org/10.1016/j.artint.2024.104175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural entropy is a metric that measures the amount of information embedded in graph structure data under a strategy of hierarchical abstracting. To measure the structural entropy of a dynamic graph, we need to decode the optimal encoding tree corresponding to the best community partitioning for each snapshot. However, the current methods do not support dynamic encoding tree updating and incremental structural entropy computation. To address this issue, we propose Incre-2dSE , a novel incremental measurement framework that dynamically adjusts the community partitioning and efficiently computes the updated structural entropy for each updated graph. Specifically, Incre-2dSE includes incremental algorithms based on two dynamic adjustment strategies for two-dimensional encoding trees, i.e., the naive adjustment strategy and the node-shifting adjustment strategy , which support theoretical analysis of updated structural entropy and incrementally optimize community partitioning towards a lower structural entropy. We conduct extensive experiments on 3 artificial datasets generated by Hawkes Process and 3 real-world datasets. Experimental results confirm that our incremental algorithms effectively capture the dynamic evolution of the communities, reduce time consumption, and provide great interpretability.},
  archive      = {J_AIJ},
  author       = {Runze Yang and Hao Peng and Chunyang Liu and Angsheng Li},
  doi          = {10.1016/j.artint.2024.104175},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104175},
  shortjournal = {Artif. Intell.},
  title        = {Incremental measurement of structural entropy for dynamic graphs},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boosting optimal symbolic planning: Operator-potential
heuristics. <em>AIJ</em>, <em>334</em>, 104174. (<a
href="https://doi.org/10.1016/j.artint.2024.104174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic search guides the exploration of states via heuristic functions h estimating remaining cost. Symbolic search instead replaces the exploration of individual states with that of state sets, compactly represented using binary decision diagrams (BDDs). In cost-optimal planning, heuristic explicit search performs best overall, but symbolic search performs best in many individual domains, so both approaches together constitute the state of the art. Yet combinations of the two have so far not been an unqualified success, because (i) h must be applicable to sets of states rather than individual ones, and (ii) the different state partitioning induced by h may be detrimental for BDD size. Many competitive heuristic functions in planning do not qualify for (i), and it has been shown that even extremely informed heuristics can deteriorate search performance due to (ii). Here we show how to achieve (i) for a state-of-the-art family of heuristic functions, namely potential heuristics. These assign a fixed potential value to each state-variable/value pair, ensuring by LP constraints that the sum over these values, for any state, yields an admissible and consistent heuristic function. Our key observation is that we can express potential heuristics through fixed potential values for operators instead, capturing the change of heuristic value induced by each operator. These reformulated heuristics satisfy (i) because we can express the heuristic value change as part of the BDD transition relation in symbolic search steps. We run exhaustive experiments on IPC benchmarks, evaluating several different instantiations of potential heuristics in forward, backward, and bi-directional symbolic search. Our operator-potential heuristics turn out to be highly beneficial, in particular they hardly ever suffer from (ii). Our best configurations soundly beat previous optimal symbolic planning algorithms, bringing them on par with the state of the art in optimal heuristic explicit search planning in overall performance.},
  archive      = {J_AIJ},
  author       = {Daniel Fišer and Álvaro Torralba and Jörg Hoffmann},
  doi          = {10.1016/j.artint.2024.104174},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104174},
  shortjournal = {Artif. Intell.},
  title        = {Boosting optimal symbolic planning: Operator-potential heuristics},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyper-heuristics for personnel scheduling domains.
<em>AIJ</em>, <em>334</em>, 104172. (<a
href="https://doi.org/10.1016/j.artint.2024.104172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-life applications problems can frequently change or require small adaptations. Manually creating and tuning algorithms for different problem domains or different versions of a problem can be cumbersome and time-consuming. In this paper we consider several important problems with high practical relevance, which are Rotating Workforce Scheduling, Minimum Shift Design, and Bus Driver Scheduling. Instead of designing very specific solution methods , we propose to use the more general approach based on hyper-heuristics which take a set of simpler low-level heuristics and combine them to automatically create a fitting heuristic for the problem at hand. This paper presents a major study on applying hyper-heuristics to these domains, which contributes in four different ways: First, it defines new low-level heuristics for these scheduling domains, allowing to apply hyper-heuristics to them for the first time. Second, it provides a comparison of several state-of-the-art hyper-heuristics on those domains. Third, new best solutions for several instances of the different problem domains are found. Finally, a detailed investigation of the use of low-level heuristics by the hyper-heuristics gives insights in the way hyper-heuristics apply to different domains and the importance of different low-level heuristics. The results show that hyper-heuristics are able to perform well even on very complex practical problem domains in the area of scheduling and, while being more general and requiring less problem-specific adaptation, can in several cases compete with specialized algorithms for the specific problems. Several hyper-heuristics with very good performance across different real-life domains are identified. They can efficiently select low-level heuristics to apply for each domain, but for repeated application they benefit from evaluating and selecting the most useful subset of these heuristics. These results help to improve industrial systems in use for solving different scheduling scenarios by allowing faster and easier adaptation to new problem variants.},
  archive      = {J_AIJ},
  author       = {Lucas Kletzander and Nysret Musliu},
  doi          = {10.1016/j.artint.2024.104172},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104172},
  shortjournal = {Artif. Intell.},
  title        = {Hyper-heuristics for personnel scheduling domains},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Delegated online search. <em>AIJ</em>, <em>334</em>, 104171.
(<a href="https://doi.org/10.1016/j.artint.2024.104171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a delegation problem, a principal P P with commitment power tries to pick one out of n options. Each option is drawn independently from a known distribution. Instead of inspecting the options herself, P P delegates the information acquisition to a rational and self-interested agent A A . After inspection, A A proposes one of the options, and P P can accept or reject. Delegation is a classic setting in economic information design with many prominent applications, but the computational problems are only poorly understood. In this paper, we study a natural online variant of delegation, in which the agent searches through the options in an online fashion. For each option, he has to irrevocably decide if he wants to propose the current option or discard it, before seeing information on the next option(s). How can we design algorithms for P P that approximate the utility of her best option in hindsight? We show that in general P P can obtain a Θ ( 1 / n ) Θ(1/n) -approximation and extend this result to ratios of Θ ( k / n ) Θ(k/n) in case (1) A A has a lookahead of k rounds, or (2) A A can propose up to k different options. We provide fine-grained bounds independent of n based on three parameters. If the ratio of maximum and minimum utility for A A is bounded by a factor α , we obtain an Ω ( log ⁡ log ⁡ α / log ⁡ α ) Ω(log⁡log⁡α/log⁡α) -approximation algorithm, and we show that this is best possible. Additionally, if P P cannot distinguish options with the same value for herself, we show that ratios polynomial in 1 / α 1/α cannot be avoided. If there are at most β different utility values for A A , we show a Θ ( 1 / β ) Θ(1/β) -approximation. If the utilities of P P and A A for each option are related by a factor γ , we obtain an Ω ( 1 / log ⁡ γ ) Ω(1/log⁡γ) -approximation, where O ( log ⁡ log ⁡ γ / log ⁡ γ ) O(log⁡log⁡γ/log⁡γ) is best possible.},
  archive      = {J_AIJ},
  author       = {Pirmin Braun and Niklas Hahn and Martin Hoefer and Conrad Schecker},
  doi          = {10.1016/j.artint.2024.104171},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104171},
  shortjournal = {Artif. Intell.},
  title        = {Delegated online search},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extensive study of security games with strategic
informants. <em>AIJ</em>, <em>334</em>, 104162. (<a
href="https://doi.org/10.1016/j.artint.2024.104162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past years, game-theoretic modeling for security and public safety issues (also known as security games ) have attracted intensive research attention and have been successfully deployed in many real-world applications for fighting, e.g., illegal poaching, fishing and urban crimes. However, few existing works consider how information from local communities would affect the structure of these games. In this paper, we systematically investigate how a new type of players – strategic informants who are from local communities and may observe and report upcoming attacks – affects the classic defender-attacker security interactions. Characterized by a private type, each informant has a utility structure that drives their strategic behaviors. For situations with a single informant, we capture the problem as a 3-player extensive-form game and develop a novel solution concept, Strong Stackelberg-perfect Bayesian equilibrium, for the game. To find an optimal defender strategy, we establish that though the informant can have infinitely many types in general, there always exists an optimal defense plan using only a linear number of patrol strategies; this succinct characterization then enables us to efficiently solve the game via linear programming. For situations with multiple informants, we show that there is also an optimal defense plan with only a linear number of patrol strategies that admits a simple structure based on plurality voting among multiple informants. Finally, we conduct extensive experiments to study the effect of the strategic informants and demonstrate the efficiency of our algorithm. Our experiments show that the existence of such informants significantly increases the defender&#39;s utility. Even though the informants exhibit strategic behaviors, the information they supply holds great value as defensive resources. Compared to existing works, our study leads to a deeper understanding on the role of informants in such defender-attacker interactions.},
  archive      = {J_AIJ},
  author       = {Weiran Shen and Minbiao Han and Weizhe Chen and Taoan Huang and Rohit Singh and Haifeng Xu and Fei Fang},
  doi          = {10.1016/j.artint.2024.104162},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104162},
  shortjournal = {Artif. Intell.},
  title        = {An extensive study of security games with strategic informants},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A domain-independent agent architecture for adaptive
operation in evolving open worlds. <em>AIJ</em>, <em>334</em>, 104161.
(<a href="https://doi.org/10.1016/j.artint.2024.104161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reasoning agents are ill-equipped to act in novel situations in which their model of the environment no longer sufficiently represents the world. We propose HYDRA, a framework for designing model-based agents operating in mixed discrete-continuous worlds that can autonomously detect when the environment has evolved from its canonical setup, understand how it has evolved, and adapt the agents&#39; models to perform effectively. HYDRA is based upon PDDL+, a rich modeling language for planning in mixed, discrete-continuous environments. It augments the planning module with visual reasoning, task selection, and action execution modules for closed-loop interaction with complex environments. HYDRA implements a novel meta-reasoning process that enables the agent to monitor its own behavior from a variety of aspects. The process employs a diverse set of computational methods to maintain expectations about the agent&#39;s own behavior in an environment. Divergences from those expectations are useful in detecting when the environment has evolved and identifying opportunities to adapt the underlying models. HYDRA builds upon ideas from diagnosis and repair and uses a heuristics-guided search over model changes such that they become competent in novel conditions. The HYDRA framework has been used to implement novelty-aware agents for three diverse domains - CartPole++ (a higher dimension variant of a classic control problem), Science Birds (an IJCAI competition problem 1 ), and PogoStick (a specific problem domain in Minecraft). We report empirical observations from these domains to demonstrate the efficacy of various components in the novelty meta-reasoning process.},
  archive      = {J_AIJ},
  author       = {Shiwali Mohan and Wiktor Piotrowski and Roni Stern and Sachin Grover and Sookyung Kim and Jacob Le and Yoni Sher and Johan de Kleer},
  doi          = {10.1016/j.artint.2024.104161},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104161},
  shortjournal = {Artif. Intell.},
  title        = {A domain-independent agent architecture for adaptive operation in evolving open worlds},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability based on single-agent deviations in additively
separable hedonic games. <em>AIJ</em>, <em>334</em>, 104160. (<a
href="https://doi.org/10.1016/j.artint.2024.104160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coalition formation is a central concern in multiagent systems. A common desideratum for coalition structures is stability, defined by the absence of beneficial deviations of single agents. Such deviations require an agent to improve her utility by joining another coalition. On top of that, the feasibility of deviations may also be restricted by demanding consent of agents in the welcoming and/or the abandoned coalition. While most of the literature focuses on deviations constrained by unanimous consent, we also study consent decided by majority vote and introduce two new stability notions that can be seen as local variants of another solution concept called popularity. We investigate stability in additively separable hedonic games by pinpointing boundaries to computational complexity depending on the type of consent and friend-oriented utility restrictions. The latter restrictions shed new light on well-studied classes of games based on the appreciation of friends or the aversion to enemies. Many of our positive results follow from a new combinatorial observation that we call the Deviation Lemma and that we leverage to prove the convergence of simple and natural single-agent dynamics under fairly general conditions. Our negative results, in particular, resolve the complexity of contractual Nash stability in additively separable hedonic games.},
  archive      = {J_AIJ},
  author       = {Felix Brandt and Martin Bullinger and Leo Tappe},
  doi          = {10.1016/j.artint.2024.104160},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104160},
  shortjournal = {Artif. Intell.},
  title        = {Stability based on single-agent deviations in additively separable hedonic games},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Functional relation field: A model-agnostic framework for
multivariate time series forecasting. <em>AIJ</em>, <em>334</em>,
104158. (<a href="https://doi.org/10.1016/j.artint.2024.104158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multivariate time series forecasting, the most popular strategy for modeling the relationship between multiple time series is the construction of graph, where each time series is represented as a node and related nodes are connected by edges. However, the relationship between multiple time series is typically complicated, e.g. the sum of outflows from upstream nodes may be equal to the inflows of downstream nodes. Such relations widely exist in many real-world scenarios for multivariate time series forecasting, yet are far from well studied. In these cases, graph might be insufficient for modeling the complex dependency between nodes. To this end, we explore a new framework to model the inter-node relationship in a more precise way based our proposed inductive bias, Functional Relation Field , where a group of functions parameterized by neural networks are learned to characterize the dependency between multiple time series. Essentially, these learned functions then form a “field”, i.e. a particular set of constraints, to regularize the training loss of the backbone prediction network and enforce the inference process to satisfy these constraints. Since our framework introduces the relationship bias in a data-driven manner, it is flexible and model-agnostic such that it can be applied to any existing multivariate time series prediction networks for boosting performance. The experiment is conducted on one toy dataset to show our approach can well recover the true constraint relationship between nodes. And various real-world datasets are also considered with different backbone prediction networks. Results show that the prediction error can be reduced remarkably with the aid of the proposed framework.},
  archive      = {J_AIJ},
  author       = {Ting Li and Bing Yu and Jianguo Li and Zhanxing Zhu},
  doi          = {10.1016/j.artint.2024.104158},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104158},
  shortjournal = {Artif. Intell.},
  title        = {Functional relation field: A model-agnostic framework for multivariate time series forecasting},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Probabilistic reach-avoid for bayesian neural networks.
<em>AIJ</em>, <em>334</em>, 104132. (<a
href="https://doi.org/10.1016/j.artint.2024.104132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning seeks to simultaneously learn the dynamics of an unknown stochastic environment and synthesise an optimal policy for acting in it. Ensuring the safety and robustness of sequential decisions made through a policy in such an environment is a key challenge for policies intended for safety-critical scenarios. In this work, we investigate two complementary problems: first, computing reach-avoid probabilities for iterative predictions made with dynamical models, with dynamics described by Bayesian neural network (BNN); second, synthesising control policies that are optimal with respect to a given reach-avoid specification (reaching a “target” state, while avoiding a set of “unsafe” states) and a learned BNN model. Our solution leverages interval propagation and backward recursion techniques to compute lower bounds for the probability that a policy&#39;s sequence of actions leads to satisfying the reach-avoid specification. Such computed lower bounds provide safety certification for the given policy and BNN model. We then introduce control synthesis algorithms to derive policies maximizing said lower bounds on the safety probability. We demonstrate the effectiveness of our method on a series of control benchmarks characterized by learned BNN dynamics models. On our most challenging benchmark, compared to purely data-driven policies the optimal synthesis algorithm is able to provide more than a four-fold increase in the number of certifiable states and more than a three-fold increase in the average guaranteed reach-avoid probability.},
  archive      = {J_AIJ},
  author       = {Matthew Wicker and Luca Laurenti and Andrea Patane and Nicola Paoletti and Alessandro Abate and Marta Kwiatkowska},
  doi          = {10.1016/j.artint.2024.104132},
  journal      = {Artificial Intelligence},
  month        = {9},
  pages        = {104132},
  shortjournal = {Artif. Intell.},
  title        = {Probabilistic reach-avoid for bayesian neural networks},
  volume       = {334},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Credulous acceptance in high-order argumentation frameworks
with necessities: An incremental approach. <em>AIJ</em>, <em>333</em>,
104159. (<a href="https://doi.org/10.1016/j.artint.2024.104159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Argumentation is an important research area in the field of AI. There is a substantial amount of work on different aspects of Dung&#39;s abstract Argumentation Framework (AF). Two relevant aspects considered separately so far are: i ) extending the framework to account for recursive attacks and supports, and i i ) ii) considering dynamics, i.e. , AFs evolving over time. In this paper, we jointly deal with these two aspects. We focus on High-Order Argumentation Frameworks with Necessities (HOAFNs) which allow for attack and support relations (interpreted as necessity ) not only between arguments but also targeting attacks and supports at any level. We propose an approach for the incremental evaluation of the credulous acceptance problem in HOAFNs, by “incrementally” computing an extension (a set of accepted arguments, attacks and supports), if it exists, containing a given goal element in an updated HOAFN. In particular, we are interested in monitoring the credulous acceptance of a given argument, attack or support (goal) in an evolving HOAFN. Thus, our approach assumes to have a HOAFN Δ, a goal ϱ occurring in Δ, an extension E for Δ containing ϱ , and an update u establishing some changes in the original HOAFN, and uses the extension for first checking whether the update is relevant; for relevant updates, an extension of the updated HOAFN containing the goal is computed by translating the problem to the AF domain and leveraging on AF solvers. We provide formal results for our incremental approach and empirically show that it outperforms the evaluation from scratch of the credulous acceptance problem for an updated HOAFN.},
  archive      = {J_AIJ},
  author       = {Gianvincenzo Alfano and Andrea Cohen and Sebastian Gottifredi and Sergio Greco and Francesco Parisi and Guillermo R. Simari},
  doi          = {10.1016/j.artint.2024.104159},
  journal      = {Artificial Intelligence},
  month        = {8},
  pages        = {104159},
  shortjournal = {Artif. Intell.},
  title        = {Credulous acceptance in high-order argumentation frameworks with necessities: An incremental approach},
  volume       = {333},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Acquiring and modeling abstract commonsense knowledge via
conceptualization. <em>AIJ</em>, <em>333</em>, 104149. (<a
href="https://doi.org/10.1016/j.artint.2024.104149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conceptualization, or viewing entities and situations as instances of abstract concepts in mind and making inferences based on that, is a vital component in human intelligence for commonsense reasoning. Despite recent progress in artificial intelligence to acquire and model commonsense attributed to neural language models and commonsense knowledge graphs (CKGs), conceptualization is yet to be introduced thoroughly, making current approaches ineffective to cover knowledge about countless diverse entities and situations in the real world. To address the problem, we thoroughly study the role of conceptualization in commonsense reasoning, and formulate a framework to replicate human conceptual induction by acquiring abstract knowledge about events regarding abstract concepts, as well as higher-level triples or inferences upon them. We then apply the framework to ATOMIC, a large-scale human-annotated CKG, aided by the taxonomy Probase. We annotate a dataset on the validity of contextualized conceptualizations from ATOMIC on both event and triple levels, develop a series of heuristic rules based on linguistic features, and train a set of neural models to generate and verify abstract knowledge. Based on these components, a pipeline to acquire abstract knowledge is built. A large abstract CKG upon ATOMIC is then induced, ready to be instantiated to infer about unseen entities or situations. Finally, we empirically show the benefits of augmenting CKGs with abstract knowledge in downstream tasks like commonsense inference and zero-shot commonsense QA.},
  archive      = {J_AIJ},
  author       = {Mutian He and Tianqing Fang and Weiqi Wang and Yangqiu Song},
  doi          = {10.1016/j.artint.2024.104149},
  journal      = {Artificial Intelligence},
  month        = {8},
  pages        = {104149},
  shortjournal = {Artif. Intell.},
  title        = {Acquiring and modeling abstract commonsense knowledge via conceptualization},
  volume       = {333},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing pathfinding for goal legibility and recognition
in cooperative partially observable environments. <em>AIJ</em>,
<em>333</em>, 104148. (<a
href="https://doi.org/10.1016/j.artint.2024.104148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we perform a joint design of goal legibility and recognition in a cooperative, multi-agent pathfinding setting with partial observability. More specifically, we consider a set of identical agents (the actors) that move in an environment only partially observable to an observer in the loop. The actors are tasked with reaching a set of locations that need to be serviced in a timely fashion. The observer monitors the actors&#39; behavior from a distance and needs to identify each actor&#39;s destination based on the actor&#39;s observable movements. Our approach generates legible paths for the actors; namely, it constructs one path from the origin to each destination so that these paths overlap as little as possible while satisfying budget constraints. It also equips the observer with a goal-recognition mapping between unique sequences of observations and destinations, ensuring that the observer can infer an actor&#39;s destination by making the minimum number of observations (legibility delay). Our method substantially extends previous work, which is limited to an observer with full observability, showing that optimizing pathfinding for goal legibility and recognition can be performed via a reformulation into a classical minimum cost flow problem in the partially observable case when the algorithms for the fully observable case are appropriately modified. Our empirical evaluation shows that our techniques are as effective in partially observable settings as in fully observable ones.},
  archive      = {J_AIJ},
  author       = {Sara Bernardini and Fabio Fagnani and Alexandra Neacsu and Santiago Franco},
  doi          = {10.1016/j.artint.2024.104148},
  journal      = {Artificial Intelligence},
  month        = {8},
  pages        = {104148},
  shortjournal = {Artif. Intell.},
  title        = {Optimizing pathfinding for goal legibility and recognition in cooperative partially observable environments},
  volume       = {333},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge is power: Open-world knowledge representation
learning for knowledge-based visual reasoning. <em>AIJ</em>,
<em>333</em>, 104147. (<a
href="https://doi.org/10.1016/j.artint.2024.104147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-based visual reasoning requires the ability to associate outside knowledge that is not present in a given image for cross-modal visual understanding. Two deficiencies of the existing approaches are that (1) they only employ or construct elementary and explicit but superficial knowledge graphs while lacking complex and implicit but indispensable cross-modal knowledge for visual reasoning, and (2) they also cannot reason new/ unseen images or questions in open environments and are often violated in real-world applications. How to represent and leverage tacit multimodal knowledge for open-world visual reasoning scenarios has been less studied. In this paper, we propose a novel open-world knowledge representation learning method to not only construct implicit knowledge representations from the given images and their questions but also enable knowledge transfer from a known given scene to an unknown scene for answer prediction. Extensive experiments conducted on six benchmarks demonstrate the superiority of our approach over other state-of-the-art methods. We apply our approach to other visual reasoning tasks, and the experimental results show that our approach, with its good performance, can support related reasoning applications.},
  archive      = {J_AIJ},
  author       = {Wenbo Zheng and Lan Yan and Fei-Yue Wang},
  doi          = {10.1016/j.artint.2024.104147},
  journal      = {Artificial Intelligence},
  month        = {8},
  pages        = {104147},
  shortjournal = {Artif. Intell.},
  title        = {Knowledge is power: Open-world knowledge representation learning for knowledge-based visual reasoning},
  volume       = {333},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint learning of reward machines and policies in
environments with partially known semantics. <em>AIJ</em>, <em>333</em>,
104146. (<a href="https://doi.org/10.1016/j.artint.2024.104146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of reinforcement learning for a task encoded by a reward machine. The task is defined over a set of properties in the environment, called atomic propositions, and represented by Boolean variables. One unrealistic assumption commonly used in the literature is that the truth values of these propositions are accurately known. In real situations, however, these truth values are uncertain since they come from sensors that suffer from imperfections. At the same time, reward machines can be difficult to model explicitly, especially when they encode complicated tasks. We develop a reinforcement-learning algorithm that infers a reward machine that encodes the underlying task while learning how to execute it, despite the uncertainties of the propositions&#39; truth values. In order to address such uncertainties, the algorithm maintains a probabilistic estimate about the truth value of the atomic propositions; it updates this estimate according to new sensory measurements that arrive from exploration of the environment. Additionally, the algorithm maintains a hypothesis reward machine, which acts as an estimate of the reward machine that encodes the task to be learned. As the agent explores the environment, the algorithm updates the hypothesis reward machine according to the obtained rewards and the estimate of the atomic propositions&#39; truth value. Finally, the algorithm uses a Q-learning procedure for the states of the hypothesis reward machine to determine an optimal policy that accomplishes the task. We prove that the algorithm successfully infers the reward machine and asymptotically learns a policy that accomplishes the respective task.},
  archive      = {J_AIJ},
  author       = {Christos K. Verginis and Cevahir Koprulu and Sandeep Chinchali and Ufuk Topcu},
  doi          = {10.1016/j.artint.2024.104146},
  journal      = {Artificial Intelligence},
  month        = {8},
  pages        = {104146},
  shortjournal = {Artif. Intell.},
  title        = {Joint learning of reward machines and policies in environments with partially known semantics},
  volume       = {333},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploring the psychology of LLMs’ moral and legal reasoning.
<em>AIJ</em>, <em>333</em>, 104145. (<a
href="https://doi.org/10.1016/j.artint.2024.104145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) exhibit expert-level performance in tasks across a wide range of different domains. Ethical issues raised by LLMs and the need to align future versions makes it important to know how state of the art models reason about moral and legal issues. In this paper, we employ the methods of experimental psychology to probe into this question. We replicate eight studies from the experimental literature with instances of Google&#39;s Gemini Pro, Anthropic&#39;s Claude 2.1, OpenAI&#39;s GPT-4, and Meta&#39;s Llama 2 Chat 70b. We find that alignment with human responses shifts from one experiment to another, and that models differ amongst themselves as to their overall alignment, with GPT-4 taking a clear lead over all other models we tested. Nonetheless, even when LLM-generated responses are highly correlated to human responses, there are still systematic differences, with a tendency for models to exaggerate effects that are present among humans, in part by reducing variance. This recommends caution with regards to proposals of replacing human participants with current state-of-the-art LLMs in psychological research and highlights the need for further research about the distinctive aspects of machine psychology.},
  archive      = {J_AIJ},
  author       = {Guilherme F.C.F. Almeida and José Luiz Nunes and Neele Engelmann and Alex Wiegmann and Marcelo de Araújo},
  doi          = {10.1016/j.artint.2024.104145},
  journal      = {Artificial Intelligence},
  month        = {8},
  pages        = {104145},
  shortjournal = {Artif. Intell.},
  title        = {Exploring the psychology of LLMs’ moral and legal reasoning},
  volume       = {333},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-graph representation for event extraction.
<em>AIJ</em>, <em>332</em>, 104144. (<a
href="https://doi.org/10.1016/j.artint.2024.104144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction has a trend in identifying event triggers and arguments in a unified framework, which has the advantage of avoiding the cascading failure in pipeline methods. The main problem is that joint models usually assume a one-to-one relationship between event triggers and arguments. It leads to the argument multiplexing problem, in which an argument mention can serve different roles in an event or shared by different events. To address this problem, we propose a multigraph-based event extraction framework. It allows parallel edges between any nodes, which is effective to represent semantic structures of an event. The framework enables the neural network to map a sentence(s) into a structurized semantic representation, which encodes multi-overlapped events. After evaluated on four public datasets, our method achieves the state-of-the-art performance, outperforming all compared models. Analytical experiments show that the multigraph representation is effective to address the argument multiplexing problem and helpful to advance the discriminability of the neural network for event extraction.},
  archive      = {J_AIJ},
  author       = {Hui Huang and Yanping Chen and Chuan Lin and Ruizhang Huang and Qinghua Zheng and Yongbin Qin},
  doi          = {10.1016/j.artint.2024.104144},
  journal      = {Artificial Intelligence},
  month        = {7},
  pages        = {104144},
  shortjournal = {Artif. Intell.},
  title        = {A multi-graph representation for event extraction},
  volume       = {332},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mitigating social biases of pre-trained language models via
contrastive self-debiasing with double data augmentation. <em>AIJ</em>,
<em>332</em>, 104143. (<a
href="https://doi.org/10.1016/j.artint.2024.104143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained Language Models (PLMs) have been shown to inherit and even amplify the social biases contained in the training corpus, leading to undesired stereotype in real-world applications. Existing techniques for mitigating the social biases of PLMs mainly rely on data augmentation with manually designed prior knowledge or fine-tuning with abundant external corpora to debias. However, these methods are not only limited by artificial experience, but also consume a lot of resources to access all the parameters of the PLMs and are prone to introduce new external biases when fine-tuning with external corpora. In this paper, we propose a C ontrastive Self- D ebiasing Model with D ouble D ata Augmentation (named CD 3 ) for mitigating social biases of PLMs. Specifically, CD 3 consists of two stages: double data augmentation and contrastive self-debiasing. First, we build on counterfactual data augmentation to perform a secondary augmentation using biased prompts that are automatically searched by maximizing the differences in PLMs&#39; encoding across demographic groups. Double data augmentation further amplifies the biases between sample pairs to break the limitations of previous debiasing models that heavily rely on prior knowledge in data augmentation. We then leverage the augmented data for contrastive learning to train a plug-and-play adapter to mitigate the social biases in PLMs&#39; encoding without tuning the PLMs. Extensive experimental results on BERT, ALBERT, and RoBERTa on several real-world datasets and fairness metrics show that CD 3 outperforms baseline models on gender debiasing and race debiasing while retaining the language modeling capabilities of PLMs.},
  archive      = {J_AIJ},
  author       = {Yingji Li and Mengnan Du and Rui Song and Xin Wang and Mingchen Sun and Ying Wang},
  doi          = {10.1016/j.artint.2024.104143},
  journal      = {Artificial Intelligence},
  month        = {7},
  pages        = {104143},
  shortjournal = {Artif. Intell.},
  title        = {Mitigating social biases of pre-trained language models via contrastive self-debiasing with double data augmentation},
  volume       = {332},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative voting with partial preferences. <em>AIJ</em>,
<em>332</em>, 104133. (<a
href="https://doi.org/10.1016/j.artint.2024.104133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voting platforms can offer participants the option to sequentially modify their preferences, whenever they have a reason to do so. But such iterative voting may never converge, meaning that a state where all agents are happy with their submitted preferences may never be reached. This problem has received increasing attention within the area of computational social choice. Yet, the relevant literature hinges on the rather stringent assumption that the agents are able to rank all alternatives they are presented with, i.e., that they hold preferences that are linear orders. We relax this assumption and investigate iterative voting under partial preferences. To that end, we define and study two families of rules that extend the well-known k -approval rules in the standard voting framework. Although we show that for none of these rules convergence is guaranteed in general, we also are able to identify natural conditions under which such guarantees can be given. Finally, we conduct simulation experiments to test the practical implications of our results.},
  archive      = {J_AIJ},
  author       = {Zoi Terzopoulou and Panagiotis Terzopoulos and Ulle Endriss},
  doi          = {10.1016/j.artint.2024.104133},
  journal      = {Artificial Intelligence},
  month        = {7},
  pages        = {104133},
  shortjournal = {Artif. Intell.},
  title        = {Iterative voting with partial preferences},
  volume       = {332},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete preference games with logic-based agents: Formal
framework, complexity, and islands of tractability. <em>AIJ</em>,
<em>332</em>, 104131. (<a
href="https://doi.org/10.1016/j.artint.2024.104131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing and predicting the dynamics of opinion formation in the context of social environments are problems that attracted much attention in literature. While grounded in social psychology, these problems are nowadays popular within the artificial intelligence community, where opinion dynamics are often studied via game-theoretic models in which individuals/agents hold opinions taken from a fixed set of discrete alternatives, and where the goal is to find those configurations where the opinions expressed by the agents emerge as a kind of compromise between their innate opinions and the social pressure they receive from the environments. As a matter of facts, however, these studies are based on very high-level and sometimes simplistic formalizations of the social environments, where the mental state of each individual is typically encoded as a variable taking values from a Boolean domain. To overcome these limitations, the paper proposes a framework generalizing such discrete preference games by modeling the reasoning capabilities of agents in terms of weighted propositional logics. It is shown that the framework easily encodes different kinds of earlier approaches and fits more expressive scenarios populated by conformist and dissenter agents. Problems related to the existence and computation of stable configurations are studied, under different theoretical assumptions on the structural shape of the social interactions and on the class of logic formulas that are allowed. Remarkably, during its trip to identify some relevant tractability islands, the paper devises a novel technical machinery whose significance goes beyond the specific application to analyzing opinion formation and diffusion, since it significantly enlarges the class of Integer Linear Programs that were known to be tractable so far.},
  archive      = {J_AIJ},
  author       = {Gianluigi Greco and Marco Manna},
  doi          = {10.1016/j.artint.2024.104131},
  journal      = {Artificial Intelligence},
  month        = {7},
  pages        = {104131},
  shortjournal = {Artif. Intell.},
  title        = {Discrete preference games with logic-based agents: Formal framework, complexity, and islands of tractability},
  volume       = {332},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified momentum-based paradigm of decentralized SGD for
non-convex models and heterogeneous data. <em>AIJ</em>, <em>332</em>,
104130. (<a href="https://doi.org/10.1016/j.artint.2024.104130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging distributed applications recently boosted the development of decentralized machine learning, especially in IoT and edge computing fields. In real-world scenarios, the common problems of non-convexity and data heterogeneity result in inefficiency, performance degradation, and development stagnation. The bulk of studies concentrate on one of the issues mentioned above without having a more general framework that has been proven optimal. To this end, we propose a unified paradigm called UMP, which comprises two algorithms D-SUM and GT-DSUM based on the momentum technique with decentralized stochastic gradient descent (SGD). The former provides a convergence guarantee for general non-convex objectives, while the latter is extended by introducing gradient tracking, which estimates the global optimization direction to mitigate data heterogeneity ( i.e. , distribution drift). We can cover most momentum-based variants based on the classical heavy ball or Nesterov&#39;s acceleration with different parameters in UMP. In theory, we rigorously provide the convergence analysis of these two approaches for non-convex objectives and conduct extensive experiments, demonstrating a significant improvement in model accuracy up to 57.6% compared to other methods in practice.},
  archive      = {J_AIJ},
  author       = {Haizhou Du and Chaoqian Cheng and Chengdong Ni},
  doi          = {10.1016/j.artint.2024.104130},
  journal      = {Artificial Intelligence},
  month        = {7},
  pages        = {104130},
  shortjournal = {Artif. Intell.},
  title        = {A unified momentum-based paradigm of decentralized SGD for non-convex models and heterogeneous data},
  volume       = {332},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Polarized message-passing in graph neural networks.
<em>AIJ</em>, <em>331</em>, 104129. (<a
href="https://doi.org/10.1016/j.artint.2024.104129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present Polarized message-passing (PMP), a novel paradigm to revolutionize the design of message-passing graph neural networks (GNNs). In contrast to existing methods, PMP captures the power of node-node similarity and dissimilarity to acquire dual sources of messages from neighbors. The messages are then coalesced to enable GNNs to learn expressive representations from sparse but strongly correlated neighbors. Three novel GNNs based on the PMP paradigm, namely PMP graph convolutional network (PMP-GCN), PMP graph attention network (PMP-GAT), and PMP graph PageRank network (PMP-GPN) are proposed to perform various downstream tasks. Theoretical analysis is also conducted to verify the high expressiveness of the proposed PMP-based GNNs. In addition, an empirical study of five learning tasks based on 12 real-world datasets is conducted to validate the performances of PMP-GCN, PMP-GAT, and PMP-GPN. The proposed PMP-GCN, PMP-GAT, and PMP-GPN outperform numerous strong message-passing GNNs across all five learning tasks, demonstrating the effectiveness of the proposed PMP paradigm.},
  archive      = {J_AIJ},
  author       = {Tiantian He and Yang Liu and Yew-Soon Ong and Xiaohu Wu and Xin Luo},
  doi          = {10.1016/j.artint.2024.104129},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104129},
  shortjournal = {Artif. Intell.},
  title        = {Polarized message-passing in graph neural networks},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matching papers and reviewers at large conferences.
<em>AIJ</em>, <em>331</em>, 104119. (<a
href="https://doi.org/10.1016/j.artint.2024.104119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peer-reviewed conferences, the main publication venues in CS, rely critically on matching highly qualified reviewers for each paper. Because of the growing scale of these conferences, the tight timelines on which they operate, and a recent surge in explicitly dishonest behavior, there is now no alternative to performing this matching in an automated way. This paper introduces Large Conference Matching (LCM) , a novel reviewer–paper matching approach that was recently deployed in the 35th AAAI Conference on Artificial Intelligence (AAAI 2021), and has since been adopted (wholly or partially) by other conferences including ICML 2022, AAAI 2022-2024, and IJCAI 2022-2024. LCM has three main elements: (1) collecting and processing input data to identify problematic matches and generate reviewer–paper scores; (2) formulating and solving an optimization problem to find good reviewer–paper matchings; and (3) a two-phase reviewing process that shifts reviewing resources away from papers likely to be rejected and towards papers closer to the decision boundary. This paper also describes an evaluation of these innovations based on an extensive post-hoc analysis on real data—including a comparison with the matching algorithm used in AAAI&#39;s previous (2020) iteration—and supplements this with additional numerical experimentation. 2},
  archive      = {J_AIJ},
  author       = {Kevin Leyton-Brown and Mausam and Yatin Nandwani and Hedayat Zarkoob and Chris Cameron and Neil Newman and Dinesh Raghu},
  doi          = {10.1016/j.artint.2024.104119},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104119},
  shortjournal = {Artif. Intell.},
  title        = {Matching papers and reviewers at large conferences},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Almost proportional allocations of indivisible chores:
Computation, approximation and efficiency. <em>AIJ</em>, <em>331</em>,
104118. (<a href="https://doi.org/10.1016/j.artint.2024.104118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proportionality (PROP) is one of the simplest and most intuitive fairness criteria used for allocating items among agents with additive utilities. However, when the items are indivisible, ensuring PROP becomes unattainable, leading to increased focus on its relaxations. In this paper, we focus on the relaxation of proportionality up to any item (PROPX), where proportionality is satisfied if an arbitrary item is removed from every agent&#39;s allocation. We show that PROPX is an appealing fairness notion for the allocation of indivisible chores, which approximately implies some share-based notions, such as maximin share (MMS) and AnyPrice share (APS). We further provide a comprehensive understanding of PROPX allocations, regarding the computation, approximation, and compatibility with efficiency. On top of these, we extend the study to scenarios where agents do not share equal liability towards the chores, and approximate PROPX allocations using partial information about agents&#39; utilities.},
  archive      = {J_AIJ},
  author       = {Haris Aziz and Bo Li and Hervé Moulin and Xiaowei Wu and Xinran Zhu},
  doi          = {10.1016/j.artint.2024.104118},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104118},
  shortjournal = {Artif. Intell.},
  title        = {Almost proportional allocations of indivisible chores: Computation, approximation and efficiency},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Knowledge-driven profile dynamics. <em>AIJ</em>,
<em>331</em>, 104117. (<a
href="https://doi.org/10.1016/j.artint.2024.104117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, user profiles have been used in several areas of information technology. In the literature, most research works, and systems focus on the creation of profiles (using Data Mining techniques based on user&#39;s navigation or interaction history). In general, the dynamics of profiles are made by means of a systematic recreation of the profiles, without using the previous profiles. In this paper we propose to formalize the creation, representation, and dynamics of profiles from a Knowledge-Driven perspective. We introduce and axiomatically characterize four operators for changing profiles using a belief change inspired approach.},
  archive      = {J_AIJ},
  author       = {Eduardo Fermé and Marco Garapa and Maurício D.L. Reis and Yuri Almeida and Teresa Paulino and Mariana Rodrigues},
  doi          = {10.1016/j.artint.2024.104117},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104117},
  shortjournal = {Artif. Intell.},
  title        = {Knowledge-driven profile dynamics},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Critical observations in model-based diagnosis.
<em>AIJ</em>, <em>331</em>, 104116. (<a
href="https://doi.org/10.1016/j.artint.2024.104116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of finding the part of the observations that is useful for the diagnosis. We define a sub-observation as an abstraction of the observations. We then argue that a sub-observation is sufficient if it allows a diagnoser to derive the same minimal diagnosis as the original observations; and we define critical observations as a maximally abstracted sufficient sub-observation. We show how to compute a critical observation, and discuss a number of algorithmic improvements that also shed light on the theory of critical observations. Finally, we illustrate this framework on both state-based and event-based observations.},
  archive      = {J_AIJ},
  author       = {Cody James Christopher and Alban Grastien},
  doi          = {10.1016/j.artint.2024.104116},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104116},
  shortjournal = {Artif. Intell.},
  title        = {Critical observations in model-based diagnosis},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hyperbolic secant representation of the logistic function:
Application to probabilistic multiple instance learning for CT
intracranial hemorrhage detection. <em>AIJ</em>, <em>331</em>, 104115.
(<a href="https://doi.org/10.1016/j.artint.2024.104115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Instance Learning (MIL) is a weakly supervised paradigm that has been successfully applied to many different scientific areas and is particularly well suited to medical imaging. Probabilistic MIL methods, and more specifically Gaussian Processes (GPs), have achieved excellent results due to their high expressiveness and uncertainty quantification capabilities. One of the most successful GP-based MIL methods, VGPMIL, resorts to a variational bound to handle the intractability of the logistic function. Here, we formulate VGPMIL using Pólya-Gamma random variables. This approach yields the same variational posterior approximations as the original VGPMIL, which is a consequence of the two representations that the Hyperbolic Secant distribution admits. This leads us to propose a general GP-based MIL method that takes different forms by simply leveraging distributions other than the Hyperbolic Secant one. Using the Gamma distribution we arrive at a new approach that obtains competitive or superior predictive performance and efficiency. This is validated in a comprehensive experimental study including one synthetic MIL dataset, two well-known MIL benchmarks, and a real-world medical problem. We expect that this work provides useful ideas beyond MIL that can foster further research in the field.},
  archive      = {J_AIJ},
  author       = {Francisco M. Castro-Macías and Pablo Morales-Álvarez and Yunan Wu and Rafael Molina and Aggelos K. Katsaggelos},
  doi          = {10.1016/j.artint.2024.104115},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104115},
  shortjournal = {Artif. Intell.},
  title        = {Hyperbolic secant representation of the logistic function: Application to probabilistic multiple instance learning for CT intracranial hemorrhage detection},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lifted algorithms for symmetric weighted first-order model
sampling. <em>AIJ</em>, <em>331</em>, 104114. (<a
href="https://doi.org/10.1016/j.artint.2024.104114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted model counting (WMC) is the task of computing the weighted sum of all satisfying assignments (i.e., models) of a propositional formula. Similarly, weighted model sampling (WMS) aims to randomly generate models with probability proportional to their respective weights. Both WMC and WMS are hard to solve exactly, falling under the # P -hard complexity class. However, it is known that the counting problem may sometimes be tractable, if the propositional formula can be compactly represented and expressed in first-order logic. In such cases, model counting problems can be solved in time polynomial in the domain size, and are known as domain-liftable . The following question then arises: Is it also the case for WMS? This paper addresses this question and answers it affirmatively. Specifically, we prove the domain-liftability under sampling for the two-variables fragment of first-order logic with counting quantifiers in this paper, by devising an efficient sampling algorithm for this fragment that runs in time polynomial in the domain size. We then further show that this result continues to hold even in the presence of cardinality constraints. To empirically validate our approach, we conduct experiments over various first-order formulas designed for the uniform generation of combinatorial structures and sampling in statistical-relational models. The results demonstrate that our algorithm outperforms a state-of-the-art WMS sampler by a substantial margin, confirming the theoretical results.},
  archive      = {J_AIJ},
  author       = {Yuanhong Wang and Juhua Pu and Yuyi Wang and Ondřej Kuželka},
  doi          = {10.1016/j.artint.2024.104114},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104114},
  shortjournal = {Artif. Intell.},
  title        = {Lifted algorithms for symmetric weighted first-order model sampling},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Regular decision processes. <em>AIJ</em>, <em>331</em>,
104113. (<a href="https://doi.org/10.1016/j.artint.2024.104113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study Regular Decision Processes (RDPs), a new, compact model for domains with non-Markovian dynamics and rewards, in which the dependence on the past is regular, in the language theoretic sense. RDPs are an intermediate model between MDPs and POMDPs. They generalize k -order MDPs and can be viewed as a POMDP in which the hidden state is a regular function of the entire history. In factored RDPs, transition and reward functions are specified using formulas in linear temporal logics over finite traces, or using regular expressions. This allows specifying complex dependence on the past using intuitive and compact formulas, and building models of partially observable domains without specifying an underlying state space.},
  archive      = {J_AIJ},
  author       = {Ronen I. Brafman and Giuseppe De Giacomo},
  doi          = {10.1016/j.artint.2024.104113},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104113},
  shortjournal = {Artif. Intell.},
  title        = {Regular decision processes},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Embedding justification theory in approximation fixpoint
theory. <em>AIJ</em>, <em>331</em>, 104112. (<a
href="https://doi.org/10.1016/j.artint.2024.104112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximation Fixpoint Theory (AFT) and Justification Theory (JT) are two frameworks to unify logical formalisms. AFT studies semantics in terms of fixpoints of lattice operators, and JT in terms of so-called justifications, which are explanations of why certain facts do or do not hold in a model. While the approaches differ, the frameworks were designed with similar goals in mind, namely to study the different semantics that arise in (mainly) non-monotonic logics. The first contribution of our current paper is to provide a formal link between the two frameworks. To be precise, we show that every justification frame induces an approximator and that this mapping from JT to AFT preserves all major semantics. The second contribution exploits this correspondence to extend JT with a novel class of semantics, namely ultimate semantics : we formally show that ultimate semantics can be obtained in JT by a syntactic transformation on the justification frame, essentially performing a sort of resolution on the rules.},
  archive      = {J_AIJ},
  author       = {Simon Marynissen and Bart Bogaerts and Marc Denecker},
  doi          = {10.1016/j.artint.2024.104112},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104112},
  shortjournal = {Artif. Intell.},
  title        = {Embedding justification theory in approximation fixpoint theory},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neurosymbolic cognitive architecture framework for
handling novelties in open worlds. <em>AIJ</em>, <em>331</em>, 104111.
(<a href="https://doi.org/10.1016/j.artint.2024.104111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Open world” environments are those in which novel objects, agents, events, and more can appear and contradict previous understandings of the environment. This runs counter to the “closed world” assumption used in most AI research, where the environment is assumed to be fully understood and unchanging. The types of environments AI agents can be deployed in are limited by the inability to handle the novelties that occur in open world environments. This paper presents a novel cognitive architecture framework to handle open-world novelties. This framework combines symbolic planning, counterfactual reasoning, reinforcement learning, and deep computer vision to detect and accommodate novelties. We introduce general algorithms for exploring open worlds using inference and machine learning methodologies to facilitate novelty accommodation. The ability to detect and accommodate novelties allows agents built on this framework to successfully complete tasks despite a variety of novel changes to the world. Both the framework components and the entire system are evaluated in Minecraft-like simulated environments. Our results indicate that agents are able to efficiently complete tasks while accommodating “concealed novelties” not shared with the architecture development team.},
  archive      = {J_AIJ},
  author       = {Shivam Goel and Panagiotis Lymperopoulos and Ravenna Thielstrom and Evan Krause and Patrick Feeney and Pierrick Lorang and Sarah Schneider and Yichen Wei and Eric Kildebeck and Stephen Goss and Michael C. Hughes and Liping Liu and Jivko Sinapov and Matthias Scheutz},
  doi          = {10.1016/j.artint.2024.104111},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104111},
  shortjournal = {Artif. Intell.},
  title        = {A neurosymbolic cognitive architecture framework for handling novelties in open worlds},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-deterministic approximation fixpoint theory and its
application in disjunctive logic programming. <em>AIJ</em>,
<em>331</em>, 104110. (<a
href="https://doi.org/10.1016/j.artint.2024.104110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximation fixpoint theory (AFT) is an abstract and general algebraic framework for studying the semantics of nonmonotonic logics. It provides a unifying study of the semantics of different formalisms for nonmonotonic reasoning, such as logic programming, default logic and autoepistemic logic. In this paper, we extend AFT to dealing with non-deterministic constructs that allow to handle indefinite information, represented e.g. by disjunctive formulas. This is done by generalizing the main constructions and corresponding results of AFT to non-deterministic operators, whose ranges are sets of elements rather than single elements. The applicability and usefulness of this generalization is illustrated in the context of disjunctive logic programming.},
  archive      = {J_AIJ},
  author       = {Jesse Heyninck and Ofer Arieli and Bart Bogaerts},
  doi          = {10.1016/j.artint.2024.104110},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104110},
  shortjournal = {Artif. Intell.},
  title        = {Non-deterministic approximation fixpoint theory and its application in disjunctive logic programming},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A differentiable first-order rule learner for inductive
logic programming. <em>AIJ</em>, <em>331</em>, 104108. (<a
href="https://doi.org/10.1016/j.artint.2024.104108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning first-order logic programs from relational facts yields intuitive insights into the data. Inductive logic programming (ILP) models are effective in learning first-order logic programs from observed relational data. Symbolic ILP models support rule learning in a data-efficient manner. However, symbolic ILP models are not robust to learn from noisy data. Neuro-symbolic ILP models utilize neural networks to learn logic programs in a differentiable manner which improves the robustness of ILP models. However, most neuro-symbolic methods need a strong language bias to learn logic programs, which reduces the usability and flexibility of ILP models and limits the logic program formats. In addition, most neuro-symbolic ILP methods cannot learn logic programs effectively from both small-size datasets and large-size datasets such as knowledge graphs. In the paper, we introduce a novel differentiable ILP model called differentiable first-order rule learner (DFORL), which is scalable to learn rules from both smaller and larger datasets. Besides, DFORL only needs the number of variables in the learned logic programs as input. Hence, DFORL is easy to use and does not need a strong language bias. We demonstrate that DFORL can perform well on several standard ILP datasets, knowledge graphs, and probabilistic relation facts and outperform several well-known differentiable ILP models. Experimental results indicate that DFORL is a precise, robust, scalable, and computationally cheap differentiable ILP model.},
  archive      = {J_AIJ},
  author       = {Kun Gao and Katsumi Inoue and Yongzhi Cao and Hanpin Wang},
  doi          = {10.1016/j.artint.2024.104108},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104108},
  shortjournal = {Artif. Intell.},
  title        = {A differentiable first-order rule learner for inductive logic programming},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decentralized fused-learner architectures for bayesian
reinforcement learning. <em>AIJ</em>, <em>331</em>, 104094. (<a
href="https://doi.org/10.1016/j.artint.2024.104094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized training is a robust solution for learning over an extensive network of distributed agents. Many existing solutions involve the averaging of locally inferred parameters which constrain the architecture to independent agents with identical learning algorithms. Here, we propose decentralized fused-learner architectures for Bayesian reinforcement learning, named fused Bayesian-learner architectures (FBLAs), that are capable of learning an optimal policy by fusing potentially heterogeneous Bayesian policy gradient learners, i.e., agents that employ different learning architectures to estimate the gradient of a control policy. The novelty of FBLAs relies on fusing the full posterior distributions of the local policy gradients. The inclusion of higher-order information, i.e., probabilistic uncertainty, is employed to robustly fuse the locally-trained parameters. FBLAs find the barycenter of all local posterior densities by minimizing the total Kullback–Leibler divergence from the barycenter distribution to the local posterior densities. The proposed FBLAs are demonstrated on a sensor-selection problem for Bernoulli tracking, where multiple sensors observe a dynamic target and only a subset of sensors is allowed to be active at any time.},
  archive      = {J_AIJ},
  author       = {Augustin A. Saucan and Subhro Das and Moe Z. Win},
  doi          = {10.1016/j.artint.2024.104094},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104094},
  shortjournal = {Artif. Intell.},
  title        = {Decentralized fused-learner architectures for bayesian reinforcement learning},
  volume       = {331},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Aspmc: New frontiers of algebraic answer set counting.
<em>AIJ</em>, <em>330</em>, 104109. (<a
href="https://doi.org/10.1016/j.artint.2024.104109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, there has been increasing interest in extensions of answer set programming (ASP) that cater for quantitative information such as weights or probabilities. A wide range of quantitative reasoning tasks for ASP and logic programming, among them probabilistic inference and parameter learning in the neuro-symbolic setting, can be expressed as algebraic answer set counting (AASC) tasks, i.e., weighted model counting for ASP with weights calculated over some semiring, which makes efficient solvers for AASC desirable. In this article, we present , a new solver for AASC that pushes the limits of efficient solvability. Notably, provides improved performance compared to the state of the art in probabilistic inference by exploiting three insights gained from thorough theoretical investigations in our work. Namely, we consider the knowledge compilation step in the AASC pipeline, where the underlying logical theory specified by the answer set program is converted into a tractable circuit representation, on which AASC is feasible in polynomial time. First, we provide a detailed comparison of different approaches to knowledge compilation for programs, revealing that translation to propositional formulas followed by compilation to sd-DNNF seems favorable. Second, we study how the translation to propositional formulas should proceed to result in efficient compilation. This leads to the second and third insight, namely a novel way of breaking the positive cyclic dependencies in a program, called T P TP -Unfolding, and an improvement to the Clark Completion, the procedure used to transform programs without positive cyclic dependencies into propositional formulas. Both improvements are tailored towards efficient knowledge compilation. Our empirical evaluation reveals that while all three advancements contribute to the success of , T P TP -Unfolding improves performance significantly by allowing us to handle cyclic instances better.},
  archive      = {J_AIJ},
  author       = {Thomas Eiter and Markus Hecher and Rafael Kiesel},
  doi          = {10.1016/j.artint.2024.104109},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104109},
  shortjournal = {Artif. Intell.},
  title        = {Aspmc: New frontiers of algebraic answer set counting},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). “Guess what i’m doing”: Extending legibility to sequential
decision tasks. <em>AIJ</em>, <em>330</em>, 104107. (<a
href="https://doi.org/10.1016/j.artint.2024.104107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate the notion of legibility in sequential decision tasks under uncertainty. Previous works that extend legibility to scenarios beyond robot motion either focus on deterministic settings or are computationally too expensive. Our proposed approach, dubbed PoLMDP, is able to handle uncertainty while remaining computationally tractable. We establish the advantages of our approach against state-of-the-art approaches in several scenarios of varying complexity. We also showcase the use of our legible policies as demonstrations in machine teaching scenarios, establishing their superiority in teaching new behaviours against the commonly used demonstrations based on the optimal policy. Finally, we assess the legibility of our computed policies through a user study, where people are asked to infer the goal of a mobile robot following a legible policy by observing its actions.},
  archive      = {J_AIJ},
  author       = {Miguel Faria and Francisco S. Melo and Ana Paiva},
  doi          = {10.1016/j.artint.2024.104107},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104107},
  shortjournal = {Artif. Intell.},
  title        = {“Guess what i&#39;m doing”: Extending legibility to sequential decision tasks},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Investigating the properties of neural network
representations in reinforcement learning. <em>AIJ</em>, <em>330</em>,
104100. (<a href="https://doi.org/10.1016/j.artint.2024.104100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate the properties of representations learned by deep reinforcement learning systems. Much of the early work on representations for reinforcement learning focused on designing fixed-basis architectures to achieve properties thought to be desirable, such as orthogonality and sparsity. In contrast, the idea behind deep reinforcement learning methods is that the agent designer should not encode representational properties, but rather that the data stream should determine the properties of the representation—good representations emerge under appropriate training schemes. In this paper we bring these two perspectives together, empirically investigating the properties of representations that support transfer in reinforcement learning. We introduce and measure six representational properties over more than 25,000 agent-task settings. We consider Deep Q-learning agents with different auxiliary losses in a pixel-based navigation environment, with source and transfer tasks corresponding to different goal locations. We develop a method to better understand why some representations work better for transfer, through a systematic approach varying task similarity and measuring and correlating representation properties with transfer performance. We demonstrate the generality of the methodology by investigating representations learned by a Rainbow agent that successfully transfers across Atari 2600 game modes.},
  archive      = {J_AIJ},
  author       = {Han Wang and Erfan Miahi and Martha White and Marlos C. Machado and Zaheer Abbas and Raksha Kumaraswamy and Vincent Liu and Adam White},
  doi          = {10.1016/j.artint.2024.104100},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104100},
  shortjournal = {Artif. Intell.},
  title        = {Investigating the properties of neural network representations in reinforcement learning},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Datalog rewritability and data complexity of ALCHOIQ with
closed predicates. <em>AIJ</em>, <em>330</em>, 104099. (<a
href="https://doi.org/10.1016/j.artint.2024.104099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the relative expressiveness of ontology-mediated queries (OMQs) formulated in the expressive Description Logic ALCHOIQ extended with closed predicates. In particular, we present a polynomial time translation from OMQs into Datalog with negation under the stable model semantics, the formalism that underlies Answer Set Programming. This is a novel and non-trivial result: the considered OMQs are not only non-monotonic, but also feature a tricky combination of nominals, inverse roles, and counting. We start with atomic queries and then lift our approach to a large class of first-order queries where quantification is “guarded” by closed predicates. Our translation is based on a characterization of the query answering problem via integer programming, and a specially crafted program in Datalog with negation that finds solutions to dynamically generated systems of integer inequalities. As an important by-product of our translation we get that the query answering problem is co-NP-complete in data complexity for the considered class of OMQs. Thus, answering these OMQs in the presence of closed predicates is not harder than answering them in the standard setting. This is not obvious as closed predicates are known to increase data complexity for some existing ontology languages.},
  archive      = {J_AIJ},
  author       = {Sanja Lukumbuzya and Magdalena Ortiz and Mantas Šimkus},
  doi          = {10.1016/j.artint.2024.104099},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104099},
  shortjournal = {Artif. Intell.},
  title        = {Datalog rewritability and data complexity of ALCHOIQ with closed predicates},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Crossover can guarantee exponential speed-ups in
evolutionary multi-objective optimisation. <em>AIJ</em>, <em>330</em>,
104098. (<a href="https://doi.org/10.1016/j.artint.2024.104098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms are popular algorithms for multi-objective optimisation (also called Pareto optimisation) as they use a population to store trade-offs between different objectives. Despite their popularity, the theoretical foundation of multi-objective evolutionary optimisation (EMO) is still in its early development. Fundamental questions such as the benefits of the crossover operator are still not fully understood. We provide a theoretical analysis of the well-known EMO algorithms GSEMO and NSGA-II to showcase the possible advantages of crossover: we propose classes of “royal road” functions on which these algorithms cover the whole Pareto front in expected polynomial time if crossover is being used. But when disabling crossover, they require exponential time in expectation to cover the Pareto front. The latter even holds for a large class of black-box algorithms using any elitist selection and any unbiased mutation operator. Moreover, even the expected time to create a single Pareto-optimal search point is exponential. We provide two different function classes, one tailored for one-point crossover and another one tailored for uniform crossover, and we show that some immune-inspired hypermutations cannot avoid exponential optimisation times. Our work shows the first example of an exponential performance gap through the use of crossover for the widely used NSGA-II algorithm and contributes to a deeper understanding of its limitations and capabilities.},
  archive      = {J_AIJ},
  author       = {Duc-Cuong Dang and Andre Opris and Dirk Sudholt},
  doi          = {10.1016/j.artint.2024.104098},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104098},
  shortjournal = {Artif. Intell.},
  title        = {Crossover can guarantee exponential speed-ups in evolutionary multi-objective optimisation},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalized planning as heuristic search: A new planning
search-space that leverages pointers over objects. <em>AIJ</em>,
<em>330</em>, 104097. (<a
href="https://doi.org/10.1016/j.artint.2024.104097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning as heuristic search is one of the most successful approaches to classical planning but unfortunately, it does not trivially extend to Generalized Planning (GP); GP aims to compute algorithmic solutions that are valid for a set of classical planning instances from a given domain, even if these instances differ in their number of objects, the initial and goal configuration of these objects and hence, in the number (and possible values) of the state variables. State-space search , as it is implemented by heuristic planners, becomes then impractical for GP. In this paper we adapt the planning as heuristic search paradigm to the generalization requirements of GP, and present the first native heuristic search approach to GP. First, the paper introduces a new pointer-based solution space for GP that is independent of the number of classical planning instances in a GP problem and the size of those instances (i.e. the number of objects, state variables and their domain sizes). Second, the paper defines an upgraded version of our GP algorithm, called Best-First Generalized Planning ( BFGP ), that implements a best-first search in our pointer-based solution space for GP. Lastly, the paper defines a set of evaluation and heuristic functions for BFGP that assess the structural complexity of the candidate GP solutions, as well as their fitness to a given input set of classical planning instances. The computation of these evaluation and heuristic functions does not require grounding states or actions in advance. Therefore our GP as heuristic search approach can handle large sets of state variables with large numerical domains, e.g. integers .},
  archive      = {J_AIJ},
  author       = {Javier Segovia-Aguas and Sergio Jiménez and Anders Jonsson},
  doi          = {10.1016/j.artint.2024.104097},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104097},
  shortjournal = {Artif. Intell.},
  title        = {Generalized planning as heuristic search: A new planning search-space that leverages pointers over objects},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding the optimal exploration-exploitation trade-off
online through bayesian risk estimation and minimization. <em>AIJ</em>,
<em>330</em>, 104096. (<a
href="https://doi.org/10.1016/j.artint.2024.104096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose endogenous Bayesian risk minimization (EBRM) over policy sets as an approach to online learning across a wide range of settings. Many real-world online learning problems have complexities such as action- and belief-dependent rewards, time-discounting of reward, and heterogeneous costs for actions and feedback; we find that existing online learning heuristics cannot leverage most problem-specific information, to the detriment of their performance. We introduce a belief-space Markov decision process (BMDP) model that can capture these complexities, and further apply the concepts of aleatoric , epistemic , and process risks to online learning. These risk functions describe the risk inherent to the learning problem, the risk due to the agent&#39;s lack of knowledge, and the relative quality of its policy, respectively. We demonstrate how computing and minimizing these risk functions guides the online learning agent towards the optimal exploration-exploitation trade-off in any stochastic online learning problem, constituting the basis of the EBRM approach. We also show how Bayes&#39; risk, the minimization objective in stochastic online learning problems, can be decomposed into the aforementioned aleatoric, epistemic, and process risks. In simulation experiments, EBRM algorithms achieve state-of-the-art performance across various classical online learning problems, including Gaussian and Bernoulli multi-armed bandits, best-arm identification, mixed objectives with action- and belief-dependent rewards, and dynamic pricing, a finite partial monitoring problem. To our knowledge, it is also the first computationally efficient online learning approach that can provide online bounds on an algorithm&#39;s Bayes&#39; risk. Finally, because the EBRM approach is parameterized by a set of policy algorithms, it can be extended to incorporate new developments in online learning algorithms, and is thus well-suited as the foundation for developing real-world learning agents.},
  archive      = {J_AIJ},
  author       = {Stewart Jamieson and Jonathan P. How and Yogesh Girdhar},
  doi          = {10.1016/j.artint.2024.104096},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104096},
  shortjournal = {Artif. Intell.},
  title        = {Finding the optimal exploration-exploitation trade-off online through bayesian risk estimation and minimization},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal segmentation in multi agent path finding with
applications to explainability. <em>AIJ</em>, <em>330</em>, 104087. (<a
href="https://doi.org/10.1016/j.artint.2024.104087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Path Finding (MAPF) is the problem of planning paths for agents to reach their targets from their start locations, such that the agents do not collide while executing the plan. In many settings, the plan (or a digest thereof) is conveyed to a supervising entity, e.g., for confirmation before execution, for a report, etc. In such cases, we wish to convey that the plan is collision-free with minimal amount of information. To this end, we propose an explanation scheme for MAPF. The scheme decomposes a plan into segments such that within each segment, the agents&#39; paths are disjoint. We can then convey the plan whilst convincing that it is collision-free, using a small number of frames (dubbed an explanation ). We can also measure the simplicity of a plan by the number of segments required for the decomposition. We study the complexity of algorithmic problems that arise by the explanation scheme and the tradeoff between the length (makespan) of a plan and its minimal decomposition. We also introduce two centralized (i.e. runs on a single CPU with full knowledge of the multi-agent system) algorithms for planning with explanations. One is based on a coupled search algorithm similar to A ⁎ , and the other is a decoupled method based on Conflict-Based Search (CBS). We refer to the latter as Explanation-Guided CBS (XG-CBS), which uses a low-level search for individual agents and maintains a high-level conflict tree to guide the low-level search to avoid collisions as well as increasing the number of segments. We propose four approaches to the low-level search of XG-CBS by modifying A ⁎ for explanations and analyze their effects on the completeness of XG-CBS. Finally, we highlight important aspects of the proposed explanation scheme in various MAPF problems and empirically evaluate the performance of the proposed planning algorithms in a series of benchmark problems.},
  archive      = {J_AIJ},
  author       = {Shaull Almagor and Justin Kottinger and Morteza Lahijanian},
  doi          = {10.1016/j.artint.2024.104087},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104087},
  shortjournal = {Artif. Intell.},
  title        = {Temporal segmentation in multi agent path finding with applications to explainability},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An extended view on lifting gaussian bayesian networks.
<em>AIJ</em>, <em>330</em>, 104082. (<a
href="https://doi.org/10.1016/j.artint.2024.104082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifting probabilistic graphical models and developing lifted inference algorithms aim to use higher level groups of random variables instead of individual instances. In the past, many inference algorithms for discrete probabilistic graphical models have been lifted. Lifting continuous probabilistic graphical models has played a minor role. Since many real-world applications involve continuous random variables, this article turns its focus to lifting approaches for Gaussian Bayesian networks. Specifically, we present algorithms for constructing a lifted joint distribution for scenarios of sequences of overlapping and non-overlapping logical variables. We present operations that work in a fully lifted way including addition, multiplication, and inversion. We present how the operations can be used for lifted query answering algorithms and extend the existing query answering algorithm by a new way of evidence handling. The new way of evidence handling groups evidence that has the same effect on its neighboring variables in cases of partial overlap between the logical-variable sequences. In the theoretical complexity analysis and the experimental evaluation, we show under which conditions the existing lifted approach and the new lifted approach including evidence grouping lead to the most time savings compared to the grounded approach.},
  archive      = {J_AIJ},
  author       = {Mattis Hartwig and Ralf Möller and Tanya Braun},
  doi          = {10.1016/j.artint.2024.104082},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104082},
  shortjournal = {Artif. Intell.},
  title        = {An extended view on lifting gaussian bayesian networks},
  volume       = {330},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Primarily about primaries. <em>AIJ</em>, <em>329</em>,
104095. (<a href="https://doi.org/10.1016/j.artint.2024.104095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much of the social choice literature examines direct voting systems, in which voters submit their ranked preferences over candidates and a voting rule picks a winner. Real-world elections and decision-making processes are often more complex and involve multiple stages. For instance, one popular voting system filters candidates through primaries : first, voters affiliated with each political party vote over candidates of their own party and the voting rule picks a set of candidates, one from each party, who then compete in a general election. We present a model to analyze such multi-stage elections, and conduct what is, to the best of our knowledge, the first quantitative comparison of the direct and primary voting systems in terms of the quality of the elected candidate, using the metric of distortion , which attempts to quantify how far from the optimal winner is the actual winner of an election. Our main theoretical result is that voting rules (which are independent of party affiliations, of course) are guaranteed to perform in the primary system within a constant factor of the direct, single stage setting. Surprisingly, the converse does not hold: we show settings in which there exist voting rules that perform significantly better under the primary system than under the direct system. Using simulations, we see that plurality benefits significantly from using a primary system over a direct one, while Condorcet-consistent rules do not.},
  archive      = {J_AIJ},
  author       = {Allan Borodin and Omer Lev and Nisarg Shah and Tyrone Strangway},
  doi          = {10.1016/j.artint.2024.104095},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104095},
  shortjournal = {Artif. Intell.},
  title        = {Primarily about primaries},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient optimal kolmogorov approximation of random
variables. <em>AIJ</em>, <em>329</em>, 104086. (<a
href="https://doi.org/10.1016/j.artint.2024.104086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete random variables are essential ingredients in various artificial intelligence problems. These include the estimation of the probability of missing the deadline in a series-parallel schedule and the assignment of suppliers to tasks in a project in a manner that maximizes the probability of meeting the overall project deadline. The solving of such problems involves repetitive operations, such as summation, over random variables. However, these computations are NP-hard. Therefore, we explore techniques and methods for approximating random variables with a given support size and minimal Kolmogorov distance. We examine both the general problem of approximating a random variable and a one-sided version in which over-approximation is allowed but not under-approximation. We propose several algorithms and evaluate their performance through computational complexity analysis and empirical evaluation. All the presented algorithms are optimal in the sense that given an input random variable and a requested support size, they return a new approximated random variable with the requested support size and minimal Kolmogorov distance from the input random variable. Our approximation algorithms offer useful estimations of probabilities in situations where exact computations are not feasible due to NP-hardness complexity.},
  archive      = {J_AIJ},
  author       = {Liat Cohen and Tal Grinshpoun and Gera Weiss},
  doi          = {10.1016/j.artint.2024.104086},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104086},
  shortjournal = {Artif. Intell.},
  title        = {Efficient optimal kolmogorov approximation of random variables},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal inductive path neural network for temporal
knowledge graph reasoning. <em>AIJ</em>, <em>329</em>, 104085. (<a
href="https://doi.org/10.1016/j.artint.2024.104085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Knowledge Graph (TKG) is an extension of traditional Knowledge Graph (KG) that incorporates the dimension of time. Reasoning on TKGs is a crucial task that aims to predict future facts based on historical occurrences. The key challenge lies in uncovering structural dependencies within historical subgraphs and temporal patterns. Most existing approaches model TKGs relying on entity modeling, as nodes in the graph play a crucial role in knowledge representation. However, the real-world scenario often involves an extensive number of entities, with new entities emerging over time. This makes it challenging for entity-dependent methods to cope with extensive volumes of entities, and effectively handling newly emerging entities also becomes a significant challenge. Therefore, we propose T emporal I nductive P ath N eural N etwork (TiPNN), which models historical information in an entity-independent perspective. Specifically, TiPNN adopts a unified graph, namely history temporal graph , to comprehensively capture and encapsulate information from history. Subsequently, we utilize the defined query-aware temporal paths on a history temporal graph to model historical path information related to queries for reasoning. Extensive experiments illustrate that the proposed model not only attains significant performance enhancements but also handles inductive settings, while additionally facilitating the provision of reasoning evidence through history temporal graphs.},
  archive      = {J_AIJ},
  author       = {Hao Dong and Pengyang Wang and Meng Xiao and Zhiyuan Ning and Pengfei Wang and Yuanchun Zhou},
  doi          = {10.1016/j.artint.2024.104085},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104085},
  shortjournal = {Artif. Intell.},
  title        = {Temporal inductive path neural network for temporal knowledge graph reasoning},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A stochastic process approach for multi-agent path finding
with non-asymptotic performance guarantees. <em>AIJ</em>, <em>329</em>,
104084. (<a href="https://doi.org/10.1016/j.artint.2024.104084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent path finding (MAPF) is a classical NP-hard problem that considers planning collision-free paths for multiple agents simultaneously. A MAPF problem is typically solved via addressing a sequence of single-agent path finding subproblems in which well-studied algorithms such as ⁎ A ⁎ A⁎ are applicable. Existing methods based on this idea, however, rely on an exhaustive search and therefore only have asymptotic performance guarantees. In this article, we provide a modeling paradigm that converts a MAPF problem into a stochastic process and adopts a confidence bound based rule for finding the optimal state transition strategy. A randomized algorithm is proposed to solve this stochastic process, which combines ideas from conflict based search and Monte Carlo tree search. We show that the proposed method is almost surely optimal while enjoying non-asymptotic performance guarantees. In particular, the proposed method can, after solving N single-agent subproblems, produce a feasible solution with suboptimality bounded by O ( 1 / N ) O(1/N) . The theoretical results are verified by several numerical experiments based on grid maps.},
  archive      = {J_AIJ},
  author       = {Xiaoyu He and Xueyan Tang and Wentong Cai and Jingning Li},
  doi          = {10.1016/j.artint.2024.104084},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104084},
  shortjournal = {Artif. Intell.},
  title        = {A stochastic process approach for multi-agent path finding with non-asymptotic performance guarantees},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Counterexamples and amendments to the termination and
optimality of ADOPT-based algorithms. <em>AIJ</em>, <em>329</em>,
104083. (<a href="https://doi.org/10.1016/j.artint.2024.104083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A distributed constraint optimization problem (DCOP) is a framework to model multi-agent coordination problems. Asynchronous distributed optimization (ADOPT) is a well-known complete DCOP algorithm, and many of its variants have been proposed over the last decade. It is considered proven that ADOPT-based algorithms have the key properties of termination and optimality , which guarantee that the algorithms terminate in a finite time and obtain an optimal solution, respectively. In this paper, we present counterexamples to the termination and optimality of ADOPT-based algorithms. They are classified into three types, at least one of which exists in each of ADOPT and eight of its variants that we analyzed. In other words, the algorithms may potentially not terminate or terminate with a suboptimal solution. Furthermore, we show that the bounded-error approximation of ADOPT, which enables the algorithm to terminate faster with the quality of the solution guaranteed within a predefined error bound , also suffers from flaws. Additionally, we propose an amended version of ADOPT that avoids the flaws in existing algorithms and prove that it has the properties of termination and optimality.},
  archive      = {J_AIJ},
  author       = {Koji Noshiro and Koji Hasebe},
  doi          = {10.1016/j.artint.2024.104083},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104083},
  shortjournal = {Artif. Intell.},
  title        = {Counterexamples and amendments to the termination and optimality of ADOPT-based algorithms},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pre-training and diagnosing knowledge base completion
models. <em>AIJ</em>, <em>329</em>, 104081. (<a
href="https://doi.org/10.1016/j.artint.2024.104081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce and analyze an approach to knowledge transfer from one collection of facts to another without the need for entity or relation matching. The method works for both canonicalized knowledge bases and uncanonicalized or open knowledge bases , i.e., knowledge bases where more than one copy of a real-world entity or relation may exist. The main contribution is a method that can make use of large-scale pre-training on facts, which were collected from unstructured text, to improve predictions on structured data from a specific domain. The introduced method is most impactful on small datasets such as ReVerb20k , where a 6% absolute increase of mean reciprocal rank and 65% relative decrease of mean rank over the previously best method was achieved, despite not relying on large pre-trained models like Bert . To understand the obtained pre-trained models better, we then introduce a novel dataset for the analysis of pre-trained models for Open Knowledge Base Completion, called Doge (Diagnostics of Open knowledge Graph Embeddings). It consists of 6 subsets and is designed to measure multiple properties of a pre-trained model: robustness against synonyms, ability to perform deductive reasoning, presence of gender stereotypes, consistency with reverse relations, and coverage of different areas of general knowledge. Using the introduced dataset, we show that the existing OKBC models lack consistency in presence of synonyms and inverse relations and are unable to perform deductive reasoning. Moreover, their predictions often align with gender stereotypes, which persist even when presented with counterevidence. We additionally investigate the role of pre-trained word embeddings and demonstrate that avoiding biased word embeddings is not a sufficient measure to prevent biased behavior of OKBC models.},
  archive      = {J_AIJ},
  author       = {Vid Kocijan and Myeongjun Jang and Thomas Lukasiewicz},
  doi          = {10.1016/j.artint.2024.104081},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104081},
  shortjournal = {Artif. Intell.},
  title        = {Pre-training and diagnosing knowledge base completion models},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revision operators with compact representations.
<em>AIJ</em>, <em>329</em>, 104080. (<a
href="https://doi.org/10.1016/j.artint.2024.104080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the great theoretical advancements in the area of Belief Revision, there has been limited success in terms of implementations. One of the hurdles in implementing revision operators is that their specification (let alone their computation), requires substantial resources. On the other hand, implementing a specific revision operator, like Dalal&#39;s operator, would be of limited use. In this paper we generalise Dalal&#39;s construction, defining a whole family of concrete revision operators, called Parametrised Difference revision operators or PD operators for short. This family is wide enough to cover a wide range of different applications, and at the same time it is easy to represent. In addition to its semantic definition, we characterise the family of PD operators axiomatically (including a characterisation specifically for Dalal&#39;s operator), we prove its&#39; compliance with Parikh&#39;s relevance-sensitive postulate (P), we study its computational complexity, and discuss its benefits for belief revision implementations.},
  archive      = {J_AIJ},
  author       = {Pavlos Peppas and Mary-Anne Williams and Grigoris Antoniou},
  doi          = {10.1016/j.artint.2024.104080},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104080},
  shortjournal = {Artif. Intell.},
  title        = {Revision operators with compact representations},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transferable dynamics models for efficient object-oriented
reinforcement learning. <em>AIJ</em>, <em>329</em>, 104079. (<a
href="https://doi.org/10.1016/j.artint.2024.104079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Reinforcement Learning (RL) framework offers a general paradigm for constructing autonomous agents that can make effective decisions when solving tasks. An important area of study within the field of RL is transfer learning , where an agent utilizes knowledge gained from solving previous tasks to solve a new task more efficiently. While the notion of transfer learning is conceptually appealing, in practice, not all RL representations are amenable to transfer learning. Moreover, much of the research on transfer learning in RL is purely empirical. Previous research has shown that object-oriented representations are suitable for the purposes of transfer learning with theoretical efficiency guarantees. Such representations leverage the notion of object classes to learn lifted rules that apply to grounded object instantiations . In this paper, we extend previous research on object-oriented representations and introduce two formalisms: the first is based on deictic predicates, and is used to learn a transferable transition dynamics model; the second is based on propositions, and is used to learn a transferable reward dynamics model. In addition, we extend previously introduced efficient learning algorithms for object-oriented representations to our proposed formalisms. Our frameworks are then combined into a single efficient algorithm that learns transferable transition and reward dynamics models across a domain of related tasks. We illustrate our proposed algorithm empirically on an extended version of the Taxi domain, as well as the more difficult Sokoban domain, showing the benefits of our approach with regards to efficient learning and transfer.},
  archive      = {J_AIJ},
  author       = {Ofir Marom and Benjamin Rosman},
  doi          = {10.1016/j.artint.2024.104079},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104079},
  shortjournal = {Artif. Intell.},
  title        = {Transferable dynamics models for efficient object-oriented reinforcement learning},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Emotion selectable end-to-end text-based speech editing.
<em>AIJ</em>, <em>329</em>, 104076. (<a
href="https://doi.org/10.1016/j.artint.2024.104076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based speech editing is a convenient way for users to edit speech by intuitively cutting, copying, and pasting text. Previous work introduced CampNet, a context-aware mask prediction network that significantly improved the quality of edited speech. However, this paper proposes a new task: adding emotional effects to the edited speech during text-based speech editing to enhance the expressiveness and controllability of the edited speech. To achieve this, we introduce Emo-CampNet, which allows users to select emotional attributes for the generated speech and has the ability to edit the speech of unseen speakers. Firstly, the proposed end-to-end model controls the generated speech&#39;s emotion by introducing additional emotion attributes based on the context-aware mask prediction network. Secondly, to prevent emotional interference from the original speech, a neutral content generator is proposed to remove the emotional components, which is optimized using the generative adversarial framework. Thirdly, two data augmentation methods are proposed to enrich the emotional and pronunciation information in the training set. Experimental results 1 show that Emo-CampNet effectively controls the generated speech&#39;s emotion and can edit the speech of unseen speakers. Ablation experiments further validate the effectiveness of emotional selectivity and data augmentation methods.},
  archive      = {J_AIJ},
  author       = {Tao Wang and Jiangyan Yi and Ruibo Fu and Jianhua Tao and Zhengqi Wen and Chu Yuan Zhang},
  doi          = {10.1016/j.artint.2024.104076},
  journal      = {Artificial Intelligence},
  month        = {4},
  pages        = {104076},
  shortjournal = {Artif. Intell.},
  title        = {Emotion selectable end-to-end text-based speech editing},
  volume       = {329},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Saliency-aware regularized graph neural network.
<em>AIJ</em>, <em>328</em>, 104078. (<a
href="https://doi.org/10.1016/j.artint.2024.104078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crux of graph classification lies in the effective representation learning for the entire graph. Typical graph neural networks focus on modeling the local dependencies when aggregating features of neighboring nodes, and obtain the representation for the entire graph by aggregating node features. Such methods have two potential limitations: 1) the global node saliency w.r.t. graph classification is not explicitly modeled, which is crucial since different nodes may have different semantic relevance to graph classification; 2) the graph representation directly aggregated from node features may have limited effectiveness to reflect graph-level information. In this work, we propose the Saliency-Aware Regularized Graph Neural Network ( SAR-GNN ) for graph classification, which consists of two core modules: 1) a traditional graph neural network serving as the backbone for learning node features and 2) the Graph Neural Memory designed to distill a compact graph representation from node features of the backbone. We first estimate the global node saliency by measuring the semantic similarity between the compact graph representation and node features. Then the learned saliency distribution is leveraged to regularize the neighborhood aggregation of the backbone, which facilitates the message passing of features for salient nodes and suppresses the less relevant nodes. Thus, our model can learn more effective graph representation. We demonstrate the merits of SAR-GNN by extensive experiments on seven datasets across various types of graph data.},
  archive      = {J_AIJ},
  author       = {Wenjie Pei and WeiNa Xu and Zongze Wu and Weichao Li and Jinfan Wang and Guangming Lu and Xiangrong Wang},
  doi          = {10.1016/j.artint.2024.104078},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104078},
  shortjournal = {Artif. Intell.},
  title        = {Saliency-aware regularized graph neural network},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the role of logical separability in knowledge
compilation. <em>AIJ</em>, <em>328</em>, 104077. (<a
href="https://doi.org/10.1016/j.artint.2024.104077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge compilation is an alternative solution to address demanding reasoning tasks with high complexity via converting knowledge bases into a suitable target language. The notion of logical separability , proposed by Levesque, offers a general explanation for the tractability of clausal entailment for two remarkable languages: decomposable negation normal form and prime implicates. It is interesting to explore what role logical separability plays in problem tractability. In this paper, we apply the notion of logical separability to a number of reasoning problems within the context of propositional logic: satisfiability checking ( CO ), clausal entailment checking ( CE ), model counting ( CT ), model enumeration ( ME ) and forgetting ( FO ), as well as their dual tasks, contributing to several recursive procedures . We provide the corresponding logical separability based properties: CO -logical separability, CE -logical separability, CT -logical separability, ME -logical separability and their duals. Based on these properties, we then identify four novel normal forms: CO - LSNNF CO-LSNNF , CE - LSNNF CE-LSNNF , CT - LSNNF CT-LSNNF and ME - LSNNF ME-LSNNF , as well as their dual languages. We show that each of them is the necessary and sufficient condition under which the corresponding procedure is correct. We finally integrate the above normal forms into the knowledge compilation map.},
  archive      = {J_AIJ},
  author       = {Junming Qiu and Wenqing Li and Liangda Fang and Quanlong Guan and Zhanhao Xiao and Zhao-Rong Lai and Qian Dong},
  doi          = {10.1016/j.artint.2024.104077},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104077},
  shortjournal = {Artif. Intell.},
  title        = {On the role of logical separability in knowledge compilation},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Corrigendum to “learning constraints through partial
queries” [artificial intelligence 319 (2023) 103896]. <em>AIJ</em>,
<em>328</em>, 104075. (<a
href="https://doi.org/10.1016/j.artint.2024.104075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIJ},
  author       = {Christian Bessiere and Clément Carbonnel and Anton Dries and Emmanuel Hebrard and George Katsirelos and Nadjib Lazaar and Nina Narodytska and Claude-Guy Quimper and Kostas Stergiou and Dimosthenis C. Tsouros and Toby Walsh},
  doi          = {10.1016/j.artint.2024.104075},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104075},
  shortjournal = {Artif. Intell.},
  title        = {Corrigendum to “Learning constraints through partial queries” [Artificial intelligence 319 (2023) 103896]},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing SMT-based weighted model integration by structure
awareness. <em>AIJ</em>, <em>328</em>, 104067. (<a
href="https://doi.org/10.1016/j.artint.2024.104067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of efficient exact and approximate algorithms for probabilistic inference is a long-standing goal of artificial intelligence research. Whereas substantial progress has been made in dealing with purely discrete or purely continuous domains, adapting the developed solutions to tackle hybrid domains, characterized by discrete and continuous variables and their relationships, is highly non-trivial. Weighted Model Integration (WMI) recently emerged as a unifying formalism for probabilistic inference in hybrid domains. Despite a considerable amount of recent work, allowing WMI algorithms to scale with the complexity of the hybrid problem is still a challenge. In this paper we highlight some substantial limitations of existing state-of-the-art solutions, and develop an algorithm that combines SMT-based enumeration, an efficient technique in formal verification , with an effective encoding of the problem structure. This allows our algorithm to avoid generating redundant models , resulting in drastic computational savings. Additionally, we show how SMT-based approaches can seamlessly deal with different integration techniques, both exact and approximate, significantly expanding the set of problems that can be tackled by WMI technology. An extensive experimental evaluation on both synthetic and real-world datasets confirms the substantial advantage of the proposed solution over existing alternatives. The application potential of this technology is further showcased on a prototypical task aimed at verifying the fairness of probabilistic programs.},
  archive      = {J_AIJ},
  author       = {Giuseppe Spallitta and Gabriele Masina and Paolo Morettin and Andrea Passerini and Roberto Sebastiani},
  doi          = {10.1016/j.artint.2024.104067},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104067},
  shortjournal = {Artif. Intell.},
  title        = {Enhancing SMT-based weighted model integration by structure awareness},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The distortion of distributed facility location.
<em>AIJ</em>, <em>328</em>, 104066. (<a
href="https://doi.org/10.1016/j.artint.2024.104066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the distributed facility location problem , where a set of agents with positions on the line of real numbers are partitioned into disjoint districts, and the goal is to choose a point to satisfy certain criteria, such as optimize an objective function or avoid strategic behavior. A mechanism in our distributed setting works in two steps: For each district it chooses a point that is representative of the positions reported by the agents in the district, and then decides one of these representative points as the final output. We consider two classes of mechanisms: Unrestricted mechanisms which assume that the agents directly provide their true positions as input, and strategyproof mechanisms which deal with strategic agents and aim to incentivize them to truthfully report their positions. For both classes, we show tight bounds on the best possible approximation in terms of several minimization social objectives, including the well-known average social cost (average total distance of agents from the chosen point) and max cost (maximum distance among all agents from the chosen point), as well as other fairness-inspired objectives that are tailor-made for the distributed setting, in particular, the max-of-average and the average-of-max.},
  archive      = {J_AIJ},
  author       = {Aris Filos-Ratsikas and Panagiotis Kanellopoulos and Alexandros A. Voudouris and Rongsen Zhang},
  doi          = {10.1016/j.artint.2024.104066},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104066},
  shortjournal = {Artif. Intell.},
  title        = {The distortion of distributed facility location},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-track spatio-temporal learning for urban flow
prediction with adaptive normalization. <em>AIJ</em>, <em>328</em>,
104065. (<a href="https://doi.org/10.1016/j.artint.2024.104065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust urban flow prediction is crucial for transportation planning and management in urban areas. Although recent advances in modeling spatio-temporal correlations have shown potential, most models fail to adequately consider the complex spatio-temporal semantic information present in real-world scenarios. We summarize the following three primary limitations in existing models: a) The majority of existing models project overall time periods into the same latent space, neglecting the diverse temporal semantics between different time intervals. b) Existing models tend to capture spatial dependencies from a locale perspective such as surroundings but do not pay attention to the global influence factors. c) Beyond the spatio-temporal properties, the dynamics and instability of the data sequences introduce perturbations to the prediction results, potentially leading to model degradation . To address these issues, we propose a dual-track spatial-temporal learning module named DualST for accurate urban flow inference. To more effectively differentiate semantic information in the time dimension, we assign the overall time scales into closeness and periodicity. The dual-track module, which includes temporal causality inference and temporal contextual inference, simultaneously exploits the dynamic evolutionary trends and periodic traffic patterns, respectively. The proposed DualST captures global spatial features in a self-supervised manner which not only enriches the spatial semantics but also avoids introducing additional prior knowledge. To eliminate the instability caused by dynamics, we first adopt spatio-temporal adaptive normalization to learn appropriate data sequence normalization. We evaluate the proposed DualST on two typical urban flow datasets. The experiment results show that our model not only exhibits a consistent superiority over various state-of-the-art baselines but also has remarkable generalization capability.},
  archive      = {J_AIJ},
  author       = {Xiaoyu Li and Yongshun Gong and Wei Liu and Yilong Yin and Yu Zheng and Liqiang Nie},
  doi          = {10.1016/j.artint.2024.104065},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104065},
  shortjournal = {Artif. Intell.},
  title        = {Dual-track spatio-temporal learning for urban flow prediction with adaptive normalization},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An attention model for the formation of collectives in
real-world domains. <em>AIJ</em>, <em>328</em>, 104064. (<a
href="https://doi.org/10.1016/j.artint.2023.104064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of forming collectives of agents inherent in application domains aligned with Sustainable Development Goals 4 and 11 (i.e., team formation and ridesharing, respectively). We propose a general solution approach based on a novel combination of an attention model and an integer linear program (ILP). In more detail, we propose an attention encoder-decoder model that transforms a collective formation instance to a weighted set packing problem, which is then solved by an ILP. Results on collective formation problems inherent in the ridesharing and team formation domains show that our approach provides comparable solutions (in terms of quality) to the ones produced by state-of-the-art approaches specific to each domain. Moreover, our solution outperforms the most recent general approach for forming collectives based on Monte Carlo tree search .},
  archive      = {J_AIJ},
  author       = {Adrià Fenoy and Filippo Bistaffa and Alessandro Farinelli},
  doi          = {10.1016/j.artint.2023.104064},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104064},
  shortjournal = {Artif. Intell.},
  title        = {An attention model for the formation of collectives in real-world domains},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The computational complexity of multi-agent pathfinding on
directed graphs. <em>AIJ</em>, <em>328</em>, 104063. (<a
href="https://doi.org/10.1016/j.artint.2023.104063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the non-optimizing variant of multi-agent pathfinding on undirected graphs is known to be a polynomial-time problem since almost forty years, a similar result has not been established for directed graphs. In this paper, it will be shown that this problem is NP-complete. For strongly connected directed graphs, however, the problem is polynomial. And both of these results hold even if one allows for synchronous rotations on fully occupied cycles. Interestingly, the results apply also to the so-called graph motion planning feasibility problem on directed graphs.},
  archive      = {J_AIJ},
  author       = {Bernhard Nebel},
  doi          = {10.1016/j.artint.2023.104063},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104063},
  shortjournal = {Artif. Intell.},
  title        = {The computational complexity of multi-agent pathfinding on directed graphs},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). From statistical relational to neurosymbolic artificial
intelligence: A survey. <em>AIJ</em>, <em>328</em>, 104062. (<a
href="https://doi.org/10.1016/j.artint.2023.104062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey explores the integration of learning and reasoning in two different fields of artificial intelligence : neurosymbolic and statistical relational artificial intelligence. Neurosymbolic artificial intelligence (NeSy) studies the integration of symbolic reasoning and neural networks , while statistical relational artificial intelligence (StarAI) focuses on integrating logic with probabilistic graphical models . This survey identifies seven shared dimensions between these two subfields of AI. These dimensions can be used to characterize different NeSy and StarAI systems. They are concerned with (1) the approach to logical inference, whether model or proof-based; (2) the syntax of the used logical theories; (3) the logical semantics of the systems and their extensions to facilitate learning; (4) the scope of learning, encompassing either parameter or structure learning ; (5) the presence of symbolic and subsymbolic representations; (6) the degree to which systems capture the original logic, probabilistic, and neural paradigms; and (7) the classes of learning tasks the systems are applied to. By positioning various NeSy and StarAI systems along these dimensions and pointing out similarities and differences between them, this survey contributes fundamental concepts for understanding the integration of learning and reasoning.},
  archive      = {J_AIJ},
  author       = {Giuseppe Marra and Sebastijan Dumančić and Robin Manhaeve and Luc De Raedt},
  doi          = {10.1016/j.artint.2023.104062},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104062},
  shortjournal = {Artif. Intell.},
  title        = {From statistical relational to neurosymbolic artificial intelligence: A survey},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-adjusting offspring population sizes outperform fixed
parameters on the cliff function. <em>AIJ</em>, <em>328</em>, 104061.
(<a href="https://doi.org/10.1016/j.artint.2023.104061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the discrete domain, self-adjusting parameters of evolutionary algorithms (EAs) have emerged as a fruitful research area with many runtime analyses showing that self-adjusting parameters can outperform the best fixed parameters. Most existing runtime analyses focus on elitist EAs on simple problems, for which moderate performance gains were shown. Here we consider a much more challenging scenario: the multimodal function Cliff, defined as an example where a ( 1 , λ ) (1,λ) EA is effective, and for which the best known upper runtime bound for standard EAs is O ( n 25 ) O(n25) . We prove that a ( 1 , λ ) (1,λ) EA self-adjusting the offspring population size λ using success-based rules optimises Cliff in O ( n ) O(n) expected generations and O ( n log ⁡ n ) O(nlog⁡n) expected evaluations. Along the way, we prove tight upper and lower bounds on the runtime for fixed λ (up to a logarithmic factor) and identify the runtime for the best fixed λ as n η nη for η ≈ 3.97677 η≈3.97677 (up to sub-polynomial factors). Hence, the self-adjusting ( 1 , λ ) (1,λ) EA outperforms the best fixed parameter by a factor of at least n 2.9767 n2.9767 .},
  archive      = {J_AIJ},
  author       = {Mario Alejandro Hevia Fajardo and Dirk Sudholt},
  doi          = {10.1016/j.artint.2023.104061},
  journal      = {Artificial Intelligence},
  month        = {3},
  pages        = {104061},
  shortjournal = {Artif. Intell.},
  title        = {Self-adjusting offspring population sizes outperform fixed parameters on the cliff function},
  volume       = {328},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fragility, robustness and antifragility in deep learning.
<em>AIJ</em>, <em>327</em>, 104060. (<a
href="https://doi.org/10.1016/j.artint.2023.104060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a systematic analysis of deep neural networks (DNNs) based on a signal processing technique for network parameter removal, in the form of synaptic filters that identifies the fragility , robustness and antifragility characteristics of DNN parameters. Our proposed analysis investigates if the DNN performance is impacted negatively, invariantly, or positively on both clean and adversarially perturbed test datasets when the DNN undergoes synaptic filtering. We define three filtering scores for quantifying the fragility, robustness and antifragility characteristics of DNN parameters based on the performances for (i) clean dataset, (ii) adversarial dataset, and (iii) the difference in performances of clean and adversarial datasets. We validate the proposed systematic analysis on ResNet-18, ResNet-50, SqueezeNet-v1.1 and ShuffleNet V2 x1.0 network architectures for MNIST, CIFAR10 and Tiny ImageNet datasets. The filtering scores, for a given network architecture, identify network parameters that are invariant in characteristics across different datasets over learning epochs. Vice-versa, for a given dataset, the filtering scores identify the parameters that are invariant in characteristics across different network architectures. We show that our synaptic filtering method improves the test accuracy of ResNet and ShuffleNet models on adversarial dataset when only the robust and antifragile parameters are selectively retrained at any given epoch, thus demonstrating applications of the proposed strategy in improving model robustness.},
  archive      = {J_AIJ},
  author       = {Chandresh Pravin and Ivan Martino and Giuseppe Nicosia and Varun Ojha},
  doi          = {10.1016/j.artint.2023.104060},
  journal      = {Artificial Intelligence},
  month        = {2},
  pages        = {104060},
  shortjournal = {Artif. Intell.},
  title        = {Fragility, robustness and antifragility in deep learning},
  volume       = {327},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exploratory machine learning with unknown unknowns.
<em>AIJ</em>, <em>327</em>, 104059. (<a
href="https://doi.org/10.1016/j.artint.2023.104059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In conventional supervised learning, a training dataset is given with ground-truth labels from a known label set, and the learned model will classify unseen instances to known labels. This paper studies a new problem setting in which there are unknown classes in the training data misperceived as other labels, and thus their existence appears unknown from the given supervision. We attribute the unknown unknowns to the fact that the training dataset is badly advised by the incompletely perceived label space due to the insufficient feature information. To this end, we propose the exploratory machine learning , which examines and investigates training data by actively augmenting the feature space to discover potentially hidden classes. Our method consists of three ingredients including rejection model, feature exploration, and model cascade. We provide theoretical analysis to justify its superiority, and validate the effectiveness on both synthetic and real datasets.},
  archive      = {J_AIJ},
  author       = {Peng Zhao and Jia-Wei Shan and Yu-Jie Zhang and Zhi-Hua Zhou},
  doi          = {10.1016/j.artint.2023.104059},
  journal      = {Artificial Intelligence},
  month        = {2},
  pages        = {104059},
  shortjournal = {Artif. Intell.},
  title        = {Exploratory machine learning with unknown unknowns},
  volume       = {327},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Is this a violation? Learning and understanding norm
violations in online communities. <em>AIJ</em>, <em>327</em>, 104058.
(<a href="https://doi.org/10.1016/j.artint.2023.104058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using norms to guide and coordinate interactions has gained tremendous attention in the multi-agent community. However, new challenges arise as the interest moves towards dynamic socio-technical systems, where human and software agents interact, and interactions are required to adapt to human&#39;s changing needs. For instance, different agents (human or software) might not have the same understanding of what it means to violate a norm (e.g., what characterizes hate speech), or their understanding of a norm might change over time (e.g., what constitutes an acceptable response time). The challenge is to address these issues by learning the meaning of a norm violation from limited interaction data. For this, we use batch and incremental learning to train an ensemble of classifiers . Ensemble learning and data-sampling handle the imbalanced class distribution of the interaction stream. At the same time, the training approaches use different strategies to ensure that the ensemble models reflect the latest community view on the meaning of norm violation. Batch learning uses weight assignment , while incremental learning continuously updates the ensemble models as community members interact. Here, we extend our previous work by creating a different balance strategy for online learning and integrating interpretability to understand norm violations. Additionally, we evaluate the proposed approaches in the context of Wikipedia article edits, where interactions revolve around editing articles, and the norm in question is prohibiting vandalism. Lastly, we conduct ablation studies to compare the ensemble&#39;s performance against a single model approach and to examine the behavior of two data sampling techniques. Results indicate that the different machine learning frameworks can learn the meaning of a norm violation in a setting with data imbalance and concept drift, although with significant differences.},
  archive      = {J_AIJ},
  author       = {Thiago Freitas dos Santos and Nardine Osman and Marco Schorlemmer},
  doi          = {10.1016/j.artint.2023.104058},
  journal      = {Artificial Intelligence},
  month        = {2},
  pages        = {104058},
  shortjournal = {Artif. Intell.},
  title        = {Is this a violation? learning and understanding norm violations in online communities},
  volume       = {327},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolving interpretable decision trees for reinforcement
learning. <em>AIJ</em>, <em>327</em>, 104057. (<a
href="https://doi.org/10.1016/j.artint.2023.104057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reinforcement learning (RL) techniques have achieved great success in many different applications. However, their heavy reliance on complex deep neural networks makes most RL models uninterpretable, limiting their application in domains where trust and security are important. To address this challenge, we propose MENS-DT-RL, an algorithm capable of constructing interpretable models for RL via the evolution of decision tree (DT) models. MENS-DT-RL uses a multi-method ensemble algorithm to evolve univariate DTs, guiding the process with a fitness metric that prioritizes interpretability and consistent high performance. Three different initializations for the MENS-DT-RL are proposed, including the use of Imitation Learning (IL) techniques, and a novel pruning approach that reduces solution size without compromising performance. To evaluate the proposed approach, we compare it with other models from the literature on three benchmark tasks from the OpenAI Gym library, as well as on a fertilization problem inspired by real-world crop management. To the best of our knowledge, the proposed scheme is the first to solve the Lunar Lander benchmark with both interpretability and a high confidence rate (90% of episodes are successful), as well as the first to solve the Mountain Car environment with a tree of only 7 nodes. On the real-world task, the proposed MENS-DT-RL is able to produce solutions with the same quality as deep RL policies, with the added bonus of interpretability. We also analyze the best solutions found by the algorithm and show that they are not only interpretable but also diverse in their behavior, empowering the end user with the choice of which model to apply. Overall, the findings show that the proposed approach is capable of producing high-quality transparent models for RL, achieving interpretability without losing performance.},
  archive      = {J_AIJ},
  author       = {Vinícius G. Costa and Jorge Pérez-Aracil and Sancho Salcedo-Sanz and Carlos E. Pedreira},
  doi          = {10.1016/j.artint.2023.104057},
  journal      = {Artificial Intelligence},
  month        = {2},
  pages        = {104057},
  shortjournal = {Artif. Intell.},
  title        = {Evolving interpretable decision trees for reinforcement learning},
  volume       = {327},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Negotiation strategies for agents with ordinal preferences:
Theoretical analysis and human study. <em>AIJ</em>, <em>327</em>,
104050. (<a href="https://doi.org/10.1016/j.artint.2023.104050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Negotiation is a very common interaction between agents. Many common negotiation protocols work with cardinal utilities, even though ordinal preferences, which only rank the outcomes, are easier to elicit from humans. In this work, we focus on negotiation with ordinal preferences over a finite set of outcomes. We study an intuitive protocol for bilateral negotiations, where the two parties make offers alternately. We analyze the negotiation protocol under two settings: First, we consider the full information setting, where each party is fully aware of the other party&#39;s preference order . For this case, we provide elegant strategies that specify a sub-game perfect equilibrium. In addition, we show how the studied negotiation protocol almost completely implements a known bargaining rule. Second, we analyze the complementary no-information setting where neither party knows the preference order of the other party. For this case, we provide a Maxmin strategy and show that every pair of Maxmin strategies specifies a robust-optimization equilibrium. Finally, through a human study ( N = 150 N=150 ), we empirically study the practical relevance of our full information analysis to people engaging in negotiations with each other and/or with an automated agent using the studied protocol. Surprisingly, our results indicate that people tend to arrive at the equilibrium outcomes despite frequently departing from the proposed strategies. In addition, in contrast to commonly held beliefs, we find that an equilibrium-following agent performs very well with people.},
  archive      = {J_AIJ},
  author       = {Noam Hazon and Sefi Erlich and Ariel Rosenfeld and Sarit Kraus},
  doi          = {10.1016/j.artint.2023.104050},
  journal      = {Artificial Intelligence},
  month        = {2},
  pages        = {104050},
  shortjournal = {Artif. Intell.},
  title        = {Negotiation strategies for agents with ordinal preferences: Theoretical analysis and human study},
  volume       = {327},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved maximin guarantees for subadditive and fractionally
subadditive fair allocation problem. <em>AIJ</em>, <em>327</em>, 104049.
(<a href="https://doi.org/10.1016/j.artint.2023.104049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the maximin share fairness notion ( MMS MMS ) for allocation of indivisible goods in the subadditive and fractionally subadditive settings. While previous work refutes the possibility of obtaining an allocation which is better than 1/2- MMS , the only positive result for the subadditive setting states that when the number of items is equal to m , there always exists an Ω ( 1 / log ⁡ m ) Ω(1/log⁡m) - MMS allocation. Since the number of items may be larger than the number of agents ( n ), such a bound can only imply a weak bound of Ω ( 1 n log ⁡ n ) Ω(1nlog⁡n) - MMS MMS allocation in general. In this work, we improve this bound exponentially to Ω ( 1 log ⁡ n log ⁡ log ⁡ n ) Ω(1log⁡nlog⁡log⁡n) - MMS guarantee. In addition to this, we prove that when the valuation functions are fractionally subadditive, a 0.2192235- MMS allocation is guaranteed to exist. This also improves upon the previous bound of 1/5- MMS guarantee for the fractionally subadditive setting.},
  archive      = {J_AIJ},
  author       = {Masoud Seddighin and Saeed Seddighin},
  doi          = {10.1016/j.artint.2023.104049},
  journal      = {Artificial Intelligence},
  month        = {2},
  pages        = {104049},
  shortjournal = {Artif. Intell.},
  title        = {Improved maximin guarantees for subadditive and fractionally subadditive fair allocation problem},
  volume       = {327},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Pessimistic value iteration for multi-task data sharing in
offline reinforcement learning. <em>AIJ</em>, <em>326</em>, 104048. (<a
href="https://doi.org/10.1016/j.artint.2023.104048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL) has shown promising results in learning a task-specific policy from a fixed dataset. However, successful offline RL often relies heavily on the coverage and quality of the given dataset. In scenarios where the dataset for a specific task is limited, a natural approach is to improve offline RL with datasets from other tasks, namely, to conduct Multi-Task Data Sharing (MTDS). Nevertheless, directly sharing datasets from other tasks exacerbates the distribution shift in offline RL. In this paper, we propose an uncertainty-based MTDS approach that shares the entire dataset without data selection. Given ensemble-based uncertainty quantification , we perform pessimistic value iteration on the shared offline dataset, which provides a unified framework for single- and multi-task offline RL. We further provide theoretical analysis, which shows that the optimality gap of our method is only related to the expected data coverage of the shared dataset, thus resolving the distribution shift issue in data sharing. Empirically, we release an MTDS benchmark and collect datasets from three challenging domains. The experimental results show our algorithm outperforms the previous state-of-the-art methods in challenging MTDS problems.},
  archive      = {J_AIJ},
  author       = {Chenjia Bai and Lingxiao Wang and Jianye Hao and Zhuoran Yang and Bin Zhao and Zhen Wang and Xuelong Li},
  doi          = {10.1016/j.artint.2023.104048},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104048},
  shortjournal = {Artif. Intell.},
  title        = {Pessimistic value iteration for multi-task data sharing in offline reinforcement learning},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sound and relatively complete belief hoare logic for
statistical hypothesis testing programs. <em>AIJ</em>, <em>326</em>,
104045. (<a href="https://doi.org/10.1016/j.artint.2023.104045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new approach to formally describing the requirement for statistical inference and checking whether a program uses the statistical method appropriately. Specifically, we define belief Hoare logic (BHL) for formalizing and reasoning about the statistical beliefs acquired via hypothesis testing. This program logic is sound and relatively complete with respect to a Kripke model for hypothesis tests. We demonstrate by examples that BHL is useful for reasoning about practical issues in hypothesis testing. In our framework, we clarify the importance of prior beliefs in acquiring statistical beliefs through hypothesis testing, and discuss the whole picture of the justification of statistical inference inside and outside the program logic.},
  archive      = {J_AIJ},
  author       = {Yusuke Kawamoto and Tetsuya Sato and Kohei Suenaga},
  doi          = {10.1016/j.artint.2023.104045},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104045},
  shortjournal = {Artif. Intell.},
  title        = {Sound and relatively complete belief hoare logic for statistical hypothesis testing programs},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximately EFX allocations for indivisible chores.
<em>AIJ</em>, <em>326</em>, 104037. (<a
href="https://doi.org/10.1016/j.artint.2023.104037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study how to fairly allocate a set of m indivisible chores to a group of n agents, each of which has a general additive cost function on the items. Since envy-free (EF) allocations are not guaranteed to exist, we consider the notion of envy-freeness up to any item (EFX). In contrast to the fruitful results regarding the (approximation of) EFX allocations for goods, very little is known for the allocation of chores. Prior to our work, for the allocation of chores, it is known that EFX allocations always exist for two agents or general number of agents with identical ordering cost functions. For general instances, no non-trivial approximation result regarding EFX allocation is known. In this paper, we make progress in this direction by providing several polynomial time algorithms for the computation of EFX and approximately EFX allocations. We show that for three agents we can always compute a ( 2 + 6 ) (2+6) -approximation of EFX allocation. For n ≥ 4 n≥4 agents, our algorithm always computes a ( 3 n 2 − n ) (3n2−n) -approximation. We also study the bi-valued instances, in which agents have at most two cost values on the chores. For three agents, we provide an algorithm for the computation of EFX allocations. For n ≥ 4 n≥4 agents, we present algorithms for the computation of partial EFX allocations with at most ( n − 1 ) (n−1) unallocated items; and ( n − 1 ) (n−1) -approximation of EFX allocations.},
  archive      = {J_AIJ},
  author       = {Shengwei Zhou and Xiaowei Wu},
  doi          = {10.1016/j.artint.2023.104037},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104037},
  shortjournal = {Artif. Intell.},
  title        = {Approximately EFX allocations for indivisible chores},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual forgetting operators in the context of weakest
sufficient and strongest necessary conditions. <em>AIJ</em>,
<em>326</em>, 104036. (<a
href="https://doi.org/10.1016/j.artint.2023.104036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forgetting is an important concept in knowledge representation and automated reasoning with widespread applications across a number of disciplines. A standard forgetting operator, characterized in [26] in terms of model-theoretic semantics and primarily focusing on the propositional case , opened up a new research subarea. In this paper, a new operator called weak forgetting , dual to standard forgetting, is introduced and both together are shown to offer a new more uniform perspective on forgetting operators in general. Both the weak and standard forgetting operators are characterized in terms of entailment and inference, rather than a model theoretic semantics. This naturally leads to a useful algorithmic perspective based on quantifier elimination and the use of Ackermann&#39;s Lemma and its fixpoint generalization. The strong formal relationship between standard forgetting and strongest necessary conditions and weak forgetting and weakest sufficient conditions is also characterized quite naturally through the entailment-based, inferential perspective used. The framework used to characterize the dual forgetting operators is also generalized to the first-order case and includes useful algorithms for computing first-order forgetting operators in special cases. Practical examples are also included to show the importance of both weak and standard forgetting in modeling and representation.},
  archive      = {J_AIJ},
  author       = {Patrick Doherty and Andrzej Szałas},
  doi          = {10.1016/j.artint.2023.104036},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104036},
  shortjournal = {Artif. Intell.},
  title        = {Dual forgetting operators in the context of weakest sufficient and strongest necessary conditions},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gerrymandering individual fairness. <em>AIJ</em>,
<em>326</em>, 104035. (<a
href="https://doi.org/10.1016/j.artint.2023.104035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual fairness requires that similar individuals are treated similarly. It is supposed to prevent the unfair treatment of individuals on the subgroup level and to overcome the problem that group fairness measures are susceptible to manipulation or gerrymandering. The goal of the present paper is to explore the extent to which individual fairness itself can be gerrymandered. It will be proved that individual fairness can be gerrymandered in the context of predicting scores. Then, it will be argued that individual fairness is a very weak notion of fairness for some choices of feature space and metric. Finally, it will be discussed which properties of (individual) fairness are desirable.},
  archive      = {J_AIJ},
  author       = {Tim Räz},
  doi          = {10.1016/j.artint.2023.104035},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104035},
  shortjournal = {Artif. Intell.},
  title        = {Gerrymandering individual fairness},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extending the description logic EL with threshold concepts
induced by concept measures. <em>AIJ</em>, <em>326</em>, 104034. (<a
href="https://doi.org/10.1016/j.artint.2023.104034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In applications of AI systems where exact definitions of the important notions of the application domain are hard to come by, the use of traditional logic-based knowledge representation languages such as Description Logics may lead to very large and unintuitive definitions, and high complexity of reasoning. To overcome this problem, we define new concept constructors that allow us to define concepts in an approximate way. To be more precise, we present a family τ EL ( m ) τEL(m) of extensions of the lightweight Description Logic EL EL that use threshold constructors for this purpose. To define the semantics of these constructors we employ graded membership functions m , which for each individual in an interpretation and concept yield a number in the interval [ 0 , 1 ] [0,1] expressing the degree to which the individual belongs to the concept in the interpretation. Threshold concepts C ⋈ t C⋈t for ⋈ ∈ { , ≥ } ⋈∈{&amp;lt;,≤,&amp;gt;,≥} then collect all the individuals that belong to C with degree ⋈ t . The logic τ EL ( m ) τEL(m) extends EL EL with threshold concepts whose semantics is defined relative to a function m . To construct appropriate graded membership functions, we show how concept measures ∼ (which are graded generalizations of subsumption or equivalence between concepts) can be used to define graded membership functions m ∼ m∼ . Then we introduce a large class of concept measures, called simi-d , for which the logics τ EL ( m ∼ ) τEL(m∼) have good algorithmic properties. Basically, we show that reasoning in τ EL ( m ∼ ) τEL(m∼) is NP/coNP-complete without TBox, PSpace-complete w.r.t. acyclic TBoxes, and ExpTime-complete w.r.t. general TBoxes. The exception is the instance problem, which is already PSpace-complete without TBox w.r.t. combined complexity. While the upper bounds hold for all elements of simi-d , we could prove some of the hardness results only for a subclass of simi-d . This article considerably improves on and generalizes results we have shown in three previous conference papers and it provides detailed proofs of all our results.},
  archive      = {J_AIJ},
  author       = {Franz Baader and Oliver Fernández Gil},
  doi          = {10.1016/j.artint.2023.104034},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104034},
  shortjournal = {Artif. Intell.},
  title        = {Extending the description logic EL with threshold concepts induced by concept measures},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Syntactic ASP forgetting with forks. <em>AIJ</em>,
<em>326</em>, 104033. (<a
href="https://doi.org/10.1016/j.artint.2023.104033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer Set Programming (ASP) constitutes nowadays one of the most successful paradigms for practical Knowledge Representation and declarative problem solving. The formal analysis of ASP programs is essential for a rigorous treatment of specifications, the correct construction of solvers and the extension with other representational features. In this paper, we present a syntactic transformation, called the unfolding operator, that allows forgetting an atom in a logic program (under ASP semantics). The main advantage of unfolding is that, unlike other syntactic operators, it is always applicable and guarantees strong persistence, that is, the result preserves the same stable models with respect to any context where the forgotten atom does not occur. The price for its completeness is that the result is an expression that may contain the fork operator. Yet, we illustrate how, in some cases, the application of fork properties may allow us to reduce the fork to a logic program.},
  archive      = {J_AIJ},
  author       = {Felicidad Aguado and Pedro Cabalar and Jorge Fandinno and David Pearce and Gilberto Pérez and Concepción Vidal},
  doi          = {10.1016/j.artint.2023.104033},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104033},
  shortjournal = {Artif. Intell.},
  title        = {Syntactic ASP forgetting with forks},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed web hacking by adaptive consensus-based
reinforcement learning. <em>AIJ</em>, <em>326</em>, 104032. (<a
href="https://doi.org/10.1016/j.artint.2023.104032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel adaptive consensus-based learning algorithm for automated and distributed web hacking. We aim to assist ethical hackers in conducting legitimate penetration testing and improving web security by identifying system vulnerabilities at an early stage. Ethical hacking is modeled as a capture-the-flag style task addressed within a distributed reinforcement learning framework. To achieve our goal, we employ interconnected intelligent agents that interact with their copies of the environment simultaneously to reach the target. They perform local information processing to optimize their policies and exchange information with neighboring agents. We propose a novel adaptive consensus scheme for inter-agent communications, which enables the agents to efficiently share network-wide information in a decentralized manner. The scheme dynamically adjusts its weights based on heuristics, involving both recency and frequency metrics of actions selected at a given state by an individual agent, similar to eligibility traces. We extensively analyze the convergence properties of our algorithm and introduce a new communication scheme design. We demonstrate that this design ensures the fastest convergence to the desired asymptotic values under the general setting of asymmetric communication topologies. Additionally, we provide a comprehensive review of the current state of the field and propose a web agent model with improved scalability compared to existing solutions. Numerical simulations are conducted to illustrate the key characteristics of our algorithm. The results demonstrate that it outperforms both non-cooperative and average consensus schemes. Moreover, our algorithm significantly reduces hacking times when compared to baseline algorithms that rely on more complex models. These findings offer valuable insights to system security administrators, enabling them to address identified shortcomings and vulnerabilities effectively.},
  archive      = {J_AIJ},
  author       = {Nemanja Ilić and Dejan Dašić and Miljan Vučetić and Aleksej Makarov and Ranko Petrović},
  doi          = {10.1016/j.artint.2023.104032},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104032},
  shortjournal = {Artif. Intell.},
  title        = {Distributed web hacking by adaptive consensus-based reinforcement learning},
  volume       = {326},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
