<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cor---287">COR - 287</h2>
<ul>
<li><details>
<summary>
(2024). New heuristics for the 2-stage assembly scheduling problem
with total earliness and tardiness minimisation: A computational
evaluation. <em>COR</em>, <em>172</em>, 106824. (<a
href="https://doi.org/10.1016/j.cor.2024.106824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, scheduling literature has focused mainly on solving problems related to processing jobs with non-assembly operations. Despite the growing interest in the assembly literature in recent years, knowledge of the problem is still in its early stages in many aspects. In this regard, we are not aware of any previous contributions that address the assembly scheduling problem with just-in-time objectives. To fill this gap, this paper studies the 2-stage assembly scheduling problem minimising the sum of total earliness and total tardiness. We first analyse the relationship between the decision problem and the generation of the due dates of the jobs, and identify the equivalences with different related decision problems depending on the instances. The properties and conclusions obtained in the analysis are applied to design two constructive heuristics and a composite heuristic. To evaluate our proposals, different heuristics from the state-of-the-art of related scheduling problems are adapted, and a computational evaluation is carried out. The excellent behaviour of the proposed algorithms is demonstrated by an extensive computational evaluation.},
  archive      = {J_COR},
  author       = {Carla Talens and Jorge M.S. Valente and Victor Fernandez-Viagas},
  doi          = {10.1016/j.cor.2024.106824},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106824},
  shortjournal = {Comput. Oper. Res.},
  title        = {New heuristics for the 2-stage assembly scheduling problem with total earliness and tardiness minimisation: A computational evaluation},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Redesigning a NSGA-II metaheuristic for the bi-objective
support vector machine with feature selection. <em>COR</em>,
<em>172</em>, 106821. (<a
href="https://doi.org/10.1016/j.cor.2024.106821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Support Vector Machine is a well-known technique used in supervised classification. Feature selection offers several benefits but also adds complexity to the problem. In this paper, we consider the soft margin SVM and given that two different objectives are considered simultaneously, obtaining the Pareto front , or at least a good approximation of it, gives the decision-maker a wide variety of solutions and has several advantages over having only one solution. The only metaheuristic that has been developed to give an approximation of such a front is a NSGA-II based technique. However, the design of such technique presents some limitations that are analyzed in this paper. We present a new metaheuristic that has been completely redesigned in order to overcome those drawbacks. We compare both techniques through an extensive computational experiment that demonstrates the superior efficiency of the new technique.},
  archive      = {J_COR},
  author       = {Javier Alcaraz},
  doi          = {10.1016/j.cor.2024.106821},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106821},
  shortjournal = {Comput. Oper. Res.},
  title        = {Redesigning a NSGA-II metaheuristic for the bi-objective support vector machine with feature selection},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Problem size reduction methods for large CVRPs.
<em>COR</em>, <em>172</em>, 106820. (<a
href="https://doi.org/10.1016/j.cor.2024.106820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We solve the Capacitated Vehicle Routing Problem (CVRP) by introducing a novel approach to problem size reduction. We propose the generation of short sequences of nodes called “sections”, which effectively act as single nodes in a reduced CVRP that is faster and easier to solve. Three section generation methods are compared, and the trade-off between solution quality and computation time savings is evaluated. We show that reduced problem sizes of up to around 60 percent of the original problem size, result in only modest decreases in solution quality, but allow for significant reductions of computation time, regardless of the optimization algorithm used. Our findings highlight the potential benefits of problem aggregation and size reduction for large-scale CVRPs and suggest opportunities for further improving aggregation methods.},
  archive      = {J_COR},
  author       = {Alina G. Dragomir and David I. Müller},
  doi          = {10.1016/j.cor.2024.106820},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106820},
  shortjournal = {Comput. Oper. Res.},
  title        = {Problem size reduction methods for large CVRPs},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fitness landscapes of buffer allocation problem for
production lines with unreliable machines. <em>COR</em>, <em>172</em>,
106819. (<a href="https://doi.org/10.1016/j.cor.2024.106819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the structural properties of the buffer allocation problem from the fitness landscape perspective. We consider manufacturing flow lines with series–parallel network structure. The machines are supposed to be unreliable, their time to failure and repair time are exponentially distributed. Tentative solutions are evaluated by means of an approximate method based on the Markov models aggregation. We carry out computational experiments with local search and genetic algorithms in order to evaluate the fitness landscape properties of previously published instances and their modifications. It turns out that the so-called ‘massif central’ or ‘big valley’ structure of the fitness landscape is present but only partially: The fitness of local optima is negatively correlated with the distance to the best found solution, yet the set of local optima cannot be encompassed by a ball of relatively small size with respect to the size of solution space. Moreover, we show that in many problem instances, several clusters of local optima can be identified. The performance of genetic algorithms is discussed with respect to population clustering and the permanent usage of crossover is recommended.},
  archive      = {J_COR},
  author       = {Alexandre Dolgui and Anton V. Eremeev and Vyatcheslav S. Sigaev},
  doi          = {10.1016/j.cor.2024.106819},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106819},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fitness landscapes of buffer allocation problem for production lines with unreliable machines},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A GRASP algorithm for the concrete delivery problem.
<em>COR</em>, <em>172</em>, 106818. (<a
href="https://doi.org/10.1016/j.cor.2024.106818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a novel variant of the Concrete Delivery Problem (CDP), which involves the efficient scheduling of ready-mixed concrete deliveries to construction sites while balancing the conflicting goals of minimizing transportation costs and maximizing customer satisfaction. In this study, we propose an exact formulation and a heuristic approach based on the Greedy Randomized Adaptive Search Procedure (GRASP) to tackle this challenging CDP variant. This variant introduces realistic side constraints, including driver working shifts, a minimum driver working time, and overtime penalties. Additionally, it considers the case where customers may request multiple types of concrete delivered within the same time window. We assess the performance of our heuristic using new instances generated for this problem and provide a comparative analysis with another CDP variant from the literature to demonstrate its effectiveness.},
  archive      = {J_COR},
  author       = {Ousmane Ali and Jean-François Côté and Leandro C. Coelho},
  doi          = {10.1016/j.cor.2024.106818},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106818},
  shortjournal = {Comput. Oper. Res.},
  title        = {A GRASP algorithm for the concrete delivery problem},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tri-objective lot-streaming scheduling optimization for
hybrid flow shops with uncertainties in machine breakdowns and job
arrivals using an enhanced genetic programming hyper-heuristic.
<em>COR</em>, <em>172</em>, 106817. (<a
href="https://doi.org/10.1016/j.cor.2024.106817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lot-streaming scheduling has been widely recognized as a means to improve shop productivity, but there is few research on lot-streaming scheduling problems under dynamic disturbances. To fill the gap, lot-streaming scheduling optimization approach for hybrid flow shops with uncertainties in machine breakdowns and job arrivals is proposed. A mathematical model is formulated with objectives of minimizing maximum tardiness, total idle energy consumption of the machine, and maximum makespan. Since the Genetic Programming Hyper Heuristic algorithm has better results in solving dynamic scheduling problems, a Collaborative Harmony Search-based Genetic Programming Hyper Heuristic (CHS-GPHH) is presented to solve the dynamic lot-streaming hybrid flow shop scheduling problem (DLS-HFSSP) with the two dynamic events occurring simultaneously. In the improved algorithm, a neighborhood structure based on harmony search is developed for lot splitting. To verify the effectiveness of the proposed approach, the various comparative studies c are conducted on the lot-streaming dynamic hybrid flow shop scheduling. The results demonstrate the effectiveness of each improvement component of the CHS-GPHH, and verify that CHS-GPHH is an effective approach to deal with DLS-HFSSP with the in all the scenarios.},
  archive      = {J_COR},
  author       = {Jianguo Duan and Fanfan Liu and Qinglei Zhang and Jiyun Qin},
  doi          = {10.1016/j.cor.2024.106817},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106817},
  shortjournal = {Comput. Oper. Res.},
  title        = {Tri-objective lot-streaming scheduling optimization for hybrid flow shops with uncertainties in machine breakdowns and job arrivals using an enhanced genetic programming hyper-heuristic},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-cut algorithm for the time-dependent vehicle
routing problem with time windows and combinatorial auctions.
<em>COR</em>, <em>172</em>, 106807. (<a
href="https://doi.org/10.1016/j.cor.2024.106807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The urban logistics industry typically faces traffic congestion problems that result in variation of travel times across the day and impose a great challenge in routing design. While companies may either use a private fleet of delivery vehicles or outsource the tasks to the third-party logistics (3PL) providers to fulfill their logistics demand, some companies might employ a combination of both when their resource is unable to cope with demand or if demand fluctuates significantly over time. To tackle both challenges, we focus on a new variant of the vehicle routing problem known as the time-dependent vehicle routing problem with time windows and combinatorial auctions (TD-VRPTWCA), which considers time-dependent travel times in the routing design of the private fleet while selecting competitive bids from the 3PLs to serve a subset of the customers economically. The goal is to minimize the sum of the travel cost incurred by the private fleet and the outsourcing cost charged by the 3PLs for the chosen bids. To solve this problem, we present an arc-flow model with nine families of valid inequalities to strengthen the linear relaxation of the model. Based on this, a branch-and-cut approach is developed and evaluated on instances adapted from the well-known Solomon’s benchmark data. Extensive computational results demonstrate the effectiveness of the proposed method.},
  archive      = {J_COR},
  author       = {Jiachen Wei and Mark Poon and Zhenzhen Zhang},
  doi          = {10.1016/j.cor.2024.106807},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106807},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-cut algorithm for the time-dependent vehicle routing problem with time windows and combinatorial auctions},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A genetic algorithm to solve the production lot-sizing
problem with capacity adjustment. <em>COR</em>, <em>172</em>, 106806.
(<a href="https://doi.org/10.1016/j.cor.2024.106806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When dynamic production capacity is considered in production lot-sizing plans, it becomes very challenging to efficiently determine the optimal production plan. Many papers apply “at most one fractional production period” to develop efficient algorithms, but those algorithms are still time consuming. In this paper, in a special situation where costs are non-speculative, we provide a novel proposal based on “at least one balance period”, in which the products made in this period not only satisfy the demands in this period but also backlogged demands and some demands after this period, to obtain an efficient algorithm. This algorithm complexity is one level lower than the algorithm without non-speculative cost assumptions in the literature regarding the number of periods in their time complexity function. Then, in a general situation, we propose a combination of two complementary algorithms as an efficient heuristic method. Moreover, in the literature, the estimation of computation time complexity in searching for the optimal production plan considers only the number of capacity levels and production periods on theoretical view. However, with numerical experiments, we observe that demand variation could also have significant effects on the computation time in practice.},
  archive      = {J_COR},
  author       = {Jinglei Yang and Michael Zhang and Jiejian Feng and Kai He},
  doi          = {10.1016/j.cor.2024.106806},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106806},
  shortjournal = {Comput. Oper. Res.},
  title        = {A genetic algorithm to solve the production lot-sizing problem with capacity adjustment},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cooperative coevolutionary genetic programming
hyper-heuristic for multi-objective makespan and cost optimization in
cloud workflow scheduling. <em>COR</em>, <em>172</em>, 106805. (<a
href="https://doi.org/10.1016/j.cor.2024.106805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel multi-objective approach for NP-hard workflow scheduling in cloud computing environments. Traditional rule-based heuristics offer flexibility but lack consistent superiority across all criteria and scenarios. The development of specific rules usually requires tedious manual refinement by experts. To overcome this limitation, our method leverages evolutionary computation and simulation to automatically derive new rules. Moreover, workflow scheduling involves two crucial and related aspects: task scheduling and the allocation of virtual machines. Our contribution includes three distinct algorithms: two that address each decision separately and a third approach that coevolves priority rules for both decisions simultaneously. Computational tests demonstrate superior performance, with an exploration of rules yielding a 72.91% larger hypervolume for optimizing makespan and costs compared to benchmark heuristics from the literature. The validation on unseen instances shows a 90.26% improvement in hypervolume performance, highlighting the robustness of our approach.},
  archive      = {J_COR},
  author       = {Tomás Zaki and Yannik Zeiträg and Rui Neves and José Rui Figueira},
  doi          = {10.1016/j.cor.2024.106805},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106805},
  shortjournal = {Comput. Oper. Res.},
  title        = {A cooperative coevolutionary genetic programming hyper-heuristic for multi-objective makespan and cost optimization in cloud workflow scheduling},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Closed-loop supply chain network design with
price-greenness-sensitive demand: A distributionally robust
chance-constrained optimization approach. <em>COR</em>, <em>172</em>,
106803. (<a href="https://doi.org/10.1016/j.cor.2024.106803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the government’s heightened focus on recycling and remanufacturing, as well as the growing awareness among consumers about environmental security, manufacturing companies are currently required to establish efficient closed-loop supply chain networks in order to improve their social reputation and competitive advantage. This study investigates the optimization of a Closed-Loop Supply Chain (CLSC) network that involves multiple products, multiple periods, and uncertain returns, which also considers the influence of many factors, such as carbon cap-and-trade policy, raw part procurement discounts, and facility capacity constraints, on the supply chain. Simultaneously, customer demand is sensitive to both product pricing and product greenness, and product greenness can be improved by investing in emission reduction technologies. To address the uncertainty in the returns, we propose a two-stage distributionally robust chance-constrained optimization model, which is transformed into a mixed integer linear programming model. To efficiently address the complex problem, we design an improved Benders decomposition (IBD) algorithm. The experimental results confirm that the IBD algorithm has significant advantages when compared to the Benders decomposition algorithm. Additionally, this study conducted a sensitivity analysis on key parameters and proposed operation suggestions of practical importance.},
  archive      = {J_COR},
  author       = {Yao Gao and Shaojun Lu and Sheng Zhan and Chaoming Hu and Xinbao Liu},
  doi          = {10.1016/j.cor.2024.106803},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106803},
  shortjournal = {Comput. Oper. Res.},
  title        = {Closed-loop supply chain network design with price-greenness-sensitive demand: A distributionally robust chance-constrained optimization approach},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk-averse multistage stochastic programs with expected
conditional risk measures. <em>COR</em>, <em>172</em>, 106802. (<a
href="https://doi.org/10.1016/j.cor.2024.106802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study risk-averse multistage stochastic programs with expected conditional risk measures (ECRMs). ECRMs are attractive because they are time-consistent, which means that a plan made today will not be changed in the future if the problem is re-solved given a realization of the random variables. We show that the computational burden of solving the risk-averse problems based on ECRMs is the same as the risk-neutral ones. We consider ECRMs for both quantile and deviation mean-risk measures, deriving the Bellman equations in each case. Finally, we illustrate our results with extensive numerical computations for problems from two applications: hydrothermal scheduling and portfolio selection. The results show that the ECRM approach provides higher expected costs in the early stages to hedge against cost spikes in later stages for the hydrothermal scheduling problem. For the portfolio selection problem, the new approach gives well-diversified portfolios over time. Overall, the ECRM approach provides superior performance over the risk-neutral model under extreme scenario conditions.},
  archive      = {J_COR},
  author       = {Maryam Khatami and Thuener Silva and Bernardo K. Pagnoncelli and Lewis Ntaimo},
  doi          = {10.1016/j.cor.2024.106802},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106802},
  shortjournal = {Comput. Oper. Res.},
  title        = {Risk-averse multistage stochastic programs with expected conditional risk measures},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved timetable edge finder rule for cumulative
constraint with profile. <em>COR</em>, <em>172</em>, 106795. (<a
href="https://doi.org/10.1016/j.cor.2024.106795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data structures are the main ingredient to strengthen both the time complexity and the filtering power of algorithms in Constraint-Based Scheduling. The TimeTable and the Profile are well-known data structures applied to filtering algorithms for cumulative constraint. The two data structures in this paper are applied simultaneously to overload checking and edge-finding rules. The resulting rules named TimeTable Horizontally Elastic Overload Checker and TimeTable Horizontally Elastic Edge Finder rules respectively subsume the enhancement of the overload checking rule and the edge-finding rule with the individual data structure. This new edge-finding rule is relaxed after a successive application of Profile on well-selected task intervals, then TimeTable on the new horizontally elastic edge-finding rule. Potential task intervals for the edge-finding rule are selected based on two criteria (specified later in the paper) and the strong detection rule of the horizontally elastic edge finder rule of Fetgo Betmbe and Djamegni (2022) is then applied to those selected task intervals. The new horizontally elastic edge-finder rule subsumes the edge-finding rule and is not comparable to the timetable edge-finding rule. A two-phase filtering algorithm of complexity O ( n 2 ) O(n2) each (where n n is the number of tasks sharing the resource) is proposed for the new rule. Improvements based on the TimeTable are obtained by considering fixed parts of external tasks that overlap with the potential task intervals. The improved rule subsumes the timetable edge-finding rule, and a quadratic algorithm is derived from the previous algorithm. Experimental results, on a well-known suite of benchmark instances of Resource-Constrained Project Scheduling Problems, show that the propounded algorithms are competitive with the state-of-the-art algorithms regarding running time and tree search reduction.},
  archive      = {J_COR},
  author       = {Roger Kameugne and Sévérine Fetgo Betmbe and Thierry Noulamo and Clémentin Tayou Djamegni},
  doi          = {10.1016/j.cor.2024.106795},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106795},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improved timetable edge finder rule for cumulative constraint with profile},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast local search algorithm for minimum sum coloring
problem on massive graphs. <em>COR</em>, <em>172</em>, 106794. (<a
href="https://doi.org/10.1016/j.cor.2024.106794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum sum coloring problem (MSCP) is an important extension of the graph coloring problem with wide real-world applications. Compared to the classic graph coloring problem, where lots of methods have been developed and even massive graphs with millions of vertices can be solved well, few works have been done for the MSCP, and no specialized MSCP algorithms are available for solving massive graphs. This paper explores how to solve MSCP on massive graphs, and then proposes a fast local search algorithm for the MSCP based on three main ideas including a coarse-grained reduction method, two kinds of scoring functions and selection rules as well as a novel local search framework. Experiments are conducted to compare our algorithm with several state-of-the-art algorithms on massive graphs. The proposed algorithm outperforms previous algorithms in almost all the massive graphs and also improves the best-known solutions for some conventional instances, which demonstrates the performance and robustness of the proposed algorithm.},
  archive      = {J_COR},
  author       = {Yan Li and Mengyu Zhao and Xindi Zhang and Yiyuan Wang},
  doi          = {10.1016/j.cor.2024.106794},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106794},
  shortjournal = {Comput. Oper. Res.},
  title        = {A fast local search algorithm for minimum sum coloring problem on massive graphs},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A graph reinforcement learning framework for neural adaptive
large neighbourhood search. <em>COR</em>, <em>172</em>, 106791. (<a
href="https://doi.org/10.1016/j.cor.2024.106791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive Large Neighbourhood Search (ALNS) is a popular metaheuristic with renowned efficiency in solving combinatorial optimisation problems. However, despite 18 years of intensive research into ALNS, the design of an effective adaptive layer for selecting operators to improve the solution remains an open question. In this work, we isolate this problem by formulating it as a Markov Decision Process, in which an agent is rewarded proportionally to the improvement of the incumbent. We propose Graph Reinforcement Learning for Operator Selection (GRLOS), a method based on Deep Reinforcement Learning and Graph Neural Networks, as well as Learned Roulette Wheel (LRW), a lightweight approach inspired by the classic Roulette Wheel adaptive layer. The methods, which are broadly applicable to optimisation problems that can be represented as graphs, are comprehensively evaluated on 5 routing problems using a large portfolio of 28 destroy and 7 repair operators. Results show that both GRLOS and LRW outperform the classic selection mechanism in ALNS, owing to the operator choices being learned in a prior training phase. GRLOS is also shown to consistently achieve better performance than a recent Deep Reinforcement Learning method due to its substantially more flexible state representation. The evaluation further examines the impact of the operator budget and type of initial solution, and is applied to problem instances with up to 1000 customers. The findings arising from our extensive benchmarking bear relevance to the wider literature of hybrid methods combining metaheuristics and machine learning.},
  archive      = {J_COR},
  author       = {Syu-Ning Johnn and Victor-Alexandru Darvariu and Julia Handl and Jörg Kalcsics},
  doi          = {10.1016/j.cor.2024.106791},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106791},
  shortjournal = {Comput. Oper. Res.},
  title        = {A graph reinforcement learning framework for neural adaptive large neighbourhood search},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated packing and routing: A model and its solutions.
<em>COR</em>, <em>172</em>, 106790. (<a
href="https://doi.org/10.1016/j.cor.2024.106790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the two-level vehicle routing and loading problem (2L-VRLP), an innovative model integrating the two-level bin packing and vehicle routing problems to address real-world logistics challenges that require simultaneous packing and transportation decisions. By capturing the essence of dual-level packing (boxes onto pallets, pallets onto vehicles) and optimising vehicle routing, the 2L-VRLP offers an integrated framework that outperforms traditional separated models, demonstrating superior solutions that align closely with practical logistics operations. We propose a set of heuristic algorithms tailored for the 2L-VRLP’s unique requirements and explore automated algorithm selection using an artificial neural network (ANN), marking a step towards incorporating machine learning in logistics optimisation. This work not only showcases the 2L-VRLP model’s potential to enhance logistics management but also sets the groundwork for future research and applications in this domain.},
  archive      = {J_COR},
  author       = {Congzheng Liu and Jing Lyu and Ke Fang},
  doi          = {10.1016/j.cor.2024.106790},
  journal      = {Computers &amp; Operations Research},
  month        = {12},
  pages        = {106790},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integrated packing and routing: A model and its solutions},
  volume       = {172},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the predictive accuracy of production frontier
models for efficiency measurement using machine learning: The LSB-MAFS
method. <em>COR</em>, <em>171</em>, 106793. (<a
href="https://doi.org/10.1016/j.cor.2024.106793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Making accurate predictions of the true production frontier is critical for reliable efficiency analysis. However, canonical deterministic methods like Data Envelopment Analysis (DEA) provide approximations of the production frontier that cannot accommodate noise satisfactorily and suffer from overfitting. This study combines machine learning techniques known as Least Squares Boosting (LSB) and Multivariate Adaptive Regression Splines (MARS), to introduce a new methodology that improves the accuracy of production frontiers predictions and overcomes previous limitations. The new method fits pairwise regression splines to the data while ensuring that the predicted production frontiers satisfy certain the required regularity conditions: envelopmentness, monotonicity, and concavity. The method, termed LSB-MAFS, is implemented through computational algorithms, and we illustrate its applicability by performing simulations with several data generating processes. We also compare its performance against the most popular alternatives, considering both deterministic and stochastic scenarios: DEA, bootstrapped DEA, Corrected Concave Non-Parametric Least Squares (C 2 NLS) and Stochastic Frontier Analysis (SFA). The new method outperforms these alternatives in the most complex scenarios, including stochastic settings where parametric methods like SFA should perform better in principle. We conclude that our approach to production frontier prediction is a valid and competitive alternative for dependable efficiency analysis.},
  archive      = {J_COR},
  author       = {María D. Guillen and Juan Aparicio and José L. Zofío and Victor J. España},
  doi          = {10.1016/j.cor.2024.106793},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106793},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improving the predictive accuracy of production frontier models for efficiency measurement using machine learning: The LSB-MAFS method},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bay design problem in less-than-unit-load production
warehouse. <em>COR</em>, <em>171</em>, 106792. (<a
href="https://doi.org/10.1016/j.cor.2024.106792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a bay design problem in a less-than-unit-load production warehouse, which is motivated by a real-world problem in a semiconductor company. The objective is to maximize the utilization of the vertical space in bays by considering several practical storage requirements. To solve the problem, a non-linear integer programming model is first formulated. Since the problem is similar to a two-stage cutting stock problem (CSP), a column-and-row generation (CRG) method is developed, in which the original problem is decomposed into a restricted master problem and three subproblems, including two classical column generation subproblems and a row generation subproblem. The two former subproblems are solved as unbounded knapsack problems and for the latter, a two-stage approach is applied. The results of computational experiments on randomly generated instances show that the proposed CRG method is more efficient than the classic column-generation-based method, solving the non-linear model directly and solving a cut model in the literature directly. The results of a case study show that our strategy can improve the utilization of the existing warehouse storage space significantly by about 24%. The CRG method is also tested on basic two-stage two-dimensional CSP benchmarks and its performance is compared to those of other pattern-based methods. The results show its potential for effectively solving the basic two-stage two-dimensional CSPs.},
  archive      = {J_COR},
  author       = {Shijin Wang and Xiangning Li and Yihong Hu and Feng Chu},
  doi          = {10.1016/j.cor.2024.106792},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106792},
  shortjournal = {Comput. Oper. Res.},
  title        = {A bay design problem in less-than-unit-load production warehouse},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated optimization of pilot and pilot carrier routing
in seaports. <em>COR</em>, <em>171</em>, 106789. (<a
href="https://doi.org/10.1016/j.cor.2024.106789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pilotage is an important service for vessels to enter and leave seaports. When vessels entering or leaving their berths, pilots are assigned to provide assistance on board to maneuver the vessels. Pilot carriers, such as pilot boats and helicopters are utilized to transport pilots from the pilot station to the vessels at appointed ground. With the increasing number of calling vessels, the pilotage plan should be made properly considering the limited pilots and carriers resources in seaports to enhance timing reliability, which is a key port performance indicator. This paper studies the pilot and pilot carrier routing problem arising in seaports, where both the routes of pilots and carriers are determined jointly to achieve the lowest pilotage costs. The required service time intervals of vessels, the synchronization between pilots and carriers and the limited working duration for both pilots and carriers are considered. The problem is formulated as an arc-flow model, and a hybrid multi-start adaptive large neighborhood search and local search algorithm (mALNS-LS) is developed. Efficient departure time and cost computation methods are designed based on a set of forward and backward functions, and a model-based post optimization is applied. Computational experiments verify the performance of the proposed mALNS-LS in terms of solution quality and efficiency.},
  archive      = {J_COR},
  author       = {Xin Wang and Yijing Liang and Ek Peng Chew and Haobin Li and Kok Choon Tan},
  doi          = {10.1016/j.cor.2024.106789},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106789},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integrated optimization of pilot and pilot carrier routing in seaports},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributionally robust optimization approach for the
potassium fertilizer product transportation considering transshipment
through crossdocks. <em>COR</em>, <em>171</em>, 106788. (<a
href="https://doi.org/10.1016/j.cor.2024.106788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Potassium fertilizer is an essential input for agricultural productivity, and plays a critical role in various plant processes, influencing water uptake, enzyme activation, and photosynthesis. The efficient delivery of potassium fertilizer products to the end-users, typically farmers and agricultural enterprises, is of utmost importance. Due to the long traveling distance between the supplier and customers, decision makers of supplier normally set up multiple crossdocks to aid in transition and storage of potassium fertilizer products. In this situation, making an optimal transportation plan as well as the inventory level of crossdocks will directly enhance the efficiency and effectiveness of long-distance transportation. In this study, we model this problem as a dynamic transportation problem with transshipment considering the uncertain time-varying customers’ demand. To characterize the demand information, we first construct an ambiguity set of customers’ demand based in limited historical data and then develop a distributionally robust optimization-based (DRO) framework to optimize the transportation plan and related inventory level of crossdocks simultaneously. We also propose a general approach to overcome the computational challenges of DRO by transforming the original DRO into a second-order cone programming based on duality theory. Additionally, we introduce linear decision rules to adjust the optimization strategy based on the new observed demand, thus lead the model to handle the dynamic information flow in real time. In case study, all involved data are collected or derived from a real potassium fertilizer company located at Western China. The results show our model reduces the cost by 18.07% compared to stochastic model (sample average approximation), indicating a significant effectiveness of our model on the improvement of delivery efficiency and cost saving in real dynamic logistic systems. Also, we conclude the managerial insight that decision-makers should develop a comprehensive strategy, including improving communication to ensure order status updates, planning rationally to evenly distribute orders, and proactively allocating resources to meet operational demands.},
  archive      = {J_COR},
  author       = {Shancheng Jiang and Qize Liu and Lubin Wu and Yu Zhang and Muhammet Deveci and Zhen-Song Chen},
  doi          = {10.1016/j.cor.2024.106788},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106788},
  shortjournal = {Comput. Oper. Res.},
  title        = {A distributionally robust optimization approach for the potassium fertilizer product transportation considering transshipment through crossdocks},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scalable learning approach for the capacitated vehicle
routing problem. <em>COR</em>, <em>171</em>, 106787. (<a
href="https://doi.org/10.1016/j.cor.2024.106787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing efficient heuristics for the different variants of vehicle routing problems and customising the heuristics to various input distributions is a time-consuming and expensive task. In recent years, end-to-end machine learning techniques have been developed because they are easy to modify for different problem variants, thereby saving on the design time to develop new efficient heuristics. These learning techniques, such as the transformer-based constructive methods, struggle to provide high quality solutions on problem instances with hundreds to thousands of customers in a reasonable time. Furthermore, many of the end-to-end heuristics also do not guarantee that solutions obey fleet-size constraints. We propose a heuristic for solving large capacitated vehicle routing problem (CVRP) that carefully integrates a machine learning heuristic with Integer Linear Programming techniques. To address the issue of solutions with poor objective function values generated by end-to-end machine learning approaches on larger instances, we dynamically partition the CVRP problem instance into smaller sub-problems and apply a machine heuristic on the smaller sub-problems. This allows the machine learning heuristic to always operate on smaller problems similar in size to those for which it was trained. The machine learning heuristic generates many solutions for each sub-problem which are then combined using a set partitioning approach based on a ILP formulation. The set partitioning ILP also guarantees that solutions obey fleet-size constraints. We evaluate the performance of our heuristic on a difficult set of benchmark instances with hundreds to thousands of nodes, achieving small gaps (less than 3% on average) with respect to best known solutions, significantly improving upon the solution quality of the existing learning heuristics. Furthermore, we demonstrate that our results generalise well to other vehicle routing problems, such as green vehicle routing problem.},
  archive      = {J_COR},
  author       = {James Fitzpatrick and Deepak Ajwani and Paula Carroll},
  doi          = {10.1016/j.cor.2024.106787},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106787},
  shortjournal = {Comput. Oper. Res.},
  title        = {A scalable learning approach for the capacitated vehicle routing problem},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient two-stage optimization algorithm for a flexible
job shop scheduling problem with worker shift arrangement. <em>COR</em>,
<em>171</em>, 106785. (<a
href="https://doi.org/10.1016/j.cor.2024.106785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the involvement of workers, scheduling production jobs necessitates consideration of worker shifts in most production activities. In this study, we address a flexible job shop scheduling problem with worker shift arrangement, considering constraints such as job priority, limited resources, and resource unavailability. To minimize the overdue days of low-priority jobs and ensure the timely delivery of high-priority jobs, we establish a mixed-integer programming model to allocate production resources, process sequencing, and schedule worker shifts. An improved differential evolution algorithm is proposed and designed such that overdue days and worker overtime of all jobs are calculated. Furthermore, we develop a two-stage intelligent optimization algorithm. First, we design a two-segment chromosome encoding and decoding method. Then, we propose generation strategies that follow the urgency of the priority rule to generate high-quality initial chromosomes. In adaptive worker shift adjustment, we prioritize high-priority jobs to align with delivery times. We conducted experiments to validate our model and algorithm by comparing them against four well-known intelligent optimization algorithms. Our improved algorithm proves to be highly beneficial in job and worker scheduling as it effectively minimizes overdue days and arranges worker overtime.},
  archive      = {J_COR},
  author       = {Hui Li and Jianbiao Peng and Xi Wang},
  doi          = {10.1016/j.cor.2024.106785},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106785},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient two-stage optimization algorithm for a flexible job shop scheduling problem with worker shift arrangement},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shelter location–allocation problem for disaster evacuation
planning: A simulation optimization approach. <em>COR</em>,
<em>171</em>, 106784. (<a
href="https://doi.org/10.1016/j.cor.2024.106784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Immediately after a major earthquake strikes, a segment of the people in the disaster region must evacuate to relief shelters. If the evacuation proceeds in an efficient and safe manner, many lives can potentially be saved as the effects of secondary factors, e.g., secondary collapses, stampedes, and aftershocks, can largely be mitigated, while at the same time the people taking refuge can quickly gain access to vital relief goods. Formulating the best possible protocols for post-earthquake evacuation is a crucial, yet highly challenging problem considering the profound uncertainty which is present in the post-disaster environment, including the location and degree of infrastructural damage, the number and location of people who need to evacuate, the behavior and psychology of evacuees, etc. In this research, we formulate a two-stage stochastic evacuation simulation model capable of credibly accounting for these uncertainties. We develop a solution methodology to solve the shelter location–allocation problem represented by the two-stage model, finding the optimal location of shelters to be open as the first stage solution and the optimal assignment of evacuees to shelters as the second stage solution to minimize the total expected cost. The cost-based objective function consists of the cost of opening shelters, a deprivation cost component, the cost of trapped evacuees, and the cost of shelters exceeding capacity. In developing this framework, we collaborate with the National Science and Technology Center for Disaster Reduction (NCDR) in utilizing GIS-based probabilistic models of road damage. We apply the proposed framework to run an extensive numerical study and present various valuable observations and insights which can be gained.},
  archive      = {J_COR},
  author       = {Kuo-Hao Chang and Yow-Jen Pan and Hongey Chen},
  doi          = {10.1016/j.cor.2024.106784},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106784},
  shortjournal = {Comput. Oper. Res.},
  title        = {Shelter location–allocation problem for disaster evacuation planning: A simulation optimization approach},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rolling optimal scheduling for urban parcel crowdsourced
delivery with new order insertion. <em>COR</em>, <em>171</em>, 106779.
(<a href="https://doi.org/10.1016/j.cor.2024.106779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of mobile information technology has introduced numerous new solutions for delivery companies to enhance profits. One such solution employed by some companies is crowdsourced delivery. In this paper, we focus on rolling optimal scheduling for urban parcel crowdsourced delivery by utilizing private cars that will be in passing with the incorporation of new order insertion. The bonus incentive strategy is introduced to enhance the delivery probability of private car drivers. A static model and a rolling optimization model to maximize profits and the number of parcels delivered by private cars are established. To address the NP-hard problem, a hybrid genetic algorithm and insertion algorithm are designed. Numerical experiments are carried out to verify the proposed method in different scenarios, including the scattered network, clustered network, Dalian network, and Foursquare network. The computational results demonstrate that the method enhances the matching ratio and increases profits. Utilizing private cars that will be in passing for urban parcel delivery reduces the need for dedicated vehicles, mitigating traffic growth and alleviating traffic congestion. Increasing the private car-parcel ratio improves profits and the matching ratio while reducing traffic growth. Raising the incentive coefficient for bonuses increases the matching ratio and detour distance, but profits first increase and then decrease, and delivery distance by dedicated vehicles decreases. Our research findings offer a more rational basis for green urban parcel delivery decision-making by companies.},
  archive      = {J_COR},
  author       = {Xiaoping Liang and Hualong Yang and Zheng Wang},
  doi          = {10.1016/j.cor.2024.106779},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106779},
  shortjournal = {Comput. Oper. Res.},
  title        = {Rolling optimal scheduling for urban parcel crowdsourced delivery with new order insertion},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A matheuristic for the two-echelon inventory-routing
problem. <em>COR</em>, <em>171</em>, 106778. (<a
href="https://doi.org/10.1016/j.cor.2024.106778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective coordination of operational decisions in today’s global supply chains has grown increasingly important. This paper considers a two-echelon inventory-routing problem under a vendor-managed inventory system, where suppliers are responsible for fulfilling the demands of geographically scattered customers through a set of intermediate facilities over a finite planning horizon. The problem involves determining the routing and delivery decisions to minimize the total routing and inventory costs. We introduce an effective two-phase matheuristic approach that combines tabu search and mathematical programming models. Computational experiments show that our approach achieves excellent results regarding solution quality and computational time. For small instances, the matheuristic finds 99 optimal solutions out of 165 known optimal solutions and achieves an average gap of ( − 2 . 32 % ) (−2.32%) over 235 instances with a known best upper bound only, improving 159 known best upper bounds. Our approach also solves larger instances within a reasonable computational time and provides upper bounds for all 400 large-sized instances for the first time in the literature. Through a comprehensive series of experiments, we provide insights into the efficacy of different components of the proposed solution method.},
  archive      = {J_COR},
  author       = {Sara Charaf and Duygu Taş and Simme Douwe P. Flapper and Tom Van Woensel},
  doi          = {10.1016/j.cor.2024.106778},
  journal      = {Computers &amp; Operations Research},
  month        = {11},
  pages        = {106778},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic for the two-echelon inventory-routing problem},
  volume       = {171},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The hampered k-median problem with neighbourhoods.
<em>COR</em>, <em>170</em>, 106786. (<a
href="https://doi.org/10.1016/j.cor.2024.106786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with facility location problems in a continuous space with neighbours and barriers. Each one of these two elements, neighbours and barriers, makes the problems harder than their standard counterparts. Combining all together results in a new challenging problem that, as far as we know, has not been addressed before, but has applications for inspection and surveillance activities and the delivery industry assuming uniformly distributed demand in some regions. Specifically, we analyse the k k -Median problem with neighbours and polygonal barriers in two different situations. None of these problems can be seen as a simple incremental contribution since in both cases the tools required to analyse and solve them go beyond any standard overlapping of techniques used in the separated problems. As a first building block, we deal with the problem assuming that the neighbourhoods are not visible from one another and therefore there are no rectilinear paths that join two of them without crossing barriers. Under this hypothesis, we derive a valid mixed-integer linear formulation. Removing that hypothesis leads to a more general and realistic problem, but at the price of making it more challenging. Adapting the elements of the first formulation, we also develop another valid mixed-integer bilinear formulation. Both formulations rely on tools borrowed from computational geometry that allow to handle polygonal barriers and neighbours that are second-order cone (SOC) representable, which we preprocess and strengthen with valid inequalities. These mathematical programming formulations are also instrumental to derive an adapted matheuristic algorithm that provides good quality solutions for both problems in short computing time. The paper also reports extensive computational experience, counting 2400 experiments, showing that our exact and heuristic approaches are useful: the exact approach can solve optimally instances with up to 50 neighbourhoods and different number of barriers within one hour of CPU time, whereas the matheuristic approach always returns good feasible solutions in less than 300 s.},
  archive      = {J_COR},
  author       = {Justo Puerto and Carlos Valverde},
  doi          = {10.1016/j.cor.2024.106786},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106786},
  shortjournal = {Comput. Oper. Res.},
  title        = {The hampered k-median problem with neighbourhoods},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A path relinking with tabu search algorithm for solving
hybrid flow shop scheduling problem considering multiple critical paths.
<em>COR</em>, <em>170</em>, 106783. (<a
href="https://doi.org/10.1016/j.cor.2024.106783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling is a challenging problem due to its high complexity and widespread applications in industrial production systems. In this paper, we propose a hybrid method that integrates path relinking with tabu search (PRTS) to solve this problem with the objective of minimizing the makespan. PRTS utilizes permutation-based encoding to effectively find some promising areas. Subsequently, it transitions to complete encoding representation to guarantee the inclusion of all feasible semiactive schedules. Building upon this, the path relinking procedure helps to increase diversity and enhance global exploration, while tabu search contributes to local exploitation. Two effective neighborhood structures are modified by considering multiple critical paths, and a rapid evaluation method is designed. The proposed algorithm is tested on two benchmarks that comprise 250 instances and is compared to some state-of-the-art algorithms. The results demonstrate the superiority of PRTS over existing methods and provide new best solutions for 102 challenging instances.},
  archive      = {J_COR},
  author       = {Hao Zhou and Hui Liu and Chang Lv and Chaoyong Zhang and Weiming Shen},
  doi          = {10.1016/j.cor.2024.106783},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106783},
  shortjournal = {Comput. Oper. Res.},
  title        = {A path relinking with tabu search algorithm for solving hybrid flow shop scheduling problem considering multiple critical paths},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formulations and heuristic for the long-term preventive
maintenance order scheduling problem. <em>COR</em>, <em>170</em>,
106781. (<a href="https://doi.org/10.1016/j.cor.2024.106781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the long-term preventive maintenance order scheduling problem (LTPMOSP). The problem consists of deciding which maintenance should be scheduled, assigning each maintenance simultaneously to a team and a machine over the planning horizon, and determining when each maintenance should be performed. The goal of the problem is to minimize the number of teams activated and the sum of penalties for maintenance not scheduled. This paper presents two new formulations for the problem, where the first formulation is based on time-indexed variables, and the second formulation combines time-indexed variables with precedence variables. Furthermore, to solve large-size instances, an algorithm based on the GRASP metaheuristic is proposed. The results of the computational experiments show that the new formulations significantly outperform the literature formulation by finding new optimal solutions for some instances with up to 600 maintenance orders. The second formulation stands out by finding a more significant number of optimal solutions. The results also show a superiority of the GRASP algorithm over heuristic methods in the literature, generating better upper bounds in expressively less time, resulting in a schedule with a greater percentage of maintenance planned to be performed.},
  archive      = {J_COR},
  author       = {João Luiz Marques de Andrade and Marcone Jamilson Freitas Souza and Elisangela Martins de Sá and Gustavo Campos Menezes and Sérgio Ricardo de Souza},
  doi          = {10.1016/j.cor.2024.106781},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106781},
  shortjournal = {Comput. Oper. Res.},
  title        = {Formulations and heuristic for the long-term preventive maintenance order scheduling problem},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling jobs with shared additional operations on
parallel identical machines. <em>COR</em>, <em>170</em>, 106780. (<a
href="https://doi.org/10.1016/j.cor.2024.106780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is concerned with assigning jobs, each with associated additional operations, to identical machines. A machine, allocated to a job, must also process all the additional operations associated with this job. An additional operation that is associated with several jobs assigned to the same machine needs to be processed by this machine only once. The goal is to minimise the time needed for the completion of all jobs and their additional operations. It is shown that even very restricted particular cases of the considered problem remain NP-hard in the strong sense. For the general case, the paper introduces two mixed integer linear programs as well as a broad class of approximation algorithms and a performance guarantee that is valid for any algorithm in this class. It is shown that, for one of the above-mentioned NP-hard particular cases, the considered class contains the best possible approximation algorithm. The performance of the mixed integer linear programs and several approximation algorithms is compared by means of computational experiments.},
  archive      = {J_COR},
  author       = {Yakov Zinder and Joanna Berlińska and Bertrand M.T. Lin},
  doi          = {10.1016/j.cor.2024.106780},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106780},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling jobs with shared additional operations on parallel identical machines},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-efficient scheduling in an identical parallel machine
environment with peak power consumption and deadline constraints.
<em>COR</em>, <em>170</em>, 106777. (<a
href="https://doi.org/10.1016/j.cor.2024.106777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-efficient scheduling is an essential means of achieving sustainability in manufacturing systems. This paper defines and addresses the problem of scheduling n n jobs on m m identical parallel machines in which peak power consumption and deadline constraints exist simultaneously. The objective is to maximize the total value of the selected jobs. We show that this problem is equivalent to a special case of the rectangular knapsack problem, based on which four properties are observed. To solve the problem, an effective mixed integer linear programming model is proposed based on the properties, and it is much more efficient compared to the performance of modeling methods inspired by other works. Furthermore, three effective decoding methods are proposed and embedded into genetic algorithms (GAs). Comparisons with the exact algorithm (i.e., the proposed model) show that our GAs can lead to good-quality solutions within one second for small instances. Meanwhile, experimental results for large instances indicate that the proposed GAs can obtain near-optimal or satisfactory solutions. Finally, results also show that the proposed GA-DD significantly outperforms the existing matheuristic algorithm.},
  archive      = {J_COR},
  author       = {XiYing Li and ChenGuang Liu},
  doi          = {10.1016/j.cor.2024.106777},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106777},
  shortjournal = {Comput. Oper. Res.},
  title        = {Energy-efficient scheduling in an identical parallel machine environment with peak power consumption and deadline constraints},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributionally robust approach for the parallel machine
scheduling problem with optional machines and job tardiness.
<em>COR</em>, <em>170</em>, 106776. (<a
href="https://doi.org/10.1016/j.cor.2024.106776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a parallel machine scheduling problem with uncertain job processing time, where the job tardiness and optional machines are considered. To address the factor of energy saving, only a subset of all available machines are turned on, which is referred to as not-all-machine (NAM). To depict the uncertain processing time, a mean–mean absolute deviation (MAD) ambiguity set is utilized, and the cost of job tardiness is minimized under the worst-case distribution scenario over the ambiguity set. After building a distributionally robust optimization (DRO) model, theoretical bounds of the optimal number of machines are obtained. Since the model is not computationally scalable, an upper bound on its inner minimization problem is employed, and a mixed integer linear programming (MILP) approximation is obtained based on McCormick inequalities. For the DRO model, tailored speedup techniques are employed, significantly enhancing the computational performance. To evaluate the validity of the proposed DRO model, we compare it with its stochastic programming (SP) counterpart under various parameter settings. Numerical experiments demonstrate that the DRO model exhibits strong performance in the worst-case scenarios. As the problem size increases, the DRO model casts clear advantages over the SP model in terms of computational efficiency and reliability. It is observed that the performance of the DRO model is more stable than that of the nominal sequence, especially with loose due dates. Furthermore, the out-of-sample performance under various decision making preferences shed new lights into the trade-off between energy saving and production efficiency.},
  archive      = {J_COR},
  author       = {Haimin Lu and Ye Shi and Zhi Pei},
  doi          = {10.1016/j.cor.2024.106776},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106776},
  shortjournal = {Comput. Oper. Res.},
  title        = {A distributionally robust approach for the parallel machine scheduling problem with optional machines and job tardiness},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). VNSMAS: A constraint-based portfolio profit maximization.
<em>COR</em>, <em>170</em>, 106769. (<a
href="https://doi.org/10.1016/j.cor.2024.106769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock trading has a more significant influence on the global economy. Stock trading with portfolio optimization became challenging due to the complexity of analyzing the high variance in time series stock data. Efficient portfolio management increases profit and avoids risky situations when investing. The present work aims to model a Variable Neighborhood Search Multi-Agent System for Portfolio Optimization (VNSMASPPO) to optimize the profit on defined trading constraints on buying, selling, and holding trading decisions. This work proposes a novel Variable Neighborhood Search-based Multi-Agent System (VNASMAS) algorithm for profit computation with a constraint-based multi-agent system. The stock price history experimental data sets are collected from 8th August 2016 to 31st March 2023 with 14,567 records. The proposed model achieved an RMSE of 10.11, MAE of 2.75, and MAPE of 0.017, outperforming the literature models. VNSMASPPO maximizes the portfolio profit and is a reliable, adaptable approach.},
  archive      = {J_COR},
  author       = {Usha Devi N.S.S.S.N. and R. Mohan},
  doi          = {10.1016/j.cor.2024.106769},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106769},
  shortjournal = {Comput. Oper. Res.},
  title        = {VNSMAS: A constraint-based portfolio profit maximization},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-layer heuristic for patient sequencing in the
operating room theatre considering multiple resource phases.
<em>COR</em>, <em>170</em>, 106768. (<a
href="https://doi.org/10.1016/j.cor.2024.106768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the surgery scheduling problem in the operating room theatre. The problem considers the sequencing of patients and calculation of their start times with splitting of surgeries into resource phases to facilitate the efficient use of different types of resources. We propose a dedicated two-layer heuristic to compose an operational patient and resource schedule. The first optimisation layer applies an evolutionary heuristic to devise patient schedules while considering the scheduling of the operating surgeons and rooms. This step employs a machine-learning mechanism predicting the feasibility of chromosomes, which improves the algorithm’s efficiency and effectiveness, and relies on novel local search operators to find high-quality solutions. The second layer devises the schedule of the other resources using a decomposition-based heuristic. Computational experiments are conducted to show the performance of the proposed two-layer heuristic and validate its design choices. We benchmark the proposed algorithm with other optimisation procedures and show the contribution of considering multiple resource phases for real-life decision-making.},
  archive      = {J_COR},
  author       = {Babak Akbarzadeh and Broos Maenhout},
  doi          = {10.1016/j.cor.2024.106768},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106768},
  shortjournal = {Comput. Oper. Res.},
  title        = {A two-layer heuristic for patient sequencing in the operating room theatre considering multiple resource phases},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributionally robust optimization model for
inventory-transportation integrated optimization problem of petroleum
products under uncertainty. <em>COR</em>, <em>170</em>, 106767. (<a
href="https://doi.org/10.1016/j.cor.2024.106767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the downstream supply chain of petroleum products, the logistics planning optimization is a crucial issue that not only involves the inventory management of oil depots to stabilize market supply, but also needs to take transportation into account and develop a reasonable resource allocation plan associated with replenishment costs. However, the fluctuation of market sales makes oil product outbound volumes full of uncertainty, which also increases the challenge and difficulty of planning optimization. Therefore, this paper investigates the inventory-transportation integrated optimization problem of petroleum products, proposes a novel distributionally robust optimization (DRO) modeling method aiming at a solution scheme addressing the uncertainty in real business. Firstly, considering the uncertainty of random variable distribution, an ambiguity set is confirmed based on the maximum mean discrepancy (MMD) metric. Subsequently, a MMD-DRO model is combined and transformed into an equivalent and solvable mixed-integer linear programming model. Futhermore, with regard to the deficiency of solvers in handling large-scale regional problems, a logic-based Benders decomposition (LBBD) algorithm is designed and enhanced by heuristic strategies. Finally, with the cases from PetroChina, the efficacy and applicability of the proposed approach are validated, and demonstrated the superior performance of the improved LBBD algorithm.},
  archive      = {J_COR},
  author       = {Xiaofeng Xu and Zhiang Chen and Yuheng Song and Wanli Yi},
  doi          = {10.1016/j.cor.2024.106767},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106767},
  shortjournal = {Comput. Oper. Res.},
  title        = {A distributionally robust optimization model for inventory-transportation integrated optimization problem of petroleum products under uncertainty},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Managing ESG ratings disagreement in sustainable portfolio
selection. <em>COR</em>, <em>170</em>, 106766. (<a
href="https://doi.org/10.1016/j.cor.2024.106766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In sustainable portfolio selection, investors have a twofold objective: they want to achieve the best compromise between portfolio risk and return, but they also want to take into account the sustainability of their investment, assessed through some Environmental, Social, and Governance (ESG) evaluation criteria. The inclusion of sustainable goals in the portfolio selection process may have an impact on the portfolio financial performance. ESG scores provided by the rating agencies are generally considered good proxies for the sustainability performance of an investment, as well as appropriate measures for Socially Responsible Investments (SRI). In this framework, the lack of alignment between ratings provided by different agencies is a crucial issue that inevitably undermines the robustness and reliability of these evaluation measures. In fact, the ESG rating disagreement may produce conflicting information, implying difficulty for the investors in the ESG evaluation of their portfolios. This may cause underestimation or overestimation of the market opportunities for a sustainable investment. In this paper, we deal with a multi-criteria portfolio selection problem, taking into account risk, return, and ESG criteria. For the ESG evaluation of the securities, we consider more than one agency and propose a new approach to overcome the problem related to the disagreement between the ESG ratings given by different agencies. For our three-criteria portfolio selection problem, we present an optimization model which adopts the so-called k− sum operator to formulate a concise ESG evaluation measure. The natural formulation of the model, in which the portfolio risk is measured by the variance of its returns, leads to a nonlinear program, but we show that it can be reformulated as an equivalent convex quadratic model. We also show that the model can be generalized to include any convex portfolio risk measures. An extensive empirical analysis of the out-of-sample performance of this model is provided on real-world financial data sets. From a theoretical viewpoint, our work extends the use of k− sum methodology to quadratic programming.},
  archive      = {J_COR},
  author       = {Francesco Cesarone and Manuel Luis Martino and Federica Ricca and Andrea Scozzari},
  doi          = {10.1016/j.cor.2024.106766},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106766},
  shortjournal = {Comput. Oper. Res.},
  title        = {Managing ESG ratings disagreement in sustainable portfolio selection},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unmanned aerial vehicle variable radius set covering problem
for emergency wireless network. <em>COR</em>, <em>170</em>, 106765. (<a
href="https://doi.org/10.1016/j.cor.2024.106765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of unmanned aerial vehicles (UAVs) has garnered increasing interest across various disciplines. The idea of smart cities led to the exploration of using UAVs in the public service industry, with a focus on integrating all aspects of the system through information and physical items. In this paper, we introduce and model the operational problem of using UAVs to construct an emergency wireless network in a disaster situation using the set covering approach. Unique to our study is the consideration that UAVs do not require predetermined positioning or altitude specifications. Consequently, the problem described in this paper can be classified as a planar variable radius covering problem , which involves a nonconvex continuous relaxation feasible set. We introduce the application of the Dantzig–Wolfe decomposition alongside a branch-and-price algorithm to tackle this problem. Additionally, the pricing subproblem’s solvable equivalent formulation is ingeniously derived from existing theories on the minimum covering circle. For large-scale instances, we propose a heuristic derived from an extended formulation. Comparative computational experiments demonstrate that our proposed algorithms significantly surpass the efficiency of the benchmark genetic algorithm previously reported in the literature.},
  archive      = {J_COR},
  author       = {Youngsoo Park and Chang Seong Ko and Ilkyeong Moon},
  doi          = {10.1016/j.cor.2024.106765},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106765},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unmanned aerial vehicle variable radius set covering problem for emergency wireless network},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-warehouse inventory model under hybrid-price-stock
dependent demand and a bulk release pattern. <em>COR</em>, <em>170</em>,
106764. (<a href="https://doi.org/10.1016/j.cor.2024.106764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In retailing, sales may determinatively depend on both selling price and how much stock is displayed before customers. However, when high logistics costs are incurred at the point of sale, nearby rented warehouses may be arranged as an economic stock point in-between, and partially in lieu of, external orders. Likewise, a simplified ordering process can be attained via modular logistics, a practice considered in different competitive markets. The objective of the present paper is to develop a deterministic modular replenishment model with multiple warehouses (an own warehouse, OW, and rented warehouses, RW, of custom capacities), assuming price- and stock-dependent demand, and a bulk release pattern. The global optimal selling price, order-up-to level, reorder level, and the number and capacity of warehouses conducive to profit maximisation are then determined. To this end, theoretical research in extension of multi-warehouse and hybrid-price-stock dependent demand inventory models is conducted together with computer-assisted numerical studies. Findings show that 1) optimal selling price and displayed stock level may increase with market size, 2) displayed-stock demand elasticity can improve market efficiency, 3) partial use of existing fixed OW capacity may prove optimal as demand decreases, 4) successive RWs may increase profit, yet at a decreasing rate, 5) joint warehouse/price optimisation can be most profitable as demand decreases. From the above, it follows that modular downstream warehousing, jointly with displayed stock-based marketing practices, may constitute an effective tool toward industry profitability and supply–demand alignment, specially during contractionary periods, where price-reducing regulatory efforts may, in turn, become partly dispensable.},
  archive      = {J_COR},
  author       = {Jaime Rodríguez-Mazo and Rocío Ruiz-Benítez},
  doi          = {10.1016/j.cor.2024.106764},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106764},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-warehouse inventory model under hybrid-price-stock dependent demand and a bulk release pattern},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling and solving framework for tactical maintenance
planning problems with health index considerations. <em>COR</em>,
<em>170</em>, 106763. (<a
href="https://doi.org/10.1016/j.cor.2024.106763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintenance planning is one of the main challenges of the management of production systems. Thanks to recent technological innovations and the development of sensors, it is possible to construct degradation models of equipment condition, thus providing an assessment of the equipment health modeled by a health index indicator. In this work, we present an original tactical maintenance planning problem involving a Health Index indicator on the components of the equipment. Within this framework, maintenance can be seen as a form of delayed production. This observation allows us to derive an original lot-sizing based approach for our tactical maintenance planning problem. Aside from the classical cost minimization objective, the problem also involves a resource consumption objective to be minimized. The problem is proven to be strongly NP-hard in the general case, and a bi-objective Mixed Integer Linear Program is proposed. Then, two matheuristics are defined. A degradation matheuristic allowing several degradations of the objective functions and a Pareto-based matheuristic selecting solution of good quality from a restricted pareto front.},
  archive      = {J_COR},
  author       = {Ernest Foussard and Margaux Nattaf and Marie-Laure Espinouse and Grégory Mounié},
  doi          = {10.1016/j.cor.2024.106763},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106763},
  shortjournal = {Comput. Oper. Res.},
  title        = {Modeling and solving framework for tactical maintenance planning problems with health index considerations},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating order picking and vehicle routing decisions in a
dynamic e-commerce setting. <em>COR</em>, <em>170</em>, 106762. (<a
href="https://doi.org/10.1016/j.cor.2024.106762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Responding to e-commerce orders as quickly as possible is indispensable for companies competing in the current retailing landscape. After a customer orders online, the requested items should be picked in the warehouse and delivered to the customer’s location. Previous research showed the benefits of integrating the order picking and vehicle routing decisions in a static context. To achieve shorter customer response times, we propose multiple new algorithms in this study, able to handle the integrated problem of picking and delivery in a setting with dynamic order arrivals and considering more complex picking policies. We develop and implement four online large neighbourhood search algorithms, differing in their degree of integration between picking and routing decisions. The algorithms are tested on different operational settings. Differences between the algorithms and the impact of the operating context are analysed by use of an ANOVA. The results highlight the importance of integrated decision-making, as well as the large impact of the operating context on the operational efficiency. Furthermore, we demonstrate the environmental impact of stringent customer requests. These insights can be used by companies to optimise their operations.},
  archive      = {J_COR},
  author       = {Ruben D’Haen and Katrien Ramaekers and Claudia Archetti and Kris Braekers},
  doi          = {10.1016/j.cor.2024.106762},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106762},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integrating order picking and vehicle routing decisions in a dynamic e-commerce setting},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact algorithm for simultaneous pickup and delivery
problem with split demand and time windows. <em>COR</em>, <em>170</em>,
106761. (<a href="https://doi.org/10.1016/j.cor.2024.106761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a new variant of the vehicle routing problem (VRP) called the simultaneous pickup and delivery problem with split demand and time windows (SPDP-SDTW). The motivation behind this study stems from real-life urban and rural delivery scenarios, encompassing features such as split demand, simultaneous pickup and delivery, many-to-many pickup and delivery, and time windows. The study thoroughly investigates the properties of the optimal solution for the SPDP-SDTW. Based on these properties, an arc flow model is developed for the SPDP-SDTW. Dantzig Wolfe (DW) decomposition techniques are employed to obtain the master problem and the pricing subproblem. In order to effectively address the SPDP-SDTW, an improved branch and price (I-BP) algorithm is proposed, incorporating a tailored column generation (CG) algorithm, branching strategies, and dual stabilization strategies. The proposed CG algorithm provides a framework that combines the improved adaptive degree heuristic (I-AGH) algorithm and the solver Gurobi. This integration substantially mitigates the computational burden involved in solving the subproblem. Extensive computational experiments conducted on datasets of varying sizes, including small, medium, and large instances, consistently demonstrate that the I-BP algorithm performs the best in both solution quality and computational efficiency when compared to existing exact and heuristic algorithms.},
  archive      = {J_COR},
  author       = {Ziqiang Zhu and Yanru Chen and M.I.M. Wahab},
  doi          = {10.1016/j.cor.2024.106761},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106761},
  shortjournal = {Comput. Oper. Res.},
  title        = {An exact algorithm for simultaneous pickup and delivery problem with split demand and time windows},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the online on-demand warehousing problem.
<em>COR</em>, <em>170</em>, 106760. (<a
href="https://doi.org/10.1016/j.cor.2024.106760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In On-Demand Warehousing, an online platform acts as a central mechanism to match unused storage space and related services offered by suppliers to customers. Storage requests can be for small capacities and very short commitment periods if compared to traditional leasing models. The objective of the On-Demand Warehousing Problem (ODWP) is to maximize the number of successful transactions among the collected offers and requests, considering the satisfaction of both the supply and demand side to preserve future participation to the platform. The Online ODWP can be modeled as a stochastic reservation and assignment problem, where dynamically arriving requests of customers must be rapidly assigned to suppliers. Firstly, an online stochastic combinatorial optimization framework is adapted to the Online ODWP. The key idea of this approach is to generate samples of future requests by evaluating possible allocations for the current request against these samples. In addition, expectation, consensus, and regret, and two greedy algorithms are implemented. All solution methods are compared on a dataset of realistic instances of different sizes and features, demonstrating their effectiveness compared to the oracle solutions, which are based on the assumption of perfect information about future request arrivals. A newly proposed approach of risk approximation is shown to outperform alternative algorithms on large instances. Managerial insights regarding acceptance and rejection strategies for the platform are derived. It is shown how requests with large demand, long time frame, not very long spanning time, and average compatibility degree, are very likely to be rejected in the optimal solution.},
  archive      = {J_COR},
  author       = {Sara Ceschia and Margaretha Gansterer and Simona Mancini and Antonella Meneghetti},
  doi          = {10.1016/j.cor.2024.106760},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106760},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving the online on-demand warehousing problem},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Lower bounds for minimizing two types of unnecessary costs
in the film and television industry. <em>COR</em>, <em>170</em>, 106759.
(<a href="https://doi.org/10.1016/j.cor.2024.106759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To optimize film and television production costs, we aim to minimize unnecessary expenditures such as the idle time of top-paid actors and the rental periods of expensive equipment. By scheduling scenes that require these resources on consecutive days, significant cost reductions are achieved. In this study, a branch-and-bound algorithm with two lower bounds has been developed to serve as a benchmark for evaluating other metaheuristic algorithms. The novelty of these lower bounds stems from their set-based operations, which avoid time-consuming computations involving large sparse matrixes. The computational results confirm that the proposed lower bounds effectively reduce these costs. Clearly, this approach can be extended to other industries with similarly complex job compositions, such as scenarios involving multiple small tasks in a single job.},
  archive      = {J_COR},
  author       = {Lie-Fen Lin and Jen-Ya Wang},
  doi          = {10.1016/j.cor.2024.106759},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106759},
  shortjournal = {Comput. Oper. Res.},
  title        = {Lower bounds for minimizing two types of unnecessary costs in the film and television industry},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reinforcement learning guided hybrid evolutionary
algorithm for the latency location routing problem. <em>COR</em>,
<em>170</em>, 106758. (<a
href="https://doi.org/10.1016/j.cor.2024.106758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The latency location routing problem integrates the facility location problem and the multi-depot cumulative capacitated vehicle routing problem. This problem involves making simultaneous decisions about depot locations and vehicle routes to serve customers while aiming to minimize the sum of waiting (arriving) times for all customers. To address this computationally challenging problem, we propose a reinforcement learning guided hybrid evolutionary algorithm following the framework of the memetic algorithm. The proposed algorithm relies on a diversity-enhanced multi-parent edge assembly crossover to build promising offspring and a reinforcement learning guided variable neighborhood descent to determine the exploration order of multiple neighborhoods. Additionally, strategic oscillation is used to achieve a balanced exploration of both feasible and infeasible solutions. The competitiveness of the algorithm against state-of-the-art methods is demonstrated by experimental results on the three sets of 76 popular instances, including 51 improved best solutions (new upper bounds) for the 59 instances with unknown optima and equal best results for the remaining instances. We also conduct additional experiments to shed light on the key components of the algorithm.},
  archive      = {J_COR},
  author       = {Yuji Zou and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1016/j.cor.2024.106758},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106758},
  shortjournal = {Comput. Oper. Res.},
  title        = {A reinforcement learning guided hybrid evolutionary algorithm for the latency location routing problem},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive variable neighborhood search algorithm with
metropolis rule and tabu list for satellite range scheduling problem.
<em>COR</em>, <em>170</em>, 106757. (<a
href="https://doi.org/10.1016/j.cor.2024.106757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient scheduling of measurement and control resources plays a critical role in successful satellite operations. The tremendous growth in the number of satellites in orbit exacerbates resource scarcity, further enhancing the significance of the satellite range scheduling problem (SRSP). In order to maximize the benefits of measurement and control tasks, we propose an innovative algorithm to solve the SRSP with numerous constraints. Firstly, the SRSP operation flow is analyzed to establish a constraint satisfaction model. A task-resource matching algorithm based on fitness is then designed to generate an initial feasible solution with superior quality by heuristic criteria. Subsequently, an adaptive variable neighborhood search algorithm with Metropolis rule and tabu list (AVNS-MT) is proposed to solve the mathematical model. Three swap neighborhood structures are constructed to explore the solution space efficiently during the variable neighborhood descent search process. Meanwhile, three migration neighborhood structures are devised to enable the shaking of solutions and evasion from the local optimum. Moreover, the incorporation of the Metropolis rule and tabu search strategy will contribute to enhancing the algorithm convergence. Finally, we have conducted extensive simulations to verify the effectiveness and efficiency of the proposed AVNS-MT. Comparison experiments with several state-of-the-art methods validate the superiority of the proposed algorithm.},
  archive      = {J_COR},
  author       = {Tianyu Wang and Yi Gu and Huilin Wang and Guohua Wu},
  doi          = {10.1016/j.cor.2024.106757},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106757},
  shortjournal = {Comput. Oper. Res.},
  title        = {Adaptive variable neighborhood search algorithm with metropolis rule and tabu list for satellite range scheduling problem},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient probability-based VNS algorithm for delivery
territory design. <em>COR</em>, <em>170</em>, 106756. (<a
href="https://doi.org/10.1016/j.cor.2024.106756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the Delivery Territory Design Problem (DTDP), a districting problem that often occurs in delivery operations. The goal of the problem is to construct clusters of nodes (territories) such that the maximum diameter of a territory is minimized, while the territories designed are balanced w.r.t. some performance measures. We propose to solve the DTDP using a Probabilistic Variable Neighborhood Search (ProbVNS) algorithm based on two local search procedures: a tailored randomized shake procedure that targets both a reduction of infeasibility and diversification, and a deterministic local search based on a linear combination of objective and constraint violation. In addition to searching in different neighborhoods, the ProbVNS also changes the search direction by exploring different penalties for violating constraints. Numerical experiments show that ProbVNS outperforms a recent GRASP with the Path-Relinking (PR) algorithm proposed in the literature in terms of feasibility and objective value. In the tested instances, ProbVNS obtained a lower infeasibility measure in 90% of the instances. For these instances, the average decrease in the objective value was 8.3%, with a maximum decrease of 51%. Finally, the running times of ProbVNS are, on average, 2.7 times lower than those of PR.},
  archive      = {J_COR},
  author       = {Ahmed Aly and Adriana F. Gabor and Nenad Mladenovic and Andrei Sleptchenko},
  doi          = {10.1016/j.cor.2024.106756},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106756},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient probability-based VNS algorithm for delivery territory design},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributionally robust chance-constrained kernel-based
support vector machine. <em>COR</em>, <em>170</em>, 106755. (<a
href="https://doi.org/10.1016/j.cor.2024.106755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is a powerful model for supervised learning. This article addresses the nonlinear binary classification problem using kernel-based SVM with uncertainty involved in the input data specified by the first- and second-order moments. To achieve a robust classifier with small probabilities of misclassification, we investigate a distributionally robust chance-constrained kernel-based SVM model. Since the moment information in the original problem becomes unclear/unavailable in the feature space via kernel transformation, we develop a data-driven approach utilizing empirical moments to provide a second-order cone programming (SOCP) reformulation for efficient computation. To speed up the required computations for solving large-size problems in higher dimensional space and/or with more sampling points involved in estimating empirical moments, we further design an alternating direction multipliers-based algorithm for fast computations. Extensive computational results support the effectiveness and efficiency of the proposed model and solution method. Results on public benchmark datasets without any moment information indicate that the proposed approach still works and, surprisingly, outperforms some commonly used state-of-the-art kernel-based SVM models.},
  archive      = {J_COR},
  author       = {Fengming Lin and Shu-Cherng Fang and Xiaolei Fang and Zheming Gao},
  doi          = {10.1016/j.cor.2024.106755},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106755},
  shortjournal = {Comput. Oper. Res.},
  title        = {Distributionally robust chance-constrained kernel-based support vector machine},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Epsilon oscillation algorithm for the bi-objective green
identical parallel machine scheduling problem. <em>COR</em>,
<em>170</em>, 106754. (<a
href="https://doi.org/10.1016/j.cor.2024.106754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the bi-objective optimization problem of scheduling jobs on multiple identical parallel machines to minimize both makespan and total energy consumption. The problem can be denoted as P m , T O U ∣ ∣ C m a x , T E C Pm,TOU∣∣Cmax,TEC . A Pipe Variable Neighborhood Descent approach with Dynamic Programming, employing an Epsilon Constraint method and incorporating an Epsilon Oscillation technique that consists of alternating between ascending and descending ways to vary the epsilon value. This technique improves the pareto front by exploring new search space. A comparison is provided between the proposed Epsilon Oscillation Algorithm (EOA) and the state-of-the-art solving techniques. The experimental results as well as the statistical tests show the significant superiority of the EOA, motivating its adaptation to solve other bi-objective scheduling problems.},
  archive      = {J_COR},
  author       = {Bassem Jarboui and Malek Masmoudi and Mansour Eddaly},
  doi          = {10.1016/j.cor.2024.106754},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106754},
  shortjournal = {Comput. Oper. Res.},
  title        = {Epsilon oscillation algorithm for the bi-objective green identical parallel machine scheduling problem},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning tabu search algorithms: A scheduling application.
<em>COR</em>, <em>170</em>, 106751. (<a
href="https://doi.org/10.1016/j.cor.2024.106751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics provide efficient approaches for many combinatorial problems. Research focused on improving the performance of metaheuristics has increasingly relied on either combining different metaheuristics, or leveraging methods that originate outside the field of metaheuristics. This paper presents a learning algorithm for improving tabu search by reducing its search space and evaluation effort. The learning tabu search algorithm uses classification methods in order to better motivate moves through the search space. The learning tabu search is compared to an enhanced version of tabu search that includes diversification, intensification and three neighborhoods in a physician scheduling application. We use the deterministic case to test the design of the algorithm (features and parameters) and as a proof of concept. We then solve the stochastic version of the problem. The experimental results demonstrate the benefit of using a learning mechanism under stochastic conditions.},
  archive      = {J_COR},
  author       = {Nazgol Niroumandrad and Nadia Lahrichi and Andrea Lodi},
  doi          = {10.1016/j.cor.2024.106751},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106751},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning tabu search algorithms: A scheduling application},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-price-and-cut algorithm for the home health
care routing and scheduling problem with multiple prioritized time
windows. <em>COR</em>, <em>170</em>, 106749. (<a
href="https://doi.org/10.1016/j.cor.2024.106749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a variant of home health care routing and scheduling problem with endogenous time window options for patients. The objective is to minimize the total operational cost while ensuring a specified level of service satisfaction regarding patients’ prioritized time windows. We formulate the problem as a set-covering model and propose a branch-and-price-and-cut (BPC) algorithm to tackle it. Specifically, we devise a column generation procedure to obtain the lower bounds in the branch-and-bound framework, in which we employ a labeling algorithm with a multiple time windows processing mechanism to deal with the pricing sub-problems. Additionally, the lower bound is strengthened by incorporating 2-path inequalities and subset-row inequalities. The effectiveness of the BPC algorithm is demonstrated through numerical experiments conducted on the modified Solomon benchmark instances. Furthermore, we analyze the problem and derive the following managerial insights: i) Incorporating the assignment decisions of time windows for patients into the problem can significantly reduce nurse costs and travel costs, even when accounting for patients’ preferences for time windows. ii) There is a negative correlation between cost savings and the overall satisfaction levels of patients’ preferred time windows, with marginal cost savings decreasing as the overall satisfaction level declines. iii) Besides the total satisfaction level, the operational cost is also influenced by factors such as the distribution of patient locations, the width of time windows, and the proportion of patients with multiple time windows.},
  archive      = {J_COR},
  author       = {Juan Du and Xiuli Wang},
  doi          = {10.1016/j.cor.2024.106749},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106749},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-price-and-cut algorithm for the home health care routing and scheduling problem with multiple prioritized time windows},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Applying instance space analysis for metaheuristic
selection to the 0–1 multidemand multidimensional knapsack problem.
<em>COR</em>, <em>170</em>, 106747. (<a
href="https://doi.org/10.1016/j.cor.2024.106747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The empirical testing of metaheuristic solution methods for optimization applications should consider the effect of the underlying structure of the optimization problem test instances employed. This paper presents a methodology for analyzing the performance of metaheuristics applied to the 0–1 multidemand multidimensional knapsack problem (MDMKP) specifically considering problem structure. This research leverages instance space analysis (ISA) to graphically depict both the multidimensional problem structure and metaheuristic performance. A new instance generation method augments the existing set of test instances; in doing so, it introduces correlation structure into the problem and helps ensure MDMKP instance feasibility. Testing compares four metaheuristics from the literature and trains an interpretable machine learning model to select a metaheuristic for a given instance based on that problem’s meta-features. The results show that the correlation structure meta-features are significant factors affecting metaheuristic performance and that a decision tree model can provide interpretable insights into the algorithm selection problem. This work demonstrates the usefulness of ISA for rigorous empirical testing to enhance understanding the performance of metaheuristics applied to the MDMKP.},
  archive      = {J_COR},
  author       = {Matthew E. Scherer and Raymond R. Hill and Brian J. Lunday and Bruce A. Cox and Edward D. White},
  doi          = {10.1016/j.cor.2024.106747},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106747},
  shortjournal = {Comput. Oper. Res.},
  title        = {Applying instance space analysis for metaheuristic selection to the 0–1 multidemand multidimensional knapsack problem},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Effective heuristics for permutation and non-permutation
flow shop scheduling with missing operations. <em>COR</em>,
<em>170</em>, 106742. (<a
href="https://doi.org/10.1016/j.cor.2024.106742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, thanks to the fourth industrial revolution, there have been significant increases in the flexibility and agility of industrial processes. In this way, business models based on mass customization of production have gained presence in the industry. In terms of production scheduling in flow shop systems, customization affects production operations, in many cases giving rise to the problem of missing operations, that is, there are jobs that do not perform all operations. Modeling missing operations as zero-time operations, allows to find schedules, but wastes efficiency since zero-time operations lead to unnecessary waiting times. In this paper, we demonstrate that even in permutation flow shops treating missing operations as zero-time operations can make the makespan or the total flow time of optimal schedules arbitrarily worse. We show that a promising way to address missing operations is to consider limited non-permutation solutions over the sub-jobs of a job composed of regular operations. We introduce an efficient representation for such schedules and propose algorithms that allow to solve the problem based on iterated greedy methods. The computational results show that the proposed algorithms are superior to the state-of-the-art algorithms.},
  archive      = {J_COR},
  author       = {Marcus Ritt and Daniel Alejandro Rossit},
  doi          = {10.1016/j.cor.2024.106742},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106742},
  shortjournal = {Comput. Oper. Res.},
  title        = {Effective heuristics for permutation and non-permutation flow shop scheduling with missing operations},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-aware flow shop scheduling with uncertain renewable
energy. <em>COR</em>, <em>170</em>, 106741. (<a
href="https://doi.org/10.1016/j.cor.2024.106741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an energy-aware flow shop scheduling problem with on-site renewable and grid energy resources. To deal with the uncertainty of renewable energy resources, we first develop two two-stage stochastic programming formulations based on pulse and step models to minimize the total energy cost purchased from the grid. Next, we develop two robust models where in the first one we assume the cost of buying energy from the grid is limited to a given budget and we aim to maximize the number of scenarios that comply with this limitation. In the second robust model, we aim to minimize the grid energy cost by considering a predetermined confidence level. To solve the stochastic and robust models, we develop Benders decomposition algorithms and incorporate the warm-up technique for Benders algorithm. Computational experiments on randomly generated test instances demonstrate that the step formulation outperforms the pulse formulation for larger instances. Additionally, each developed Benders decomposition algorithm outperforms its corresponding model, and the warm-up technique improves the performance of the Benders decomposition algorithms.},
  archive      = {J_COR},
  author       = {Masoumeh Ghorbanzadeh and Morteza Davari and Mohammad Ranjbar},
  doi          = {10.1016/j.cor.2024.106741},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106741},
  shortjournal = {Comput. Oper. Res.},
  title        = {Energy-aware flow shop scheduling with uncertain renewable energy},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic capacity allotment planning for airlines via travel
agencies. <em>COR</em>, <em>170</em>, 106740. (<a
href="https://doi.org/10.1016/j.cor.2024.106740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the dynamic capacity allocation problem of an airline using allotment contracts among travel agencies. The capacity allocation problem is formulated as a dynamic programming model where the initial fixed allotment is determined on the basis of a contract between agencies and the airline while the variable allotment is distributed over the planning horizon. We develop approximation methods based on linear programming and Lagrangian relaxation to solve the underlying dynamic programming model. The computational experiments are designed to illustrate the performance of the proposed approaches using real data. The numerical results show that the capacity allotment policy in terms of fixed and variable allotments is significantly affected by price and demand patterns. Even though fixed allotments can provide a cushion against the loss due to potential empty seats, they may not be in the best interest of the airline. Moreover, the booking rules and the airline’s capacity allocation strategy have an impact on the airline’s revenue and the agency’s profit.},
  archive      = {J_COR},
  author       = {Nurşen Aydın and Nalan Gülpınar and Yijun Zheng},
  doi          = {10.1016/j.cor.2024.106740},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106740},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic capacity allotment planning for airlines via travel agencies},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved ALNS for hybrid pickup and drones delivery
system in disaster by penalizing deprivation time. <em>COR</em>,
<em>170</em>, 106722. (<a
href="https://doi.org/10.1016/j.cor.2024.106722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanitarian logistics aims to reduce the time relief goods and services take to reach affected areas; deprivation time is one of the most significant factors in such conditions. Thus, utilizing a suitable transport fleet, including modern vehicles like drones, is essential. This paper introduces a new hybrid vehicle routing problem with pickup and delivery services, minimizing deprivation costs with multiple trucks and drones in a disaster. The model is presented as a mixed-integer linear programming problem focusing on minimizing deprivation cost in post-disaster situations through proper routing and inventory decisions made by heterogeneous vehicles. The deprivation time is divided into three main categories based on the arrival time of relief goods to affected areas and will be served by multiple relief goods. Due to the complexity of the problem, an improved adaptive large neighborhood search (ALNS) metaheuristic has been developed. This algorithm employs a heuristic algorithm to generate high-quality initial solutions and improve solutions with 17 destroy and repair operators. The algorithm was tested on a large-scale dataset based on real-world data from a crisis such as the Tehran earthquake, and the results demonstrate its superiority in providing better-quality solutions and lower solution time.},
  archive      = {J_COR},
  author       = {Sanaz Khalaj Rahimi and Donya Rahmani},
  doi          = {10.1016/j.cor.2024.106722},
  journal      = {Computers &amp; Operations Research},
  month        = {10},
  pages        = {106722},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved ALNS for hybrid pickup and drones delivery system in disaster by penalizing deprivation time},
  volume       = {170},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic resource leveling in projects with flexible
structures. <em>COR</em>, <em>169</em>, 106753. (<a
href="https://doi.org/10.1016/j.cor.2024.106753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In project management, efficient utilization of resources plays a key role in project success, and resource leveling is an effective technique to optimize resource usage. During project execution, there are often uncertainties that complicate resource leveling. Furthermore, existing research on resource leveling typically assumes a fixed project structure. However, this is not always the case in practice, because there may be a variety of optional technical solutions for some activities, leading to a flexible project structure. Therefore, considering both stochastic activity durations and flexible project structures, we propose and study the stochastic resource leveling problem with flexible project structures (SRLP-PS). The solution of the SRLP-PS is in the form of a scheduling policy. We design two algorithms for solving the NP-hard SRLP-PS: (a) an exact algorithm based on stochastic programming, in which we formulate a scenario-based non-linear stochastic programming model and linearize it into an equivalent deterministic mixed-integer linear programming model that can be directly solved by CPLEX; and (b) an improved differential evolution algorithm, which is equipped with several problem-specific components, such as two mutation operators balancing exploration and exploitation, initialization, and local improvement search. Extensive computational experiments on a large number of benchmark instances are performed to validate our algorithms, which are also compared with state-of-the-art meta -heuristics. The computational results reveal the effectiveness and competitiveness of our algorithms. We also analyze the value of stochastic information based on the exact algorithm and the meta -heuristics, respectively.},
  archive      = {J_COR},
  author       = {Hongbo Li and Linwen Zheng and Rui Chen and Xianchao Zhang},
  doi          = {10.1016/j.cor.2024.106753},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106753},
  shortjournal = {Comput. Oper. Res.},
  title        = {Stochastic resource leveling in projects with flexible structures},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the restricted steiner multi cycle problem. <em>COR</em>,
<em>169</em>, 106752. (<a
href="https://doi.org/10.1016/j.cor.2024.106752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new problem, called Steiner Multi Cycle Problem, in which we are given a complete weighted graph G = ( V , E ) G=(V,E) , which respects the triangle inequality, a collection of terminal sets { T 1 , … , T k } {T1,…,Tk} , where for each a a in [ k ] [k] we have a subset T a Ta of V V and these terminal sets are pairwise disjoint. The goal is to find a set of disjoint cycles of minimum cost such that for each a a in [ k ] [k] , all vertices of T a Ta belong to a same cycle. Our main interest is in a restricted case where | T a | = 2 |Ta|=2 , for each a a in [ k ] [k] , which models a collaborative problem with pickup and delivery. We show that even the restricted problem is NP-Hard, and present three heuristics to solve it: a dynamic programming algorithm called Refinement Search Heuristic, which explores geometric and laminar set properties; a heuristic based on the Gonzales Clustering algorithm; and a GRASP Heuristic with Path Relinking. We performed computational experiments with 525 instances to compare these methods, which achieved results close to the optimum, highlighting the performance of the Refinement Search Heuristic both in quality and time.},
  archive      = {J_COR},
  author       = {Vinicius de Novaes Guimarães Pereira and Mário César San Felice and Pedro Henrique Del Bianco Hokama and Eduardo Candido Xavier},
  doi          = {10.1016/j.cor.2024.106752},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106752},
  shortjournal = {Comput. Oper. Res.},
  title        = {On the restricted steiner multi cycle problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An ALNS metaheuristic for the family multiple traveling
salesman problem. <em>COR</em>, <em>169</em>, 106750. (<a
href="https://doi.org/10.1016/j.cor.2024.106750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel variant of the Family Traveling Salesman Problem (FTSP), a well-known NP-hard problem introduced by Morán-Mirabal et al. (2014). In the FTSP, the set of nodes is partitioned into several subsets called families, and the aim is to determine the minimum-cost cycle that begins and ends at the depot and visits a predefined number of nodes in each family. We extend the FTSP by requiring that m m tours be generated, each having a number of nodes between a minimum and a maximum quantity, thus yielding the family multiple traveling salesman problem (FmTSP). We present a two-index MIP formulation and develop an ALNS metaheuristic as a solution method for large-sized instances. Our proposed ALNS was initially employed to solve the FTSP benchmark instances and allowed us to improve some of the best-known solutions. The results for new derived instances requiring multiple tours show that our ALNS also achieves optimality for all instances with proven-optimal solutions.},
  archive      = {J_COR},
  author       = {Claudio B. Cunha and Dieferson Flori Massarotto and Sergio Luiz Fornazza and André Bergsten Mendes},
  doi          = {10.1016/j.cor.2024.106750},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106750},
  shortjournal = {Comput. Oper. Res.},
  title        = {An ALNS metaheuristic for the family multiple traveling salesman problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling jobs to minimize a convex function of resource
usage. <em>COR</em>, <em>169</em>, 106748. (<a
href="https://doi.org/10.1016/j.cor.2024.106748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a finite set of jobs and a common resource. Each job has the same processing time p p , alongside an individual release date and deadline, and utilizes either zero or one unit from the resource. A schedule specifies a star time for each job, and it determines the resource usage over time. The objective is to minimize a separable convex function of the resource usage. Prior to our work, the existing body of research only tackled the scenario where p = 1 p=1 . We explore three variations of this fundamental problem, accompanied by applications drawn from existing literature. In the first variant, all jobs require one unit of the resource each. In the second and third variants, there are m m parallel machines, and at most m m jobs may be processed concurrently at any given moment. Furthermore, in the second variant, each job has a unit processing time, and may require either 0 or 1 unit of the resource. In the third case, there are ν ν distinct resource types each linked with a convex function, and each job requires precisely one of these resources types. The jobs have a uniform processing time p p and possess agreeable release dates and deadlines. For each of these cases, we introduce novel polynomial-time algorithms designed to determine optimal solutions.},
  archive      = {J_COR},
  author       = {Tamás Kis and Evelin Szögi},
  doi          = {10.1016/j.cor.2024.106748},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106748},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling jobs to minimize a convex function of resource usage},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The ordered median tree location problem. <em>COR</em>,
<em>169</em>, 106746. (<a
href="https://doi.org/10.1016/j.cor.2024.106746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the Ordered Median Tree Location Problem ( OMT ). The OMT is a single-allocation facility location problem where p p facilities must be placed on a network connected by a non-directed tree. The objective is to minimize the sum of the ordered weighted averaged allocation costs plus the sum of the costs of connecting the facilities in the tree. We present different MILP formulations for the OMT based on properties of the minimum spanning tree problem and the ordered median optimization. Given that ordered median location problems are rather difficult to solve we have improved the OMT solution performance by introducing covering variables in a valid reformulation plus developing two pre-processing phases to reduce the size of this formulations. In addition, we propose a Benders decomposition algorithm to approach the OMT . We establish an empirical comparison between these new formulations and we also provide enhancements that together with a proper formulation allow to solve medium size instances on general random graphs.},
  archive      = {J_COR},
  author       = {Miguel A. Pozo and Justo Puerto and Alberto Torrejón},
  doi          = {10.1016/j.cor.2024.106746},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106746},
  shortjournal = {Comput. Oper. Res.},
  title        = {The ordered median tree location problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A progressive hedging-based matheuristic for the stochastic
production routing problem with adaptive routing. <em>COR</em>,
<em>169</em>, 106745. (<a
href="https://doi.org/10.1016/j.cor.2024.106745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The production routing problem (PRP) arises in the context where a manufacturing facility manages its production schedule, the delivery of goods to customers by a fleet of vehicles, and the inventory levels both at the plant and at the customers. The presence of uncertainty often complicates the planning process. In particular, production and distribution costs may significantly increase if demand uncertainty is ignored in the planning phase. Nevertheless, only a few studies have considered demand uncertainty in the PRP. In this article, we propose a two-stage stochastic programming approach for a one-to-many PRP with a single product and demand uncertainty. Unlike previous studies in the literature, we consider the case where routing decisions are made in the second stage after customer demands become known. This offers more flexibility, which can decrease transportation costs by preventing unnecessary customer visits. In addition to the static–dynamic case, in which setup decisions are made first and production quantities are decided in the second stage, we also consider the static–static setting where both sets of decisions must be made prior to the demand realization. A progressive hedging algorithm combined with a matheuristic is developed to solve the problem. The role of the progressive hedging algorithm is to decompose the stochastic problem into more tractable scenario-specific subproblems and lead the first-stage variables towards convergence by modifying their Lagrangean multipliers. However, solving the subproblems remains challenging since they include routing decisions, and we thus propose a matheuristic to exploit the structural characteristics of the subproblems. First, a Traveling Salesman Problem (TSP) is solved to find the optimal tour for all customers regardless of demand and capacity. Utilizing the sequence obtained from the TSP, we then solve a restricted PRP while taking into account the other constraints of the original problem. Finally, for each period and scenario, a vehicle routing problem is solved to improve the quality of the solutions. Computational experiments are conducted to analyze the algorithm’s efficiency and to assess the benefits that can be achieved by handling routing in the second stage.},
  archive      = {J_COR},
  author       = {Ali Kermani and Jean-François Cordeau and Raf Jans},
  doi          = {10.1016/j.cor.2024.106745},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106745},
  shortjournal = {Comput. Oper. Res.},
  title        = {A progressive hedging-based matheuristic for the stochastic production routing problem with adaptive routing},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective evolutionary algorithm based flexible
assembly job-shop rescheduling with component sharing for order
insertion. <em>COR</em>, <em>169</em>, 106744. (<a
href="https://doi.org/10.1016/j.cor.2024.106744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a rescheduling problem in an order-driven flexible assembly job-shop, which encompasses a complete production line from machining to assembly. Some products have a multi-level assembly structure, and certain components can be shared among different products. When an order with tight delivery date is inserted, rescheduling is necessary for adjusting original production scheme and tradeoffs among makespan, total tardiness and count of machine changes. To formulate the flexible assembly job-shop rescheduling problem with component sharing (FAJRP-CS), a mixed-integer linear programming model is established. The model involves three categories of decision variables that determine the machine assignment, shared component allocation, and operation sequencing. Meanwhile, solution of FAJRP-CS is analyzed by using graph model, and a neighborhood structure containing two-type move for critical operations is proposed for local optimizing. Then, a hybrid non-dominated sorting genetic algorithm with tabu search (NSGATS) is developed to maintain diversity while improving convergence. The approach is first compared with 8 algorithms on nine test instances, and the effectiveness of the operators, framework and neighborhood structure are discussed separately. Subsequently, NSGATS is applied to solve the multi-stage rescheduling problem in a medical device workshop with 6 products and 56 components. The experimental results demonstrate that NSGATS is effective for solving the FAJRP-CS.},
  archive      = {J_COR},
  author       = {Jinghe Sun and Zhuo Zhang and Guohui Zhang and Zhouchun Huang},
  doi          = {10.1016/j.cor.2024.106744},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106744},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective evolutionary algorithm based flexible assembly job-shop rescheduling with component sharing for order insertion},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimisation of steel rolling schedule based on evolutionary
multi-tasking transfer algorithm. <em>COR</em>, <em>169</em>, 106743.
(<a href="https://doi.org/10.1016/j.cor.2024.106743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strip rolling is an important part of steel processing. The load distribution scheme in the rolling process directly affects production efficiency and product quality. A dynamic rolling process with changing speed is investigated to improve quality and reduce energy use. To balance the iterative calculation of the complex industrial evolution process and the requirements of high real-time, this study examine the rolling process by combining the multivariate, multi-constraint, and strong coupling characteristics of field measured data. On this basis, several conflicting rolling optimisation objectives in the process of rolling schedule optimisation were analysed, and a dimension reduction migration model based on transfer component analysis was established. In case of an inefficient transfer of feasible solutions, a multi-objective multifactorial evolutionary algorithm based on an explicit transfer solution strategy (MOMFEA-ETS) was proposed. The proposed algorithm obtained four average distance optimal values for eight practical rolling programming problems.},
  archive      = {J_COR},
  author       = {Ziyu Hu and Shan Wang and Yulin Li and Lixin Wei and Hao Sun},
  doi          = {10.1016/j.cor.2024.106743},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106743},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimisation of steel rolling schedule based on evolutionary multi-tasking transfer algorithm},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Ensemble learning method for classification: Integrating
data envelopment analysis with machine learning. <em>COR</em>,
<em>169</em>, 106739. (<a
href="https://doi.org/10.1016/j.cor.2024.106739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification tasks with large sample sets, the use of a single classifier carries the risk of overfitting. To overcome this issue, an ensemble of classifier models has often been shown to outperform the use of a single “best” model. Given the rich variety of classifier models available, the selection of the high-efficiency classifiers for a given task dataset remains an urgent challenge. However, most of the previous classifier selection methods only focus on the measurement of classification output performance without considering the computational cost. This paper proposes a new ensemble learning method to improve the classification quality for big datasets by using data envelopment analysis. It contains the following two stages: classifier selection and classifier combination. In the first stage, the commonly used classifiers are evaluated on the basis of their performance on resource consumption and classification output performance using the range directional model (RDM); then, the most efficient classifiers are selected. In the second stage, the classifier confusion matrix is evaluated using the data envelopment analysis (DEA) cross-efficiency model. Then, the weight for the classifier combination is determined to ensure that classifiers with higher performance have greater weights based on the cross-efficiency values. Experimental results demonstrate the superiority of the cross-efficiency model over the BCC model and the benchmark voting method in model ensemble. Furthermore, our method has been shown to save more computational resources and yields better results than existing methods.},
  archive      = {J_COR},
  author       = {Qingxian An and Siwei Huang and Yuxuan Han and You Zhu},
  doi          = {10.1016/j.cor.2024.106739},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106739},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ensemble learning method for classification: Integrating data envelopment analysis with machine learning},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LG-GNN: Local and global information-aware graph neural
network for default detection. <em>COR</em>, <em>169</em>, 106738. (<a
href="https://doi.org/10.1016/j.cor.2024.106738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Default detection, a crucial aspect of individual credit scoring, has attracted considerable attention in research. Previous approaches typically focus on classifying applicants using only explicit attributes, overlooking the importance of latent relations among them. Concurrently, graph-based techniques have emerged as promising tools for credit scoring. However, existing graph-based methods often need to be more accurate in aggregating information from limited neighbors, which can lead to misclassification when the target node has differently labeled neighbors. Motivated by these challenges, we propose a Local and Global Information-aware Graph Neural Network (LG-GNN) approach for default detection. By leveraging the loan applicant relation graph, LG-GNN dynamically learns the representation of the target node from both local and global perspectives. Furthermore, it adaptively fuses the information from these perspectives and employs contrastive learning to enhance feature variations. Extensive experiments demonstrate the superiority of LG-GNN over mainstream methods across several widely used default detection datasets. Specifically, LG-GNN achieves an average relative performance improvement of 47.9% compared to baselines. Moreover, compared to the most competitive default detection methods, LG-GNN exhibits an average performance improvement of 11.9%. Our code is publicly available at https://github.com/BERA-wx/LG-GNN .},
  archive      = {J_COR},
  author       = {Yi Liu and Xuan Wang and Tao Meng and Wei Ai and Keqin Li},
  doi          = {10.1016/j.cor.2024.106738},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106738},
  shortjournal = {Comput. Oper. Res.},
  title        = {LG-GNN: Local and global information-aware graph neural network for default detection},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic tuberculosis screening for healthcare employees.
<em>COR</em>, <em>169</em>, 106737. (<a
href="https://doi.org/10.1016/j.cor.2024.106737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular tuberculosis (TB) screening is required for healthcare employees. TB is a potentially deadly disease. Early detection prevents the spread of the disease and helps with treatment. Two types of TB diagnostic tests, which vary in terms of cost and accuracy, are available on the market. Thus, hospitals need to carefully consider the available screening options to effectively monitor TB prevalence at low cost. We develop the first optimization model and solution approach in the literature that can be used to obtain effective TB screening policies where testing decisions are differentiated based on employee characteristics. We categorize healthcare employees based on the department they work in, the specific job they do, and their history of vaccination against TB. We develop a Markov decision process (MDP) model to determine which TB test should be utilized for each employee category to minimize the total costs related to testing, undetected infections, and employees’ time lost due to testing. Due to the size of the problem, we use approximate dynamic programming (ADP) to obtain near-optimal solutions. We analyze the ADP solutions under varying assumptions to develop a screening policy that specifies not only the type of the tests that should be used but also the frequency with which each test should be administered. We further examine the impact of system parameters such as costs and TB prevalence on our policy recommendation via a sensitivity analysis. The results indicate that our approach yields a simple policy that can be used by healthcare providers that do not have the expertise or the resources to develop and solve sophisticated optimization models on an ongoing basis.},
  archive      = {J_COR},
  author       = {Mahsa Kiani and Tugce Isik and Burak Eksioglu and Ronald G. Pirrallo},
  doi          = {10.1016/j.cor.2024.106737},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106737},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic tuberculosis screening for healthcare employees},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The low-carbon vehicle routing problem with dynamic speed on
steep roads. <em>COR</em>, <em>169</em>, 106736. (<a
href="https://doi.org/10.1016/j.cor.2024.106736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-carbon vehicle routing problem with dynamic speeds on steep roads (LCVRPDS-SR) considers the combined effects of dynamic speeds, steep roads, and loads on carbon emissions. Earlier low-carbon vehicle routing problems typically assumed that vehicles travel at a constant speed on flat roads. However, such models do not apply in urban or rural areas with steep roads. Although the subsequent studies further explored the effect of steep roads, their performance are still suboptimal since they fail to take into account the varying speeds on the terrain. This paper proposes an extended LCVRPDS-SR model that tackles dynamic speed decisions on steep roads for the low-carbon vehicle routing problem. The objective function is non-linear and considers only environmental factors. Then an improved adaptive large neighborhood search algorithm is presented, including a new speed optimization algorithm and several improved removal and insertion operators. Extensive experiments are conducted on the generated instances to verify the effectiveness of the model and algorithm and derive managerial insights. The significant reduction in greenhouse gas emissions is achieved when considering dynamic speeds.},
  archive      = {J_COR},
  author       = {Jianhua Xiao and Xiaoyang Liu and Huixian Zhang and Zhiguang Cao and Liujiang Kang and Yunyun Niu},
  doi          = {10.1016/j.cor.2024.106736},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106736},
  shortjournal = {Comput. Oper. Res.},
  title        = {The low-carbon vehicle routing problem with dynamic speed on steep roads},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective shipment consolidation and dispatching
problem. <em>COR</em>, <em>169</em>, 106728. (<a
href="https://doi.org/10.1016/j.cor.2024.106728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the increase in global production and demand, transportation problems have become a widely studied area, and studies focus on providing high-quality service at the lowest cost. This study considers a bi-objective shipment consolidation and dispatching problem with the objectives of minimizing the total cost and the total distance. To the best of our knowledge, this is the first study to include both objectives in this problem. Additionally, different from the literature, where usually predefined routes are assumed, we incorporate the routing decisions in our model. In order to create a non-dominated solution set, a multi-objective mixed integer linear programming model is developed and augmented ϵ ϵ -constraint method is used to generate the non-dominated frontier. However, this approach is not capable of finding the non-dominated solution set in a reasonable time, even for small-sized instances, and therefore, we propose a multi-objective variable neighborhood search heuristic. To measure the performance of the proposed approach, a computational experiment is conducted on randomly generated instances available in the literature. The experimental results indicate that the multi-objective variable neighborhood search heuristic performs efficiently in reasonable time.},
  archive      = {J_COR},
  author       = {Özge Büyükdeveci and Selin Özpeynirci and Özgür Özpeynirci},
  doi          = {10.1016/j.cor.2024.106728},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106728},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective shipment consolidation and dispatching problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Location and routing of armed unmanned aerial vehicles and
carrier platforms against mobile targets. <em>COR</em>, <em>169</em>,
106727. (<a href="https://doi.org/10.1016/j.cor.2024.106727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider a real-life combinatorial optimization problem related to deploying and routing Unmanned Aerial Vehicles (UAVs) and naval carrier platforms. In particular, we seek to determine the initial locations for carrier platforms and the optimal type and number of UAVs to be stationed on each carrier platform as well as their spatial/temporal routes for engaging hostile surface targets in the region. Our modeling framework incorporates a number of realistic but challenging ingredients and assumptions such as the mobility of surface targets and carrier platforms during the mission, capacitated multiple platforms and UAVs, UAV-carrier platform compatibility, and allowance for different takeoff/land on platforms for UAVs. In the effort to represent the problem mathematically, we first formulated an Integer Linear Program (ILP) model which seeks to maximize the total time-dependent weights of the targets engaged. Next, we proposed a heuristic solution algorithm based on the ant colony optimization framework. Our computational experiments performed on instances with different sizes showed that the heuristic approach achieves high-quality solutions even for large-size problem instances in short CPU times.},
  archive      = {J_COR},
  author       = {Ertan Yakıcı and Mumtaz Karatas and Levent Eriskin and Engin Cicek},
  doi          = {10.1016/j.cor.2024.106727},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106727},
  shortjournal = {Comput. Oper. Res.},
  title        = {Location and routing of armed unmanned aerial vehicles and carrier platforms against mobile targets},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dispersed starting solutions in facility location: The case
of the planar p-median problem. <em>COR</em>, <em>169</em>, 106726. (<a
href="https://doi.org/10.1016/j.cor.2024.106726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many planar multiple facilities location problems for which the optimal locations tend to be spread out. The most popular of these is the planar p p -median problem. With this in mind, we propose several procedures to generate sparse configurations as starting solutions. The proposed procedures are easy to implement, and can be used as modules combined in different sequences within heuristics such as a recent trajectory-based procedure that we tested in this paper. The procedures are tested experimentally on a set of 24 large problem instances with up to 10,000 demand points and 100 facilities. We are able to demonstrate that the sparse starting solutions generated by the new procedures lead to significant improvements of final p p -median solutions.},
  archive      = {J_COR},
  author       = {Zvi Drezner and Jack Brimberg and Anita Schöbel},
  doi          = {10.1016/j.cor.2024.106726},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106726},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dispersed starting solutions in facility location: The case of the planar p-median problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximal covering location with partial coverage for
second-level specialized health care services. <em>COR</em>,
<em>169</em>, 106725. (<a
href="https://doi.org/10.1016/j.cor.2024.106725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of access to Second-level Health Care Services (SHCS) in developing countries is primarily due to the scarcity of facilities and the limited investment of resources in the public sector. Access to these services directly relates to the distance the population travels to these facilities. In that sense, a maximal covering location problem can be helpful to maximize the impact of decisions related to the location of new SHCS. In this paper, we propose a model to guide the location of additional sites where second-level services can be installed in a network of public hospitals. The partial coverage and variable radius are considered in the problem to assess a large territory with different characteristics and population densities. The system is composed of multiple institutions that supply differentiated varying levels of coverage concerning their own demand and external demand. The objective of the problem is to improve the demand coverage in the system by locating new sites, since there are already sites offering different services. A case study in the Mexican public health system is conducted to assess four specialized SHCS. The obtained results evidence for the benefit of using optimization tools in the resource planning of SHCS.},
  archive      = {J_COR},
  author       = {Rodolfo Mendoza-Gómez and Roger Z. Ríos-Mercado},
  doi          = {10.1016/j.cor.2024.106725},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106725},
  shortjournal = {Comput. Oper. Res.},
  title        = {Maximal covering location with partial coverage for second-level specialized health care services},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finding small feedback arc sets on large graphs.
<em>COR</em>, <em>169</em>, 106724. (<a
href="https://doi.org/10.1016/j.cor.2024.106724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum feedback arc set problem (FASP), which seeks to remove a minimum set of arcs from a directed graph to make the remaining graph acyclic, is fundamental in graph algorithms with many applications in social network analysis, circuit testing, deadlock resolution, algorithmic games, and other fields. However, in theory, FASP is NP-Hard and cannot be approximated within any constant under the Unique-Games Conjecture. In practice, the performance of existing algorithms on large graphs is still unsatisfactory. To solve FASP on large graphs, we propose two novel methods in this paper. First, we systematically study the reduction rules for FASP that can quickly reduce the scale of input graphs without losing optimality. We integrate the reduction rules into an algorithm that can be used as a preprocessor for all existing FASP algorithms to simplify the input graphs. Second, we provide a scalable heuristic algorithm based on the divide-and-conquer method for better solution quality. Extensive experiments on a wide range of real-world graphs show that the reduction algorithm effectively reduces the size of input instances. Furthermore, for half of the circuit benchmark graphs, our final algorithm improves the quality of the existing heuristic solution by 24% to 40% within an acceptable running time.},
  archive      = {J_COR},
  author       = {Ziliang Xiong and Yi Zhou and Mingyu Xiao and Bakhadyr Khoussainov},
  doi          = {10.1016/j.cor.2024.106724},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106724},
  shortjournal = {Comput. Oper. Res.},
  title        = {Finding small feedback arc sets on large graphs},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mathematical formulation and a tabu search heuristic for
the joint vessel-UAV routing problem. <em>COR</em>, <em>169</em>,
106723. (<a href="https://doi.org/10.1016/j.cor.2024.106723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by offshore inspection practices, we investigate a joint vessel-unmanned aerial vehicle (UAV) routing problem where vessels and UAVs work coordinately to perform inspection tasks. The problem is an extension of the mothership-drone routing problem by further considering multiple vessels and realistic constraints such as temporal-spatial coordination, service time, and inspection cycle. The goal is to minimize overall operational costs, including fixed vessel cost, and vessel and UAV routing costs. Decision-making involves task assignment, vessel route determination, and UAV take-off and landing locations. We formulate the problem as a mixed-integer second-order cone program. Addressing its NP-hard nature, we develop an enhanced tabu search algorithm (TS-RC), which incorporates two innovative mechanisms to reduce the computational burden. The first is to determine UAV take-off/landing points based on a new constructive procedure. The second is assessing neighborhood solutions using an approximate procedure. Results on a real-world case demonstrate a 10.29% reduction in operational costs compared to a classic vessel routing model. Moreover, numerical experiments on random instances with up to four vessels and 39 tasks demonstrate the performance of the proposed TS-RC method.},
  archive      = {J_COR},
  author       = {Yantong Li and Shengjie Wang and Shanshan Zhou and Zheng Wang},
  doi          = {10.1016/j.cor.2024.106723},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106723},
  shortjournal = {Comput. Oper. Res.},
  title        = {A mathematical formulation and a tabu search heuristic for the joint vessel-UAV routing problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The maximal covering location disruption problem.
<em>COR</em>, <em>169</em>, 106721. (<a
href="https://doi.org/10.1016/j.cor.2024.106721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research sets forth and examines a new sequential, competitive location problem. The maximal covering location disruption problem is a zero-sum Stackelberg game comprised of two stages. A leader denies access to at most q q out of n n possible facility locations in the first stage and, in the second stage, a follower solves a maximal covering location problem while emplacing at most p p facilities. Identifying this problem as both relevant and unaddressed in the current literature, this research examines properties of the bilevel programming formulation to inform heuristic development, subsequently evaluating the efficacy and efficiency of two variants each of an iterative, bounding heuristic (IBH) and a reformulation-based construction heuristic (RCH) over a two sets collectively consisting of 2160 test instances representing a breadth of relative parametric values. Although we illustrate that each heuristic may not identify an optimal solution, computational testing demonstrates the superlative and generally excellent performance of the RCH variants. For the 12.4% of instances for which the RCH does not readily verify the optimality of its solution, lower-bounding procedures characterize solution quality. Both of the RCH variants attain solutions with an average 4.08% relative optimality gap, and they scaled well over different parametric value combinations, solving instances in an average of 98.0 and 123.6 seconds, respectively.},
  archive      = {J_COR},
  author       = {Brian J. Lunday},
  doi          = {10.1016/j.cor.2024.106721},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106721},
  shortjournal = {Comput. Oper. Res.},
  title        = {The maximal covering location disruption problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Joint optimization of dynamic pricing, quality, and
production quantity in the presence of online reviews: A
distributionally robust optimization approach. <em>COR</em>,
<em>169</em>, 106720. (<a
href="https://doi.org/10.1016/j.cor.2024.106720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the joint pricing, product quality, and production quantity decisions of a firm in a two-stage scenario, considering potential market demand uncertainty and the existence of online reviews. Two decision models are established based on whether the firm adjusts product quality and prices according to consumer feedback from reviews: a static model (as a baseline) and a dynamic model. In the static model, the firm decides product quality, prices, and production quantity in the first stage, while in the second stage, the firm does not enhance product quality, and prices remain unchanged. In the dynamic model, in the first stage, the firm decides initial product quality and pricing, then in the second stage, adjusts product quality based on consumer feedback and sets pricing accordingly. We propose a distributionally robust optimization (DRO) method to address this problem, obtaining a closed-form solution for the expected profit function under the worst distribution, making it easy to determine the optimal decision. Through numerical simulation analysis, we find that the firm implementing dynamic decisions always make higher profits compared to those using static decisions. This highlights the superiority of dynamic decisions in adapting to market changes and improving product quality. We also analyze the impact of expected and standard deviation of potential market demand, as well as consumer private assessment weight, on business decisions and profits. Our research provides effective support for firms with limited market information, enabling them to better formulate joint pricing, quality, and production decisions.},
  archive      = {J_COR},
  author       = {Chuan Zhang and Yu-Xin Tian},
  doi          = {10.1016/j.cor.2024.106720},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106720},
  shortjournal = {Comput. Oper. Res.},
  title        = {Joint optimization of dynamic pricing, quality, and production quantity in the presence of online reviews: A distributionally robust optimization approach},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Assigning multi-skill configurations to multiple servers
with a scenario-based planning and recombination approach. <em>COR</em>,
<em>169</em>, 106719. (<a
href="https://doi.org/10.1016/j.cor.2024.106719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work deals with a dynamic problem arising from an outpatient healthcare facility. Patients with varying priorities arrive throughout the day, each with specific service requests that must be satisfied within target times. Failure to meet these targets incurs weighted tardiness penalties. Additionally, patients may choose to leave the system if subjected to prolonged waiting times, leading to further weighted penalties. The outpatient facility is equipped with multiple identical servers, each capable of providing a finite subset of services, referred to as configurations. The objective is to dynamically assign configurations, selected from a predefined set, to servers by minimizing the sum of weighted tardiness and abandonment penalties. Assignments are not fixed statically but can be dynamically changed over time to cope with the service requests. To address this problem, we propose a Scenario-Based Planning and Recombination Approach (SBPRA) that integrates an inner Reduced Variable Neighborhood Search. Differently from the traditional Scenario-Based Planning Approach (SBPA), which makes decisions based only on the solutions of individual scenarios, our approach solves an optimization problem to produce an additional solution that offers the best balance among the scenario solutions. Extensive tests on realistic instances show that SBPRA generates solutions that are 38% on average more effective than those generated by SBPA. Overall, the proposed approach can optimize resource allocation, mitigate the impact of patient abandonment, and improve the performance of the outpatient healthcare facility.},
  archive      = {J_COR},
  author       = {Beatrice Bolsi and Thiago Alves de Queiroz and Vinícius Loti de Lima and Arthur Kramer and Manuel Iori},
  doi          = {10.1016/j.cor.2024.106719},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106719},
  shortjournal = {Comput. Oper. Res.},
  title        = {Assigning multi-skill configurations to multiple servers with a scenario-based planning and recombination approach},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extremal behavior of the greedy algorithm for a triangle
scheduling problem. <em>COR</em>, <em>169</em>, 106718. (<a
href="https://doi.org/10.1016/j.cor.2024.106718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the mixed-criticality scheduling problem, where the goal is to schedule jobs with different criticality levels on a single machine. As shown by Dürr et al. (2018), the problem can be treated as a specific 1-dimensional triangle scheduling problem. In that paper a new Greedy algorithm was defined, and the authors proved that its approximation ratio lies between 1.05 and 3/2. In this paper we present a quadratic integer programming model, which can be used to computationally analyze the algorithm for inputs with small sizes. The model simulates the behavior of the algorithm and it compares the makespan with the optimal one. Using this model, we found sequences extendable to longer series, giving a lower bound of 1.27 for the Greedy algorithm. Also, the optimum on problem instances consisting of intervals of natural numbers is analyzed and a closed formula is determined. In this way, we detected two input classes where, in one of them, Greedy is far from optimal (we think that this could be the worst case), and in the other one it is optimal.},
  archive      = {J_COR},
  author       = {János Balogh and József Békési and Nóra Büki and György Dósa and Zsolt Tuza},
  doi          = {10.1016/j.cor.2024.106718},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106718},
  shortjournal = {Comput. Oper. Res.},
  title        = {Extremal behavior of the greedy algorithm for a triangle scheduling problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An iterated local search matheuristic approach for the
multi-vehicle inventory routing problem. <em>COR</em>, <em>169</em>,
106717. (<a href="https://doi.org/10.1016/j.cor.2024.106717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-vehicle inventory routing problem considers an integrated system in which a supplier must satisfy deterministic demands from a set of customers over a finite and discrete time horizon. A limited inventory capacity is available at the customers, and a deterministic amount of product is available at the supplier in each period to fulfill customer demands with a homogeneous fleet of vehicles. The supplier decides when to resupply the customers, the quantities of product to deliver, and the routes to serve the customers. The aim is to find the best supply policy, which minimizes the total inventory and routing costs while ensuring that no stock-out occurs at the customers, while respecting the capacity of each vehicle. The problem has attracted significant attention in recent decades due to its wide applicability in fields where both inventory and routing aspects are addressed together. In this work, we present a matheuristic algorithm based on a mathematical formulation in which we associate a decision variable with each route and period. The size of this set of decision variables is clearly exponential; therefore, we devise a column generation approach in which we heuristically generate a subset of these variables within an iterated local search framework. Each iteration of the algorithm is composed by two phases: in the first one, the current model is solved by means of a general-purpose solver, whereas in the second one the model is updated by replacing some variables with a suitable subset of new variables. Once a local optimum is reached, a diversification step takes place in which the set of columns is expanded to possibly define a new starting solution. We have compared our approach with state-of-the-art algorithms on a large benchmark of instances from the literature. Our computational results show that the proposed algorithm outperforms most of the existing heuristic methods.},
  archive      = {J_COR},
  author       = {Demetrio Laganà and Enrico Malaguti and Michele Monaci and Roberto Musmanno and Paolo Paronuzzi},
  doi          = {10.1016/j.cor.2024.106717},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106717},
  shortjournal = {Comput. Oper. Res.},
  title        = {An iterated local search matheuristic approach for the multi-vehicle inventory routing problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid-biased genetic algorithm for packing unequal
rectangles into a fixed-size circle. <em>COR</em>, <em>169</em>, 106716.
(<a href="https://doi.org/10.1016/j.cor.2024.106716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the two-dimensional circular knapsack packing problem, which packs unequal rectangles into a circular container to maximize the number or the area of items packed. A biased genetic algorithm hybridized with a local search algorithm is proposed to solve the problem. The algorithm has a powerful global searching ability and is responsible for exploration, and a local search is applied for exploitation. Therefore, the proposed approach has an excellent search ability that can balance intensification and diversification well. A decoding procedure is proposed to transform the chromosome into a packing layout. The procedure first produces several initial layouts that contain a few rectangles, forms a complete layout for each initial layout, and selects the best one as the final packing layout. Three new types of initial layouts are considered. A new set of evaluation rules for the placement position and a random selection method are proposed. Computational experiments using two benchmark datasets showed that the evolutionary algorithm could provide better solutions than state-of-the-art algorithms from the literature, with 64 new best solutions out of 108 benchmark instances.},
  archive      = {J_COR},
  author       = {Qiang Luo and Yunqing Rao and Piaoruo Yang and Xusheng Zhao},
  doi          = {10.1016/j.cor.2024.106716},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106716},
  shortjournal = {Comput. Oper. Res.},
  title        = {Hybrid-biased genetic algorithm for packing unequal rectangles into a fixed-size circle},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse dynamic discretization discovery via arc-dependent
time discretizations. <em>COR</em>, <em>169</em>, 106715. (<a
href="https://doi.org/10.1016/j.cor.2024.106715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While many time-dependent network design problems can be formulated as time-indexed formulations with strong relaxations, the size of these formulations depends on the discretization of the time horizon and can become prohibitively large. The recently-developed dynamic discretization discovery (DDD) method allows many time-dependent problems to become more tractable by iteratively solving instances of the problem on smaller networks where each node has its own discrete set of departure times. However, in the current implementation of DDD, all arcs departing a common node share the same set of departure times. This causes DDD to be ineffective for solving problems where all near-optimal solutions require many distinct departure times at the majority of the high-degree nodes in the network. Region-based networks are one such structure that often leads to many high-degree nodes, and their increasing popularity underscores the importance of tailoring solution methods for these networks. To improve methods for solving problems that require many departure times at nodes, we develop a DDD framework where the set of departure times is determined on the arc level rather than the node level. We apply this arc-based DDD method to a temporal variant of the service network design problem (SND). We show that an arc-based approach is particularly advantageous when instances arise from region-based networks, and when candidate paths are fixed in the base graph for each commodity. Moreover, our algorithm builds upon the existing DDD framework and achieves these improvements with only benign modifications to the original implementation.},
  archive      = {J_COR},
  author       = {Madison Van Dyk and Jochen Koenemann},
  doi          = {10.1016/j.cor.2024.106715},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106715},
  shortjournal = {Comput. Oper. Res.},
  title        = {Sparse dynamic discretization discovery via arc-dependent time discretizations},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The parallel stack loading problem of minimizing the exact
number of relocations. <em>COR</em>, <em>169</em>, 106712. (<a
href="https://doi.org/10.1016/j.cor.2024.106712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the parallel stack loading problem, a general optimization problem arising in storage facilities such as container yards, slab yards, and warehouses. In this problem, we load incoming items into parallel stacks in the loading phase to minimize the number of relocations in the subsequent retrieval phase. Because of difficulties in treating the nested problem structure originating from the mutual dependence of the two phases, the existing studies approximately minimized the number of relocations using surrogate objective functions. In contrast, this study considers the parallel stack loading problem aiming to minimize the exact number of relocations. We first provide an integer programming formulation and next develop a nested branch-and-bound algorithm. In a computational study, we verify the effectiveness of the proposed branch-and-bound algorithm and evaluate the known surrogate objective functions based on the exact minimization.},
  archive      = {J_COR},
  author       = {Shunji Tanaka and Mohamed ElWakil and Amr Eltawil},
  doi          = {10.1016/j.cor.2024.106712},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106712},
  shortjournal = {Comput. Oper. Res.},
  title        = {The parallel stack loading problem of minimizing the exact number of relocations},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximate linear programming for a queueing control
problem. <em>COR</em>, <em>169</em>, 106711. (<a
href="https://doi.org/10.1016/j.cor.2024.106711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Admission decisions for loss systems accessed by multiple customer classes are a classical queueing control problem with a wide variety of applications. When a server is available, the decision is whether to admit an arriving customer and collect a lump-sum revenue. The system can be modeled as a continuous-time infinite-horizon dynamic program, but suffers from the curse of dimensionality when different customer classes have different service rates. We use approximate linear programming to solve the problem under three approximation architectures: affine, separable piecewise linear and finite affine. The finite affine approximation is a recently proposed generalization of the affine approximation, which allows for non-stationary parameters. For both affine and finite affine approximations, we derive equivalent, but more compact, formulations that can be efficiently solved. We propose a column generation algorithm for the separable piecewise linear approximation. Our numerical results show that the finite affine approximation can obtain the tightest bounds for 75% of the instances among the three approximations. Especially, when the number of servers is large and/or the load on the system is high, the finite affine approximation always achieves the tightest bounds. Regarding policy performance, the finite affine approximation has the best performance on average compared to the other two approximations and the achievable performance region method (Bertsimaset al., 1994, Kumar and Kumar, 1994). Furthermore, the finite affine approximation is 4 to 5 orders of magnitude faster than the achievable performance region method and the separable piecewise linear approximation for large-scale instances. Therefore, considering bounds, policy performance, and computational efficiency, the finite affine approximation emerges as a competitive approximation architecture for the class of problems studied here.},
  archive      = {J_COR},
  author       = {Saied Samiedaluie and Dan Zhang and Rui Zhang},
  doi          = {10.1016/j.cor.2024.106711},
  journal      = {Computers &amp; Operations Research},
  month        = {9},
  pages        = {106711},
  shortjournal = {Comput. Oper. Res.},
  title        = {Approximate linear programming for a queueing control problem},
  volume       = {169},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Estimating optimal split delivery vehicle routing problem
solution values. <em>COR</em>, <em>168</em>, 106714. (<a
href="https://doi.org/10.1016/j.cor.2024.106714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the application of linear regression models to estimate the optimal solution value (i.e., the sum of tour lengths) for the Split Delivery Vehicle Routing Problem (SDVRP). We present novel models that integrate topological features along with the mean and standard deviation of feasible solution values, achieving an impressive accuracy with an error margin of approximately 3%. To obtain random feasible solutions for the SDVRP quickly, we propose a modified Clarke &amp; Wright algorithm with split delivery (MCWSD). Our results demonstrate the potential of extending our earlier work to more complex routing problems, highlighting the importance of incorporating diverse features to obtain accurate approximations.},
  archive      = {J_COR},
  author       = {Shuhan Kou and Bruce Golden and Luca Bertazzi},
  doi          = {10.1016/j.cor.2024.106714},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106714},
  shortjournal = {Comput. Oper. Res.},
  title        = {Estimating optimal split delivery vehicle routing problem solution values},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A flexible variable neighbourhood search algorithm for
different variants of the electric vehicle routing problem.
<em>COR</em>, <em>168</em>, 106713. (<a
href="https://doi.org/10.1016/j.cor.2024.106713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript presents a flexible variable neighbourhood search (VNS)-based (Flexi-VNS) algorithm to tackle both the classical Electrical Vehicle Routing Problem (EVRP) and the Battery Swap Station Location-routing Problem with Capacitated Electric Vehicles (BSS-EV-LRP). The latter has been addressed in just a few studies. It incorporates into the EVRP the battery swapping stations (BSS) location requirement to be jointly taken with decisions on the routing of electric vehicles. The Flexi-VNS algorithm includes a Randomised Variable Neighbourhood Descent (RVND) method as the local search procedure, which incorporates a new intra-RVND procedure called every time a solution is modified and applied only to those routes that have been modified. We assess the performance of Flexi-VNS on EVRP and BSS-EV-LRP benchmark instances and compare it with some algorithms in the literature. The statistical test did not guarantee the existence of a statistical difference between the proposed algorithm and the best algorithm from the literature for each problem, considering a 95% confidence level. However, despite this, computational results showed the Flexi-VNS efficiency. It improved several of the best-known solutions and reduced the number of constructed battery swap stations. More specifically, Flexi-VNS was able to equal or improve the BKS values of 15 out of a total of 20 instances with available results in the literature for BSS-EV-LRP and 47 out of 52 instances available for the EVRP, totalling 75% of the BSS-EV-LRP instances and 90.38% of the EVRP instances. Furthermore, compared to the exact algorithms, the optimal solutions were found using only a fraction of the computational times reported. Additionally, Flexi-VNS was the first to provide solutions for some BSS-EV-LRP instances.},
  archive      = {J_COR},
  author       = {André L.S. Souza and Marcella Papini and Puca H.V. Penna and Marcone J.F. Souza},
  doi          = {10.1016/j.cor.2024.106713},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106713},
  shortjournal = {Comput. Oper. Res.},
  title        = {A flexible variable neighbourhood search algorithm for different variants of the electric vehicle routing problem},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing electric vehicle routing under traffic
congestion: A comprehensive energy consumption model considering
drivetrain losses. <em>COR</em>, <em>168</em>, 106710. (<a
href="https://doi.org/10.1016/j.cor.2024.106710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption is a critical concern within the electric vehicle (EV) industry. Despite its substantial impact, drivetrain losses have been inadequately addressed in some studies. This paper introduces drivetrain losses as a nonlinear function of velocity, incorporating them into the comprehensive energy consumption model. Considering the influence of traffic congestion on vehicle speed, our proposed model integrates drivetrain losses, aerodynamic losses, tire losses, kinetic energy losses, and potential energy losses. The objective is to optimize routing with the aim of minimizing energy consumption. To tackle this problem, we present a dedicated adaptive large neighborhood search algorithm. Our numerical experiments reveal key findings: (1) Drivetrain losses represent a higher percentage of total energy consumption compared to aerodynamic and tire losses; (2) Drivetrain losses influenced by traffic congestion constitute a significant share, ranging between 63.82% and 72.08% of total energy consumption; (3) Energy consumption experiences notable increases under the impact of traffic congestion.},
  archive      = {J_COR},
  author       = {Hao Xiong and Yumiao Xu and Huili Yan and Haoying Guo and Chen Zhang},
  doi          = {10.1016/j.cor.2024.106710},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106710},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing electric vehicle routing under traffic congestion: A comprehensive energy consumption model considering drivetrain losses},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revisiting the development trajectory of parallel machine
scheduling. <em>COR</em>, <em>168</em>, 106709. (<a
href="https://doi.org/10.1016/j.cor.2024.106709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on the Parallel Machine Scheduling Problem (PMSP) has undergone significant development. The most recent comprehensive review of published studies dates back to early 2001. This article presents an algorithmic review of PMSPs, using Main Path Analysis (MPA) to identify seminal knowledge diffusion and development trajectories. This research also sheds light on the less tangible aspects of the PMSP’s development by employing Cluster Analysis (CA). Our findings indicate that the scheduling of semiconductor production operations received recent and growing attention, which is mostly driven by the industry’s strategic nature. Specifically, the research cluster relevant to setups —material preparation, tool changes, machine settings, testing, and adjustments— requires investigation to address case-specific operational needs. From a theoretical perspective, further development of batch scheduling is needed, particularly when conflicting objectives are considered. Additionally, developing approximation algorithms for multi-objective optimization to integrate non-financial considerations into production scheduling is expected to continue as a growing research topic.},
  archive      = {J_COR},
  author       = {Kuo-Ching Ying and Pourya Pourhejazy and Xin-Yi Huang},
  doi          = {10.1016/j.cor.2024.106709},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106709},
  shortjournal = {Comput. Oper. Res.},
  title        = {Revisiting the development trajectory of parallel machine scheduling},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Non-identical parallel machines batch processing problem to
minimize the makespan: Models and algorithms. <em>COR</em>,
<em>168</em>, 106708. (<a
href="https://doi.org/10.1016/j.cor.2024.106708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a parallel heterogeneous machine batching and scheduling problem in which weighted jobs are first batched, and the batches are then assigned and sequenced on machines of varying capacities. The duration of a batch is the longest time needed to process a job, and the objective is that of minimizing the makespan, or the sum of the batches durations on the machine finishing last. The authors develop polynomial-size mathematical formulations and a variable neighborhood search metaheuristic. Extensive computational results suggest that a flow-based formulation outperforms a compact formulation, despite its larger number of variables. The metaheuristic is capable of producing high-quality solutions within a limited computing time.},
  archive      = {J_COR},
  author       = {Pedram Beldar and Maria Battarra and Gilbert Laporte},
  doi          = {10.1016/j.cor.2024.106708},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106708},
  shortjournal = {Comput. Oper. Res.},
  title        = {Non-identical parallel machines batch processing problem to minimize the makespan: Models and algorithms},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Balancing economic and environmental goals: A novel strategy
for growing items acquisition in livestock farming under an incremental
discount and a power demand pattern. <em>COR</em>, <em>168</em>, 106707.
(<a href="https://doi.org/10.1016/j.cor.2024.106707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human food supply chain is significantly influenced by growing items (GIs) like beef, sheep, hog, chicken, turkey, and other species, as these provide major contributions to food security worldwide. Industrial farming businesses carry out their operations by purchasing a certain species of baby GIs from a supplier, feeding and caring for them until they reach an acceptable living weight, and then selling them after they have been slaughtered and processed. In addition, the production of livestock worldwide accounts for 14.5% of all anthropogenic greenhouse gas (GHG) emissions, according to the Food and Agriculture Organization (FAO), making it a substantial contributor to GHG emissions. Thereby, to regulate emissions, governments from several countries have imposed a tax scheme on the farm’s emission volume. Due to the discrete nature of purchase numbers, using a differentiation-based optimization approach is not appropriate for determining the optimal GI procurement for an industrial farm, making the decision significantly more challenging. The primary goal of this study is to identify the optimal number of GIs for a farm to enhance financial and environmental performance when the cost per weight unit of procurement depends on the volume of purchases and the consumption of processed commodities follows a power demand pattern. A comparison tactic is employed only for the discrete decision variable, while the classical optimization tactic, based on differentiation, is adopted for the remaining continuous decision variable of the derived problem. Our method, which is quite straightforward in its operation, enables the creation of a rule to distinguish between instances in which there is only one optimum solution and those in which there are two. The results from the execution of the novel solution technique reveal that the farm reduces the overall cost of the order while keeping the integrality of the purchased GIs by taking into account the regulation for carbon emissions, the discount, and the power demand pattern.},
  archive      = {J_COR},
  author       = {Md. Al-Amin Khan and Leopoldo Eduardo Cárdenas-Barrón and Gerardo Treviño-Garza and Armando Céspedes-Mota and Biswajit Sarkar},
  doi          = {10.1016/j.cor.2024.106707},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106707},
  shortjournal = {Comput. Oper. Res.},
  title        = {Balancing economic and environmental goals: A novel strategy for growing items acquisition in livestock farming under an incremental discount and a power demand pattern},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logic-based benders decomposition for order acceptance and
scheduling on heterogeneous factories with carbon caps. <em>COR</em>,
<em>168</em>, 106706. (<a
href="https://doi.org/10.1016/j.cor.2024.106706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an integrated order acceptance and scheduling problem for heterogeneous factories with carbon caps, order-dependent processing speeds, and setup times. Three joint decisions including order selection, order assignment and order sequencing are made to maximize profits, i.e., total revenue minus total production and tardiness cost. Firstly, we develop a mixed integer programming model to simultaneously optimize the three decisions and propose several dominance rules to enhance the model. Secondly, due to the particular structure of the problem, we propose a logic-based Benders decomposition (LBBD) method that decomposes the complicated original problem into a master problem and a number of subproblems. The master problem aims to determine order acceptance and order assignment, and each subproblem is for determining order sequencing in each factory. A branch and bound algorithm is then designed to quickly solve the subproblems. The branch and check framework is implemented to accelerate the solving process of the LBBD. Finally, numerical experiments verify that the proposed dominance rules play a promising role in enhancing the model, and the results of the algorithm comparison experiments show the significant advantages of proposed LBBD algorithm combined with the branch and check framework. Sensitivity experiments reveal that carbon cap serves as a major constraint on order acceptance.},
  archive      = {J_COR},
  author       = {Jian Chen and Xudong Ye and Wenjing Ma and Dehua Xu},
  doi          = {10.1016/j.cor.2024.106706},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106706},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition for order acceptance and scheduling on heterogeneous factories with carbon caps},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-cut algorithm for a skip pick-up and delivery
problem. <em>COR</em>, <em>168</em>, 106705. (<a
href="https://doi.org/10.1016/j.cor.2024.106705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study we present a branch-and-cut algorithm for a skip pick-up and delivery problem. The study is motivated by a real-life problem in which full skips are transported from waste drop-off stations to treatment facilities where they are emptied, and then brought back to the original drop-off station. The transportation of the skips is done by trucks with the capacity of carrying two containers at a time. The planning problem is to design the routes of the trucks that perform the collection to satisfy a number of requests in a planning period. A truck route starts at the first pick-up, the truck then performs a sequence of pick-ups, treatments, and deliveries, and the route ends at the last delivery. From the truck perspective, the three actions of pick-up, treatment, and delivery can be performed in any order that respects the vehicle capacity of two and the route duration constraint, but for the single request, the three actions must be performed in the stated order. The problem is formulated as a mixed integer linear problem and several classes of valid inequalities are proposed and integrated into a branch-and-cut algorithm.},
  archive      = {J_COR},
  author       = {José M. Belenguer and Maximiliano Cubillos and Sanne Wøhlk},
  doi          = {10.1016/j.cor.2024.106705},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106705},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-cut algorithm for a skip pick-up and delivery problem},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Experimental analysis of algorithms for the independent
quadratic assignment problem. <em>COR</em>, <em>168</em>, 106704. (<a
href="https://doi.org/10.1016/j.cor.2024.106704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The independent quadratic assignment problem is a variation of the well-known Koopmans–Beckman quadratic assignment problem. The model has a wide variety of applications but it is strongly NP-hard and is also hard to approximate. In this paper we present innovative and simple heuristic algorithms to optimize the problem based on the paradigms of local search, very large-scale neighborhood (VLSN) search, and local search with path-relinking. The performance of these algorithms are analyzed using results generated by extensive computational experiments. Our experimental study highlights that the strategies of path-relinking and VLSN search when worked in unison produced superior outcomes, outperforming algorithms that employ these strategies individually. This underscores the power of hybrid algorithmic approaches in solving complex optimization problems, in particular, the independent quadratic assignment problem. This is the first experimental study available on the independent quadratic assignment problem. We also have constructed (and made available) test instances with different characteristics which can be used as benchmarks in future experimental studies on the problem.},
  archive      = {J_COR},
  author       = {Wei Yang and Yang Wang and Ante Ćustić and Abraham P. Punnen},
  doi          = {10.1016/j.cor.2024.106704},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106704},
  shortjournal = {Comput. Oper. Res.},
  title        = {Experimental analysis of algorithms for the independent quadratic assignment problem},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Obtaining the grundy chromatic number: How bad can my greedy
heuristic coloring be? <em>COR</em>, <em>168</em>, 106703. (<a
href="https://doi.org/10.1016/j.cor.2024.106703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple undirected graph G G , its Grundy chromatic number Γ ( G ) Γ(G) (or Grundy number) defines the worst-case behavior for the well-known and widely-used greedy first-fit coloring heuristic. Specifically, Γ ( G ) Γ(G) is the largest k k for which a k k -coloring can be obtained with the first-fit heuristic. In this paper, we address the Grundy coloring problem, the optimization problem consisting of obtaining the Grundy number of a graph. First, we propose a new combinatorial upper bound for the problem. Second, we describe a standard integer programming formulation and a formulation by representatives. The latter attempts to overcome the symmetries in the problem and relies on the idea that a subset of the vertices in the graph can be represented by one of its vertices, denoted as a representative. Finally, as integer programming approaches can struggle to tackle instances of the problem, we devise a biased random-key genetic algorithm (BRKGA) to obtain heuristic solutions in low computational times. Computational experiments show that our new upper bound can improve over well-established combinatorial bounds available in the literature for several instances. The results also indicate that the formulation by representatives has an overall superior performance than the standard formulation, achieving better results for the denser instances while slightly underperforming on the sparser ones. Furthermore, the BRKGA can find high-quality solutions and can be used with confidence in large instances where the formulations fail.},
  archive      = {J_COR},
  author       = {Mateus C. Silva and Rafael A. Melo and Mauricio G.C. Resende and Marcio C. Santos and Rodrigo F. Toso},
  doi          = {10.1016/j.cor.2024.106703},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106703},
  shortjournal = {Comput. Oper. Res.},
  title        = {Obtaining the grundy chromatic number: How bad can my greedy heuristic coloring be?},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributionally robust disaster relief planning under the
wasserstein set. <em>COR</em>, <em>168</em>, 106689. (<a
href="https://doi.org/10.1016/j.cor.2024.106689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a two-stage natural disaster management problem modeled as a stochastic program, where the first stage consists of a facility location problem, deciding where to open facilities and pre-allocate resources such as medical and food kits, and the second stage is a fixed-charge transportation problem, routing resources to affected areas after observing a disaster. Our model has binary variables present in both stages. Due to the lack of data, classical stochastic programming approaches may be ill-suited, and we propose a two-stage distributionally robust formulation with a Wasserstein ambiguity set, where we consider distributions consistent with historical data and a tunable parameter to control the level of risk aversion. We develop a tailored column-and-constraint generation (CCG) algorithm to solve an extensive reformulation, where scenarios are iteratively generated. We handle the presence of binary variables in the second stage by leveraging the structure of our support set and second-stage problem, and provide conditions under which the optimal value of the latter is concave with respect to the intensity of the disaster, leading to an efficient scenario generation procedure. We also show that our results extend to the case where the second stage is a fixed-charge network flow problem. We perform extensive computational experiments demonstrating the computational advantage of our method over classical CCG implementations on synthetic instances, and illustrate the benefits of our approach on a popular case study from the literature of hurricane threats on the Gulf of Mexico in the United States.},
  archive      = {J_COR},
  author       = {Mohamed El Tonbari and George Nemhauser and Alejandro Toriello},
  doi          = {10.1016/j.cor.2024.106689},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106689},
  shortjournal = {Comput. Oper. Res.},
  title        = {Distributionally robust disaster relief planning under the wasserstein set},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An enhanced exact algorithm for the multi-trip vehicle
routing problem with time windows and capacitated unloading station.
<em>COR</em>, <em>168</em>, 106688. (<a
href="https://doi.org/10.1016/j.cor.2024.106688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a vehicle routing problem that simultaneously considers multiple trips, time windows, and a capacitated unloading station. This problem is a generalization of the multi-trip vehicle routing problem with time windows, which determines a set of least-cost vehicle routes to fulfill all customer demands while respecting the constraints of vehicle capacity and time windows. Due to restricted resources (e.g., equipment and labor force) at the depot, vehicles may need to wait in a queue for being unloaded when they arrive. This unloading capacity constraint significantly complicates the problem, as it causes a trip to involve three stages—traveling, waiting, and unloading. We formulate this problem as an arc flow model and a trip-based set partitioning model, where the latter is solved by a branch-price-and-cut (BPC) algorithm. To improve the computational aspect of the BPC framework, a two-phase column generation (CG) algorithm is designed. First, a bidirectional labeling algorithm is tailored to solve the pricing problem, where two accelerating strategies are employed to speed up the resolution process. Meanwhile, k k -path inequalities and limited-memory subset row inequalities are utilized to tighten the linear relaxation of the master problem. Computational results based on the instances adapted from the well-known Solomon’s benchmark show that the developed BPC algorithm can solve most instances within 50 customers to optimality in a short time frame and some instances of 100 customers to optimality within a 3-hour time limit. Moreover, our BPC algorithm performs better than exact algorithms in the literature for similar problem variants in both solution quality and computing time.},
  archive      = {J_COR},
  author       = {Nan Huang and Hu Qin and Gangyan Xu and Fang Wan},
  doi          = {10.1016/j.cor.2024.106688},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106688},
  shortjournal = {Comput. Oper. Res.},
  title        = {An enhanced exact algorithm for the multi-trip vehicle routing problem with time windows and capacitated unloading station},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous scheduling of jobs and transporters in a hybrid
flow shop with collision-free transporter routing: A novel parallel
heuristic. <em>COR</em>, <em>168</em>, 106687. (<a
href="https://doi.org/10.1016/j.cor.2024.106687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A computationally potent two-stage parallel heuristic (TSPH) and a mixed integer linear programming (MILP) are suggested to address the simultaneous scheduling of jobs and transporters in a hybrid flow shop system, wherein multiple transporters, stage omission, transporter eligibility, machine eligibility, and collision-free transporter routing are assumed. To the best of our knowledge, the significance of transporter collision-free routing has not been spotlighted in the literature on flow shop systems. Collision-free routing of transporters is a requisite technical attribute as transport means may collide on routes and break down the whole system. Our MILP and TSPH assume collision-free routing to impede the issue. Being equipped with parallel computing, TSPH can deal with large problems in a considerably short time. To support, TSPH is analogized against the suggested MILP, two-step MILP (TSMILP), and an efficient parallel meta-heuristic (i.e., parallel particle swarm optimization and genetic algorithm (PPSOGA)) that outperformed many literarily prominent meta-heuristics in the literature. The benchmark results uncover that TSPH outclasses both TSMILP and PPSOGA in the quality of solutions. Eventually, utilizing the convergence plot and Nemenyi’s post-hoc procedure for Friedman’s test, it is revealed that the outcomes of TSPH are remarkably more desirable than those of TSMILP and PPSOGA.},
  archive      = {J_COR},
  author       = {Arash Amirteimoori and Moataz Mohamed and Reza Kia},
  doi          = {10.1016/j.cor.2024.106687},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106687},
  shortjournal = {Comput. Oper. Res.},
  title        = {Simultaneous scheduling of jobs and transporters in a hybrid flow shop with collision-free transporter routing: A novel parallel heuristic},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Out-of-home delivery in last-mile logistics: A review.
<em>COR</em>, <em>168</em>, 106686. (<a
href="https://doi.org/10.1016/j.cor.2024.106686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In light of labor shortages, rising fuel costs, and thin profit margins, providers of last-mile delivery services face a mounting pressure to innovate. One avenue to more efficient last-mile operations is the incorporation of out-of-home delivery (OOHD) services. OOHD, i.e., the delivery to parcel shops and parcel lockers, instead of customers’ homes, offers manifold advantages, including the consolidation of customers into a single delivery location and a reduction in the number of failed delivery attempts. In the past five years, the number of scientific publications dealing with optimization problems in the context of OOHD has increased rapidly. In this survey, we assess the various opportunities for optimization in OOHD-based concepts for last mile logistics. Categorizing their manifold aspects, we provide a classification of problem components and point out key challenges. We then present comprehensive overviews of the literature for all three major decision types (facility location, vehicle routing, location routing). Finally, we extensively discuss gaps in the current literature and indicate directions for future research.},
  archive      = {J_COR},
  author       = {Lukas Janinhoff and Robert Klein and Daniela Sailer and Jim Morten Schoppa},
  doi          = {10.1016/j.cor.2024.106686},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106686},
  shortjournal = {Comput. Oper. Res.},
  title        = {Out-of-home delivery in last-mile logistics: A review},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fixed set search matheuristic applied to the knapsack
problem with forfeits. <em>COR</em>, <em>168</em>, 106685. (<a
href="https://doi.org/10.1016/j.cor.2024.106685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on solving the knapsack problem with forfeits (KPF). This variation of the knapsack problem includes soft conflicts or forfeits, where forfeit pairs consist of two items and an associated penalty, which must be subtracted from the total profit if both items in the pair are chosen to be jointly in the knapsack. The proposed method combines the fixed set search (FSS) metaheuristic’s learning mechanism with integer programming to solve subproblems. A new ground set of elements for the KPF is introduced to augment the information provided by the fixed set, and the method for creating fixed sets is adjusted to increase the diversity of solutions. The conducted computational experiments show that the proposed method significantly outperforms current state-of-the-art methods and finds a large number of best-known solutions for the standard test instances. Moreover, the method performs well across a wide range of parameter values. The proposed approach does not significantly exploit any specific properties of the KPF and could potentially be applied to other 0–1 problems, such as the minimum vertex cover problem or the facility location problem, without significant modifications. Additionally, the method’s simplicity makes it suitable for hybridization with other metaheuristic approaches or the incorporation of specific KPF properties to improve its performance.},
  archive      = {J_COR},
  author       = {Raka Jovanovic and Stefan Voß},
  doi          = {10.1016/j.cor.2024.106685},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106685},
  shortjournal = {Comput. Oper. Res.},
  title        = {Fixed set search matheuristic applied to the knapsack problem with forfeits},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A large population island framework for the unconstrained
binary quadratic problem. <em>COR</em>, <em>168</em>, 106684. (<a
href="https://doi.org/10.1016/j.cor.2024.106684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unconstrained binary quadratic problem is an NP-hard problem and has applications in many fields. Recently, the problem has attracted much interest in the field of quantum optimization, as it is directly related to the Ising problem in physics and the development of quantum computers. However, effectively solving large instances of this problem remains a major challenge for existing solution methods. To advance the state of the art in solving the problem on a large scale, we propose an evolutionary algorithm with a very large population organized in different islands and integrating a new pairing and recombination method to produce promising offspring in each generation. Numerous experiments are conducted to evaluate the effects of different pairing strategies, crossovers, and migration topologies. This research has led to the discovery of new bounds for difficult instances of the maximum cut problem, which has been transformed using the binary quadratic formulation.},
  archive      = {J_COR},
  author       = {Olivier Goudet and Adrien Goëffon and Jin-Kao Hao},
  doi          = {10.1016/j.cor.2024.106684},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106684},
  shortjournal = {Comput. Oper. Res.},
  title        = {A large population island framework for the unconstrained binary quadratic problem},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep reinforcement learning for multi-objective game
strategy selection. <em>COR</em>, <em>168</em>, 106683. (<a
href="https://doi.org/10.1016/j.cor.2024.106683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective game (MOG) is a fundamental model for the decision-making problems in which each player must consider multi-dimensional payoffs that reflect different objectives. Typically, solving MOG involves refining the set of equilibrium strategies, which is also known as MOG strategy selection (MOGS). However, existing MOG algorithms only allow one metric for MOGS, which limits the application in real-world scenarios where the players may have different preferences over multiple metrics. In this paper, we first develop a preference-based MOGS framework to encompass multiple metrics with different preferences in MOGS. Based on the framework, we introduce the concept of comprehensive evaluation value (CEV) to evaluate the quality of a strategy set given the preference of each metric. Using CEV as a reward signal, we formulate the problem of finding the optimal strategy set as a Markov decision process, and use deep reinforcement learning to train a policy for MOG strategy selection given the metrics and the corresponding preferences. Specifically, we combine a rational strategy filtering procedure with a Transformer-based encoder–decoder policy network to refine the strategies given the preferences, and then we use a revised REINFORCE algorithm to train the policy network. Besides, we introduce variable beam search decoding to improve the quality of a rollout by keeping track of the most promising strategy sets and choosing the best one. We benchmark our algorithm on the MOG instances generated by GAMUT, and extensive experiments demonstrate that our algorithm can generate the strategy set significantly better than the state-of-the-art baselines with lower computational overhead given different preferences. Furthermore, we compare our approach on real-world problems, showing the great advantages in both performance and runtime.},
  archive      = {J_COR},
  author       = {Ruhao Jiang and Yanchen Deng and Yingying Chen and He Luo and Bo An},
  doi          = {10.1016/j.cor.2024.106683},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106683},
  shortjournal = {Comput. Oper. Res.},
  title        = {Deep reinforcement learning for multi-objective game strategy selection},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving euclidean max-sum problems exactly with cutting
planes. <em>COR</em>, <em>168</em>, 106682. (<a
href="https://doi.org/10.1016/j.cor.2024.106682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies binary quadratic programs in which the objective is defined by the maximisation of a Euclidean distance matrix, subject to a general polyhedral constraint set. This class of nonconcave maximisation problems, which we refer to as the Euclidean Max-Sum problem, includes the capacitated, generalised and max-sum diversity problems as special cases. Due to the nonconcave objective, traditional cutting plane algorithms are not guaranteed to converge globally. In this paper, we introduce two exact cutting plane algorithms to address this limitation. The new algorithms remove the need for a concave reformulation, which is known to significantly slow down convergence. We establish exactness of the new algorithms by examining the concavity of the quadratic objective in a given direction, a concept we refer to as directional concavity . Numerical results show that the algorithms outperform other exact methods for benchmark diversity problems (capacitated, generalised and max-sum), and can easily solve problems of up to three thousand variables.},
  archive      = {J_COR},
  author       = {Hoa T. Bui and Sandy Spiers and Ryan Loxton},
  doi          = {10.1016/j.cor.2024.106682},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106682},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving euclidean max-sum problems exactly with cutting planes},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inverse optimization in semi-definite programs to impute
unknown constraint matrices. <em>COR</em>, <em>168</em>, 106681. (<a
href="https://doi.org/10.1016/j.cor.2024.106681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a typical (forward) optimization problem, a decision-maker uses given values of model parameters to compute the values of decision variables. The goal in inverse optimization (IO) is instead to infer parameters that render given values of decision variables optimal. Most papers on IO utilize duality to impute objective function parameters. A corresponding literature for imputing constraint parameters is essentially non-existent, even for linear programs. The difficulty is that these IO problems include nonconvex bilinear constraints and/or objectives. We study inverse semi-definite programs (SDPs) where matrices on the left-hand-sides of constraints are unknown. These unknown matrices must satisfy some side constraints. We consider two types of such problems, depending on which SDP decision variable values are given: primal or dual. In each situation, we study three sub-cases based on whether both the right-hand-side coefficients and the objective function matrix are known or only one of these two is known. This creates six variants of the inverse problem. For each variant, we first look for sufficient conditions, either on the side constraints or on problem structure, under which the nonconvex bilinear inverse problem can be simplified substantially. In particular, it either has a trivial solution or can be reformulated as a (set of) convex program(s). When such conditions are not evident, we propose three tailored heuristics called the Convex–Concave Procedure, Sequential Semi-definite Programming, and Alternate Convex Search. We perform computational experiments to gain insights into the performance of these three methods.},
  archive      = {J_COR},
  author       = {Zahra Ghatrani and Archis Ghate},
  doi          = {10.1016/j.cor.2024.106681},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106681},
  shortjournal = {Comput. Oper. Res.},
  title        = {Inverse optimization in semi-definite programs to impute unknown constraint matrices},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Autonomous data detection and inspection with a fleet of
UAVs. <em>COR</em>, <em>168</em>, 106678. (<a
href="https://doi.org/10.1016/j.cor.2024.106678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider an area of interest A A , where a set of n n sites lie. Two kinds of information can be captured from each site: light and heavy information. A fleet of m m homogeneous UAVs, each one equipped with a battery B B , is available at a common depot, where the flight mission of each UAV starts and finishes. The problem we consider focuses on a single flight of the fleet of UAVs and aims at collecting their light information from all sites (that can be retrieved, not necessarily passing over each site, but simply “close” to it). At the same time, the fleet will have to select a limited number of sites from which to collect their heavy information. Flying among sites and acquiring information from them (both light and heavy) has a battery cost. On the other hand, a profit is associated with the action of acquiring heavy information from a site. We refer to the extraction of light and heavy information from a site as to weakly or strongly cover the site. The aim of the problem consists of retrieving light information from all sites while maximizing the overall profit, keeping the battery consumption of each UAV within B B . In this paper, we model this real-life situation as a new combinatorial optimization problem that we call m3DIP, for which we provide a mixed integer programming model. Given the high degree of complexity of the problem, in this way we are not able to provide a solution in a reasonable time. To address larger instances we propose a matheuristic in which we exploit a path-based algorithm filled with only a subset of feasible cycles (paths) provided by different heuristics. The output indicates which path to select and the set of nodes to be strongly and weakly covered by each trip. We compare our matheuristic with the results obtained by every single heuristic on a large set of instances, showing that the matheuristic strongly outperforms them. An interesting insight is that even paths provided by a heuristic with very bad performances can be useful if combined with paths provided by other heuristics and if the coverage decisions are reoptimized by the matheuristic. We also show the benefit of adding fictitious additional points that UAVs can visit to weakly cover a subset of sites, without actually visiting none of them.},
  archive      = {J_COR},
  author       = {Tiziana Calamoneri and Federico Corò and Simona Mancini},
  doi          = {10.1016/j.cor.2024.106678},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106678},
  shortjournal = {Comput. Oper. Res.},
  title        = {Autonomous data detection and inspection with a fleet of UAVs},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficiently routing a fleet of autonomous vehicles in a
real-time ride-sharing system. <em>COR</em>, <em>168</em>, 106668. (<a
href="https://doi.org/10.1016/j.cor.2024.106668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of new communication technologies (e.g., smartphone) and autonomous vehicles (AVs) is enabling real-time ride-sharing systems where the travel requests arrives in the system on very short notice or even en-route, i.e., when AVs are already serving other users. Each request specifies an origin, a destination and a time window of pick-up, and must be immediately either accepted or rejected. Each request accepted must be assigned to an AV and both scheduled and inserted in its route considering the other possible requests already assigned to the same AV. In a lexicographic way, first we want to maximize the total number of new requests accepted, then we want to minimize the total traveled distance and finally, the total time of serving the requests. The problem is formulated as a Mixed Integer Linear Program and solved by a rolling horizon approach (MILP-RH). To efficiently address medium/large-sized instances, a rolling horizon Local Search (RHLS) is also designed, with moves properly tailored for the problem Numerical comparisons show that, on both the small-sized and some medium-sized instances, the RHLS outperforms the MILP-RH concerning the total computational time. Instead, on some medium-sized and on the large-sized instances, the RHLS is the only viable method since the MILP-RH is not able to even find a feasible solution in the given time limit. A sensitivity analysis on possible variation of some parameters is also performed deriving some useful managerial insights.},
  archive      = {J_COR},
  author       = {M. Bruglieri and R. Peruzzini and O. Pisacane},
  doi          = {10.1016/j.cor.2024.106668},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {106668},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficiently routing a fleet of autonomous vehicles in a real-time ride-sharing system},
  volume       = {168},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparative cost assessment of coalescing epidemic control
strategies in heterogeneous social-contact networks. <em>COR</em>,
<em>167</em>, 106680. (<a
href="https://doi.org/10.1016/j.cor.2024.106680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outcome of an epidemic is contingent upon the mitigating control strategies deployed by policymakers. The deployment of control strategies is constrained by the cost of economic, social, and technological factors, which often depend on regional conditions. Our model facilitates a comparative assessment of costs between two interconnected subpopulations within a heterogeneous social-contact network, which may deploy either aligned or divergent control strategies, as is frequently the case for neighboring countries. Depending on their respective asymmetric resources, each subpopulation can deploy a contact confinement strategy, a vaccination strategy, or a hybrid of both. The multi-objective goal of minimizing both the epidemic burden and the economic cost from policy implementation and productivity losses is compounded using a scaled scalarization method. Due to the inter-dependence of policy outcomes, the optimal strategy is derived from the Nash equilibrium in a 2-player compounded pay-off matrix of the total cost. Our network-based model implements a probabilistic Susceptible-Exposed-Infectious-Recovered-Dead dynamics. It also includes the effects of ego-network support and waning immunity modulated by re-exposure to viral contaminants (‘SEIRSD’). Robust outcomes of repeated network simulations with COVID-19 parameters are examined. Our method aims to equip policymakers in a negotiation process with a comparative cost matrix for divergent mitigation policies and to identify the optimal Nash-based strategy profile.},
  archive      = {J_COR},
  author       = {Jan B. Broekaert and Davide La Torre and Faizal Hafiz and Marco Repetto},
  doi          = {10.1016/j.cor.2024.106680},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106680},
  shortjournal = {Comput. Oper. Res.},
  title        = {A comparative cost assessment of coalescing epidemic control strategies in heterogeneous social-contact networks},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A MaxSAT approach for solving a new dynamic discretization
discovery model for train rescheduling problems. <em>COR</em>,
<em>167</em>, 106679. (<a
href="https://doi.org/10.1016/j.cor.2024.106679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Train scheduling is a critical activity in rail traffic management, both off-line (timetabling) and on-line (dispatching). Time-Indexed formulations for scheduling problems are stronger than other classical formulations, like Big- M M . Unfortunately, their size grows usually very large with the size of the scheduling instance, making even the linear relaxation hard to solve. Moreover, the approximation introduced by time discretization can lead to solutions which cannot be realized in practice. Dynamic Discretization Discovery (DDD), recently introduced by Boland et al. (2017) for the continuous-time service network design problem, is a technique to keep at bay the growth of Time-Indexed formulations and their response times and, at the same time, ensures the necessary modelling precision. By exploiting the DDD paradigm, we develop a novel approach to train dispatching and, more in general, to job-shop scheduling. The algorithm implemented represents the first application of a Maximum SATisfiability problem approach to the field. In our comparisons on real-life instances of train dispatching, our restricted Time-Indexed formulation solves faster on piece-wise constant objective functions, while the Big- M M approach maintains the lead on linear continuous objectives.},
  archive      = {J_COR},
  author       = {Anna Livia Croella and Bjørnar Luteberget and Carlo Mannino and Paolo Ventura},
  doi          = {10.1016/j.cor.2024.106679},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106679},
  shortjournal = {Comput. Oper. Res.},
  title        = {A MaxSAT approach for solving a new dynamic discretization discovery model for train rescheduling problems},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A variational inequality formulation for stochastic user
equilibrium with a bounded choice set. <em>COR</em>, <em>167</em>,
106677. (<a href="https://doi.org/10.1016/j.cor.2024.106677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops a variational inequality (VI) formulation for the stochastic user equilibrium with a bounded choice set, known as the bounded choice model (BCM). A novel mapping is devised to facilitate the development of the VI formulation. The VI formulation offers a new avenue for analysing and solving the BCM. It is shown that all paths in the considered choice set should have an equal mapping at the optimal solution, which resembles the equilibrated travel cost in the user equilibrium (UE). The new formulation has two algorithmic benefits. First, an algorithm that solves a VI problem (i.e., the extragradient method) can outperform the method of successive averages (MSA) in large networks under a UE-type convergent measurement. Second, it is possible to avoid the column reduction procedure when finding the choice set that satisfies the BCM requirement because a projection-type algorithm that solves the VI formulation can assign zero flow to a path. This is more efficient than the MSA, which uses diminishing step sizes to update solutions over iterations, leading to a sublinear rate of convergence and small residual flows on paths that should carry zero flows. Numerical experiments are conducted to demonstrate the properties of the model and compare the performance of different algorithms using the Sioux Falls, Eastern Massachusetts, and Anaheim networks.},
  archive      = {J_COR},
  author       = {Yu Jiang},
  doi          = {10.1016/j.cor.2024.106677},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106677},
  shortjournal = {Comput. Oper. Res.},
  title        = {A variational inequality formulation for stochastic user equilibrium with a bounded choice set},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Collaborative optimization of routing and storage strategy
of multi-period multimodal transport in an uncertain environment.
<em>COR</em>, <em>167</em>, 106676. (<a
href="https://doi.org/10.1016/j.cor.2024.106676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study uses a storage service strategy to investigate a multiperiod multimodal transport routing and transit planning problem (MPMT-RTP). First, a mathematical integer programming model is used to describe the problem in a deterministic environment. Second, two robust optimization models are established to address the uncertainty of the freight rate fluctuations in each period and the storage space in the total set, thereby improving the solving efficiency of the model through a robust equation transformation. Subsequently, hybrid heuristics are proposed to solve the above problems, and a series of small-scale experiments are conducted to verify the accuracy of the model and effectiveness of the algorithm. Finally, this study conducts case experiments based on survey data. The results show that the total operating cost is reduced by 13.31 % via strategic multiperiod multimodal transport planning. A price fluctuation study shows that under different price fluctuations, the transportation and storage periods of some orders change accordingly, and under three specific price fluctuations, the operating costs are 1085100, 967330, and 948770, respectively. Therefore, the results of this study can provide theoretical guidance for enterprises to optimize their resource allocation paradigms and better adapt to freight rate fluctuations to minimize their operating costs.},
  archive      = {J_COR},
  author       = {Fang Guo and Yan Xu and Zhihong Huang and Yunxiang Wu},
  doi          = {10.1016/j.cor.2024.106676},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106676},
  shortjournal = {Comput. Oper. Res.},
  title        = {Collaborative optimization of routing and storage strategy of multi-period multimodal transport in an uncertain environment},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benders decomposition algorithms for minimizing the spread
of harmful contagions in networks. <em>COR</em>, <em>167</em>, 106675.
(<a href="https://doi.org/10.1016/j.cor.2024.106675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has been a recent example for the spread of a harmful contagion in large populations. Moreover, the spread of harmful contagions is not only restricted to an infectious disease, but is also relevant to computer viruses and malware in computer networks. Furthermore, the spread of fake news and propaganda in online social networks is also of major concern. In this study, we introduce the measure-based spread minimization problem (MBSMP), which can help policy makers in minimizing the spread of harmful contagions in large networks. We develop exact solution methods based on branch-and-Benders-cut algorithms that make use of the application of Benders decomposition method to two different mixed-integer programming formulations of the MBSMP: an arc-based formulation and a path-based formulation. We show that for both formulations the Benders optimality cuts can be generated using a combinatorial procedure rather than solving the dual subproblems using linear programming. Additional improvements such as using scenario-dependent extended seed sets, initial cuts, and a starting heuristic are also incorporated into our branch-and-Benders-cut algorithms. We investigate the contribution of various components of the solution algorithms to the performance on the basis of computational results obtained on a set of instances derived from existing ones in the literature.},
  archive      = {J_COR},
  author       = {Kübra Tanınmış and Necati Aras and Evren Güney and Markus Sinnl},
  doi          = {10.1016/j.cor.2024.106675},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106675},
  shortjournal = {Comput. Oper. Res.},
  title        = {Benders decomposition algorithms for minimizing the spread of harmful contagions in networks},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved MOEA/d for multi-objective flexible job shop
scheduling by considering efficiency and cost. <em>COR</em>,
<em>167</em>, 106674. (<a
href="https://doi.org/10.1016/j.cor.2024.106674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve cost reduction and efficiency improvement in the production process of the aerospace industry, this study establishes a mathematical model for the multi-objective flexible job shop scheduling problem (MOFJSP). The model comprehensively considers four optimisation objectives: completion time, tool number, machine load, and machine energy consumption. For solving the MOFJSP, an improved MOEA/D (IMOEA/D) algorithm is proposed. To improve the quality of solutions, the algorithm introduces another global update strategy in addition to the original substitution operation. The population is initialised using four allocation rules, and the neighbourhood is dynamically updated based on the degree of population evolution. The simulation results on a single instance indicate that the simulation time of IMOEA/D has decreased by 10.5% and machine energy consumption has reduced by 9.5%. Moreover, when compared to various classic multi-objective algorithms on 25 benchmark instances, the IMOEA/D algorithm achieved optimal results in 19 instances for inverted generational distance comparisons, 15 instances for hypervolume comparisons and nearly all instances for set coverage comparisons. The results reveal that the proposed IMOEA/D is effective and competitive in solving MOFJSP.},
  archive      = {J_COR},
  author       = {Biao Xiao and Zhengcai Zhao and Yingchen Wu and Xialin Zhu and Shixin Peng and Honghua Su},
  doi          = {10.1016/j.cor.2024.106674},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106674},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved MOEA/D for multi-objective flexible job shop scheduling by considering efficiency and cost},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerated benders decomposition and local branching for
dynamic maximum covering location problems. <em>COR</em>, <em>167</em>,
106673. (<a href="https://doi.org/10.1016/j.cor.2024.106673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum covering location problem (MCLP) is a key problem in facility location, with many applications and variants. One such variant is the dynamic (or multi-period) MCLP, which considers the installation of facilities across multiple time periods. To the best of our knowledge, no exact solution method has been proposed to tackle large-scale instances of this problem. To that end, in this work, we expand upon the current state-of-the-art branch-and-Benders-cut solution method in the static case, by exploring several acceleration techniques. Additionally, we propose a specialised local branching scheme which exploits the separability of the problem by time period. This scheme uses a novel distance metric in its definition of subproblems and features a new method for efficient and exact solving of the subproblems. These methods are then compared through extensive computational experiments, highlighting the strengths of the proposed methodologies.},
  archive      = {J_COR},
  author       = {Steven Lamontagne and Margarida Carvalho and Ribal Atallah},
  doi          = {10.1016/j.cor.2024.106673},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106673},
  shortjournal = {Comput. Oper. Res.},
  title        = {Accelerated benders decomposition and local branching for dynamic maximum covering location problems},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Facility location decisions for drone delivery with riding:
A literature review. <em>COR</em>, <em>167</em>, 106672. (<a
href="https://doi.org/10.1016/j.cor.2024.106672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive literature survey on facility location problems for drone (uncrewed vehicle) delivery in situations where drones can ride in or on other vehicles. This includes facilities visited by only one type of vehicle, as well as facilities visited by both drones and other vehicles. Unlike traditional facility location problems for delivery systems with one vehicle type, hybrid vehicle-drone delivery systems usually require determining locations where the two vehicle types meet and separate. The main goals of this paper are to review the large volume of drone delivery literature with riding from a facility location perspective to provide a connection between the studies from different research areas that cover similar problems, and to highlight future research directions in this area. We first review the functions of drones, including aerial and ground drones, and the different types of facilities used for hybrid vehicle-drone delivery systems. The literature is categorized based on the presence of resupply operations, the locations of drone launch and retrieval points, the types of drones (aerial or ground) and the location space (discrete or continuous). Each category is analyzed in terms of the modeling approach, decision(s), objective function(s), constraints and additional features. The paper concludes with promising future research directions.},
  archive      = {J_COR},
  author       = {Okan Dukkanci and James F. Campbell and Bahar Y. Kara},
  doi          = {10.1016/j.cor.2024.106672},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106672},
  shortjournal = {Comput. Oper. Res.},
  title        = {Facility location decisions for drone delivery with riding: A literature review},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-level capacitated arc routing problem with
intermediate facilities in waste collection. <em>COR</em>, <em>167</em>,
106671. (<a href="https://doi.org/10.1016/j.cor.2024.106671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates a multi-level capacitated arc routing problem for waste collection with two levels of intermediate facilities: huts and transfer stations. The problem aims to implement integrated optimisation of the intermediate facilities and find optimal routes for a fleet consisting of manually operated vehicles and vehicles with compressors. We first build an integer linear programming model to address this problem. Then, we propose an extended adaptive large neighbourhood search (E-ALNS) approach, including a tailored Shake procedure inspired by variable neighbourhood search to effectively solve this problem. Computational experiments were conducted on 264 instances generated using existing benchmarks. Compared to commercial optimisation software and other algorithms, our extended algorithm exhibits superior performance for this problem. The results also demonstrate that the integrated optimisation of intermediate facilities significantly decreases the total cost compared to separate optimisations.},
  archive      = {J_COR},
  author       = {Chenge Wei and Sanne Wøhlk and Ada Che},
  doi          = {10.1016/j.cor.2024.106671},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106671},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-level capacitated arc routing problem with intermediate facilities in waste collection},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Decomposition algorithms for the robust unidirectional quay
crane scheduling problems. <em>COR</em>, <em>167</em>, 106670. (<a
href="https://doi.org/10.1016/j.cor.2024.106670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our study focuses on a two-stage robust optimization model for the unidirectional quay crane scheduling problem with uncertain handling times at container terminals. We first implement two classical algorithms adopted in Li and Zhang (2021), the Benders decomposition algorithm and the column-and-constraint generation algorithm, to solve the robust model. Based on analytical and numerical comparisons of them, we design an exact hybrid algorithm to leverage capabilities of both algorithms by alternatively adding cuts of both kinds. Extensive experiments validate the effectiveness of this mechanism. Numerical experiments also reveal that the benefit and the cost of robustness fade away as the uncertainty budget increases and highlight the advantage of our robust approach to deal with uncertainty over a two-stage stochastic program under extreme situations.},
  archive      = {J_COR},
  author       = {Yitian Li and Xinyi Li and Canrong Zhang and Tao Wu},
  doi          = {10.1016/j.cor.2024.106670},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106670},
  shortjournal = {Comput. Oper. Res.},
  title        = {Decomposition algorithms for the robust unidirectional quay crane scheduling problems},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The static ridesharing routing problem with flexible
locations: A norwegian case study. <em>COR</em>, <em>167</em>, 106669.
(<a href="https://doi.org/10.1016/j.cor.2024.106669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The municipalities in the Bergen region in Norway have recently announced a pilot project for ridesharing in the region as a means to reduce traffic congestion. As part of this project, we study the Static Ridesharing Routing Problem with Flexible Locations (SRRPFL), which aims at determining efficient routes and schedules for a set of drivers to pick up and deliver passengers at different, flexible pickup and delivery locations. We present a bi-objective mixed integer programming (MIP) model for the SRRPFL where we (lexicographically) first maximize the number of passengers serviced and then minimize the total travel times. To solve real-life instances of the SRRPFL, we propose a new Adaptive Large Neighborhood Search (ALNS) heuristic. To further improve its performance, we extend the ALNS heuristic with a local search, as well as with a set partitioning problem (denoted the Route Combination Problem) that optimally recombines the routes previously encountered in the search. The ALNS heuristic is tested on a number of test instances based on real trip data and the results demonstrate its effectiveness. The results also provide a number of insights regarding the potential benefits of ridesharing in our case study.},
  archive      = {J_COR},
  author       = {Jacob Nitter and Shusheng Yang and Kjetil Fagerholt and Andreas Breivik Ormevik},
  doi          = {10.1016/j.cor.2024.106669},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106669},
  shortjournal = {Comput. Oper. Res.},
  title        = {The static ridesharing routing problem with flexible locations: A norwegian case study},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The joint maintenance operation selection and technician
routing problem. <em>COR</em>, <em>167</em>, 106667. (<a
href="https://doi.org/10.1016/j.cor.2024.106667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous studies have explored the challenge of optimizing maintenance grouping, aiming to efficiently manage maintenance resources and reduce costs associated with various maintenance opportunities. Maintenance grouping is even more important when the systems to maintain are geographically distributed because it significantly reduces travel costs. In this research, we tackle a novel problem that integrates condition-based maintenance with the selection of maintenance operations and technician routing. The problem involves the selection of machines requiring maintenance for each time period, determining the nature of required operations (based on the uncertain degradation state of the machines), selecting suitable technicians based on their skills and availability, and planning their routes. We formulate this problem as a mixed-integer program and propose a heuristic approach for its solution. Our method constructs a solution by iteratively adding maintenance operations to technician routes. To assess the method’s performance, we conduct experiments that evaluate both running times and solution quality.},
  archive      = {J_COR},
  author       = {Florian Delavernhe and Bruno Castanier and Christelle Guéret and Jorge E. Mendoza},
  doi          = {10.1016/j.cor.2024.106667},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106667},
  shortjournal = {Comput. Oper. Res.},
  title        = {The joint maintenance operation selection and technician routing problem},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust ordered weighted averaging loss model for portfolio
optimization. <em>COR</em>, <em>167</em>, 106666. (<a
href="https://doi.org/10.1016/j.cor.2024.106666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we will propose a Robust Ordered Weighted Averaging (ROWA) optimization model to find a portfolio according to different attitudes towards risk of a decision maker. The rationale of our model is supported by the idea of measuring risk through conditional means of losses from a database of past returns. The way in which these means of extreme losses affect to the final decision may be different according to the risk perception of the decision maker ( scenarios ). In this context, a compromise portfolio is identified to reconcile the admisible risk attitudes of a decision maker according to different paradigms. We will also link the robustness of the proposed solution with its efficiency from a multi-criterion decision making viewpoint ( Pareto optimality ). Both concepts have been connected previously in the literature in different contexts. The paper ends with an extensive numerical experiment in order to check the applicability of our model to real data on six financial markets.},
  archive      = {J_COR},
  author       = {Stefano Benati and Eduardo Conde},
  doi          = {10.1016/j.cor.2024.106666},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106666},
  shortjournal = {Comput. Oper. Res.},
  title        = {A robust ordered weighted averaging loss model for portfolio optimization},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A stabilised benders decomposition with adaptive oracles for
large-scale stochastic programming with short-term and long-term
uncertainty. <em>COR</em>, <em>167</em>, 106665. (<a
href="https://doi.org/10.1016/j.cor.2024.106665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benders decomposition with adaptive oracles was proposed to solve large-scale optimisation problems with a column-bounded block-diagonal structure, where subproblems differ only in the right-hand side and cost coefficients. Adaptive Benders reduces computational effort significantly by iteratively building inexact cutting planes and valid upper and lower bounds. However, Adaptive Benders and standard Benders may suffer severe oscillation when solving degenerate models. Therefore, we propose stabilising Adaptive Benders with the level method and adaptively selecting which subproblems to solve each iteration for more accurate information. In addition, we propose a dynamic level method to improve the robustness of stabilised Adaptive Benders by adjusting the level set each iteration. We compare stabilised Adaptive Benders with the unstabilised versions of Adaptive Benders with one subproblem solved per iteration and standard Benders on a multi-region long-term power system investment planning problem with short-term and long-term uncertainty. The problem is formulated as multi-horizon stochastic programming. Four algorithms were implemented to solve linear programming with up to 1 billion variables and 4.5 billion constraints. The computational results show that: (a) for a 1.00% convergence tolerance, the proposed stabilised method is up to 113.7 times faster than standard Benders and 2.1 times faster than unstabilised Adaptive Benders; (b) for a 0.10% convergence tolerance, the proposed stabilised method is up to 45.5 times faster than standard Benders and unstabilised Adaptive Benders cannot solve the largest instance to convergence tolerance due to severe oscillation and (c) dynamic level method makes stabilisation more robust.},
  archive      = {J_COR},
  author       = {Hongyu Zhang and Nicolò Mazzi and Ken McKinnon and Rodrigo Garcia Nava and Asgeir Tomasgard},
  doi          = {10.1016/j.cor.2024.106665},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106665},
  shortjournal = {Comput. Oper. Res.},
  title        = {A stabilised benders decomposition with adaptive oracles for large-scale stochastic programming with short-term and long-term uncertainty},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A skyline-based heuristic for orthogonal packing rectangles
in a circle. <em>COR</em>, <em>167</em>, 106664. (<a
href="https://doi.org/10.1016/j.cor.2024.106664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of orthogonal packing rectangles in a circle (OPRC), which requires finding a subset of rectangles that can be packed into a circular container to maximize the area or the number of packed items. The skyline is widely used for the rectangle packing problem (RPP) due to its simplicity and efficiency in checking the feasibility and evaluation of placement. Several skyline-based best-fit heuristics have been introduced and obtained the best results for the RPP. The only difference between the OPRC and RPP is that the container in RPP is a rectangle, while that in OPRC is a circle. It is still an open question whether the skyline could be used to solve the OPRC. The initialization, skyline update method, and fitness function must be carefully designed due to the circle boundary. This paper adapts the skyline for the first time to solve the OPRC. It proposes a skyline-based heuristic consisting of a greedy approach to generate the initial skyline, several rules to update the skyline, and a best-fit function to select and pack the rectangle iteratively according to a given sequence of rectangles. Then, it employs the variable neighborhood search algorithm consisting of two shaking and three local search operators to improve the solution. The benchmark instances’ results show the proposed approach’s effectiveness and efficiency, improving the best-known solutions for most (24 out of 27 for maximizing area and 25 out of 27 for maximizing the number) large-scale instances within less computing time.},
  archive      = {J_COR},
  author       = {Tai Zhang and Runqin Wang and Hao Zhang and Qiang Liu and Lijun Wei},
  doi          = {10.1016/j.cor.2024.106664},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106664},
  shortjournal = {Comput. Oper. Res.},
  title        = {A skyline-based heuristic for orthogonal packing rectangles in a circle},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Route recombination for deterministic and non-deterministic
orienteering problems with time windows: A dynamic programming approach.
<em>COR</em>, <em>167</em>, 106663. (<a
href="https://doi.org/10.1016/j.cor.2024.106663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the Orienteering Problem with Time Windows (OPTW) where the goal is to visit customers within available time windows while maximizing the total reward provided by successive customer visits. For this problem, we introduce a new route recombination procedure that takes a set of solutions as input and returns the best combination containing at most k subsequences of customer visits from these solutions. This route recombination procedure is based on a dynamic programming algorithm enhanced with pruning strategies that can significantly reduce the size of the search space. It is also able to deal with time-dependent transition times. The experiments show that the algorithm proposed can be used as a lightweight and efficient post-optimization procedure working on elite solutions provided by a standard incomplete OPTW solver. Moreover, it can be used in a non-deterministic context where the reward values are not precisely known in advance; in this case, OPTW solutions can be first generated for various reward scenarios during an offline phase, and then combined during an online phase to quickly get a high-quality solution given the last-known reward values.},
  archive      = {J_COR},
  author       = {Trong-Hieu Tran and Cédric Pralet and Hélène Fargier},
  doi          = {10.1016/j.cor.2024.106663},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106663},
  shortjournal = {Comput. Oper. Res.},
  title        = {Route recombination for deterministic and non-deterministic orienteering problems with time windows: A dynamic programming approach},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variable neighbourhood search based on metropolis criterion
for crowdsourced delivery scheduling problem in dispatch model.
<em>COR</em>, <em>167</em>, 106662. (<a
href="https://doi.org/10.1016/j.cor.2024.106662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing demand for last-mile delivery, primarily because of booming e-commerce and online-to-offline industries, crowdsourced delivery has been playing a more important role. This study explores the crowdsourcing delivery scheduling problem in dispatch mode (CDSPDM), which is a combination of order allocation and path planning. CDSPDM is a new combinatorial optimisation problem. Herein, a variable neighbourhood search based on the Metropolis criterion (VNSMC) is proposed to solve CDSPDM. The proposed VNSMC is a variant of fixed neighbourhood search (FNS) that incorporates the idea of the simulated annealing algorithm (SA), whereby a new solution using the Metropolis criterion is obtained to enhance the exploration capability of the solution space. In VNSMC, a shaking procedure based on order reassignment is proposed to expand the search scope of the solution space. Thereafter, a local search based on the combination of two local search operators is conducted to obtain local optimal solutions, and the branch-and-bound method is used to plan the travel routes for each rider. To evaluate the performance of the proposed VNSMC for CDSPDM, a genetic algorithm (GA) was adapted to the state-of-the-art CDSPDM. Consequently, a fixed neighbourhood search algorithm without the Metropolis criterion, and a simulated annealing algorithm that uses the two proposed local search operators were developed to solve the CDSPDM. The experimental results showed that the proposed VNSMC obtains better solutions than the adapted GA, FNS, and SA for CDSPDM.},
  archive      = {J_COR},
  author       = {Fanchao Meng and Xuequan Zhou and Xuefeng Piao and Dianhui Chu},
  doi          = {10.1016/j.cor.2024.106662},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106662},
  shortjournal = {Comput. Oper. Res.},
  title        = {Variable neighbourhood search based on metropolis criterion for crowdsourced delivery scheduling problem in dispatch model},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The pollution traveling salesman problem with refueling.
<em>COR</em>, <em>167</em>, 106661. (<a
href="https://doi.org/10.1016/j.cor.2024.106661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the Pollution Traveling Salesman Problem with Refueling, a novel optimization problem which integrates two recently proposed variants of the Traveling Salesman Problem: the Pollution Traveling Salesman Problem and the Traveling Salesman Problem with Refueling. The proposed problem captures the operational dynamics of a real-world routing scenario involving a single vehicle originating from a central depot and delivering products to end customers. When considering the vehicle’s fuel tank capacity and fuel consumption during the routing process, the need to visit fuel stations for refueling arises. To address this complex problem, a new mixed integer linear programming model was developed, and the Gurobi solver was employed to solve smaller instances. For the effective resolution of larger practical problem cases, a two-stage double adaptive general variable neighborhood search method was proposed. The proposed methodology exhibits comparable efficiency to a commercial solver, demonstrating notably low execution time requirements. To further assess its performance, a comparative study was conducted on TSPLib instances. In comparison to various solution approaches documented in the open literature, encompassing both Variable Neighborhood Search-based and alternative methods, our proposed approach consistently yields highly competitive results within low execution times.},
  archive      = {J_COR},
  author       = {Panagiotis Karakostas and Angelo Sifaleras},
  doi          = {10.1016/j.cor.2024.106661},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106661},
  shortjournal = {Comput. Oper. Res.},
  title        = {The pollution traveling salesman problem with refueling},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-period vaccines supply chain network design with
capacity expansion and different replenishment cycles under uncertain
demand. <em>COR</em>, <em>167</em>, 106660. (<a
href="https://doi.org/10.1016/j.cor.2024.106660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The World Health Organization (WHO) proposes guidelines for vaccine distribution networks that incorporate economic order quantity and risk pooling principles, specifically through implementing different replenishment cycles between different levels of the distribution network. The substantial impact of different replenishment cycles on inventory levels is demonstrated in the existing literature. However, current optimization network design research has paid limited attention to this aspect. This article aims to address this research gap by investigating a two-stage stochastic programming for a multi-period perishable vaccine network design problem, taking into account the different replenishment cycles characteristic and capacity expansion under uncertain demand conditions. Given the inherent difficulty of solving the proposed problem, a matheuristic approach based on Variable Neighborhood Search (VNS) is developed. To illustrate the practical application and analyze the impact of uncertain demand, we apply the proposed model and its solution method using the Indonesia dataset in the COVID-19 situation. The computational results indicate that lower replenishment cycles leads to higher inventory levels, total costs, and capacity requirements for the top-level distribution center. Optimum replenishment cycles and further managerial implications and future potential research are also presented.},
  archive      = {J_COR},
  author       = {Paulina Kus Ariningsih and Chandra Ade Irawan and Antony Paulraj and Jing Dai},
  doi          = {10.1016/j.cor.2024.106660},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106660},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-period vaccines supply chain network design with capacity expansion and different replenishment cycles under uncertain demand},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterated variable neighborhood search for integrated
scheduling of additive manufacturing and multi-trip vehicle routing
problem. <em>COR</em>, <em>167</em>, 106659. (<a
href="https://doi.org/10.1016/j.cor.2024.106659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses a novel problem structure for integrated scheduling of additive manufacturing and delivery processes. In the manufacturing process, we consider batch production of parts, simulating Selective Laser Melting technology in parallel additive manufacturing machines with heterogeneous specifications. A batch production, referred to as a build, must consist of parts with homogenous material. During the production run, sequence-dependent material setup times occur in between builds. In the delivery process, parts are delivered in batches using a limited number of homogenous capacitated vehicles. Each vehicle might perform multi-trips. Thus, the route for each trip and departure schedule among trips must be decided. In this regard, batch delivery is independent to batch production. The problem objective function is to minimize the total completion time of all parts. For optimally solving the problem, a mixed-integer linear programming model is devised. To solve larger problems sizes under a lower computation time, an iterated variable neighborhood search algorithm with embedded rule-based heuristics is proposed. The computational experiment denotes that the proposed algorithm with route minimization rule effectively solves small-scale problems, while capacity usage maximization rule performs the best in large-scale problems and outperforms other existing metaheuristics. Further result analysis is also performed to provide managerial insights.},
  archive      = {J_COR},
  author       = {Willy Chandra Sugianto and Byung Soo Kim},
  doi          = {10.1016/j.cor.2024.106659},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106659},
  shortjournal = {Comput. Oper. Res.},
  title        = {Iterated variable neighborhood search for integrated scheduling of additive manufacturing and multi-trip vehicle routing problem},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the three-dimensional open-dimension rectangular
packing problem: A constraint programming model. <em>COR</em>,
<em>167</em>, 106651. (<a
href="https://doi.org/10.1016/j.cor.2024.106651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the three-dimensional open-dimension rectangular packing problem (3D-ODRPP). This problem addresses a set of rectangular boxes of given dimensions and a rectangular container of open dimensions. The objective is to pack all boxes orthogonally into the container while minimizing the container volume. Real-world applications of the 3D-ODRPP arise in production systems with operations of shipping or moving. The literature has presented mainly mixed-integer programming (MIP) formulations and their linearization techniques for the problem allied with general-purpose optimization solvers. To model and solve the 3D-ODRPP, we propose a constraint programming model based on a position-free modeling approach with logic operators. We ran computational experiments to assess the performance of the proposed model compared to the benchmark MIP models from instances of the literature. The results show our approach is competitive in different sets of problem instances in terms of reaching optimality as well as providing satisfactory feasible solutions quickly.},
  archive      = {J_COR},
  author       = {Mateus Martin and Thiago Alves de Queiroz and Reinaldo Morabito},
  doi          = {10.1016/j.cor.2024.106651},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106651},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving the three-dimensional open-dimension rectangular packing problem: A constraint programming model},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrating parcel delivery schedules with public transport
networks in urban co-modality systems. <em>COR</em>, <em>167</em>,
106650. (<a href="https://doi.org/10.1016/j.cor.2024.106650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-modality transportation advocates using urban public transport to support urban freight operations. This study considers the implementation of co-modality in a fixed-route transit network comprising multiple lines following predetermined routes and schedules. We first develop a schedule-based parcel assignment model to formulate the synchronized co-modality transportation problem (SCTP). The effectiveness of the proposed arc-based meta-heuristic algorithm is substantiated through a comprehensive computational analysis, comparing its performance with that of an exact approach and genetic algorithm. Our findings reveal a nuanced trade-off between transportation efficiency and co-modal stop utilization, identifying a threshold beyond which additional stops do not improve efficiency but increase costs. We also discover a &#39;buckets effect&#39; in co-modal capacities, suggesting that balanced vehicle and stop capacities are crucial for optimizing system performance. A case study with real urban transit data validates our model&#39;s potential for significant efficiency gains in co-modality transportation systems, offering actionable insights for urban logistics.},
  archive      = {J_COR},
  author       = {Xuan Yang and Xinyao Nie and Hao Luo and George Q. Huang},
  doi          = {10.1016/j.cor.2024.106650},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106650},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integrating parcel delivery schedules with public transport networks in urban co-modality systems},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A logistics provider’s profit maximization facility location
problem with random utility maximizing followers. <em>COR</em>,
<em>167</em>, 106649. (<a
href="https://doi.org/10.1016/j.cor.2024.106649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a strategic decision-making problem faced by logistics providers (LPs) seeking facility location decisions that lead to profitable operations. The profitability depends on the revenue generated through agreements with shippers, and the costs arising when satisfying these agreements. The latter depends, in turn, on the service levels and characteristics of the shippers’ customers. However, at a strategic level, the LP has imperfect information thereof. We propose a stochastic bilevel formulation where a given LP (leader) anticipates the decisions of shippers (followers) arising from a random utility maximization model. Using a sample average approximation and properties of the associated optimal solutions, we propose a heuristic that can compute high-quality solutions. It is based on a reduced single-level mixed integer linear programming formulation that can be solved by a general-purpose solver after a preprocessing phase. We can quickly identify situations that lead to zero expected profit for the LP. Experimental results show that expected profit highly depends on shippers’ price sensitivities. Underestimating price sensitivities can lead to an overestimation of the expected profit.},
  archive      = {J_COR},
  author       = {David Pinzon Ulloa and Emma Frejinger and Bernard Gendron},
  doi          = {10.1016/j.cor.2024.106649},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106649},
  shortjournal = {Comput. Oper. Res.},
  title        = {A logistics provider’s profit maximization facility location problem with random utility maximizing followers},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling jobs using queries to interactively learn human
availability times. <em>COR</em>, <em>167</em>, 106648. (<a
href="https://doi.org/10.1016/j.cor.2024.106648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution to a job scheduling problem that involves humans as well some other shared resource has to consider the humans’ availability times. For practical acceptance of a scheduling tool, it is crucial that the interaction with the humans is kept simple and to a minimum. It is rarely practical to ask users to fully specify their availability times or to let them enumerate all possible starting times for their jobs. In the scenario we are considering, users initially only propose a single starting time for each of their jobs and a feasible and optimized schedule shall then be found within a small number of interaction rounds. In each such interaction round, our scheduling approach may propose each user a small number of alternative time intervals for scheduling the user’s jobs, and then the user may accept or reject these. To make the best out of these limited interaction possibilities, we propose an approach that utilizes integer linear programming and an exact and computationally efficient probability calculation for the users’ availabilities assuming two different stochastic models. In this way, educated proposals of alternative time intervals for performing the jobs are determined based on the computed availability probabilities and the improvements these time intervals would enable. The approach is experimentally evaluated on a variety of artificial benchmark scenarios, and different variants are compared with each other and to diverse baselines. Results show that an initial schedule can usually be quickly improved over few interaction rounds even when assuming a quite simple stochastic model, and the final schedule may come close to the solution of the full-knowledge case despite the strongly limited interaction.},
  archive      = {J_COR},
  author       = {Johannes Varga and Günther R. Raidl and Elina Rönnberg and Tobias Rodemann},
  doi          = {10.1016/j.cor.2024.106648},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106648},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling jobs using queries to interactively learn human availability times},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Speeding up the passenger assignment problem in transit
planning by the direct link network representation. <em>COR</em>,
<em>167</em>, 106647. (<a
href="https://doi.org/10.1016/j.cor.2024.106647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When designing a public transport network with the passenger travel time in mind, the passenger assignment problem (PAP) needs to be addressed explicitly. It is a complex problem on its own and even the simplest version requires determination of the shortest path for all demand pairs in the network. It is typically treated as a subproblem of larger problems by public transport planners, such as the transit network design problem (TNDP). In the TNDP, bi-level optimization models and/or metaheuristics are used where the PAP is solved when evaluating a line plan. In doing so, the PAP is often addressed by representing the transit network with a so-called ‘Change-and-Go’ (CNG) network with dummy transfer nodes in order to model transfer penalties as part of the passenger travel time. Then, in order to solve the PAP, the all-pairs shortest path problem needs to be solved for this CNG network representation. In this paper, we present a much more efficient network representation, ‘Direct Link Network’ (DLN), where additional edges are added instead of additional nodes. We compare the theoretical complexity of both representations and the computation time required to solve the PAP by using CNG and DLN on the most commonly used benchmark networks and also several real-life networks. The results show that with the DLN representation, the PAP can be solved multiple times faster than with CNG. Consequently, DLN can significantly speed up all TNDP algorithms that solve the PAP multiple times when designing a public transport network.},
  archive      = {J_COR},
  author       = {Dilay Aktaş and Evert Vermeir and Pieter Vansteenwegen},
  doi          = {10.1016/j.cor.2024.106647},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106647},
  shortjournal = {Comput. Oper. Res.},
  title        = {Speeding up the passenger assignment problem in transit planning by the direct link network representation},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dry port hub-and-spoke network design: An optimization
model, solution method, and application. <em>COR</em>, <em>167</em>,
106646. (<a href="https://doi.org/10.1016/j.cor.2024.106646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an innovative bi-objective optimization model for the dry port hub-and-spoke network that considers both the minimization of the total costs and the total amount of carbon emissions. The model is formulated as a two-stage stochastic program due to the uncertain nature of demand. Here, the decision variables include the optimal locations of dry ports, their respective numbers, and their connections, together with the flows of containers. Two types of dry ports are taken into account, where there may be container flows from a relatively small dry port (feeder dry port) to a large dry port (hub dry port). As the problem is NP-hard and practically too complex to solve by an exact method, an efficient hybrid Genetic Algorithm (GA) with interesting ingredients is developed to obtain a promising set of non-dominated solutions. The performance of the proposed methodology is evaluated on a case study of Tianjin Port, China. The computational experiments reveal that the proposed method is promising while providing a useful practical optimization tool that can provide insightful directions for governmental and industrial stakeholders as well as logistic companies on which dry ports can make a suitable addition to their portfolio.},
  archive      = {J_COR},
  author       = {Chandra Ade Irawan and Said Salhi and Dylan Jones and Jing Dai and Martin J. Liu},
  doi          = {10.1016/j.cor.2024.106646},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106646},
  shortjournal = {Comput. Oper. Res.},
  title        = {A dry port hub-and-spoke network design: An optimization model, solution method, and application},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An agent-based simulation framework for emergency
evacuations from toxic gas incidents and an empirical study in taiwan.
<em>COR</em>, <em>167</em>, 106645. (<a
href="https://doi.org/10.1016/j.cor.2024.106645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the event of a large-scale toxic gas incident in an urbanized area, the mass evacuation of people located in the affected area is a highly challenging yet essential measure. We formulate a two-phase agent-based evacuation simulation model informed by real data from the National Science and Technology Center for Disaster Reduction (NCDR) in Taiwan and Aerial Location of Hazardous Atmosphere (ALOHA) software which can be leveraged by disaster management decision makers to bolster preparation and response mechanisms in the context of a toxic gas incident. Both phases of the evacuation simulation framework utilize agent-based rules tailored to manage the risk related to a toxic gas incident. Phase 1 is designed to realistically simulate the movement of pedestrian agents through a cell-based road network from their location in the hot zone or warm zone to a pre-determined set of assembly points to which high capacity public vehicles are dispatched. In Phase 2, the public vehicles also follow natural agent-based rules to select a shelter destination located outside the affected area and then to traverse through the cellular road network from assembly point to shelter. To pre-select an efficacious set of assembly points to be utilized in the event of an actual evacuation, a heuristic based on the k k -means clustering algorithm is designed and implemented. We applied our two-phase agent-based evacuation simulation framework to carry out an empirical study based on a hypothetical massive toxic gas incident in an industrial zone in a large Taiwanese city. The empirical study looks at the effect of several model parameters on the evacuation simulation process, including the choice of assembly point arrangement. Compared to the current government policy, the proposed assembly point arrangement is shown to respectively decrease the average Phase 1 and Phase 2 evacuation times by 22% and 13%, which can be critical in reducing or preventing exposure to harmful levels of toxic gas.},
  archive      = {J_COR},
  author       = {Kuo-Hao Chang and Chien-Chi Hsu and Wen-Ray Su},
  doi          = {10.1016/j.cor.2024.106645},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106645},
  shortjournal = {Comput. Oper. Res.},
  title        = {An agent-based simulation framework for emergency evacuations from toxic gas incidents and an empirical study in taiwan},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A triple bottom line optimization model for assignment and
routing of on-demand home services. <em>COR</em>, <em>167</em>, 106644.
(<a href="https://doi.org/10.1016/j.cor.2024.106644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {‘On-demand home services’ is a fast-growing industry where online platforms match independent service professionals with customers seeking aid for household tasks. In this paper, we study the assignment and routing of service professionals for serving customers of an on-demand home services platform considering the Triple Bottom Line (TBL) criteria for ensuring sustainability in operations. We characterize this as the Home Services Assignment and Routing Problem with the Triple Bottom Line (HSARP-TBL) and implement a Mixed Integer Linear Programming (MILP) model for solving it. We assign service professionals to customers based on their desired time slots and also transport modes for each customer visit by a professional, considering either combinations of public transport or a personal vehicle for each professional’s tour. The objective is to minimize costs due to time window violations and uncovered customers, catering to the economic pillar of the TBL. We incorporate additional constraints related to the TBL by improving customer satisfaction based on the ratings of assigned professionals to customers, with and without subscription (economic), controlling emissions due to transportation of professionals (environmental) and ensuring equity in service allocation and net earnings between professionals (social). For tackling large instances we implement a Hybrid Genetic Search (HGS) algorithm adapting it to our problem setting. We demonstrate that the HGS outperforms the MILP model systematically for large instances in terms of solution value and computational time. Finally, we observe that for some instances, without worsening the primary economic objective, all the TBL indicators can be improved.},
  archive      = {J_COR},
  author       = {Debajyoti Biswas and Laurent Alfandari and Claudia Archetti},
  doi          = {10.1016/j.cor.2024.106644},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106644},
  shortjournal = {Comput. Oper. Res.},
  title        = {A triple bottom line optimization model for assignment and routing of on-demand home services},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Automated placement of analog integrated circuits using
priority-based constructive heuristic. <em>COR</em>, <em>167</em>,
106643. (<a href="https://doi.org/10.1016/j.cor.2024.106643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a heuristic approach for solving the placement of Analog and Mixed-Signal Integrated Circuits. Placement is a crucial step in the physical design of integrated circuits. During this step, designers choose the position and variant of each circuit device. We focus on the specific class of analog placement, which requires so-called pockets, their possible merging, and parametrizable minimum distances between devices, which are features mostly omitted in recent research and literature. We formulate the problem using Integer Linear Programming and propose a priority-based constructive heuristic inspired by algorithms for the Facility Layout Problem. Our solution minimizes the perimeter of the circuit’s bounding box and the approximated wire length. Multiple variants of the devices with different dimensions are considered. Furthermore, we model constraints crucial for the placement problem, such as symmetry groups and blockage areas. Our outlined improvements make the heuristic suitable to handle complex rules of placement. With a search guided either by a Genetic Algorithm or a Covariance Matrix Adaptation Evolution Strategy, we show the quality of the proposed method on both synthetically generated and real-life industrial instances accompanied by manually created designs. Furthermore, we apply reinforcement learning to control the hyper-parameters of the genetic algorithm. Synthetic instances with more than 200 devices demonstrate that our method can tackle problems more complex than typical industry examples. We also compare our method with results achieved by contemporary state-of-the-art methods on the MCNC and GSRC datasets.},
  archive      = {J_COR},
  author       = {Josef Grus and Zdeněk Hanzálek},
  doi          = {10.1016/j.cor.2024.106643},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106643},
  shortjournal = {Comput. Oper. Res.},
  title        = {Automated placement of analog integrated circuits using priority-based constructive heuristic},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Target-oriented robust satisficing models for the single
machine scheduling problems with release time. <em>COR</em>,
<em>167</em>, 106642. (<a
href="https://doi.org/10.1016/j.cor.2024.106642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate single machine scheduling problems with release times and random processing times, where the release times can be either deterministic or random. The objective is to determine a scheduling sequence that exhibits strong out-of-sample performance. To achieve this, we employ target-oriented robust satisficing models to obtain the scheduling sequence. For the scheduling problem with deterministic release times, we derive an equivalent mixed-integer linear program and an approximate reformulation to address cases involving a large number of jobs. For the scheduling problem with random release times, we first demonstrate the challenges associated with providing an equivalent reformulation. To overcome this intractability, we propose an approximate reformulation based on the linear decision rule. Numerical experiments are conducted to demonstrate the superiority of our solutions through comparisons with several benchmarks. Furthermore, the numerical results demonstrate that a relatively higher target should be chosen if the worst-case performance is valued, otherwise, the decision-maker should set a relatively lower target to obtain better average performance.},
  archive      = {J_COR},
  author       = {Xun Zhang and Du Chen},
  doi          = {10.1016/j.cor.2024.106642},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106642},
  shortjournal = {Comput. Oper. Res.},
  title        = {Target-oriented robust satisficing models for the single machine scheduling problems with release time},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributionally robust scheduling of stochastic knapsack
arrivals. <em>COR</em>, <em>167</em>, 106641. (<a
href="https://doi.org/10.1016/j.cor.2024.106641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the discrete-time Stochastic Knapsack with Periodic Scheduled Arrivals (SKPSA). The goal is to find a schedule such that the capacity usage of the unconstrained cousin of the knapsack is as close as possible to a target utilization. We approximate the SKPSA with a Wasserstein distance based Distributionally Robust Optimization (DRO) model, resulting in the DRO-SKPSA. We present an algorithm that efficiently solves this model, and show that the DRO-SKPSA produces robust schedules. The problem arises in particular in healthcare settings in the development of Master Surgical Schedules (MSSs). We discuss managerial insights for MSSs with downstream capacity constraints.},
  archive      = {J_COR},
  author       = {Hayo Bos and Richard J. Boucherie and Erwin W. Hans and Gréanne Leeftink},
  doi          = {10.1016/j.cor.2024.106641},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106641},
  shortjournal = {Comput. Oper. Res.},
  title        = {Distributionally robust scheduling of stochastic knapsack arrivals},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The bus rapid transit investment problem. <em>COR</em>,
<em>167</em>, 106640. (<a
href="https://doi.org/10.1016/j.cor.2024.106640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bus Rapid Transit (BRT) systems can provide a fast and reliable service to passengers at low investment costs compared to tram, metro and train systems. Therefore, they can be of great value to attract more passengers to use public transport. This paper thus focuses on the BRT investment problem: Which segments of a single bus line should be upgraded such that the number of newly attracted passengers is maximized? Motivated by the construction of a new BRT line around Copenhagen, we consider a setting in which multiple parties are responsible for the financing of different segments of the line. As each party has a limited willingness to invest, we solve a bi-objective problem to quantify the trade-off between the number of attracted passengers and the investment budget. We model different problem variants: First, we consider two potential passenger responses to upgrades on the line. Second, to prevent scattered upgrades along the line, we consider different restrictions on the number of upgraded connected components on the line. We propose an epsilon-constraint-based algorithm to enumerate the complete set of non-dominated points and investigate the complexity of this problem. Moreover, we perform extensive numerical experiments on artificial instances and a case study based on the BRT line around Copenhagen. Our results show that we can generate the full Pareto front for real-life instances and that the resulting trade-off between investment budget and attracted passengers depends both on the origin–destination demand and on the passenger response to upgrades. Moreover, we illustrate how the generated Pareto plots can assist decision makers in selecting from a set of geographical route alternatives in our case study.},
  archive      = {J_COR},
  author       = {Rowan Hoogervorst and Evelien van der Hurk and Philine Schiewe and Anita Schöbel and Reena Urban},
  doi          = {10.1016/j.cor.2024.106640},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106640},
  shortjournal = {Comput. Oper. Res.},
  title        = {The bus rapid transit investment problem},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating value function approximations for dynamic
dial-a-ride problems via dimensionality reductions. <em>COR</em>,
<em>167</em>, 106639. (<a
href="https://doi.org/10.1016/j.cor.2024.106639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the success of ride-sharing mobility service providers shows, customer demand for shared mobility services is increasing. The availability of mobile devices enables the constant accessibility of mobility apps and the immediate placement of transport requests. To provide such a dynamic dial-a-ride service, an effective control of the fleet is necessary. One promising solution approach is the value function approximation (VFA), which on the one hand convinces through good performance, but on the other hand also stands out through fast response times for a request. Training a VFA can be a challenging task since, among other things, the dimensionality of the state space plays a decisive role. If many variables to describe a state are used, a high amount of information can produce good performance after completion of the learning process. If the state space is too high-dimensional, there is also a risk that the method will not be able to find a reasonable solution. In contrast, if the number of variables is reduced, the learning speed can be accelerated, but the eventual performance may suffer from the associated loss of information. Furthermore, not all variables are equally relevant, as they contain different amounts of information. This paper presents a hybrid strategy, temporarily lowering the dimensionality of the problem using dimension reduction methods and subsequently increasing it by mapping the lower-dimensional state representations back onto a high-dimensional state space in order to exploit the advantages of both space dimensionalities. VFA in itself results in competitive performance for the dynamic dial-a-ride problem with shared rides. The proposed hybrid state representation can outperform the reference state representations by 3%, which corresponds to a meaningful acceleration in VFA learning speed.},
  archive      = {J_COR},
  author       = {R.-Julius O. Heitmann and Ninja Soeffker and Frank Klawonn and Marlin W. Ulmer and Dirk C. Mattfeld},
  doi          = {10.1016/j.cor.2024.106639},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106639},
  shortjournal = {Comput. Oper. Res.},
  title        = {Accelerating value function approximations for dynamic dial-a-ride problems via dimensionality reductions},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing the makespan on two parallel machines with a
common server in charge of loading and unloading operations.
<em>COR</em>, <em>167</em>, 106638. (<a
href="https://doi.org/10.1016/j.cor.2024.106638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the scheduling problem on two identical parallel machines with a single server in charge of loading and unloading operations of jobs. Each job has to be loaded by the server before being processed on one of the two machines and unloaded by the same server after its processing. No delay is allowed between loading and processing, and between processing and unloading. The objective function involves the minimization of the makespan. This problem referred to as P 2 , S 1 | s j , t j | C m a x P2,S1|sj,tj|Cmax generalizes the classical parallel machine scheduling problem with a single server which performs only the loading (i.e., setup) operation of each job. For this NP NP -hard problem, no solution algorithm was proposed in the literature. Therefore, we present two mixed-integer linear programming (MILP) formulations, one with completion-time variables along with two valid inequalities and one with time-indexed variables. In addition, we propose some polynomial-time solvable cases and a tight theoretical lower bound. We also show that the minimization of the makespan is equivalent to the minimization of the total idle-times on the machines. To solve large-sized instances of the problem, an efficient General Variable Neighborhood Search (GVNS) metaheuristic with two mechanisms for finding an initial solution is designed. The GVNS is evaluated by comparing its performance with the results provided by the MILPs and another metaheuristic. The results show that the average percentage deviation from the theoretical lower bound of GVNS is within 0.642%. We finally compare our approaches with the related literature.},
  archive      = {J_COR},
  author       = {Abdelhak Elidrissi and Rachid Benmansour and Keramat Hasani and Frank Werner},
  doi          = {10.1016/j.cor.2024.106638},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106638},
  shortjournal = {Comput. Oper. Res.},
  title        = {Minimizing the makespan on two parallel machines with a common server in charge of loading and unloading operations},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient configuration of heterogeneous multistatic sonar
networks: A mixed-integer linear programming approach. <em>COR</em>,
<em>167</em>, 106637. (<a
href="https://doi.org/10.1016/j.cor.2024.106637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work undertaken in this paper pertains to the optimal spatial configuration of a heterogeneous Wireless Sensor Network (WSN) for the Area Coverage (AC) problem. Specifically, this research falls under the heading of Anti-Submarine Warfare (ASW) with an emphasis on active sonar systems and, more pointedly still, on a specific type of sensor: sonobuoys (portmanteau word formed by “sonar” and “buoy”). These buoys are further divided into three main categories: transmitter-only (Tx), receiver-only (Rx) and transmitter–receiver (TxRx). In this paper, we will therefore try to determine the geographical location of the different buoys comprising a Multistatic Sonar Network (MSN), special case of WSN, so as to maximize the overall surface area covered. To do this, we discretize an Area of Interest (AoI) into regular cells using bathymetric and altimetric data, and place a deployment position and a fictitious target at the center of each cell so that we can evaluate the network’s performance. More precisely, we are taking into account a limited number of sensors (buoys) with possible pairwise incompatibilities, variable performances, probabilistic detection models, an adverse masking effect (direct blast) as well as coastlines features. Finally, in order to solve this problem, we have developed several efficient Mixed-Integer Linear Programs (MILPs), all of which have been thoroughly tried-and-tested on a benchmark set of 100 instances derived from real elevation data. This has led us to identify an ideal model, i.e. one that is significantly better than all the others in the statistical sense.},
  archive      = {J_COR},
  author       = {Owein Thuillier and Nicolas Le Josse and Alexandru-Liviu Olteanu and Marc Sevaux and Hervé Tanguy},
  doi          = {10.1016/j.cor.2024.106637},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106637},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient configuration of heterogeneous multistatic sonar networks: A mixed-integer linear programming approach},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reduced variable neighborhood search for the just in time
job shop scheduling problem with sequence dependent setup times.
<em>COR</em>, <em>167</em>, 106634. (<a
href="https://doi.org/10.1016/j.cor.2024.106634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with the just-in-time job shop scheduling problem with sequence-dependent setup times and release dates. Given a set of jobs characterized by release and due dates, the goal is to execute them by minimizing a weighted sum of their earliness, tardiness, and flow time (i.e., the difference between completion and start time of each job). We develop new destroy and repair operators by exploiting the structure of the problem, and we use them within a reduced variable neighborhood search matheuristic. Computational experiments carried out on several sets of instances show that the proposed algorithm outperforms existing solution methods.},
  archive      = {J_COR},
  author       = {Paolo Brandimarte and Edoardo Fadda},
  doi          = {10.1016/j.cor.2024.106634},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106634},
  shortjournal = {Comput. Oper. Res.},
  title        = {A reduced variable neighborhood search for the just in time job shop scheduling problem with sequence dependent setup times},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Centralized multi-visitor trip planning with activity
reservations in crowded destinations. <em>COR</em>, <em>167</em>,
106633. (<a href="https://doi.org/10.1016/j.cor.2024.106633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of centralized planning of leisure trips in congested areas for visitor groups with reservations for activities. We develop an algorithm that through a combination of customization and coordination can improve average happiness considerably. Extensive numerical experimentation with both synthetic and real-life data show that our algorithm strongly outperforms the classical First-Come-First-Served reservation policy, both in terms of visitor happiness and in terms of fairness among visitors. Moreover, our results show that our algorithm leads to good solutions for small-sized problem instances (with errors typically within 5%–10% from an optimal solution obtained via Integer Linear Programming). Finally, the computational effort with regard to number of visitors is bounded by the capacity and the number of activities, while the increase in computation time for the number of attractions is bounded by the average number of activities that fit into a trip. As a result, our approach leads to good solutions within minutes in realistic settings with more than 10 thousand visitors a day.},
  archive      = {J_COR},
  author       = {Joris Slootweg and Rob van der Mei and Caroline J. Jagtenberg and Frank Ottenhof},
  doi          = {10.1016/j.cor.2024.106633},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106633},
  shortjournal = {Comput. Oper. Res.},
  title        = {Centralized multi-visitor trip planning with activity reservations in crowded destinations},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multistage adaptive distributionally robust optimization for
the medical supplies distribution problem with uncertain demand in
humanitarian aid. <em>COR</em>, <em>167</em>, 106631. (<a
href="https://doi.org/10.1016/j.cor.2024.106631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production, inventory, distribution, and dispensing of relief resources are critical operational functions in humanitarian aid. To design an efficient humanitarian relief network, it is beneficial to study these operational functions in an integrated way. Accounting for the demand uncertainty of medical supplies, we propose a multistage adaptive distributionally robust model for the medical supplies distribution network design that considers simultaneously the issues of production, inventory, distribution and dispensing of medical resources, as well as the life-loss due to the delays in treatment. The objective is to dynamically match the supply and demand of medical supplies so as to minimize the total cost consisting of the production cost, holding cost, dispensing cost, and life-loss cost related to the unmet demand. We also introduce a safety-stock and production capacity model to efficiently predetermine the initial supply of medical supplies and maximum available production abilities under the given demand information. To obtain tractable formulations, we approximate the developed models using an enhanced linear decision rule (ELDR) and a simplified ELDR (SELDR), respectively. Using a set of real-world COVID-19 data, we show that (i) both the ELDR and SELDR can yield feasible solutions extremely close to the optimal solution of the multistage adaptive distributionally robust model, whereas the SELDR is about one order of magnitude faster than the ELDR; and (ii) accounting for the safety-stock and production capacity model yields significant improvements of the obtained solution, which can also inform the decision-maker about at least how many initial supply of vaccines and the maximum available production abilities should be set to counter the risk of demand uncertainty. We also analyze the impact of some model parameters to gain managerial implications.},
  archive      = {J_COR},
  author       = {Yuze Yang and Zunhao Luo and Yongjian Yang and Dujuan Wang},
  doi          = {10.1016/j.cor.2024.106631},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106631},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multistage adaptive distributionally robust optimization for the medical supplies distribution problem with uncertain demand in humanitarian aid},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General VNS for asymmetric vehicle routing problem with time
and capacity constraints. <em>COR</em>, <em>167</em>, 106630. (<a
href="https://doi.org/10.1016/j.cor.2024.106630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a real-life transportation problem from a hypermarket company in Serbia that consists of delivering online ordered and possibly perishable goods from a single depot to multiple customers. It can be modeled as an asymmetric vehicle routing problem that requires visiting and serving all customers using a limited number of homogeneous vehicles and taking into account time and capacity constraints. The objective function to be minimized is the total distance traveled. We provide a mixed-integer programming (MIP) formulation of the problem and develop several Local Search based metaheuristic methods exploring combinatorial formulation of the considered problem: Multistart Local Search (MLS), Greedy Randomized Adaptive Search Procedure (GRASP), and several variants of General Variable Neighborhood Search (GVNS) methods. All methods are compared on real-life instances provided by the hypermarket company and benchmark instances from the relevant literature. The obtained results show the superiority of GVNS-based methods with respect to both solution quality and running time, confirming that systematic search procedures have more success when dealing with hard optimization problems.},
  archive      = {J_COR},
  author       = {Luka Matijević and Vladimir Ilin and Tatjana Davidović and Tatjana Jakšić-Krüger and Panos M. Pardalos},
  doi          = {10.1016/j.cor.2024.106630},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106630},
  shortjournal = {Comput. Oper. Res.},
  title        = {General VNS for asymmetric vehicle routing problem with time and capacity constraints},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid and adaptive evolutionary approach for multitask
optimization of post-disaster traveling salesman and repairman problems.
<em>COR</em>, <em>167</em>, 106622. (<a
href="https://doi.org/10.1016/j.cor.2024.106622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traveling Salesman Problem (TSP) and Traveling Repairman Problem (TRP) have been studied due to their real-world applications. While the TSP minimizes the total time to travel to all customers, the TRP minimizes the total waiting time between a main depot and customers. Solving two problems simultaneously is shown to obtain promising results due to their high similarity in solution representation and overlap in search space. However, these two problems in the context of post-disaster have not yet been considered in line with the three following restrictions. First, the salesman cannot travel on several destroyed roads. Second, the salesman needs additional time to remove debris, which means the debris removal time is added to the travel cost. Finally, we do not consider each vertex equally because they have different characteristics depending on their population or vulnerability. Therefore, reaching a vertex with higher priority takes more benefit overall. To tackle these problems, we first formalize TSP and TRP in post-disaster scenarios as TSPPD and TRPPD, respectively, and then propose the effective metaheuristic, MFEA-TS, combining a Multifactorial Evolutionary Algorithm (MFEA) and Tabu Search (TS) to solve them simultaneously and efficiently. In the proposed MFEA-TS, the MFEA can explore the search space well by transferring knowledge between two problems, while the TS can exploit good solutions in the search space. The proposed algorithm overcomes the drawbacks of the existing MFEA algorithms due to good exploitation capacity and prevention of revisiting previous solution spaces. We further conduct extensive experiments to verify the performance of our MFEA-TS with TRPPD and TSPPD. The empirical results show that the proposed algorithm can give high-quality solutions on a range of benchmarks, thus confirming the impressive efficiency of the proposed formulations and algorithm MFEA-TS.},
  archive      = {J_COR},
  author       = {Ha-Bang Ban and Huynh Thi Thanh Binh and Tuan Anh Do and Cong Dao Tran and Su Nguyen},
  doi          = {10.1016/j.cor.2024.106622},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106622},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid and adaptive evolutionary approach for multitask optimization of post-disaster traveling salesman and repairman problems},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solution algorithms for dock scheduling and truck sequencing
in cross-docks: A neural branch-and-price and a metaheuristic.
<em>COR</em>, <em>167</em>, 106604. (<a
href="https://doi.org/10.1016/j.cor.2024.106604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a novel mathematical model for the integrated challenge of dock scheduling and truck sequencing in cross-docking facilities. Many existing models for variations of this problem in the literature rely on big-M constraints, known for their poor performance when applied to general-purpose mixed-integer programming solvers. This introduces significant limitations, especially when tackling smaller instances. Consequently, most solution methods in the literature gravitate towards metaheuristic approaches. Our proposed model offers a compact formulation without any big-M constraints, utilizing 4-index variables. It is strategically designed to lend itself well to a dual decomposition approach (Dantzig–Wolfe) and can be effectively solved using a branch-and-price methodology. We address the pricing problem through a branch-and-cut scheme and illustrate its efficiency in handling large instances. Recognizing the pricing problem as the primary bottleneck, we employ a deep neural network trained on a comprehensive set of instances with the same distribution to predict promising duals. Extensive computational experiments demonstrate a notable reduction of over 50% in overall computational times. Additionally, we introduce a heuristic sharing similarities with certain Variable Neighborhood Search (VNS) approaches. Our proposed heuristic has proven highly efficient in extensive computational experiments.},
  archive      = {J_COR},
  author       = {Rahimeh Neamatian Monemi and Shahin Gelareh and Nelson Maculan},
  doi          = {10.1016/j.cor.2024.106604},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106604},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solution algorithms for dock scheduling and truck sequencing in cross-docks: A neural branch-and-price and a metaheuristic},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two-echelon time-dependent vehicle routing problem with
simultaneous pickup and delivery and satellite synchronization.
<em>COR</em>, <em>167</em>, 106600. (<a
href="https://doi.org/10.1016/j.cor.2024.106600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-echelon distribution strategy has been widely applied in city logistics systems. This study develops a mixed-integer linear programming model for a new variant of vehicle routing problem, namely, a two-echelon time-dependent vehicle routing problem with simultaneous pickup and delivery and satellite synchronization, in which customers are divided into multiple customer regions according to different geographical characteristics. The pickup and delivery activities with hard time windows are performed simultaneously by the same vehicles from depots to satellites in the first echelon and from satellites to customers in different customer regions in the second echelon. A vehicle speed function is developed for each echelon based on traffic conditions. The function depends on commuter traffic and urbanization level. Satellites with storage buffer capacities for split and consolidation are allowed. Thus, demand unloading, storage, and reloading are synchronized. Costs of transportation, loading/unloading, inventory, and environment during one complete distribution process are considered. A memetic algorithm (MA) is proposed including a split algorithm for chromosome decoding and a three-phase construction heuristic for initial population generation. Self-adaptive operators of crossover, mutation, and local search are designed, and a neighborhood route improvement strategy is devised that includes distance-related destroy, route-based destroy, distance-based greedy repair, and time-distance cluster repair operators. Results of different scales of numerical experiments and sensitivity analysis show the effectiveness of the model and MA by comparing it with an exact algorithm, CPLEX, and adaptive large neighborhood search.},
  archive      = {J_COR},
  author       = {Guanghui Zhou and Dengyuhui Li and Junsong Bian and Yixiang Zhang},
  doi          = {10.1016/j.cor.2024.106600},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106600},
  shortjournal = {Comput. Oper. Res.},
  title        = {Two-echelon time-dependent vehicle routing problem with simultaneous pickup and delivery and satellite synchronization},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved dynamic programming algorithms for unconstrained
two-dimensional guillotine cutting. <em>COR</em>, <em>167</em>, 106490.
(<a href="https://doi.org/10.1016/j.cor.2023.106490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the unconstrained two-dimensional cutting problem (U2DCP), we are given a large rectangular sheet to be cut in order to extract small rectangular pieces, with no limits on the number (demand) of desired pieces. We face the variant with guillotine constraint, requiring to cut any rectangle in two parts through vertical/horizontal cuts with end points on the rectangle boundaries. For a given U2DCP instance, the dynamic programming approach can be used either to optimally solve it, or to obtain a full matrix of upper bounds suitable for the constrained variant of the problem where limits exist on the piece demands. The elements of the full matrix are also usable as partial solutions to build lower bounds for the non-guillotine variant. In this paper, we propose two major improvements to a dynamic programming procedure previously shown to be capable of solving very large size instances. First, we introduce a new option for one of the three conditions used for the anti-redundancy strategies on cut coordinates. Second, following the effort of the Operations Research community to exploit the feature of modern CPUs containing multi-core processors, we provide a parallelization scheme. An extended computational campaign is presented. We compare the upgraded procedure with its previous version on a single thread and with the currently state-of-the-art algorithm for multi-thread platforms, outperforming both in terms of execution time on average by a factor of 1.7 and 12, respectively, or for some problem instances up to 4.5 and 50, respectively. Moreover, the new procedure can solve two very large instances previously unsolved, as well as the new huge instances proposed in this paper.},
  archive      = {J_COR},
  author       = {Adriano Masone and Mauro Russo and Claudio Sterle},
  doi          = {10.1016/j.cor.2023.106490},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {106490},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improved dynamic programming algorithms for unconstrained two-dimensional guillotine cutting},
  volume       = {167},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A filtered beam search based heuristic algorithm for packing
unit circles into a circular container. <em>COR</em>, <em>166</em>,
106636. (<a href="https://doi.org/10.1016/j.cor.2024.106636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A constructive method for addressing the circular packing problem is proposed based on the filtered beam search framework, with the goal of minimizing the radius of a circular container that can hold N unit circles without overlapping. To position each circle in the container, the proposed method employs a corner-occupying placement strategy. Since there are often multiple possible positions for a circle to be packed, the method employs two steps to select the best placement. The positions are quickly assessed in the first phase, known as the filtering phase. In the second phase, known as the beam selection phase, a computationally intensive strategy is used to evaluate the positions more accurately. To balance the accuracy and efficiency of the method, two parameters are utilized, namely filterwidth and beamwidth . These parameters control the pruning operations in the tree-based search procedure. The performance of the proposed method is assessed utilizing two sets of 19 publicly available instances from the literature, and a comparative analysis is conducted against five constructive-based algorithms and one global optimization method. The computational results demonstrate its competitive performance, surpassing all constructive-based reference algorithms. Furthermore, a thorough investigation is conducted into the suggested method&#39;s parameter settings and essential components.},
  archive      = {J_COR},
  author       = {Mao Chen and Yajing Yang and Zeyu Zeng and Xiangyang Tang and Xicheng Peng and Sannuya Liu},
  doi          = {10.1016/j.cor.2024.106636},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106636},
  shortjournal = {Comput. Oper. Res.},
  title        = {A filtered beam search based heuristic algorithm for packing unit circles into a circular container},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The container premarshalling problem under limited crane
time: A constraint programming approach. <em>COR</em>, <em>166</em>,
106635. (<a href="https://doi.org/10.1016/j.cor.2024.106635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the premarshalling problem when the crane time is limited and a complete rearrangement of the bay is not possible. This issue has been neglected in the literature, but it is very common in practice. We show that the use of standard approaches often fails to yield good solutions and develop a model for the problem in two steps. First, a constraint programming model is proposed for premarshalling with crane time minimization objective. Then, this model is adapted to the new problem. An extensive computational study shows that the first model improves on the performance of the existing state-of-the-art integer programming model and that the model of the new problem obtains high quality solutions even in short running times.},
  archive      = {J_COR},
  author       = {Celia Jiménez-Piqueras and Consuelo Parreño-Torres and Ramon Alvarez-Valdes and Rubén Ruiz},
  doi          = {10.1016/j.cor.2024.106635},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106635},
  shortjournal = {Comput. Oper. Res.},
  title        = {The container premarshalling problem under limited crane time: A constraint programming approach},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Arrival and service time dependencies in the single- and
multi-visit selective traveling salesman problem. <em>COR</em>,
<em>166</em>, 106632. (<a
href="https://doi.org/10.1016/j.cor.2024.106632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze several time dependency issues for the selective traveling salesman problem with time-dependent profits. Specifically, we consider the case in which the profit collected at a vertex depends on the service time, understood as the time spent at this vertex, and when the service time at each vertex depends on the arrival time at the vertex. For each of these two cases, we formulate two continuous-time problems: (i) a vertex can be visited at most once, and (ii) vertices may be visited more than once. In each case, we consider general profit functions at the vertices, i.e., the profit functions are not limited to monotonic functions of time. We also formulate the problems as discrete-time problems using appropriate variants of an auxiliary time-extended graph, and we solve them with Gurobi. We apply our methodology to two sets of instances. First, we use a set of artificial instances to illustrate the main differences amongst the different versions of the problem. We then solve several instances adapted from TSPLIB to evaluate the computational capabilities of the methodology.},
  archive      = {J_COR},
  author       = {David Canca and Eva Barrena and Gilbert Laporte},
  doi          = {10.1016/j.cor.2024.106632},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106632},
  shortjournal = {Comput. Oper. Res.},
  title        = {Arrival and service time dependencies in the single- and multi-visit selective traveling salesman problem},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal classification trees with leaf-branch and binary
constraints. <em>COR</em>, <em>166</em>, 106629. (<a
href="https://doi.org/10.1016/j.cor.2024.106629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using empirical models to predict whether sections within pipes have defects can save inspection costs and, potentially, avoid oil spills. Optimal Classification Tree (OCT) formulations offer potentially desirable combinations of interpretability and prediction accuracy on unseen pipes. Approaches based on powerful state-of-the-art OCT formulations have enabled researchers to solve decision tree problems optimally instead of using traditional sub-optimal greedy approaches. Yet, the recently proposed formulations also have limitations. Some of the most recent formulations require a large number of decision variables and constraints leading to computational inefficiencies. Previous formulations have optimal solutions with undesirable or invalid tree structures which may depend on the particular software implementation. Additionally, some formulations always grow a full tree even when desirable parsimonious tree options are available. This article proposes the Modified Optimal Classification Tree (M-OCT) formulation with novel leaf-branch-interaction constraints, which could stabilize the previous formulation and reduce the chance of invalid tree structures when generating optimal trees. By incorporating the idea of binary encoding of thresholds from a previous article, we reduce the total number of binary variables. We then extend M-OCT to construct a novel formulation called Binary Node Penalty Optimal Classification Tree (BNP-OCT) with binary splits and node complexity constraints, which support efficiency in standard branch-and-cut solvers and prevents the overfitting issue when learning the optimal tree models. We compare the proposed methods with alternatives including standard formulations using 15 standard data sets. In addition, we use 750 test cases to compare the computational stability of pre-existing formulations to those involving the proposed leaf-branch constraints. We demonstrate that the proposed formulation offers advantages in accuracy, computational efficiency, and structural stability. We also describe how the proposed methods are able to achieve 94% classification accuracy on balanced test sets for unseen pipes.},
  archive      = {J_COR},
  author       = {Enhao Liu and Tengmu Hu and Theodore T. Allen and Christoph Hermes},
  doi          = {10.1016/j.cor.2024.106629},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106629},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal classification trees with leaf-branch and binary constraints},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven optimization for seismic-resilient power network
planning. <em>COR</em>, <em>166</em>, 106628. (<a
href="https://doi.org/10.1016/j.cor.2024.106628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many regions of the planet are exposed to seismic hazards that can cause devastating consequences on power systems. Due to these systems’ crucial role, the evaluation and planning for their safe and reliable operation are paramount. This paper develops a novel data-driven optimization framework to assess the power network’s seismic resilience and plan cost-effective investments for its enhancement. Under a robust optimization scheme, an earthquake attacker–defender model finds the worst-case realization of random earthquake network contingencies within an uncertainty set defined with a large number of scenarios generated by state-of-the-art engineering methods. Moreover, data-driven stochastic-robust optimization is employed in a two-stage seismic-resilient power network planning model, leveraging multiple seismic sources’ distributional information. Transmission line expansions and siting and sizing of battery energy storage systems are decided in the first stage, while the second stage decides operational variables. Experiments on a 281-node Chilean power system provide insights for seismic-resilient planning and demonstrate the efficiency of the proposed approach.},
  archive      = {J_COR},
  author       = {Alfredo Oneto and Álvaro Lorca and Elisa Ferrario and Alan Poulos and Juan Carlos De La Llera and Matías Negrete-Pincetic},
  doi          = {10.1016/j.cor.2024.106628},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106628},
  shortjournal = {Comput. Oper. Res.},
  title        = {Data-driven optimization for seismic-resilient power network planning},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A feature correlation reinforce clustering and evolutionary
algorithm for the green bike-sharing reposition problem. <em>COR</em>,
<em>166</em>, 106627. (<a
href="https://doi.org/10.1016/j.cor.2024.106627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the green bike-sharing reposition problem (GBSRP) considering the reposition quality and carbon emission during the reposition simultaneously. With the expanding scale of today’s bike-sharing system (BSS), the environmental pollution during the reposition becomes obvious. GBSRP aims to satisfy the inventory request of every bike-sharing station through an identified route set while minimizing the routing fuel consumption and relevant carbon emission. This paper provides an effective feature correlation mechanism for both the clustering strategy and algorithm design, which aims at solving large-scale reposition. The original problem is clustered through the feature correlation reinforce clustering (FCRC) strategy. Then, a multi-objective evolutionary algorithm based on decomposition combined with feature correlation mechanism (FC-MOEA/D) is designed considering both the carbon emission and reposition quality. Finally, the carbon emissions of each module of the Comprehensive Modal Emissions Modeling under different reposition qualities are analyzed. The Pareto front of each instance is displayed and compared based on different clustering strategies and algorithms. The results demonstrate the competitiveness of the FCRC strategy and FC-MOEA/D algorithm. We also further discuss the relevant strategies for different reposition quality preferences and how they minimize the carbon emission during the reposition for BSS managers reference.},
  archive      = {J_COR},
  author       = {Chang Lv and Qiong Liu and Chaoyong Zhang and Yaping Ren and Hao Zhou},
  doi          = {10.1016/j.cor.2024.106627},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106627},
  shortjournal = {Comput. Oper. Res.},
  title        = {A feature correlation reinforce clustering and evolutionary algorithm for the green bike-sharing reposition problem},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tight compact quadratically constrained convex relaxation
of the optimal power flow problem. <em>COR</em>, <em>166</em>, 106626.
(<a href="https://doi.org/10.1016/j.cor.2024.106626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the Optimal Power Flow (OPF) problem which consists in determining the power production at each bus of an electric network by minimizing the production cost. Our contribution is an exact solution algorithm for the OPF problem. It consists in a spatial branch-and-bound algorithm based on a compact quadratically-constrained convex relaxation. It is computed by solving the semidefinite rank relaxation of OPF once at the root node of the algorithm. An important result is that the optimal value of our compact relaxation is equal to the rank relaxation value. Then, at every sub-nodes of our branch-and-bound, the lower bound is obtained by solving a quadratic convex problem instead of an SDP. Another contribution is that we add only O ( n + m ) O(n+m) variables that model the squares of the initial variables, where n n is the number of buses in the power system and m m the number of transmission lines, to construct our relaxation. Then, since the relations between the initial and auxiliary variables are non-convex, we relax them to get a quadratic convex relaxation. Finally, in our branch-and-bound algorithm, we only have to force a reduced number of equalities to prove global optimality. This quadratic convex relaxation approach is here tailored to the OPF problem, but it can address any application whose formulation is a quadratic optimization problem subject to quadratic equalities and ring constraints. Our first experiments on instances of the OPF problem show that our new algorithm Compact OPF ( COPF ) is more efficient than the standard solvers and other quadratic convex relaxation based methods we compare it with.},
  archive      = {J_COR},
  author       = {Amélie Lambert},
  doi          = {10.1016/j.cor.2024.106626},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106626},
  shortjournal = {Comput. Oper. Res.},
  title        = {A tight compact quadratically constrained convex relaxation of the optimal power flow problem},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Real-time schedule adjustments for conflict-free vehicle
routing. <em>COR</em>, <em>166</em>, 106625. (<a
href="https://doi.org/10.1016/j.cor.2024.106625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict-Free Vehicle Routing Problems (CFVRPs) arise in manufacturing, transportation and logistics applications where Automated Guided Vehicles (AGVs) are utilized to move pallets and containers. A peculiar feature of these problems is that collision avoidance among vehicles must be considered explicitly. To make things more complex, the uncertainty affecting both travel times and machine ready times often results in vehicle delays or anticipations that require real-time modifications to the fleet nominal plan. In this paper, the determination of such modifications (schedule adjustment problem in CFVRPs) is modeled as a sequential decision problem for which we develop a tailored fast exact algorithm suitable for any objective function that is non-decreasing in the arrival times. Computational results show that optimal solutions can be found within at most 3.3 milliseconds for instances with up to 300 vehicles with improvements of various performance measures up to 74% compared to state-of-the-art solution algorithms.},
  archive      = {J_COR},
  author       = {Tommaso Adamo and Gianpaolo Ghiani and Emanuela Guerriero},
  doi          = {10.1016/j.cor.2024.106625},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106625},
  shortjournal = {Comput. Oper. Res.},
  title        = {Real-time schedule adjustments for conflict-free vehicle routing},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A chance-constrained optimization approach integrating
project scheduling and material ordering to manage the uncertain
material supply. <em>COR</em>, <em>166</em>, 106624. (<a
href="https://doi.org/10.1016/j.cor.2024.106624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deal with the impact of uncertain material supply on the implementation of projects, we investigate a problem of concurrently finding a robust baseline schedule and a material ordering plan under different levels of uncertainty. Assuming the material warehouses are restricted, a chance-constrained model of the integrated resource-constrained project scheduling and material ordering problem with a confidence level ( 1 − θ ) (1−θ) is thus formulated. To tackle the difficult joint chance constraints, we firstly transform the chance-constrained model into a scenario-based integer programming model by the sample average approximation approach. Based on dominance relationship among scenarios, we then derive an exact branch-and-bound algorithm and a sampling-based genetic algorithm (SGA) to solve the model. For the branch-and-bound algorithm, a tailor-made branching scheme and four pruning rules are developed to accelerate the search process. For the SGA, two sampling methods and a local search procedure are presented to boost solution quality. Furthermore, extensive numerical experiments are carried out to test the performance of the proposed algorithms. Specifically, 4608 instances with four different confidence levels and six different sample sizes are generated. Then the Taguchi method is employed to calibrate the parameters of the SGA. Besides, the numerical results demonstrate that the proposed branch-and-bound algorithm can solve more instances with shorter CPU times than the CPLEX solver, and the solution quality of the proposed SGA is far better than that of two existing meta-heuristics and two variants of SGA. Finally, a sensitivity analysis for the key parameters of the model is conducted. By considering the uncertain material supply, limited warehouse capacity and various confidence levels, our research contributes to the effective decision on project scheduling and material ordering in real-world contexts.},
  archive      = {J_COR},
  author       = {Baofeng Tian and Jingwen Zhang and Erik Demeulemeester and Hao Liu},
  doi          = {10.1016/j.cor.2024.106624},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106624},
  shortjournal = {Comput. Oper. Res.},
  title        = {A chance-constrained optimization approach integrating project scheduling and material ordering to manage the uncertain material supply},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-bound algorithm for the proactive
resource-constrained project scheduling problem with a robustness
maximization objective. <em>COR</em>, <em>166</em>, 106623. (<a
href="https://doi.org/10.1016/j.cor.2024.106623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a branch-and-bound (B&amp;B) algorithm for the proactive scheduling problem, which incorporates a degree of anticipated variability in practical projects. First, the resource-constrained proactive scheduling model is formulated. Second, solving the resource-unconstrained version of the problem with an adapted Fulkerson algorithm provides an upper bound solution. Then, the subproblems of the model are derived by introducing additional precedence relationships to resolve the resource conflict in the upper bound solution. Third, we solve the resource-constrained proactive scheduling problem with the proposed B&amp;B algorithm. The resource conflicts found in the upper bound solution are resolved by adding additional precedence relationships. According to the problem analysis, two dominance rules are proposed for additional node fathoming with the aim of improving the algorithm. Fourth, a genetic algorithm is designed to provide an effective heuristic method for solving the research problem. Finally, we conduct an extensive computational experiment on 6,000 randomly generated instances. The obtained results show that the B&amp;B algorithm has advantages over CPLEX and the genetic algorithm. In addition, the impacts of the dominance rules and the three key parameters on the computational time and project robustness are analysed.},
  archive      = {J_COR},
  author       = {Xue Li and Zhengwen He and Nengmin Wang},
  doi          = {10.1016/j.cor.2024.106623},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106623},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-bound algorithm for the proactive resource-constrained project scheduling problem with a robustness maximization objective},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drone-based hybrid charging for multiple sensors: A
distributionally robust optimization approach. <em>COR</em>,
<em>166</em>, 106621. (<a
href="https://doi.org/10.1016/j.cor.2024.106621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The drone-based charging is emerging as a promising way to supply electricity to sensors that keep the Internet of Things working. One-to-one and one-to-many charging strategies can both be adopted. In this background, how to dispatch drones and decide the charging strategy becomes an important problem. In this paper, we first investigate the electricity consumption uncertainty during drone travel, and then develop a distributionally robust hover location and routing optimization model with hybrid charging strategies. After that, we transform the established model into a tractable mixed-integer linear programming model based on dual theory. In order to solve it, we introduce a pre-screening process based on greedy algorithm to select the candidate hover locations. Finally, we conduct extensive numerical experiments and sensitive analysis to verify the efficacy and advantages of the proposed method. We find that the optimized charging strategies and drone dispatching schemes can vary with different sensor distribution patterns. Valuable managerial insights are also provided for drone-based hybrid charging in practice.},
  archive      = {J_COR},
  author       = {Xiaoyang Zhou and Tingting Guo and Shouyang Wang and Benjamin Lev and Zhe Zhang},
  doi          = {10.1016/j.cor.2024.106621},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106621},
  shortjournal = {Comput. Oper. Res.},
  title        = {Drone-based hybrid charging for multiple sensors: A distributionally robust optimization approach},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the set covering problem with conflicts on sets: A
new parallel GRASP. <em>COR</em>, <em>166</em>, 106620. (<a
href="https://doi.org/10.1016/j.cor.2024.106620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze a new variant of the well-known NP-hard Set Covering Problem, characterized by pairwise conflicts among subsets of items. Two subsets in conflict can belong to a solution provided that a positive penalty is paid. The problem looks for the optimal collection of subsets representing a cover and minimizing the sum of covering and penalty costs. We introduce two integer linear programming formulations and a quadratic one for the problem and provide a parallel GRASP (Greedy Randomized Adaptive Search Procedure) that, during parallel executions of the same basic procedure, shares information among threads. We tailor such a parallel processing to address the specific problem in an innovative way that allows us to prevent redundant computations in different threads, ultimately saving time. To evaluate the performance of our algorithm, we conduct extensive experiments on a large set of new instances obtained by adapting existing instances for the Set Covering Problem. Computational results show that the proposed approach is extremely effective and efficient providing better results than Gurobi (tackling three alternative mathematical formulations of the problem) in less than 1/6 of the computational time.},
  archive      = {J_COR},
  author       = {Francesco Carrabs and Raffaele Cerulli and Renata Mansini and Lorenzo Moreschini and Domenico Serra},
  doi          = {10.1016/j.cor.2024.106620},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106620},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving the set covering problem with conflicts on sets: A new parallel GRASP},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic exploration–exploitation pareto approach for
high-dimensional expensive black-box optimization. <em>COR</em>,
<em>166</em>, 106619. (<a
href="https://doi.org/10.1016/j.cor.2024.106619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate Optimization (SO) plays a vital role in optimizing performance parameters for computationally expensive simulations. However, SO encounters significant challenges in high-dimensional spaces due to the curse of dimensionality, hampering effective point sampling around global optima. In this paper, we introduce “Dynamic Exploration–Exploitation Pareto Approach (DEEPA),” a novel SO method that combines Pareto sampling with a dynamic discretization schema to optimize high-dimensional black-box functions. Unlike traditional SO methods that heavily rely on specific surrogate models, Pareto sampling offers a more adaptable approach. Improvement-based acquisition functions, frequently employed in black-box optimization, are sensitive to model accuracy and tend to prioritize exploitation, potentially missing valuable regions of interest in complex landscapes. Furthermore, they can encounter challenges when dealing with high-dimensional problems due to the curse of dimensionality. DEEPA leverages dynamic coordinate importance to generate samples effectively, providing a solution for addressing high-dimensionality and complex functions. We employ feature selection strategies to assign importance probabilities to perturb each coordinate, demonstrating the impact of importance-based perturbation on convergence to a near-optimal region. We showcase DEEPA’s versatility in fixed-batch evaluation environments using complex global optimization test problems with various topological properties. We compare DEEPA’s performance with state-of-the-art black-box optimization algorithms, and our experimental results demonstrate DEEPA’s superior performance, particularly in complex problems with multiple local minima.},
  archive      = {J_COR},
  author       = {Nazanin Nezami and Hadis Anahideh},
  doi          = {10.1016/j.cor.2024.106619},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106619},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic Exploration–Exploitation pareto approach for high-dimensional expensive black-box optimization},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benders decomposition for the energy aware task scheduling
of constellations of nanosatellites. <em>COR</em>, <em>166</em>, 106618.
(<a href="https://doi.org/10.1016/j.cor.2024.106618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a novel method for optimizing nanosatellite constellation scheduling based on Benders decomposition. The optimization of nanosatellite constellations is challenging due to the large number of variables and constraints involved, which increases the computational work required to get optimal solutions as the number of participating objects increases. Our strategy overcomes this obstacle by decomposing the complex problem into smaller, more manageable subproblems, rendering the original formulation scalable. The outcomes demonstrate that the Benders decomposition achieves the same optimal solutions obtained with the Gurobi solver applied to the baseline formulation while being significantly faster and more efficient, especially for larger constellation sizes. This method provides a valuable tool for decision-makers in the nanosatellite job scheduling process, highlighting the potential benefits of using decomposition methods such as the Benders decomposition for large-scale or challenging optimization problems in Offline Nanosatellite Task Scheduling (ONTS).},
  archive      = {J_COR},
  author       = {Laio Oriel Seman and Cezar Antônio Rigo and Eduardo Camponogara and Eduardo Augusto Bezerra},
  doi          = {10.1016/j.cor.2024.106618},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106618},
  shortjournal = {Comput. Oper. Res.},
  title        = {Benders decomposition for the energy aware task scheduling of constellations of nanosatellites},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Due-date assignment with acceptable lead-times on parallel
machines. <em>COR</em>, <em>166</em>, 106617. (<a
href="https://doi.org/10.1016/j.cor.2024.106617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper studies scheduling and due-date assignment problems on parallel machines. We consider the DIF (different due date) model, which assumes job-dependent acceptable lead-times. Thus, in addition to the classical job-earliness and job-tardiness costs, the scheduler is penalized if an assigned due-date exceeds its lead-time. First, the case of a common lead-time is studied. Then we focus on the setting of job-dependent lead-times and identical (earliness, tardiness, and lead-time) costs. Both models are examined for parallel identical, uniform, and unrelated machines. The case in which the option of job-rejection is allowed is also considered. For all these NP-hard problems, efficient pseudo-polynomial dynamic programming algorithms are introduced and tested. Our numerical tests indicate that problems containing 500 jobs are solved in less than 0.3 s.},
  archive      = {J_COR},
  author       = {Baruch Mor and Gur Mosheiov},
  doi          = {10.1016/j.cor.2024.106617},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106617},
  shortjournal = {Comput. Oper. Res.},
  title        = {Due-date assignment with acceptable lead-times on parallel machines},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The dynamic facility location problem with mobile production
units: A waste recycling application. <em>COR</em>, <em>166</em>,
106609. (<a href="https://doi.org/10.1016/j.cor.2024.106609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a multi-period location–production problem involving small recycling units that are embedded in standard containers and can, therefore, be relocated from site to site at short notice. The waste generated over time at different locations can be stored up to a specific limit, at which point recycling must occur. A mixed-integer program is implemented to plan the relocation of the mobile recycling units in such a way that the total cost resulting from waste transport and facility relocation is minimized. To solve large instances, three heuristics are developed that form the basis for a detailed computational study. The results reveal that mobile recycling units can significantly reduce the total costs compared to centralized recycling because (a) a larger number of mobile recycling units, (b) larger storage capacities, and (c) more short-term relocation possibilities increase the optimization scope and thus the possibility to reduce the total transport distances, and thereby, the costs. However, achieving this requires intelligent planning that considers the complex interdependencies between the influencing parameters and balances the existing trade-offs.},
  archive      = {J_COR},
  author       = {Eduardo Alarcon-Gerbier and Udo Buscher},
  doi          = {10.1016/j.cor.2024.106609},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106609},
  shortjournal = {Comput. Oper. Res.},
  title        = {The dynamic facility location problem with mobile production units: A waste recycling application},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Benchmarking problems for robust discrete optimization.
<em>COR</em>, <em>166</em>, 106608. (<a
href="https://doi.org/10.1016/j.cor.2024.106608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust discrete optimization is a highly active field of research where a plenitude of combinations between decision criteria, uncertainty sets and underlying nominal problems are considered. Usually, a robust problem becomes harder to solve than its nominal counterpart, even if it remains in the same complexity class. For this reason, specialized solution algorithms have been developed. To further drive the development of stronger solution algorithms and to facilitate the comparison between methods, a set of benchmark instances is necessary but so far missing. In this paper we propose a further step towards this goal by proposing several instance generation procedures for combinations of min–max, min–max regret, two-stage and recoverable robustness with interval, discrete, budgeted or ellipsoidal uncertainty sets. Besides sampling methods that go beyond the simple uniform sampling method that is the de-facto standard to produce instances, also optimization models to construct hard instances are considered. Using a selection problem for the nominal ground problem, we are able to generate instances that are several orders of magnitudes harder to solve than uniformly sampled instances when solving them with a general mixed-integer programming solver. All instances and generator codes are made available online.},
  archive      = {J_COR},
  author       = {Marc Goerigk and Mohammad Khosravi},
  doi          = {10.1016/j.cor.2024.106608},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106608},
  shortjournal = {Comput. Oper. Res.},
  title        = {Benchmarking problems for robust discrete optimization},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing emergency supply pre-positioning for disaster
relief: A two-stage distributionally robust approach. <em>COR</em>,
<em>166</em>, 106607. (<a
href="https://doi.org/10.1016/j.cor.2024.106607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanitarian organizations commonly establish facilities to store emergency supplies in advance, ensuring a prompt and adequate response to non-climate and sudden-onset natural disasters. However, existing research on facility location and inventory pre-positioning does not adequately examine multiple sources of post-disaster emergency supplies, which are critical for an efficient response. Additionally, disaster managers encounter various uncertain parameters when making decisions, such as disaster characteristics, demand, transportation, and supply. To address these issues, we develop a novel two-stage distributionally robust optimization model to minimize the total expected costs in the worst case. The facility location and quantity of pre-positioned emergency supplies are decided in the first stage before the occurrence of disasters. In the second stage, emergency supplies that are pre-positioned in advance or purchased from spot markets, as well as in-kind donations, are distributed to affected areas. Two tailor-made column-and-constraint generation (C&amp;CG) algorithms, consisting of an exact and an approximation scheme, are designed to solve the proposed model. A case study based on the data collected from the earthquakes in Pu’er City, Yunnan Province, China, demonstrates the superiority of the proposed model, and provides managerial insights for decision-makers. Furthermore, the effectiveness and efficiency of the proposed algorithms are demonstrated by the results of experiments conducted on randomly generated instances.},
  archive      = {J_COR},
  author       = {Ada Che and Jing Li and Feng Chu and Chengbin Chu},
  doi          = {10.1016/j.cor.2024.106607},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106607},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing emergency supply pre-positioning for disaster relief: A two-stage distributionally robust approach},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation algorithms for job scheduling with block-type
conflict graphs. <em>COR</em>, <em>166</em>, 106606. (<a
href="https://doi.org/10.1016/j.cor.2024.106606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of scheduling jobs on parallel machines (identical, uniform, or unrelated), under incompatibility relation modeled as a block graph, under the makespan optimality criterion, is considered in this paper. No two jobs that are in the relation (equivalently in the same block) may be scheduled on the same machine in this model. The presented model stems from a well-established line of research combining scheduling theory with methods relevant to graph coloring. Recently, cluster graphs and their extensions like block graphs were given additional attention. We complement hardness results provided by other researchers for block graphs by providing approximation algorithms. In particular, we provide a 2-approximation algorithm for P | G = block graph | C max P|G=block graph|Cmax and a PTAS for the case when the jobs are unit time in addition. In the case of uniform machines, we analyze two cases. The first one is when the number of blocks is bounded, i.e. Q | G = k − block graph | C max Q|G=k − block graph|Cmax . For this case, we provide a PTAS, improving upon results presented by D. Page and R. Solis-Oba. The improvement is two-fold: we allow richer graph structure, and we allow the number of machine speeds to be part of the input. Due to strong NP-hardness of Q | G = 2 − clique graph | C max Q|G=2 − clique graph|Cmax , the result establishes the approximation status of Q | G = k − block graph | C max Q|G=k − block graph|Cmax . The PTAS might be of independent interest because the problem is tightly related to the NUMERICAL k k -DIMENSIONAL MATCHING WITH TARGET SUMS problem. The second case that we analyze is when the number of blocks is arbitrary, but the number of cut-vertices is bounded and jobs are of unit time. In this case, we present an exact algorithm. In addition, we present an FPTAS for graphs with bounded treewidth and a bounded number of unrelated machines. The paper ends with extensive tests of the selected algorithms.},
  archive      = {J_COR},
  author       = {Hanna Furmańczyk and Tytus Pikies and Inka Sokołowska and Krzysztof Turowski},
  doi          = {10.1016/j.cor.2024.106606},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106606},
  shortjournal = {Comput. Oper. Res.},
  title        = {Approximation algorithms for job scheduling with block-type conflict graphs},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast path relinking algorithm for the min–max edge
crossing problem. <em>COR</em>, <em>166</em>, 106603. (<a
href="https://doi.org/10.1016/j.cor.2024.106603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The min–max edge crossing problem (MMECP) is a challenging and important problem arising in integrated-circuit design, information visualization, and software engineering. Drawing edges as straight lines in accordance with the hierarchical graph drawing standard, the goal is to reduce the maximum number of edge crossings in graphs. In this study, we propose a fast path relinking (FPR) method based on dynamic-programming local search to tackle the MMECP, where an efficient neighborhood reduction mechanism is employed to evaluate only the so-called critical vertices instead of all the vertices. Moreover, the proposed FPR can simultaneously manage a number of neighborhood moves at each search iteration, which is significantly different from all the previous approaches based on one neighborhood in the literature. Extensive computational experiments on MMECP instances show that our proposed FPR approach is relatively competitive compared to the best-performing heuristics and the optimization Gurobi solver. In particular, our algorithm improved the best-known solutions for 104 of the 301 publicly available benchmark instances. Additional experiments were conducted to elucidate the key elements and search parameters of the proposed FPR. Furthermore, we made the source code of the algorithm publicly available to facilitate its use in real applications and future research.},
  archive      = {J_COR},
  author       = {Bo Peng and Lunwen Wu and Rafael Martí and Jiangshui Ma},
  doi          = {10.1016/j.cor.2024.106603},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106603},
  shortjournal = {Comput. Oper. Res.},
  title        = {A fast path relinking algorithm for the min–max edge crossing problem},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A matheuristic for locating obnoxious facilities.
<em>COR</em>, <em>166</em>, 106602. (<a
href="https://doi.org/10.1016/j.cor.2024.106602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilities such as waste plants or wind turbines are often referred to as obnoxious facilities because they negatively affect their nearby environment, for example, through noise or pollution. In the obnoxious p p -median problem, a set of clients and a set of potential locations for obnoxious facilities are given. From the set of potential locations, p p facilities must be opened. The goal is to place the facilities far away from the clients to avoid high negative effects. Existing approaches for this planning problem are either not scalable to large instances or not flexible in considering practical constraints that often arise in real-world settings. To address these limitations, we propose a matheuristic for the obnoxious p p -median problem. First, the matheuristic generates diverse initial solutions, allowing an effective exploration of the solution space. Second, it iteratively improves these initial solutions using enhanced mathematical models. We additionally propose a clustering-based scaling technique to tackle large instances. Thus, our matheuristic is scalable to instances involving thousands of clients and potential locations and is flexible to incorporate practical constraints. Our computational results show that our matheuristic outperforms the leading metaheuristics from the literature on large instances and is competitive with the leading metaheuristics on small and medium instances. The features of our matheuristic can be generalized and applied to related planning problems.},
  archive      = {J_COR},
  author       = {Tamara Bigler},
  doi          = {10.1016/j.cor.2024.106602},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106602},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic for locating obnoxious facilities},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch-and-cut approach to solve the fault diagnosis
problem with lazy spread and imperfect system information. <em>COR</em>,
<em>166</em>, 106598. (<a
href="https://doi.org/10.1016/j.cor.2024.106598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach to solving the Fault Diagnosis Problem with Lazy Spread (FDPL) that arises in many fault-tolerant real-world systems with few opportunities for maintenance during their operations and significant failure interactions between the subsystems/components. As opposed to cascading faults that spread to most of the system almost instantaneously, FDPL considers fault-resistant systems where the spread of failures is relatively slow (lazy), i.e., only a small fraction of the components are faulty at the time of inspection, and accurate diagnosis of the faulty components is of critical importance to restore system performance and stop further damage. Introducing an extra level of difficulty, FDPL needs to be solved under imperfect (missing and wrong) system information in most real-world settings. To address this challenging prediction problem, we use graph theory concepts to develop an integer programming formulation and devise an efficient branch-and-cut algorithm for its solution. Extensive numerical experiments on realistic problem instances attest to the superior performance of our approach in terms of both computational efficiency and prediction accuracy compared to the state-of-the-art in the literature.},
  archive      = {J_COR},
  author       = {Kaan Pekel and Yılmazcan Özyurt and Barış Yıldız and Ali K. Dogru},
  doi          = {10.1016/j.cor.2024.106598},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106598},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-cut approach to solve the fault diagnosis problem with lazy spread and imperfect system information},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A branch, bound and remember algorithm for maximizing the
production rate in the simple assembly line balancing problem.
<em>COR</em>, <em>166</em>, 106597. (<a
href="https://doi.org/10.1016/j.cor.2024.106597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simple assembly line balancing problem is a classical optimization problem. It aims at efficiently assigning elementary operations to the workstations of a paced assembly line to optimize some efficiency measure. In this paper, we deal with the type-2 version of the problem in which the efficiency measure is the maximization of throughput with a given number of workstations. This problem has been scarcely studied compared to its type-1 counterpart, in which the throughput is fixed and the objective is to minimize the number of workstations. This has led to the development of indirect methods using type-1 exact solution methods to tackle the type-2 case. In this paper, we provide lower bounds, logical tests, and dominance rules for the type-2 problem and adapt the state-of-the-art method for the type-1 problem to develop a direct approach for solving the type-2 problem with a direct approach. Computational results show the effectiveness of the direct method, which can outperform recent type-1-based indirect approaches. The proposed method is able to close all instances from the classical instance set and solves to optimality over 90% of the large (100 tasks) and 76.5% of the very large (1000 tasks) instances derived from the current reference set for its type-1 counterpart. The average gaps between the upper and lower bounds on the optimal cycle time are also tight and are less than 0.13% (0.4%) for large (very large) instances. Finally, our results show that direct and indirect methods are comparable in terms of solution quality, but the direct method outperforms its indirect counterpart in terms of running time and optimality gaps. Moreover, we identify that instances averaging two to three tasks per workstation and featuring large variability between task times pose significant challenges to solve to optimality.},
  archive      = {J_COR},
  author       = {Eduardo Álvarez-Miranda and Jordi Pereira and Mariona Vilà},
  doi          = {10.1016/j.cor.2024.106597},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106597},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch, bound and remember algorithm for maximizing the production rate in the simple assembly line balancing problem},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heuristic and metaheuristic procedures for the parallel
assembly lines balancing problem with multi-line workstations and buffer
sizing. <em>COR</em>, <em>166</em>, 106596. (<a
href="https://doi.org/10.1016/j.cor.2024.106596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the parallel assembly lines balancing problem (PALBP) with multi-line workstations, lines with different cycle times and buffer sizing. When a PALB system works with lines with different cycle times, the lines with multi-line workstations have to produce in batches; thus, the use of buffers may be needed. For the first time in the literature, this study jointly solved the PALBP and the buffer sizing problem (PALBP-B). Due to the multi-objective nature of the problem (minimising the number of workstations and the total buffer size in the multi-line workstations), several multi-objective heuristics and metaheuristics are proposed to solve the PALBP-B. Finally, an extensive computational experiment is carried out to analyse all the procedures presented.},
  archive      = {J_COR},
  author       = {Harry Aguilar and Alberto García-Villoria and Rafael Pastor},
  doi          = {10.1016/j.cor.2024.106596},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106596},
  shortjournal = {Comput. Oper. Res.},
  title        = {Heuristic and metaheuristic procedures for the parallel assembly lines balancing problem with multi-line workstations and buffer sizing},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reentrant open shop scheduling problem with time lags and
no-wait constraints. <em>COR</em>, <em>166</em>, 106595. (<a
href="https://doi.org/10.1016/j.cor.2024.106595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the two-machine reentrant open shop scheduling problem with no-wait and exact time lags constraints. The objective is to minimize the makespan. We first prove that this problem is NP-hard in the strong sense, then we provide some polynomial sub-problems. To solve the general problem, a heuristic and metaheuristics with hybridizations are proposed with numerical experiments.},
  archive      = {J_COR},
  author       = {Kenza Alioui and Karim Amrouche and Mourad Boudhar},
  doi          = {10.1016/j.cor.2024.106595},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106595},
  shortjournal = {Comput. Oper. Res.},
  title        = {Reentrant open shop scheduling problem with time lags and no-wait constraints},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quick response under strategic consumers with high-price and
stockout regrets. <em>COR</em>, <em>166</em>, 106590. (<a
href="https://doi.org/10.1016/j.cor.2024.106590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies optimal pricing and inventory decisions of a perishable goods vendor in a traditional replenishment and quick-response system context—with the vendor offering strategic consumers who may exhibit regret behavior. Sometimes consumers may purchase goods without discounts (full-price) later experiencing high-price regret. Alternatively, consumers may face stockout regret when during goods price discount periods they face stockout. This study asks the question of whether and how firm price setting and inventory policy are affected by this dichotomy of regret and the quick-response cost with this regret behavior. The paper then identifies and compares the values of regret in the two systems and the values of quick response with and without regret. Findings show that stockout regret positively affects firm optimal pricing and profit in both systems. High-price regret has opposite effects. Additionally, regret in both systems have a positive value when stockout regret is significant and a negative value otherwise. When considering situations with and without regret, quick-response policy is consistently better than traditional replenishment policy. In a high quick-response cost situation, as the level of stockout (or high-price) regret increases (or decreases), the optimal firm policy transitions from traditional replenishment to quick-response policy. Finally, when stockout regret (or high-price regret) is significant, the value of regret in the quick-response system is higher than traditional replenishment system value of regret when quick-response cost is high (or low).},
  archive      = {J_COR},
  author       = {Hua Wang and Chunguang Bai and Benjamin Lev and Wei Chen},
  doi          = {10.1016/j.cor.2024.106590},
  journal      = {Computers &amp; Operations Research},
  month        = {6},
  pages        = {106590},
  shortjournal = {Comput. Oper. Res.},
  title        = {Quick response under strategic consumers with high-price and stockout regrets},
  volume       = {166},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model and metaheuristic for human–robot collaboration
assembly line worker assignment and balancing problem. <em>COR</em>,
<em>165</em>, 106605. (<a
href="https://doi.org/10.1016/j.cor.2024.106605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the Industry 5.0 trend towards human-centric and resilient industries, workers continue to be considered as a valuable and irreplaceable resource. Human–robot collaboration (HRC) is a promising production mode that combines the advantages of both human workers and robots, resulting in improved productivity and reduced ergonomic risks for workers. In this study, we present one of the first attempts to address the human–robot collaboration assembly line worker assignment and balancing problem (HRCALWABP), which allows workers and robots to perform tasks in parallel or in collaboration. Workers are heterogeneous, leading to variations in task execution times. We formulate a mixed-integer linear programming (MILP) model that minimizes the cycle time and propose a tight lower/upper bound. A rebalancing process is further considered in this study. Due to the complexity of HRCALWABP, we develop an improved adaptive neighborhood simulated annealing algorithm (IASA). An adaptive mechanism is applied to the IASA to dynamically adjust the selection probability of the designed neighborhood structures and operators, and a restart mechanism is developed for improving the search capacity. Extensive computational experiments are conducted to evaluate the performance of both the MILP and IASA, and the results confirm the superiority of the IASA compared to the MILP and other existing algorithms.},
  archive      = {J_COR},
  author       = {Zhaofang Mao and Yiting Sun and Kan Fang and Dian Huang and Jiaxin Zhang},
  doi          = {10.1016/j.cor.2024.106605},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106605},
  shortjournal = {Comput. Oper. Res.},
  title        = {Model and metaheuristic for human–robot collaboration assembly line worker assignment and balancing problem},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A proactive aircraft recovery approach based on airport
spatiotemporal network supply and demand coordination. <em>COR</em>,
<em>165</em>, 106599. (<a
href="https://doi.org/10.1016/j.cor.2024.106599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Aircraft Recovery Problem (ARP) is to modify the flight and aircraft schedules with compensation for the irregular aircraft operations due to disruptions, falling under passive control. This reactive approach is challenging and often leads to additional secondary delays. The accumulation of historical data and advancements in big data technology have enabled a proactive approach to ARP. If the disruptions that will occur in a certain period of time in the future can be predicted in advance, a preventive plan can be made in advance to actively control the irregular operation of the flight. Predicting disruptions before they occur allows for preemptive planning to actively manage flight irregularities. This paper proposes a proactive approach to ARP, optimizing recovery decisions considering the unpredictability of airport capacity in space and time and the dynamics of flight delay resolutions. It examines ARP from the viewpoint of balancing supply and demand across the airport spatiotemporal network through aircraft rotations between airports. The paper builds a Proactive Aircraft Recovery Model and proposes a Decision-Decomposition-Based Algorithm framework based on collaborative allocation of airport capacity and flow. By applying this approach to operational data from four Chinese airlines, it demonstrates the ability to dynamically reschedule flights and reassign aircraft based on anticipated disruptions, proactively addressing real-time aircraft schedule disruptions within a suitable operational timeframe. Results indicate that mitigating airport demand-capacity imbalances at the spatiotemporal level effectively reduce airline delays and operating costs in actual operations.},
  archive      = {J_COR},
  author       = {Haipei Zang and Jinfu Zhu and Qi Zhu and Qiang Gao},
  doi          = {10.1016/j.cor.2024.106599},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106599},
  shortjournal = {Comput. Oper. Res.},
  title        = {A proactive aircraft recovery approach based on airport spatiotemporal network supply and demand coordination},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A variable neighborhood search approach for solving a
real-world hierarchical multi-echelon vehicle routing problem involving
HCT vehicles. <em>COR</em>, <em>165</em>, 106594. (<a
href="https://doi.org/10.1016/j.cor.2024.106594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the Hierarchical Multi-Switch Multi-Echelon VRP (HMSME-VRP), a newly introduced VRP variant based on a real-world case involving High Capacity Vehicles (HCV). The problem originates from the policies of a distribution company in the Nordic countries where HCVs of up to 34.5 m and up to 76 tons are allowed. The HMSME-VRP offer a new way to model distribution problems to cover large geographical areas without substantial costs in infrastructure. Furthermore, it adds complexity to the standard VRP and, as such, remains NP NP -hard and difficult to solve to optimality. Indeed, it has been demonstrated that only very small instances can be solved to optimality by a commercial solver. Thus, in order to handle instances of real-world size, we propose two General Variable Neighborhood Search (GVNS) procedures, the second of which is adaptive, utilizing an intelligent reordering mechanism. In order to evaluate the proposed procedures, 48 benchmark instances of various sizes and characteristics are generated and made publicly available, comprising of clustered, random, and semi-clustered customers. The computational results show that both GVNS procedures outperform the exact solver. Additionally, the adaptive version outperforms the conventional version based on both average and best solutions. Furthermore, we present a statistical analysis to verify the superiority of the adaptive version.},
  archive      = {J_COR},
  author       = {Marduch Tadaros and Angelo Sifaleras and Athanasios Migdalas},
  doi          = {10.1016/j.cor.2024.106594},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106594},
  shortjournal = {Comput. Oper. Res.},
  title        = {A variable neighborhood search approach for solving a real-world hierarchical multi-echelon vehicle routing problem involving HCT vehicles},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Supplier selection under disruption risk with hybrid
procurement. <em>COR</em>, <em>165</em>, 106593. (<a
href="https://doi.org/10.1016/j.cor.2024.106593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s global landscape, supply chains face a plethora of risks due to the increasingly dynamic and turbulent business environment. In this study, we introduce a supplier selection model with hybrid procurement under disruption risk. Specifically, we consider the supplier selection problem of a firm with multiple units (or business segments) demanding several products, raw materials, and services. The firm has a centralized supplier selection strategy at the corporate level. However, instead of allocating orders to selected suppliers, the corporate management allows each unit to use its most preferred suppliers from the selected ones in a decentralized manner. To mitigate the impact of disruptions, less preferred suppliers of each unit serve as a backup. We present a mathematical model for this problem and study the structural properties of our formulation. We develop an exact Benders decomposition algorithm, and also present a method to generate upper and lower bounds. We compare the performance of the proposed solution algorithms on large-scale instances. Finally, we present a numerical example to demonstrate the impact of decentralized procurement with different objectives. Our results show that the expected procurement cost can increase significantly if suppliers are selected without considering the decentralized decisions of units.},
  archive      = {J_COR},
  author       = {Shakiba Enayati and Osman Y. Özaltın},
  doi          = {10.1016/j.cor.2024.106593},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106593},
  shortjournal = {Comput. Oper. Res.},
  title        = {Supplier selection under disruption risk with hybrid procurement},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nesting and scheduling optimization of additive
manufacturing systems: Mapping the territory. <em>COR</em>,
<em>165</em>, 106592. (<a
href="https://doi.org/10.1016/j.cor.2024.106592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Additive Manufacturing (AM) within industrial settings brings new challenges to operational research. This paper provides in-depth analyses of nesting and scheduling problems in the context of AM. Using bibliometric and systematic review methods, we map the progression of knowledge in this territory and provide a detailed characterization of the existing mathematical models and approaches. Our findings indicate the fundamental decisions that predominate in these models and reveal the relationships between the critical studies, which form the backbone of the research. While the nesting and scheduling problem can be categorized into six types of decision, we have also found other emerging and interrelated optimization problems associated with nesting and scheduling decisions. To provide further details, an ample number of models are systematized in a reference framework for modeling nesting and scheduling in AM. Finally, pressing future research avenues that have emerged from our analysis and that need to be addressed to further advance the field are presented.},
  archive      = {J_COR},
  author       = {Marcelo Pinto and Cristóvão Silva and Matthias Thürer and Samuel Moniz},
  doi          = {10.1016/j.cor.2024.106592},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106592},
  shortjournal = {Comput. Oper. Res.},
  title        = {Nesting and scheduling optimization of additive manufacturing systems: Mapping the territory},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparison of alternative models for solving a non-linear
single plant hydro unit commitment problem. <em>COR</em>, <em>165</em>,
106591. (<a href="https://doi.org/10.1016/j.cor.2024.106591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wide range of real world optimization problems involves continuous decisions and non-linearities. Each non-linear component of such problems can be modeled either linearly or non-linearly, considering or not additional integer variables. This results into different modeling choices that can drastically impact the solution time and quality. In this paper, we evaluate representative modeling alternatives, including common models from the literature as well as new models featuring less common functions. The single plant Hydro Unit Commitment problem (1-HUC) is the considered non-linear use case. Among the non-linearities of the 1-HUC, we focus on those involved in the power production, more precisely the head effect and the turbines efficiency. The power is defined as a two-dimensional non-convex and non-concave function of the water flow and head decision variables, the latter being itself a one-dimensional concave function of the turbined volume. We consider both the general problem and a common special case, assuming that the water head is fixed. Several available solvers are used for each non-linear model and the best virtual solver is retained to focus on the model capabilities rather than on the solver performance. Based on the numerical experiments, three models stand out as the most efficient in terms of computational time, solution quality and feasibility, sometimes in a counter-intuitive manner. For each of these models, a solver is highlighted as the most adequate.},
  archive      = {J_COR},
  author       = {Alexandre Heintzmann and Christian Artigues and Pascale Bendotti and Sandra Ulrich Ngueveu and Cécile Rottner},
  doi          = {10.1016/j.cor.2024.106591},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106591},
  shortjournal = {Comput. Oper. Res.},
  title        = {A comparison of alternative models for solving a non-linear single plant hydro unit commitment problem},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parallel variable neighborhood search for α-neighbor
facility location problems. <em>COR</em>, <em>165</em>, 106589. (<a
href="https://doi.org/10.1016/j.cor.2024.106589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we employ the less is more approach to develop a Parallel Variable Neighborhood Search (VNS) algorithm for the α α -neighbor p p -center problem ( α α N p p CP) and the α α -neighbor p p -median problem ( α α N p p MP). The α α N p p CP and the α α N p p MP are generalizations of the p p -center ( p p CP) and p p -median ( p p MP) problems, respectively. In the α α -neighbor problems, one seeks to open p p facilities and assign each of the n n customers to their closest α α ones. The objective is to minimize the maximum distance of a customer to its α α th facility, in the case of the α α N p p CP, and the sum of the distances from each customer to their α α nearest facilities, in the case of the α α N p p MP. Our VNS adapts simple but efficient algorithms and data structures from the p p CP and p p MP literature to the α α N p p CP and α α N p p MP context. We also introduce an updated objective function for the α α N p p CP, which adds more information to the solution cost and helps the VNS to escape from local optima. Several experimental tests show that our VNS outperforms more complex state-of-the-art algorithms. Regarding the α α N p p CP, on 120 instances derived from the OR-library set, our algorithm improved best-known solutions for 22, with an average improvement of 34.26%; the overall gap on the 120 instances is 6.18% in favor of our algorithm. Moreover, on 231 instances derived from the TSPLIB set, we improved the solutions for 115, with an average improvement of 5.30%, and an overall improvement gap of 2.47% for all 231 instances. Considering the α α N p p MP results, our heuristic obtained better results than a heuristic from literature in all 80 instances tested, finding optimal solutions in all these instances.},
  archive      = {J_COR},
  author       = {Guilherme O. Chagas and Luiz A.N. Lorena and Rafael D.C. dos Santos and Jacques Renaud and Leandro C. Coelho},
  doi          = {10.1016/j.cor.2024.106589},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106589},
  shortjournal = {Comput. Oper. Res.},
  title        = {A parallel variable neighborhood search for α-neighbor facility location problems},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A ride time-oriented scheduling algorithm for dial-a-ride
problems. <em>COR</em>, <em>165</em>, 106588. (<a
href="https://doi.org/10.1016/j.cor.2024.106588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper offers a new algorithm to efficiently optimize scheduling decisions for dial-a-ride problems (DARPs), including problem variants considering electric and autonomous vehicles (e-ADARPs). The scheduling heuristic, based on linear programming theory, aims at finding minimal user ride time schedules in worst-case quadratic time. The algorithm can either return feasible routes or it can return incorrect infeasibility declarations, on which feasibility can be recovered through a specifically-designed heuristic. The algorithm is furthermore supplemented by a battery management algorithm that can be used to determine charging decisions for electric and autonomous vehicle fleets. Timing solutions from the proposed scheduling algorithm are obtained on millions of routes extracted from DARP and e-ADARP benchmark instances. They are compared to those obtained from a linear program, as well as to popular scheduling procedures from the DARP literature. The proposed procedure mostly yields optimal solutions, with nearly-optimal solutions occurring in only 27 out of 21.5 million cases on DARP instances. Additionally, it demonstrates an average speed improvement of around 60% compared to a linear program and performs comparably to benchmark scheduling approaches from the DARP literature, while outperforming them in solution quality.},
  archive      = {J_COR},
  author       = {Claudia Bongiovanni and Nikolas Geroliminis and Mor Kaspi},
  doi          = {10.1016/j.cor.2024.106588},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106588},
  shortjournal = {Comput. Oper. Res.},
  title        = {A ride time-oriented scheduling algorithm for dial-a-ride problems},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The impact of partial production capacity sharing via
production as a service. <em>COR</em>, <em>165</em>, 106587. (<a
href="https://doi.org/10.1016/j.cor.2024.106587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud manufacturing, one of the trends subsumed under Industry 4.0, influences industrial production settings as it transforms resource utilization into a shared on-demand service. Central to cloud manufacturing is the Production as a Service (PaaS) paradigm, which allows intermediaries to coordinate supply and demand of idle production capacities and enables collaboration in production through outsourcing. Current practical implementations of PaaS use multiple steps to connect buyers and suppliers through an intermediary that treats each demand request individually and subsequently contacts a pool of suppliers. In contrast, we study a novel optimization-based PaaS approach and develop a combinatorial exchange model for production capacity sharing among multiple suppliers and buyers. To this end, we adapt the winner determination problem from procurement auction settings. We find that key performance indicators such as matched capacity, overall payment, and unfulfilled minimum demand depend on both the employed bidding behavior and the buyer and supplier ratio. We additionally develop a corresponding online counterpart that can be readily implemented in practice and show that it yields close to optimal solutions. Finally, we show that our solution approach increases the efficiency of matching idle production capacities on average by 39% and also increases the average supplier payoff by up to 74% compared to a practice-based benchmark heuristic.},
  archive      = {J_COR},
  author       = {Christina J. Liepold and Okan Arslan and Gilbert Laporte and Maximilian Schiffer},
  doi          = {10.1016/j.cor.2024.106587},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106587},
  shortjournal = {Comput. Oper. Res.},
  title        = {The impact of partial production capacity sharing via production as a service},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving unconstrained binary polynomial programs with
limited reach: Application to low autocorrelation binary sequences.
<em>COR</em>, <em>165</em>, 106586. (<a
href="https://doi.org/10.1016/j.cor.2024.106586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unconstrained Binary Polynomial Programs (UBPs) are a class of optimization problems relevant in a broad array of fields. In this paper, we examine an example from communication engineering, namely low autocorrelation binary sequences and propose a new dynamic programming approach that is particularly effective on UBP instances that have a limited so-called reach, which is a metric that states the maximum difference between any two variable indices across all monomials in the UBP. Based on the reach, the dynamic programming approach decomposes the problem into a number of overlapping stages that can be solved in parallel. On a set of publicly available low autocorrelation binary sequence problems, we demonstrate the superiority of the approach by showing that the method solves to optimality for the first time several previously unsolved instances. In particular, we provide a direct comparison between the proposed method and a modern version of a previously proposed dynamic program for UBPs. We give a detailed analysis of the connection between the two different algorithms and demonstrate that the advantage of the proposed dynamic program is in its ability to implicitly identify the multilinear polynomials that are required in the recursive steps of the two dynamic programs. For perspective, a comparison to several other methods is also provided.},
  archive      = {J_COR},
  author       = {Jens Vinther Clausen and Yves Crama and Richard Lusby and Elisabeth Rodríguez-Heck and Stefan Ropke},
  doi          = {10.1016/j.cor.2024.106586},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106586},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving unconstrained binary polynomial programs with limited reach: Application to low autocorrelation binary sequences},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shore hydrogen deployment problem in green ports.
<em>COR</em>, <em>165</em>, 106585. (<a
href="https://doi.org/10.1016/j.cor.2024.106585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of carbon neutrality and peak carbon, research on emerging technologies for the clean, efficient, safe, and sustainable development of green ports and green shipping is crucial. The application of carbon-free hydrogen fuel cell technology to vessels and ports is seen as an effective solution. This study investigates the deployment of shore hydrogen in a green port, aiming to optimize a hydrogen energy retrofit and subsidy scheme to maximize the port’s profit and the hydrogen energy consumption given a limited government subsidy. A mixed integer linear programming model is constructed to take into account the reconstruction of the port and the retrofitting of the vessels calling at the port. We develop a tailored branch-and-cut algorithm to solve the problem. Extensive numerical experiments are carried out, and the results demonstrate the applicability and efficiency of the algorithm in solving the problem. The solution to the problem provided by our algorithm could promote the use of hydrogen energy while maintaining port profits, thereby effectively reducing carbon emissions from vessels calling at port.},
  archive      = {J_COR},
  author       = {Qian Zhang and Zheyi Tan and Shuaian Wang and Lu Zhen},
  doi          = {10.1016/j.cor.2024.106585},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106585},
  shortjournal = {Comput. Oper. Res.},
  title        = {Shore hydrogen deployment problem in green ports},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). General variable neighborhood search for the optimization of
software quality. <em>COR</em>, <em>165</em>, 106584. (<a
href="https://doi.org/10.1016/j.cor.2024.106584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the area of Search-Based Software Engineering, software engineering issues are formulated and tackled as optimization problems. Among the problems within this area, the Software Module Clustering Problem (SMCP) consists of finding an organization of a software project that minimizes coupling and maximizes cohesion. Since modular code is easier to understand, the objective of this problem is to increase the quality of software projects, thus increasing their maintainability and reducing the associated costs. In this work we study a recently proposed objective function named Function of Complexity Balance (FCB). Since this problem has been demonstrated to be NP NP -hard, we propose a new heuristic algorithm based on the General Variable Neighborhood Search (GVNS) schema to tackle the problem. For the GVNS, we propose six different neighborhood structures and categorize them into three different groups. Then, we analyze their contribution to the results obtained by the algorithm. In order to improve the efficiency of the proposed approach, we leverage domain-specific information to perform incremental evaluations of the objective function and to explore only areas of interest in the search space. The proposed algorithm has been tested over a set of real world software repositories, achieving better results than the previous state-of-the-art method, a Hybrid Genetic Algorithm, in terms of both quality and computing times. Furthermore, the relevance of the improvement produced by our proposal has been corroborated by non-parametric statistical tests.},
  archive      = {J_COR},
  author       = {Javier Yuste and Eduardo G. Pardo and Abraham Duarte},
  doi          = {10.1016/j.cor.2024.106584},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106584},
  shortjournal = {Comput. Oper. Res.},
  title        = {General variable neighborhood search for the optimization of software quality},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A comparative study of alternative formulations for the
periodic vehicle routing problem. <em>COR</em>, <em>165</em>, 106583.
(<a href="https://doi.org/10.1016/j.cor.2024.106583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the periodic vehicle routing problem (PVRP) and its variant with time windows with a particular focus on alternative formulation approaches that can be solved by a state-of-the-art commercial solver. We propose a new vehicle flow formulation for the PVRP and strengthen it with valid inequalities. We also investigate two prominent formulations for the PVRP available in the literature: a commodity flow formulation, referred to as the load-based formulation, and a cut-based formulation which is adapted from a formulation originally developed for a variant of the PVRP. We also extend these formulations to model the PVRP with time windows (PVRPTW) and employ valid inequalities to tighten the resulting formulations. A comprehensive computational study is then carried out to compare the performances of alternative PVRP and PVRPTW formulations on various sets of benchmark instances with different characteristics. The results attest to the robustness and the consistency of the proposed formulation and its strengthened versions in producing good quality solutions, especially for large instances although the load-based formulations tend to perform well in small instances.},
  archive      = {J_COR},
  author       = {Saeedeh Ahmadi Basir and Güvenç Şahin and Gizem Özbaygın},
  doi          = {10.1016/j.cor.2024.106583},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106583},
  shortjournal = {Comput. Oper. Res.},
  title        = {A comparative study of alternative formulations for the periodic vehicle routing problem},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving the scheduling of railway maintenance projects by
minimizing passenger delays subject to event requests of railway
operators. <em>COR</em>, <em>165</em>, 106580. (<a
href="https://doi.org/10.1016/j.cor.2024.106580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Netherlands, it is expected that passenger activities on railway networks will double by 2050. To manage the passenger demand, railway capacity planning needs to be adapted. One fundamental aspect of the railway capacity planning is the scheduling of large maintenance projects. These maintenance requests should not be scheduled during major events to avoid the disruption of service. To do so, passenger operators can submit event request, i.e., a time period and location in which no maintenance project should be scheduled. Currently, these event requests are considered as hard constraints and the flexibility in maintenance scheduling decreases resulting in conflicts. In this study, the focus is on scheduling maintenance projects to minimize passenger delays while relaxing the hard constraints of event requests. This problem is addressed by introducing a Mixed Integer Linear Program (MILP) that minimizes passenger delays while scheduling maintenance projects, which includes capacity constraints for alternative services in event request areas during maintenance projects. The computational complexity of the proposed model is reduced by adding valid inequalities from the Single Machine Scheduling problem and using a simulated annealing meta-heuristic to find a favorable initial solution guess. Then, the MILP is solved to global optimality with Branch-and-Bound. A case study on the Dutch railway network shows improvements when event requests are not considered as hard constraints and an increase in the flexibility to schedule maintenance projects. This allows decision makers to choose from a set of optimal maintenance schedules with different characteristics.},
  archive      = {J_COR},
  author       = {Y.R. de Weert and K. Gkiotsalitis and E.C. van Berkum},
  doi          = {10.1016/j.cor.2024.106580},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106580},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improving the scheduling of railway maintenance projects by minimizing passenger delays subject to event requests of railway operators},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved column-generation-based matheuristic for
learning classification trees. <em>COR</em>, <em>165</em>, 106579. (<a
href="https://doi.org/10.1016/j.cor.2024.106579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees are highly interpretable models for solving classification problems in machine learning (ML). The standard ML algorithms for training decision trees are fast but generate suboptimal trees in terms of accuracy. Other discrete optimization models in the literature address the optimality problem but only work well on relatively small datasets. Firat et al. (2020) proposed a column-generation-based heuristic approach for learning decision trees. This approach improves scalability and can work with large datasets. In this paper, we describe improvements to this column generation approach. First, we modify the subproblem model to significantly reduce the number of subproblems in multiclass classification instances. Next, we show that the data-dependent constraints in the master problem are implied, and use them as cutting planes. Furthermore, we describe a separation model to generate data points for which the linear programming relaxation solution violates their corresponding constraints. We conclude by presenting computational results that show that these modifications result in better scalability.},
  archive      = {J_COR},
  author       = {Krunal Kishor Patel and Guy Desaulniers and Andrea Lodi},
  doi          = {10.1016/j.cor.2024.106579},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106579},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved column-generation-based matheuristic for learning classification trees},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The costs of overcrowding (and release): Strategic
discharges for isolated facilities during epidemiological outbreaks.
<em>COR</em>, <em>165</em>, 106578. (<a
href="https://doi.org/10.1016/j.cor.2024.106578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For isolated, densely populated facilities, such as prisons and nursing homes, it is difficult to enact social distancing measures when catastrophic epidemiological outbreaks occur. In such facilities, strategic releases can enhance social distancing, yet have inherent costs, e.g., the potential for recidivism in crime for prisons, or the financial cost of incentives for residents to break contracts in nursing homes. In this paper, we examine how to structure these releases over time to de-densify isolated facilities under several competing objectives. We model the impact of strategic releases on infection transmission with a quadratic function that relates population size and daily interaction rate, which we call the de-densification function . Then, we formulate a multi-criteria MDP and develop dynamic algorithms that employ Monte Carlo simulations, k k -means clustering, and Q Q -learning with linear function approximation. We consider a facility experiencing an outbreak described by a Susceptible–Infectious–Recovered epidemiological model. Under this framework, we derive theoretical conditions for the de-densification function, to ensure it has an intuitive impact on infection transmission. Via extensive numerical studies, we show that dynamic release policies can improve long-term cost over single, one-time release actions, and the use of k k -means clustering in Monte Carlo simulations can improve objective performance while maintaining similar computational time.},
  archive      = {J_COR},
  author       = {Kati Moug and Siqian Shen},
  doi          = {10.1016/j.cor.2024.106578},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106578},
  shortjournal = {Comput. Oper. Res.},
  title        = {The costs of overcrowding (and release): Strategic discharges for isolated facilities during epidemiological outbreaks},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal resource allocation and routing in robotic mobile
fulfillment systems. <em>COR</em>, <em>165</em>, 106571. (<a
href="https://doi.org/10.1016/j.cor.2024.106571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a combinatorial optimization problem in the context of a robotic mobile fulfillment system deployed in a warehouse that consists of movable racks, a picker, and a fleet of mobile robots. The objective is to efficiently prepare a set of orders with specified due dates by bringing the racks to a picking station in a sequential manner, where the picker selects the required products for the open orders, namely the orders that are being processed simultaneously. The picking station has a limited capacity for processing of open orders. Our goal is to minimize the total travel times of the robots and the delays in fulfilling orders. To achieve this, several decision variables need to be determined, including order sequencing, rack allocation, rack scheduling, and mobile robot routing. We formulate the problem as a mixed integer programming model and devise a heuristic algorithm grounded in decomposition principles to address the problem across two distinct phases. Additionally, we introduce two variable neighborhood search (VNS) algorithms tailored to resolve each respective phase within the aforementioned heuristic framework. The performance of the proposed solution approaches is evaluated and compared using two sets of randomly generated test instances, encompassing small-size and large-size instances. Furthermore, we conduct an analysis to examine the influence of key parameters on the objective function value.},
  archive      = {J_COR},
  author       = {Saeedeh Hashemi and Mohammad Ranjbar},
  doi          = {10.1016/j.cor.2024.106571},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106571},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal resource allocation and routing in robotic mobile fulfillment systems},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parallel branch-and-bound heuristic for the integrated
long-haul and local vehicle routing problem on an adaptive
transportation network. <em>COR</em>, <em>165</em>, 106570. (<a
href="https://doi.org/10.1016/j.cor.2024.106570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consolidation of commodities and coordination of vehicle routes are fundamental features of supply chain management problems. While locations for consolidation and coordination are typically known a priori, in adaptive transportation networks this is not the case. The identification of such consolidation locations forms part of the decision making process . Supply chain management problems integrating the designation of consolidation locations with the coordination of long haul and local vehicle routing is not only challenging to solve, but also very difficult to formulate mathematically. In this paper, the first mathematical model integrating location clustering with long haul and local vehicle routing is proposed. This mathematical formulation is used to develop algorithms to find high quality solutions. A novel parallel framework is developed that combines exact and heuristic methods to improve the search for high quality solutions and provide valid bounds. The results demonstrate that using exact methods to guide heuristic search is an effective approach to find high quality solutions for difficult supply chain management problems.},
  archive      = {J_COR},
  author       = {Junko Hosoda and Stephen J. Maher and Yuji Shinano and Jonas Christoffer Villumsen},
  doi          = {10.1016/j.cor.2024.106570},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106570},
  shortjournal = {Comput. Oper. Res.},
  title        = {A parallel branch-and-bound heuristic for the integrated long-haul and local vehicle routing problem on an adaptive transportation network},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust optimization for a steel production planning problem
with uncertain demand and product substitution. <em>COR</em>,
<em>165</em>, 106569. (<a
href="https://doi.org/10.1016/j.cor.2024.106569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a production planning problem in the steel industry, specifically focusing on determining production quantities and product-to-order assignment considering uncertain demand and product substitution. For the deterministic scenario, we formulate the problem as a mixed integer programming model to effectively represent its combinatorial nature. For uncertain scenarios, we develop a two-stage robust optimization model. This model represents demand values as a box uncertainty set and separates production quantities decision and product-to-order assignment decision into two stages to handle uncertainty effectively. To tackle the model, we propose an enhanced Benders decomposition algorithm that incorporates a problem-specific method for generating valid inequalities to strengthen the master problem, and a hybrid strategy that combines approximate and exact methods to solve the non-convex slave problem. We have performed a large number of computational experiments on synthetic examples to verify the performance of the proposed robust optimization method, and the results demonstrate its efficiency and effectiveness.},
  archive      = {J_COR},
  author       = {Gongshu Wang and Jing Wu and Yang Yang and Lijie Su},
  doi          = {10.1016/j.cor.2024.106569},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106569},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust optimization for a steel production planning problem with uncertain demand and product substitution},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reducing the feasible solution space of resource-constrained
project instances. <em>COR</em>, <em>165</em>, 106567. (<a
href="https://doi.org/10.1016/j.cor.2024.106567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper present an instance transformation procedure to modify known instances of the resource-constrained project scheduling problem to make them easier to solve by heuristic and/or exact solution algorithms. The procedure makes use of a set of transformation rules that aim at reducing the feasible search space without excluding at least one possible optimal solution. The procedure will be applied to a set of 11,183 instances and it will be shown by a set of experiments that these transformations lead to 110 improved lower bounds, 16 new and better schedules (found by three meta-heuristic procedures and a set of branch-and-bound procedures) and even 64 new optimal solutions which were never not found before.},
  archive      = {J_COR},
  author       = {Mario Vanhoucke and José Coelho},
  doi          = {10.1016/j.cor.2024.106567},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106567},
  shortjournal = {Comput. Oper. Res.},
  title        = {Reducing the feasible solution space of resource-constrained project instances},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal-transport satisficing with applications to
capacitated hub location. <em>COR</em>, <em>165</em>, 106566. (<a
href="https://doi.org/10.1016/j.cor.2024.106566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a coherent satisficing criterion for evaluating the attractiveness of strategic decisions under uncertainty. Specifically, we define a satisficing criterion using the optimal-transport measure, termed as Optimal-Transport Satisficing (OTS), to evaluate the random cost saving (that equals cost target minus cost) associated with a strategic decision. We apply this criterion to the capacitated hub location problem under demand and cost uncertainty, a problem that minimizes a setting up cost of selected hubs and a shipping cost. We seek the optimal strategic decision by maximizing OTS, termed as the Optimal-Transport satisficing model, whose solution shares the finite sample performance guarantee as in distributionally robust optimization. Methodologically, we show that the Optimal-Transport satisficing model possesses a compact (regularization) form for the cost uncertainty. Computationally, we propose a column-and-constraint generation based bisection search algorithm for solving the model under demand and cost uncertainty. Numerical experiments demonstrate the attractiveness and competitiveness of our proposed model.},
  archive      = {J_COR},
  author       = {Jie Hu and Tianqi Liu and Zhi Chen and Shuming Wang},
  doi          = {10.1016/j.cor.2024.106566},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106566},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal-transport satisficing with applications to capacitated hub location},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimizing high-speed railway express system under
uncertainty. <em>COR</em>, <em>165</em>, 106565. (<a
href="https://doi.org/10.1016/j.cor.2024.106565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of high-speed railway (HSR) networks has elevated the HSR express system, which combines road and HSR transport, as a notable intermodal transport choice. This research delves into the optimization challenges present in the HSR express system&#39;s operation, given the unpredictable freight demands. These challenges encompass vehicle arrangement, station selection, freight allocation, and the optimization of HSR freight routes. To address these challenges, we introduce a two-stage mixed integer linear programming model aiming to optimize the anticipated net gains of the HSR express system. We also put forward a meta-heuristic method to efficiently solve the model. Empirical tests and sensitivity studies, grounded in a real-world example from the China Railway Nanchang Group Co., Ltd., are executed. Additionally, advanced techniques, including parallel computing tailored to the problem&#39;s nature, have been employed to trim down computational times, especially for intricate real-world scenarios. The findings from this study provide valuable insights for industry practitioners.},
  archive      = {J_COR},
  author       = {Lu Zhen and Xueting He and Nianzu Zhang and Zhiyuan Yang and Yiran Ren},
  doi          = {10.1016/j.cor.2024.106565},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106565},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing high-speed railway express system under uncertainty},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep clustering of the traveling salesman problem to
parallelize its solution. <em>COR</em>, <em>165</em>, 106548. (<a
href="https://doi.org/10.1016/j.cor.2024.106548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A method of heuristically solving large traveling salesman problems is suggested, where a dramatic computational speedup is guaranteed. A specific genetic algorithm is the solver. The initial problem is broken into a set of open-loop subproblems by clustering the nodes. First, the nodes are broken into just two clusters. If these open-loop subproblems are tractable and can be solved within reasonable amount of time, no further clustering is needed. Otherwise, the clustering pattern is applied once again, and each of the previous clusters is broken into just two clusters. Thus, the clusters evolve being re-clustered deeper until the size of the respective open-loop subproblems becomes sufficiently small. Therefore, the number of clusters is a power of 2 depending on the number of available processors and available memory with the maximum possible array. The cluster open-loop subproblems are quickly solved in any order and then their solutions as open-loop subroutes are aggregated into the close-loop route as an approximate solution of the initial problem. By the centroid-based approach, the open-loop subroutes are aggregated by the shortest closed loop route passing through the centroids of the clusters. The aggregation route is found as the respective supplementary traveling salesman problem solution. By the serpentine-based approach, the open-loop subroutes are aggregated by a symmetric rectangular close-loop serpentine passing through the rectangular lattice cell centers approximately corresponding to the centroids.},
  archive      = {J_COR},
  author       = {Vadim V. Romanuke},
  doi          = {10.1016/j.cor.2024.106548},
  journal      = {Computers &amp; Operations Research},
  month        = {5},
  pages        = {106548},
  shortjournal = {Comput. Oper. Res.},
  title        = {Deep clustering of the traveling salesman problem to parallelize its solution},
  volume       = {165},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimizing passenger waiting time in the multi-route bus
fleet allocation problem through distributionally robust optimization
and reinforcement learning. <em>COR</em>, <em>164</em>, 106568. (<a
href="https://doi.org/10.1016/j.cor.2024.106568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public buses serve a vital role in urban transportation systems by alleviating traffic congestion, reducing carbon emissions, and providing cost-effective and accessible travel options. Nonetheless, a noticeable mismatch frequently exists between the supply and demand for bus services, leading to reduced passenger satisfaction in reality, especially in suburban areas. To tackle this problem, our study delves into the bus fleet allocation problem by incorporating a range of real-world operations management issues, including the uncertainty in passenger demand, the coordination of multiple bus routes, the availability of various bus types, the constraints related to parking space and staffing, as well as the maximum departure intervals. To navigate the uncertain passenger demand, a distributionally robust optimization (DRO) model that comprehensively integrates these real-world characteristics is formulated. In addition, we conduct an in-depth analysis of the DRO model and its dual problem , assessing its scalability using a general-purpose solver. We also perform sensitivity analyses within the problem domain to offer valuable managerial insights. For large-scale problems, we develop a multi-operator genetic algorithm and enhance the algorithm’s efficiency by incorporating a reinforcement learning mechanism. Finally, comparative experiments based on real-world cases show that: by incorporating a reinforcement learning mechanism, the computational capability of the proposed algorithm has improved by 3.39%; compared to other heuristic algorithms , the efficiency of the proposed algorithm has increased by 5.32%.},
  archive      = {J_COR},
  author       = {Xiang Li and Xiaojie An and Bowen Zhang},
  doi          = {10.1016/j.cor.2024.106568},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106568},
  shortjournal = {Comput. Oper. Res.},
  title        = {Minimizing passenger waiting time in the multi-route bus fleet allocation problem through distributionally robust optimization and reinforcement learning},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-period fourth-party logistics network design with the
temporary outsourcing service under demand uncertainty. <em>COR</em>,
<em>164</em>, 106564. (<a
href="https://doi.org/10.1016/j.cor.2024.106564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel multi-period fourth party logistics (4PL) network design problem integrating the temporary outsourcing service under demand uncertainty is studied, in which the temporary outsourcing strategy is proposed to accommodate uncertain demand overflows. To address this problem, a two-stage stochastic programming model is formulated. Using the Latin hypercube sampling approach, a mixed integer linear programming reformulation model is provided. To deal with the challenges of sampling in solving efficiency, an improved sample average approximation method is proposed by integrating an improved subgradient algorithm with the dual decomposition and Lagrangian relaxation technique. Computational results of several numerical instances followed by a real-life case clearly support the applicability and effectiveness of the proposed model and algorithm. Comparative analysis shows that integrating temporary outsourcing service into multi-period 4PL network design indeed changes the 4PL network structure and enhances the supply chain performance at a lower overall cost.},
  archive      = {J_COR},
  author       = {Mingqiang Yin and Min Huang and Dazhi Wang and Shu-Cherng Fang and Xiaohu Qian and Xingwei Wang},
  doi          = {10.1016/j.cor.2024.106564},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106564},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-period fourth-party logistics network design with the temporary outsourcing service under demand uncertainty},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A discrete group teaching optimization algorithm for solving
many-objective sand casting whole process production scheduling problem.
<em>COR</em>, <em>164</em>, 106563. (<a
href="https://doi.org/10.1016/j.cor.2024.106563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid flowshop scheduling is widely used in various industrial manufacturing areas, particularly in the production of castings. The parallel processes in the mold manufacturing stage and the single batch coupled processes in the melting and casting and post-processing stages make the model more complex. Firstly, a multi-stage hybrid flowshop scheduling model is constructed to minimize makespan, machine load, penalty of tardiness and earliness, and carbon emission. This paper proposes a discrete group teaching optimization algorithm (DGTOA) with an improved initialization strategy and dynamic search strategy to solve the model. To enhance the effectiveness of the DGTOA, a segmented decoding rule based on different measurement criteria is designed to decode different processing processes in different stages. In addition, several strategies were designed for the whole process of casting scheduling. A hybrid operator has been developed to improve selection ability by introducing principal component analysis (PCA) to address the issue of the algorithm&#39;s selection pressure becoming too high in many-objective problems. Finally, the comprehensive experiments and the case study indicate that DGTOA maintains a good balance between exploration and development. Its performance in solving approximation problems is significantly higher than other algorithms.},
  archive      = {J_COR},
  author       = {Hongtao Tang and Wei Zhang and Xixing Li and Shupeng Wei},
  doi          = {10.1016/j.cor.2024.106563},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106563},
  shortjournal = {Comput. Oper. Res.},
  title        = {A discrete group teaching optimization algorithm for solving many-objective sand casting whole process production scheduling problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Routing one million customers in a handful of minutes.
<em>COR</em>, <em>164</em>, 106562. (<a
href="https://doi.org/10.1016/j.cor.2024.106562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new dataset of Capacitated Vehicle Routing Problem instances, up to two orders of magnitude larger than those in the currently used benchmarks. Although these sizes might not have an immediate application to real-world logistic scenarios, we believe they could foster fresh new research efforts on the design of effective and efficient algorithmic components for routing problems. We provide computational results for such instances by running FILO2, an adaptation of the FILO algorithm proposed in Accorsi and Vigo (2021), designed to handle extremely large-scale CVRP instances. Solutions for such instances are obtained using a standard personal computer in a considerably short computing time, thus showing the effectiveness of the acceleration and pruning techniques already proposed in FILO. Finally, results of FILO2 on well-known literature instances show that the newly introduced changes improve the overall scalability of the approach with respect to the previous FILO design.},
  archive      = {J_COR},
  author       = {Luca Accorsi and Daniele Vigo},
  doi          = {10.1016/j.cor.2024.106562},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106562},
  shortjournal = {Comput. Oper. Res.},
  title        = {Routing one million customers in a handful of minutes},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact and heuristic solution approaches for the generalized
independent set problem. <em>COR</em>, <em>164</em>, 106561. (<a
href="https://doi.org/10.1016/j.cor.2024.106561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized independent set problem (GIS) is a generalization of the classical maximum independent set problem and has various practical applications, such as forest harvesting and image/video processing. In this work, we present highly effective exact and heuristic algorithms for the GIS. In the proposed exact algorithm, a new upper bound on the maximum net benefit of an independent set in a subgraph is derived using a Lagrangian relaxation of a linear integer programming formulation of the GIS problem. This bound is then employed in a combinatorial branch-and-bound (B&amp;B) algorithm. To solve larger instances, we propose an adaptive local search procedure which jointly considers several neighborhoods and selects a neighborhood to explore in an adaptive manner at each iteration. Our proposed exact and heuristic algorithms are evaluated on a set of 216 GIS benchmark instances and compared with several state-of-the-art algorithms. Computational results indicate that our proposed algorithm competes favorably with the best existing approaches for the GIS. In particular, the exact algorithm is able to attain all known optimal solutions and to solve 26 more instances to optimality for the first time.},
  archive      = {J_COR},
  author       = {Mingming Zheng and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1016/j.cor.2024.106561},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106561},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact and heuristic solution approaches for the generalized independent set problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A surrogate-based heuristic for production planning problem
of orders in small foundries. <em>COR</em>, <em>164</em>, 106560. (<a
href="https://doi.org/10.1016/j.cor.2024.106560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Market foundry production processes are characterized by raw materials that feed a furnace that produces metal alloys with limited capacity to meet item order demand. The foundry production system considered here is make-to-order. Although in the literature, production planning does not usually consider items produced as belonging to orders, it is essential to address this specificity. All component items must be produced to fulfill an order. We propose a surrogate-based heuristic (SUBH) to address the production planning problem of orders in small foundries. The quality of the lower bounds is compared to that of the linearly relaxed problem. The feasibility and optimality of the solutions are tested. Most tested instances are proved optimal. For infeasible solutions, we proposed a feasibility procedure based on item weight and order costs. We obtain excellent results with low computational time .},
  archive      = {J_COR},
  author       = {Giovanna Abreu Alves and Iago Pinheiro de Freitas and Victor Claudio Bento Camargo},
  doi          = {10.1016/j.cor.2024.106560},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106560},
  shortjournal = {Comput. Oper. Res.},
  title        = {A surrogate-based heuristic for production planning problem of orders in small foundries},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact solution method for vehicle-and-drone cooperative
delivery routing of blood products. <em>COR</em>, <em>164</em>, 106559.
(<a href="https://doi.org/10.1016/j.cor.2024.106559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood products, such as platelets, play a major role in saving and maintaining lives, and preventing and treating diseases, which need timely delivery. To achieve cost-efficient and fast deliveries, integrating unmanned aerial vehicles (or drones) into blood product distribution network design provides a competitive advantage, which however increases the operational challenges. We address the vehicle-and-drone cooperative delivery routing problem where a fleet of blood transport vehicles, each of which carries a given number of homogeneous drones, are deployed to collaboratively deliver blood products from a blood centre to a set of hospitals. To take advantage of the drone fleet, some or all of the drones associated with a vehicle can be simultaneously dispatched to make deliveries to nearby hospitals when the vehicle is parked at an intermediate movable depot (a hospital cluster centre), where the drones can set off from and land on the vehicle. The goal is to find the collaborative routes of the vehicle-drone combinations to minimize the sum of the assignment cost, the transport cost, and the total disutility of blood product delivery. We devise an exact algorithm for solving the problem in the framework of the integer L L -shaped method, which decomposes the problem into a Benders master problem and a Benders subproblem . The Benders master problem determines which hospitals are served as cluster centres, and which hospitals are assigned to each cluster centre that will be served by drones. The resulting Benders subproblem reduces to a capacitated vehicle routing problem with time window that is solved by a branch-and-price algorithm to identify Benders optimality and feasibility cuts, and the found cuts are incorporated into the Benders master problem to guide the solution process. We perform extensive computational experiments to verify the computation efficiency of the algorithm, ascertain the benefit of vehicle-and-drone cooperative delivery over vehicle-only delivery, and analyse the sensitivity of key parameters. We also show how our model would perform should it be used for blood product delivery in the Blood Centre of Chongqing, China.},
  archive      = {J_COR},
  author       = {Yunqiang Yin and Ling Qing and Dujuan Wang and T.C.E. Cheng and Joshua Ignatius},
  doi          = {10.1016/j.cor.2024.106559},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106559},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact solution method for vehicle-and-drone cooperative delivery routing of blood products},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling and solving the two-level generalized median tour
problem. <em>COR</em>, <em>164</em>, 106558. (<a
href="https://doi.org/10.1016/j.cor.2024.106558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world situations, the beneficiaries of a distribution system may be grouped into clusters, requiring a transportation structure to serve each cluster of beneficiaries efficiently. For instance, in public services, such as health, education, and emergencies, delivery tasks rely on the local authority of each district or cluster. In this context, a two-level distribution system named the Two-Level Generalized Median Tour Problem (TLGMTP) is introduced. The first level addresses product distribution using a specialized vehicle, starting and ending at a depot and visiting some clusters. In this manner, products are delivered to one or more nodes belonging to the visited clusters. The second level comprises smaller vehicles that start their trips from the nodes belonging to the first level and transport the products to one or more nodes located in a non-visited cluster, ensuring that all non-visited clusters of the first level are visited in the second level. Then, the non-visited nodes in each cluster must reach a node in the same cluster to collect their products. In this study, we present, model, and solve the TLGMTP to minimize the total transportation costs. We develop three mathematical formulations and solve them using a branch-and-cut algorithm. Exhaustive computational experiments involving tests and real-world instances are presented to show the efficiency and advantages of the proposed methodology.},
  archive      = {J_COR},
  author       = {Carlos Obreque and Germán Paredes-Belmar and Pablo A. Miranda-Gonzalez and Giovanni Campuzano and Gabriel Gutiérrez-Jarpa},
  doi          = {10.1016/j.cor.2024.106558},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106558},
  shortjournal = {Comput. Oper. Res.},
  title        = {Modeling and solving the two-level generalized median tour problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The pollution-routing problem with speed optimization and
uneven topography. <em>COR</em>, <em>164</em>, 106557. (<a
href="https://doi.org/10.1016/j.cor.2024.106557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a joint pollution-routing with time windows and speed optimization problem (PRP-SO) where vehicle speed, payload, and road grade influence fuel costs and CO 2 e CO2e emissions. We present two advanced optimization methods (i.e., approximate and exact) for solving the PRP-SO. The approximate strategy solves large-scale instances of the problem with a Tabu search-based metaheuristic coupled with an efficient fixed-sequence speed optimization algorithm . The second strategy consists of a tailored branch-and-price (BP) algorithm to manage speed optimization within the pricing problem. We test both methods on modified Solomon benchmarks and newly constructed real-life instance sets. Our BP algorithm successfully solves the majority of instances involving up to 50 customers and many instances with 75 and 100 customers. The heuristic can find near-optimal solutions to all instances and requires less than one minute of computational time per instance. Results on real-world instances suggest several managerial insights. First, fuel savings of up to 53% can be achieved when explicitly considering arc payloads and road grades. Second, fuel savings and emission reduction can be achieved by scheduling uphill customers later along the routes. Lastly, we show that ignoring elevation information when planning routes leads to highly inaccurate fuel consumption estimates.},
  archive      = {J_COR},
  author       = {David Lai and Yasel Costa and Emrah Demir and Alexandre M. Florio and Tom Van Woensel},
  doi          = {10.1016/j.cor.2024.106557},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106557},
  shortjournal = {Comput. Oper. Res.},
  title        = {The pollution-routing problem with speed optimization and uneven topography},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Routing and scheduling of platform supply vessels in
offshore oil and gas logistics. <em>COR</em>, <em>164</em>, 106556. (<a
href="https://doi.org/10.1016/j.cor.2024.106556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we focus on an operational logistics problem that arises in the offshore oil and gas exploration and production industry. In particular, we aim to design cost-effective routes and schedules for platform supply vessels, which are routinely employed to deliver necessary supplies to the platforms as well as to collect from those platforms used materials that need to be transported back to the onshore base for maintenance, reuse, or discarding. To address the rich-featured routing problem that arises in this offshore logistics application, we introduce a novel mixed-integer linear programming formulation and propose a specialized branch-and-cut algorithm to solve such a model. Furthermore, in order to evaluate our proposed algorithm’s performance, we conduct an extensive computational study using representative benchmark instances inspired by real operational data. The computational results show that our algorithm solved the majority of those instances to optimality , demonstrating its potential for practical use in offshore oil and gas logistics operations.},
  archive      = {J_COR},
  author       = {Victor A. Silva and Akang Wang and Virgílio José Martins Ferreira Filho and Chrysanthos E. Gounaris},
  doi          = {10.1016/j.cor.2024.106556},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106556},
  shortjournal = {Comput. Oper. Res.},
  title        = {Routing and scheduling of platform supply vessels in offshore oil and gas logistics},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Planning container inspection and repair: A case study.
<em>COR</em>, <em>164</em>, 106555. (<a
href="https://doi.org/10.1016/j.cor.2024.106555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to introduce a real-life problem of optimal planning of container inspection and repair on several facilities over several time periods assuring effective supply of empty containers indispensable for seamless global maritime transportation. The containers are of several types and quality levels. The objective is to minimize the total holding, inspection, repair, transportation and rejection costs. We formulate a deterministic min-cost multi-commodity network flow problem and prove NP-hardness for two special cases. Values of the rejection costs are determined such that no container is rejected in an optimal solution if there exists a feasible solution with no container rejected. An algorithmic mechanism is proposed to support a negotiation of periodic container demands between the container provider and the container users with the aim to reduce the overall costs. Computer experiments with instances obtained by random deviation from industrial data demonstrate that the majority of instances with up to 4 facilities, 4 container types, 7 quality levels, and 7, 14 or 30 time periods can be solved with an acceptable quality using an academic version of CPLEX in two hours on a standard PC.},
  archive      = {J_COR},
  author       = {Mikhail Y. Kovalyov and Katarzyna A. Kuzmicz and Mikhail N. Lukashevich and Erwin Pesch},
  doi          = {10.1016/j.cor.2024.106555},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106555},
  shortjournal = {Comput. Oper. Res.},
  title        = {Planning container inspection and repair: A case study},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The integrated on-demand bus routing problem: Combining
on-demand buses with a high-frequency fixed line public transport
network. <em>COR</em>, <em>164</em>, 106554. (<a
href="https://doi.org/10.1016/j.cor.2024.106554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we analyze the performance of integrating a large-scale on-demand bus system with a high-frequency fixed line public transport network in an urban context. Given are a high-speed metro network, a set of real-time requests, a set of bus station locations and a fleet of fixed capacity minibuses. Requests have a set of possible departure/arrival bus stations within walking distance of the actual departure/arrival location and have to be served within a certain time window. The aim is to simultaneously (1) decide on the trip type for each passenger (only bus, only metro or mixed), (2) route the on-demand buses, (3) in the case of a bus-leg in the trip, assign each passenger to a departure and arrival bus station (bus station assignment), and (4) in the case of a metro-leg in the trip, decide the assigned transfer station(s) and used metro lines (transfer station assignment). We call this problem the integrated on-demand bus routing problem . After presenting a mathematical model , we propose a quick and scalable insertion-based heuristic to solve the problem. The results found by the heuristic are further used to compare the performance of an integrated system , to a system that only uses on-demand buses. It is concluded that the integrated system always performs better regarding the service rate or number of served requests. Depending on the speed and layout of the metro network, also the average user ride time per passenger improves by the integration.},
  archive      = {J_COR},
  author       = {Lissa Melis and Michell Queiroz and Kenneth Sörensen},
  doi          = {10.1016/j.cor.2024.106554},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106554},
  shortjournal = {Comput. Oper. Res.},
  title        = {The integrated on-demand bus routing problem: Combining on-demand buses with a high-frequency fixed line public transport network},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Delay-resistant robust vehicle routing with heterogeneous
time windows. <em>COR</em>, <em>164</em>, 106553. (<a
href="https://doi.org/10.1016/j.cor.2024.106553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a robust variant of the vehicle routing problem with heterogeneous time windows (RVRP-HTW) with a focus on delay-resistant solutions. Here, customers have different availability time windows for every vehicle and must be provided with a preferably tight appointment window for the planned service. Different vehicles are a possibility to model different days on which one physical vehicle can serve a customer. This is the main reason why different time windows for different vehicles are of high practical relevance. To ensure that the appointment windows are adhered to as much as possible, we introduce a new objective function that penalizes delays. Our novel approach allows us to find solutions that are robust with respect to uncertainties in travel and service times limited by a budget polytope . We present a set-partitioning model, the solution of which is based on column generation and employs a labeling algorithm that integrates robustness into the calculations and is adapted to our problem-specific constraints. In a Monte-Carlo simulation on real-life data, we evaluate this method in terms of runtime and solution quality. Our solutions show very good performance , even if the data is more uncertain than assumed for the optimization, incurring only marginal extra travel time compared to a naive deterministic planning scheme.},
  archive      = {J_COR},
  author       = {Lukas Metz and Petra Mutzel and Tim Niemann and Lukas Schürmann and Sebastian Stiller and Andreas M. Tillmann},
  doi          = {10.1016/j.cor.2024.106553},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106553},
  shortjournal = {Comput. Oper. Res.},
  title        = {Delay-resistant robust vehicle routing with heterogeneous time windows},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling identical serial-batching machines in the engine
manufacturing supply chain by an integrated variable neighborhood search
algorithm. <em>COR</em>, <em>164</em>, 106552. (<a
href="https://doi.org/10.1016/j.cor.2024.106552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of the high-end equipment manufacturing process is becoming progressively more difficult, which brings a big challenge for high-end equipment manufacturers. Numerous variables, such as equipment wear and tear, the service level of the supply chain , etc., may have a significant impact on the efficiency of high-end equipment manufacturing. In this paper, motivated by the need to improve the productivity of engines, we study a scheduling problem considering the deterioration effect, component parts supply, and parallel serial-batch processing machines. The job processing time is sum-of-actual-processing-time-dependent and the set-up time of a batch is time-dependent. The objective is to minimize the makespan. Firstly, we analyze the structural properties of the problem under two special cases. Then, a dynamic programming (DP) algorithm is proposed to group the jobs into batches, and two heuristic algorithms are designed to improve the job sequence based on the structural properties . Algorithm 3 is proposed to provide a lower bound for the investigated problem. Next, we develop a variable neighborhood search algorithm (VNS-H) which integrates the DP algorithm, heuristic algorithms , and four local search strategies. Extensive computational experiments are conducted to validate the performance of the proposed algorithm. The results show that the VNS-H algorithm solves the proposed problem effectively and outperforms other involved metaheuristics . The proposed methods in this work can provide manufacturers with useful decision-making support that improves production efficiency and reduces operational costs.},
  archive      = {J_COR},
  author       = {Shaojun Lu and Chongyao Ma and Xinbao Liu and Panos M. Pardalos},
  doi          = {10.1016/j.cor.2024.106552},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106552},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling identical serial-batching machines in the engine manufacturing supply chain by an integrated variable neighborhood search algorithm},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective search game: Long-term vs short-term.
<em>COR</em>, <em>164</em>, 106551. (<a
href="https://doi.org/10.1016/j.cor.2024.106551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on investigating a multi-objective search allocation game problem, specifically addressing the distribution of a search budget (player 1) across a searched area to detect an evading target (player 2). The game is defined as a two-person zero-sum game, as an optimal search strategy must consider the target’s optimal evasion strategy. Traditionally, the sole objective function in search theory literature has been to maximize the detection probability at the end of the time horizon. Our work extends the problem by proposing a multi-objective formulation that aims to strike a balance between long-term and short-term search objectives. In this context, the goal is to maximize the detection probability of the target at the end of each time period ( e.g. , hourly) throughout the time horizon. The main challenge in this problem lies in handling a multitude of objective functions, where the number of objective functions is an input data . To the best of our knowledge, no prior research has explored the multi-objective search allocation game. Therefore, we meticulously study the significance of this problem by highlighting the disparities and conflicts among these objectives. Subsequently, we propose a solution approach based on the epsilon-constraint algorithm, as well as a heuristic method that decomposes the problem into smaller multi-objective subproblems . We conduct a series of experiments to evaluate two key aspects of the methods: computation time and quality.},
  archive      = {J_COR},
  author       = {Florian Delavernhe},
  doi          = {10.1016/j.cor.2024.106551},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106551},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective search game: Long-term vs short-term},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The stochastic share-a-ride problem with electric vehicles
and customer priorities. <em>COR</em>, <em>164</em>, 106550. (<a
href="https://doi.org/10.1016/j.cor.2024.106550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a stochastic share-a-ride problem in which a fleet of electric vehicles (EV) in a ride-hailing system are dynamically dispatched to serve passenger and parcel orders in a shared manner. We assume uncertain demands of both passenger and parcel orders and consider that passenger orders have priority over parcel orders. Passengers must be transported directly from their origins to destinations, while parcels can share a vehicle with other orders. The operator of the ride-hailing platform needs to decide whether to accept a newly arrived service request, how to assign orders to vehicles, and how to route and charge the EVs. To develop dynamic policies for the problem, we formulate the problem as a Markov decision process (MDP) and propose a reinforcement learning (RL) approach to solve the problem. We develop action-space restriction and state-space aggregation schemes to facilitate the implementation of the RL algorithm. We also present two rolling horizon heuristic methods to develop dynamic policies for our problem. We conduct computational experiments based on real-world taxi data from New York City. The computational results show that our RL policies perform better than the three benchmark policies in terms of serving more orders and collecting more rewards. Our RL policies are able to make high-quality decisions more efficiently when compared with the rolling horizon policies.},
  archive      = {J_COR},
  author       = {Yutong Gao and Shu Zhang and Zhiwei Zhang and Quanwu Zhao},
  doi          = {10.1016/j.cor.2024.106550},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106550},
  shortjournal = {Comput. Oper. Res.},
  title        = {The stochastic share-a-ride problem with electric vehicles and customer priorities},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning driven three-phase search for the maximum
independent union of cliques problem. <em>COR</em>, <em>164</em>,
106549. (<a href="https://doi.org/10.1016/j.cor.2024.106549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple and undirected graph , the maximum independent union of cliques (IUC) problem aims to identify a subset of vertices with maximum cardinality , such that each connected component of the induced subgraph is a complete graph. As a generalization of the popular NP-hard maximum clique problem, the maximum IUC problem is of great practical importance for social network analysis and network-based data mining . In this work, we present the first learning driven three-phase search algorithm for this relevant problem. The proposed algorithm incorporates a constrained swap-based tabu search to effectively examine candidate solutions and a frequency-based perturbation to diversify the search. It additionally integrates a probability learning mechanism to learn useful information during the search, which helps to build promising new starting solutions. Computational results on 83 benchmark graphs from the well-known 2nd DIMACS Challenge indicate that the algorithm competes very favorably with the current best-performing algorithms. We also present a practical application of the algorithm to social network analysis . Key algorithmic components are analyzed to understand their influences on the algorithm.},
  archive      = {J_COR},
  author       = {Zhi Lu and Jian Gao and Jin-Kao Hao and Pingle Yang and Lixin Zhou},
  doi          = {10.1016/j.cor.2024.106549},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106549},
  shortjournal = {Comput. Oper. Res.},
  title        = {Learning driven three-phase search for the maximum independent union of cliques problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model formulations for pickup and delivery problems in
designated driver services. <em>COR</em>, <em>164</em>, 106547. (<a
href="https://doi.org/10.1016/j.cor.2024.106547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designated driver services use company vehicles to deliver drivers to customers. The drivers then drive the customers from their origins to their destinations in the customers’ own cars; at the destinations, the drivers are picked up by a company vehicle. We typically see teams of drivers assigned to company vehicles serving customers. However, when the drivers may be dropped off by one vehicle and picked up by another, a challenging pick-up and delivery problem arises. In this paper, we study the structural properties of the designated driver problem focusing on the synchronization between company vehicles and drivers. We present a two-index formulations to generate optimal, least-cost routes using a general-purpose solver. We benchmark the two-index formulations against a 3-index formulation and a path enumeration strategy. Based on a set of experiments, we find that the two-index formulation performs well, both in terms of quality and solution time, especially on the formulations with more flexibility in the pairing of drivers to company vehicles. Our computational experiments show that up to 75% cost savings are possible from using a flexible operating strategy as compared to a strategy in which drivers and company vehicles stay together throughout a shift.},
  archive      = {J_COR},
  author       = {Alp Arslan and Niels Agatz and F. Jordan Srour},
  doi          = {10.1016/j.cor.2024.106547},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106547},
  shortjournal = {Comput. Oper. Res.},
  title        = {Model formulations for pickup and delivery problems in designated driver services},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simulation-based variable neighborhood search for optimizing
skill assignments in multi-server facilities with inventories.
<em>COR</em>, <em>164</em>, 106546. (<a
href="https://doi.org/10.1016/j.cor.2024.106546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the joint optimization problem of skill assignments and inventory in a multi-skill, multi-server repair facility. Failures of different part types occur according to Poisson processes , and each part type requires a certain repair skill. The repair facility supplies ready-to-install spare parts when available in the inventory, according to the ( S − 1 , S ) (S−1,S) inventory policy . The repair times follow exponential distributions , with rates dependent on the part type. After repair, the parts are returned to the inventory as ready-to-install spare parts. If the inventory is empty when a failed part arrives, the replacement part is backordered, and a penalty cost is incurred. The objective of the problem is to find an assignment of repair skills to servers and inventory levels that minimize the expected total cost of the system. That is, the costs for servers, the costs to upgrade the skills of servers, and the expected holding and backorder costs. We propose to solve this problem by a simulation-based Variable Neighborhood Search (VNS) approach, in which a Discrete Event Simulation is applied to evaluate the expected backorder and holding costs given the skill assignments. The proposed method is capable of significantly improving the results of a recently published Genetic Algorithm, achieving an average cost reduction of 5.1% in the same running time. Moreover, it is able to find comparable solutions in one fifth of the GA running time.},
  archive      = {J_COR},
  author       = {Moustafa Abdelwanis and Adriana F. Gabor and Nenad Mladenovic and Andrei Sleptchenko},
  doi          = {10.1016/j.cor.2024.106546},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106546},
  shortjournal = {Comput. Oper. Res.},
  title        = {Simulation-based variable neighborhood search for optimizing skill assignments in multi-server facilities with inventories},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Combinatorial benders decomposition for the operational
aircraft maintenance routing problem. <em>COR</em>, <em>164</em>,
106545. (<a href="https://doi.org/10.1016/j.cor.2024.106545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operational aircraft maintenance routing problem (OAMRP) assigns the aircraft in a fleet to scheduled flights while satisfying maintenance requirements. Aviation rules enforce the aircraft to undergo maintenance before the maximum accumulated flight hour is exceeded. Due to the dynamic environment of the airline industry, aircraft routes considering operational requirements become definite a few days before their operation. Thus, disruption-prone plans entail the development of fast solution algorithms. We propose a combinatorial Benders decomposition algorithm to solve this problem. The proposed algorithm is enhanced with valid inequalities to improve convergence. In addition, we implement a branch-and-Benders-cut algorithm. A computational study is conducted to quantify the effectiveness of the derived inequalities. We also provide an extensive comparison to evaluate the performance of the proposed algorithm. The results indicate that the proposed algorithm outperforms other approaches in terms of solution quality and computation time.},
  archive      = {J_COR},
  author       = {Emine Es Yurek},
  doi          = {10.1016/j.cor.2024.106545},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106545},
  shortjournal = {Comput. Oper. Res.},
  title        = {Combinatorial benders decomposition for the operational aircraft maintenance routing problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient optimization in stochastic production planning
problems with product substitution. <em>COR</em>, <em>164</em>, 106544.
(<a href="https://doi.org/10.1016/j.cor.2024.106544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the stochastic production planning problem with product substitution, which can be decomposed into several optimization subproblems with sequential decisions. The decision variables in each time period include (1) the product substitution decision and (2) the recipe input quantity decision. The goal is to minimize the total of production cost, holding cost, and shortage cost, while achieving a service level for demand satisfaction. Since this optimization model involves analytically intractable probabilistic formulation , traditional mathematical programming techniques cannot be readily applied. We develop the deterministic SPLINE and the stochastic R-SPLINE algorithms for different scenarios. The probability generating function is embedded into the deterministic algorithm to exactly calculate the desired performance measures, which is reasonable when dealing with independent data (with a small number of product classes as well). The stochastic R-SPLINE algorithm uses simulation to estimate the desired probabilistic measures , allowing correlations between different production recipes as well as between different demand classes. We also present a convergence analysis for the stochastic R-SPLINE algorithm. Experimental results demonstrate the efficiency of the developed algorithms compared to other existing approaches.},
  archive      = {J_COR},
  author       = {Shing Chih Tsai and Yingchieh Yeh and Honggang Wang and Tsung Ching Chou},
  doi          = {10.1016/j.cor.2024.106544},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106544},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient optimization in stochastic production planning problems with product substitution},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Re-use of samples in stochastic annealing. <em>COR</em>,
<em>164</em>, 106543. (<a
href="https://doi.org/10.1016/j.cor.2024.106543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The re-use of samples in stochastic black box optimisation is a double-edged sword. On the one hand it has the potential of substantially reducing the number of simulation runs required, on the other hand it introduces dependencies between iterations of the optimisation algorithm that may misguide the search. This paper proposes a principled way to re-use samples in stochastic annealing, a generalisation of simulated annealing for stochastic black-box optimisation problems . We propose three alternative algorithms that all, despite the stochastic errors when evaluating a solution via simulation, obey the detailed balance equation and thus have the same assurance of converging to the true optimum as standard simulated annealing in the deterministic case . This is achieved by optimising in the product space of solution and error. We compare our new algorithms in terms of their acceptance ratio as well as empirically on two stochastic combinatorial optimisation problems and find that the best algorithms are of order twice as efficient as the state-of-the-art. Furthermore, one algorithm we propose can work with non-Gaussian and even unknown error distributions.},
  archive      = {J_COR},
  author       = {Robin Ball and Juergen Branke and Stephan Meisel},
  doi          = {10.1016/j.cor.2024.106543},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106543},
  shortjournal = {Comput. Oper. Res.},
  title        = {Re-use of samples in stochastic annealing},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A lagrangian relaxation algorithm for stochastic fixed
interval scheduling problem with non-identical machines and job classes.
<em>COR</em>, <em>164</em>, 106542. (<a
href="https://doi.org/10.1016/j.cor.2024.106542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with operational fixed interval scheduling problems under uncertainty caused by random delays. This stochastic programming problem has a deterministic reformulation based on network flow under the assumption that the machines are identical and the multivariate distribution of random delays follows an Archimedean copula. In this paper, we focus on the problem with heterogeneous machines and jobs classes. The deterministic problem with no delays and more than one machine type has been shown to be NP-hard. We generalize the deterministic reformulation of the stochastic problem with random delays for non-identical (heterogeneous) machines. This formulation for more than one machine type loses an important property of total unimodularity that holds for identical machines reformulation using the network flow problem. Therefore, an algorithm based on the Lagrangian relaxation is derived and implemented together with an efficient upper bounding heuristic. Its efficiency is confirmed by solving a large number of simulated instances.},
  archive      = {J_COR},
  author       = {Martin Branda and Monika Matoušková},
  doi          = {10.1016/j.cor.2024.106542},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106542},
  shortjournal = {Comput. Oper. Res.},
  title        = {A lagrangian relaxation algorithm for stochastic fixed interval scheduling problem with non-identical machines and job classes},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A modified variable neighborhood search algorithm for
dynamic lot-sizing with supplier selection under varying delivery time
quotation. <em>COR</em>, <em>164</em>, 106532. (<a
href="https://doi.org/10.1016/j.cor.2024.106532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a dynamic lot-sizing problem with supplier selection, where the manufacturer develops an aggregate plan to meet product delivery demand with the objective of minimizing the cost. Specifically, a novel supplier selection scenario with varying delivery time quotation is considered, i.e., the manufacturer places raw material replenishment orders with varying delivery time quotation and dynamically selects suppliers, and the suppliers guarantee delivery within the quoted delivery lead time. In the dynamic lot-sizing problem with supplier selection, a joint decision on the production plan, replenishment order, and supplier selection needs to be made. To tackle this complex problem, a modified Variable Neighborhood Search algorithm with nested two parallel neighborhoods (PN-VNS) is first developed for the decision on the production plan and replenishment order. Then, the decision on supplier selection needs to be made for the given replenishment order, and a pre-pruning optimization rule is proposed to obtain the optimal supplier scheme. Computational experiments are conducted to evaluate the performance of the proposed algorithm, and the experimental results demonstrate that our algorithm performs better both in terms of solution quality and running time.},
  archive      = {J_COR},
  author       = {Fangjun Zhu and Jun Pei and Baoyu Liao and Ya Zhou and Panos M. Pardalos},
  doi          = {10.1016/j.cor.2024.106532},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106532},
  shortjournal = {Comput. Oper. Res.},
  title        = {A modified variable neighborhood search algorithm for dynamic lot-sizing with supplier selection under varying delivery time quotation},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive variable neighbourhood search approach for the
dynamic vehicle routing problem. <em>COR</em>, <em>164</em>, 106531. (<a
href="https://doi.org/10.1016/j.cor.2024.106531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the traditional vehicle routing problem (VRP), a route plan is pre-determined and remains unchanged afterwards. However in practice, several unforeseen events could occur at any point, which cause traffic congestion and delay to the original planned routes. It is therefore important to re-optimise the routes by taking into consideration the real-time information, leading to the Dynamic VRP (DVRP). While most of the DVRP literature mainly focused on the customer requests as the dynamic aspect, this paper, however, concentrates on the dynamic traffic information based on the level of urgency of the accidents. Critical nodes are introduced into the network to provide a diversion opportunity for the en-route vehicle. This novel concept of ‘criticality’ is also more practical than the commonly adopted strategy that allows instantaneous diversion at the current vehicle location. We proposed an adaptive variable neighbourhood search (AVNS) algorithm to generate routes in the static environment which is then adapted accordingly for the dynamic setting. This is a two stage VNS approach with the first one acts as a learning stage whose information is then used in stage 2. Here, a smaller number of neighbourhoods and local searches are chosen at each iteration while adopting a pseudo-random selection procedure derived from stage 1. To provide solution diversity, a large neighbourhood search is also embedded into the search. The flexibility and adaptability of our AVNS approach are demonstrated by the high quality solutions obtained when tested on the commonly used VRP datasets, ranging in size from 50 to 1200 customers, which are modified accordingly. In addition, managerial insights related to the tightness of the routes are also presented and analysed.},
  archive      = {J_COR},
  author       = {Jeeu Fong Sze and Said Salhi and Niaz Wassan},
  doi          = {10.1016/j.cor.2024.106531},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106531},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive variable neighbourhood search approach for the dynamic vehicle routing problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Revised eight-step feasibility checking procedure with
linear time complexity for the dial-a-ride problem (DARP). <em>COR</em>,
<em>164</em>, 106530. (<a
href="https://doi.org/10.1016/j.cor.2024.106530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of Dial-a-Ride Problems (DARPs), the eight-step feasibility checking procedure is one of the most commonly used methods. The time complexity of this procedure is considered as O ( n 2 ) O(n2) in the literature. In this study, a version of this procedure is proposed with O ( n l o g Q ) O(nlogQ) time complexity. Since, in DARPs, the capacity of each vehicle is a small constant, the method introduced in this paper performs as a linear-time technique in this context. The revised scheme is just as elegant as the original one, which makes this improvement in the time complexity more noteworthy. Our proposed technique has a lower time complexity and/or is noticeably easier to comprehend and implement than the other feasibility checking methods in the literature. Considering the standard benchmark instances, experimental results show that the revised method outperforms the classic one in terms of the computational time . Moreover, it is demonstrated that the execution time of our algorithm is competitive with that of the only technique with linear time complexity in the literature.},
  archive      = {J_COR},
  author       = {Somayeh Sohrabi and Koorush Ziarati and Morteza Keshtkaran},
  doi          = {10.1016/j.cor.2024.106530},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106530},
  shortjournal = {Comput. Oper. Res.},
  title        = {Revised eight-step feasibility checking procedure with linear time complexity for the dial-a-ride problem (DARP)},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Algorithms and computational study on a transportation
system integrating public transit and ridesharing of personal vehicles.
<em>COR</em>, <em>164</em>, 106529. (<a
href="https://doi.org/10.1016/j.cor.2024.106529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The potential of integrating public transit with ridesharing includes shorter travel time for commuters and higher occupancy rate of personal vehicles and public transit ridership. In this paper, we describe a centralized transit system that integrates public transit and ridesharing to reduce travel time for commuters. In the system, a set of ridesharing providers (drivers) and a set of public transit riders are received. The optimization goal of the system is to assign riders to drivers by arranging public transit and ridesharing combined routes for as many riders as possible subject to shorter commuting time. As an exact algorithm approach, we give a (0,1) integer linear programming (ILP) formulation based on a hypergraph representation of the problem. Leveraging the ILP and hypergraph, we give approximation algorithms based on LP-rounding and hypergraph matching/weighted set packing , respectively. As a case study , we conduct an extensive computational study based on real-world public transit dataset and ridesharing dataset in Chicago city. To evaluate the effectiveness of the transit system and our algorithms, we generate data instances from the datasets. The experimental results show that more than 60% of riders are assigned to drivers on average, riders’ commuting time is reduced by 23% and vehicle occupancy rate is improved to almost 3. Our proposed algorithms are efficient for practical scenarios.},
  archive      = {J_COR},
  author       = {Qian-Ping Gu and Jiajian Leo Liang},
  doi          = {10.1016/j.cor.2024.106529},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106529},
  shortjournal = {Comput. Oper. Res.},
  title        = {Algorithms and computational study on a transportation system integrating public transit and ridesharing of personal vehicles},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logic-based benders decomposition for bi-objective parallel
machine selection and job scheduling with release dates and resource
consumption. <em>COR</em>, <em>164</em>, 106528. (<a
href="https://doi.org/10.1016/j.cor.2023.106528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses a new bi-objective parallel machine selection and job scheduling problem with release dates and resource consumption. It consists in optimally selecting subcontractors (machines) from a set of geographically dispersed locations and scheduling the orders (jobs) to the selected subcontractors for processing while meeting the order release dates and resource consumption restrictions, so as to simultaneously minimize the maximum completion time, i.e., the makespan, and the total cost including machine usage cost and resource consumption cost. The problem is first formulated into a bi-objective mixed-integer linear program based on linear ordering (LO-MILP), and then valid inequalities are explored based on property analysis. To solve it, an ɛ ɛ ɛ -constraint method based on LO-MILP ( ɛ ɛ ɛ -LO-MILP) is first proposed. To more efficiently solve it, we also develop a tailored logic-based Benders decomposition combined with ɛ ɛ ɛ -constraint method ( ɛ ɛ ɛ -LBBD) where a novel method to obtain a tight lower bound of the identical parallel machine with machine-dependent release dates and some problem-specific cuts are proposed. Numerical experiments on an illustrative example are conducted to show the applicability of the model and algorithm and intuitively reveal the trade-off between production efficiency and cost. Experimental results on 200 instances with up to 100 orders demonstrate that ɛ ɛ ɛ -LBBD can reduce the computation time by about 28.92% compared to ɛ ɛ ɛ -LO-MILP and yields better Pareto solutions than ɛ ɛ ɛ -LO-MILP and the well-known non-dominated sorted genetic algorithm II do.},
  archive      = {J_COR},
  author       = {Peng Wu and Yun Wang and Chengbin Chu},
  doi          = {10.1016/j.cor.2023.106528},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106528},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition for bi-objective parallel machine selection and job scheduling with release dates and resource consumption},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mathematical models and exact algorithms for the colored bin
packing problem. <em>COR</em>, <em>164</em>, 106527. (<a
href="https://doi.org/10.1016/j.cor.2023.106527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on exact approaches for the Colored Bin Packing Problem (CBPP), a generalization of the classical one-dimensional Bin Packing Problem in which each item has, in addition to its length, a color, and no two items of the same color can appear consecutively in the same bin. To simplify modeling, we present a characterization of any feasible packing of this problem in a way that does not depend on its ordering. This allows us to describe the problem with a simple mathematical model . Furthermore, we present four exact algorithms for the CBPP. First, we propose a generalization of Valério de Carvalho’s arc flow formulation for the CBPP using a graph with multiple layers, each representing a color. Second, we present an improved arc flow formulation that uses a more compact graph and has the same linear relaxation bound as the first formulation. And finally, we design two exponential set-partition models based on reductions to a generalized vehicle routing problem , which are solved by a branch-cut-and-price algorithm through VRPSolver. To compare the proposed algorithms, a varied benchmark set with 574 instances of the CBPP is presented. Experimental results show that our best model, the improved arc flow formulation, was able to solve instances of up to 500 items and 37 colors. The set-partition models are also shown to exceed their arc flow counterparts in instances with a very small number of colors.},
  archive      = {J_COR},
  author       = {Yulle G.F. Borges and Rafael C.S. Schouery and Flávio K. Miyazawa},
  doi          = {10.1016/j.cor.2023.106527},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106527},
  shortjournal = {Comput. Oper. Res.},
  title        = {Mathematical models and exact algorithms for the colored bin packing problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unified branch-and-benders-cut for two-stage stochastic
mixed-integer programs. <em>COR</em>, <em>164</em>, 106526. (<a
href="https://doi.org/10.1016/j.cor.2023.106526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-stage stochastic programs are a class of stochastic problems where uncertainty is discretized into scenarios, making them amenable to solution approaches such as Benders decomposition . However, classic Benders decomposition is not applicable to general two-stage stochastic mixed-integer programs due to the restriction that the second-stage variables should be continuous. We propose a novel Benders decomposition-based framework that accommodates mixed-integer variables in both stages as well as uncertainty in all of the recourse parameters. The proposed approach is a unified branch-and-Benders algorithm, where we use a heuristic to maintain a global upper bound and a post-processing phase to determine an optimal solution. This new approach is flexible, allowing practitioners to integrate acceleration techniques such as partial decomposition or convexification schemes. We demonstrate the efficiency of our approach versus classic ones on the stochastic server location problem, and its generality on a new, complex stochastic problem where the second stage is a traveling salesman problem .},
  archive      = {J_COR},
  author       = {Arthur Mahéo and Simon Belieres and Yossiri Adulyasak and Jean-François Cordeau},
  doi          = {10.1016/j.cor.2023.106526},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106526},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unified branch-and-benders-cut for two-stage stochastic mixed-integer programs},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient greedy heuristic for the real-time train
platforming problem. <em>COR</em>, <em>164</em>, 106525. (<a
href="https://doi.org/10.1016/j.cor.2023.106525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a special class of real-time railway traffic management problem: efficiently reallocating trains to platforms at stations in case of slight schedule changes or major disruptions . The need for a real-time response with a high level of quality makes this problem particularly challenging. To address this issue, the authors propose a mesoscopic approach that involves preprocessing the data to determine feasible routes and other disruption parameters. They develop a greedy interchange heuristic to solve the mesoscopic real-time train platforming problem, providing high-quality routing and timing decisions within the computational time constraints of real-time management problems. The performance of the proposed heuristic is analyzed through case studies using both synthetic and realistic scenarios from the Spanish railway traffic system. For large instances of the Atocha-Cercanías station case study, the solutions are generated from 5 to 10 times faster by the heuristic algorithm than by the exact method. The authors conclude that the proposed heuristic is a promising solution for real-time train platforming problems.},
  archive      = {J_COR},
  author       = {Ricardo García-Ródenas and María Luz López-García and Luis Cadarso and Esteve Codina},
  doi          = {10.1016/j.cor.2023.106525},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106525},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient greedy heuristic for the real-time train platforming problem},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nested column generation for split pickup vehicle routing
problem with time windows and time-dependent demand. <em>COR</em>,
<em>164</em>, 106523. (<a
href="https://doi.org/10.1016/j.cor.2023.106523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study attempts to solve a split pickup vehicle routing problem with time windows and time-dependent demand. This is a vehicle routing problem in which demand is generated at different constant rates for different customers, and vehicles are allowed to pick up demand during the demand generation process. In this problem, the pickup time determines the quantity of demand that can be picked up, and a partial pickup is permitted during a single visit. The problem is formulated into a mixed-integer nonlinear programming model, and a sequence-extended network is designed to represent the relationship between multiple pickups. Because of the interdependences of time, load, and cost in the pricing subproblem, the classic labelling algorithm with weak dominance rules is ineffective, therefore, a nested column generation-based branch-and-price-and-cut algorithm is proposed to tackle the problem. The nested structure allows these trade-offs to be resolved in a lower-level column generation, and it can be applied to other interdependent routing problems. The computational results show that the proposed algorithm is effective in obtaining optimal solutions for small- and medium-scale instances within a reasonable time limit.},
  archive      = {J_COR},
  author       = {Shiping Wu and Hongguang Bo and Chun Jin and Xiaobing Liu},
  doi          = {10.1016/j.cor.2023.106523},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106523},
  shortjournal = {Comput. Oper. Res.},
  title        = {Nested column generation for split pickup vehicle routing problem with time windows and time-dependent demand},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient solution space exploring and descent method for
packing equal spheres in a sphere. <em>COR</em>, <em>164</em>, 106522.
(<a href="https://doi.org/10.1016/j.cor.2023.106522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of packing equal spheres in a spherical container is a classic global optimization problem , which has attracted enormous studies in academia and found various applications in industry. This problem is computationally very challenging, and many efforts focus on small-scale instances with the number of spherical items less than 200 in the literature. In this work, we propose an efficient local search heuristic algorithm named solution space exploring and descent for solving this problem, which can quantify the solution’s quality to determine the number of exploring actions and quickly discover a high-quality configuration. Besides, we propose an adaptive neighbor item maintenance method to speed up the convergence of the continuous optimization process and reduce the time consumption. Computational experiments on a large number of benchmark instances with 5 ≤ n ≤ 400 5≤n≤400 spherical items show that our algorithm significantly outperforms the state-of-the-art algorithm. Specifically, our algorithm improves 274 best-known results and matches 84 best-known results out of the 396 well-known benchmark instances.},
  archive      = {J_COR},
  author       = {Jianrong Zhou and Shuo Ren and Kun He and Yanli Liu and Chu-Min Li},
  doi          = {10.1016/j.cor.2023.106522},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106522},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient solution space exploring and descent method for packing equal spheres in a sphere},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An inventory model with price- and stock-dependent demand
and time- and stock quantity-dependent holding cost under profitability
maximization. <em>COR</em>, <em>164</em>, 106520. (<a
href="https://doi.org/10.1016/j.cor.2023.106520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on inventory models with a broad framework for the storage cost and the demand rate. The cumulative storage cost is modelled with a power function, depending on both time and stock quantity, by using two elasticity coefficients. Similarly, the demand rate has an isoelastic dependence on sale price and stock quantity, modelled with another two elasticity coefficients. These four elasticity coefficients allow many real practical situations to be modelled. A reference price is used to measure the effect of the sale price on the demand rate. The goal is to maximize the income expense ratio (IER), and the sale price, the order level and the reorder point are the decision variables. The operating expense ratio (OER) of the system, defined as the quotient cost/income, is used to solve the problem. The optimum values are obtained with explicit expressions, which is an interesting result for inventory managers. Under the optimum policy, the reorder point is always equal to zero and the order quantity depends on the replenishing cost, the purchase price and the four elasticity coefficients. However, the optimum ordering policy does not depend on the scale parameters of the storage cost and the demand rate. A complete sensitivity analysis for most of the model parameters is performed. A numerical example is used to compare the optimum policies for the maximum income expense ratio and the maximum profit per unit time. Finally, some managerial insights derived from the results are given.},
  archive      = {J_COR},
  author       = {Valentín Pando and Luis A. San-José and Joaquín Sicilia and David Alcaide-López-de-Pablo},
  doi          = {10.1016/j.cor.2023.106520},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106520},
  shortjournal = {Comput. Oper. Res.},
  title        = {An inventory model with price- and stock-dependent demand and time- and stock quantity-dependent holding cost under profitability maximization},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A two-level hierarchical nested cooperative location model.
<em>COR</em>, <em>164</em>, 106519. (<a
href="https://doi.org/10.1016/j.cor.2023.106519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the two-level Hierarchical Nested Cooperative Location (HNCL) model, extending the literature on discrete cooperative covering problems . We analyse the problem of locating facilities arranged in a two-level nested hierarchy and cooperating to maximize the covered demand. Facilities are characterized by different coverage decay functions according to the hierarchical level they belong to (upper and lower). Cooperation occurs between facilities at the same level ( intra-level cooperation ) and at different levels ( inter-level cooperation ) of the hierarchy according to mechanisms modelled through joint coverage functions. Two budget constraints are introduced for the total cost the decision-maker is willing to incur for locating facilities at each level. The HNCL problem is first formulated as a mixed-integer non-linear programming (MINLP) model; then, an equivalent mixed-integer linear program (MILP) is developed. We tested the HNCL model on instances randomly generated and extracted from a real-world network. The results are provided and discussed, highlighting the contribution of cooperative coverage compared to the individual one.},
  archive      = {J_COR},
  author       = {Silvia Baldassarre and Giuseppe Bruno and Ioannis Giannikos and Carmela Piccolo},
  doi          = {10.1016/j.cor.2023.106519},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106519},
  shortjournal = {Comput. Oper. Res.},
  title        = {A two-level hierarchical nested cooperative location model},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A smart energy scheduling under uncertainties of an iron ore
stockyard-port system using a rolling horizon algorithm. <em>COR</em>,
<em>164</em>, 106518. (<a
href="https://doi.org/10.1016/j.cor.2023.106518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning the efficient use of electricity in iron ore stockyard operations is a strategic issue due to the constant rise in energy prices nowadays and its considerable impact on production costs. This paper proposes a new large-scale mixed-integer nonlinear programming (MINLP) model for stockyard-port energy planning solved by the energy scheduling algorithm and a commercial solver to minimize power costs. The proposed nonlinear optimization problem is solved through an equivalent MILP model to minimize the flows of power and material between the stockyard-port equipment. The electrical machines are powered by different electricity energy providers, and eventually consume storage energy from batteries. The energy scheduling algorithm allows the planner to find a solution that saves electrical power costs in real time under unforeseen operational changes. Numerical results obtained through the proposed algorithm with a scheduling horizon of 24 h, show that the presence of the battery in the stockyard-port electrical grid allows for an energy cost reduction of up to 17.88% compared to the case without the battery. The energy scheduling based on rolling horizon algorithm provides feasible solutions near to the optimal solution, with an average distance of 1.78%, and it has an affordable computation time in instances where the MINLP model is not able to provide a solution.},
  archive      = {J_COR},
  author       = {Marcos W.J. Servare Junior and Helder R. de Oliveira Rocha and José L. Félix Salles},
  doi          = {10.1016/j.cor.2023.106518},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106518},
  shortjournal = {Comput. Oper. Res.},
  title        = {A smart energy scheduling under uncertainties of an iron ore stockyard-port system using a rolling horizon algorithm},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New optimization models for optimal classification trees.
<em>COR</em>, <em>164</em>, 106515. (<a
href="https://doi.org/10.1016/j.cor.2023.106515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most efficient state-of-the-art methods to build classification trees are greedy heuristics (e.g. CART) that may fail to find underlying characteristics in datasets. Recently, exact linear formulations that have shown better accuracy were introduced. However they do not scale up to datasets with more than a few thousands data points . In this paper, we introduce four new formulations for building optimal trees. The first one is a quadratic model based on the well-known formulation of Bertsimas et al. We then propose two different linearizations of this new quadratic model . The last model is an extension to real-valued datasets of a flow-formulation limited to binary datasets (Aghaei et al.). Each model is introduced for both axis-aligned and oblique splits. We further prove that our new formulations have stronger continuous relaxations than existing models. Finally, we present computational results on 22 standard datasets with up to thousands of data points . Our exact models have reduced solution times with learning performances as strong or significantly better than state of the art exact approaches.},
  archive      = {J_COR},
  author       = {Zacharie Ales and Valentine Huré and Amélie Lambert},
  doi          = {10.1016/j.cor.2023.106515},
  journal      = {Computers &amp; Operations Research},
  month        = {4},
  pages        = {106515},
  shortjournal = {Comput. Oper. Res.},
  title        = {New optimization models for optimal classification trees},
  volume       = {164},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improved heuristics for solving large-scale scanning
transmission electron microscopy image segmentation using the ordered
median problem. <em>COR</em>, <em>163</em>, 106524. (<a
href="https://doi.org/10.1016/j.cor.2023.106524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discrete ordered median problem can be applied in a wide variety of areas. The application of this problem in electron tomography image segmentation is currently being considered since high-quality images are obtained when this model is applied. However, its application means that a high computing time is required to obtain solutions for large-scale instances. The size of the images is of great importance in electron tomography experiments, since the larger the image size, the higher the quality of the image. With the goal of reducing the computation times , this paper introduces different heuristic procedures to obtain feasible solutions for the ordered median problem that provide high-quality images in low computing times. Moreover, some noticeable improvements for the heuristic techniques are developed, taking advantage of the particular versions of the ordered median function that have been proven to be especially suitable for electron tomography image segmentation.},
  archive      = {J_COR},
  author       = {Juan M. Muñoz-Ocaña and Justo Puerto and Antonio M. Rodríguez-Chía},
  doi          = {10.1016/j.cor.2023.106524},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106524},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improved heuristics for solving large-scale scanning transmission electron microscopy image segmentation using the ordered median problem},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid genetic algorithm based on reinforcement learning
for the energy-aware production scheduling in the photovoltaic glass
industry. <em>COR</em>, <em>163</em>, 106521. (<a
href="https://doi.org/10.1016/j.cor.2023.106521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the growing solar energy capacity has played a significant role in developing a clean energy supply system in China. However, the resulting rapid expansion of photovoltaic component (e.g., glass) manufacturing intensifies the energy demand in the locality of the plant. Therefore, this paper considers the energy-aware production scheduling of a deep-processing line in the photovoltaic glass plant, whose layout is a hybrid flow shop with batch and non-batch machines. Firstly, we establish a mixed integer programming model with the minimization of the energy consumption and the penalty for excess of the due date. Then, we propose a hybrid genetic algorithm (GA) based on reinforcement learning to solve the problem. Specifically, the expected Sarsa is used to extract critical knowledge about algorithmic parameters during the population evolution to guide the exploration of the GA. Finally, we conduct extensive numerical experiments to validate the effectiveness of the proposed algorithm by comparing it with a commercial optimization solver and other metaheuristics . The numerical results show that the average gap between the solver and the proposed algorithm is around 4% in small-sized instances. Compared with the heuristic used in the plant, the improvements of this paper are about 16% ∼ ∼ 18% and 17% ∼ ∼ 21% in practical-sized instances for the delay penalty and energy consumption objectives, respectively. In addition, the computational results provide managerial insights for managers in further pursuing energy efficiency from higher-level decision-making, e.g., planning over multiple periods from a tactical perspective, and changing production line configurations and introducing new processing techniques from a strategic perspective.},
  archive      = {J_COR},
  author       = {Weiwei Cui and Biao Yuan},
  doi          = {10.1016/j.cor.2023.106521},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106521},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid genetic algorithm based on reinforcement learning for the energy-aware production scheduling in the photovoltaic glass industry},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Classification and regression in prescriptive analytics:
Development of hybrid models and an example of ship inspection by port
state control. <em>COR</em>, <em>163</em>, 106517. (<a
href="https://doi.org/10.1016/j.cor.2023.106517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In prescriptive analytics , unknown quantities are involved in practical decision-making problems, and these unknown quantities need to be predicted using auxiliary data. A classic approach is to develop machine learning (ML) models to generate point estimates, which are then input to the decision making problem in a deterministic manner to prescribe the optimal decision . However, the limited quantity and inevitable errors in the auxiliary data lead to inaccurate predictions and thus sub-optimal decisions. One viable approach to addressing the above issue is to consider the uncertainties in data by inputting the conditional distributions of the unknown quantities on the auxiliary data to the optimization problem on hand, and the distributions are predicted by regression ML models. Meanwhile, it is observed that the quantitative target in some problems are discrete , and these properties are analogous to categorical targets in classification problems. Considering the fact that describing and estimating the distribution of categorical variables are much easier than quantitative variables, this study innovatively develops random forest (RF) models with regression and classification features to generate the distribution of quantitative targets that are discrete. Especially, nodes splitting criteria in the RF models is in a regression manner, while the outputs of individual decision trees and the whole RF model is in a classification manner. Numerical experiments using real port state control (PSC) inspection records and settings at the Hong Kong port are conducted to validate and compare the above prescriptive analytics approaches. The superiority of applying the newly proposed RF model into the development of prescriptive analytics approaches is also demonstrated.},
  archive      = {J_COR},
  author       = {Ran Yan and Shuaian Wang and Lu Zhen and Shuo Jiang},
  doi          = {10.1016/j.cor.2023.106517},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106517},
  shortjournal = {Comput. Oper. Res.},
  title        = {Classification and regression in prescriptive analytics: Development of hybrid models and an example of ship inspection by port state control},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multi-algorithm approach for operational human resources
workload balancing in a last mile urban delivery system. <em>COR</em>,
<em>163</em>, 106516. (<a
href="https://doi.org/10.1016/j.cor.2023.106516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient workload assignment to the workforce is critical in last-mile package delivery systems. The explosive increase of e-commerce and last-mile package logistics after the COVID-19 pandemic has produced, among other issues, difficulties in balancing the daily workload of the workforce in many delivery zones. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account to minimize the travel time of the workers. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have successfully illustrated the performance of the proposed approach in a real-world problem of human resource balancing in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Guadalajara, Spain.},
  archive      = {J_COR},
  author       = {Luis M. Moreno-Saavedra and Silvia Jiménez-Fernández and José A. Portilla-Figueras and David Casillas-Pérez and Sancho Salcedo-Sanz},
  doi          = {10.1016/j.cor.2023.106516},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106516},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel drone scheduling vehicle routing problems with
collective drones. <em>COR</em>, <em>163</em>, 106514. (<a
href="https://doi.org/10.1016/j.cor.2023.106514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study last-mile delivery problems where trucks and drones collaborate to deliver goods to final customers. In particular, we focus on problem settings where either a single truck or a fleet with several homogeneous trucks work in parallel to drones, and drones have the capability of collaborating for delivering missions. This cooperative behavior of the drones, which are able to connect to each other and work together for some delivery tasks, enhance their potential, since connected drone has increased lifting capabilities and can fly at higher speed, overcoming the main limitations of the setting where the drones can only work independently. In this work, we contribute a Constraint Programming model and a valid inequality for the version of the problem with one truck, namely the Parallel Drone Scheduling Traveling Salesman Problem with Collective Drones and we introduce for the first time the variant with multiple trucks, called the Parallel Drone Scheduling Vehicle Routing Problem with Collective Drones . For the latter version of the problem, we propose two Constraint Programming models and a Mixed Integer Linear Programming model. An extensive experimental campaign leads to state-of-the-art results for the problem with one truck and some understanding of the presented models’ behavior on the version with multiple trucks. Some insights about future research are finally discussed.},
  archive      = {J_COR},
  author       = {Roberto Montemanni and Mauro Dell’Amico and Andrea Corsini},
  doi          = {10.1016/j.cor.2023.106514},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106514},
  shortjournal = {Comput. Oper. Res.},
  title        = {Parallel drone scheduling vehicle routing problems with collective drones},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving critical buildings energy resilience via shared
autonomous electric vehicles — a sequential optimization framework.
<em>COR</em>, <em>163</em>, 106513. (<a
href="https://doi.org/10.1016/j.cor.2023.106513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interdependence between electric power systems and transportation systems is rapidly increasing due to the high adoption of Electric Vehicles (EVs) and their charging infrastructures. Electric vehicles can represent additional load for the power system, but can also bring new opportunities for contributing to the efficient and resilient operations of the power grid. This is mainly because of their ability to provide back power to the system when it is not used for transportation, essentially serving as a moving battery source for the power grid. This so-called Vehicle-to-Grid (V2G), Vehicle-to-Building (V2B), or, generally, Vehicle-to-X (V2X) capability of EVs has been extensively studied in the literature. However, the upcoming development of autonomous driving systems and their integration within sharing mobility services can significantly add to the possibilities of interaction between the transportation system and the power grid. This paradigm is studied to a much lesser extent in the existing literature. Shared Autonomous Electric Vehicles (SAEVs) could allow for more control of the actions of the fleet allowing for large-scale coordinated responses both to mobility and energy demands. This coordinated response can be particularly useful for providing emergency power services in case of power loss while maintaining a high level of transportation service. Thus, improving the overall resilience of the system. In this work, we develop a dynamic optimization framework to evaluate the potential contribution of the SAEV fleet for improving critical buildings’ energy resilience via V2B services. The model considers passengers’ pick-up and transportation, relocation of vehicles, and battery charging and discharging. Power outage scenarios for critical buildings are considered and the potential of the SAEV fleet to fully or partially respond to the emergency power outage is studied. In addition, sensitivity analysis for key parameters such as the outage parameters is introduced. The results of the case study for the Ile-de-France region in France shows that the SAEV fleet has the potential to provide V2B service for critical building at an acceptable loss of passenger total waiting time on the transportation side. Furthermore, it is shown that it is capable of satisfying the emergency power load at a lower cost compared to investing in extra backup generators unless the outage occurs at significantly high frequencies.},
  archive      = {J_COR},
  author       = {Jinming Liu and Adam Abdin and Jakob Puchinger},
  doi          = {10.1016/j.cor.2023.106513},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106513},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improving critical buildings energy resilience via shared autonomous electric vehicles — a sequential optimization framework},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-objective continuous review inventory policy using
MOPSO and TOPSIS methods. <em>COR</em>, <em>163</em>, 106512. (<a
href="https://doi.org/10.1016/j.cor.2023.106512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the dynamic business environment of today, decision-making involves considering various conflicting aspects. Inventory planning problems aim to determine how much and when to order products to satisfy customer demand at the lowest possible cost while maintaining a desirable service level. These problems can be formulated as a MOPSO algorithm, which is used to handle multiple objectives in a continuous review stochastic inventory control system ( r, Q ). Unfortunately, most multi-objective inventory models have been solved by aggregating objectives using specific weights or by optimizing only one objective and treating the others as constraints. Considering the complexity of real-world inventory control problems, which involves conflicting objectives such as minimizing cost and maximizing service level, the need arises to employ more precise optimizers that can generate better and more diverse non-dominated solutions of reorder point and order size system. In this paper multi-criteria decision-making framework that combines MOPSO algorithm and TOPSIS method to generate a Pareto front of non-dominated solutions and rank them based on decision makers&#39; preferences. Initially, the original MOPSO is applied to the multi-objective inventory control problem, and then the mutation operator is integrated into the MOPSO to maintain diversity in the swarm and explore the entire search space . Next, the leader selection strategy called the geographically-based system (Grids) is replaced by the crowding distance factor to choose the global optimal particle as a leader. Additionally, the ε ε -dominance concept is employed to limit the archive size and maintain more diversity and convergence in the MOPSO for optimizing the inventory control problem. In conclusion, this work not only pioneers a cutting-edge approach to multi objective inventory control but also underscores its practical value. By facilitating the generation of superior solutions that cater to diverse decision-maker preferences, our methodology resonates deeply with real-world challenges and sets a new benchmark for effective inventory planning.},
  archive      = {J_COR},
  author       = {Karzan Ghafour},
  doi          = {10.1016/j.cor.2023.106512},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106512},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective continuous review inventory policy using MOPSO and TOPSIS methods},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving an unrelated parallel machines scheduling problem
with machine- and job-dependent setups and precedence constraints
considering support machines. <em>COR</em>, <em>163</em>, 106511. (<a
href="https://doi.org/10.1016/j.cor.2023.106511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-stage production planning problems are common in the academic literature and in real-world environments. One of the least studied scenarios in the literature for this environment is that with Unrelated Parallel Machines. In this work, this type of problem is inspired by a real station within the wind tower production process. The problem presents characteristics that have already been studied, such as mandatory precedences and setup times that depend on the machine and the job. However, a new and real feature is presented: the existence of “support machines”, which are machines that can continue to work but cannot complete jobs due to reduced capacity for some operational reason. In this case, instead of abandoning their work, support machines can still be used to assist other machines by performing partial jobs before handing them over to full-capacity machines for completion. This innovative concept of support machines, never before presented in this context of production planning, introduces a unique approach to dealing with reduced-capacity machines without sacrificing their operational potential. A Mixed-Integer Linear Programming (MILP) model is formulated to mathematically represent this problem. This work explores the impact of these support machines on production planning. For this purpose, Tabu Search and Simulated Annealing metaheuristics have been adapted for their solution, and a novel Constructive Heuristic has been developed based on the real and manual process currently performed in the aforementioned factory. These three algorithms are run and compared on a real database in order to minimise the makespan. Their analysis shows that although the use of support machines generally gives positive results, an improvement is not achieved in all cases. Furthermore, contrary to what might be expected, the use of full-capacity machines in the role of support machines sometimes improves completion times.},
  archive      = {J_COR},
  author       = {María-Luisa Muñoz-Díaz and Alejandro Escudero-Santana and Antonio Lorenzo-Espejo},
  doi          = {10.1016/j.cor.2023.106511},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106511},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving an unrelated parallel machines scheduling problem with machine- and job-dependent setups and precedence constraints considering support machines},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An approximated dynamic programming model for the supply
vessel fleet sizing problem. <em>COR</em>, <em>163</em>, 106510. (<a
href="https://doi.org/10.1016/j.cor.2023.106510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The offshore oil and gas exploration and production activities heavily rely on a fleet of supply vessels, which play a crucial role in regularly providing necessary provisions from an onshore supply depot to the offshore installations. For Petrobras, the decision-making process concerning the number of supply vessels to be hired for the upcoming two years holds significant economic implications, given that the daily rates for a single supply vessel can soar to tens of thousands of USDs. In this study, we address the challenges of this heterogeneous fleet sizing problem by presenting an innovative approximated dynamic programming (ADP) model. The model takes into account the uncertainties associated with sea conditions and future demand, making it well-suited for real-world applications. To tackle this problem, we explored two types of approximate value functions : a piecewise linear concave value function and a neural network value function. Both methods underwent rigorous testing and demonstrated their capability to effectively address real-world problems. Consequently, our proposed method exhibits promising potential for practical implementation, allowing companies like Petrobras to accurately assess and determine the ideal fleet composition. By introducing this ADP model, we aim to provide valuable insights and solutions that enhance decision-making processes related to supply vessel fleet sizing in offshore operations. Through considering various uncertainties and complexities, our approach offers a robust and reliable framework to support critical economic decisions in this dynamic industry.},
  archive      = {J_COR},
  author       = {Leonardo Souza Ribeiro},
  doi          = {10.1016/j.cor.2023.106510},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106510},
  shortjournal = {Comput. Oper. Res.},
  title        = {An approximated dynamic programming model for the supply vessel fleet sizing problem},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Biased random-key genetic algorithm for the job sequencing
and tool switching problem with non-identical parallel machines.
<em>COR</em>, <em>163</em>, 106509. (<a
href="https://doi.org/10.1016/j.cor.2023.106509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the job sequencing and tool switching problem associated with non-identical parallel machines – a variation of the well-known sequencing and switching problem (SSP) better adapted to reflect the challenges in modern production environments. The NP NP -hard problem is approached by considering two isolated objective functions: the minimization of the makespan and the minimization of the total flow time. We present two versions of a parallel biased random-key genetic algorithm hybridized with tailored local search procedures that are organized using variable neighborhood descent. The proposed methods are compared with state-of-the-art methods by considering 640 benchmark instances from literature. For both objective functions considered, the proposed methods consistently outperform the compared methods. All known optimal values for both objectives are achieved, and a substantial gap is reported for all instance groups when compared with the best previously published solution values.},
  archive      = {J_COR},
  author       = {Leonardo C.R. Soares and Marco A.M. Carvalho},
  doi          = {10.1016/j.cor.2023.106509},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106509},
  shortjournal = {Comput. Oper. Res.},
  title        = {Biased random-key genetic algorithm for the job sequencing and tool switching problem with non-identical parallel machines},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simulation optimization framework to solve stochastic
flexible job-shop scheduling problems—case: Semiconductor manufacturing.
<em>COR</em>, <em>163</em>, 106508. (<a
href="https://doi.org/10.1016/j.cor.2023.106508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a Stochastic Flexible Job-Shop Scheduling Problem (SFJSSP) in the context of semiconductor manufacturing. Semiconductor industry is among the most capital-intensive businesses whose operational excellence is of vital importance. Within the front-end fab of the semiconductor industry, the photolithography workstation is the well-known bottleneck process. To elevate the performance of the whole semiconductor manufacturing system, developing a competent schedule for its bottleneck is essential. However, the re-entrant product flows, high uncertainties in operations times, and rapidly changing products and technologies within the photolithography, make it difficult to develop a schedule for the whole semiconductor fab. Considering Industry 4.0 , hybrid methods such as Simulation Optimization (SO) have proven their applicability in addressing complex production scheduling problems. Thus, this paper develops a mathematical model for SFJSSP of the semiconductor manufacturing considering special constraints of the photolithography workstation (machine process capability, machine dedication, and maximum reticles (masks) sharing constraints). Next, we transform the developed model into an SO model integrated with a computer simulation model capable of modeling the photolithography workstation. The simulation model develops an initial schedule based on the Least Work Remaining (LWR) dispatching rule . Moreover, the simulation model calculates the objective function of the SFJSSP. A tailored Genetic Algorithm (GA) is then developed, which attempts to optimize the initially proposed schedule. To validate the superiority of the presented SO methodology in addressing SJSSPs, it is compared with previously proposed methods. Furthermore, to assess the impact of the three special constraints of the photolithography work area on system performance, two sets of experiments are proposed. In the first set of experiments, the performance of two SFJSS environments, one with the special constraints and one without, is compared. The second set of experiments involves observing the system’s performance while systematically varying the severity of the special constraints. The results indicate that improved performance levels can be accomplished by enhancing flexibility within both the operations of individual jobs and the machines within the manufacturing system.},
  archive      = {J_COR},
  author       = {Ensieh Ghaedy-Heidary and Erfan Nejati and Amir Ghasemi and S. Ali Torabi},
  doi          = {10.1016/j.cor.2023.106508},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106508},
  shortjournal = {Comput. Oper. Res.},
  title        = {A simulation optimization framework to solve stochastic flexible job-shop scheduling Problems—Case: Semiconductor manufacturing},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matheuristics vs. Metaheuristics for joint lot-sizing and
dynamic pricing problem with nonlinear demands. <em>COR</em>,
<em>163</em>, 106507. (<a
href="https://doi.org/10.1016/j.cor.2023.106507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a joint dynamic pricing and production planning decisions problem for a profit-maximizing firm that produces and sells multiple products. The objective is to develop a coordinated decision approach for multi-product pricing and lot sizing decisions for a manufacturer considering a limited production capacity. The demand for each product is assumed to be iso-elastic and integrates the complementarity and the substitution effects between the products. First, the problem is formulated as a non-convex mixed integer nonlinear programming model ( M I N L P MINLP ) incorporating capacity constraints, setup costs, and nonlinear demand functions. Then, since the model is nonlinear and non-convex, a set of approximate approaches based on the Genetic algorithm, Late Acceptance Hill Climbing and Simulated Annealing methods are designed to solve this problem. Based on this study, the performances of two variants of approximate methods: matheuristics and metaheuristics are discussed and analyzed. The extensive experimental study, performed on real-world inspired instances, shows that matheuristic methods with setup-variables encoding scheme outperform the rest of the methods. The research outcomes show that coordinating a decision-making process by optimizing both prices and production plans simultaneously can result in significant profit for a company. However, one must consider the joint effect of the parameters of the demand function as well as the impact of the production capacity. This comprehensive understanding enables the company to avoid excessive investments in less lucrative products with lower sales potential, thereby ensuring resource allocation aligns with profitability and market demand.},
  archive      = {J_COR},
  author       = {Mourad Terzi and Yassine Ouazene and Alice Yalaoui and Farouk Yalaoui},
  doi          = {10.1016/j.cor.2023.106507},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106507},
  shortjournal = {Comput. Oper. Res.},
  title        = {Matheuristics vs. metaheuristics for joint lot-sizing and dynamic pricing problem with nonlinear demands},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient dominance filtering for unions and minkowski sums
of non-dominated sets. <em>COR</em>, <em>163</em>, 106506. (<a
href="https://doi.org/10.1016/j.cor.2023.106506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The repeated filtering of vectors for non-dominance is an important component in many multi-objective programming approaches, like e. g. decomposition approaches, dynamic programming or meta heuristics. Often the set of vectors to be filtered is given as the union A ∪ B A∪B or Minkowski sum A + B A+B of finite Pareto (or stable) sets, i. e. within both sets A A and B B the vectors are pairwise non-dominated. We propose several algorithms for both problems and compare them to a well-known static divide-and-conquer non-dominance filtering algorithm. Based on numerical experiments, we give recommendations for choosing a suitable method for particular situations, depending on, e.g., the number of objectives or the relative sizes of the sets A A and B B . Moreover, we consider non-dominance filtering for multi-set sums S = A 1 + … + A s . S=A1+…+As.},
  archive      = {J_COR},
  author       = {Kathrin Klamroth and Bruno Lang and Michael Stiglmayr},
  doi          = {10.1016/j.cor.2023.106506},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106506},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient dominance filtering for unions and minkowski sums of non-dominated sets},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scheduling of automated guided vehicles for tandem quay
cranes in automated container terminals. <em>COR</em>, <em>163</em>,
106505. (<a href="https://doi.org/10.1016/j.cor.2023.106505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the automated guided vehicle scheduling problem for serving the tandem quay cranes in the automated container terminal. The tandem quay crane is equipped with two spreaders, allowing it to execute both single-lift and tandem-lift operations. When performing a tandem-lift, two automated guided vehicles are required to support the tandem quay crane’s operation. Considering the coordination between tandem quay cranes and automated guided vehicles, a mixed-integer linear programming model is established to minimize the completion time of unloading operations by the tandem quay cranes. The formulation takes into account various crucial factors, such as traffic congestion and conflicts among automated guided vehicles, and the capacity limitation of yard buffers. A multi-start local search algorithm is developed for solving the problem. Computational experiments demonstrate the algorithm’s efficiency and effectiveness in solving both small- and large-scale instances. Furthermore, the computational analysis highlights the importance of considering traffic congestion and conflicts, as well as limited yard buffers in the automated container terminal. The study also reveals that when a sufficient number of vehicles are available, the deployment of tandem quay cranes can lead to a substantial enhancement of approximately 30% in operational efficiency compared to conventional single-spreader quay cranes.},
  archive      = {J_COR},
  author       = {Lingrui Kong and Mingjun Ji and Anxu Yu and Zhendi Gao},
  doi          = {10.1016/j.cor.2023.106505},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106505},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling of automated guided vehicles for tandem quay cranes in automated container terminals},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fix-and-optimize heuristic for the unrelated parallel
machine scheduling problem. <em>COR</em>, <em>163</em>, 106504. (<a
href="https://doi.org/10.1016/j.cor.2023.106504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes and evaluates a matheuristic approach for the Unrelated Parallel Machine Scheduling Problem (UPMSP). The UPMSP consists of assigning jobs to unrelated parallel machines considering different processing times for the same job in different machines. Additionally, a setup time is considered between the execution of jobs in the same machine. The problem is addressed by a fix-and-optimize matheuristic that iteratively selects a subset of variables to be fixed to their current values so that the remaining variables will compose a subproblem to be optimized by a mathematical programming solver. In the proposed approach, each subproblem consists of a subset of jobs that are assigned to a subset of machines in the incumbent solution. The subproblems are solved by the state-of-the-art exact algorithm for the UPMSP. In the experiments conducted on benchmark instances, the proposed fix-and-optimize algorithm achieved remarkable results. It outperformed the standalone exact algorithm by a large margin and resulted in competitive solutions when compared to the literature’s best-performing heuristic method for the problem. The proposed algorithm obtained the best solution for 669 out of the 1000 instances addressed in this work. Among them, 338 are new best-known solutions. In general, the proposed approach excels at solving instances with a high number of jobs per machine — it resulted in the best solution for 89% of the instances with a ratio of 10 or more jobs per machine in total.},
  archive      = {J_COR},
  author       = {George H.G. Fonseca and Guilherme B. Figueiroa and Túlio A.M. Toffolo},
  doi          = {10.1016/j.cor.2023.106504},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106504},
  shortjournal = {Comput. Oper. Res.},
  title        = {A fix-and-optimize heuristic for the unrelated parallel machine scheduling problem},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic inventory routing with dynamic demands and
intra-day depletion. <em>COR</em>, <em>163</em>, 106503. (<a
href="https://doi.org/10.1016/j.cor.2023.106503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Businesses such as supermarkets face an inventory routing problem with distinct stochastic dynamic demand distributions for various weekdays and times of the day. Most research, however, considers aggregated per-period demand and inventory depletion, thereby oversimplifying actual events. We formulate the problem as a finite-horizon stochastic dynamic program that accounts for the dynamic demand throughout the planning horizon and within each planning period. The models include different levels of information aggregation to decide the replenishment quantities and times by dividing periods into sub-periods with distinct demand distributions. This division helps the supplier create efficient replenishment plans and account for intra-day inventory levels. The modeled characteristics include routing, holding and stock-out costs, delivery time windows, inventory and vehicle capacities, and delivery time windows. The problem is solved using an iterative lookahead algorithm with an adaptive large neighborhood search for the routing and policy learning for the replenishment decisions. Numerical evaluations show the benefit of intra-day planning, effects of instance sizes, different coefficients of variation , and holding costs compared to benchmark replenishment policies. Considering intra-day depletion and demand data for each sub-period helps achieve savings of more than 20% compared to planning for full periods. The savings are obtained by adjusting delivery quantities, incorporating intra-day consumption, creating more efficient delivery routes, and correctly timing replenishments.},
  archive      = {J_COR},
  author       = {Emilio J. Alarcon Ortega and Sebastian Malicki and Karl F. Doerner and Stefan Minner},
  doi          = {10.1016/j.cor.2023.106503},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106503},
  shortjournal = {Comput. Oper. Res.},
  title        = {Stochastic inventory routing with dynamic demands and intra-day depletion},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A heuristic approach for the integrated
production–transportation problem with process flexibility.
<em>COR</em>, <em>163</em>, 106502. (<a
href="https://doi.org/10.1016/j.cor.2023.106502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an integrated multi-item production and distribution problem considering a network of multiple plants and clients, who are geographically dispersed, with direct shipments from the plants to the clients. In addition to the decisions on production and distribution, a decision needs to be taken on the level of process flexibility in the network, i.e., which items can be produced in which plants. There is a clear trade-off between these decisions. On the one hand, a network with total flexibility where each plant can produce all types of items allows for lower transportation costs, but requires large investments in flexibility and frequent setups. On the other hand, a network with a limited amount of flexibility where each plant produces only a few items, will increase the transportation costs, but requires a lower investment in flexibility. We model this problem as an extension of the capacitated lot-sizing problem. We limit the investment in flexibility by a budget constraint and minimize the operational costs. Varying this budget allows us to analyze different levels of flexibility. In this paper, we propose mathematical models and a hybrid solution method that combines a mixed integer programming-based approach and a kernel search heuristic . Our computational results using data sets from the literature show that the proposed hybrid method produces on average better solutions with significantly lower computational times when compared with the results produced by a state-of-the-art optimization software. Additional computational results are presented by varying key parameters and analyzing their impact on the value of flexibility. These computational experiments indicate that some of the main managerial insights which were derived in the literature for the case without transportation costs are no longer valid when we consider transportation costs.},
  archive      = {J_COR},
  author       = {Desiree M. Carvalho and Raf Jans and Silvio A. de Araujo and Diego J. Fiorotto},
  doi          = {10.1016/j.cor.2023.106502},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106502},
  shortjournal = {Comput. Oper. Res.},
  title        = {A heuristic approach for the integrated production–transportation problem with process flexibility},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the impact of initialisation strategies on maximum flow
algorithm performance. <em>COR</em>, <em>163</em>, 106492. (<a
href="https://doi.org/10.1016/j.cor.2023.106492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its theoretical and practical importance in network theory , designing effective algorithms for the Maximum Flow Problem (MFP) remains a focus of research efforts. Although worst-case performance analysis is the main tool for examining performance, empirical analysis across a wide variety of benchmark cases can identify scenarios where practical performance may contradict theoretical worse-case. In our previous work, we used Instance Space Analysis (ISA) to identify the practical strengths and weaknesses of four state-of-the-art MFP algorithms, and identified that the arc/path finding strategies employed by the algorithms explain critical differences in the algorithms’ behaviours. In this paper, we leverage these insights to propose two new initialisation strategies, which are an essential part of the arc/path finding strategy. To employ these new strategies on our previously studied four algorithms, we propose modifications that result in 15 new algorithmic variants. Using a comprehensive experimental setup and ISA, we examine the impact of these proposed initialisation strategies on performance, and discuss the conditions under which each initialisation strategy is expected to improve performance. One of the novel initialisation strategies is shown to improve the performance of MFP algorithms in many instances, making it promising for even further improvements of the algorithms.},
  archive      = {J_COR},
  author       = {Hossein Alipour and Mario Andrés Muñoz and Kate Smith-Miles},
  doi          = {10.1016/j.cor.2023.106492},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106492},
  shortjournal = {Comput. Oper. Res.},
  title        = {On the impact of initialisation strategies on maximum flow algorithm performance},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact decomposition technique for the
deadline-constrained discrete time/cost trade-off problem with
discounted cash flows. <em>COR</em>, <em>163</em>, 106491. (<a
href="https://doi.org/10.1016/j.cor.2023.106491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the deadline-constrained discrete time/cost trade-off problem with discounted cash flows in project scheduling optimization. Our objective is to optimize the net present value (NPV) of cash flows by selecting execution modes for activities while considering project deadlines. To address this problem, we propose an adapted model that combines the activity-on-node representation of the project network with the milestone activity payment system commonly used in real-world scenarios. This enhanced model accurately depicts project dynamics, enabling improved decision-making in NPV optimization. To solve the problem, we employ the generalized benders decomposition technique, which provides an exact solution approach to handle the computational complexity of the problem. Our approach introduces three types of feasibility cuts. The first type eliminates infeasible solutions by analyzing subproblem infeasibility. The second type enhances the generation of high-quality optimality cuts by iteratively introducing constraints to the master problem, utilizing dominated paths in the project network graph. Lastly, the third type targets the elimination of inferior infeasible solutions. Additionally, we generate a comprehensive dataset encompassing various scenarios and parameter ranges from existing literature. This dataset serves as a valuable resource for further research, with online accessibility and the latest solutions available for approximately 32,400 generated instances. Through our research, we demonstrate the superiority of our proposed solution procedure compared to existing methods in the field. By considering the specific requirements of project scheduling with NPV optimization and project deadlines, our approach contributes to more effective project planning and decision-making in real-world contexts.},
  archive      = {J_COR},
  author       = {Majid Yazdani and Tarik Aouam and Mario Vanhoucke},
  doi          = {10.1016/j.cor.2023.106491},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106491},
  shortjournal = {Comput. Oper. Res.},
  title        = {An exact decomposition technique for the deadline-constrained discrete time/cost trade-off problem with discounted cash flows},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Metaheuristics for the bi-objective resource-constrained
project scheduling problem with time-dependent resource costs: An
experimental comparison. <em>COR</em>, <em>163</em>, 106489. (<a
href="https://doi.org/10.1016/j.cor.2023.106489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bi-objective resource-constrained project scheduling problem with time-dependent resource costs was recently introduced and consists of scheduling a set of activities subject to precedence and resource constraints, minimizing the makespan and the total cost for resource usage. Precisely, costs are determined by the resource being considered together with the time it is used. Although this generalization of the traditional resource-constrained project scheduling problem is rather recent, it has garnered substantial interest as it succeeds in meeting a wide range of real-world demands. In such a multi-objective context, solving the aforementioned problem poses a challenge, as both objectives conflict with each other, giving rise to a set of trade-off optimal solutions, commonly known as the Pareto front (PF). Given that many medium or large-sized instances of this problem cannot be solved by exact methods, the development of metaheuristics to find the PF is necessary. So far, only one metaheuristic had been developed to solve this problem. In this work we have implemented six additional multi-objective evolutionary algorithms (MOEAs), representing different paradigms, and subsequently, an exhaustive comparison of their performance has been carried out. In particular, all the compared MOEAs share the same encoding and main operators, focusing the comparison on the general algorithm framework rather than specific versions. Metaheuristic algorithms typically yield an approximation of the optimal PF, prompting the question of how to assess the quality of the obtained approximations. To this end, a computational and statistically supported study is conducted, choosing a benchmark of bi-criteria resource-constrained project scheduling problems and applying a set of performance measures to the solution sets obtained by each methodology. The results show that there are significant differences among the performance of the metaheuristics evaluated.},
  archive      = {J_COR},
  author       = {Sofía Rodríguez-Ballesteros and Javier Alcaraz and Laura Anton-Sanchez},
  doi          = {10.1016/j.cor.2023.106489},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106489},
  shortjournal = {Comput. Oper. Res.},
  title        = {Metaheuristics for the bi-objective resource-constrained project scheduling problem with time-dependent resource costs: An experimental comparison},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A cooperative team orienteering optimisation model and a
customised resolution metaheuristic. <em>COR</em>, <em>163</em>, 106488.
(<a href="https://doi.org/10.1016/j.cor.2023.106488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workforce routing optimisation is an essential management task to achieve customer satisfaction and minimise costs in service-providing companies. A typical problem for an energy-saving company (ESCo) is to optimise the provisioning of maintenance services for the contracted buildings through a fleet of heterogeneous maintenance staff. This problem is modelled as a cooperative orienteering problem with time windows, operator qualification, and synchronisation constraints. A novel insertion heuristic is proposed and embedded in an adaptive large neighbourhood search algorithm and it is tested against a state-of-the-art algorithm using real-world data. The comparative study demonstrates the potential of the heuristic and a sensitivity analysis shows its robustness, focusing on time window length variation, and the number of synchronisation requirements. We consider managerial insights supported by results and concerns, e.g., the employment of further technicians to increase the number of served facilities. The proposed model and algorithm apply to similar problems as well.},
  archive      = {J_COR},
  author       = {Andrea Bendazzoli and Michele Urbani and Matteo Brunelli and Francesco Pilati},
  doi          = {10.1016/j.cor.2023.106488},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106488},
  shortjournal = {Comput. Oper. Res.},
  title        = {A cooperative team orienteering optimisation model and a customised resolution metaheuristic},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Location-pricing problem in a two-echelon supply chain: A
behavioral game-theoretic approach. <em>COR</em>, <em>163</em>, 106486.
(<a href="https://doi.org/10.1016/j.cor.2023.106486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The location-pricing problem is a relatively new class of problems in operations research that aims to solve both the pricing and facility location problems simultaneously. Unlike the classical facility location problem, where the demand of customers is known, in the location-pricing problem, the demand is a function of price. Other factors can also influence the final price of products, including production, transportation and inventory costs, competition and agents&#39; behavior, which make the location-pricing problem complex. To this end, this paper proposes a bi-level mixed integer nonlinear programming model for the location-pricing problem in a two-echelon supply chain with players who make decisions based on their social preferences in a competitive market. The social preferences of players are a topic of great importance in the field of behavioral game theory. If the supply chain players care about the profits of other competitors in their utility functions, the simplifying assumption of pure selfishness must be corrected. It is predicted that considering social preferences for supply chain members can lead to better outcomes and payoffs. This paper proposes a single-to-multiple Stackelberg-Nash game in which a focal company serves as the leader, responsible for the location, capacity allocation, pricing, and production/distribution planning of manufacturers. Additionally, there are two competing retailers, as followers who base their pricing strategies on social preferences in order to gain a larger market share. The competition between the retailers determines the demands of customers. The effects of various parameters are then examined using a sensitivity analysis, and some economic and managerial insights are provided. The findings indicate that when both retailers exhibit status-seeking behavior in the market, average market demand increases as a result of lower retail and wholesale prices, resulting in an increase in the profit margins of the supply chain and agents compared to a model with self-interested players.},
  archive      = {J_COR},
  author       = {Maryam Gharegozlu and Abdolsalam Ghaderi and Amir Hossein Seddighi},
  doi          = {10.1016/j.cor.2023.106486},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106486},
  shortjournal = {Comput. Oper. Res.},
  title        = {Location-pricing problem in a two-echelon supply chain: A behavioral game-theoretic approach},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluating different methods for ranking inputs in the
context of the performance assessment of decision making units: A
machine learning approach. <em>COR</em>, <em>163</em>, 106485. (<a
href="https://doi.org/10.1016/j.cor.2023.106485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of assessing the performance of decision-making units (companies, institutions, etc.), it is important to know the contribution or importance of each input to the generation of products and services in the production process. Identifying the degree of relevance of each input is a challenge from both an applied and a methodological point of view, especially within the field of non-parametric techniques, such as Data Envelopment Analysis (DEA), where the mathematical expression of the production function associated with the data generating process is not specified. This means that there is no specific coefficient to be estimated for each input, which makes it difficult to determine a ranking of importance of this type of variable compared to parametric methods, where a target function dependent on some parameters must be previously specified. Within this challenging context associated with the non-parametric approach to estimating technical efficiency , in this paper, we adapt several methods for identifying the importance of features used together with the Support Vector Machine technique in order to determine an importance ranking of the inputs in a productive process. The different adaptations developed in this article are computationally checked through a simulated experiment.},
  archive      = {J_COR},
  author       = {Daniel Valero-Carreras and Raul Moragues and Juan Aparicio and Nadia M. Guerrero},
  doi          = {10.1016/j.cor.2023.106485},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106485},
  shortjournal = {Comput. Oper. Res.},
  title        = {Evaluating different methods for ranking inputs in the context of the performance assessment of decision making units: A machine learning approach},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact algorithms for a parallel machine scheduling problem
with workforce and contiguity constraints. <em>COR</em>, <em>163</em>,
106484. (<a href="https://doi.org/10.1016/j.cor.2023.106484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a real-world scheduling problem where the objective is to allocate a set of tasks to a set of machines and to a set of workers in such a way that the total weighted tardiness is minimized. Our case study encompasses four types of constraints: precedence, resource, eligibility, and contiguity. While the first three constraints are common in the scheduling literature, contiguity constraints, which can be defined as a form of precedence constraints that requires both a predecessor and its successor to be processed on the same machine with no intermediate jobs in-between (but idle time is allowed), have never been studied in the literature. We present four exact methods to solve the problem: two methods use integer linear programming , one uses constraint programming , and one uses a combinatorial Benders’ decomposition. We introduce method-specific strategies to model the contiguity constraints for each of the proposed methods. We empirically evaluate, through an extensive set of computational experiments, the performance of the four methods on a heterogeneous dataset composed of real, realistic, and random instances, and outline that every method offers a competitive advantage on a targeted subset of instances. We also show that our algorithms can be generalized to solve related scheduling problems with contiguity constraints.},
  archive      = {J_COR},
  author       = {Giulia Caselli and Maxence Delorme and Manuel Iori and Carlo Alberto Magni},
  doi          = {10.1016/j.cor.2023.106484},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106484},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact algorithms for a parallel machine scheduling problem with workforce and contiguity constraints},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved solution methodology for the urban transit
routing problem. <em>COR</em>, <em>163</em>, 106481. (<a
href="https://doi.org/10.1016/j.cor.2023.106481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved solution methodology is proposed in this paper for the urban transit routing problem (UTRP). This methodology includes a procedure for the generation of improved initial solutions as well as improved metaheuristic search approaches, involving the use of hyperheuristics to manage search operators in both trajectory-based and population-based metaheuristics. The UTRP variant considered in this paper is that of deciding upon efficient bus transit routes. The design criteria embedded in our UTRP model are the simultaneous minimisation of the expected average passenger travel time and minimisation of the system operator’s cost (measuring the latter as the sum total of all route lengths in the system). The model takes as input an origin–destination demand matrix for a pre-specified set of bus stops, along with an underlying road network structure, and returns as output a set of bus route trade-off solutions. The decision maker can then select one of these route sets subjectively, based on the desired degree of trade-off between the aforementioned transit system design criteria. This bi-objective minimisation problem is solved approximately in three distinct stages — a solution initialisation stage , an intermediate analysis stage, and an iterative metaheuristic search stage during which high-quality trade-off solutions are sought. A novel procedure is introduced for the solution initialisation stage, aimed at effectively generating high-quality initial feasible solutions . Two metaheuristics are implemented to solve instances of the problem, namely a dominance-based multi-objective simulated annealing algorithm and an improved non-dominated sorting genetic algorithm, each equipped with a hyperheuristic capable of managing the perturbation operators employed. Various novel operators are proposed for these metaheuristics, of which the most noteworthy take into account the demand of passengers.},
  archive      = {J_COR},
  author       = {G. Hüsselmann and J.H. van Vuuren and S.J. Andersen},
  doi          = {10.1016/j.cor.2023.106481},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106481},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved solution methodology for the urban transit routing problem},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Self-adaptive general variable neighborhood search algorithm
for parallel machine scheduling with unrelated servers. <em>COR</em>,
<em>163</em>, 106480. (<a
href="https://doi.org/10.1016/j.cor.2023.106480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a machine learning-augmented General Variable Neighborhood Search algorithm, termed Self-adaptive General Variable Neighborhood Search (SGVNS), for solving the two-identical parallel machine scheduling problem with unrelated servers. The studied problem is of high practical relevance in various industries and presents a significant gap in the existing literature. The motivation for this study stems from the healthcare industry , specifically surgery scheduling with limited anesthesiologists’ availability. Two mathematical formulations are presented to solve this scheduling problem. However, these formulations are limited to small-scale problems, prompting the need for an efficient metaheuristic . Therefore, a novel variant of the General Variable Neighborhood Search metaheuristic is developed, incorporating a self-adaption mechanism based on an Extreme Learning Machine (ELM) algorithm. Extensive experiments are conducted to assess the performance of the SGVNS metaheuristic on various classes of instances. The results demonstrate the effectiveness and efficiency of SGVNS in solving previously unsolved small-sized instances, outperforming both formulations while maintaining reasonable computation times .},
  archive      = {J_COR},
  author       = {Issam Krimi and Rachid Benmansour},
  doi          = {10.1016/j.cor.2023.106480},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106480},
  shortjournal = {Comput. Oper. Res.},
  title        = {Self-adaptive general variable neighborhood search algorithm for parallel machine scheduling with unrelated servers},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multi-period facility location and capacity expansion with
modular capacities and convex short-term costs. <em>COR</em>,
<em>163</em>, 106395. (<a
href="https://doi.org/10.1016/j.cor.2023.106395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a multi-period facility location problem with capacity expansion motivated by the real-world problem of establishing hydrogen production infrastructure in Norway. The problem is formulated using modular capacities that capture economies of scale in production costs. The costs of opening a facility are represented by concave long-term costs, while the production costs of each capacity level are given by convex short-term costs. In our model, we allow only one expansion during the planning horizon, and have to observe limits on minimum production quantities. The objective is to minimize the sum of investment, expansion, production, and distribution costs while satisfying customer demand. To solve the problem we implement a solution method based on Lagrangian relaxation . The lower bound is calculated using a dynamic programming approach. To obtain an upper bound solution, we develop a greedy heuristic that converts the solution to the Lagrangian dual into a feasible solution . The approach is tested on different problem instances based on real-world data. The results show that our solution method based on Lagrangian relaxation outperforms Gurobi in terms of run time for all tested instances. Our Lagrangian based approach also always finds good or even near-optimal solutions, whereas Gurobi fails to find feasible solutions for some of the larger instances.},
  archive      = {J_COR},
  author       = {Šárka Štádlerová and Peter Schütz and Asgeir Tomasgard},
  doi          = {10.1016/j.cor.2023.106395},
  journal      = {Computers &amp; Operations Research},
  month        = {3},
  pages        = {106395},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-period facility location and capacity expansion with modular capacities and convex short-term costs},
  volume       = {163},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intra-facility equity in discrete and continuous p-facility
location problems. <em>COR</em>, <em>162</em>, 106487. (<a
href="https://doi.org/10.1016/j.cor.2023.106487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider facility location problems with a new form of equity criterion. Demand points have preference order on the sites where the plants can be located. The goal is to find the location of the facilities minimizing the envy felt by the demand points with respect to the rest of the demand points allocated to the same plant. After defining this new envy criterion and the general framework based on it, we provide formulations that model this approach in both the discrete and the continuous framework. The problems are illustrated with examples and the computational tests reported show the potential and limits of each formulation on several types of instances. Although this article is mainly focused on the introduction, modeling and formulation of this new concept of envy, some improvements for all the formulations presented are developed, obtaining in some cases better solution times.},
  archive      = {J_COR},
  author       = {Víctor Blanco and Alfredo Marín and Justo Puerto},
  doi          = {10.1016/j.cor.2023.106487},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106487},
  shortjournal = {Comput. Oper. Res.},
  title        = {Intra-facility equity in discrete and continuous p-facility location problems},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evolutionary multi-objective design of autoencoders for
compact representation of histopathology whole slide images.
<em>COR</em>, <em>162</em>, 106483. (<a
href="https://doi.org/10.1016/j.cor.2023.106483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent success of deep learning coincides with the surge of digital pathology as an effect of the pandemic. However, processing a massive volume of gigapixel histopathology images is daunting. Hence, establishing compact image representations for efficient computational pathology becomes paramount. Deep autoencoders have been frequently used to compress feature vectors extracted from pre-trained networks. However, the topology of autoencoders is generally set heuristically. In this paper, we propose a multi-objective evolutionary framework as a bi-level optimization scheme in which the outer level evolves autoencoders for the goal of dimension reduction while the inner level is to optimize their weights for training. Throughout the evolution process, multiple minimization objectives such as complexity, classification error , and code size are considered. These objectives can obtain compressed models to generate a very small set of deep features with the highest classification accuracy . We use images from The Cancer Genome Atlas (TCGA) repository provided by the National Cancer Institute to train and validate our optimization framework. We increased the classification accuracy by 8% while the image representation is 46,000 times shorter. We apply the framework to demonstrate higher accuracy, substantial memory reduction and faster processing for image retrieval compared to SOTA.},
  archive      = {J_COR},
  author       = {Davood Zaman Farsa and Shahryar Rahnamayan and Azam Asilian Bidgoli and H.R. Tizhoosh},
  doi          = {10.1016/j.cor.2023.106483},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106483},
  shortjournal = {Comput. Oper. Res.},
  title        = {Evolutionary multi-objective design of autoencoders for compact representation of histopathology whole slide images},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Theoretical and computational analysis of a new formulation
for the rural postman problem and the general routing problem.
<em>COR</em>, <em>162</em>, 106482. (<a
href="https://doi.org/10.1016/j.cor.2023.106482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Rural Postman Problem (RPP) is one of the most well-known problems in arc routing. Given an undirected graph , the RPP consists of finding a closed walk traversing and servicing a given subset of edges with minimum total cost. In the General Routing Problem (GRP), there is also a subset of vertices that must be visited. Both problems were introduced by Orloff and proved to be NP-hard. In this paper, we propose a new formulation for the RPP and the GRP using two sets of binary variables representing the first and second traversal, respectively, of each edge. We present several families of valid inequalities that induce facets of the polyhedron of solutions under mild conditions . Using this formulation and these families of inequalities, we propose a branch-and-cut algorithm, test it on a large set of benchmark instances, and compare its performance against the exact procedure that, as far as we know, produced the best results. The results obtained show that the proposed formulation is useful for solving undirected RPP and GRP instances of very large size.},
  archive      = {J_COR},
  author       = {Ángel Corberán and Isaac Plana and José M. Sanchis and Paula Segura},
  doi          = {10.1016/j.cor.2023.106482},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106482},
  shortjournal = {Comput. Oper. Res.},
  title        = {Theoretical and computational analysis of a new formulation for the rural postman problem and the general routing problem},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient iterative optimization to real-time train
regulation in urban rail transit networks combined with benders
decomposition method. <em>COR</em>, <em>162</em>, 106479. (<a
href="https://doi.org/10.1016/j.cor.2023.106479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the rapid expansion of urban rail transit networks and increasing transfer demands, this paper investigates the design of real-time train regulation strategies for urban rail networks under disturbances. Specifically, a mixed-integer nonlinear programming (MINLP) model is constructed in a rolling horizon (RH) framework to reduce train deviations and passenger waiting times, which involves complex coupling relationships among network-wide non-transfer passengers, transfer passengers and train traffics of different lines. To effectively address the model complexity and adapt to the real-time nature of this issue, we proposed an efficient iterative optimization (IO) approach to split the original problem into a smaller-scale regulation issue and a computationally cheap passenger loading procedure, which can efficiently treat the introduced nonconvexity of the exact modelling scheme. Besides, tailored to the mixed-integer property of the model, the generalized Benders decomposition (GBD) technique is incorporated into our algorithm. Furthermore, to verify the effectiveness of our method, we describe the detailed implementation of a series of numerical experiments on a small-scale and a real-world case. Computational results show that our regulation method can effectively contribute to the reliability of train systems, improving operational efficiency and service level. Besides, it performs promising computational efficiency in dealing with large-scale real-world cases, applicable for real-time applications.},
  archive      = {J_COR},
  author       = {Yin Yuan and Shukai Li and Lixing Yang and Ziyou Gao},
  doi          = {10.1016/j.cor.2023.106479},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106479},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient iterative optimization to real-time train regulation in urban rail transit networks combined with benders decomposition method},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Manipulating hidden-markov-model inferences by corrupting
batch data. <em>COR</em>, <em>162</em>, 106478. (<a
href="https://doi.org/10.1016/j.cor.2023.106478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series models typically assume untainted and legitimate streams of data. However, a self-interested adversary may have incentive to corrupt this data, thereby altering a decision maker’s inference. Within the broader field of adversarial machine learning , this research provides a novel, probabilistic perspective toward the manipulation of hidden Markov model inferences via corrupted data. In particular, we provision a suite of corruption problems for filtering, smoothing, and decoding inferences leveraging an adversarial risk analysis approach. Multiple stochastic programming models are set forth that incorporate realistic uncertainties and varied attacker objectives. Three general solution methods are developed by alternatively viewing estimation from frequentist and Bayesian perspectives . The efficacy of each method is illustrated via extensive, empirical testing. The developed methods are characterized by their solution quality and computational effort , resulting in a stratification of techniques across varying problem-instance architectures. This research highlights the weaknesses of hidden Markov models under adversarial activity, thereby motivating the need for robustification techniques to ensure their security.},
  archive      = {J_COR},
  author       = {William N. Caballero and Jose Manuel Camacho and Tahir Ekin and Roi Naveiro},
  doi          = {10.1016/j.cor.2023.106478},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106478},
  shortjournal = {Comput. Oper. Res.},
  title        = {Manipulating hidden-markov-model inferences by corrupting batch data},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Verifying new instances of the multidemand multidimensional
knapsack problem with instance space analysis. <em>COR</em>,
<em>162</em>, 106477. (<a
href="https://doi.org/10.1016/j.cor.2023.106477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization literature contains numerous studies defining a problem and showing a state-of-the-art implementation of a solution method . These studies may involve an empirical evaluation of the solution methods but assume the current collection of test instances is sufficient. This paper is concerned with instance generation methods for the multidemand multidimensional knapsack problem . We use instance space analysis to characterize the landscape of existing instances and validate the novelty of new instances. We discuss gaps present within the current instance space landscape and fill them with three new sets of instances. We find feasibility issues within instance generation methods and address them through a primal problem instance generator (PPIG). The instance generator is capable of producing feasible and diverse instances by directly controlling the problem features. PPIG contributes to the previous collections of instances and is validated through instance space analysis.},
  archive      = {J_COR},
  author       = {Matthew E. Scherer and Raymond R. Hill and Brian J. Lunday and Bruce A. Cox and Edward D. White},
  doi          = {10.1016/j.cor.2023.106477},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106477},
  shortjournal = {Comput. Oper. Res.},
  title        = {Verifying new instances of the multidemand multidimensional knapsack problem with instance space analysis},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An iteratively doubling binary search for the
two-dimensional irregular multiple-size bin packing problem raised in
the steel industry. <em>COR</em>, <em>162</em>, 106476. (<a
href="https://doi.org/10.1016/j.cor.2023.106476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the two-dimensional irregular multiple-size bin packing problem , where the goal is to pack all the given irregular pieces into bins of various sizes such that the total area of the used bins is minimized. Meanwhile, the irregular pieces include holes, and the bins can be irregular, also. This problem is raised in the steel industry considering the reuse of leftover material. An iteratively doubling binary search is proposed to solve this problem. Moreover, a binary search strategy is introduced to search the bin combination with minimum area, and an iteratively doubling strategy is utilized to control the search effort on each bin combination. Once the bins are identified, a first-fit bottom-left method is utilized to generate the initial position for each piece. An overlap minimization approach, which includes a local search by exchanging the positions of two pieces, is adapted to minimize the overlap in the initial solution. Experiment results on existing instances show that our approach could find a better solution than existing methods. Several instances representing different application scenarios are generated, and the results show our approach’s effectiveness and generality.},
  archive      = {J_COR},
  author       = {Shaowen Yao and Chao Tang and Hao Zhang and Songhuan Wu and Lijun Wei and Qiang Liu},
  doi          = {10.1016/j.cor.2023.106476},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106476},
  shortjournal = {Comput. Oper. Res.},
  title        = {An iteratively doubling binary search for the two-dimensional irregular multiple-size bin packing problem raised in the steel industry},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Drop-and-pull container drayage with flexible assignment of
work break for vehicle drivers. <em>COR</em>, <em>162</em>, 106475. (<a
href="https://doi.org/10.1016/j.cor.2023.106475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consideration of driver-related constraints, such as mandatory work break, in vehicle scheduling and routing is of extraordinary importance for safety driving and guaranteeing the interests of vehicle drivers. Drop-and-pull transportation is an efficient mode in container drayage services and creates interdependencies between the routes of vehicle drivers. The situation becomes even more complicated when the drivers must comply with requirements of the mandatory work break. This paper addresses a drop-and-pull container drayage problem with flexible assignment of work break. The time and location of work break for drivers can be flexibly chosen based on scheduling, routing and optimization requirements. The transportation vehicle is comprised of two parts as a tractor and a trailer. The tractor can drag at most one trailer at a time, and is separable from the trailer when executing drayage activities. The problem is formulated as a mixed-integer programming model, which is then strengthened by proposing several families of valid inequalities. To efficiently solve realistic-sized instances, a backtracking adaptive threshold accepting algorithm with a mixed-integer programming model specially coping with the assignment of work break is proposed. Mechanisms of tabu search are incorporated to enhance the searching ability of the algorithm. Experiments indicate that the proposed algorithm can efficiently handle the vehicle scheduling and routing as well as the work break assignment and outperforms the mathematical programming approach. Sensitivity analyses about different policies and varied length of the work break are also conducted with some managerial insights presented.},
  archive      = {J_COR},
  author       = {Decheng Wang and Ruiyou Zhang and Bin Qiu and Wenpeng Chen and Xiaolan Xie},
  doi          = {10.1016/j.cor.2023.106475},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106475},
  shortjournal = {Comput. Oper. Res.},
  title        = {Drop-and-pull container drayage with flexible assignment of work break for vehicle drivers},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unrelated parallel batch processing machine scheduling with
time requirements and two-dimensional packing constraints. <em>COR</em>,
<em>162</em>, 106474. (<a
href="https://doi.org/10.1016/j.cor.2023.106474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In various complex manufacturing systems such as wafer fabrication, ceramic processes, and additive manufacturing , a single machine often performs multiple distinct jobs simultaneously, requiring non-overlapping positions in the 2D-plane. As the demand for manufacturing with two-dimensional (2D) packing constraints continues to rise, there is an urgent need to address the integrated scheduling of batch processing machines (BPMs) and 2D packing. However, only a limited number of studies have explored BPM scheduling problems with 2D packing constraints. In this study, we focus on the scheduling of unrelated parallel BPMs to process jobs with non-identical sizes, unequal release dates, and due dates. To model the machine’s capacity, we move beyond the traditional one-dimensional knapsack approach and consider it as a 2D rectangle, taking into account the 2D packing constraints. It is crucial to ensure that no overlapping or stacking occurs within the machine’s capacity under these constraints. To address this problem, we propose a mixed integer linear programming model as the initial approach. Additionally, we develop an adaptive large neighborhood search (ALNS) heuristic specifically designed for handling large instances. The ALNS incorporates eleven removal operators and seven insertion operators, offering a comprehensive exploration and improvement of solutions. To tackle the packing procedure, we adopt two distinct packing patterns, namely Skyline and Open Space . These patterns play a significant role in optimizing the packing of jobs within the machine’s capacity. Furthermore, we conduct extensive computational experiments, generating 48 categories of instances with varying job attributes. These experiments serve to compare the performance of the two packing patterns and validate the effectiveness of our ALNS approach. In conclusion, our research addresses the critical gap in BPM scheduling problems with 2D packing constraints. By introducing a mixed integer linear programming model and developing the ALNS heuristic with diverse operators, coupled with the adoption of different packing patterns, we present a comprehensive approach to tackle this complex problem. Computational experiments are conducted to compare packing patterns and verify the performance of our ALNS method.},
  archive      = {J_COR},
  author       = {Kanxin Hu and Yuxin Che and Tsan Sheng Ng and Jie Deng},
  doi          = {10.1016/j.cor.2023.106474},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106474},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unrelated parallel batch processing machine scheduling with time requirements and two-dimensional packing constraints},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deterministic constructive vN-NEH+ algorithm to solve
permutation flow shop scheduling problem with makespan criterion.
<em>COR</em>, <em>162</em>, 106473. (<a
href="https://doi.org/10.1016/j.cor.2023.106473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling jobs in a permutation flow shop (PFS) environment is one of the most studied problems in scheduling theory and practice. In this paper, we propose a new efficient algorithm to solve the permutation flow shop scheduling problem (PFSP) with the makespan criterion. The proposed algorithm, referred to as vN -NEH+, extends the Nawaz–Enscore–Ham (NEH) heuristic by employing the variable-length list ( vN -list) of candidate jobs. Extensive numerical experiments on the standard set of benchmarks show that the proposed vN -NEH+ algorithm is one of the most efficient NEH-based deterministic constructive algorithms in terms of trade-off between solution quality and computing time. Moreover, in contrary to existing scheduling methods, vN -NEH+ produces in a single run a set of good quality solutions that can serve as an initial population in population-based metaheuristics for solving PFSPs. Another advantage of vN -NEH+ is that it can work in parallel mode, which is difficult or even impossible with other NEH-based heuristics. In addition to vN -NEH+, we propose a new ART.NEH (Average Relative Time over NEH) indicator to assess the running time of PFSP algorithms. The main advantage of ART.NEH is its hardware/software and instance size independence, which allows an objective and reliable comparison of computational effort of PFSP algorithms. In addition, the idea behind ART.NEH can be easily adopted to reliably assess time complexity of algorithms for solving various other computational problems.},
  archive      = {J_COR},
  author       = {Radosław Puka and Iwona Skalna and Jerzy Duda and Adam Stawowy},
  doi          = {10.1016/j.cor.2023.106473},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106473},
  shortjournal = {Comput. Oper. Res.},
  title        = {Deterministic constructive vN-NEH+ algorithm to solve permutation flow shop scheduling problem with makespan criterion},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unmanned surface vehicles (USVs) scheduling method by a
bi-level mission planning and path control. <em>COR</em>, <em>162</em>,
106472. (<a href="https://doi.org/10.1016/j.cor.2023.106472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the operational efficiency of container terminals, we propose a bi-level scheduling method that employs unmanned surface vehicles (USVs) to transport containers exclusively between different berths on the waterside of terminals. In the upper level, Considering time windows, berth coordination, energy replenishment, etc., we formulate the mission decision model to obtain a cost-effective USVs shipping solution by minimizing unplanned delay and total execution cost. In the lower level, considering path distance, path smoothness, and motion constraints, we develop the USV path control model to achieve the USV path planning and reduce path tracking errors. Finally, we integrate the advantages of the chaotic Electron Search and multi-population Genetic Algorithm (ES-mGA) to solve the bi-level USVs scheduling model. Experimental results demonstrate the effectiveness of our approach and algorithm in guiding the USVs to efficiently accomplish container transshipment and acquire stable USV sailing states.},
  archive      = {J_COR},
  author       = {Xinghai Guo and Netirith Narthsirinth and Weidan Zhang and Yuzhen Hu},
  doi          = {10.1016/j.cor.2023.106472},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106472},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unmanned surface vehicles (USVs) scheduling method by a bi-level mission planning and path control},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generating linear programming instances with controllable
rank and condition number. <em>COR</em>, <em>162</em>, 106471. (<a
href="https://doi.org/10.1016/j.cor.2023.106471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance generation is crucial for linear programming algorithms, especially for the evaluation and verification of corresponding methods. This study proposes a general framework for designing linear programming instances based on the preset optimal solution. First, we give a constraint matrix generation method with controllable condition number and rank from the perspective of matrix decomposition . Based on the preset optimal solution, a bounded feasible linear programming instance is generated with the right-hand side and objective coefficients satisfying the primal feasibility and dual feasibility. In addition, we provide three neighborhood exchange operators and prove that instances generated under this method can fill the entire space of feasible bounded linear programming instances. We experimentally validate that the proposed schedule generates more controllable linear programming instances in rank and condition number, while neighborhood exchange operators construct more complex instances.},
  archive      = {J_COR},
  author       = {Anqi Li and Congying Han and Tiande Guo and Bonan Li},
  doi          = {10.1016/j.cor.2023.106471},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106471},
  shortjournal = {Comput. Oper. Res.},
  title        = {Generating linear programming instances with controllable rank and condition number},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cutting plane approaches for the robust kidney exchange
problem. <em>COR</em>, <em>162</em>, 106470. (<a
href="https://doi.org/10.1016/j.cor.2023.106470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renal patients who have a willing but incompatible donor can decide to participate in a kidney exchange program (KEP). The goal of a KEP is to identify sets of incompatible pairs that can exchange donors, leading to compatible transplants for each recipient. Significant uncertainty is involved in this process, as planned transplants may be canceled for many reasons. It is therefore crucial to take into account failures while planning exchanges. In this paper, we consider a robust variant of this problem with recourse studied in the literature that takes into account failures of donors or recipients. This problem belongs to the class of defender–attacker–defender (DAD) models. We propose a cutting plane method for solving the attacker–defender subproblem based on two commonly used mixed-integer programming formulations for kidney exchange problems. Our results imply a running time improvement of one order of magnitude compared to the state-of-the-art. Moreover, our cutting plane methods can solve many previously unsolved instances. Furthermore, we propose a new practical policy for recourse in KEPs and show that the robust optimization problem concerning this policy is tractable for small to mid-size KEPs in practice.},
  archive      = {J_COR},
  author       = {Danny Blom and Christopher Hojny and Bart Smeulders},
  doi          = {10.1016/j.cor.2023.106470},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106470},
  shortjournal = {Comput. Oper. Res.},
  title        = {Cutting plane approaches for the robust kidney exchange problem},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Electric vehicle-based express service network design with
recharging management: A branch-and-price approach. <em>COR</em>,
<em>162</em>, 106469. (<a
href="https://doi.org/10.1016/j.cor.2023.106469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With soaring fuel prices and the imperative to reduce global carbon emissions, electric vehicles (EVs) possess unparalleled advantages in terms of sustainability. Consequently, numerous express service providers have commenced the implementation of EV-based express service networks . However, designing an effective service network for EV fleets necessitates considering recharging operations during the route planning process. In this study, we explore a problem involving the design of an EV-based express service network under the constraint of limited recharging resources, while taking into account power management for each EV throughout the entire operational cycle. To address this challenge, we present a mixed-integer optimization model incorporating a Dantzig–Wolfe reformulation. Additionally, we develop resource extension functions that enable an efficient dynamic labeling algorithm, incorporating dominance rules, to solve complex subproblems . We propose a branch-and-price framework that integrates an aggregated branching strategy and a heuristic upper-bound technique, enabling the attainment of exact solutions for instances involving large fleet sizes. Computational experiments conducted on realistic instances, involving up to 20 terminals and over 2000 EVs, substantiate the efficiency of our approach.},
  archive      = {J_COR},
  author       = {Xudong Diao and Meng Qiu and Gangyan Xu},
  doi          = {10.1016/j.cor.2023.106469},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106469},
  shortjournal = {Comput. Oper. Res.},
  title        = {Electric vehicle-based express service network design with recharging management: A branch-and-price approach},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The berth allocation and quay crane assignment problem with
crane travel and setup times. <em>COR</em>, <em>162</em>, 106468. (<a
href="https://doi.org/10.1016/j.cor.2023.106468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new approach for including quay crane travel and setup times in the berth allocation and quay crane assignment problem. We first develop a new mixed integer linear programming model (MILP) for the problem without setups (BACASP), in which berthing positions and times are considered as continuous variables. Several groups of valid inequalities are also set forth. Then, for the BACASP with crane travel and setup times, which we denote as BACASP-S, we propose two MILPs: the first is based on the previous BACASP formulation and the second on routing formulations. Due to the complexity of the BACASP-S, we also propose a genetic algorithm and an exact approach which combines various MILPs with the genetic algorithm. All methods and valid inequalities are computationally tested over two different sets of randomly generated instances . According to the results, the models and algorithms can optimally solve, in less than one hour, BACASP-S instances of up to 40 vessels within a quay one kilometer long and a time horizon of one week. Additionally, extensive experiments were conducted on a new large set of instances to assess the effect of various BACASP-S input parameters on the computation effort required to solve the problem. Ceteris paribus , the computational effort required seems to increase with decreasing number of cranes, while vessel processing times and crane setup times seem not to affect it.},
  archive      = {J_COR},
  author       = {Juan F. Correcher and Federico Perea and Ramon Alvarez-Valdes},
  doi          = {10.1016/j.cor.2023.106468},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106468},
  shortjournal = {Comput. Oper. Res.},
  title        = {The berth allocation and quay crane assignment problem with crane travel and setup times},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified exact approach for a broad class of vehicle
routing problems with simultaneous pickup and delivery. <em>COR</em>,
<em>162</em>, 106467. (<a
href="https://doi.org/10.1016/j.cor.2023.106467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vehicle routing problem (VRP) with simultaneous pickup and delivery (VRPSPD) is a classical combinatorial optimization problem in which one aims at determining least-cost routes, starting and ending at the depot, while simultaneously meeting the pickup and delivery demands of geographically dispersed customers in a single visit, and without violating the capacity of the vehicle. In this work, we propose a unified branch-cut-and-price (BCP) algorithm to solve ten variants of the problem, considering not only the standard version but also those including additional attributes such as a heterogeneous fleet of vehicles, time windows, route duration, multiple depots, and location decisions. The resulting problem that generalizes all of these variants can be formulated as a heterogeneous location routing problem with simultaneous pickup and delivery and time windows (HLRPSPDTW), for which we propose a compact formulation to serve as the basis for an extended formulation associated with the BCP approach. The proposed exact method includes many of the features developed in recent years, such as a bucket graph-based labeling algorithm, rank-1 cuts with limited memory, and dynamic ng-sets. Extensive computational experiments were performed on more than 550 benchmark instances and our algorithm was capable of obtaining a number of new optimal solutions, as well as improved lower bounds, for all variants addressed in this paper.},
  archive      = {J_COR},
  author       = {Rafael Praxedes and Teobaldo Bulhões and Anand Subramanian and Eduardo Uchoa},
  doi          = {10.1016/j.cor.2023.106467},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106467},
  shortjournal = {Comput. Oper. Res.},
  title        = {A unified exact approach for a broad class of vehicle routing problems with simultaneous pickup and delivery},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bilevel optimization for the deployment of refuelling
stations for electric vehicles on road networks. <em>COR</em>,
<em>162</em>, 106460. (<a
href="https://doi.org/10.1016/j.cor.2023.106460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work consists of a procedure to optimally select, among a group of candidate sites where gas stations were already located, a sufficient number of charging points in order to guarantee that an electric vehicle can make its journey without a problem of energy autonomy and that each selected charging station has another one that serves as useful support in case of failure (reinforced coverage service). For this purpose, we propose a bilevel model that, in a former level, minimizes the number of refuelling points necessary to guarantee a reinforced service coverage for all users who transit from their origin to destination and, as a second level, maximize the volume of demand that can be satisfied subject to budgetary restrictions. With the first of the objectives we are addressing the typical requirement of the administration, which consists of guaranteeing the viability of the solutions, and the second of the objectives is a criterion typically used by the private sector initiative, compatible with the profit maximization.},
  archive      = {J_COR},
  author       = {Ramón Piedra-de-la-Cuadra and Francisco A. Ortega},
  doi          = {10.1016/j.cor.2023.106460},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106460},
  shortjournal = {Comput. Oper. Res.},
  title        = {Bilevel optimization for the deployment of refuelling stations for electric vehicles on road networks},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An asynchronous parallel benders decomposition method for
stochastic network design problems. <em>COR</em>, <em>162</em>, 106459.
(<a href="https://doi.org/10.1016/j.cor.2023.106459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benders decomposition (BD) is one of the most popular solution algorithms for stochastic integer programs . The BD method decomposes stochastic problems into one master problem and multiple disjoint subproblems . It thus lends itself readily to parallelization . In almost all studies on the parallelization of this algorithm, the master problem remains idle until every subproblem is solved and vice versa. This can clearly result in an extremely inefficient parallel algorithm due to excessive idle times. On the other hand, relaxing the synchronization requirement can yield a nonconvergent or less efficient algorithm that may even underperform when compared to the sequential version. Addressing these issues, we introduce an asynchronous parallel BD method for stochastic network design problems. We show that the proposed algorithm converges to the global optimum and suggest various acceleration strategies to enhance its performance. We conduct an extensive numerical study on benchmark instances from a generic stochastic network design problem. The results indicate that using up to 20 processors, our asynchronous algorithm is on average 1.4 times faster than the conventional low-level parallel methods.},
  archive      = {J_COR},
  author       = {Ragheb Rahmaniani and Teodor Gabriel Crainic and Michel Gendreau and Walter Rei},
  doi          = {10.1016/j.cor.2023.106459},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106459},
  shortjournal = {Comput. Oper. Res.},
  title        = {An asynchronous parallel benders decomposition method for stochastic network design problems},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Job-shop scheduling with limited flexible workers
considering ergonomic factors using an improved multi-objective discrete
jaya algorithm. <em>COR</em>, <em>162</em>, 106456. (<a
href="https://doi.org/10.1016/j.cor.2023.106456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Job-Shop Scheduling Problem (JSP) with worker flexibility has gained significant attention in recent years, offering cost reduction and improved efficiency by limiting the number of workers. However, consideration of ergonomic factors is generally ignored for such systems. The ergonomic consideration is important to prevent stress, fatigue, and lack of focus among the workers, particularly when recurring manual tasks are involved. To prioritize productivity and workforce relief simultaneously, this article addresses the JSP with limited flexible workers considering ergonomic factors (JSPLFW-ER). The study focuses on worker workload and human energy expenditure as the key ergonomic factors. The average human energy expenditure rate is also considered to ensure that its value does not exceed the critical limit. An improved multi-objective discrete Jaya algorithm (IMDJA) is proposed to solve JSPLFW-ER by minimizing the makespan, maximum worker workload, and maximum human energy expenditure of the assigned operations. IMDJA incorporates a Jaya random partial updating mechanism in which a certain number of elements of the individual are randomly selected for Jaya updating. The number of elements to be selected for Jaya updating is evaluated using the Taguchi analysis. The performance of IMDJA is investigated with comprehensive experiments, using the 40 newly constructed instances and found competitive to solve JSPLFW-ER. Furthermore, a real-world industrial problem is presented with multiple experiments, which demonstrates the applicability of the JSPLFW-ER and effectiveness of the proposed IMDJA for solving the industrial problem.},
  archive      = {J_COR},
  author       = {Shaban Usman and Cong Lu},
  doi          = {10.1016/j.cor.2023.106456},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106456},
  shortjournal = {Comput. Oper. Res.},
  title        = {Job-shop scheduling with limited flexible workers considering ergonomic factors using an improved multi-objective discrete jaya algorithm},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A hybrid genetic algorithm for the min–max multiple
traveling salesman problem. <em>COR</em>, <em>162</em>, 106455. (<a
href="https://doi.org/10.1016/j.cor.2023.106455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a hybrid genetic algorithm for solving the Multiple Traveling Salesman Problem (mTSP) to minimize the length of the longest tour. The genetic algorithm utilizes a TSP sequence as the representation of each individual, and a dynamic programming algorithm is employed to evaluate the individual and find the optimal mTSP solution for the given sequence of cities. A novel crossover operator is designed to combine similar tours from two parents and offers great diversity for the population. For some of the generated offspring , we detect and remove intersections between tours to obtain a solution with no intersections. This is particularly useful for the min–max mTSP. The generated offspring are also improved by a self-adaptive random local search and a thorough neighborhood search. Our algorithm outperforms all existing algorithms on average, with similar cutoff time thresholds, when tested against multiple benchmark sets found in the literature. Additionally, we improve the best-known solutions for 21 out of 89 instances on four benchmark sets.},
  archive      = {J_COR},
  author       = {Sasan Mahmoudinazlou and Changhyun Kwon},
  doi          = {10.1016/j.cor.2023.106455},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106455},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid genetic algorithm for the min–max multiple traveling salesman problem},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matheuristic for synchronized vehicle routing problem with
multiple constraints and variable service time: Managing a fleet of
sprayers and a tender tanker. <em>COR</em>, <em>162</em>, 106454. (<a
href="https://doi.org/10.1016/j.cor.2023.106454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an extension of the vehicle routing problem with synchronization constraints and introduces the vehicle routing problem with multiple synchronization constraints and variable service time . This important problem is motivated by a real-world problem faced by one of the largest agricultural companies in the world providing precision agriculture services to their clients who are farmers and growers. The solution to this problem impacts the performance of farm spraying operations and can help design policies to improve spraying operations in large-scale farming. We propose a Mixed Integer Programming (MIP) model for this challenging problem, along with problem-specific valid inequalities . A three-phase powerful matheuristic is proposed to solve large instances enhanced with a novel local search method. We conduct extensive numerical analysis using realistic data. Results show that our matheuristic is fast and efficient in terms of solution quality and computational time compared to the state-of-the-art MIP solver. Using real-world data, we demonstrate the importance of considering an optimization approach to solve the problem, showing that the policy implemented in practice overestimates the costs by 15%–20%. Finally, we compare and contrast the impact of various decision-maker preferences on several key performance metrics by comparing different mathematical models .},
  archive      = {J_COR},
  author       = {Faisal Alkaabneh},
  doi          = {10.1016/j.cor.2023.106454},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106454},
  shortjournal = {Comput. Oper. Res.},
  title        = {Matheuristic for synchronized vehicle routing problem with multiple constraints and variable service time: Managing a fleet of sprayers and a tender tanker},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An exact constraint programming based procedure for the
multi-manned assembly line balancing problem. <em>COR</em>,
<em>162</em>, 106451. (<a
href="https://doi.org/10.1016/j.cor.2023.106451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike the Simple Assembly Line Balancing Problem (SALBP), the Multi-manned Assembly Line Balancing Problem (MALBP) allows the assignment of multiple workers at the same station. This study proposes a novel Constraint Programming (CP) model to evaluate the satisfiability of a type-F MALBP. Given a cycle time limit, the number of workers and the number of stations are set as parameters in each iteration. We adopt an exact lexicographical procedure as the solution method for this multi-objective optimization problem , performing a lower-bound search to minimize the number of workers as the primary objective . Such an assumption is common for real-world applications, in which the total cost of a worker is usually several orders of magnitude higher than the cost of a station. When dealing with hard instances, we adopt the task–worker assignment solution for SALBP as input to an auxiliary Mixed-Integer Linear Programming (MILP) model, which provides an initial condition for the task scheduling portion of the CP model. Strong tasks’ scheduling bounds are also provided to tighten the search space , and mathematical similarities with SALBP are exploited to support our solution method. The integrated MILP-CP procedure yielded 126 optimal solutions from a 140-instance dataset, including nine new optimality proofs. Moreover, twelve additional instances were improved compared to the literature, enhancing the solution quality. Considering the best-found primal bounds, the maximum gap for the still-open instances is just 0.32%. These results demonstrated the effectiveness of the proposed procedure in solving MALBP when combined with solid bounds.},
  archive      = {J_COR},
  author       = {Moacyr Carlos Possan Junior and Adalberto Sato Michels and Leandro Magatão},
  doi          = {10.1016/j.cor.2023.106451},
  journal      = {Computers &amp; Operations Research},
  month        = {2},
  pages        = {106451},
  shortjournal = {Comput. Oper. Res.},
  title        = {An exact constraint programming based procedure for the multi-manned assembly line balancing problem},
  volume       = {162},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Intermittent sampling for statistical process control with
the number of defectives. <em>COR</em>, <em>161</em>, 106423. (<a
href="https://doi.org/10.1016/j.cor.2023.106423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intermittent sampling model for statistical process control (SPC) is introduced to monitor the quality of output from a production process where the number of defective units in a sample is measured in selected time periods. A Li mited M emory I nfluence D iagram (LIMID) model is implemented to determine the time periods in which to collect samples and the decision strategy to minimize total costs of quality control . In periods where samples are collected, the observed defectives determine whether the process is stopped to investigate and repair an assignable cause of variation. Based on sample results, the process can alternatively be allowed to run without interruption until the next predetermined sampling interval, or the results may suggest collecting a sample again in the next period. The model only requires the user to know the result of the current sample to make a decision, in contrast to Bayesian methods that require calculations based on all prior samples and a history of actions. Despite the limited and intermittent nature of the information, the model provides lower quality costs than existing methods for a wide range of production time horizons.},
  archive      = {J_COR},
  author       = {Barry R. Cobb},
  doi          = {10.1016/j.cor.2023.106423},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106423},
  shortjournal = {Comput. Oper. Res.},
  title        = {Intermittent sampling for statistical process control with the number of defectives},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An improved genetic algorithm for the berth scheduling with
ship-to-ship transshipment operations integrated model. <em>COR</em>,
<em>161</em>, 106409. (<a
href="https://doi.org/10.1016/j.cor.2023.106409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a dynamic variant of Berth Allocation Problem with ship-to-ship transshipment in a container terminal, namely (DBAP STS STS ), where ships can arrive after the start of the planning plan. A novel mixed integer linear program (MILP) is developed to optimize the berthing schedule and build a transshipment connections planning between feeder and mother vessels. The aim is to reduce vessels dwell times in the terminal, and the penalty due to late vessels and decide the mode of transshipment needed. First, we develop a packing heuristic, and later we use an improved genetic algorithm based heuristic (GA) to solve the problem efficiently. We conducted a statistical analysis to identify relative importance and effective settings for parameters control of the GA, and we applied this algorithm with the control parameters settings determined to carry out the computational experiments on random generated instances. The proposed tailored method is able to solve the problem in an acceptable computing time for medium and large instances while a commercial solver was able to solve only small size instances.},
  archive      = {J_COR},
  author       = {Marwa Al Samrout and Abdelkader Sbihi and Adnan Yassine},
  doi          = {10.1016/j.cor.2023.106409},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106409},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved genetic algorithm for the berth scheduling with ship-to-ship transshipment operations integrated model},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A column generation approach for the team formation problem.
<em>COR</em>, <em>161</em>, 106406. (<a
href="https://doi.org/10.1016/j.cor.2023.106406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a cooperative multi-team formation problem where there are multiple teams in an organization, and teams can be reformed by exchanging members among each other. We formulate this problem as a nonlinear integer programming model, by later reformulating it, which prescribes the optimal exchange decisions for all teams that maximizes the minimum resulting team value across all teams. For this problem, in order to obtain tighter dual bounds, we propose a column generation approach where each column represents specific exchange decisions of a team pair, and at each iteration, a set of attractive exchange patterns for all team pairs are generated by a series of subproblems . We implement a parallel processing scheme to solve all subproblems in order to further accelerate the procedure. In addition, to obtain near-optimal solutions, we propose a column generation-based methodology, where at the last iteration, the restricted master problem is solved as an integer programming model with all generated columns. Our results show that the column generation procedure provides dual bound improvements ranging between 2.44% and 5.31%, on average, over the linear programming relaxation of the original model for our generated instances. In addition, the proposed column generation-based methodology yields near-optimal, and in most cases, optimal solutions by providing CPU savings ranging from 71.6% to 89.2%, on average, over the CPU times of the original integer model.},
  archive      = {J_COR},
  author       = {Megan Muniz and Tülay Flamand},
  doi          = {10.1016/j.cor.2023.106406},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106406},
  shortjournal = {Comput. Oper. Res.},
  title        = {A column generation approach for the team formation problem},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Simultaneous location and vehicle fleet sizing of relief
goods distribution centers and vehicle routing for post-disaster
logistics. <em>COR</em>, <em>161</em>, 106404. (<a
href="https://doi.org/10.1016/j.cor.2023.106404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The occurrence of a sudden-onset disaster such as a major earthquake brings about a great deal of uncertainty in, for example, the severity of damage to the road network and other infrastructure across the disaster region, the traffic flow conditions in the post-disaster network, and the demand for relief goods at relief centers. Despite these uncertainties, crucial decisions must still be made both before and rapidly after the occurrence of the disaster such that the logistical operation of relief goods distribution can have the greatest possible chance of success. In this research, we propose a two-stage stochastic programming model in which the first stage optimizes the location of relief goods distribution centers as well as the number of vehicles allocated to the logistical operation, while the second stage determines the best vehicle and inventory routing decisions for the logistics operation in the critical first time window after the random factors associated with the disaster are revealed. We collaborate with the National Science and Technology Center for Disaster Reduction (NCDR) in Taiwan to effectively model post-disaster road network conditions and the speed of vehicle traffic as a function of earthquake parameters (e.g., magnitude, time of strike). An efficient simulation optimization algorithm with feedback is proposed to tackle the two-stage stochastic programming model. We carry out an empirical study that consists of a set of experiments based on real data from NCDR to investigate the impact of critical factors in the proposed model under a variety of different conditions. Managerial insights are derived for decision makers pertinent to both the preparation and response phases of a sudden-onset disaster.},
  archive      = {J_COR},
  author       = {Kuo-Hao Chang and Yi-Chieh Chiang and Tzu-Yin Chang},
  doi          = {10.1016/j.cor.2023.106404},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106404},
  shortjournal = {Comput. Oper. Res.},
  title        = {Simultaneous location and vehicle fleet sizing of relief goods distribution centers and vehicle routing for post-disaster logistics},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Heuristic algorithms based on column generation for an
online product shipping problem. <em>COR</em>, <em>161</em>, 106403. (<a
href="https://doi.org/10.1016/j.cor.2023.106403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a product shipping problem (PSP). Given a time horizon and a set of products, each with a weight, a release date, and a due date, the PSP calls for product shipping to be planned between a fixed origin–destination pair so as to minimize the total shipping cost . Given several types of boxes with different sizes and shipping costs, packing several products into one larger box may lead to cheaper shipping costs than sending them separately in smaller boxes. The online PSP is a problem with an online constraint that requires a decision to be made for each day without knowing about future demands or being able to change boxes that have already been packed and shipped. For the online PSP, we propose column-generation-based algorithms with six different criteria, incorporating ideas such as iterative surplus reduction, and heuristic column generation . In the computational experiments, we tested 15 types of online algorithms under each criterion. Computational results on three different sets of instances show that one type of the proposed algorithms with one of the six criteria called “regret with cost of remaining capacity” obtains high-quality solutions with average gaps of 3.4% over all the tested instances.},
  archive      = {J_COR},
  author       = {Wei Wu and Mayu Ito and Yannan Hu and Hiromichi Goko and Mihiro Sasaki and Mutsunori Yagiura},
  doi          = {10.1016/j.cor.2023.106403},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106403},
  shortjournal = {Comput. Oper. Res.},
  title        = {Heuristic algorithms based on column generation for an online product shipping problem},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Formulations for the clustered traveling salesman problem
with d-relaxed priority rule. <em>COR</em>, <em>161</em>, 106402. (<a
href="https://doi.org/10.1016/j.cor.2023.106402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the classical Traveling Salesman Problem , the order in which the vertices are visited has no restrictions. The only condition imposed is that each vertex is visited only once. In some real situations this condition may not be sufficient to represent the problem, as there are cases in which the vertex visit order becomes extremely important. In other words, it is also necessary to consider a priority between the vertices. To deal with these situations, some formulations are proposed in the literature and are based on a rule called d d -relaxed priority rule that captures the trade-off between total distance and vertex priorities. In this paper, the formulations from the literature are improved using valid inequalities and different formulations based on precedence variables are proposed. Computational results, based on data from the literature, are presented to demonstrate the competitiveness of the proposed approaches.},
  archive      = {J_COR},
  author       = {Eduardo dos Santos Teixeira and Silvio Alexandre de Araujo},
  doi          = {10.1016/j.cor.2023.106402},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106402},
  shortjournal = {Comput. Oper. Res.},
  title        = {Formulations for the clustered traveling salesman problem with d-relaxed priority rule},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A matheuristic for tri-objective binary integer linear
programming. <em>COR</em>, <em>161</em>, 106397. (<a
href="https://doi.org/10.1016/j.cor.2023.106397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world optimisation problems involve multiple objectives. When considered concurrently, they give rise to a set of optimal trade-off solutions, also known as efficient solutions. These solutions have the property that neither objective can be improved without deteriorating another objective. Motivated by the success of matheuristics in the single-objective domain, we propose a linear programming-based matheuristic for tri-objective binary integer linear programming . To achieve a high-quality approximation of the optimal set of trade-off solutions, a lower bound set is first obtained using the vector linear programming solver Bensolve. Then, feasibility pump-based ideas in combination with path relinking are applied in novel ways so as to obtain a high-quality upper bound set. Our matheuristic is compared to a recently suggested algorithm that is, to the best of our knowledge, the only existing matheuristic method for tri-objective binary integer linear programming. In an extensive computational study, we show that our method generates a better approximation of the true Pareto front than the state-of-the-art matheuristic on a large set of tri-objective benchmark instances. Since the developed approach starts from a potentially fractional lower bound set, it may also be used as a primal heuristic in the context of linear relaxation-based multi-objective branch-and-bound algorithms.},
  archive      = {J_COR},
  author       = {Duleabom An and Sophie N. Parragh and Markus Sinnl and Fabien Tricoire},
  doi          = {10.1016/j.cor.2023.106397},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106397},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic for tri-objective binary integer linear programming},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal locating by integrating volumetric fuzzy sets and
geographic coordinate system: An application to healthcare.
<em>COR</em>, <em>161</em>, 106377. (<a
href="https://doi.org/10.1016/j.cor.2023.106377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The volumetric fuzzy set (VFS) deals with the uncertainties associated with two-dimensional variables. This study shows the application of VFS in finding the optimal coordinates for a new hospital by considering several fuzzy goals. For this purpose, we first define two types of volumetric fuzzy goals: type one following the proximity to an ideal point and type two following far from an anti-ideal point. Then, we extract the membership functions (MFs) for type-one and type-two volumetric fuzzy goals. These MFs determine the membership degrees of each point for volumetric fuzzy goals based on its distances from the ideal or anti-ideal points. We consider the Manhattan distance to extract these MFs because it better measures the real distance between two points in urban areas. Next, we design a new weighted volumetric fuzzy multi-objective decision-making (VFMODM) model considering type-one and type-two fuzzy goals. This model answers this question: what are the optimal coordinates for a new hospital to maximize overall satisfaction? Compared to existing fuzzy optimization models, the VFMODM model considers uncertainty for two-dimensional variables.},
  archive      = {J_COR},
  author       = {Hosein Arman and Abdollah Hadi-Vencheh and Amir-Mohammad Golmohammadi and Sanaz Dehghani and Mohammad H. Nadimi-Shahraki},
  doi          = {10.1016/j.cor.2023.106377},
  journal      = {Computers &amp; Operations Research},
  month        = {1},
  pages        = {106377},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal locating by integrating volumetric fuzzy sets and geographic coordinate system: An application to healthcare},
  volume       = {161},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
